[00:03:24] *** Quits: tyson2 (~user@bras-base-toroon0628w-grc-46-142-112-141-177.dsl.bell.ca) (Ping timeout: 252 seconds)
[00:04:06] <shka> oh, rubel made a quite recovery
[00:04:12] <shka> shame that i can't see any
[00:13:14] <waleee> I think it might be because the trade with them trickled down with the russian prohibition for citizens to buy dollar/euro
[00:24:17] <selwyn> shka: so this football club owned by an oligarch keeps getting screwed over and it is very funny
[00:24:33] <selwyn> their sponsors are pulling out one by one
[00:25:26] <selwyn> their fans are not the smartest and chant his name during the minutes respect for ukraine before games
[00:37:25] <selwyn> it seems that i know someone who worked on these x ray lasers
[01:00:18] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-08-70-29-36-27.dsl.bell.ca)
[01:28:19] <hayley> What the hell, Bakerposting died to a SIGSEGV? And SBCL didn't trap it?
[01:29:18] *** Joins: Bakerposting (~Bakerpost@n122-104-71-229.sun4.vic.optusnet.com.au)
[01:29:46] *** Quits: Bakerposting (~Bakerpost@n122-104-71-229.sun4.vic.optusnet.com.au) (Remote host closed the connection)
[01:30:18] <Duuqnd> That's the most disappointing thing I've heard all week, I think
[01:35:06] *** Joins: Bakerposting (~Bakerpost@n122-104-71-229.sun4.vic.optusnet.com.au)
[01:35:28] <hayley> Bakerposting: how ironic
[01:35:28] <Bakerposting> In either case, the percentage of objects which can be successfully reclaimed by lazy allocation will be greatly increased. (CONS Should not CONS its Arguments, or, a Lazy Alloc is a Smart Alloc <https://plover.com/~mjd/misc/hbaker-archive/LazyAlloc.html>)
[01:35:29] -ixelp- ACM Sigplan Notices 27, 3 (Mar 1992), 24-34.
[01:35:46] <hayley> pony
[01:35:46] <Bakerposting> OMG!! Ponies!!!
[01:36:08] <hayley> I added some more articles, but I am still reminded that I need to redo my sentence splitting code. 
[01:39:10] <hayley> Bakerposting: gimme one of the new ones
[01:39:11] <Bakerposting> The bit-xxx-3 functions have two read streams and a write stream, and come in both from-start and from-end versions. (Efficient Implementation of Bit-vector Operations in Common Lisp <https://plover.com/~mjd/misc/hbaker-archive/Bitvectors.html>)
[01:39:11] -ixelp- ACM Lisp Pointers 3, 2-4 (Apr/Jun 1990), 8-22.
[01:39:20] <hayley> No, not that one.
[01:41:51] <pl> shka: the problem with highly enriched fuel for breeders is overrated (in fact, some breeders don't need enriched at all, like CANDU and the infamous RBMK), and for the media darling thorium (which can't start otherwise) linacs were proposed as solution
[01:42:35] <hayley> Hm, problem is the new ones don't have many sentences in them.
[01:42:39] <shka> pl: yeah, i know, but CANDU is still not production ready and RBMK... well
[01:42:53] <shka> has a safety flaw
[01:43:05] <pl> shka: ummmm, CANDU has been used for  over 40-50 years now?
[01:43:07] <pl> in production?
[01:43:12] <shka> huh?
[01:43:58] <pl> the problem with "no enriched uranium needed" breeders is that they either need a kickstart and fast neutron scheme, or require graphite or heavy water moderators
[01:44:00] <shka> pl: i confused this with candu smr
[01:44:22] <pl> CANDU's problem was cost of heavy water and USA hitting them in proliferation risks
[01:45:56] <shka> RBMK was pretty cost efficient design otherwise
[01:47:35] <shka> i wonder how history would play out if chernobyl didn't happen
[01:47:47] <shka> perhaps there would be dozens RBMK reactors constructed
[01:49:00] <gilberth> I am not so sure that Chernobyl actually made such a difference.
[01:49:39] <hayley> https://www.youtube.com/watch?v=V43iobDBNW8
[01:49:40] -ixelp- My Way / When Do I Get To Sing 'My Way' (Live in London 2018) - YouTube
[01:51:37] * hayley spots that the POSSIBLY-SIMILAR-STATES table has 7 entries, whereas there are 482 states so far.
[02:04:05] * hayley looks in REMOVE-TAGS and finds that she wrote (KLEENE (REMOVE-TAGS R)) for the INVERT case. Oops.
[02:04:27] <hayley> Doesn't help, but it better get fixed sooner than latter.
[02:09:45] *** Quits: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20) (Quit: ERC (IRC client for Emacs 27.1))
[02:14:49] <hayley> I found («A»|B)*(¬C)(¬D)E makes a lot of states here. And it's quite slow at it.
[02:19:42] <pl> shka: Chornobyl actually failed soviet safety requirements
[02:20:00] <pl> shka: and apparently KGB "cleaned up" after another accident early on
[02:22:20] <shka> pl: Russian classic at this point
[02:22:29] <shka> pretend that problem does not exists
[02:23:23] * hayley uploaded an image: (48KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/WtlxDDVYAiGFFdeDlSkKScFJ/Screenshot%20from%202022-03-13%2009-51-21.png >
[02:23:26] * hayley gives helpful advice to C++ students
[02:24:01] <shka> good night all
[02:24:41] <kakuhen> good night
[02:25:01] <kakuhen> hayley: that is indeed useful
[02:25:19] <kakuhen> one of my friends is stuck in a C++ class and I showed him the copy-and-swap pattern
[02:25:47] <kakuhen> it's an ugly but most sane way to handle copying your own classes without having to track complicated allocation s
[02:25:56] <hayley> BDW GC: More likely to free memory than a C programmer™
[02:27:18] <shka> https://www.polytechnique-insights.com/en/columns/science/cleaning-up-nuclear-waste-with-super-powered-lasers/
[02:27:19] -ixelp- Super-powered lasers to transform nuclear waste - Polytechnique Insights
[02:27:49] <shka> Gérard Mourou seems to be also interested in using lasers for thorsium fission
[02:27:55] <shka> selwyn: ^^
[02:27:59] <kakuhen> huh, size_t is part of std?
[02:28:31] <kakuhen> i swore i used it without using the namespace before, but maybe that is clang doing implicit imports again, just like with assert()
[02:29:33] <shka> kakuhen: yes, it is part of C++, but is also part of C
[02:29:58] <shka> and because it is part of C, and headers are the way they are in, you probably was using C type, not C++
[02:30:21] <shka> selwyn: https://arxiv.org/abs/2008.03498
[02:32:13] <moon-child> kakuhen: <cstddef> -> guaranteed std::size_t, maybe size_t; <stddef.h> -> guaranteed size_t, maybe std::size_t
[02:32:17] <moon-child> basically
[02:33:02] <shka> selwyn: 
[02:33:03] <shka> In the preformation picture, the later-emitted nucleus
[02:33:05] <shka> oscillates back and forth within its parent nucleus. Ev-
[02:33:07] <shka> ery time it hits the potential wall, it has a probability
[02:33:08] <shka> of tunneling out.
[02:33:18] <shka> so this is how it is supposed to work
[02:35:15] <shka> selwyn: this could be really big
[02:39:27] <hayley> How tf is stack overflow real, just use Cheney on the MTA
[02:44:33] *** Quits: shka (~herr@109.231.3.55) (Ping timeout: 252 seconds)
[02:48:19] <gilberth> Bummer. GLX somehow ignores the SHAPE extension. What is it with GLX that it can only clip to a single rectangle and also can swap only a single rectangle? I mean, it obviously can deal with swapping a region composed out of more than one rectangle. Namely, when another top level window obscures yours. *sigh*
[02:50:08] <gilberth> For clipping I could use the stencil buffer just fine. But for swapping?
[02:58:21] <gilberth> Yep, when I set the shape of the top level window, it could do partial swaps. But that is not something I could use.
[03:08:46] <hayley> https://www.youtube.com/watch?v=MRqaLipoHYY
[03:08:47] -ixelp- 70s P*rno Music Tutorial - YouTube
[03:20:40] <gilberth> What works is having two subwindows. Render to the first, then render to the other. Each having their own glSwapBuffers. But: (1) would it work with creating and destroying subwindows on the fly? And (2) how to make sure that there is exactly one physical buffer swap despite two calls to glSwapBuffers?
[03:32:01] *** Joins: tophullyte (tophullyte@gateway/vpn/protonvpn/tophullyte)
[03:33:12] <gilberth> Nah, won't work. As I would need to remove those windows eventually and the X server would be helpful and clear bits for me. Or not. It's up to the X server. :'(
[03:40:26] *** Quits: random-nick (~random-ni@87.116.176.196) (Ping timeout: 272 seconds)
[03:48:49] <gilberth> Well, if I could depend on that my back buffer is the very same back buffer after two glSwapBuffers, I could just draw the union of the current and the previous dirty region. But that is a bet I won't make.
[03:50:22] <gilberth> This is a real pity. I am after minimal redraws. Like each a blinking cursor just sitting there. There is no reason to redraw the whole frame just because the cursor blinks there hoping to catch your attention.
[03:50:28] * gilberth takes a break.
[03:51:16] <gilberth> However in the blinking cursor case, the previous and the current dirty region would be equal.
[03:58:29] <hayley> .oO( Might not be a new thought, but I suppose that using CPython for an algorithms class forces students to focus on O() and not constants [e.g. time taken to cache miss/divide/branch/etc], since you can't optimise any other way. )
[04:08:17] <hayley> Adding some relatively constant latency to every "instruction" has the effect of making the relative difference in latency slower. Rather than, say, a 300ps add and a 2ns divide, you have, maybe a 5.3ns add and a 7ns divide.
[04:08:47] <hayley> The bytecode interpreter might also ruin superscalar execution, too, but I haven't tested.
[04:15:33] <gilberth> hayley, I suppose your class is about O calculus and not about some tricks you can play now given the exact CPU design you happen to have now given the compilers and tools you have now.
[04:16:01] <hayley> Yes, it is.
[04:16:25] <hayley> But most of the tricks are applicable to any complex CPU design, I think.
[04:16:50] <gilberth> hayley, what is it about O calculus that you haven't got?
[04:17:08] <gilberth> And do you know how CPUs will look like in 30 years?
[04:17:30] <hayley> I'm pretty sure I understand it. And I don't know what CPUs will look like in 30 years.
[04:18:16] <hayley> That said, teaching how to analyse imperative algorithms is going to be worthless if somehow CPUs go full on graph reduction/dataflow or something not Von Neumann-esque.
[04:18:42] <gilberth> That still are only constant factors.
[04:20:00] <gilberth> And data flow is so 90ies. Didn't caught on, although it's a very nice idea and super-scalar actually is very small-scale data flow implementation.
[04:20:46] <hayley> The Von Neumann bottleneck is a thing.
[04:21:13] <gilberth> Still only constant factors.
[04:22:09] <hayley> Still, if they motivate hardware manufacturers (somehow) to break decades of backwards compatibility, you're going to find yourself in trouble if you can only analyse for loops.
[04:22:47] <gilberth> hayley, nothing will change.
[04:23:13] <hayley> So we do know how CPUs will look in 30 years, and that is "the same"?
[04:24:39] <gilberth> hayley, as long as our machines fundamentally work like ours, nothing changes. A dataflow machine doesn't change your complexity.
[04:26:05] <hayley> Sure. But I can't imagine compiling a "for" or "while" loop to a dataflow machine. So if they only teach you to analyse such loops, you are screwed.
[04:28:13] <gilberth> No, you're not. Even if you formulate your algorithm differently, this doesn't change the O calculus.
[04:28:35] <kakuhen> i hate packages i hate packages 
[04:28:48] <gilberth> And besides, we don't need a new computing model for a dataflow machine.
[04:28:53] <hayley> They don't tell you how to analyse an algorithm that is formulated differently, though.
[04:28:56] <kakuhen> linking ffmpeg against an arib caption library may break libffmpeg's ABI and require me to revbump every single dependent of ffmpeg in macports
[04:29:19] <kakuhen> it looks like having to revbump mpv (dependent on ffmpeg) was foreshadowing this nightmare
[04:30:13] <kakuhen> while macports automatically scans binaries for linker errors, revbumps do not help you determine what ports to recompile because otool will report the exact same version number
[04:30:34] <gilberth> hayley: Don't your fellow students have a brain? Just count the number of operations you are interested in depending on the input size n. Done. And what other formulations are there to begin with? Recursion. Ok. What else?
[04:30:48] <kakuhen> AFAIK the linker error check is very simplistic and just makes sure (1) libraries outputted by otool indeed exist on your system, and (2) they match the version reported by otool
[04:31:34] <hayley> gilberth: There was once a tale of a Gopher that stated they liked only having for loops, and not e.g. map() because they couldn't imagine the complexity of map(), but could compute O(n^X) for X nested loops.
[04:32:14] <gilberth> What's so hard about map? That's trivial.
[04:33:05] <kakuhen> probably hard for them to guess the cost of copying an array or whatever they are iterating over
[04:33:13] <gilberth> The recursive definition of the Fibonacci function makes my brain hurt. That's tricky.
[04:33:18] <kakuhen> and compilers may do funky things to make sure a map() is equivalent to a for() loop
[04:34:00] * hayley searches r/programmingcirclejerk logs
[04:34:08] <hayley> https://www.reddit.com/r/programmingcirclejerk/comments/6f1xpa/it_is_very_easy_to_read_go_code_and_it_is_very/ Close enough?
[04:34:09] -ixelp- It is very easy to read [Go code] and it is very explicit and does not hide complexity. Meanwhile many expressive langua [...]
[04:34:11] <gilberth> kakuhen: We are talking about O calculus here. Copying an array of length n is O(n). Trivial.
[04:35:19] <hayley> https://www.reddit.com/r/programmingcirclejerk/comments/5sc8h8/go_takes_a_relatively_strict_stance_on_making_the/ Here's an O(n^k) claim, even.
[04:35:20] -ixelp- Go takes a relatively strict stance on making the _how_ obvious to the programmer. It goes out of its way to avoid hidin [...]
[04:36:32] <kakuhen> my experience reading Go code is that I find it too verbose heh
[04:36:38] <hayley> https://i.imgur.com/jfTNQeD.png
[04:36:44] <gilberth> hayley: So what do you want to tell? That people are uneducated and don't know what a fold or map is?
[04:36:50] <kakuhen> or if you run a function that can return error, i want to be able to know what errors it can return, but it's not obvious at all from seeing `if err = nil { return err }`
[04:36:58] <hayley> gilberth: Yes.
[04:37:31] <kakuhen> common lisp is almost the same, but at least I can expect someone running code that handles various conditions will likely wrap it all under a handler-bind or handler-case
[04:37:44] <kakuhen> rather than `if err != nil { return err }` a million times
[04:37:52] <gilberth> Which complexity has append()? It's not safe to assume it's O(1).
[04:37:54] <hayley> Protip: you can do a map-reduce with one function call by (reduce #'reducer sequence :key #'mapper)
[04:38:15] <gilberth> It's reasonable to assume that map() is O(n) by itself.
[04:38:45] <hayley> Tricky. The worst case of append() is O(n) if you copy, so one might think O(n²). But you tend to double the backing array size, so you only hit the worst case O(log n) times. Thus O(n log n)
[04:39:39] <hayley> A sufficiently smart compiler could guess the size of the resulting array. And I think JavaScript engines do something similar w.r.t picking enough slots for an object, when you create one by "foo.bar = baz; foo.quux = quack; ..."
[04:39:44] <gilberth> See. I my opinion append() is hiding more here than map(). As I would claim a map not being O(n) in itself buggy.
[04:40:35] <gilberth> What is such a vector [1,2,3]? A linked list? With a tail pointer? Then append() could be O(1). A vector? Then it can be O(n) or just O(log n). Hmm.
[04:40:48] <hayley> e.g. <https://v8.dev/blog/slack-tracking> V8 gives objects some room to grow, until it can properly predict how many slots you will use.
[04:40:48] -ixelp- Slack tracking in V8 · V8
[04:41:14] <hayley> gilberth: Don't worry, I've seen O(n²) map. Think you have too, in the past.
[04:41:25] <gilberth> append() could also be O(1), if you bump allocate and no other allocations happen between append()s. :-p
[04:41:56] <hayley> Granted, counting repeated calls to append() in a loop is a bit harder than propagating the slots used in straight line code.
[04:42:20] <gilberth> hayley: Yes, but I would still call a O(n^2) map() buggy. For both vectors and linked lists.
[04:42:30] <hayley> Sure.
[04:43:45] <gilberth> With vectors I would call an O(log n) append() fine. For lists, I won't be surprised with an O(n) append. Like CL:APPEND. You could have a tail pointer and have O(1). I repeat myself.
[04:47:38] <hayley> Still, they feel the need to elaborate on "find the order of growth of the number of times some operation is done w.r.t input size", and show specifically how to handle for and while loops and such. (Recursion is the topic of this week, I think.)
[04:52:18] <gilberth> Makes sense, as I could imagine that most people have less difficulties with loops than with recursion. But even loops could be tricky. Imagine we write what append() does right into that little loop. With like if (n >= room) { room = 1.5 * room; realloc buffer; }. Now what? Loops still easy?
[04:53:42] <hayley> Irregardless of all that, I also can't imagine, say, a division being faster than assignment, because division is more complex than addition. Nor can I imagine a return to the olde days where you'd finish a load in 1 instruction, just due to physics and propagation delay.
[04:54:42] <gilberth> Yes, but that still are only constant factors. Doesn't matter much.
[04:54:57] <hayley> So I'd feel pretty comfortable saying those will remain the same in 30 years. And the O() still matters there, of course, but the difference in constant factors is pretty big.
[04:55:32] <gilberth> Besides that there usually is hand-waving assuming that arithmetic operations show how are O(1).
[04:55:45] * hayley nods
[04:56:17] <Alfr> gilberth, fixed sized ones are.
[04:56:19] <gilberth> Somehow, rather.
[04:56:21] <hayley> I remember Cliff Click once spoke of doing some pretty spiffy decompression algorithms, just to stretch out memory bandwidth. The decompression would be done all in registers.
[04:56:50] <gilberth> Alfr: Is 32-bit x 32-bit multiplication on an ARM7 O(1)?
[04:58:17] <gilberth> hayley: Yes, you are young an can afford to chase the last cycle to squeze out of something. If you grow older, you'd learn that this is not important.
[04:58:46] <hayley> So, tell me about your lexer again...
[04:59:25] <Alfr> gilberth, sure. Their time cost certainly is bounded by a constant factor wrt input size.
[04:59:27] <gilberth> hayley: My lexer is faster because of a better algorithm.
[04:59:49] <gilberth> Alfr: Input size also is bounded. Thus all is O(1) :-p
[05:00:07] <Alfr> gilberth, as the input size itself is bounded, you can fudge the constant factor so as to only consider the unit input size.
[05:01:19] <hayley> gilberth: Only a better algorithm?
[05:01:35] <Alfr> gilberth, that's why input-size usually is defined as length of representation in some positional system.
[05:03:07] <gilberth> It begins with that your /n/ is something. Take polygon clipping for instance (just because I am playing with that atm). The complexity is given in terms of /n/ edges. Each edge assumed to be of unit size. You would get a different result, when you also would consider the size of the coordinates in that edges. It actually is of some concern here, as you need bignums.
[05:04:25] <gilberth> hayley: For the most part, yes. And for submatch addressing: We don't need to discuss O(n) versus O(nm) with n being the input size and m the automata size.
[05:05:04] <Alfr> gilberth, assuming that your edges are bounded in size, just take the largest one and you can resort to counting edges for O-notation.
[05:05:20] <hayley> I believe I've found that compilation also helps, even for DFA against DFA.
[05:05:35] <gilberth> Alfr: Yes, what I said.
[05:06:23] <gilberth> hayley: Yes, but compilation doesn't change the O(). Compilation is not the trick per se. It's an implementation detail.
[05:06:32] <hayley> Should also mention that this compression stuff was for a machine learning system, and ML tends to be damn slow unless you try.
[05:07:13] <Alfr> gilberth, I just don't see why you aren't happy with that. One can always resort to trying to count operations ...
[05:08:15] <hayley> In a "maths for computing" assignment they wanted me to compare the performance of different configurations (or "hyperparameters"). I argued that, since training _one_ network took like 5 minutes on my machine, training enough to make a comparison worth anything would take far too long. Got no marks for that, still.
[05:08:15] <gilberth> Alfr: I am happy with that. All I said was, that there is hand-waving going on. And one should be careful in saying how input size is measured.
[05:09:20] <Alfr> gilberth, most of the time it boils down to the number of bits you feed into an algorithm.
[05:09:24] <gilberth> And what operations are of concern. With sorting a[i]=a[j] is assumed to be O(1). This is not true on a tape e.g.
[05:10:28] <Alfr> gilberth, with three tapes you can use MERGE.
[05:10:58] <gilberth> Alfr: Sure. But if it is the number of bits, you need to say that you don't do the O calculus with respect to the number of bits. And usually you don't. It always is: Given n edges. [Or segments rather] Not bits.
[05:11:11] <hayley> (That said, I've only managed to max out memory bandwidth with a memchr implementation. Doesn't help that I have a latency of like 3 cycles for any 256-bit operation on this machine.)
[05:11:53] <gilberth> Alfr: Yep. I always imagined that this is reason why you spot many tape drives on photos of ancient machines. But I really don't know.
[05:12:16] <Alfr> gilberth, assuming edges are bounded by size, then the size of all edges is O(n).
[05:12:22] <Alfr> s/by/in/
[05:12:45] <gilberth> Alfr: Yes. But then you don't talk about bits anymore.
[05:15:48] <Alfr> gilberth, if that n does end up in log or exp, you'll run into problems.
[05:16:28] <Alfr> gilberth, (as well as anything not a polynomial, maybe?)
[05:17:08] <gilberth> Alfr: What's the problem?
[05:27:08] <Alfr> gilberth, for a>1: f \in O(e^{a n}) => f \not\in O(e^n)
[05:27:28] *** Quits: tophullyte (tophullyte@gateway/vpn/protonvpn/tophullyte) (Ping timeout: 272 seconds)
[05:28:34] <Alfr> gilberth, so converting from number of elements to bits means you'll also need to change the bounding function.
[05:34:39] *** Quits: lucerne (~lucerne@ip202.ip-51-178-215.eu) (Read error: Connection reset by peer)
[05:37:04] *** Joins: lucerne (~lucerne@ip202.ip-51-178-215.eu)
[05:52:16] *** Joins: razetime (~quassel@117.254.34.148)
[05:54:32] <gilberth> Alfr: If you identify an input of size /n/ edges with /m/ bits, each edge /k/ bits, and show that T(m) \n O(f(m)) you then have to say T(n) is in O(f(n)) = O(f(kn)). That's obvious. The handwaving really happens here is that you assume that the cost for those k-bit arithmetic does not dominate T(n).
[05:57:02] *** Joins: OutsideContextPr (GreatFlea@168.138.73.107)
[05:57:16] <gilberth> Alfr: I believe we agree and there is no actual dispute and only me being bad at saying what he wants to say.
[05:59:20] <Alfr> gilberth, hm ... I think, your k-bit arithmetic cost, are those constant factors O hides.
[06:00:07] <gilberth> Meanwhile I wonder what an olde SGI would do when I just won't swap buffers? I assume that there was only one back buffer and the swapping done by flipping a single bit at the CRTC. Hmm.
[06:00:54] <gilberth> Alfr: They are. At the very the moment you say e.g. addition is O(1).
[06:06:31] <gilberth> And you can do that when your k is bounded. As in when you express T as T(n,k) this k mutates to just a constant in O(n,k). This really is a question about what you are interested in. It might happen that your algorithm is say O(k^2 f(n)), so you might reason that using 64 bits instead of 32 quadruples the time. And IIRC with polygon clipping it does. But I'm not sure.
[06:09:45] <gilberth> All I remember is that the precision you need grows quickly with the precision of your input with clipping. Which is why I limit the input precision even though we have bignums. I figure it is fair for it's use namely rendering graphics on a screen. What resolution do you really need? Below the wave length of light? Certainly not. :-)
[06:10:12] <gilberth> But, yes, still a constant factor only.
[06:10:34] * hayley looks up "How to draw Mandelbrot set faster" and gets results on using SIMD or multithreading.
[06:11:12] <gilberth> Poor hayley. She still chases constant factors.
[06:13:08] <hayley> Not true at all. I'm trying to cut down on how many pixels I actually have to compute, rather than how fast I can compute them.
[06:13:16] <moon-child> I wonder if there're hashlife-like algorithms for that
[06:13:56] <gilberth> Actually this is why I distaste this fast inverse square root or what ever bit fiddling trick hype with Quake. Quake was not feasible because of that but because of the clever use BSPs.
[06:14:14] <hayley> All I know of is a border tracing algorithm, where you chase just the edges of where iteration counts vary, and flood fill in between.
[06:14:35] <gilberth> And that works?
[06:15:19] <gilberth> Feels like a bet given that this is freaking fractal.
[06:15:20] <hayley> I struggle to discern a speed difference. /me needs more metering.
[06:16:45] * hayley meters and it seems 2x faster in CL.
[06:16:49] <kakuhen> i think fast inverse sqrt is popular mostly because it's "simple" in concept to understand from a math perspective
[06:17:01] <kakuhen> apply 1-2 iterations of newton's method and choose a very clever initial condition so you have fast convergence
[06:17:08] <kakuhen> the way they did it was pretty remarkable
[06:17:23] <kakuhen> but i'm not sure if i've seen people claim this implementation is why quake was able to render anything "fast enough" on hardware at the time
[06:18:37] <gilberth> See. And this is what I said. It's not this routine which saved the day, but the data structures. Without those clever data structures, you would sink even on a recent GPU.
[06:18:38] <kakuhen> note by "fast convergence" i'm actually referring to "speed of convergence"
[06:18:49] <kakuhen> ah, I guess that's a fair argument
[06:19:18] <kakuhen> i like fast inverse sqrt mostly because of how they set up newton's method to get something that converges quickly to 1/sqrt(x)
[06:20:16] <gilberth> More clever is what they did to 1/z in texture mapping with Quake 1.
[06:20:53] <gilberth> As you can't really afford one division per pixel on a Pentium.
[06:21:55] * hayley wishes SBCL could figure out type inference for iteration variables in loops.
[06:22:15] <gilberth> So they do it only every 16th pixel and interpolate in between. Clever mipmapping is the other part of the story. But that also are mere constant factors.
[06:22:28] <hayley> (do ((xi 0.0 (+ (- (* xi xi) (* yi yi)) x)) (yi 0.0 (+ (* 2.0 xi yi) y)) (i 0 (1+ i))) ((or (= i 200) (> (+ (* xi xi) (* yi yi)) 4)) i) ; X and Y are SINGLE-FLOAT, *read-default-float-format* is SINGLE-FLOAT
[06:22:37] *** Parts: OutsideContextPr (GreatFlea@168.138.73.107) (The Lounge - https://thelounge.chat)
[06:24:10] <hayley> After optimising that iteration loop, naively computing each pixel isn't much slower than the worklist. Hm.
[06:30:42] <pl> gilberth: arguably, clever BSPs were not enough for Quake, and it's related to why "faster 486" couldn't run it well while pentium did, until significant speedup over release-day pentium was achieved
[06:32:42] <pl> their software renderer as released depended on being able to issue, iirc, X integer ops per floating point op, and they made it so that the results of the floating point op would be ready by the time they needed them to adjust next bunch of pixels
[06:35:10] <pl> fast inverse square root only happened in Quake III, iirc
[06:38:07] <edgar-rft> how do I become fast inverse square root on linux?
[06:38:40] <pl> https://www.vogons.org/viewtopic.php?p=787542#p787542
[06:38:41] -ixelp- Quake without FPU \ VOGONS
[06:41:13] <hayley> I had a nice GLSL shader which would draw the Mandelbrot set, which ran tolerably on a smartphone GPU.
[06:46:01] * hayley gets bitten by using single-floats pretty quickly.
[06:47:10] <gilberth> pl: Yep. But that are still constants factors. The things mentioned are just clever coding, nothing more and nothing needing all too much of a brain. Grasping how the visibility pre-computation works takes a few more brain cells.
[06:48:54] <gilberth> I mean, in 0.1% of the code they actually reasoned about the two integer and one floating point unit. Besides not much FP happening while texture mapping.
[06:49:56] <gilberth> And that is my point. This clever and more or less obvious constant factor optimizations sure are clever, but not the major part of cleverness in Quake.
[06:51:08] <gilberth> It's only that with the other cleverness its not suffice to point to a dozen assembly instructions. And that pre-computation is not even part of the game executable.
[06:52:52] <gilberth> Speaking of which. I once found a very nice and straight forward implementation from scratch of a Quake rendering engine. Easy to read and quite small. I lost it. Can't even remember its name.
[06:58:57] *** Quits: clothespin_ (~awolven@c-73-209-95-92.hsd1.il.comcast.net) (Remote host closed the connection)
[07:06:17] <pl> gilberth: I see the 16pixel fdiv trick to be akin to HAKMEM and similar, helping reach the performance on actual hw when you already did the smart thing in the large
[07:06:42] <kakuhen> today I learned ccl:neq is a thing
[07:07:09] <kakuhen> i'm very tempted to write (ccl:neq index 0) because of how hilarious it is, but I want this to be portable, so (plusp index) it is
[07:17:44] *** Quits: razetime (~quassel@117.254.34.148) (Read error: Connection reset by peer)
[07:25:35] *** Quits: dre (~dre@2001:8003:c932:c301:5689:c0f3:d693:ff24) (Ping timeout: 252 seconds)
[07:26:03] *** Quits: luis (~luis@lisp/luis) (Quit: The Lounge - https://thelounge.chat)
[07:29:14] <gilberth> pl: It's just a piece-wise approximation of 1/z. Nothing exciting.
[07:30:41] *** Joins: luis (~luis@lisp/luis)
[07:30:44] <hayley> .oO( I could run the code on a GPU and win due to having so many damn cores, but then I'll lose precision even with double floats. Solution: use an FPGA to compute. Problem: I don't have an FPGA. )
[07:35:53] <moon-child> gpus are _supposed_ to round properly.  In practice they cheat.  But they cannot cheat at integer math; maybe softfp or fixedpoint will still win?
[07:36:30] <hayley> The issue in any case is that I run out of bits eventually.
[07:40:59] *** Quits: lucerne (~lucerne@ip202.ip-51-178-215.eu) (Remote host closed the connection)
[07:41:28] *** Joins: razetime (~quassel@117.254.34.148)
[07:41:51] *** Joins: lucerne (~lucerne@ip202.ip-51-178-215.eu)
[07:43:16] *** Joins: semz_ (~semz@user/semz)
[07:46:02] *** Quits: semz (~semz@user/semz) (Ping timeout: 260 seconds)
[07:46:59] * moon-child downloads more ram
[07:49:33] <hayley> https://twitter.com/96Stats/status/1502696581552013314
[07:49:36] <hayley> "Rumours on Chinese social media that the Queen has died. A factory in Yiwu, China (famous wholesale factory) has received a peculiar order from the UK of the British flag with the Queen's face and 1926-2022 underneath ..."
[07:52:08] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[08:13:01] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Quit: WeeChat 3.4)
[08:19:29] * pl expects to find Elizabeth the second strolling the regrowing fields as nature heals from nuclear war
[08:33:06] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-08-70-29-36-27.dsl.bell.ca) (Remote host closed the connection)
[08:33:53] *** Joins: dre (~dre@2001:8003:c932:c301:bcc3:636b:c0a:15ba)
[08:54:57] *** Quits: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340) (Ping timeout: 240 seconds)
[08:59:39] *** Quits: v3ga (~v3ga@2603-6080-5204-3b35-e149-f31f-1120-01f3.res6.spectrum.com) (Ping timeout: 252 seconds)
[09:01:31] *** Joins: v3ga (~v3ga@cpe-98-25-21-91.sc.res.rr.com)
[09:12:13] *** Quits: dre (~dre@2001:8003:c932:c301:bcc3:636b:c0a:15ba) (Ping timeout: 240 seconds)
[09:15:19] * hayley watches CPython sort 100,000 integers with someone's bubblesort implementation
[09:18:58] <dave0> poor bubble sort always getting picked on
[09:19:03] <hayley> .oO( But how many limbs do I have to sell for an FPGA that would suffice? And recall I need memory for a framebuffer too. )
[09:20:06] <hayley> .oO( Though, I could survive would I just have a small framebuffer. The idea is to have enough work at a time, so that I could have multiple independent processors running in parallel, without starving. Even 256x256x32 bits would likely suffice. )
[09:20:51] <hayley> .oO( This also means that I could have a host computer calculate the ranges of computation with its own ratio type, so that I don't have to work it out in hardware. Which leaves me with a few multipliers and adders to implement. )
[09:29:47] <hayley> dave0: it's me I'm picking on bubble sort
[09:40:15] <dave0> it's the little sort that could
[09:54:25] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[09:55:17] *** Joins: dre (~dre@2001:8003:c932:c301:efa8:3ab4:6d9d:737a)
[09:55:33] *** Quits: Bakerposting (~Bakerpost@n122-104-71-229.sun4.vic.optusnet.com.au) (Ping timeout: 256 seconds)
[10:10:38] * hayley measures stupid Quicksort to be 2280x faster than bubblesort
[10:11:01] <hayley> This is the "stupid" kind because it's the functional style with list partitions and all. Whereas "real" Quicksort is in place.
[10:12:38] <hayley> There doesn't seem to be -lgc on the university server, so sadly using Boehm for memory management in C++ is not possible.
[10:13:22] <moon-child> catenate the entire source of bdw to your own source
[10:13:55] <hayley> I suppose that could work.
[10:14:24] * hayley is fancy and writes Böhm in student chat
[10:15:00] * hayley wonders if ö is actually "oe" in English. Someone else wrote it like that. Maybe.
[10:16:46] <contrapunctus> hayley: that's an alternative to umlauts. e.g. Müller <-> Mueller
[10:17:38] <hayley> Right, thanks!
[10:20:46] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Read error: error:1408F119:SSL routines:ssl3_get_record:decryption failed or bad record mac)
[10:21:01] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[10:22:19] * hayley draws out a Mealy machine for the Mandelbrot churning core.
[10:23:51] <hayley> I'd still need a counter for handing out work to each core still. It'd probably work like a bus arbiter.
[10:26:10] <hayley> There's also the frame buffer, but it should fit in device memory hopefully.
[10:26:25] <dave0> i copied the code for making a mandelbrot from wikipedia
[10:32:18] <hayley> I wonder how the average Verilog "compiler" fares with a 256-by-256-bit multiplier.
[10:38:35] <kakuhen> given how it is in general impossible to have frame-accurate and sample-accurate seeking, i wonder how media players synchronize video and audio trackers after the user seeks to a specified timestamp
[10:38:53] <kakuhen> do we just get a bunch of sub-1ms errors that accumulate over itme
[10:38:59] <hayley> Bakerposting: foo
[10:39:12] <hayley> Again?
[10:41:24] *** Joins: Bakerposting (~Bakerpost@n122-104-71-229.sun4.vic.optusnet.com.au)
[10:41:42] <hayley> I guess I have to program in reconnection to Bakerposting.
[10:41:42] <Bakerposting> Since an EXTENDED cell cannot point to another EXTENDED cell, the forwarding of EXTENDED pointers need not be iterated. (List Processing in Real Time on a Serial Computer <https://plover.com/~mjd/misc/hbaker-archive/RealTimeGC.html>)
[10:41:43] -ixelp- Comm. of the ACM 21, 4 (April 1978), 280-294.
[10:47:51] *** Joins: Lycurgus (~juan@98.4.112.204)
[10:49:34] <ck_> dave0: how long do you leave it in the oven for?
[10:50:55] <dave0> a bun in the oven?
[10:54:47] <ck_> the Mandel Brot
[10:55:15] <Lycurgus> really?
[10:57:25] <ck_> I'm sorry are you here for serious discussion?
[10:58:21] <Lycurgus> nope, which by the way is title of a film coming out that i'm not gonna see
[10:59:09] * ck_ .oO( These .. are the members ... of the airplane?! )
[11:00:16] <Lycurgus> get out was good, us was not and i doubt nope will be any better
[11:01:36] <ck_> "The residents of a lonely gulch in inland California bear witness to an uncanny and chilling discovery."
[11:01:43] <ck_> time to learn what a gulch is
[11:02:05] <Lycurgus> its like a dry valley a big ditch
[11:02:20] <ck_> 3. A ravine, or part of the deep bed of a torrent when dry; a gully.
[11:02:26] <ck_> ah ok.  zOMG torrent pls
[11:02:46] <Lycurgus> that's his marketing gimmick he doesn't let the premis out
[11:03:08] <Lycurgus> which worked for get out because it was fairly original
[11:03:28] <ck_> do you like horror movies in general?
[11:03:41] <Lycurgus> but actually what you just summarized is enough to reject
[11:03:54] <ck_> that's just the tagline from imdb
[11:04:01] <Lycurgus> in general no, and I'm stopping cartoons and melodramas period
[11:04:31] <Lycurgus> but even so there are good ones
[11:04:41] <Lycurgus> Fresh is pretty good for example
[11:08:18] <Lycurgus> cartoons, irc, porn, relief from dealing with real humongs in the flesh
[11:10:22] <ck_> I see, escapism.  have you made your nominal cup yet by the way?
[11:10:35] <Lycurgus> nominal cup?
[11:11:18] <ck_> "Lycurgus cup"
[11:11:32] <Lycurgus> ah
[11:11:50] <Lycurgus> i forget what that's for, lemme check
[11:12:06] *** Quits: lucerne (~lucerne@ip202.ip-51-178-215.eu) (Remote host closed the connection)
[11:12:07] <Lycurgus> oh yeah just remembered
[11:12:15] <Lycurgus> it's an antiquity
[11:13:25] <ck_> some see it as evidence of very advanced materials engineering
[11:13:40] <Lycurgus> and it was made about 1200 years after its namesake lived
[11:13:52] <Lycurgus> which he probably in fact did 
[11:17:26] <Lycurgus> stuff from classical and late antiquity can seem advanced because there was thousand years where the barbarian ancestors of the modern northern european crashed cultural standards
[11:18:40] *** Joins: lucerne (~lucerne@ip202.ip-51-178-215.eu)
[11:19:41] <ck_> we're not so far from going into another regression
[11:23:43] <Lycurgus> i don't think so
[11:24:22] <Lycurgus> fortunately we're past the time of discrete civilizations
[11:24:44] <Lycurgus> and even when the west faded it was a local dip
[11:25:10] <Lycurgus> india and china were doing quite well in that period
[11:25:41] <Lycurgus> not to mention the islamic world
[11:30:06] <Lycurgus> a NATO - Russia conflict would probably only clear out a lot of dead wood
[11:30:39] <ck_> I guess we'll see, or someone else will, later on
[11:31:19] <ck_> although there was some news in the paper recently, all the time.  "peak soil"?  Probably about agriculture.  (I only look at the pictures)
[11:32:09] <Lycurgus> it's mostly in minor details that don't make the headlines but both sides have shown they have no intention of really having a hot war
[11:32:37] <Lycurgus> like russia requesting the hotline
[11:32:52] <Lycurgus> or the US refusing the polish mig transfers
[11:33:06] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Ping timeout: 250 seconds)
[11:33:07] <ck_> yeah
[11:33:25] <ck_> https://favim.com/orig/201105/07/Favim.com-37184.jpg
[11:36:04] <Lycurgus> it irks me they're starting to spell it like it was that fermented japanese dish Nato
[11:37:15] <Lycurgus> ok so that's natto
[11:38:25] <ck_> who?
[11:39:08] <Lycurgus> https://en.wikipedia.org/wiki/Natt%C5%8D
[11:40:05] <ck_> I meant who is "starting to spell it ..."
[11:40:16] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[11:40:19] <Lycurgus> instead of NATO, it being an acronym
[11:40:59] <Lycurgus> maybe because nobody paid it much attention for a generation or so
[11:41:18] <ck_> yes but who, who is doing that, what is the group of people that you see doing this
[11:41:38] <Lycurgus> the MSM, cnn and the like
[11:42:19] <hayley> https://www.youtube.com/watch?v=G4LMqCb6jPM
[11:42:19] -ixelp- This Commodore PET has 3096.01066 bytes free! That can't be right. - YouTube
[11:42:31] <Lycurgus> typically some hack staff writer for one of them
[11:42:59] <Lycurgus> in yurope they use periods for commas
[11:42:59] <ck_> oh, ok.. haven't ever seen that spelling though
[11:43:14] <ck_> only in numbers
[11:43:55] <ck_> also, it's "NATO - OTAN", thank you very much
[11:44:06] <Lycurgus> ah i c
[11:44:27] <Lycurgus> an inappropriate float looks like
[11:45:08] <Lycurgus> yeah it's an english speaking world thing
[11:53:51] <ck_> where are you in the world?
[11:54:23] <Lycurgus> between toronto and buffalo
[11:54:59] <ck_> so it's "FOUR O'CLOCK IN THE MORNING" why are you here
[11:55:05] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Ping timeout: 272 seconds)
[11:55:19] <Lycurgus> well i mostly go by utc
[11:55:31] <ck_> you shall be known as Zulucurgus
[11:55:57] <Lycurgus> and actually the time standard just changed 25 min ago, moving forward an hour to utc-4
[11:56:33] <ck_> where do you put them
[11:56:42] <ck_> your daylight savings
[11:57:23] <Lycurgus> ur sayin they don't to that in yurope?
[11:57:25] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[11:57:30] <Lycurgus> *do that
[11:57:38] <ck_> oh no we still do unfortunately
[11:57:46] <ck_> it was a jab at the concept and naming
[11:58:11] <ck_> the change is on the last weekend in march I believe
[11:58:17] <Lycurgus> lots of places don't
[11:58:38] <Lycurgus> it doesn't make any sense in countries near the equator
[11:59:14] <Lycurgus> i think they moved it up here 
[11:59:14] <ck_> I know what you're saying, but it doesn't really make sense at all to me
[12:02:44] <Lycurgus> also when it moves forward, you loose an hour
[12:03:10] <ck_> only if you don't take it back in autumn
[12:03:26] <Lycurgus> i'll be back later to flog more of your puns
[12:03:29] <ck_> otherwise it gets put in the daylight savings account for savings of daylight
[12:03:36] *** Quits: Lycurgus (~juan@98.4.112.204) (Quit: Exeunt)
[12:03:46] <ck_> see ya
[12:04:27] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Ping timeout: 252 seconds)
[12:29:07] *** Quits: razetime (~quassel@117.254.34.148) (Ping timeout: 256 seconds)
[12:29:44] *** Joins: razetime (~quassel@117.254.34.148)
[12:40:03] *** Joins: lisp123 (~lisp123@120.154.103.52)
[12:50:05] <hayley> "Dynamic program measurement will be feasible if it is partially preprocessed at compile time. Given that enough of these economies and services can be made available, it will pay to routinely design compiler systems that have built in machinery to handle the necessary bookkeeping." per https://digitalassets.lib.berkeley.edu/techreports/ucb/text/ERL-m-524.pdf
[12:55:02] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 240 seconds)
[13:11:19] *** Joins: dickbar__ (~dickbaren@86-90-132-28.fixed.kpn.net)
[13:14:06] * hayley uploaded an image: (358KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/SebijAcfJeqlyIkvugzXGflh/unicycle.gif >
[13:14:12] <hayley> scymtym's copy of Baker's site has this unicycle picture.
[13:30:40] *** Quits: mala (~mala@user/malaclyps) (Read error: Connection reset by peer)
[13:30:48] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 252 seconds)
[13:32:45] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[13:33:15] *** Joins: mala (~mala@user/malaclyps)
[13:36:05] *** Joins: cosimone (~user@93-44-187-176.ip98.fastwebnet.it)
[13:44:22] *** Joins: shka (~herr@109.231.3.55)
[13:54:58] *** Quits: lisp123 (~lisp123@120.154.103.52) (Remote host closed the connection)
[13:56:33] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[13:57:43] *** Joins: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net)
[14:04:26] *** semz_ is now known as semz
[14:18:21] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Quit: WeeChat 3.4)
[14:23:51] <kakuhen> any windows users here? how is emacs+slime on windows with and without wsl2?
[14:24:02] <kakuhen> i somehow got one of my friends interested in common lisp
[14:24:22] <moon-child> 'how is [...] windows with and without wsl2?'
[14:24:28] <moon-child> dismal and abysmal both ways
[14:24:31] <moon-child> I cannot speak to emacs
[14:24:36] <kakuhen> :(
[14:24:47] <kakuhen> although i am very inclined to give him a similar emacs+sly as mine, i also want to see if there's something less painful, since i heard emacs isn't the best on windows
[14:24:57] <moon-child> yeah I also heard that
[14:25:08] <moon-child> probably no downside to trying wsl version
[14:25:10] <kakuhen> the problem is idk if a SLIME equivalent exists for vscode, and he doesnt really like vscode either 
[14:25:17] <kakuhen> even though i insist to him "vs code is basically the best choice on windows"
[14:25:38] <kakuhen> unless you want to tinker with WSL to get emacs or vim working flawlessly
[14:25:44] <moon-child> isn't plain vs the best chocie on windows?
[14:25:57] <kakuhen> but if a simple install of emacs and sly/slime/whatever isnt buggy on windows then i think ill go with that
[14:26:26] <moon-child> my understanding is the process of getting wsl working is not super convoluted these days
[14:27:37] * |3b| uses windows with msys2, and emacs is pretty much normal aside from annoying window manager
[14:29:32] <|3b|> msys2 is pretty easy to set up too (at least for people who don't mind using pacman in a bash shell)
[14:30:27] <|3b|> (i use slime, but i assume sly works too)
[14:33:05] <moon-child> wsl2 maybe appreciably faster than msys2.  Windows is pretty slow
[14:33:19] <moon-child> (though both will beat up cygwin with a poleaxe, of course...)
[14:34:58] * |3b| hasn't noticed any problems with performance either
[14:37:11] <|3b|> hmm, wsl2 on win11 looks interesting, can run gui apps diretly, including hardware opengl
[14:37:28] <|3b|> too bad i don't have win11 hardware :(
[14:37:45] *** Quits: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net) (Ping timeout: 256 seconds)
[14:38:15] <moon-child> I would count that as a win
[14:38:17] <moon-child> personally
[14:38:58] *** Joins: lisp123 (~lisp123@120.154.103.52)
[14:39:03] <|3b|> not having a choice whether to run win11 or not is a win?
[14:39:16] <|3b|> (well, i guess it is a win10 at least :p)
[14:40:02] <moon-child> well, suppose I think win11 is a bad idea.  Then, as a consumer, aren't I well-served by representing the portion of the market which can not run win11?
[14:40:09] *** Joins: X-Scale` (~ARM@83.223.233.31)
[14:40:42] <moon-child> (granted, I am not very 'socially conscious'.  But it is the principle of the thing.)
[14:41:00] *** Quits: X-Scale (~ARM@219.206.137.78.rev.vodafone.pt) (Ping timeout: 272 seconds)
[14:41:01] *** X-Scale` is now known as X-Scale
[14:41:42] <|3b|> well, i didn't want to run win10, but got dragged into doing that, so might as well run 11 too
[14:42:06] <moon-child> why do you have to run win10?
[14:42:13] <moon-child> I still have 8 on my old laptop
[14:42:31] * |3b| made the mistake of somewhat liking 8.1, which unlike 7 got completely dropped by any sort of support from anyone
[14:43:06] <edgar-rft> I still have a computer with Windows 2000 (no joke)
[14:43:24] *** Quits: lisp123 (~lisp123@120.154.103.52) (Ping timeout: 240 seconds)
[14:43:38] <|3b|> (in particular i couldn't run games with raytracing, along with a few other random programs and hardware that supported 7 and 10 but not 8.x)
[14:44:00] <moon-child> ah huh
[14:44:26] <moon-child> the hw raytracing stuff sounds cool ... if only it were possible to acquire such hardware
[14:44:37] <kakuhen> <|3b|> "hmm, wsl2 on win11 looks..." <- yeah im gonna test emacs on win11 tomorrow, possibly with wsl2
[14:44:48] <kakuhen> that way this wednesday when i meet my friend, i can set up emacs on his computer with little hassle
[14:45:11] <kakuhen> apparently me constantly telling him stories of my horribly broken common lisp programs got him interested
[14:45:26] <kakuhen> and he really dislikes vs code, and editors that don't let you use a mouse
[14:46:44] <moon-child> does any editor not let you use a mouse?
[14:46:52] <moon-child> like, it'll refuse to launch if you have one plugged in
[14:47:10] <kakuhen> well, he was mostly complaining about neovim I think?
[14:47:15] <kakuhen> he doesn't like editors that need to be driven entirely by the keyboard
[14:52:24] * |3b| probably wouldn't bother with wsl2 without that direct GUI support and hardware opengl, but i mostly do graphics stuff so that probably biases my choices :)
[14:53:18] <|3b|> running a separate X server sounds annoying
[14:54:00] <|3b|> but probably either wsl2 or msys2+mingw is fine for most people
[14:56:28] <|3b|> (possibly lean towards msys2+mingw if you hope to make things for other windows users to use, if that matters)
[14:56:58] * |3b| wonders if you could run wine inside wsl2 to run windows builds in :p
[14:57:20] <|3b|> (or alternately, how hard it would be to call out to the host to run builds)
[14:59:44] <kakuhen> i allegedly heard wine is useful for getting newer windows software to run on older windows, which is ironic
[15:05:07] <pl> |3b|: why not use native GUI support for WSL2? 
[15:06:54] <pl> (as annoying as it can be due to being Wayland based) 
[15:07:14] *** Joins: notzmv (~zmv@user/notzmv)
[15:07:46] <|3b|> pl: is that available on win10?
[15:08:18] * |3b| was talking about X in the case where the native wasn't available, and thought native is win11 only
[15:08:32] <pl> Hmm.... Think I used it on Win10, not sure if they didn't do shenanigans on ot
[15:08:43] <hayley> Can I simplify |3b| to 3|b|? Not that there are any systems where it matters, methinks.
[15:10:19] <|3b|> hayley: |3b|, 3|b|, 3\b, 3b, all are fine
[15:10:35] * |3b| is less likely to notice 3|b| or 3\b though, since i don't have those highlighted
[15:10:36] * hayley takes notes
[15:10:53] <hayley> So (>= b 0)?
[15:11:13] <hayley> Rather (not (minusp b)) would I write it in CL.
[15:11:33] <moon-child> I think the former form is easier to parse
[15:11:39] <moon-child> because it is flatte
[15:11:41] <pl> Ahhh, https://github.com/microsoft/wslg/issues/347 
[15:11:41] <moon-child> r
[15:11:42] * |3b| uses || in the cl symbol syntax, not the math notation :)
[15:11:42] -ixelp- shipping with windows 10 21h2 or windows 11 · Issue #347 · microsoft/wslg · GitHub
[15:12:15] <kakuhen> that reminds me in my code recently I wrote (>= x 0) and though to myself "maybe i should write (not (minusp x)) instead
[15:12:18] <hayley> I see.
[15:12:33] <|3b|> used to be _3b but i stopped using c-like languages much so changed it :)
[15:13:11] <moon-child> wherefore the \?
[15:13:36] <|3b|> \ is single-character equivalent of || in cl symbol syntax
[15:13:44] <kakuhen> https://plaster.tymoon.eu/view/2982#
[15:13:53] <kakuhen> this is the context, feel free to tell me there's more efficient way to do what i am doing
[15:14:22] * |3b| would use (>= x 0) before (not (minusp x))
[15:14:48] <|3b|> unless possibly translating from something that describes it as non-negative
[15:15:30] <|3b|> though in that case i might just use plusp and swap the if
[15:15:42] <|3b|> minusp i mean
[15:24:27] <hayley> After https://twitter.com/theemilyaccount/status/1490857367004905473 I didn't feel right joking that I'd keep someone warm in L1 cache.
[15:25:30] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-08-70-29-36-27.dsl.bell.ca)
[15:26:16] * hayley now wonders if Krystof is Mr Rhodes. Probably is, but her memory is bad and she isn't olde enough to have seen all the nicks.
[15:26:52] * |3b| discovers that apparently this mouse has a switch to go from clicky wheel to smooth wheel... feels odd hitting that without expecting it :p
[15:28:03] <|3b|> hayley: yes, as far as i know. isn't that the main nick lately?
[15:28:30] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 252 seconds)
[15:28:30] <hayley> I didn't know.
[15:29:47] <hayley> pony
[15:29:48] <Bakerposting> OMG!! Ponies!!!
[15:30:13] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[15:30:15] * |3b| can't remember many other nicks, Xof, maybe Xophe?
[15:30:36] <hayley> .oO(X = Christ, think Xmas)
[15:34:05] <kakuhen> if i end up releasing a semi-decent library for processing audio streams and stuff, how likely will i be able to get interest from ppl in cl community
[15:34:19] <kakuhen> i ask this because i want to eventually work on opus decoder, also purely in common lisp, but it's even heavier than everything ive done so far
[15:34:43] <hayley> I have no idea. It might be random.
[15:34:56] <kakuhen> now that i finally have a sane codebase for processing linear pcm, mu-law pcm, flac, and maybe even apple lossless once i bother writing a simple mp4 parser
[15:35:08] <kakuhen> im slowly but surely trying to factor out a bunch of stuff i find myself repeating
[15:35:20] <kakuhen> and try making some library for handling an audio codec in general
[15:35:33] <kakuhen> that way you can program against a bunch of defgenerics or whatever and add support for more codecs to this lib
[15:35:43] <tyson2> there are many factors other than technical quality that affect the popularity of such tools
[15:36:14] <hayley> Legend has it that Valve developers thought the bouncy hoop at the end of Portal 1 would be the meme, but instead the cake blew up as a meme. So I don't try to predict social patterns.
[15:36:24] <kakuhen> hmm... good argument
[15:36:39] <kakuhen> that reminds me i also want to document eveeything thoroughly
[15:36:49] <kakuhen> my spring break is coming soon so i can waste all day on english and japanese documentation
[15:37:29] <hayley> Not dissimilarly, I thought the Netfarm suite would be my big project, but that obviously didn't happen. But I figure more people want to do regexes than do distributed programming.
[15:37:38] <edgar-rft> my spring is broken long ago :-)
[15:37:44] *** Joins: lisp123 (~lisp123@120.154.103.52)
[15:37:53] <tyson2> The way that dbotton is promoting Clog is impressive
[15:39:49] <tyson2> Crossing the Chasm is a relevant book
[15:41:31] <|3b|> kakuhen: is https://github.com/shamazmazum/easy-audio yours? if not might give some indication of likelihood of interest
[15:41:32] -ixelp- GitHub - shamazmazum/easy-audio: Lossless audio decoder written in common lisp
[15:41:43] <kakuhen> no
[15:41:49] <kakuhen> i have various github alt accounts and none of them have lisp code yet
[15:41:54] <hayley> Having a general audio file/codec protocol would be nice, but apparently having a general DHT protocol wasn't nice enough.
[15:41:54] <|3b|> someone wrote it, and got at least 2 bug reports :)
[15:42:00] <kakuhen> i plan to make an n-th alt account to release my actual audio library
[15:42:12] <kakuhen> that or i will use one of my friend's gitea instance
[15:42:16] *** Quits: lisp123 (~lisp123@120.154.103.52) (Ping timeout: 250 seconds)
[15:42:43] <kakuhen> it depends on how much i want to indoctrinate my japanese friends into learning common lisp
[15:43:15] <kakuhen> flood a friend's gitea instance with a bunch of completed lisp projects just so he sees what is using so much resources lol
[15:43:23] <kakuhen> suddenly using so much resources*
[15:44:23] <hayley> http://git.bsd.gay/closos/closos
[15:44:23] -ixelp- closos/closos: A very gay operating system written in, but especially inspired by Common Lisp and its interactive enviro [...]
[15:44:40] <kakuhen> oh that reminds me i saw bsd.gay a year or two ago, and i managed to see the person on fedi
[15:44:45] <hayley> No gay BSD, only CLOSOS
[15:44:53] <kakuhen> based (on common lisp)
[15:45:02] <hayley> Based (on nothing)
[15:46:13] <hayley> "A very gay operating system written in, but especially inspired by Common Lisp and its interactive environment. OwO"
[15:47:03] <hayley> Coming up with unfortunate fanfictions involving object capabilities is an exercise for the reader. But what if we were programs, and we shared capabilities, haha unless 😳 😳 😳
[15:50:00] <kakuhen> i need to sleep soon, but i have a song on loop and bikeshedding future design of my audio library
[15:50:25] <kakuhen> i may end up writing a toy srt parser and make a "repl interface" for subtitles 
[15:50:32] <hayley> I need to sleep an hour ago, but you don't see me complaining.
[15:50:38] <kakuhen> that way i can print subtitles on one thread while an audio track is playing
[15:50:41] <kakuhen> and i get to see the horror that is synchronizing things
[15:51:20] *** Joins: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net)
[15:53:23] <kakuhen> https://github.com/shamazmazum/easy-audio/blob/master/bitreader/crc.lisp
[15:53:23] -ixelp- easy-audio/crc.lisp at master · shamazmazum/easy-audio · GitHub
[15:53:25] <kakuhen> wow this is more genius than what I did
[15:53:42] <kakuhen> in my case I just (eval-when (:compile-toplevel :load-toplevel) ...) and it has a function to generate CRC table
[15:54:03] <kakuhen> except this guy seems to be hardcoding the polynomial
[15:57:31] <hayley> Evil Henry Baker: CONS should CONS its arguments
[15:58:16] *** Quits: lucerne (~lucerne@ip202.ip-51-178-215.eu) (Read error: Connection reset by peer)
[16:00:10] *** Quits: razetime (~quassel@117.254.34.148) (Ping timeout: 272 seconds)
[16:02:21] *** Joins: random-nick (~random-ni@87.116.176.196)
[16:09:32] <pl> https://fideo.info/wiki.lua/blog/sed-circuit-simulator
[16:09:34] -ixelp- Mi página web.
[16:14:57] <edgar-rft> short-circuit simulator: sed 's/.*//'
[16:30:51] *** Joins: Inline (~Inline@p200300cd473ac50039f51e8a2d5e1728.dip0.t-ipconnect.de)
[16:40:02] <dbotton> My goal tyson2 is to have the materials to promote Common Lisp to IT programmers and “full stack” people as much as to encourage use of CLOG which makes it possible to use in those environments CL in a way no web framework can
[16:40:17] <dbotton> My goal tyson2 is to have the materials to promote Common Lisp to IT programmers and “full stack” people as much as to encourage use of CLOG which makes it possible to use in those environments CL in a way no web framework can
[16:46:17] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[16:52:01] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[16:54:12] *** Joins: lucerne (~lucerne@ip202.ip-51-178-215.eu)
[16:56:25] <dbotton> I plan on adding full bindings to clog for https://plotly.com/javascript/ soon  as well support in builder
[16:56:25] -ixelp- Plotly javascript graphing library with JavaScript
[16:57:41] <dbotton> As more controls / bindings added i think will be a popular choice in many fields
[16:58:25] *** Joins: razetime (~quassel@117.193.4.214)
[17:00:16] <dave0> dbotton: are you dave?
[17:18:33] <dbotton> I never use dave as a name for myself
[17:19:49] <dbotton> I do my best to not be anonymous (mention it in tutorial 2 I think) :)
[17:21:07] <dbotton> I say enough foolish things, imagine what a person would say if he thought he was anonymous or untouchable
[17:22:39] <shka> https://www.youtube.com/watch?v=kdMG40wUCm4
[17:22:40] -ixelp- Interview with Senior Java Developer in 2022 - YouTube
[17:22:46] <shka> serious business 
[17:30:17] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Remote host closed the connection)
[17:31:17] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[17:37:42] <gilberth> Good morning #lispcafe!
[17:40:02] <tyson2> dbotton: I support the goals you mentioned.  I just wish I had more time to get into it myself.  Maybe next week...
[17:40:46] <dbotton> take a little at a time, it is the consistency not that amount that counts
[17:41:20] <tyson2> will give it a shot
[17:41:45] <dave0> dbotton: i know a dave botton
[17:42:02] <dave0> but it would be quite a coincidence if he was here :-)
[17:54:14] *** Quits: qhong (~qhong@rescomp-21-400677.stanford.edu) (Read error: Connection reset by peer)
[18:01:43] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[18:07:11] <dbotton> probably a relative, where does he live? (the only botton's not related are from Netherlands where it meant the people living on the bottom foor, there is one workind/used to work at 3M and Sun) 
[18:10:05] <dbotton> the rest go back to Solaniki (from Spain) and spread out from there after half the city burned in the late 1800s or after hittler wiped out the jews there. My family went to Egypt others England, France and US
[18:10:24] <dbotton> (Spain we all left in 1492 with inquisition)
[18:35:45] *** Quits: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net) (Ping timeout: 256 seconds)
[18:40:07] *** Quits: lucerne (~lucerne@ip202.ip-51-178-215.eu) (Remote host closed the connection)
[18:42:34] *** Joins: lucerne (~lucerne@ip202.ip-51-178-215.eu)
[18:43:17] *** Quits: razetime (~quassel@117.193.4.214) (Ping timeout: 240 seconds)
[18:52:03] *** Joins: razetime (~quassel@117.254.34.148)
[18:53:20] *** Joins: lisp123 (~lisp123@120.154.103.52)
[18:53:59] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[18:57:42] *** Quits: lisp123 (~lisp123@120.154.103.52) (Ping timeout: 250 seconds)
[18:59:32] *** Quits: robin (~robin@user/terpri) (Remote host closed the connection)
[18:59:59] *** Joins: lisp123 (~lisp123@120.154.103.52)
[19:02:23] *** Joins: robin (~robin@user/terpri)
[19:10:16] *** Quits: lisp123 (~lisp123@120.154.103.52) (Ping timeout: 250 seconds)
[19:11:30] <gilberth> As nice as the Scheme 'define' syntax is, it is curious. When I say (define (foo x) <something>) the <something> is evaluated each time I say (foo ..). Good. But when I say (define foo <otherthing>) the <otherthing> is not evaluated when I say 'foo'. Why?
[19:15:10] <|3b|> because one has () ?
[19:15:30] <|3b|> (define (foo) ...) vs (define foo ...)
[19:16:56] <gilberth> Sure. Still doesn't make sense, if you think about (define <term> <meaning>) to define what <term> should be, when used. As a kind of substitution.
[19:17:36] <gilberth> Nah, I believe this is a left-over from the idea of a functional language. A functional language has no side-effects and thus there isn't a difference.
[19:18:21] <|3b|> well, 
[19:18:58] <gilberth> I come across this because I wonder why these days arrays are special. Arrays are functions mapping indices to values. So why a different syntax or operator to evaluate an array for a given index?
[19:19:07] * |3b| gets distracted by hitting enter in the middle of sentence and forgets what i was saying
[19:21:06] <gilberth> I mean in this sense. Suppose A is an array. Then (a i j) could be fine for what is (aref a i j) in CL. [Or just a(i,j) instead of a[i,j] in infix]. And then there is a difference in (setf (a i j) ...) and (define (a i j) ...) Namely the time of evaluation of the "..." part.
[19:22:13] <gilberth> I could imagine a language working that way. Having a SETF redefining a term with being a value evaluated at the time of redefinition. And a DEFINE saying that this new value is to be evaluated each time used.
[19:22:21] <gilberth> I am just asking silly questions.
[19:23:13] <gilberth> [With early LISP, arrays were functions.]
[19:25:09] <gilberth> |3b|: And, yes, you're right. We see (foo) different from just 'foo'. As does e.g. C. But Pascal for instance doesn't. When you say 'foo' in Pascal, it could as well be a function with no arguments.
[19:26:00] <gilberth> In Common Lisp we even have two different name spaces for variables and functions.
[19:26:36] <|3b|> actually i guess scheme and c agree there, if you (define (foo)...) foo without () evaluates to the function
[19:26:56] <gilberth> That's the single name space nature. Yes.
[19:27:00] <|3b|> so it is the (foo) in the call that makes it evaluate the body
[19:27:07] <|3b|> not the () in the define
[19:27:30] <|3b|> the () in the define makes it not evaluate the body during definition
[19:28:07] <|3b|> so (define (foo) ...) is just to save you typing (define foo (lambda () ...))
[19:28:47] <gilberth> Well, technically it's a shorthand for (define foo (lambda ...)).
[19:29:29] * |3b| assumes scheme needs an argument list for lambda also
[19:30:05] <gilberth> Sure. it's in the ... :)
[19:30:28] <|3b|> ok, so that wasn't the same ... as in my example
[19:30:53] <gilberth> Anyhow, although I understand how Scheme or CL work. I am just wondering if a different perspective would lead to a sane language too.
[19:32:44] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-08-70-29-36-27.dsl.bell.ca) (Remote host closed the connection)
[19:33:12] <gilberth> However, when you allow for 'foo' to mean that it could invoke a function 'foo' instead of just yielding that function, you get into trouble. PostScript is in that trouble and solves it my marking objects and executable or not and allowing you to flip that tag. Not nice.
[19:33:48] *** Quits: robin (~robin@user/terpri) (Remote host closed the connection)
[19:35:27] <gilberth> I guess you'd then want to have currying. /me scratches head.
[19:41:29] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 256 seconds)
[19:43:34] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[19:46:02] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Quit: WeeChat 3.4)
[19:46:24] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[19:48:00] *** Quits: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com) (Client Quit)
[19:51:46] *** Joins: mfiano (~mfiano@cpe-67-240-71-179.nycap.res.rr.com)
[20:08:53] *** Joins: lisp123 (~lisp123@120.154.103.52)
[20:09:53] *** Joins: tyson2 (~user@cpe44d9e795a64f-cm688f2e2dfaa0.sdns.net.rogers.com)
[20:13:33] *** Quits: lisp123 (~lisp123@120.154.103.52) (Ping timeout: 256 seconds)
[20:27:44] *** Joins: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340)
[20:32:06] *** Quits: razetime (~quassel@117.254.34.148) (Ping timeout: 252 seconds)
[20:49:44] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[20:50:07] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[20:59:34] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[21:01:53] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[21:12:29] *** Joins: masinter (~masinter@c-73-158-116-21.hsd1.ca.comcast.net)
[21:20:49] *** Joins: robin (~robin@user/terpri)
[21:31:43] *** Quits: cosimone (~user@93-44-187-176.ip98.fastwebnet.it) (Quit: ERC (IRC client for Emacs 27.1))
[21:54:36] *** Quits: tyson2 (~user@cpe44d9e795a64f-cm688f2e2dfaa0.sdns.net.rogers.com) (Read error: Connection reset by peer)
[21:55:03] *** Joins: tyson2 (~user@cpe44d9e795a64f-cm688f2e2dfaa0.sdns.net.rogers.com)
[22:02:44] *** Quits: tyson2 (~user@cpe44d9e795a64f-cm688f2e2dfaa0.sdns.net.rogers.com) (Remote host closed the connection)
[22:13:16] <random-nick> doesn't clojure let you apply arrays and hashtables?
[22:18:26] <gilberth> The question is: Which is which? I mean, while it makes perfect sense to see hash table as a function mapping the keys, it doesn't make sense for what many languages call objects. Like JavaScript which conflates hashes with objects. So (funcall hashtable key) makes sense. Does (funcall object slot-name) make sense? Wouldn't (slot-name object) make more sense? Like with accessors in CLOS?
[22:21:50] <gilberth> This is all a bit blurry and also is about which way around you prefer currying. If you see x.f(y) as f(x)(y). It's common to say list.map(f), but not to say f.map(list). Both would make sense however. And Lisp historically had it both ways. e.g. Standard Lisp has (mapcar list fun).
[22:24:19] <gilberth> BTW with chaining you get funny infix syntax like in "a.union(b).union(c)" which could be viewed as "a .union (b) .union (c)"
[22:26:05] <gilberth> Hence with the message passing paradigm "a + b" is the "+" message sent to "a" with argument "b".
[22:26:54] <gilberth> Which of course is rather non-sense as "+" would need to dispatch on both "a" and "b".
[22:27:36] <ck_> clojure is a little weird in that regard, it allows (get map key), (map key) as well as (key map)
[22:27:58] <pjb> gilberth: and (+ a b c d) would need to dispatch on all the combinations and arities!
[22:29:16] <gilberth> ck_: That's indeed weird.
[22:30:42] <gilberth> pjb: Well, for + you could say that it really is binary and has 0 as identity and define n-arity + on terms of that. You'd need to pick whether it's left or right associative though.
[22:31:26] <pjb> While arguments are evaluated from left to right, the order in which they are added is not specified.
[22:31:45] <pjb> An implementation can sum the different types, and convert at the end.
[22:33:10] <gilberth> And? BTW I am not talking about CL here. But about syntax and programming languages in general.
[22:33:47] <ck_> 'fuck yeah I love nitpicking'
[22:34:05] <ck_> ackshually.. an implementation can just return the return value 'the-return-value
[22:34:17] <ck_> you didn't say "conforming implementation"
[22:34:22] <ck_> checkmate atheists
[22:37:38] <gilberth> ck_: Anyhow, thanks for the Clojure hint that it has both (map key) and (key map). So they realized that both could make sense. I promise to do my homework next time. ;)
[22:39:27] <ck_> thumbs up emoticon -- I hope you don't experience much disappointment
[22:39:31] *** Quits: edgar-rft (~edgar-rft@ip-109-193-249-223.um39.pools.vodafone-ip.de) (Remote host closed the connection)
[22:39:40] <ck_> compared to the clhs, many other docsets are a letdown
[22:39:50] *** Joins: edgar-rft (~edgar-rft@ip-109-193-249-223.um39.pools.vodafone-ip.de)
[22:40:17] *** Quits: Brucio-61 (~Brucio-72@ip-094-114-248-079.um31.pools.vodafone-ip.de) (Ping timeout: 240 seconds)
[22:41:26] <gilberth> Well, I have an idle sunday and ask silly questions about mappings, subroutines and syntax used. It always bothered me that there x.f(y) and f(x,y) in "modern" languages. The Clojure spec or whatever documentation doesn't have to be nice. It's interesting that they have it both ways.
[22:42:56] *** Joins: cosimone (~user@93-44-187-176.ip98.fastwebnet.it)
[22:43:43] <ck_> I didn't tell the whole story though, it's not as nice as I made it seem
[22:44:12] *** Joins: Lycurgus (~juan@98.4.112.204)
[22:44:27] <gilberth> And Lisp also has it both ways. It's (gethash key table) but (getf plist key). Then again (assoc key alist). And (nth i list) while it's (elt seq i). MAPCAR you find as (mapcar fun list) and as (mapcar list fun). For PUTPROP you find almost every permutation.
[22:51:37] <shka> "one way to do this" is a stupid idea anyway
[22:51:48] <random-nick> java and c# don't have f(x, y), just x.f(y), but sometimes x is some global constant
[22:52:43] <random-nick> well, not really global constant
[22:53:37] <random-nick> but the name of a class which contains f as a "static method"
[22:53:43] <gilberth> Yes, because both confuse modules with classes. Or rather make it easy to do so.
[22:54:38] <random-nick> c# or java have stuff like Math.cos(angle)
[22:54:44] <shka> uh, yeah
[22:54:52] <shka> Also
[22:54:55] <random-nick> wouldn't it make more sense for it to be angle.cos()?
[22:55:03] <shka> C# has C style pragmas
[22:55:06] <shka> which is weird
[22:55:09] <gilberth> To you send a "cos" message to a "Math" object? Makes sense. Not.
[22:55:50] <shka> mathematics don't lend itself toward message passing
[22:56:09] <gilberth> In Smalltalk you send messages to numbers.
[22:57:02] *** Quits: Lycurgus (~juan@98.4.112.204) (Quit: Exeunt)
[22:59:24] <gilberth> Anyhow, what really bothers me with those languages is that they are very un-modular as I usually define a new 'f' to work in x.f(y) outside the class definition of whatever class "y" is of. I can define a new f(x,y) though. Even if this really is self.f(x,y) or this.f(x,y) or whateverimpliedargument.f(x,y).
[23:00:27] <gilberth> * usually cannot define
[23:00:39] * gilberth needs a break.
[23:07:03] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 272 seconds)
[23:08:45] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[23:12:36] <moon-child> I think in js you can do that
[23:12:40] <moon-child> and maybe also python
[23:13:54] <gilberth> Yep, with its prototype object model in JS you can.
[23:14:52] <moon-child> raku is strange as it has both methods and 'multi' subroutines
[23:15:07] <moon-child> but a 'method' can also be 'multi' if it likes
[23:15:33] <gilberth> Raku is funny as it borrows a lot from CL.
[23:16:01] <moon-child> yeah
[23:16:28] <gilberth> When you read the spec at times you get the impression that it says "When I am grown up, I wanna be a Common Lisp."
[23:16:30] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[23:17:59] <gilberth> It even closes over non-local exits.
[23:18:18] <moon-child> yeah
[23:18:53] <moon-child> they also have continuations though
[23:19:15] <moon-child> (though I think those are implementation-specific, and not specified, perhaps for 'performance reasons')
[23:19:29] <gilberth> Perhaps.
[23:20:03] <gilberth> Anyhow, it feels like whoever came up with Raku did their homework.
[23:21:03] <moon-child> there are some mistakes.  But unlike cl, they have a versioning system, and code from different versions can coexist in the same image.  Which permits interesting things
[23:23:43] *** Joins: Brucio-61 (~Brucio-72@ip-094-114-248-079.um31.pools.vodafone-ip.de)
[23:27:56] <drakonis> raku seems like an absolute trip to learn
[23:28:19] <drakonis> featuring code that's even more cryptic to read than perl
[23:28:40] <drakonis> also it a MOP, wow.
[23:28:42] <drakonis> wild.
[23:32:34] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[23:43:42] *** Quits: Alfr (~Alfr@user/alfr) (Quit: Leaving)
[23:55:24] <selwyn> shka: you should have been a nuclear physicist
[23:55:53] <shka> selwyn: no, you SHOULD become a nuclear physicist :D
[23:56:03] <shka> quit that wobbly quantum stuff :P
[23:56:14] <shka> split atoms using lasers
[23:56:21] <selwyn> you also found a good review paper
[23:56:23] <shka> that's what cool kids are doing ;-)
[23:57:00] <shka> well, i am good at using google, that's why i am programmer (duh)
[23:58:18] <shka> i bet that selwyn is thinking about it :P
[23:58:22] <selwyn> protons oscillate in very intense laser fields
[23:58:36] <selwyn> which gives them a lot of kinetic energy
[23:58:44] <selwyn> which is how you can affect nuclear processes
[23:58:58] <selwyn> honestly, this makes nuclear physics look a lot like atomic physics (which i work in)
[23:59:10] <selwyn> except the wavelengths and physical systems are completely different
