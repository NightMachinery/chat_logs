[00:01:57] <two2thehead> kuudes, s0ph1a feep : I'm watching a playthough of a 2001 hidden object game. Mobile phones have made 'threats made by villains' more provable. ie Others can't claim that something just fell by accident and that the person you saw run away was just your imagination.
[00:08:48] <shawwwn> uiii
[00:13:49] <feepbot> <gwern> 'Pretzels, especially the kind you get from a vendor on nearly any corner in Manhattan, are the ultimate example of that sort of food to me. I love a good pretzel, and so I tried once again to see how the Pommery worked. I enjoyed the idea of using a mustard that costs three times as much as the pretzel. You can get jars of Pommery in the States, and it’s well worth the
[00:13:49] <feepbot> 12 to 14 bucks you’ll shell out. If you want to feel classy and upgrade your pretzel experience, use it. I felt like the Monopoly guy sitting there enjoying my pauper’s pretzel with a prince’s mustard. And since I’m talking about class, of course I brought a bottle of Grey Poupon (6). Anybody who grew up in the 1980s or ‘90s probably remembers the commercials where one
[00:13:49] <feepbot> rich guy would roll down the window of his Rolls Royce and ask the other rich guy in his Rolls Royce if he had any Grey Poupon, which helped make the mustard that has a French name but is actually made in America seem extra fancy. And I will say, even as I watched a rat scurry off with a piece of my pretzel in one of those disgusting “Only in New York” moments, that little hit
[00:13:54] <feepbot> of white wine in the Grey Poupon really made me feel like a fancy man.' https://www.insidehook.com/article/food-and-drink/30-best-mustards-tried-summer
[00:13:54] <feepbot> I Tried 30 Mustards This Summer. This Is What I Learned. - InsideHook (In 1975, James Beard ranked his 28 favorite mustards. Nearly 50 years later, I hunted them all down — and then some.)
[00:30:12] <feepbot> <gwern> 'The Chinese authorities “need to pay close attention to the potential negative inertia of population growth and make a plan with countermeasures in advance,” wrote Jiang in the study published in the Journal of Xian University of Finance and Economics. The new birth rate, though unexpectedly low, was based on data from the latest census , which is believed to be the
[00:30:12] <feepbot> most accurate yet because it was collected entirely with the aid of digital devices for the first time and cross-checked with other government data sets. Though the census findings have only partially been disclosed to the public, the limited information already shed a new light on changes and future development trends in the Chinese population, according to the researchers. “If
[00:30:12] <feepbot> the fertility rate drops to 1, in 29 years the population in our country will fall by half,” they said. According to the new census data, children make up about 17 per cent of the population, while the proportion of over-60s rose to over 18 per cent.' https://www.scmp.com/news/china/science/article/3150699/chinas-population-could-halve-within-next-45-years-new-study
[00:30:17] <feepbot> https://www.scmp.com/news/china/science/article/3150699/chinas-population-could-halve-within-next-45-years-new-study TFT is already 1.3...
[00:30:18] <feepbot> China’s population could halve within the next 45 years, new study warns | South China Morning Post (Researchers say previous estimates may have severely underestimated the pace of demographic decline.)
[00:35:12] <feepbot> <gwern> https://twitter.com/latent_entropy/status/1444029153276153860
[00:35:43] <|dbotdan> ∆S (@latent_entropy, 2021-10-01 19:59): ‘prompt engineering intensifies #CLIP #VQGAN @images_ai’ Images: https://nitter.mailstation.de/pic/media%2FFAo4ce7VgAQml3u.png%3Fname%3Dorig | https://nitter.mailstation.de/pic/media%2FFAo4jZYVgAI0CzU.png%3Fname%3Dorig | https://nitter.mailstation.de/pic/media%2FFAo4v05UcAEXgLr.png%3Fname%3Dorig |
[00:35:43] <|dbotdan> https://nitter.mailstation.de/pic/media%2FFAo41QOUUAQiRDq.png%3Fname%3Dorig
[00:36:13] <rmmh>  weird I don't see the connection to "engineering intensifies"
[00:38:00] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[00:38:25] <ivan> the first one there almost passes for real art
[00:38:38] *** Joins: srhm (~srhm@user/srhm)
[00:39:00] <ivan> ok never mind now that I look at it for more than 10 seconds
[00:39:05] <two2thehead> gwern, apparently treating your population like worker drones has bad consequences
[00:40:07] <gwern> rmmh: I assume latent has been grinding through lots of prompts to get these cool landscapes, and probably combining them etc
[00:40:51] <rmmh> (why link to a nitter mirror of a twitter image? their CDN doesn't perform any tracking)
[00:41:08] <gwern> more rliable and consistent?
[00:41:23] <rmmh> it's not, though
[00:44:54] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[00:45:59] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 252 seconds)
[00:46:12] *** Lord_of_Life_ is now known as Lord_of_Life
[00:46:15] <two2thehead> "A study published this month by the Chinese Academy of Sciences found that in the Yangtze River Delta, one of the most developed regions in the country, rapidly increasing housing prices have caused the area to have one of the lowest birth rates in the country."
[00:46:24] <two2thehead> I almost never see the hukou system mentioned
[00:46:34] <rmmh> it's not well known in the west
[00:47:06] <two2thehead> point, but this isn't a western news outlet
[00:47:34] <two2thehead> I guess they don't want to risk annoying the CCP head honchos
[00:48:42] <saturn2> rmmh: the bot uses nitter because nitter doesn't block bots, and just uses the image links as-is
[00:49:27] <rmmh> fair enough
[00:50:15] <shawwwn> .rr
[00:50:16] <feepbot> shawwwn: Clickclickclickclickclickclickbooom. You don't even hear the shot that ends you. Playing Russian Roulette with an automatic weapon was not your brightest idea in life, champ. Somewhere far away, Darwin smiles a knowing smile. You lose at life. Reloading.
[00:50:19] <Gurkenglas> what do you call the anthropic assumption that we're more likely to find ourselves in positions that matter? (such as on the spawning planet of our civilization, in the first world with high iq working on ai)
[00:51:21] <shawwwn> Gurkenglas: my mom’s assumptions
[00:51:31] <shawwwn> She always was self important
[00:51:41] <gwern> Gurkenglas: I'm not familiar with that assumption. why would you expect that?
[00:51:49] <Gurkenglas> more like updating towards it
[00:51:49] <saturn2> ancestor simulation argument, i guess
[00:52:08] <gwern> that doesn't seem like SSA or SIA... a simulation argument could give that if you assume tons of measure devoted to hinge-y times
[00:52:15] <shawwwn> SiA
[00:52:18] <two2thehead> shawwwn, I've heard of a your mom joke, but I've never heard of a my mom joke :V
[00:52:40] <shawwwn> SIA https://youtu.be/nYh-n7EOtMA
[00:52:52] <feepbot> Sia - Cheap Thrills (Lyric Video) ft. Sean Paul - YouTube (Official Lyric Video for "Cheap Thrills" by Sia feat. Sean PaulListen to Sia: https://sia.lnk.to/listenYDWatch more Sia videos: https://sia.lnk.to/listenYD/y...)
[00:53:11] <Gurkenglas> as a simple-to-describe hypothesis that wins out against SIA, seeing as SIA would put more credence on far-future observerspam
[00:54:28] <gwern> it may be simple, but why put any prior probability on it?
[00:54:59] <Gurkenglas> ...put prior probability on all the anthropic assumptions, then update towards the ones that work
[00:55:03] <gwern> there are certainly even simpler hypotheses, like "you are the first" or "you are the last", but we wouldn't consider those very good anthropic priors
[00:55:36] <Gurkenglas> yeah those two fought the bayes and the bayes won
[00:56:37] <gwern> I mean, even before updating on anything at all
[00:56:50] <gwern> 'sleeping beauty wakes up inside the featureless white cell' etc
[00:56:56] <Gurkenglas> sure, before updating on anything "you are the first" and "you are the last" get substantial probability.
[01:00:25] <Gurkenglas> (SMA does happen to stand out as corresponding to "just forget anthropic assumptions and do UDT", I guess?)
[01:04:23] * shawwwn enjoys a little orwellianism today https://www.youtube.com/watch?v=Yf12qTDBrPs&ab_channel=CBCNews
[01:04:33] <shawwwn> daily hate! daily hate!
[01:04:34] <feepbot> ‘I just signed your death warrant’: Larry Nassar's full sentencing - YouTube
[01:05:08] <gwern> Gurkenglas: so there's like 120b humans to date, let's say 10bish 'contemporary period', and then over the next century we spread to the stars and there's 100 trillion people before they change so much they are arguably outside our sampling frame. why should we expect to be in that 0.0...1% which is in the takeoff window, instead of 12x more likely in the prior history, or many X likely to be...
[01:05:14] <gwern> ...post-takeoff?
[01:05:36] <gwern> what mechanism forces that 10b to be ensouled as observers preferentially?
[01:05:41] <shawwwn> 120lb humans? they better eat more
[01:06:25] <Gurkenglas> im not saying that we should derive shawwwn's mom's assumptions from first principles and then be unsurprised at where we are; i'm saying that we should observe that we are near the plot's fulcrum and update accordingly
[01:07:14] <galambo__> gwern, yes but isnt there an argument that we are somewhere in the middle range simply because we exist today and it is unlikely we are some of the ancient people?
[01:07:30] <Gurkenglas> the fact that we are in an easily described 0.0...1% is a *hint* at the nature of meta-something.
[01:07:46] <shawwwn> I rather like the argument that the world is going to end soon because nukes were just invented
[01:07:50] <gwern> sure, I agree we are in what looks like 'the hinge', but that's drawn from tons of Inside View observations
[01:08:14] <galambo__> I think karnofsky's blog discusses this
[01:08:26] <shawwwn> what are the chances of us being born shortly after nukes were invented, if civilization lasts millions of years?
[01:08:37] <galambo__> shawwwn, exactly
[01:08:54] <Gurkenglas> don't forget that MWI is correct and there's a lot more than 100 trillion *expected* people sufficiently like us in our future
[01:09:23] <shawwwn> if only civilization ended tomorrw
[01:09:30] <Gurkenglas> aka, some of the futures deliberately stay similar, some deliberately breed
[01:10:48] <Gurkenglas> (i'm not convinced the "sufficiently like us" part needs to be stronger than, like, "would do acausal trade with us")
[01:15:49] <feepbot> <gwern> https://twitter.com/_rockt/status/1443862813156511744 https://twitter.com/y0b1byte/status/1443984263150542864  ow
[01:15:53] <|dbotdan> Tim Rocktäschel (@_rockt, 2021-10-01 08:58): ‘True story. I spent (i.e. wasted) half of my PhD doing (i.e. programming) tikZ figures, e.g. for TreeQN (https://arxiv.org/abs/1710.11417).  | The color of neural activations are randomly assigned every time you compile the PDF. Maybe that sparked my interest in progcen environments for RL?’ Images:
[01:15:53] <|dbotdan> https://nitter.namazso.eu/pic/media%2FFAmhG9PWQAAwIU4.jpg%3Fname%3Dorig (description: diagram; confidence: 1.00)
[01:15:53] <|dbotdan> yobibyte (@y0b1byte, 2021-10-01 17:00): ‘In RL, even PDFs are not reproducible!’ Images: https://nitter.domain.glass/pic/media%2FFAmhG9PWQAAwIU4.jpg%3Fname%3Dorig (description: diagram; confidence: 1.00)
[01:17:44] <saturn2> i think the doomsday argument is just straightforwardly true and all the SIA stuff is so much whistling past the graveyard
[01:18:43] <Gurkenglas> saturn2, but wouldn't it also predict doom in the world where nukes didn't exist but population still exploded, for the same reasons?
[01:20:22] <Obormot\Arcturus> What? The doomsday argument seems like total nonsense
[01:20:22] <kuudes> (what's SIA again?)
[01:20:29] <Obormot\Arcturus> kuudes: self-indication assumption
[01:20:40] <kuudes> thanks
[01:20:58] <Obormot\Arcturus> kuudes: Relevant post that just got posted (part 1 of 4): https://www.greaterwrong.com/posts/RnrpkgSY8zW5ArqPf/sia-greater-than-ssa-part-1-learning-from-the-fact-that-you
[01:21:00] <Gurkenglas> kuudes, predicts 1000/1001 that you're on the planet with the 1000 people, not the planet with the 1 people
[01:21:09] <feepbot> SIA > SSA, part 1: Learning from the fact that you exist - LessWrong 2.0 viewer ((Cross-posted from Hands and Cities) This post is the first in a four-part sequence explaining why I think that one prominent approach to anthropic reasoning is better than another. Consider: God’s extreme coin toss: [snip])
[01:21:16] <shawwwn> kuudes: https://www.youtube.com/watch?v=nYh-n7EOtMA&ab_channel=SiaVEVO
[01:21:17] <saturn2> Gurkenglas: i'm not sure i understand your question
[01:21:28] <feepbot> Sia - Cheap Thrills (Lyric Video) ft. Sean Paul - YouTube
[01:21:36] <Obormot\Arcturus> (Personally I think that SIA and SSA are both ... not even wrong? But maybe I am the one who's confused)
[01:22:20] <Obormot\Arcturus> This whole category of reasoning seems fundamentally nonsensical, and I don't understand why so many rationalist-types think it makes any sense
[01:22:32] <Gurkenglas> saturn2, ah, confused you with shawwwn.
[01:22:36] <Obormot\Arcturus> So maybe I'm just not getting something, but I've never seen it explained coherently
[01:23:22] <saturn2> Obormot\Arcturus: you don't even accept the idea of subjective probability, right?
[01:24:00] <Obormot\Arcturus> saturn2: Uhh, it's complicated, but I don't actually think rejecting that is necessary at all for me to be exactly this confused about the anthropic stuff
[01:24:03] <Gurkenglas> Obormot\Arcturus, suppose there's a thousand obormots in identical rooms numbered 1-1000, none know their number. If 1 presses, they each get 2 points. if 2-1000 press, that particular Obormot loses 1 point. Do you press?
[01:25:10] <Obormot\Arcturus> Gurkenglas: No, I guess (what is the significance of the points? maybe yes, depending on the answer to that)
[01:25:35] <Gurkenglas> You like points. You get a food you like for each point at the end.
[01:26:27] <Obormot\Arcturus> What does losing points do
[01:26:37] <Gurkenglas> Congratulations, you use SIA. (Huh, i expected the "Yes" answer. Misunderstanding? If 1 presses, *all* the obormots get 2 points.)
[01:27:07] <Gurkenglas> reduces the amount of foods you get to choose at the end...
[01:27:27] <Obormot\Arcturus> I don't know which obormot I am, presumably, right?
[01:27:34] <saturn2> something doesn't seem right about this thought experiment
[01:27:40] <Obormot\Arcturus> (Otherwise the exercise seems unmotivated)
[01:27:42] <rmmh> here we go extincting things again https://www.nature.com/articles/s41579-021-00642-4
[01:27:49] <Obormot\Arcturus> But also, why do they have to be obormots
[01:27:53] <feepbot> Influenza lineage extinction during the COVID-19 pandemic? | Nature Reviews Microbiology - The SARS-CoV-2 pandemic has seen a notable global reduction in influenza cases of both influenza A and B viruses. In particular, the B/Yamagata lineage has not been isolated from April 2020 to August 2021, su[snip]
[01:27:57] <Obormot\Arcturus> Why can't they be different people
[01:28:08] <Gurkenglas> Obormot\Arcturus, yeah, after reading the description and seeing enough evidence to convince you, you find yourself in a room like those described, and don't know which.
[01:28:08] <Obormot\Arcturus> Isn't this just the same as
[01:28:36] <Obormot\Arcturus> "There's 1k people in a room each, you're one of them, you don't know which # room you are. If the person in #1 presses... etc."
[01:29:02] <Gurkenglas> Sure, why not, let's do that.
[01:29:16] <Obormot\Arcturus> Then, if you press, your expected point gain is negative... assuming you think there's a uniform-random chance for you to be in any given room (which is maxent assumption afaii)
[01:29:28] <Obormot\Arcturus> So... what does this have to do with anything
[01:29:53] <Obormot\Arcturus> Likewise this is isomorphic to
[01:29:59] <Gurkenglas> UDT would say "given the choice between everyone to press and no one to press, i choose everyone, therefore i press"
[01:30:20] <saturn2> simpler question: you're in a town where everyone only drives cars from the town factory, which numbers all of the cars it makes sequentially. you don't know how many cars have been built, but you randomly see a car driving by with the serial number 10. what's the probability there are more than 100 cars in total?
[01:30:31] <Gurkenglas> (which does assume that the people in the other rooms also think along such lines)
[01:30:36] <Obormot\Arcturus> "You have been assigned a number uniform-random from 1 to 1000. If the # was 1 then if you press this button you gain 2 points, if it was anything else, you'll lose 1"
[01:30:49] <Obormot\Arcturus> Again the expected gain is obviously negative
[01:31:03] <Obormot\Arcturus> Bringing in multiple people, or multiple identical people, seems to add exactly nothing
[01:31:13] <Gurkenglas> Obormot\Arcturus, it's not isomorphic because if the # was 1 all the other's *also* gain 2 points
[01:31:27] <Obormot\Arcturus> Who cares
[01:31:34] <Gurkenglas> UDT :3
[01:31:37] <Obormot\Arcturus> Why
[01:31:59] <Obormot\Arcturus> I don't think UDT does actually
[01:32:01] <saturn2> then if you answer 10%, the same reasoning applied to you being the Nth human to have been born
[01:32:41] <Obormot\Arcturus> saturn2: I don't think the answer is 10%
[01:32:50] <Gurkenglas> Obormot\Arcturus, UDT would say that my setup is isomorphic to "there's one room; you are in it; to the sides are mirrors arranged such that there appear to be a thousand rooms; points are distributed as ..."
[01:32:53] <Obormot\Arcturus> I don't know why you'd say 10% tbh
[01:33:06] <saturn2> what would you say?
[01:33:46] <Obormot\Arcturus> It would depend on the size of the town, car ownership %, stuff I knew or guessed about factory size/production, lots of other stuff
[01:34:12] <saturn2> you don't know anything about that
[01:34:13] <Obormot\Arcturus> If I knew none of those things then I couldn't possibly conclude anything
[01:34:35] <Obormot\Arcturus> If I see a car #10 all I know then is that there's at least 10 that were made, nothing else
[01:35:00] <Obormot\Arcturus> Gurkenglas: Uhh I don't follow
[01:35:27] <Obormot\Arcturus> Gurkenglas: You still either gain 2 or lose 1 depending on the outcome of a 1d1000, right?
[01:35:37] <saturn2> but at some point you would have enough information to give a percentage chance that there are more than 100? how do you know when you've gone from not having enough information to having enough?
[01:36:24] <Obormot\Arcturus> saturn2: When you got 2 data points, obviously
[01:36:51] <kuudes> .wp german tank problem
[01:36:53] <feepbot> kuudes: https://en.wikipedia.org/wiki/German_tank_problem In the statistical theory of estimation, the German tank problem consists of estimating the maximum of a discrete uniform distribution from sampling without replacement. In simple terms, suppose there exists an unknown number of items which are sequentially numbered from 1 to N.
[01:36:54] <saturn2> why 2?
[01:37:38] <kuudes> https://en.wikipedia.org/wiki/File:German_tank_problem_graphs.svg
[01:38:03] <kuudes> if you only saw 1 car and its number was 10, your ml prior is that there are 20 cars
[01:38:42] <kuudes> the more cars you see the more you tend toward the max number you have seen is the number of cars produced
[01:39:24] <Gurkenglas> Obormot\Arcturus, in a one-time prisoner's dilemma against a randomly selected human from another universe, no communication before or after, cooperate or defect?
[01:40:50] <Obormot\Arcturus> saturn2: If there's 10 cars then the chance of seeing #1 is equal to the chance of seeing #10, but if there are 1000 cars then the chance of seeing #1 is still equal to the chance of seeing #10, which is equal to the chance of seeing #1000. Therefore, conditional on seeing any one #, you can't conclude anything, but once you've seen two #s, you can ask what is the expected difference between two numbers seen, compare it to
[01:40:50] <Obormot\Arcturus>  observed, condition on that.
[01:40:56] <saturn2> Gurkenglas: i don't see the point of going into these weird hypotheticals when we don't even agree on the fundamentals yet
[01:41:28] <Obormot\Arcturus> Gurkenglas: A *randomly selected human*? Of course defect, randomly selected humans don't know about PD or superrationality and, afaik, naive players choose D
[01:41:31] <Gurkenglas> saturn2, fundamentals are built on fuzzy language that one can argue onto so many tangents; hypotheticals make progress
[01:41:57] <Obormot\Arcturus> Gurkenglas: But what does this have to do with the original question?
[01:42:16] <Gurkenglas> Obormot\Arcturus, so presumably your answer changes if we replace the randomly selected human with an obormot
[01:42:30] <Obormot\Arcturus> Gurkenglas: Obviously C then
[01:42:48] <Obormot\Arcturus> But the thing with the thousand rooms isn't a PD, so again, what is the relevance
[01:43:04] <Gurkenglas> Obormot\Arcturus, the 1000 rooms question is similar to a prisoner's dilemma where the buttons is labelled "cooperate"
[01:43:10] <saturn2> Gurkenglas: i'm pretty sure your weird hypotheticals are just as built on fuzzy language and you're not making any progress
[01:43:17] <Gurkenglas> if everyone presses, everyone benefits over the situation where no one presses.
[01:44:12] <saturn2> Obormot\Arcturus: you can evaluate the difference between the number you saw and 0
[01:45:28] <saturn2> if there is 1 car, the chance of seeing #1 is 100%, if there are 2 it's 50%, if there are 3 it's 33.3%, etc
[01:50:29] <feepbot> <gwern> https://threadreaderapp.com/thread/1443926667026702391.html hm
[01:50:29] <feepbot> Thread by @Nate_Cohn: Perhaps even more important is recalling the flawed assumptions, data and conventional wisdom that made this piece so important at the time, even as it seems fairly obvious in some ways today ...…
[01:52:33] <Obormot\Arcturus> Gurkenglas: Oh, I see
[01:53:26] <Obormot\Arcturus> Gurkenglas: I think what we've proven is that you also have to condition on the probability of the relevant person not figuring out the problem structure correctly - and if it's more than 0.1%, well...
[01:53:42] <shawwwn> Spicy https://www.reddit.com/r/AmITheDevil/comments/pz20hh/i_never_loved_my_wife_and_wasted_her_time_oh_also/?utm_source=share&utm_medium=ios_app&utm_name=iossmf
[01:53:57] <feepbot> I never loved my wife and wasted her time. Oh also I'm scared of surgeries so I made her get her tubes tied even though I might one day divorce her and find love with someone else. Am I selfish? : AmITheDevil (306 votes and 89 comments so far on Reddit)
[01:58:43] <feepbot> <gwern> https://mattsclancy.substack.com/p/remote-work-and-the-future-of-innovation
[01:58:44] <feepbot> Remote Work and the Future of Innovation - by Matt Clancy - What's New Under the Sun (Why I'm an Optimist)
[02:00:30] <Gurkenglas> Obormot\Arcturus, if everyone who figures out the problem structure correctly presses, that's better for everyone who figures out the problem structure correctly than if everyone who figures out the problem structure correctly doesn't press, so long as the probability of figuring out the problem structure correctly is more than 50%.
[02:00:34] <Obormot\Arcturus> saturn2: So, I'll have to think about that for a bit more, but note that for that to be informative about the total # of cars (in the way you used the info), you need to assume there's as much prior odds of there being 10 as 10k
[02:00:47] <Obormot\Arcturus> saturn2: Which seems like a weird assumption, and not motivated by anything
[02:01:30] <Dyo> shawwwn: wait a few months, post same story with genders reversed. share results
[02:02:17] <Obormot\Arcturus> Gurkenglas: Hm, I see
[02:02:42] <saturn2> Obormot\Arcturus: sure, it's unlikely that you would have absolutely no prior information about the size of the town, but the point was just to explain the doomsday argument using a more tangible example
[02:02:57] <Obormot\Arcturus> saturn2: The same holds for the doomsday argument though
[02:03:28] <Obormot\Arcturus> Also the doomsday argument has weirder assumptions
[02:03:45] <Obormot\Arcturus> Like, "assume you're randomly selected from all the people who ever did or will exist" is totally incoherent
[02:04:37] <Obormot\Arcturus> The people who don't exist yet don't exist, so "I" can't be "randomly selected from" "them", and in any case there is no "I" until I actually exist, and there isn't anything randomly selecting people, etc.
[02:05:41] <saturn2> that's where subjective probability comes in
[02:05:49] <Obormot\Arcturus> Also notice that the doomsday argument comes to the same *relative* conclusion if applied by *literally anyone* anywhere in the entire history of an arbitrarily long-lived species, so the doomsday argument coming up "doomsday" can't possibly tell you anything about where in said history you are
[02:07:08] <Obormot\Arcturus> saturn2: Well... I don't think this application of subjective probability makes any sense, regardless of whether I think it makes sense in other contexts :\
[02:07:58] <saturn2> if all humans throughout time believe "no more than 20 times more humans as have been born so far will be born in the future", then 95% of them will be right and 5% will be wrong
[02:09:22] <Obormot_\Gaia> What I'm saying is that the doomsday argument is not capable of generating any answer other than "doomsday"
[02:09:31] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 252 seconds)
[02:09:59] <saturn2> the subjective part is that you're already either right or wrong, you're not randomly selected, but you treat it as a probability anyway since you subjectively don't know
[02:10:16] <Obormot_\Gaia> So if P("doomsday"|doomsday) = P("doomsday"|not-doomsday), then running through the argument and getting an answer of "doomsday" gives you zero information about whether doomsday or not-doomsday
[02:10:46] *** Obormot_\Gaia is now known as Obormot\Gaia
[02:11:19] <saturn2> what does not-doomsday mean here?
[02:11:19] <Obormot\Gaia> (This is because result of the argument just isn't causally entangled with the thing it's supposedly about)
[02:11:58] <Obormot\Gaia> saturn2: It's shorthand; what I'm saying is that whatever answer you get is the same answer you're always going to get, regardless of *literally anything whatsoever*
[02:12:33] <saturn2> no, the answer depends on how many humans have been born so far
[02:14:07] <Obormot\Arcturus> nnno?
[02:14:08] <ggreer> https://www.cnet.com/roadshow/news/2022-cadillac-escalade-super-cruise-hands-free-chip-shortage/ lol
[02:14:17] <ggreer> blame the chip shortage on every missed deadline
[02:14:20] <feepbot> 2022 Cadillac Escalade drops hands-free Super Cruise system amid chip shortage - Roadshow (Cadillac confirmed the Level 2 hands-free driver-assist system is not available, at least for now.)
[02:14:28] <ggreer> they already built the cars. how the hell is it a chip shortage issue?
[02:14:43] <saturn2> everyone gets a different point estimate, but their credible intervals can still be well-calibrated
[02:17:23] <Obormot\Arcturus> What does "well-calibrated" mean here, exactly?
[02:19:38] <saturn2> it means <saturn2> if all humans throughout time believe "no more than 20 times more humans as have been born so far will be born in the future", then 95% of them will be right and 5% will be wrong
[02:22:28] <saturn2> since i have no reason to believe i'm different from those other humans, i conclude that the statement is 95% probable
[02:23:05] <Obormot\Arcturus> I mean, I think you're clearly different from those other humans, because the ones who haven't been born yet don't exist, so you can't be any of them
[02:24:20] <saturn2> i can't be anyone except me, but i don't think that matters
[02:24:27] <Obormot\Arcturus> I think it matters
[02:24:40] <saturn2> ok, why?
[02:25:40] <Obormot\Arcturus> It's impossible to be one of the humans who haven't been born yet; at best you can be the *first* human who is right about the doomsday argument, but what are the chances of that? 1 out of however many people have been born so far, right?
[02:26:57] <saturn2> i agree that it's very unlikely that i am the first, but what does that matter?
[02:29:26] <Obormot\Arcturus> If it's unlikely that you're the first, then the overwhelmingly likely conclusion is that you're *not* the first, but the only remaining options are "wrong about the doomsday argument"
[02:31:04] <saturn2> i don't see how that follows
[02:31:17] <Obormot\Arcturus> (This doesn't count people born after you, of course)
[02:31:57] <saturn2> it's more likely that the first is already older than i am
[02:32:58] <Obormot\Arcturus> I don't see how *that* follows
[02:33:17] <Obormot\Arcturus> Really I just don't think it makes sense to think of being drawn from some distribution that includes people who don't exist yet
[02:33:33] <Obormot\Arcturus> There's no way of constructing that question that seems at all coherent to me
[02:35:07] <saturn2> does it make sense to believe that things will happen in the future?
[02:35:30] <Obormot\Arcturus> Something's certainly gonna happen, yeah
[02:35:49] <Obormot\Arcturus> Well, it might not
[02:36:03] <Obormot\Arcturus> Vacuum collapse could destroy the multiverse or something and then there'd be no more time
[02:36:08] <Obormot\Arcturus> But probably things will happen
[02:36:15] <saturn2> does it make sense to believe that people in the future will have beliefs?
[02:36:33] <Obormot\Arcturus> Yeah totally but I'm not one of those people and can't ever have been
[02:36:42] <Obormot\Arcturus> I could only ever have been the specific person I already am
[02:36:57] <saturn2> i agree!
[02:37:35] <Obormot\Arcturus> I don't see how you reach your conclusion then :\
[02:37:37] <saturn2> my reasoning doesn't rely on the idea that i randomly could have been someone else
[02:37:57] <Obormot\Arcturus> Well you said
[02:38:05] <Obormot\Arcturus> "if all humans throughout time believe "no more than 20 times more humans as have been born so far will be born in the future", then 95% of them will be right and 5% will be wrong"
[02:38:49] <Obormot\Arcturus> But if we want to draw any conclusions from this then we have to believe that we're a priori equally likely to be any of these "all humans throughout time"
[02:38:53] <Obormot\Arcturus> But we're not!
[02:39:05] <Obormot\Arcturus> We could only possibly be one of the humans who have been born already
[02:39:37] <Obormot\Arcturus> But we don't know how many of those "all humans throughout time" have been born already (that being the original question)
[02:40:08] <saturn2> i don't have to *be* a different person, i only have to see no reason that they would be more or less likely to be right than i am
[02:43:37] <two2thehead> kuudes, s0ph1a feep : til that the reptile base brain theory has less evidence than i thought https://en.wikipedia.org/wiki/Triune_brain
[02:43:48] <feepbot> The triune brain is a model of the evolution of the vertebrate forebrain and behavior, proposed by the American physician and neuroscientist Paul D. MacLean. MacLean originally formulated his model in the 1960s and propounded it at length in his 1990 book The Triune Brain in Evolution.
[02:43:57] <Obormot\Arcturus> saturn2: I don't think that helps if what you're trying to figure out is how many such people there are and which you are among them etc.
[02:44:51] <Obormot\Arcturus> "I know of one college here in Brazil that, like all or nearly all colleges, shut down in-person lectures for Covid. Students were organizing and consistently demanding refunds, also consistently explicitly asking for a reopening.
[02:44:51] <Obormot\Arcturus> Then towards the end of 2020, the college tried to reopen as soon as the government authorized colleges to reopen.
[02:44:52] <Obormot\Arcturus> Almost no students showed up for class." ... lol
[02:46:24] <saturn2> if i know that 95% of all humans have an arbitrary property "flob", and i don't know anything else about who is flob, i conclude that there is a 95% chance that i am flob
[02:47:20] <saturn2> this continues to hold when flob is being right about doomsday
[02:47:21] <Obormot\Arcturus> saturn2: That breaks down when (a) some (unknown) proportion of those humans don't exist (yet?), (b) "flob" is something that depends on whether or not you exist yet
[02:49:28] <Obormot\Arcturus> Again, in the universe where humans live for 1,000 more years (assuming growth rates as assumed and so on, in all cases), and in the universe where humans live for 1,000,000 more years, you reach exactly the same conclusion by running the doomsday argument, so the doomsday argument can't tell you anything about which of those universes you live in
[02:50:01] <saturn2> i don't agree
[02:50:07] <Obormot\Arcturus> With which part
[02:51:19] <saturn2> even though it's possible for evidence to be misleading, it usually isn't misleading, so it still tells me something
[02:51:24] <PlanckWalk> There are hypothetical other observers in those hypothetical other universes which have a different distribution, but people with your observations don't.
[02:53:38] <saturn2> we aren't talking about other universes, just uncertainty about the future of this one
[02:53:46] <Obormot\Arcturus> Right
[02:53:58] <PlanckWalk> Yes, that's why the hypothetical other universes are extrapolations from now.
[02:54:12] <PlanckWalk> With various numbers of total observers.
[02:54:36] <PlanckWalk> (We already ruled out the ones where there are no observers from now on)
[02:54:47] <PlanckWalk> Err, by now and onward
[02:56:09] <saturn2> oh, i see what you mean
[02:56:13] <PlanckWalk> E.g. in some hypothetical universe World War III occurred in 1963 and nuclear winter caused extniction.
[02:56:34] <PlanckWalk> We ruled that, and those like them, out.
[02:57:08] <saturn2> yes, this is another way of formulating subjective probability
[02:58:04] <PlanckWalk> So what evidence are you using to rule out the universe where humanity lives another million years?
[02:59:12] <saturn2> the monty hall dispute was settled by running simulations, but i think we agree about what would happen in a simulation, so i guess that doesn't get us anywhere
[03:00:05] <PlanckWalk> The argument seems to be "most observers in the million year universe would see history going back a large fraction of a million years"
[03:00:40] <PlanckWalk> But most observers have observations that don't match ours in *every* universe, so they're irrelevant.
[03:00:53] *** Quits: two2thehead (~user@27.114.133.108) (Quit: Leaving)
[03:01:27] <PlanckWalk> We see about 5000-year histories, so the relevant observations are "of those who have about 5000-year histories, ..."
[03:04:39] <Obormot\Arcturus> saturn2: Monty Hall is what I was thinking of when trying to think about this, in fact... in that one, the solution is to notice the distribution of starting positions and go from there, but in doomsday that doesn't apply because there's only one possible starting position and that's "you are who you are"
[03:09:40] <feepbot> <gwern> https://www.nytimes.com/2021/10/01/science/zombie-plants-parasites.html
[03:09:40] <feepbot> This Parasite Turns Plants Into Zombies - The New York Times (It’s a never-ending cycle of "Night of the Living Dead-meets-Dracula” in the world of green and leafy things.)
[03:10:54] <Obormot\Arcturus> Wait a minute
[03:11:29] <Obormot\Arcturus> Was this parasite created by some mad scientist who was trying to cheat at https://www.plants-vszombies.com/
[03:11:41] <feepbot> Plants Vs Zombies Games - Play Zombies Games Online Free : Plants-vszombies.com (Play Plant Vs Zombies Games online free at plants-vszombies.com. Enjoy playing other funny Zombies Games with many levels right now. Try Cool Plant Vs Zombies Games without downloading.)
[03:12:19] <saturn2> "SIA treats you as a specific possible person-in-your-epistemic-situation, who might or might not have existed, even conditional on there being someone in that situation. And it thinks of worlds as “pulling” some number people-in-your-epistemic-situation from the “hat” of the platonic realm." this, on the other hand, sounds absurd to me. i guess that must be how i sound to obormot
[03:13:21] <Obormot\Arcturus> yes :\
[03:14:26] *** Quits: Thurl (~Nivim@184.99.50.23) (Quit: Probably due to necessity, but of the planned kind.)
[03:18:22] <feepbot> <gwern> uploads https://www.gwern.net/docs/sociology/2021-engzell.pdf
[03:23:15] <PlanckWalk> SIA is the most probabilistic one.
[03:24:30] <PlanckWalk> Given any probability distribution of possible worlds (e.g. generated by a distribution of models), it just does the Bayesian thing of throwing out observers who don't match your observations.
[03:25:27] <PlanckWalk> Whether Bayesian updates are appropriate for such situations is a different question.
[03:26:14] <Obormot\Arcturus> saturn2: One of the problems I have with this sort of reasoning is that it's impossible to say anything about how correct it was even in retrospect. Like, let's say that tomorrow an asteroid destroys Earth, and as it's about to hit we go "well, was the doomsday argument correct or not?"; and the answer is going to be "out of all humans throughout history who believed it, 95% were correct". But if instead the asteroid hits us
[03:26:14] <Obormot\Arcturus>  in 100 years, or in 10,000 years, the answer is going to be exactly the same! And precisely where in that distribution any given human happened to turn out to have been, depends on absolutely nothing they did or could have observed at the time...
[03:26:29] <Obormot\Arcturus> (This is similar to my problem with subjective probability, of course)
[03:27:47] <Obormot\Arcturus> PlanckWalk: It seems to me that the output of such reasoning is completely dependent on how you generate your models, which doesn't strike me as any kind of a good way to think about things
[03:27:57] <PlanckWalk> They're the prior.
[03:28:04] <PlanckWalk> All Bayesian updates need a prior
[03:28:14] <Obormot\Arcturus> That's hardly the point
[03:28:21] <PlanckWalk> Also as I sadi: "Whether Bayesian updates are appropriate for such situations is a different question."
[03:28:32] <PlanckWalk> I'm not convinced they are.
[03:28:34] <Obormot\Arcturus> I don't think that's really the question
[03:28:42] <Obormot\Arcturus> Distributions of possible worlds are a pretty arbitrary prior
[03:29:17] <PlanckWalk> But ... that's what a prior is?
[03:30:02] <PlanckWalk> Unfortunately, afk for quite a while.  Interesting discussion!
[03:31:35] <Obormot\Arcturus> No, I don't think that's right
[03:31:53] <Obormot\Arcturus> Most priors don't actually come from literally nowhere, despite that we have to pretend they do for convenience
[03:32:44] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[03:46:34] <kuudes> hmm. in free market situation, in case rate of return for investment is about 6%, would it work out re buying home to take the apparent rent in year you would deem reasonable to pay for similar lodging and then multiply that by 1/0.06?
[03:46:36] <saturn2> Obormot\Arcturus: i agree that that's unsatisfactory, but i think "we can't say anything at all" is even less satisfactory, and i'm not aware of anything better
[03:47:11] <kuudes> ie housing price should be then about monthly rent*200 or less to buy, if more then rent?
[03:47:34] <kuudes> (0.06 /12 = 0.005 = 1/200)
[03:47:40] <saturn2> kuudes: in theory it should, yes
[03:47:52] <kuudes> nice, thanks
[03:48:08] <Betawolf_> rent also covers repairs/maintenance and landlord profits though
[03:48:29] <saturn2> there may also be a risk premium
[03:48:42] <kuudes> profits and repairs should not affect the calc but risk should
[03:49:01] <kuudes> given lack of repairs should lower rent and profit comes to you yourself
[03:49:32] <kuudes> risk premium and interest rates should likely have some sort of relation
[03:50:05] <saturn2> in a theoretical perfect market there is no way for anyone to make more profit than anyone else
[03:50:16] <kuudes> otoh similarly if you would be willing to pay more than 1/200 of house price as rent you should buy it and if not, not
[03:50:17] <kuudes> indeed
[03:50:21] <kuudes> spherical cows etc
[03:51:17] <kuudes> also living in your own house is not taxed on the profit part but renting to someone else is and other tax inequalities
[03:52:41] <kuudes> still, that is handy as a shorthand to gain prior on worth of something
[03:52:50] <catern> ignorant chemistry question: two liquids that humans drink, usually as part of a solution containing lots of other stuff like sugars, are water and ethanol. are there any other such liquids?
[03:53:25] <kuudes> ethanol is rarely drunk raw, it is usually mixed with water
[03:53:46] <kuudes> otherwise, syrup/sugar?
[03:54:13] <Obormot\Arcturus> saturn2: Hmm, I find "we can't say anything at all" more satisfactory, actually, though I agree that there's not anything better
[03:54:21] <catern> syrup is just a solution of sugars in water (afaik)
[03:54:33] <kuudes> well so is digestable ethanol
[03:55:08] <kuudes> I am unsure if there is anything not containing water which is both liquid and digestable by humans
[03:55:45] <catern> ethanol is a liquid in its pure form, sugars are not
[03:56:14] <catern> (at room temperature)
[03:56:25] <catern> I guess that's what I mean to ask: is there anything besides water and ethanol that humans drink, that is liquid in its pure form?
[03:56:39] <Fusxfaranto> aside from oils pretty much every liquid food is water-based
[03:57:39] <catern> oh yeah, I guess oil is a liquid
[03:58:16] <kuudes> doesn't ethanol separate water out of itself in room temp and therefore there is no 100% ethanol liquids at room temp?
[03:58:31] <kuudes> oils usually also contain h20
[03:58:33] <kuudes> h2o
[03:59:00] <catern> i have no idea, do they? in a pure form?
[03:59:14] <Obormot\Gaia> Uh, they do?
[03:59:18] <Obormot\Gaia> I don't think that's right...
[03:59:29] <Fusxfaranto> not beyond trace amounts as far as i'm aware
[03:59:34] <kuudes> hmm, ok
[03:59:40] <kuudes> I was mistaken then
[04:00:09] <catern> so I guess the many different types of oil are another liquid that humans consume
[04:00:23] <Fusxfaranto> i guess there's also acetic acid, technically a liquid in pure form but culinarily generally heavily diluted in water
[04:00:35] <catern> Fusxfaranto: ooh interesting
[04:00:48] <catern> good point
[04:00:51] <kuudes> https://www.physicsforums.com/threads/100-ethanol.226344/ "Pure ethanol has a great affinity for water and will absorb it from the air until it is only about 96% pure."
[04:01:03] <feepbot> 100% ethanol ? | Physics Forums (100% ethanol ??)
[04:01:07] <kuudes> so you will need to keep it separated from air
[04:02:12] <catern> so my real ultimate question is: if you separated out the human body into its component molecules, would there be anything other than water that would be liquid?
[04:02:18] <catern> and, I guess oil, obviously
[04:02:37] <catern> there are random oils inside humans, right?
[04:02:59] <Fusxfaranto> yeah, i would guess most human fats are solid at room temperature though
[04:03:12] <catern> hm
[04:03:47] <Fusxfaranto> i bet there's a bunch of random organic compounds in the body that would be liquids if you managed to isolate them
[04:03:58] <kuudes> are there acids that are soluble without water at room temperature?
[04:05:07] <Fusxfaranto> if you mean s/soluble/liquid, then yeah, i don't think it's uncommon
[04:05:15] <dTal> if you separated the human body into its component molecules, you'd have a disgusting organic vapor
[04:05:32] <Fusxfaranto> acetic acid is one, nitric acid is another
[04:05:39] <catern> dTal: well and put them into little boxes or whatever so they don't aerosolize
[04:06:28] <dTal> what, like an SQL query
[04:06:56] <dTal> select all molecules of type x and shove em into a container
[04:07:16] <saturn2> i think pure acetic acid is a liquid at room temp
[04:07:29] <saturn2> oops someone already said that
[04:08:10] <dTal> I'm not sure it's a terribly well defined question
[04:08:18] <dTal> you have to decide which bonds are okay to break
[04:08:22] <catern> (I learned acetic acid is a liquid at room temperature from https://cataclysmdda.org/ heh)
[04:08:26] <feepbot> Cataclysm: Dark Days Ahead (Official homepage of Cataclysm: Dark Days Ahead open source turn-based survival RPG development project. Hosts downloads of game and links to community sites...)
[04:09:08] <dTal> Does hydrochloric acid count?
[04:09:35] <catern> is it found in a healthy human body?
[04:09:43] <dTal> In abundance, in the stomach.
[04:10:01] <catern> hmm
[04:10:07] <catern> >Hydrochloric acid, also known as muriatic acid, is an aqueous solution of hydrogen chloride 
[04:10:10] <catern> no it doesn't count
[04:10:17] <dTal> Well hold your horses.
[04:10:31] <dTal> It's not just hydrogen chloride "mixed with" water
[04:10:33] <catern> because >The compound hydrogen chloride [...] At room temperature, it is a colourless gas,
[04:10:40] <dTal> https://en.wikipedia.org/wiki/Hydrogen_chloride
[04:10:49] <dTal> Upon contact, H2O and HCl combine to form hydronium cations H3O+ and chloride anions Cl− through a reversible chemical reaction:    HCl + H2O → H3O+ + Cl−
[04:10:52] <feepbot> The compound hydrogen chloride has the chemical formula HCl and as such is a hydrogen halide. At room temperature, it is a colourless gas, which forms white fumes of hydrochloric acid upon contact with atmospheric water vapor.
[04:11:54] <catern> I see, why the heck is it called an "aqueous solution" then, if that's just how you manufacture it and not what it really is? seems like confusing terminology
[04:12:26] <catern> (i'm sure this betrays extreme ignorance of chemistry)
[04:13:38] <catern> but yeah, then I guess it does count? well... I guess... hmm I guess as you say it's not really a well-defined question
[04:14:14] <catern> because you couldn't really meaningfully take all the hydronium cations and all the chloride anions and put them in separate boxes, I'm guessing?
[04:15:20] <kuudes> electrolysis?
[04:15:41] <kuudes> hmm. re that old battery question: are batteries anti-electrolysis?
[04:16:04] <dTal> No, that's fuel cells.
[04:16:28] <kuudes> hmm
[04:18:01] <kuudes> I mean, if you start from having cations near one metal rod and and anions on the other metal rod, does a opposing electric current happen than one you need to apply to separate the solution into those components?
[04:18:50] <shawwwn> https://twitter.com/shoosack_/status/1443899316628705286?s=21
[04:18:53] <|dbotdan> shoo (@shoosack_, 2021-10-01 11:23): ‘Doing casual monstober prompts to give myself some drawing motivations… | Day 1 - Candy’ Images: https://birdsite.xanny.family/pic/media%2FFAnCxcrVcAMzkeJ.jpg%3Fname%3Dorig (description: a toy dinosaur with a sword; confidence: 0.32)
[04:19:08] <shawwwn> Lol at sword
[04:19:16] <catern> anyway, "i would guess most human fats are solid at room temperature though/i bet there's a bunch of random organic compounds in the body that would be liquids if you managed to isolate them" answers my question to my satisfaction
[04:19:19] <catern> thanks Fusxfaranto 
[04:20:02] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[04:20:42] *** Joins: srhm (~srhm@user/srhm)
[04:21:24] <shawwwn> hi srhm
[04:23:38] <catern> thanks also to dTal for your example of hydrochloric acid which made it clear to me how this is a more complicated question than I expected
[04:24:01] <dTal> :D always a pleasure to be a pedant on IRC
[04:24:40] <catern> (now I'm wondering if there are reactions like that in liquid foods, or if they actually are all just "a bunch of random stuff mixed into water and other liquids")
[04:25:30] <dTal> Heh. How would you class gelatine?
[04:26:16] <catern> i have no idea lol
[04:26:26] <dTal> More generally, https://en.wikipedia.org/wiki/Hydrolysis
[04:26:37] <catern> hm I see
[04:26:37] <feepbot> Hydrolysis (; from Ancient Greek  hydro-  'water', and  lysis  'to unbind') is any chemical reaction in which a molecule of water breaks one or more chemical bonds. The term is used broadly for substitution, elimination, and solvation reactions in which water is the nucleophile.
[04:27:24] <dTal> Water isn't just a passive medium, it does all kinds of *stuff*
[04:27:27] <catern> I guess that definitely counts as a chemical reaction like that, since afterwards there is no more water
[04:32:27] <feepbot> <gwern> https://twitter.com/ArtirKel/status/1444083257784500225 ~soon~
[04:32:31] <|dbotdan> José Luis Ricón Fernández de la Puente (@ArtirKel, 2021-10-01 23:34): ‘Today in a call: | A: A mouse joined! | B: We are doing an experiment with them, we have to give them a say | Mouse: I am not a mouse!’ Images: https://bird.trom.tf/pic/media%2FFApp9hlUcAUQThN.png%3Fname%3Dorig (description: a small rodent in a white circular object; confidence: 0.38)
[04:37:09] *** Joins: alampridius (~kvirc@user/alampridius)
[04:37:31] <feepbot> <gwern> 'I found it *in my underwear*. Even by bumblebee standards this was a confused one, and it didn't help that I moved it over to a text on cost overrun statistics.' https://www.flickr.com/photos/arenamontanus/8714130582/ "but *why* does cost disease keep happening despite improvements in all relevant technologies???!" the bee keeps buzzing to itself. "It makes no sense!"
[04:37:32] <feepbot> Confused bumblebee | I found it *in my underwear*. Even by bumblebee standards this was a confused one, and it didn't help that I moved it over to a text on cost overrun statistics.
[04:42:32] <feepbot> <gwern> https://www.reddit.com/r/IndieGaming/comments/pzbaio/funkiest_feature_of_my_game_use_ai_to_customize/  https://www.reddit.com/r/MediaSynthesis/comments/pzcqln/this_waifu_does_not_exist_but_in_a_game_in_real/
[04:42:33] <feepbot> Funkiest feature of my game: use AI to customize 2D avatars in game! Check the demo on steam, link in comments~! : IndieGaming (10 votes and 2 comments so far on Reddit)
[04:44:23] <alampridius> Has there been scifi about a near future where neural network stuff advances far enough that literally any random person with a computer can generate as much "video evidence" and similar, containing whatever they want for whatever they want, in no time at all (including videos that exactly resemble eg a BBC new show discussing something), and chaos follows?
[04:45:51] <alampridius> s/new show/news show
[04:50:54] <rmmh> oddly s1mone is the closest 
[04:52:06] <alampridius> is it good?
[05:01:39] <median> https://www.sciencedirect.com/science/article/abs/pii/S0278262621001226
[05:01:50] <feepbot> Memory enhancement with stimulants: Differential neural effects of methylphenidate, modafinil, and caffeine. A pilot study - ScienceDirect
[05:06:39] <feepbot> <gwern> weird. no less than 3 versions: https://www.osti.gov/servlets/purl/1115483 https://www.osti.gov/servlets/purl/1682587 http://pop.h-cdn.co/assets/cm/15/06/54d15530c77d3_-_141790.pdf
[05:11:40] <feepbot> <gwern> https://twitter.com/OdedRechavi/status/1443922392435335180 "while you wasted time debating cnn and bayes, I studied the way of the christmas blade"
[05:11:42] <|dbotdan> Oded Rechavi 🦉 (@OdedRechavi, 2021-10-01 12:54): ‘PI: “great work, I worked on your draft and only made a few minor changes” ’ Watch video: https://nitter.skrep.in/OdedRechavi/status/1443922392435335180
[05:21:58] <shawwwn> “A change in change is worth d(80 IQ)/dperspective = 0 IQ points”
[05:22:13] <shawwwn> Such a lovely channel topic
[05:22:57] <shawwwn> The acceleration of perspective
[05:29:50] <shawwwn> Hmm, yannic is getting feisty https://twitter.com/ykilcher/status/1444025697211715601?s=21
[05:29:51] <|dbotdan> Yannic Kilcher, Tech Sister (@ykilcher, 2021-10-01 19:45): ‘If you force everyone to do something, can you really call it a "movement"?’
[05:36:36] <gwern> sure. just like a bowel movement forces everything out
[05:36:54] <gwern> (damn, someone beat me to it)
[05:41:05] *** Joins: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net)
[06:04:16] <rmmh> https://twitter.com/buttplugio/status/1444011935687593987
[06:04:18] <|dbotdan> buttplug.io 🍑🔌 - Open Source Sex Tech (@buttplugio, 2021-10-01 18:50): ‘how am i still allowed on r/rust’ Images: https://nitter.namazso.eu/pic/media%2FFAopM1WVIAIpgzH.jpg%3Fname%3Dorig (description: graphical user interface, application; confidence: 0.98)
[06:12:20] <shawwwn> moar than diamon moar than gol
[06:20:33] <shawwwn> https://www.youtube.com/watch?v=g2_xe3EmWIg&ab_channel=GothamChess
[06:20:43] <feepbot> QUEEN SACRIFICE by Magnus Carlsen - YouTube
[06:22:52] <gwern> typical fridging and misogyny. have you ever seen two queens talk about something other than a king, a *man*? chess badly fails the bechdel test
[06:24:36] <shawwwn> gwern just wishes he was competing in the chess legends tournament 
[06:27:25] <nshepperd> god, imagine gwern wasting his time on chess
[06:27:32] <nshepperd> i shudder at the very thought
[06:29:30] <rmmh> it's like competitive wow
[06:29:39] <rmmh> you're competing in a grind against a bunch of other nerds
[06:29:47] <gwern> the world, the flesh, and the devil board
[06:32:32] <nshepperd> https://irc.zlkj.in/uploads/f634edef66ae3a81/20211001211159_3_death_minus_yellow.png "a landscape resembling the death tarot card, by Greg Rutkowski"
[06:32:52] <nshepperd> subtracting "yellow" from the prompt made it generate pink instead
[06:33:14] <gwern> (I probably would've been a decent chess player. it seems to stress visuospatial patterns and long-term memory, both of which I do well. but odds strongly against me being a great one... and even if I was, so what)
[06:35:28] <rmmh> "The ability to play chess is the sign of a gentleman. The ability to play chess well is the sign of a wasted life."
[06:41:40] <saturn2> chess? i don't believe it exists.
[06:46:32] <gwern> rmmh: a good quote, but when I went looking for it a few weeks ago, seemed to be apocryphal
[06:47:15] <rmmh> "an unsourced quote can't be apocryphal"
[06:48:50] <gwern> one of oscar wilde's, yes, but you know how he made shit up
[06:51:10] <Obormot\Arcturus> "If there is a hair trimmer on the market, I have used it and subsequently destroyed it. I am a slayer of hair trimming products. Hair-removing creams slide away from me. And the one time I decided to try laser hair removal, the diode willingly chose to reflect its beam off a mirror and shoot itself in the lens."
[06:51:17] <Obormot\Arcturus> (from an Amazon review)
[07:04:33] <saturn2> can we make a space elevator out of that person's hair?
[07:05:23] <Obormot\Arcturus> "Lodge cast iron pans are the best. My only regret is that I bought it for a man who didn't deserve it. The good thing? It'll last forever, so unless he throws it out or gives it away he'll have a life-long reminder of what he lost!"
[07:05:29] <gwern> saturn2: not if it is a probability-manipulator. you'd make the hairevator only for a micrometeorite to hit it in the one exact spot to cause it to chatoically fray
[07:06:01] <gwern> Obormot\Arcturus: new country music trope just dropped - 'the pot Lodged in my 'eart'
[07:06:04] <Obormot\Arcturus> "I accidentally ordered the 3.5 inch [cast-iron pan]. It's amazing, solid, heavy and well made, but can probably only fry a piece of garlic in it at a time(My fault for not checking). I may keep it next to my bed and use it as a weapon if necessary, or hang it on the wall as an ornament. "
[07:06:24] * gwern wonders what they thought the '3.5 inch' referred to. the thickness?
[07:10:50] <saturn2> what are you supposed to use it for?
[07:11:22] <rmmh> stupid instagram posts https://www.vindulge.com/17-genius-uses-for-a-teeny-tiny-miniature-cast-iron-skillet/
[07:11:33] <feepbot> 17 Genius Uses for a Teeny Tiny Miniature Cast Iron Skillet - Vindulge (Ever wonder what you could do with a miniature 3.5-inch cast iron skillet? Here are 17 Genius uses for that teeny tiny miniature cast iron pan!)
[07:11:56] <rmmh> the only semi-reasonable thing in here is the cheese fondue
[07:12:39] <gwern> most of these just make me wonder why you are eating exactly 1 egg
[07:12:59] <rmmh> the instagram gods demand egg
[07:15:17] <saturn2> "Nothing says, “I’m a Badass,” like wearing a miniature cast iron skillet around your neck while sporting your faux leather jacket around your shoulder." ?????
[07:15:47] <gwern> you have to admit, people *will* look
[07:16:42] <rmmh> "statement piece" leaves the precise statement freeform
[07:17:23] <gwern> 'this is a statement piece' tactfully leaves unstated the statement
[07:19:53] <PapuaHardyNet> obormot: you really like cast iron skillets, huh
[07:20:05] <Obormot\Arcturus> PapuaHardyNet: I don't have any cast iron skillets
[07:20:23] <Obormot\Arcturus> That is, in fact, why I am looking at cast iron skillets on Amazon - to rectify that lack
[07:20:23] <PapuaHardyNet> I see, that's why you desire it so
[07:20:59] * Obormot\Arcturus ordered the 8" Lodge one
[07:21:15] <Obormot\Arcturus> One of these days I'll get one of those cool Stargazer skillets but not yet
[07:37:55] *** Joins: voltage_ (voltage@user/voltage)
[08:01:45] <gwern> I got nerdsniped :( trying to sleep and suddenly realized how to do the GPT-3 text justifier. it turns out to be downright insultingly trivial: compute the DP solutions using solely the thesaurus synonyms, and find the _n_ minimum-cost rewrites; then use the GPT-3 API to *rank them by similarity to the original* using the Semantic Search endpoint; then you just have a knob controlling how...
[08:01:51] <gwern> ...much semantic/stylistic distortion you are willing to tradeoff for more perfect linebreaking. this is trivial to implement, only requires _n_ texts in a single batched call so is very API efficient & cheap, and avoids the immense cost and potentially millions of calls if you try to thread logprobs through the DP itself
[08:03:28] <gwern> (the main issue with this is that the _n_ best candidates may all be pretty similar and the API ranking step doesn't remove much unnaturalness, but one would have to try it to see)
[08:04:17] <nshepperd2> ooh
[08:05:28] <gwern> it doesn't guarantee the best GPT-weighted rewrite, but that's not really feasible for anything but really short texts
[08:07:21] <rmmh> oh did you discuss this earlier
[08:07:26] <nshepperd2> by minimum-cost rewrites you mean like, the best justified paragraph with at most k word substitutions or something?
[08:07:45] <nshepperd2> and you'd compute that for various values of k, then run the results through gpt?
[08:07:58] <PapuaHardyNet> whenever I do a `git push --force` I feel powerful.
[08:09:32] <gwern> nshepperd2: yeah, I think you'd want to add in constraints for diversity. what I was thinking was that you would simply provide synonyms for every single word in the document, because DP is so cheap and fast, and let the API worry about semantic similiarity
[08:10:23] <rmmh> I don't think you'd need that many rewrites to get perfect justification
[08:10:41] <saturn2> why would there be millions of calls?
[08:10:45] <rmmh> 1/8th of snippets or so should be correctly justified
[08:11:03] <gwern> rmmh: you definitely shouldn't, but it's a balance between flexibility and semantics/style preservation
[08:11:27] <gwern> saturn2: the naturalness of a phrase depends on the global text, not just the lines before it
[08:11:46] <gwern> rewriting a word in the first sentence could be bad because of the content of the last sentence
[08:12:27] <saturn2> hm...
[08:13:51] <gwern> the beauty of dispatching n candidate texts along with the original to the Search endpoint is that it will evaluate them all as wholes, each candidate having all its edits simultaneously
[08:14:45] <gwern> last I knew, it was basically a compression measurement: it takes the logprobs of the candidate concatenated with all the possibilities. the better the logprobs, the more similar
[08:15:20] <gwern> if you have a rewrite which sounds like a different style, or which semantically means different things, gpt-3 will have worse logprobs when conctenated with the original, because it will be confused
[08:15:55] <gwern> (while a rewrite which is very natural and changes only a few words here and there, will compress extremely well with the original)
[08:16:45] <gwern> so this reduces to the much easier problem of simply coming up with decent candidate rewrites to score
[08:23:28] <nshepperd2> i guess you'd want to restrict the substitutions to words that have unambiguous sense in isolation
[08:23:49] <nshepperd2> bc a lot of words have like three different sets of synonyms for different usages
[08:24:09] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[08:24:13] <nshepperd2> so chances are with k=10 substitions at least one would be wrong
[08:24:33] <nshepperd2> unless you also used gpt's next word prediction to propose synonyms as well
[08:28:38] <nshepperd2> or to prefilter the synonyms from the thesaurus or something
[08:32:32] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[08:43:30] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Remote host closed the connection)
[08:44:59] <PapuaHardyNet> to understand how to use this system I have remote ssh'ed into, I'm reading ~/.bash_history
[08:49:10] <Obormot\Arcturus> https://www.greaterwrong.com/posts/Xi7Kztj5gBJt4qAgG/how-does-the-circle-grow-exactly ... kind of an amazing post
[08:49:14] *** Quits: martin02 (~silas@141.84.69.76) (Ping timeout: 246 seconds)
[08:49:22] <feepbot> How does The Circle grow, exactly? - LessWrong 2.0 viewer (There's an EA song, adapted for Solstice, which presents an optimistic view of the expanding circle of concern: CALLER: Raise a song, and so commenceALL: Circle, grow and grow.in praise of all Benevolence!Circle, grow and grow.Once a cold a [snip])
[08:49:51] *** Joins: martin02 (~silas@141.84.69.76)
[08:50:35] <adiabatty> this Stargazer pan looks great but I barely do anything on a pan anymore
[08:50:53] <Obormot\Arcturus> adiabatty: Really? I do so many things on a pan...
[08:51:01] <Obormot\Arcturus> What do you use instead?
[08:51:19] <adiabatty> baking kabobs, two half sheets at a time
[08:51:39] <PapuaHardyNet> you know, X11Forwarding is pretty amazing
[08:52:03] <PapuaHardyNet> It is basically doing what teamviewer and anydesk is doing, except without all the garbage proprietary software and protocol
[08:52:37] <PapuaHardyNet> I wonder if I can play video games using wine and X11Forwarding, basically a homebrew Stadia
[08:52:37] <Obormot\Arcturus> PapuaHardyNet: Have you heard of VNC at all
[08:52:48] <adiabatty> I've used it once and it was fucking trippy
[08:53:00] <adiabatty> I was running an application on another computer…on the computer I was using
[08:53:14] <PapuaHardyNet> I've heard of VNCs as things that channers use to hack onto chinese computers
[08:53:21] <Obormot\Arcturus> uhh
[08:53:38] <Obormot\Arcturus> I think you're thinking of VPNs
[08:53:42] <nshepperd2> i have heard that x11 forwarding is quite bad for gaming
[08:53:57] <adiabatty> the last three things I did on a pan were pancakes, pancakes, and pancakes, all on a Teflon-coated nonstick
[08:54:15] <PapuaHardyNet> well, if you think x11 forwarding is bad for gaming then it probably is
[08:54:40] <nshepperd2> like it's optimized for GUIs and stuff that don't send a lot of traffic
[08:55:05] <adiabatty> just play low-energy games like chess
[08:55:15] <nshepperd2> video games usually involve rendering 3d shit then shipping a big ol rasterized framebuffer
[08:55:50] <saturn2> AIGLX is somewhat usable on a gigabit lan
[08:56:07] <saturn2> depending on the game, probably
[08:56:15] <Obormot\Arcturus> PapuaHardyNet: https://en.wikipedia.org/wiki/Virtual_Network_Computing is what I am talking about. It's cross-platform, open source (the original, anyway), and it works better than most proprietary things...
[08:56:26] <feepbot> In computing, Virtual Network Computing (VNC) is a graphical desktop-sharing system that uses the Remote Frame Buffer protocol (RFB) to remotely control another computer.
[08:57:03] <Obormot\Arcturus> PapuaHardyNet: For example, I am not actually sitting at Arcturus's keyboard right now. I'm typing this on Gaia, VNC'd into Arcturus
[08:57:04] <adiabatty> I used the Windows thing and it blew VNC away
[08:57:12] <PapuaHardyNet> cool!
[08:57:20] <Obormot\Arcturus> adiabatty: But do you use RealVNC
[08:57:39] <adiabatty> I think I use Tight. Not very often, either.
[08:57:59] <adiabatty> Screens on the Mac side.
[08:58:22] <Obormot\Arcturus> PapuaHardyNet: In fact, sometimes I go places with Gaia (it's an MBP), and I connect to my home network via a VPN that I run, and *then* VNC into one of my desktops over that VPN connection
[08:58:27] <Obormot\Arcturus> Which also works great
[08:58:42] <saturn2> xpra is probably better than vnc for linux machines
[08:59:06] <Obormot\Arcturus> adiabatty: Screens uses the built-in Apple server stuff?
[08:59:30] <adiabatty> I use Screens as a client for what is invariably a Windows-based server
[08:59:37] <Obormot\Arcturus> Oh I see
[08:59:44] <Obormot\Arcturus> I use RealVNC on both ends
[09:00:07] <saturn2> and there's another thing for wayland but i forget what it's called
[09:00:24] <adiabatty> Would ggreer know? He talks about Wayland, doesn't he?
[09:01:06] <saturn2> maybe
[09:03:33] <saturn2> they're adding it to pipewire apparently... wtf
[09:04:06] <saturn2> i always regret even googling basic info about wayland
[09:04:51] <adiabatty> why? I'm too removed to care
[09:05:01] <adiabatty> (see also: my opinions on systemd)
[09:05:57] <nshepperd2> better not to know what you're going to be forced to endure once the people trying to destroy X11 get their way
[09:07:04] <saturn2> pipewire is the new audio daemon, so it's going to be running all the time. and it will also have screen sharing built in because god knows why
[09:07:17] <adiabatty> …wat
[09:07:50] <adiabatty> I understand the integration of, say, zfs
[09:08:01] <adiabatty> even though its integratedness offends pro-layer people
[09:09:00] <Obormot\Arcturus> What the hell
[09:09:12] <nshepperd2> its pulseaudio but for video as well
[09:10:02] <PapuaHardyNet> what's wrong with wayland
[09:10:22] <PapuaHardyNet> afaik it is a "suckless" replacement of X11
[09:10:33] <nshepperd2> yes, that's what's wrong with it
[09:10:37] <PapuaHardyNet> although the pipewire thing sounds quite retarded
[09:11:30] <PapuaHardyNet> naw, suckless is usually pretty good - look at alpine and openbsd. They aren't practically useable, sure, but they are very user friendly, when you are a user with a limited scope of features and requirements
[09:11:54] <nshepperd2> they tried to make a replacement of X11 with all the features taken out, then have slowly one-by-one realized people actually need features and added them back usually in insane and inferior ways
[09:12:26] <PapuaHardyNet> well, that does sound stupid
[09:15:43] *** Quits: alampridius (~kvirc@user/alampridius) (Quit: KVIrc 5.0.1 Aria http://www.kvirc.net/)
[09:22:21] *** Joins: badsektor (~badsektor@user/badsektor)
[09:37:12] *** Quits: adiabatty (~adiabatic@user/adiabatic) (Remote host closed the connection)
[09:37:42] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[09:37:52] *** Quits: Fusxfaranto (~Fusxfaran@cpe-75-85-179-208.san.res.rr.com) (Ping timeout: 252 seconds)
[09:42:14] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 260 seconds)
[09:42:38] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[09:43:12] *** Quits: badsektor (~badsektor@user/badsektor) (Remote host closed the connection)
[09:46:36] <saturn2> "Looking back, I think it’s basically inevitable for empires to expand at swordpoint. But could they have been more honest about it?"
[09:47:07] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[09:48:08] <saturn2> i have to give him credit for at least attempting to resolve some of the contradictions in his worldview
[09:53:30] <PapuaHardyNet> I'm smelling some plastic burning. smelled the hot air coming from my laptop vents, it *may* have been the cause, but I'm not sure
[09:54:50] <saturn2> oh no
[09:58:36] <Obormot\Arcturus> saturn2: Yeah, that's the way I felt about this post too
[09:59:08] <Obormot\Arcturus> I wonder if/when he will realize that the rationalizations/justifications/"for your own good"/etc. were and are never meant for the conquered people
[09:59:21] <Obormot\Arcturus> I think that's one of the key insights he's still missing
[10:02:30] <saturn2> well, they're for the conquered people after they lost
[10:03:15] <Obormot\Arcturus> Ok, sure, that too, but on the other hand, that's less necessary
[10:03:30] <Obormot\Arcturus> In both cases the driving factor is internal competition
[10:04:22] <saturn2> yes, you're losers and we're taking your stuff, but it's not all bad, we'll do all we can to help you adapt to your new situation sans stuff
[10:04:26] <Obormot\Arcturus> Once you've conquered people, you don't really need to explain to them that it's for their own good, because at that point it's self-evident that the way to gain advantage is to compete within the system into which they've been integrated
[10:05:24] <Obormot\Arcturus> (Although it's true that those of the conquered who catch on to this more quickly can and do use the "it's for your/our own good" line on the rest of their fellow conquered folk)
[10:06:15] <Obormot\Arcturus> At which point "it's for your own good" means "don't sabotage my attempts to advance within the conquerors' system"
[10:07:06] <Obormot\Arcturus> This whole dynamic was commonplace in the Soviet Union, to take just one obvious example
[10:08:01] <saturn2> yeah, it's an invitation to the recently conquered elite to switch sides
[10:08:19] <Obormot\Arcturus> Exactly
[10:14:29] <PapuaHardyNet> I'm spending the past hour moving tensor computations manually onto a GPU
[10:15:08] <PapuaHardyNet> as in, I'm fixing pytorch code such that the computations that automatically dump their result in cpu, now move it to gpu after it
[10:16:59] <PapuaHardyNet> and I deleted my virtual environment. perfect
[10:31:11] <saturn2> https://nitter.cattube.org/pic/media%2FFAIQYxnVUAsQAwL.jpg%3Fname%3Dorig
[10:33:40] <nshepperd2> but her polls are so inviting
[10:43:13] *** Quits: _inky (~inky_@46.36.119.235) (Ping timeout: 252 seconds)
[10:46:26] <PapuaHardyNet> I'm reading about people buying prebuilts on amazon which have their GPUs swapped
[10:46:36] <PapuaHardyNet> people are really creative
[11:00:23] <nshepperd2> just another wonderful side effect of sticky pricing
[11:04:08] <PapuaHardyNet> naw, it isn't sticky pricing that is the issue, it is amazon
[11:06:12] <nshepperd> well, people were buying prebuilts and then taking the GPU out bc they were being sold for cheaper than the gpu itself (eg. market price for a 3090)
[11:06:51] <nshepperd> i guess swapping the gpu then returning it is the obvious next step if you're sufficiently scummy
[11:09:43] <PapuaHardyNet> i mean, you can swap the gpu with the same specced gpu but which doesn't work
[11:09:55] <PapuaHardyNet> so yes, sticky pricing isn't the issue imo
[11:11:04] <nshepperd> sure
[11:32:07] *** Joins: two2thehead (~user@27.114.133.108)
[11:34:35] <Obormot\Arcturus> https://www.greaterwrong.com/posts/mHqQxwKuzZS69CXX5/whole-brain-emulation-no-progress-on-c-elgans-after-10-years
[11:34:46] <feepbot> Whole Brain Emulation: No Progress on C. elgans After 10 Years - LessWrong 2.0 viewer (Since the early 21st century, some transhumanist proponents and futuristic researchers claim that Whole Brain Emulation (WBE) is not merely science fiction - although still hypothetical, it's said to be a potenti [snip])
[11:36:09] *** Joins: badsektor (~badsektor@user/badsektor)
[11:39:11] <saturn2> sad!
[11:43:36] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[11:48:14] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[12:02:47] <shawwwn> sad
[12:11:09] <PapuaHardyNet> xxxtentacion
[12:11:10] <nshepperd2> sad :(
[12:16:37] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[12:30:37] <feep> Obormot\Arcturus: yep, glad someone noticed
[12:30:42] <feep> we really need to get elon musk to do it
[12:37:13] <Betawolf_> it could be a neuralink project: brainworms.
[12:38:54] <SDr> I mean, isn't this neuralink's core mission, to get live feed data directly from a set of neurons?
[12:39:15] <feep> yes but I don't think the problem is live data per se
[12:39:28] <feep> we don't need live data from worms, we need connection weight from worms
[12:39:48] <feep> I guess we could reverse engineer it if we could get live data from one worm neuron at a time maybe
[12:40:05] <feep> but aiu the problem is straight up that we don't know what connection strength looks like on a slice
[12:40:25] <SDr> yeah, exactly, you observe 2 neuron's firing rate as they relate to eachother, then see how one spiking up influences the other doing the same
[12:40:50] <feep> the point is you'd really want to be able to see that from a prepared slice through the worm brain, not an active sensor
[12:41:38] <SDr> active sensor is sorta better in that interference might be destructive; downside -amongst others- is that you have the entire brain as potential causation point
[12:43:12] *** Quits: badsektor (~badsektor@user/badsektor) (Quit: Leaving)
[13:14:12] <PapuaHardyNet> https://ansible.uk/writing/c-b-faq.html
[13:16:45] <PapuaHardyNet> what, why is /r/gwern a private community
[13:16:53] <PapuaHardyNet> this is outrageous
[13:19:11] <nshepperd2> gwerns only
[13:21:18] <Betawolf_>  huh, I thought I'd subscribed before.
[13:21:21] *** Joins: dv^_^_ (~user@80-42-10-216.dynamic.dsl.as9105.com)
[13:24:09] <PapuaHardyNet> I volunteer to be an honorary gwern
[13:24:58] <saturn2> he made it private because he didn't want any SJWs to see
[13:25:33] <PapuaHardyNet> oh, I see
[13:25:42] <PapuaHardyNet> that's even more enticing tbh
[13:35:47] <Obormot\Arcturus> So I am reading _What Mad Universe_ by Fredric Brown (another one of the authors listed in Appendix N)... all sorts of interesting little things about this one, due to its age (written 1949)
[13:36:45] <Obormot\Arcturus> It was written before any space missions, so the main character finds himself on the Moon at one point, looks up at Earth, and it's... yellow
[13:37:51] <Obormot\Arcturus> "Saturn is the only object in the Solar System with rings", thinks the protagonist a few pages later... of course he does, because the rings of Jupiter and Uranus were only discovered in the late 70s!
[13:38:55] <nshepperd2> ah yes, the yellow earth
[13:44:27] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[13:45:53] <saturn2> maybe he thought the sky was blue because the atmosphere reflected yellow light?
[13:48:15] <Gurkenglas> the referendum to expropriate big landlord companies in Berlin has passed and yet Deutsche Wohnen's stock price is stable, I wonder what's going on there
[13:48:41] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[14:04:16] *** Quits: dv^_^_ (~user@80-42-10-216.dynamic.dsl.as9105.com) (Remote host closed the connection)
[14:47:46] *** Joins: _inky (~inky_@46.36.119.235)
[14:56:22] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[14:57:11] *** Joins: srhm (~srhm@user/srhm)
[14:59:46] *** Quits: nullcone (uid11626@id-11626.helmsley.irccloud.com) (Quit: Connection closed for inactivity)
[15:01:28] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[15:02:24] *** Joins: srhm (~srhm@user/srhm)
[15:06:32] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[15:07:25] *** Joins: srhm (~srhm@user/srhm)
[15:07:55] <Urchin[emacs]> https://i.redd.it/3rnewjklvwq71.jpg about reasons for setting a chess record
[15:45:19] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[15:49:41] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[15:49:50] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[15:52:28] <catern> Gurkenglas: the expropriation will involve paying them compensation
[16:21:08] <kuudes> huh https://www.reuters.com/world/asia-pacific/philippine-president-duterte-says-he-is-retiring-politics-2021-10-02/
[16:21:19] <feepbot> Philippine President Rodrigo Duterte said on Saturday he was retiring from politics, a surprise move that fuelled speculation he was clearing the way for his daughter to run to succeed him, despite her filing for re-election as mayor.
[16:46:10] *** Quits: _inky (~inky_@46.36.119.235) (Ping timeout: 252 seconds)
[16:52:57] *** Joins: galambo_ (~galambo@user/galambo)
[16:55:36] *** Quits: galambo__ (galambo@user/galambo) (Remote host closed the connection)
[17:00:07] <feepbot> <gwern> uploads https://www.gwern.net/docs/modafinil/2021-adam.pdf
[17:04:23] <Gurkenglas> catern, the referendum said to pay them less than market price though, so why isn't market price falling?
[17:04:40] <gwern> Obormot\Arcturus: I didn't realize the rings were discovered so late. that shows you how hard they are to see... very different from media where a blind man can see the rings of everything
[17:05:10] <nshepperd2> Gurkenglas: it's non binding, the market probably thinks it's not going to happen
[17:05:43] <Gurkenglas> but, like, when the referendum passed the price didn't seem to move *at all* - surely they think there's some chance of it happening?
[17:06:46] <Gurkenglas> (and surely they didn't expect it to pass certainly, since 57% voted for)
[17:13:46] <PapuaHardyNet> http://www.jofreeman.com/joreen/tyranny.htm
[17:13:57] <feepbot> The Tyranny of Stuctureless by Jo Freeman
[17:28:40] <feepbot> <gwern> https://twitter.com/the_shb/status/1443740333041328128
[17:28:44] <|dbotdan> Sarah Holland-Batt (@the_shb, 2021-10-01 00:51): ‘Today seems as good a day as any to share these pics of the cat done as a Zen garden with the world’ Images: https://nitter.vxempire.xyz/pic/media%2FFAkyLEvUcBIODSh.jpg%3Fname%3Dorig (description: a baby goat lying on its back; confidence: 0.40) | https://nitter.vxempire.xyz/pic/media%2FFAkyLEvVcAEJSLC.jpg%3Fname%3Dorig |
[17:28:44] <|dbotdan> https://nitter.vxempire.xyz/pic/media%2FFAkyLExUcAcckro.jpg%3Fname%3Dorig | https://nitter.vxempire.xyz/pic/media%2FFAkyLFMVIAI79CT.jpg%3Fname%3Dorig
[17:33:46] <feepbot> <gwern> https://twitter.com/caraesten/status/1443973277584699395 uneven numbers of legs are the worst
[17:33:48] <|dbotdan> Cara-normal Activity (@caraesten, 2021-10-01 16:17): ‘zoology section at this book store goes into some unexpected categorization’ Images: https://nitter.domain.glass/pic/media%2FFAoF97dXoB82J2g.jpg%3Fname%3Dorig (description: text; confidence: 0.82) | https://nitter.domain.glass/pic/media%2FFAoGAE6XoA4wQDE.jpg%3Fname%3Dorig |
[17:33:48] <|dbotdan> https://nitter.domain.glass/pic/media%2FFAoGA95XoBgYsmw.jpg%3Fname%3Dorig | https://nitter.domain.glass/pic/media%2FFAoGCIqXoAEucog.jpg%3Fname%3Dorig
[17:38:49] <feepbot> <gwern> 'Many of my students this semester want to know what happened to Mary, the brilliant color scientist as if it’s not a thought experiment' https://twitter.com/freganmitts/status/1444019853497671691
[17:38:50] <|dbotdan> Megan Fritts (@freganmitts, 2021-10-01 19:22): ‘Just taught Nozick’s Experience Machine for the hundredth time. All but one student were immediately and unreservedly in favor of entering the machine for life. Never had that happen before, rather threw off my lesson plan!’
[17:41:16] <PapuaHardyNet> zoomers are hedonists, who knew
[17:42:09] <PapuaHardyNet> ethical hedonists*
[17:43:53] *** Joins: badsektor (~badsektor@user/badsektor)
[17:44:51] <gwern> nshepperd2: so I realized that I said 'get the top n solutions from the DP' but I don't actually know how to do that since all of the recursive values are calculated under the assumption that the policy takes the max/min at the next step, it doesn't obviously generate all solutions in value order... there must be some way to do it short of brute forcing every possible solution, scoring, and...
[17:44:57] <gwern> ...sorting, but not obvious to me. however, an easy hack would be to generate multiple DP solutions for different costs: start with an initial cost of substitution which heavily penalizes any rewrites; if 0 rewrites are optimal, halve the penalty, resolve, and so on until you get some rewrites; then you can explore that range to get different rewrite solutions with different typographic-level...
[17:45:03] <gwern> ...losses
[17:46:00] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[17:47:15] <gwern> eg you solve the layout for the problem where 1 rewrite = 1em; if there are no rewrites and it's best to just lay it out as is, then you halve the penalty to 0.5ems per rewrite; now perhaps it'll substitute a word or two; then you try 0.75, and get a different rewrite; then you bounce down to 0.625 em penalty and see if you get a different rewrite, and after a while you have _n_ different...
[17:47:21] <gwern> ...rewrites and you can score them via the API for semantic-stylistic similarity to the original and pick your tradeoff between exactly justified layout and changing words/meaning/style
[17:47:28] <shawwwn> EG
[17:47:30] <nshepperd2> ahh
[17:47:33] <shawwwn> EGG
[17:47:45] <shawwwn> egg you solve the egg
[17:48:29] <gwern> by starting with a high rewrite penalty, you should get the minimal rewrite solutions first
[17:48:54] <nshepperd2> it might improve the result to score rewrites by some sort of semantic similarity, like of the word in isolation
[17:49:16] <nshepperd2> like cosim of the gpt embedding of the word vs each of synonyms
[17:49:25] <nshepperd2> instead of just counting substitutions
[17:49:43] <nshepperd2> so that it tries more obviously correct substitutions first
[17:50:09] <gwern> my thinking is that if you try to do that inside the GPT embedding, you'll wind up doing a *lot* of calls, and that sort of greedy word choice will ignore overall style/semantics. like, it might consistently choose a short word, which in isolation is fine, but then it gets chosen across the entire text and looks really weird when you read it as a global whole
[17:50:26] <gwern> * er, try to do that embedding/logprob heuristic inside the DP
[17:50:31] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[17:51:05] <gwern> 'I know thomas jefferson did not consistently use "yo" in the Declaration of Independence, even as beautifully laid out as it looks'
[17:51:15] <PapuaHardyNet> okay so I've been thinking
[17:51:34] <PapuaHardyNet> I believe that compartmentalization is a natural human tool we have to defend against infohazards
[17:51:52] <nshepperd2> yeah you wouldn't do it inside the DP
[17:52:02] <PapuaHardyNet> (I mean, it is literally defined as a "defense mechanism")
[17:52:10] <nshepperd2> you'd just precompute the similarity between each word and its synonyms
[17:52:55] <nshepperd2> and do the DP with the constraint of "amount of similarity sacrificed" instead of "number of substitutions" as the constrint
[17:53:01] <nshepperd2> or something
[17:53:36] <gwern> ah. yeah, that could be efficient if you cache all of the distance-pairs or precompute them for your dictionary
[17:54:04] <shawwwn> (meanwhile gwern is like "I wrote a haskell!")
[17:54:32] <gwern> i maked you a code
[17:54:57] <shawwwn> your code was always the best. like grandma's cookies
[17:56:03] <gwern> eat, eat! you're so thin
[18:00:08] <PapuaHardyNet> granny gwern, sounds appropriate
[18:00:14] *** Joins: _inky (~inky_@5.77.163.108)
[18:05:09] <feepbot> <gwern> https://twitter.com/DarbraDawn/status/1444256070797496327
[18:05:10] <|dbotdan> Gas Station Barbie (@DarbraDawn, 2021-10-02 11:00): ‘Just wrote a poem about one of my cats and burst into tears AMA’
[18:10:11] <feepbot> <gwern> https://www.poetryfoundation.org/poems/50599/epitaph-on-a-hare
[18:10:12] <feepbot> Epitaph on a Hare by William Cowper | Poetry Foundation (Here lies, whom hound did ne’er pursue,)
[18:15:11] <feepbot> <gwern> https://www.mdpi.com/2073-4425/12/10/1509/htm
[18:15:11] <feepbot> Genes  | Free Full-Text | Major Depressive Disorder and Lifestyle: Correlated Genetic Effects in Extended Twin Pedigrees | HTML (In recent years, evidence has accumulated with regard to the ubiquity of pleiotropy across the genome, and shared genetic etiology is thought to play a large role in the  [snip])
[18:17:52] * shawwwn is feeling whelmed today
[18:46:34] <nshepperd> i am whelmed every day
[18:48:02] <gwern> I tend to bounce from overwhelmed to underwhelmed, and only a few days give me nice whelmed levels
[18:48:34] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[18:50:36] <nshepperd> your whelm system needs damping
[18:50:59] <gwern> yeah, that's why I keep thinking about queues. I need queues to dampen things and try to keep days at nominal whelming
[18:57:11] <feepbot> <gwern> https://twitter.com/chazfirestone/status/1444044574091923459 they lurk amogus
[18:57:15] <|dbotdan> Chaz Firestone (@chazfirestone, 2021-10-01 21:00): ‘Can you voluntarily produce a "rumbling" sound in your own ears? I can, and once thought everyone could! But no: Only some people can voluntarily control their tensor tympani, which dampens loud sounds by tensing up the eardrum. |   |
[18:57:15] <|dbotdan> https://en.wikipedia.org/wiki/Tensor_tympani_muscle?utm_content=bufferfb6d5&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer#Voluntary_control ’ Images: https://nitter.eu/pic/media%2FFApGCOKUYAECCTz.jpg%3Fname%3Dorig (description: diagram; confidence:
[18:57:15] <|dbotdan> 0.99)
[18:58:31] <gwern> https://www.reddit.com/r/earrumblersassemble/
[18:58:44] <feepbot> Ear Rumblers Assemble (r/earrumblersassemble: A subreddit for those who can control their Tensor Tympani muscle.)
[18:59:45] <nshepperd2> oh, i can do that
[18:59:51] <nshepperd2> better throw me out the airlock
[19:01:01] <adiabatic> I suppose that's one way to keep you from hearing your…or _can_ you hear your own ears rumble in space?
[19:01:39] <nshepperd2> probably
[19:01:58] <nshepperd2> i assume the sound is conducted by the bones attached to that muscle, not through the air
[19:02:16] <nshepperd2> (doesn't seem fair that i can do that, and i can whistle in reverse, but only the right half of my face can smile)
[19:02:46] *** Joins: nullcone (uid11626@id-11626.helmsley.irccloud.com)
[19:06:17] <nshepperd2> "Those with Bell’s Palsy w/permanent damage get something called “timpanic membrane synkinesis” which does something similar, but I can attest, it can be quite annoying! I didn’t mention it, but this came out today:" wait what, holy shit
[19:06:39] <nshepperd2> are these things actually connected :|:
[19:06:59] <adiabatic> oh wow
[19:08:07] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Quit: Leaving...)
[19:10:25] *** Joins: galambo__ (galambo@user/galambo)
[19:11:06] <nshepperd2> most cases of bell's palsy seem to be much more serious than what i have
[19:11:09] <nshepperd2> but uh wtf
[19:13:19] <Gurkenglas> suppose landlords were forced to sell to their renters certificates-of-one-month-of-rent at the current rent, so that they could stock up on them ahead of time. They would also be forced to buy them back at the current rent. Then if you see a 50% chance that your rent goes up, you can buy those certificates, and if the rent doubles you can sell them back at a profit and move. Would that help an escalating rents 
[19:13:19] <Gurkenglas> situation?
[19:13:44] *** Quits: galambo_ (~galambo@user/galambo) (Ping timeout: 252 seconds)
[19:17:05] <gwern> what would stop people from buying up all possible certificates and then reselling them?
[19:17:37] <Gurkenglas> I don't follow. If it's immediate it wouldn't turn a profit
[19:18:12] <Gurkenglas> If a renter invests as much money in months-of-rent as the apartment is worth, the landlord won't want to raise the rent
[19:23:13] <feepbot> <gwern> https://acamh.onlinelibrary.wiley.com/doi/10.1002/jcv2.12030
[19:23:14] <feepbot> The association between polygenic scores for attention‐deficit/hyperactivity disorder and school performance: The role of attention‐deficit/hyperactivity disorder symptoms, polygenic scores for educational attainment, and shared familial factors - Jangmo -  - JCPP Advances - Wiley Online Library
[19:25:42] <Gurkenglas> gwern, or did you mean that people might buy certificates for other apartments than their own? I don't see the problem with allowing that.
[19:25:42] <kuudes> Gurkenglas, if one has money to buy certs, why does one just not buy the apartment?
[19:25:56] <Gurkenglas> kuudes, you may have only 10% of that money
[19:26:05] <Gurkenglas> But 10% is enough to be happy when the rent goes up and move out
[19:26:20] <kuudes> the point of owning an housing is to own all future rent certificates of that house.
[19:26:47] <kuudes> surely they can't raise rent without contractual agreement but with termination period?
[19:27:06] <kuudes> ie over here it is 3 months if you have lived less than 12 months and 6 months otherwise
[19:27:14] <kuudes> 6 months is plenty to find a new apartment
[19:27:37] <Gurkenglas> that would not make you happy the rent goes up
[19:27:45] <kuudes> ?
[19:27:52] <kuudes> "But 10% is enough to be happy when the rent goes up and move out"
[19:28:04] <kuudes> 10% should be about 24 months I suppose
[19:28:20] <Gurkenglas> under the current system, when your landlord says your rent goes up, that's a "in 6 months you pay more or move out", which is not a happy prospect
[19:28:31] <kuudes> after 6months you pay more
[19:28:39] <kuudes> the 6 months are on current price
[19:28:50] <kuudes> also, rent hikes that are not in the rent contract are not allowed over here
[19:29:08] <kuudes> but termination is
[19:29:28] <Gurkenglas> <kuudes> the 6 months are on current price <- yeah, still not a happy prospect
[19:29:34] <kuudes> so they can say to you "I terminate the lease in end of this month + 6 months or you agree to new price"
[19:29:52] <Gurkenglas> yes, and you would have preferred them to just not do that
[19:30:04] <kuudes> sure. and I would prefer to live for free while we are at it?
[19:30:31] <kuudes> how does that matter?
[19:31:01] <kuudes> "be happy when the rent goes up and move out"
[19:31:11] <kuudes> you were planning to move out there. how is that different?
[19:31:11] <Gurkenglas> whereas under my system they say "you pay 20% more starting now *or* we multiply your investment by 1.2 and you move out", which does not sound like an unhappy prospect
[19:31:59] <kuudes> idgi
[19:32:39] <Gurkenglas> Okay so there's an apartment in City with small rent. The current story is you move in, make friends, get a job, and then the landlord notices that and increases the rent because you're less willing to move out
[19:32:43] <kuudes> "suppose landlords were forced to sell to their renters certificates-of-one-month-of-rent at the current rent, so that they could stock up on them ahead of time. They would also be forced to buy them back at the current rent. Then if you see a 50% chance that your rent goes up, you can buy those certificates, and if the rent doubles you can sell them back at a profit and move" <- I would not be a landlord with these rules I suppose
[19:33:12] <kuudes> buy your own house?
[19:33:24] <Gurkenglas> that is less efficient than what i am suggesting
[19:33:39] <kuudes> why should anyone build houses for bad deals?
[19:34:29] <Gurkenglas> How would it be a bad deal? If you never increase the rent, this rule has no effect except that you get free interest
[19:35:01] <feep> "I would not be a landlord with these rules" okay so? probably other people would happily take the money
[19:35:05] <kuudes> usually you put in the clause that rent increases per consumer price index or 2% minimum per year
[19:35:34] <kuudes> rents should increase the same pace as housing value increases
[19:35:34] <feep> let's all remember that the economy is optimized when everybody makes nothing
[19:35:44] <kuudes> sure
[19:36:29] <kuudes> over here we don't have rent caps and we had our last general system bancruptcy in 90s, so prices are about market prices and I don't see that much of problem with them
[19:36:36] <kuudes> in helsinki there are problems I hear
[19:36:45] <kuudes> which always happens in poles
[19:36:52] <kuudes> singularities, if we will
[19:37:25] <kuudes> there is only so much room on top of the central railroad station (schelling point of center of preferences)
[19:38:15] <Gurkenglas> The starting rent on the apartment in City is 1000$. You think to yourself that you would be willing to pay up to 2000$, and you would be happy to move back out of the city for 5000$. So you buy 5 months of rent. If the landlord increases the rent to 1800$, you eat the increase. If he increases it to 2200$, you sell the months and made 6000$ profit and move out.
[19:38:40] <Gurkenglas> The 5000$ investment is much less than it would take to buy an apartment outright
[19:39:32] <kuudes> how can he increase the rent suddenly from 1000 to 1800
[19:39:40] <kuudes> cpi rises about 2% per year
[19:40:01] <kuudes> so per years the rent goes 1000, 1020, 1040, 1060, etc
[19:40:04] <Gurkenglas> these numbers are extreme for illustrative purposes, but note that we don't need your 2% cap per year under my system
[19:40:30] <kuudes> that sounds weimar levels of inflation
[19:40:31] <feep> opposite of cap
[19:40:46] <feep> kuudes you are going into this with the assumption of a market that is basically stable and reliable
[19:40:56] <kuudes> yes
[19:41:07] <kuudes> why do you guys have bad socities :-(
[19:41:13] <feep> whereas Gurkenglas is going into it with the presumption of "landlords have zero chill and zero shame and will shit on the commons for an extra buck"
[19:41:47] <feep> kuudes: terrible, terrible incentives
[19:41:54] <kuudes> well what do you do if the landlords decide to demolish the building and construct a new one?
[19:42:06] <kuudes> you are not entitled to housing in the new building, you just have to move out
[19:42:06] <feep> created by a natural process called politics, or "rule by people who do not understand or care about incentives"
[19:42:23] <feep> but that's expensiiiive
[19:42:32] <feep> kuudes: like, you're not appreciating how regulation works
[19:42:37] <kuudes> social democracy seems the answer to many of these problems
[19:42:40] <feep> the new building will probably be worse from a landlord perspective
[19:42:46] <kuudes> why?
[19:42:47] <feep> no, social democracy is the *cause* :v
[19:42:51] <nshepperd2> my guess is: you're forcing people to do things without a clear idea of the consequences, probably unintended consequences will strike and this fucks everything up somehow
[19:42:56] <kuudes> have better social democratists
[19:42:57] <feep> why? new rules that got created after the old building was built
[19:43:06] <kuudes> ?
[19:43:15] <feep> old building is grandfathered in, rebuild it? it's probably gonna end up with less space and more expense
[19:43:21] *** Quits: badsektor (~badsektor@user/badsektor) (Quit: Leaving)
[19:43:28] <kuudes> over here we had housing subsidy to depreciate the cap the older the construction year of the apartment was
[19:43:41] <kuudes> so that it was incentivized to renovate and get up to date
[19:43:46] <feep> sensible
[19:43:46] <Gurkenglas> kuudes, the landlord must not demolish the building while the renter keeps paying rent; but you could just set the rent to infinity to force the renter out; except you don't want to do that when the renter has months saved up
[19:43:47] <feep> we don't
[19:43:49] <kuudes> because from old houses you could just get less rent
[19:44:05] <feep> look this is one of those things again
[19:44:09] <feep> where your politicians do sensible things
[19:44:10] <kuudes> because even poor people were not given money to pay rent for shitty housing
[19:44:14] <feep> and ours do fucking crazy bullshit
[19:44:15] <Gurkenglas> But you can always get them out by raising the rent until they sell&leave
[19:44:16] <feep> like
[19:44:16] <kuudes> :-(
[19:44:18] <feep> all the time
[19:44:21] <kuudes> feep, I am sorry
[19:44:27] <kuudes> .wp mauno koivisto
[19:44:29] <feepbot> kuudes: https://en.wikipedia.org/wiki/Mauno_Koivisto Mauno Henrik Koivisto GOIH (Finnish pronunciation:  [ˈmɑu̯no ˈkoi̯ʋisto]; 25 November 1923 – 12 May 2017) was a Finnish politician who served as the 9th President of Finland from 1982 to 1994. He also served twice as Prime Minister, from 1968–1970 and again from 1979–1982.
[19:44:47] <kuudes> many seem to credit him with much of the good stuff of housing here, I have read
[19:45:01] <feep> I don't know who I would credit with the good stuff of housing in germany
[19:45:01] <kuudes> also finland lost 10% of its working age population for emigration in 70s
[19:45:04] <feep> because I am not aware of any
[19:45:19] <kuudes> so here they really *had to* do something so that everyone does not flee the country
[19:45:39] <feep> again, that seems to assume basically aligned incentives
[19:45:45] <feep> kuudes: look, where I was born
[19:45:53] <feep> they had to do something so that everyone does not flee a country
[19:46:00] <feep> so they literally built a big wall and put men with machineguns on it
[19:46:04] <kuudes> so we got housing benefit, supply side subsidized loans for also for-profit housing constructor companies (with strings re life standard, rent levels), zoning and whatnot
[19:46:12] <kuudes> feep, yeah :-(
[19:46:34] <feep> I'm just saying, this is our floor level for "bad politics" :p
[19:46:39] <kuudes> yeah
[19:47:12] <feep> like, I gripe about germany, but this is the germany that had the political tool of "murder your own citizens" on the agenda in living memory
[19:47:16] <feep> technically twice
[19:47:58] <feep> one of the primary reasons people here are glad about the eu is
[19:48:05] <kuudes> indeed
[19:48:15] <feep> "well, I mean, we haven't sent our military to attack our neighbours in like 80 years now"
[19:48:23] <feep> "that's something, right? That's a step up, gotta credit it"
[19:48:30] <kuudes> technically europarlament moves once a month to be held hostage so that parliamentarians would die if there was a war
[19:49:31] <kuudes> I have thought that we should have put our eu office, chemical agency of eu, to rovaniemi instead of helsinki, as rovaniemi suffered more in the war
[19:49:38] <Gurkenglas> maybe the government could identify people whose presence harms the economy... and pay them to leave
[19:49:47] <kuudes> denmark did that
[19:49:48] <Gurkenglas> frees up apartments, lowers rents
[19:50:14] <kuudes> that incentive slope ends up with... free gas
[19:50:17] <feep> sounds   modest
[19:50:32] <kuudes> also you are warm the rest of your life
[19:50:45] <Gurkenglas> how does the incentive slope get there?
[19:50:54] <kuudes> because no one else will take them
[19:51:02] <nshepperd2> maybe try thinking for 1 minute about incentives before proposing things
[19:51:34] <Gurkenglas> but there are lots of places where the cost of living is cheap, why wouldn't they take paying customers
[19:51:43] <kuudes> personally I feel sad when people here do populism on "lets dismantle housing benefit because that only benefits landlords"
[19:52:00] <kuudes> ie "fuck you the system is complicated it is good they get moneys, every alternative is worse"
[19:53:07] <Gurkenglas> nshepperd2, rude; what is the actual problem here, who would be incentivized to do what bad thing?
[19:58:07] <feepbot> <gwern> https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3422581
[19:58:08] <feepbot> The Robot Revolution: Managerial and Employment Consequences for Firms by Jay Dixon, Bryan Hong, Lynn Wu :: SSRN (As a new general-purpose technology, robots have the potential to radically transform employment and organizations. In contrast to prior studies that predict dr)
[19:58:42] <Gurkenglas> Maybe you mean that people would do economic damage to be bought out? But obviously it would be based on opportunity, not outcome.
[20:01:14] <Gurkenglas> Maybe you mean... that subcultures would be destabilized by some of them leaving? And then the remainder would feel that the government was evil to offer money to leave their friends behind?
[20:05:26] <Gurkenglas> Like, immigration is already based on whether the immigrant can be an economic benefit; I'm merely completing the symmetry.
[20:08:21] <Gurkenglas> (it's the *other* two quadrants that degenerate - of paying money to attract good workers, and hindering people from leaving)
[20:09:03] <quanticle> "The game cannot be changed by those stuck playing it: one must play or perish. The only solution possible is for an outside force to intervene and reshape the terms of the game. Socialist revolution will be that force. With no stake in the current order, the propertyless masses will wipe the slate clean. Human life in the world to come will be twiced blessed: technology and industry has freed
[20:09:05] <quanticle> mankind from the shackles of nature. Revolution will now break the artificial shackles that technology and industry themselves had forged. From that point forward great decisions will not be filtered through the partial interests of the individual, but decided rationally, with the entire whole in mind. Then mankind would be free! Free from the manipulations of the market! Free from egoism, from
[20:09:07] <quanticle> indecency, from all the terrible things the system forces us to do to each other! Moloch vanquished, human life would finally flourish as our inborn natures intended."
[20:09:09] <quanticle> https://scholars-stage.org/xi-jinpings-war-on-spontaneous-order/
[20:09:11] <quanticle> gwern, saturn2: So the conclusion I've drawn from this essay is that Xi Jinping is really a neoreactionary monarch.
[20:09:20] <feepbot> Xi Jinping’s War on Spontaneous Order – The Scholar's Stage (Yesterday the Wall Street Journal published a letter I wrote to their editor in response to Kevin Rudd’s exposition on Xi Jinping’s "Common Prosperity” campaign:)
[20:10:46] *** Quits: _inky (~inky_@5.77.163.108) (Ping timeout: 252 seconds)
[20:14:12] <feepbot> <gwern> https://www.cnbc.com/2021/10/02/tesla-tsla-q3-2021-vehicle-delivery-numbers.html
[20:14:13] <feepbot> Tesla TSLA Q3 2021 vehicle delivery numbers (Tesla delivered 241,300 electric vehicles during the third quarter of 2021, the company said Saturday.)
[20:14:48] <Gurkenglas> kuudes, what happens if you fund housing benefit with a landlord tax? :)
[20:16:31] <quanticle> feep: As the old saying goes, "The purpose of NATO is to keep the Soviets out, the Americans in, and the Germans down"
[20:21:23] <feep> lol
[20:21:43] <[itchyjunk]> Are ANN's always approximating some functions? Do ANN's always have an output layer? I ask there two because i was wondering how the output layer and the function being approximated is related
[20:28:29] <PapuaHardyNet> 1. yes, ANNs always can be modelled as functions
[20:28:48] <PapuaHardyNet> 2. yes, a function always has an output, therefore you can assume the last layer of an ANN as an output layer
[20:31:39] <kuudes> well landlords pay capital income tax from the rents
[20:32:36] <Gurkenglas> kuudes, so let's say that rents are taxed more heavily
[20:32:41] <kuudes> why?
[20:32:51] <[itchyjunk]> PapuaHardyNet, ah neat. now i wonder if there is some sensible relationship between this layer and the function. i was wondering if the functions inflection point might be related to this maybe, for example.
[20:32:59] <Gurkenglas> kuudes, for the same reason you give housing benefits
[20:33:02] <kuudes> what you want to tax is people living in their own houses
[20:33:11] <kuudes> taxes on rent income raise rents
[20:33:20] <kuudes> .wp imputed rent
[20:33:22] <feepbot> kuudes: https://en.wikipedia.org/wiki/Imputed_rent Imputed rent is an estimate in economic theory of the rent a house owner would be willing to pay to live in his or her own house. Imputed rent can thus serve as an important measure between home owners and tenants.
[20:33:30] <Gurkenglas> How do taxes on rent income raise rants?
[20:34:09] <milanandreew> because the landlord can offset his taxes to the tenant, I assume
[20:34:13] <kuudes> because to be willing to buy or build housing a rational landlord calculates how much net income they will get in future, and do the transaction only if it profits them on their calculation
[20:34:59] <kuudes> but living in self owned house is effective tax subsidized as rarely it is taxed similarly as capital income from rent
[20:35:27] <kuudes> if rental income is not taxed, then there is no market distortion, but often politicians have wanted for some reason to subsidize home ownership specifically
[20:35:27] <feep> it occurs to me
[20:35:56] <feep> my economic view that accumulation of property is the big misstep of capitalism and that we should introduce truly universal taxation in order to approximately drag everyone onto the same level, harrison bergeron style
[20:35:58] <kuudes> taxation of imputed rent is on the eu tax harmonization long term plan, but has been there for 20+ years, so we'll see if it ever happen
[20:36:14] <kuudes> what do you mean with that feep?
[20:36:15] <feep> is structurally equivalent to the Bezos API Mandate.
[20:36:37] <kuudes> over here we had imputed rent tax until 90s
[20:36:45] <feep> no like, *universal* taxation
[20:36:48] <feep> tax literally everything
[20:37:09] <Gurkenglas> I suppose it's fair that you'd want to reduce distortions by treating house owners as renting to themselves.
[20:37:15] <kuudes> eh? yes? what do you mean feep?
[20:37:27] <kuudes> good tax system should tax most everything and about the same level
[20:37:28] <feep> harberger style
[20:37:42] <nshepperd> feep wants to destroy the future
[20:37:51] <feep> kuudes: you are not appreciating the level of taxation I am talking about
[20:38:04] <feep> I want to *progressively tax corporations based on the size of their balance sheet*.
[20:38:25] <kuudes> why not just a constant percentage?
[20:38:34] <feep> because I'm trying to destroy any accumulation of wealth
[20:38:40] <feep> I am the spectre of communism given flesh!
[20:38:46] <feep> but unironically
[20:38:50] <feep> nshepperd: right, but it's basically the api mandate
[20:39:00] <feep> the idea that companies are able to capture efficiencies of centralization
[20:39:02] <nshepperd> i still don't understand why you'd want to do something so insane
[20:39:05] <feep> indicates that the entire market system is inefficient.
[20:39:18] <Gurkenglas> [itchyjunk], I worry about possible misunderstandings about words here. ANNs are typically made of a sequence of functions; the first turns the input into some hidden datum; the second turns that datum into another; the last turns the penultimate datum into the output
[20:39:18] <nshepperd> literally incomprehensible
[20:39:27] <Gurkenglas> The compositions of all these functions is the whole function.
[20:39:29] <kuudes> I too am a bit lost what is the actual aim here
[20:39:30] <feep> and I want to incentivize every single participant to make the *backbone of the entire market system* as efficient as an in-company request.
[20:39:39] <feep> for context, the bezos api mandate was
[20:39:53] <feep> 1. every service and department in amazon can only communicate through publically documented apis
[20:40:02] <feep> 2. we can and will at any point expose these apis to the public
[20:40:10] <feep> 3. anyone who is not on board is fucking fired, do not test me on this
[20:40:13] <[itchyjunk]> Gurkenglas, oh i see. in that case, my question doesn't quite make as much sense
[20:40:24] <Gurkenglas> A layer is, depending on the way you look at it, either one of these functions, or one of the slots-where-a-datum-goes
[20:40:24] <kuudes> feep, hmm, so you want granularity
[20:40:28] <kuudes> yeah, could make sense
[20:40:29] <feep> kuudes: yep, exactly.
[20:40:50] <feep> I want to grind the entire system down until they're fucking forced to make the *entire trade system* as efficient as an in-company memo.
[20:40:57] <kuudes> that does not destroy accumulation of wealth though but just move it to personal balance sheets
[20:41:07] <feep> right, I want to destroy that too but for a different reason
[20:41:07] <nshepperd> destroying the future is not efficient
[20:41:26] <feep> destroying the future can be efficient!
[20:41:30] <feep> it's the basis of mad, for instance
[20:41:41] <feep> and this is kind of economic mad
[20:41:41] <nshepperd> no
[20:41:48] <kuudes> this sounds like rooc stuff
[20:42:10] <[itchyjunk]> So there is data (the domain), the ANN (the function) and the output (codomain). hmm i guess i don't know enough concepts to form any better question for now. thanks!
[20:42:11] <feep> kuudes: I have watched hours of very high-octane fast-edited youtube, I am in a ~mood~
[20:42:16] <kuudes> XD
[20:42:31] <kuudes> quanticle, s0ph1a "<nshepperd> destroying the future is not efficient <feep> destroying the future can be efficient!"
[20:42:37] <kuudes> rooc ^
[20:43:00] <kuudes> who manages it these days?
[20:43:24] <feep> nshepperd: but yes you're correct this is intended as a kind of economic game of chicken along the lines of "no economic prosperity except *with* the market."
[20:43:51] <nshepperd> no as far as i can tell you just want people who need to save up for things to suffer
[20:43:54] <Gurkenglas> [itchyjunk], you may want to have in your head the picture of a path of arrows; each arrow depicts one of the component functions; each start/end of an arrow depicts one of the datums; the start is the input, the end is the output
[20:44:06] <feep> monopolies are a hack, a way to establish a superior system of trade and then not share it with anyone, I want a system where a company is only efficient inasmuch as the entire system is efficient, in order to align incentives behind global optimization.
[20:44:33] <feep> nshepperd: I have no problem with saving up, I have a problem with *superlinear returns* from saving.
[20:44:49] <Gurkenglas> *every* path of arrows can be composed (in a unique manner) into one arrow/function.
[20:44:52] <nshepperd> that's the same as having a problem with saving up
[20:45:00] <feep> no it's having a problem with investing
[20:45:04] <feep> saving up is fine
[20:45:13] <nshepperd> it's the same thing
[20:45:20] <feep> only because our system is broken
[20:45:24] <nshepperd> no
[20:45:26] <feep> :v
[20:45:28] <feep> yes
[20:46:01] <nshepperd> it's intrinsically the same because of the nature of saving and finite civilizational resources
[20:46:16] <Gurkenglas> feep, which function is superlinear - time passed to profit per dollar, or money in to money out?
[20:46:20] <feep> only because we've mixed up investment spending and consumptive spending
[20:46:30] <nshepperd> that doesn't mean anything
[20:46:39] <feep> Gurkenglas: not actually sure
[20:46:49] <feep> Gurkenglas: would need to think about for longer
[20:46:52] <nshepperd> anyway this is too personal for me so i should stop
[20:47:16] <kuudes> savings related trauma?
[20:47:37] <nshepperd> lol, no
[20:47:38] <feep> hey, no shade on anyone accumulating property
[20:47:44] <feep> it's just rational in our system
[20:47:45] <kuudes> but yeah, it is sane and appreciable if you know you need to stop and then stop
[20:48:11] <feep> I'm doing the same thing lol, I just feel it really says something broken that I'm *able* to
[20:48:32] <feep> like..... the FIRE premise is "you can work and save money until you don't need to work anymore, ever"
[20:48:38] <feep> and. um, I'm happy I get to do that?
[20:48:45] <feep> and I'm mad I have to, to, like
[20:48:46] <feep> live
[20:49:04] <feep> and I feel that fact sort of obscures the fact that my ability to do so is economic insanity.
[20:49:50] <nshepperd> yes, because the contribution of your work to civilization's resources results in exponential compounding benefits to future generations that pays off your existence
[20:50:14] <feep> right but I'm a liberal first and foremost?
[20:50:42] <feep> and like, from a liberal perspective, my existence is paid off by the fact that "I am a being who has moral worth", because "every person who exists is a being who has moral worth"
[20:50:59] <nshepperd> ok so what
[20:51:21] <feep> and so the fact that I have to do this weird compounding payoff hack to secure my existence -- like, thanks for giving me the ability to cheat economics to do this
[20:51:33] <kuudes> personally I am for investing but against saving
[20:51:36] <Gurkenglas> what's the alternative? we do need someone to run the factories
[20:51:37] <feep> but nobody sane would actually design an economic system that let people do this! in an efficient economy, everybody makes nothing.
[20:51:38] <nshepperd> does having moral worth cancel out having helped out future generations or something
[20:52:02] <kuudes> well, interest rates could get to 0
[20:52:04] <Gurkenglas> feep, if everybody makes nothing why would anyone do anything
[20:52:05] <feep> whereas in our economy, *some* people make something *from* nothing.
[20:52:09] <feep> Gurkenglas: nobody would 
[20:52:17] <Gurkenglas> feep, but then you would starve
[20:52:20] <nshepperd> you're talking about a post scarcity economy, not an efficient one
[20:52:21] <feep> sorry, typing
[20:52:24] <kuudes> technically they don't
[20:52:27] <feep> Gurkenglas: nobody would *have to* do anything because it'd be post-scarcity
[20:52:42] <feep> nshepperd: post-scarcity is the goal state of economics.
[20:52:42] <kuudes> everything anyone has in an account is a debt of someone else
[20:52:49] <Gurkenglas> feep, how would it be post-scarcity if nobody runs the factories
[20:52:51] <nshepperd> yes, if we had magical ai that solved everything you wouldn't need to work
[20:52:55] <feep> Gurkenglas: it's a limit
[20:53:11] <feep> Gurkenglas: the people running the factories would be entities most suited to utterly minimizing effort in the process
[20:53:24] <Gurkenglas> feep, at the cost of productivity
[20:53:27] <feep> no?
[20:53:41] <nshepperd> post scarcity is achieved by having infinite resources, not tinkering with bits of paper
[20:53:42] <feep> if there was money on the table... it's like a shrinkwrap plastic hooked up to a vacuum
[20:53:51] <feep> if there was air in it the system would suck it out, that's what it's *for*.
[20:54:05] <kuudes> the difference between an savings account/loan and an investment is that if you are not paid the former, you can get the police to punish the party that was due to pay, and in the latter you can't, unless they have frauded you
[20:54:11] <feep> nshepperd: tinkering with bits of paper is a core part of the story of how we got the current level of resources tho.
[20:54:15] <Gurkenglas> ah, so they do get money for producing things, but the government takes exactly as much money as you *would* make if you did your best?
[20:54:27] <feep> Gurkenglas: nono, the point is, like
[20:54:36] <feep> you're mixing some things up here.
[20:54:50] <nshepperd> feep: your plan takes us further from post scarcity, not closer to it
[20:55:00] <kuudes> it feels to me that loaning money to another person and expecting to be able to project violence on them if they don't pay, violates NAP? does it not?
[20:55:16] <kuudes> can libertarians loan money and expect to retaliate if the debtor is unable to pay?
[20:55:29] <feep> in this optimal economy, the government would do nothing because every process would be perfectly efficient, in other words if someone tried to monopolize some aspect of the production they'd immediately be eaten by cheaper offerings of the same process
[20:55:47] <feep> again: this is a *limit*, not an actual feasible state of affairs. there's always leaks.
[20:55:55] <nshepperd> kuudes: no, obviously you agree to the loan being collected when you agree to it
[20:56:09] <gwern> PapuaHardyNet: what would you call the 'output layer' of a hopfield or a boltzmann machine?
[20:56:10] <nshepperd> people don't just loan money to other people against their will
[20:56:14] <feep> Gurkenglas: what I want to do though is suck out enough money that singularities are impossible.
[20:56:22] <feep> where a singularity is a process that "pays for itself".
[20:56:35] <kuudes> ah indeed, it is agreed people can voluntarily bound themselves to be killed or maimed in the future, as free persons?
[20:56:40] <kuudes> indeed, that solves it I suppose
[20:56:46] <Gurkenglas> feep, aka find a way to ask the market "would this pay for itself?" and then automatically tax it
[20:56:59] <feep> right
[20:57:11] <kuudes> I guess indeed you need to have values extra from just pure libertarianism to view debt as unethical
[20:57:15] <feep> or just "notice things paying for themselves" and then put the tax level at a point where they stop doing that
[20:57:20] <nshepperd> kuudes: yes it is a central precept of libertarianism that people are somehow able to agree to enforceable contracts
[20:57:49] <feep> Gurkenglas: again, note that I also believe in a UBI.
[20:58:11] <kuudes> thanks nshepperd
[20:58:45] <feep> so if you start with the premise that the inherent right of people to live is handled by the UBI, then any self-accumulating/boosting system effectively drains money from satisfying people's needs into a .. that's why I said it's a singularity, though attractor may also work
[20:59:19] <feep> and you can still save in this system, you just can't have a net-positive savings rate.
[20:59:23] <kuudes> can't you just fund the ubi with a linear tax on that things income?
[20:59:28] <nshepperd> that idea isn't real
[20:59:44] <feep> nshepperd: right, and there's no way to get to it.
[20:59:50] <feep> and any partial implementation would be horrible.
[20:59:57] <feep> I know all that :p
[21:00:18] <Gurkenglas> feep, what if someone needs a loan to start a business, but there are no banks to loan him money because you can't have more than 0% interest?
[21:00:21] <nshepperd> no i mean your idea that "singularities" exist that don't provide value
[21:00:30] <kuudes> I mean, if you tax all income at 60%, you can pay ubi so that everyone makes at least 60% of median income, can't you?
[21:00:46] <feep> Gurkenglas: you'd probably do the equivalent of a kickstarter
[21:01:02] <feep> again: you *can* save.
[21:01:34] <nshepperd> people sacrifice money in the present to buy things in the future because they actually genuinely value the thing in the future at more than the discount rate between now and then
[21:01:45] <feep> Gurkenglas: the idea of a "business" wouldn't really exist in this world. the people paying for the business - the common interest project, rather - would be, as in our world, people who really want the service to exist for its own sake
[21:02:27] <Gurkenglas> yeah, the someone needs the loan to buy a grill so he can provide sausage to the people
[21:02:36] <feep> basically the idea
[21:02:43] <feep> the people funding this would be sausage enthusiasts
[21:02:54] <Gurkenglas> including him, who makes nothing either way
[21:03:02] <feep> it's not that he makes nothing
[21:03:10] <feep> he makes sausage :p
[21:03:28] <Gurkenglas> and uses up raw meat, which adds up to net 0
[21:03:38] <feep> yeah but now the world has sausage in it~
[21:03:40] <feep> that's a good in itself~
[21:03:57] <feep> it's shall we say, "aesthetic value". that isn't taxed.
[21:04:11] <feep> preferential value?
[21:04:24] <feep> and again, note that the "everybody makes nothing" version is the limit state given an infinite population
[21:05:12] <feep> the goal here is to construct preference maximization out of a capitalist structure.
[21:06:27] <feep> hey, you know who would absolutely flourish in this world? elon musk.
[21:06:31] <feep> his patreon would be the thing of legends.
[21:07:07] <feep> anyway, enough dreaming~
[21:08:03] <Gurkenglas> so suppose someone sees an innovation that would increase global productivity by 10%. it could bootstrap itself up by paying for itself until everyone uses it, but your system notices the pays-for-itself property and stops the growth.
[21:08:44] <feep> if it stops the growth, it's set too tight.
[21:09:08] <feep> that said, the innovation should not be paying for itself, it should be funded by the people who benefit from it.
[21:09:17] <Gurkenglas> Okay, I see that I've head the order of limits the wrong way around in my head.
[21:09:21] <feep> like, who *will* benefit from it.
[21:09:43] <feep> the idea of a self-funding improvement is inherently based in our current singularity-based system
[21:10:16] <Gurkenglas> An innovation being funded by the people who benefit from it sounds like that group of people is a self-funding system.
[21:10:19] <feep> people who want it should get it because they want it, it shouldn't have to vampirize these people to fuel its ascension
[21:11:18] <Gurkenglas> you'd want an fai to do what people say and not what's good for them, and you want an economy to work the same way
[21:11:31] <feep> Gurkenglas: no because the group of people as a whole is also a sort of thing that my system stops the growth of
[21:11:33] <[itchyjunk]> Gurkenglas, churches notation?
[21:11:50] <feep> Gurkenglas: the only basis of value is individuals. 
[21:12:10] <feep> a singularity competes with individuals for justification of existence. that's why I want to destroy them.
[21:13:00] <Gurkenglas> [itchyjunk], no, this https://sketchtoy.com/70177974
[21:13:11] <feepbot> Sketch Toy: Draw sketches and share replays with friends! (A drawing application that lets you save and share replays of your work with friends.)
[21:13:39] <[itchyjunk]> right, just function composition
[21:13:42] <Gurkenglas> feep, but why would people fund something that benefits them if that gets them detected as a cancer and taxed
[21:14:37] <Gurkenglas> [itchyjunk], yeah, i wanted to make sure that your model has more detail than just "function from In to Out"
[21:14:45] <feep> Gurkenglas: I want to note that I find your reaction adorable
[21:15:05] <feep> Gurkenglas: the people will fund it because *they want the improvement for its own sake*.
[21:15:19] <feep> the sausage maker will fund it because it will *enable more sausage to exist in the world*.
[21:15:46] <feep> if more sausage is not a thing that the sausage maker values, then the improvement will not be funded, and this is Right and Proper.
[21:16:02] <[itchyjunk]> Gurkenglas, understood. for for input layer, the number of neuron depends on the dimension of my data?
[21:16:47] <[itchyjunk]> Say i wanted an ANN to be train on a XOR table, i would want 2 input neurons? since the data would look like (1,0),(0,1) etc
[21:16:53] <feep> Gurkenglas: the intuition here is really that "value flows from people" = "money flows from people"
[21:17:14] <feep> anyway brb store
[21:17:46] <Gurkenglas> [itchyjunk], the dots I drew represent an entire datum, which can consist of multiple real numbers
[21:18:30] <Gurkenglas> But yes, as far as I see a neuron would usually be a slot-where-a-number-goes, which number is recalculated for every input
[21:19:16] *** Quits: hellleshin (~talinck@108-225-123-172.lightspeed.cntmoh.sbcglobal.net) (Read error: Connection reset by peer)
[21:19:18] <Gurkenglas> (whereas a "parameter" is a number saved somewhere in a model, which is used to calculate the neuron contents)
[21:19:37] *** Joins: hellleshin (~talinck@108-225-123-172.lightspeed.cntmoh.sbcglobal.net)
[21:22:30] <Gurkenglas> feep, if there is a sequence (not circle!) of people each of which spends 1$ to make the next 2$s, is that detected as a self-funding system?
[21:27:31] <feepbot> <gwern> https://scholar.google.com/scholar_case?case=14859387596834387751&hl=en&lr=lang_en&as_sdt=20000006&as_vis=1&oi=scholaralrt&hist=yk1QMowAAAAJ:8485507778884620773:AAGBfm2WgcqK2BIYSC9uiWoPBFHunkuB4Q&html=&folt=kw that's a lot of modafinil
[21:27:32] <feepbot> United States v. Cullen, Dist. Court, SD New York 2021 - Google Scholar
[21:32:48] *** Quits: Kol (~Kol@d75-157-122-186.bchsia.telus.net) ()
[21:34:59] *** Joins: Fusxfaranto (~Fusxfaran@cpe-75-85-179-208.san.res.rr.com)
[21:41:08] <feepbot> <gwern> https://www.protocol.com/enterprise/ibm-lost-public-cloud what was the last thing IBM got right?
[21:41:08] <feepbot> How IBM Public Cloud struggled against AWS and Microsoft - Protocol — The people, power and politics of tech (Insiders say that marketing missteps and duplicated development processes meant IBM Cloud was doomed from the start, and eight years after it attempted to launch its own public cloud the  [snip])
[21:48:21] <feepbot> <gwern> https://www.sciencedirect.com/science/article/pii/S0092656621000519 signaling
[21:48:22] <feepbot> If giving money to the Red Cross increases well-being, does taking money from the Red Cross increase ill-being? – Evidence from three experiments - ScienceDirect
[22:05:29] <Obormot\Arcturus> https://twitter.com/freganmitts/status/1444019853497671691
[22:05:29] <|dbotdan> Megan Fritts (@freganmitts, 2021-10-01 19:22): ‘Just taught Nozick’s Experience Machine for the hundredth time. All but one student were immediately and unreservedly in favor of entering the machine for life. Never had that happen before, rather threw off my lesson plan!’
[22:10:43] *** Joins: galambo (galambo@user/galambo)
[22:11:44] <Obormot\Arcturus> https://www.datasecretslox.com/index.php/topic,4630.msg161921.html#new ... on this thread people are now discussing whether analogy questions on the SAT are racist/whatever; the infamous "regatta" question is of course the centerpiece of the argument
[22:11:57] <feepbot> educationrealist has lost a bit of confidence in the usefulness of tests
[22:12:11] <Obormot\Arcturus> But I knew "regatta" before I even knew English at all! Therefore the accusation is silly
[22:13:21] *** Quits: galambo__ (galambo@user/galambo) (Ping timeout: 265 seconds)
[22:18:49] <gwern> analogy are good tests, which therefore show racial differences, which are therefore racist
[22:19:08] <gwern> I assume no one has pointed out that for 'regatta' and other examples, blacks actually do better on them?
[22:26:29] <gwern> (at least in some cases, I recall jensen pointing out, demonstrating why you need actual data rather than furious handwaving about how something is 'obviously' biased)
[22:31:43] <capisce^> https://www.reddit.com/r/MapPorn/comments/pzhlhe/other_ways_of_saying_you_have_to_take_a_shit/
[22:31:56] <feepbot> Other ways of saying you have to take a shit : MapPorn (13,744 votes and 1,386 comments so far on Reddit)
[22:32:47] <Urchin[emacs]> capisce^: Croatian: going where kings go on foot
[22:33:03] <gwern> you'd have to too if you spent all that time on horse
[22:34:15] <gwern> strangling eels sounds very difficult. I suggest laxatives
[22:43:32] <rsaarelm> I have no idea what the three ones in Finland are supposed to be.
[22:43:54] <rsaarelm> "Grunting dark"?
[22:46:08] <ggreer> https://i.imgur.com/67pz6xk.jpg look at what they need to mimic a fraction of our power
[22:46:33] <ggreer> (I’m pretty sure that’s the plane they point at in that scene)
[22:48:23] <ggreer> This Air Force museum has 4 hangars full of aircraft. I spent 5 hours walking through it all
[22:49:08] <ggreer> If you’re ever in Dayton, check it out
[22:50:14] <kuudes> nice
[22:52:10] <quanticle> ggreer: Oh wow a YF-23
[22:52:15] <ggreer> They have a bunch of space capsules and prototype aircraft. Also a supersonic chimp ejection seat: https://i.imgur.com/FtsqmlM.jpg
[22:52:26] <quanticle> The plane that was so cool the US Air Force refused to have it built
[22:53:36] *** Joins: _inky (~inky_@46.36.119.235)
[22:53:37] <quanticle> "Too expensive" they said. "Unproven design" they said. "Not as maneuverable as a traditional fighter." Bah! Just admit it, Air Force, you looked at the Black Widow II and thought, "Nope, there is no way we're cool enough to fly this. Not yet."
[22:55:31] <ggreer> I always forget how huge some of these planes are. They’re basically buildings that fly
[23:09:18] <galambo> https://tv.apple.com/show/umc.cmc.5983fipzqbicvrve6jdfep4x3
[23:09:31] <feepbot> Foundation | Apple TV+ (Based on the award-winning novels by Isaac Asimov, Foundation chronicles a band of exiles on their monumental journey to save humanity and rebuild civ…)
[23:09:43] <quanticle> gwern: https://arstechnica.com/science/2021/09/understanding-neuromorphic-computing-and-why-intels-excited-about-it/ Looks like the efficiency gap between biology and silicon is being addressed
[23:09:55] <feepbot> Intel launches its next-generation neuromorphic processor—so, what’s that again? | Ars Technica (Intel's Loihi processors have electronics that behave a lot like neurons.)
[23:11:22] <quanticle> ggreer: https://www.thefirearmblog.com/blog/2021/06/08/jp-enterprises-jp-5-roller-delayed-blowback-9mm-carbines-now-available/ It's like a MP5 and an AR-15 had a baby
[23:11:34] <feepbot> JP Enterprises JP-5 Roller-Delayed Blowback 9mm Carbines Now Available -The Firearm Blog (After two years of development, the JP Enterprises JP-5 roller-delayed blowback 9mm carbine is now available for preorder. )
[23:12:26] <galambo> not sure if I asked this before, but why do people keep using ak47 when all these fancy guns are out there?
[23:12:41] <quanticle> Why do people still buy Toyotas when Ferraris exist?
[23:13:20] <quanticle> That 9mm carbine I just linked has a list price of $3,200
[23:13:41] <galambo> quanticle, so is it an ego thing?
[23:14:00] <galambo> people dont use ferraris in warzones
[23:14:00] <kuudes> ferraris don't drive that well in places where there are poor people and wars
[23:14:16] <quanticle> Well that rifle is designed for competition shooting, so yes, for the vast majority of people who buy it, it is an ego thing
[23:14:32] <quanticle> In the same way that the vast majority of people who buy Ferraris don't routinely take them to racetracks
[23:15:48] <galambo> but I mean professional car drivers usually drive race cars. so race cars are cool. professionals who go to war use ak47, which is readily available and cheap. so why dont people just use that?
[23:15:55] <galambo> its more authentic than that gun and cheaper
[23:20:02] <quanticle> Special forces troops generally don't use AK-47s, or even AK-74s.
[23:20:36] <quanticle> gwern, Obormot\Arcturus: https://i.imgur.com/sGynAwV.jpg <-- What fresh heresy is this?
[23:20:50] <kuudes> I wonder if they have switched here away from rk (ak-variant)?
[23:23:30] <rsaarelm> Oh huh, they rebooted ponies?
[23:23:50] <quanticle> I guess so
[23:23:55] <rsaarelm> Is the fandom still alive enough to be shouting angrily about this?
[23:24:12] <quanticle> But they must be pretty desperate to hype it if they're resorting to making Amazon boxes advertising for it
[23:24:36] <kuudes> ah, apparently here the special forces now use https://en.wikipedia.org/wiki/FN_SCAR
[23:24:47] <feepbot> The FN SCAR (Special Operations Forces Combat Assault Rifle) is a family of gas-operated (short-stroke gas piston) automatic rifles developed by Belgian manufacturer FN Herstal (FN) in 2004.
[23:24:59] <kuudes> which apparently can fire both m16 and ak47 bullets
[23:25:51] <rsaarelm> But it's just been a little while since the last pony cartoon... 11 years huh.
[23:25:58] <quanticle> It's got a replaceable barrel or something?
[23:28:05] <saturn2> "The initial solicitation indicated that the SCAR-H would also be capable of being chambered in the 7.62×39mm M43 Kalashnikov cartridge, as well as the 6.8×43mm Remington SPC cartridge, however, FN is not currently offering this configuration, and the models have likely been cancelled."
[23:28:26] <kuudes> yeah, it says that
[23:29:27] <Obormot\Arcturus> quanticle: Yeah I guess they rebooted ponies, and of course the new ones are boring and lame
[23:29:38] <Obormot\Arcturus> There isn't another Lauren Faust
[23:30:06] <kuudes> https://en.wikipedia.org/wiki/RK_95_TP
[23:30:17] <feepbot> The RK 95 TP, 'assault rifle 95 folding stock'), officially 7.62 RK 95 TP and commercially known as the M95, is a 7.
[23:30:43] <quanticle> Yes, well, apparently Hasbro regretted their (⌐■_■) Faustian bargain
[23:32:10] <saturn2> https://commons.m.wikimedia.org/wiki/File:United_States_Navy_SEALs_177.jpg what's that thing in front of his leg?
[23:32:21] <feepbot> File:United States Navy SEALs 177.jpg - Wikimedia Commons
[23:32:40] <quanticle> saturn2: Flippers, looks like
[23:32:48] <saturn2> oic
