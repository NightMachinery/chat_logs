[00:06:02] *** Quits: djapo (~archangel@user/djapo) (Ping timeout: 250 seconds)
[00:09:21] *** Joins: Tach (~Tach@user/tach)
[00:15:48] *** Joins: molt (~molt@79.140.150.21)
[00:28:37] *** Quits: jimmyb (~jimmyb@user/jimmyb) (Quit: The Lounge - https://thelounge.chat)
[00:41:17] *** Joins: jimmyb (~jimmyb@user/jimmyb)
[00:45:59] *** Quits: Haxxa (~Haxxa@122.199.46.17) (Read error: Connection reset by peer)
[00:49:06] *** Joins: Haxxa (~Haxxa@122.199.46.17)
[01:07:41] *** Joins: fedenix__ (~fedenix@gateway/tor-sasl/fedenix)
[01:10:18] *** Quits: fedenix_ (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[01:20:08] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 250 seconds)
[01:21:07] *** Joins: zakame (~zakame@user/zakame)
[01:23:37] *** Quits: blaklistd (~blaklistd@user/blaklistd) (Quit: ciao bella)
[01:26:19] *** Joins: blaklistd (~blaklistd@user/blaklistd)
[01:31:43] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 252 seconds)
[01:33:13] *** Joins: zakame (~zakame@user/zakame)
[01:34:14] *** Quits: DoofusCanadensis (~DoofusCan@2604:3d09:47c:f970:803b:ebc8:891d:8b3a) (Quit: So as you can see from this flowchSQUIRREL!!)
[01:35:42] *** Quits: Tach (~Tach@user/tach) (Quit: Tach)
[01:46:17] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 248 seconds)
[01:47:26] *** Quits: Gustavo6046 (~Gustavo60@user/gustavo6046) (Ping timeout: 250 seconds)
[01:47:32] *** Joins: zakame (~zakame@user/zakame)
[01:47:34] *** Joins: Gustavo6046_ (~Gustavo60@user/gustavo6046)
[01:47:54] *** Quits: aead (~aead@user/aead) (Quit: aead)
[01:49:49] *** Gustavo6046_ is now known as Gustavo6046
[01:49:52] *** Quits: vidbina (~vid@dynamic-078-055-018-150.78.55.pool.telefonica.de) (Ping timeout: 252 seconds)
[01:50:52] *** Joins: aead (~aead@user/aead)
[01:54:23] *** Joins: pvdp (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au)
[02:05:13] *** Quits: mickey (~user@user/mickey) (Quit: Ping timeout (120 seconds))
[02:05:37] *** Joins: mickey (~user@user/mickey)
[02:06:04] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 250 seconds)
[02:07:25] *** Joins: zakame (~zakame@user/zakame)
[02:12:40] *** Joins: djapo (~archangel@user/djapo)
[02:22:33] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 248 seconds)
[02:23:33] *** Joins: Tach (~Tach@user/tach)
[02:23:53] *** Joins: zakame (~zakame@user/zakame)
[02:29:02] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 250 seconds)
[02:29:31] <jmcantrell> When I run this script on the host, I'm able to ctrl-c out of it fine, but when I run it in a container, ctrl-c just restarts the loop and i have to hold the keys down before it exits. I'm running it with `docker run -it --rm <image> ./test-watch.sh`. Anyone know why it behaves like this? https://paste.rs/rUv
[02:30:47] *** Joins: zakame (~zakame@user/zakame)
[02:32:28] <jmcantrell> Ah. --init fixed it.
[02:37:39] *** Quits: TomTom (uid45892@id-45892.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[02:45:25] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 252 seconds)
[02:49:23] <njka> sup jmcantrell :)
[02:49:38] <jmcantrell> njka: hey :)
[02:54:40] *** Quits: SJrX (~sjr@S0106302303dfb018.vf.shawcable.net) (Ping timeout: 240 seconds)
[02:55:04] *** Quits: pycurious (~Adium@user/pycurious) (Quit: Leaving.)
[02:56:46] *** Quits: djapo (~archangel@user/djapo) (Ping timeout: 250 seconds)
[02:59:39] *** Joins: pycurious (~Adium@user/pycurious)
[03:03:00] *** Quits: fedenix__ (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[03:19:43] *** Quits: Cleverness (~clevernes@pool-108-54-152-186.nycmny.fios.verizon.net) (Quit: Leaving)
[03:20:32] *** Joins: SJrX (~sjr@S0106302303dfb018.vf.shawcable.net)
[03:32:44] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 250 seconds)
[03:33:54] *** Joins: zakame (~zakame@user/zakame)
[03:43:09] *** Quits: flynn (~mcbloch@user/flynn) (Read error: Connection reset by peer)
[03:43:30] *** Joins: flynn (~mcbloch@user/flynn)
[03:52:41] *** Quits: blaklistd (~blaklistd@user/blaklistd) (Ping timeout: 248 seconds)
[04:00:10] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 240 seconds)
[04:01:28] *** Joins: zakame (~zakame@user/zakame)
[04:04:40] *** Quits: ultima (~ultima@23.81.113.231) (Ping timeout: 240 seconds)
[04:06:01] *** Joins: Ryu945 (~Ryu945@104.129.24.147.adsl.inet-telecom.org)
[04:09:44] *** Joins: ultima (~ultima@23.81.113.230)
[04:11:25] *** Quits: ultima (~ultima@23.81.113.230) (Client Quit)
[04:12:00] *** Joins: ultima (~ultima@23.81.113.230)
[04:18:56] *** Quits: c10l (~c10l@89.34.167.207) (Read error: Connection reset by peer)
[04:21:16] *** Joins: c10l (~c10l@89.34.167.207)
[04:21:55] *** Quits: martums (~martums@user/martums) (Read error: Connection reset by peer)
[04:22:26] *** Joins: martums (~martums@user/martums)
[04:31:14] *** Quits: ultima (~ultima@23.81.113.230) (Ping timeout: 250 seconds)
[04:34:10] *** Quits: aead (~aead@user/aead) (Ping timeout: 240 seconds)
[04:47:30] *** Joins: aead (~aead@user/aead)
[04:52:40] *** Quits: aead (~aead@user/aead) (Ping timeout: 240 seconds)
[04:53:30] *** Joins: aead (~aead@user/aead)
[05:14:10] *** Joins: djapo (~archangel@user/djapo)
[05:18:38] *** Joins: PanickedKernel (~zero@77.247.181.212)
[05:20:03] <PanickedKernel> Hey all. I'm new to using docker and have installed it on a ubuntu 20.04 x64 host. On the host I also use vm's with kvm. Apparently docker does some bad stuff with iptables and it breaks networking for the vms. Where does docker store it's iptable rules? How can I change them? I don't see anything on google about this.
[05:25:02] <tabakhase> PanickedKernel if that host is a hypervisor... consider stuffing docker in a kvm as well...
[05:26:21] <tabakhase> (on actual fixes, one can iptables=false, but thats even more havoc on the other end tbh... - other "changing" is not rly a thing...)
[05:27:19] <PanickedKernel> tabakhase: This is a old desktop I'm using as a "sever". It runs ubuntu and freebsd in a kvm vm. I'm only using docker because a app I want to use recommends it. I'm not familiar with docker otherwise. You're saying make another kvm vm and run docker in that new vm?
[05:27:51] <PanickedKernel> tabakhase: I found this page and I think it might be what I want https://daniel.im/blog/2020-03-18_kvm-docker/
[05:29:01] <tabakhase> what app is that? if you havent touched docker before that smells like a "way above scope" thingy...
[05:30:32] <PanickedKernel> tabakhase: https://photoprism.app/
[05:30:35] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:30:41] <PanickedKernel> (self hosted google photos)
[05:33:44] *** Joins: n000g (~NRG@user/nrg)
[05:34:15] <PanickedKernel> Gotta test to see if the config change works across reboots. brb
[05:34:18] *** Quits: PanickedKernel (~zero@77.247.181.212) (Quit: PanickedKernel)
[05:34:26] *** Quits: nrg (~NRG@user/nrg) (Ping timeout: 268 seconds)
[05:36:32] *** Joins: jazzy (~jaziz@2600:380:4533:7020:c055:7f23:886:f4ac)
[05:38:59] *** Joins: kuler (~kulernil@gateway/tor-sasl/kuler)
[05:43:09] *** Joins: PanickedKernel (~zero@109.201.152.172)
[05:43:21] <PanickedKernel> Looks like that solved my issue. 
[05:43:40] <tabakhase> looks like its pretty much only docker yea... even there "Developers may skip this and move on to the Developer Guide" uses docker again :D with no further how-to on "you can create your own development environment based on our Dockerfile" - so manually plugging that out doesnt seem like the best idea :F
[05:44:40] <tabakhase> if its "just docker nat-setup breaking kvm" cheating that one extra iptables-rule back in may be just fine i guess - just make sure thing stay alive when restarting either of the two (dockerd/kvm)
[05:46:53] <PanickedKernel> tabakhase: Thanks for taking a look. It is kinda annoying HAVING to use docker just for this one thing. But it does work well... I have a pretty simple setup and it looks like the iptable rules from that blog post do what I want. The kvm vm's act as I want and the docker seems to work as expected as well.
[05:48:51] *** Joins: vlm (~vlm@user/vlm)
[05:53:21] <tabakhase> neato
[06:00:17] *** Quits: wibe (~wibe@213.159.81.4) (Quit: WeeChat 3.2)
[06:17:08] *** Quits: Ivyy (~Ivyy@2001:a61:135b:5001:1ee0:53a3:bb15:f50) (Remote host closed the connection)
[06:23:01] *** Joins: blaklistd (~blaklistd@user/blaklistd)
[06:24:46] *** Quits: djapo (~archangel@user/djapo) (Ping timeout: 250 seconds)
[06:28:49] *** Quits: Tach (~Tach@user/tach) (Quit: Tach)
[06:31:07] *** Joins: ultima (~ultima@23.81.113.231)
[06:39:55] *** Joins: kikijiki (~Thunderbi@user/kikijiki)
[06:43:01] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 252 seconds)
[06:43:09] *** Joins: keypushe- (keypusher@user/keypusher)
[06:46:22] *** keypushe- is now known as keypusher
[06:47:43] *** Quits: kikijiki (~Thunderbi@user/kikijiki) (Quit: kikijiki)
[06:57:42] *** Joins: kikijiki (~Thunderbi@user/kikijiki)
[07:04:56] *** Quits: kikijiki (~Thunderbi@user/kikijiki) (Quit: kikijiki)
[07:08:18] <pycurious> is anyone using packer here? 
[07:08:47] <pycurious> I'm wondering how to delete the ami that it creates in the cloud - easily preferably
[07:09:15] *** Joins: ryu__ (~Ryu945@107.150.22.75.adsl.inet-telecom.org)
[07:11:40] *** Quits: Ryu945 (~Ryu945@104.129.24.147.adsl.inet-telecom.org) (Ping timeout: 240 seconds)
[07:19:51] *** Quits: Brainium (~brainium@user/brainium) (Quit: Konversation terminated!)
[07:34:30] *** Quits: pycurious (~Adium@user/pycurious) (Quit: Leaving.)
[07:43:05] *** Joins: grep_xtrange (~x@ac255238.ppp.asahi-net.or.jp)
[08:36:00] *** Quits: notsponsible (~notsponsi@45.144.113.89) (Quit: notsponsible)
[08:36:52] *** Quits: Lyn (~Lyn@user/law) (Ping timeout: 252 seconds)
[08:43:31] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[08:44:03] *** Quits: HankHill (~aleph@pool-98-116-232-112.nycmny.fios.verizon.net) (Ping timeout: 276 seconds)
[08:44:35] *** Joins: notsponsible (~notsponsi@45.144.113.89)
[08:45:18] *** Joins: djapo (~archangel@user/djapo)
[08:45:30] *** Joins: msk (~msk@49.207.198.25)
[08:47:12] *** Joins: HankHill (~aleph@pool-98-116-232-112.nycmny.fios.verizon.net)
[08:47:14] *** Joins: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org)
[08:49:30] *** Quits: ryu__ (~Ryu945@107.150.22.75.adsl.inet-telecom.org) (Ping timeout: 250 seconds)
[08:56:45] *** Joins: ryu__ (~Ryu945@173.44.49.91.adsl.inet-telecom.org)
[08:59:25] *** Quits: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org) (Ping timeout: 252 seconds)
[09:01:38] *** Quits: ryu__ (~Ryu945@173.44.49.91.adsl.inet-telecom.org) (Ping timeout: 250 seconds)
[09:02:00] *** Joins: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org)
[09:12:15] *** Joins: ryu__ (~Ryu945@104.129.24.147.adsl.inet-telecom.org)
[09:14:40] *** Joins: jkovac16 (~jkovac1@user/jkovac1)
[09:14:49] *** Quits: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org) (Ping timeout: 252 seconds)
[09:15:37] *** Quits: dlam (~dlam@dlam.me) (*.net *.split)
[09:15:37] *** Quits: dostoyevsky2 (~sck@user/dostoyevsky2) (*.net *.split)
[09:15:37] *** Quits: mikeputnam (~mikeputna@wilug/mikeputnam) (*.net *.split)
[09:15:37] *** Quits: mjh4386 (~mjh4386@165.22.53.231) (*.net *.split)
[09:15:37] *** Quits: Anarchic (~Anarchic@getlegit.co.uk) (*.net *.split)
[09:15:37] *** Quits: dreamer (~dreamer@user/dreamer) (*.net *.split)
[09:15:37] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (*.net *.split)
[09:15:37] *** Quits: effprime (~effprime@user/effprime) (*.net *.split)
[09:15:37] *** Quits: glider (~glider@user/glider) (*.net *.split)
[09:15:37] *** Quits: matthewcroughan (~quassel@static.211.38.12.49.clients.your-server.de) (*.net *.split)
[09:15:37] *** Quits: dmvrtx (dmvrtx@2a01:7e01::f03c:92ff:fefd:6ed6) (*.net *.split)
[09:15:37] *** Quits: tardisx (~tardisx@2400:8902::f03c:91ff:fe89:d107) (*.net *.split)
[09:15:38] *** Joins: dostoyev1ky2 (~sck@user/dostoyevsky2)
[09:15:41] *** Joins: Anarchic` (~Anarchic@getlegit.co.uk)
[09:15:45] *** Joins: glider_ (~glider@user/glider)
[09:15:45] *** Joins: d3daim (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[09:15:46] *** Joins: mjh4386_ (~mjh4386@165.22.53.231)
[09:15:57] *** Joins: effprime_ (~effprime@user/effprime)
[09:15:59] *** Joins: matthewcroughan (~quassel@static.211.38.12.49.clients.your-server.de)
[09:16:06] *** Joins: dlam1 (~dlam@dlam.me)
[09:16:31] *** Joins: mikeputnam (~mikeputna@wilug/mikeputnam)
[09:16:57] *** Quits: jkovac1 (~jkovac1@user/jkovac1) (Ping timeout: 248 seconds)
[09:16:57] *** jkovac16 is now known as jkovac1
[09:18:50] *** Quits: Helikoptere (~Helikopte@infracloud.lcnaud.fr) (*.net *.split)
[09:18:50] *** Quits: Pokey (~pokey@spikeyCactus/hoosky) (*.net *.split)
[09:18:50] *** Quits: calaz (~calaz@user/calaz) (*.net *.split)
[09:18:50] *** Quits: phenom (~primus@user/phenom) (*.net *.split)
[09:18:50] *** Quits: thekingofbandit (thekingofb@user/thekingofbandit) (*.net *.split)
[09:18:50] *** Quits: jstoker (~jstoker@user/jstoker) (*.net *.split)
[09:18:50] *** Quits: bastelfreak (~bastelfre@basteles-bastelknecht.bastelfreak.org) (*.net *.split)
[09:18:50] *** Quits: Byteflux (~byte@byteflux.net) (*.net *.split)
[09:18:50] *** Quits: tianon (~tianon@user/tianon) (*.net *.split)
[09:18:50] *** Quits: seth (sid18070@user/washclof) (*.net *.split)
[09:18:50] *** Quits: Riviera (Riviera@user/riviera) (*.net *.split)
[09:18:50] *** Quits: Koopz (~Koopz@koopz.rocks) (*.net *.split)
[09:18:50] *** Quits: naos (~naos@user/naos) (*.net *.split)
[09:18:50] *** Quits: agrajag (~agrajag@user/agrajag) (*.net *.split)
[09:18:58] *** Joins: Riviera_ (Riviera@user/riviera)
[09:19:11] *** Joins: jstoker_ (~jstoker@user/jstoker)
[09:19:19] *** Joins: Bitflux (~byte@byteflux.net)
[09:19:29] *** Joins: agrajag- (~agrajag@user/agrajag)
[09:19:30] *** Joins: Pokey (~pokey@spikeyCactus/hoosky)
[09:19:31] *** jstoker_ is now known as jstoker
[09:19:33] *** Joins: Koopzington (~Koopz@koopz.rocks)
[09:19:51] *** Joins: tianon (~tianon@user/tianon)
[09:19:51] *** Joins: calaz (~calaz@user/calaz)
[09:19:54] *** Joins: phenom (~primus@user/phenom)
[09:20:03] *** Joins: thekingofbandit (thekingofb@user/thekingofbandit)
[09:20:05] *** Joins: seth (sid18070@user/washclof)
[09:21:02] *** Joins: naos (~naos@user/naos)
[09:25:24] *** Quits: ryu__ (~Ryu945@104.129.24.147.adsl.inet-telecom.org) (Quit: Leaving)
[09:41:33] *** Joins: mei (~mei@user/mei)
[09:47:52] *** Joins: kikijiki (~Thunderbi@user/kikijiki)
[09:48:07] *** Joins: kulernil (~kulernil@gateway/tor-sasl/kuler)
[09:50:03] *** Quits: kuler (~kulernil@gateway/tor-sasl/kuler) (Remote host closed the connection)
[10:00:08] *** Quits: bouncy (~ben@user/benoit) (Ping timeout: 250 seconds)
[10:14:28] *** Koopzington is now known as Koopz
[10:25:09] *** Joins: carl- (~carl-@c-138ee555.02-180-73746f39.bbcust.telenor.se)
[10:26:48] *** Quits: carl- (~carl-@c-138ee555.02-180-73746f39.bbcust.telenor.se) (Read error: Connection reset by peer)
[10:27:09] *** Joins: carl- (~carl-@c-138ee555.02-180-73746f39.bbcust.telenor.se)
[10:31:16] *** Quits: codebam (~codebam@user/codebam) (Ping timeout: 252 seconds)
[10:31:48] *** Joins: manin (~X@185.242.190.95)
[10:32:53] *** Joins: codebam (~codebam@user/codebam)
[10:33:13] *** Quits: kulernil (~kulernil@gateway/tor-sasl/kuler) (Remote host closed the connection)
[10:33:35] *** Joins: kulernil (~kulernil@gateway/tor-sasl/kuler)
[10:40:26] *** Quits: djapo (~archangel@user/djapo) (Ping timeout: 250 seconds)
[10:40:54] *** Quits: alcohol (~rob@composer/alcohol) (Quit: WeeChat 3.2)
[10:42:46] *** Joins: kijotex (~oscard@91.116.34.215)
[10:49:36] *** Joins: lemonzest (~lemonzest@user/lemonzest)
[10:53:52] *** Quits: Haxxa (~Haxxa@122.199.46.17) (Ping timeout: 250 seconds)
[10:56:04] *** Joins: Haxxa (~Haxxa@122.199.46.17)
[10:57:04] *** Joins: paulman (~kulernil@gateway/tor-sasl/kuler)
[10:59:11] *** Quits: kulernil (~kulernil@gateway/tor-sasl/kuler) (Remote host closed the connection)
[11:00:04] *** Joins: djapo (~archangel@user/djapo)
[11:06:07] *** Quits: codebam (~codebam@user/codebam) (Ping timeout: 240 seconds)
[11:07:48] *** Joins: codebam (~codebam@user/codebam)
[11:10:17] *** Joins: AnapodoPsalidaki (~AnapodoPs@2a02:587:2910:6a35:d5b6:1cec:7da8:af3e)
[11:16:10] *** Quits: jazzy (~jaziz@2600:380:4533:7020:c055:7f23:886:f4ac) (Ping timeout: 240 seconds)
[11:26:27] *** Quits: djapo (~archangel@user/djapo) (Ping timeout: 240 seconds)
[11:30:47] *** Quits: codebam (~codebam@user/codebam) (Ping timeout: 240 seconds)
[11:31:36] *** Joins: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[11:32:41] *** Quits: notsponsible (~notsponsi@45.144.113.89) (Quit: notsponsible)
[11:34:19] *** Joins: night_wulfe__ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[11:34:31] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 252 seconds)
[11:36:40] *** Joins: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[11:37:49] *** Quits: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 252 seconds)
[11:39:47] *** Quits: night_wulfe__ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 240 seconds)
[11:43:48] *** Joins: bastelfreak (~bastelfre@basteles-bastelknecht.bastelfreak.org)
[11:44:58] *** Quits: manin (~X@185.242.190.95) (Ping timeout: 252 seconds)
[11:49:16] *** Joins: notsponsible (~notsponsi@45.144.113.89)
[11:53:54] *** Joins: lithium (~lithium@user/lithium)
[11:53:59] *** Joins: dingen (~dreamer@user/dreamer)
[11:54:02] *** dingen is now known as dreamer
[11:57:12] *** Joins: onizu (uid373383@id-373383.highgate.irccloud.com)
[12:01:40] *** Joins: manin (~X@185.242.190.95)
[12:01:40] *** Quits: Atque (~Atque@user/atque) (Ping timeout: 240 seconds)
[12:03:21] *** Joins: wibe (~wibe@213.159.81.4)
[12:04:18] <wibe> how can i run unshared during docker build? i suspect that the default seccomp options enforced during build prevent unshared from running
[12:04:41] <wibe> error: "unshare (Operation not permitted)"
[12:19:15] *** Joins: bouncy (~ben@user/benoit)
[12:32:07] *** Quits: qilx (~quassel@dynamic-109-81-210-86.ipv4.broadband.iol.cz) (Ping timeout: 245 seconds)
[12:33:17] *** Joins: qilx (~quassel@62.201.21.8)
[12:35:12] *** Joins: fibsifan (~quassel@dynamic-089-014-030-171.89.14.pool.telefonica.de)
[12:38:42] *** Quits: samuelbernardo (~samuelber@nata02.lip.pt) (Quit: ZNC 1.8.2 - https://znc.in)
[12:39:14] *** Joins: The_Loko (~The_Loko@79.116.18.231)
[12:54:02] *** Joins: sincorchetes (~sincorche@2.red-79-146-41.dynamicip.rima-tde.net)
[12:54:05] <sincorchetes> Hello all
[12:56:35] <sincorchetes> I want to create a pg container mounted binding custom directory.  For example: docker build -t custom_image . && docker run -d -v "$(pwd)":/database custom_image -- I have a script to create psql database with:  su - postgres -c "pg_ctl init -D /var/lib/pgsql/"--- But I have a permisson denied. If I run touch example, file is created because this task is made by root.
[12:57:16] <sincorchetes> I think user postgres cannot write into my custom directory mounted as bind resource
[12:57:48] *** Quits: artok (~azo@mobile-access-bcee5a-71.dhcp.inet.fi) (Ping timeout: 250 seconds)
[12:59:57] <sincorchetes> I have to set chown perms into directory before run pg_ctl init to work
[13:00:03] <sincorchetes> solved
[13:02:41] <sincorchetes> Although is not very recommended to run a container with the root user. But, How I can do this as postgres user, so?
[13:20:57] *** Quits: Cameron (~Cameron@user/cameron) (Remote host closed the connection)
[13:21:09] *** Joins: samuelbernardo (~samuelber@nata01.lip.pt)
[13:22:52] *** Quits: manin (~X@185.242.190.95) (Ping timeout: 252 seconds)
[13:27:27] *** Joins: artok (~azo@mobile-access-bcee5a-71.dhcp.inet.fi)
[13:27:52] *** Joins: manin (~X@185.242.190.95)
[13:33:07] *** Quits: artok (~azo@mobile-access-bcee5a-71.dhcp.inet.fi) (Ping timeout: 240 seconds)
[13:33:43] *** Joins: Helikoptere (~Helikopte@infracloud.lcnaud.fr)
[13:38:17] *** Joins: mjbatty (~mjbatty@82.2.17.205)
[13:38:48] *** Quits: Proxysna (~Proxysna@62.119.254.142) (Remote host closed the connection)
[13:46:49] *** Quits: jonifen (~jonifen@user/jonifen) (Ping timeout: 248 seconds)
[14:06:47] *** Joins: thiras (~thiras@user/thiras)
[14:14:10] *** Joins: TomTom (uid45892@id-45892.charlton.irccloud.com)
[14:18:26] *** Joins: ExeciN (~ExeciN@user/nicexe)
[14:22:53] *** Joins: rsx (~dummy@ppp-188-174-138-96.dynamic.mnet-online.de)
[14:25:14] *** Joins: jazzy (~jaziz@2600:380:8773:c113:1093:1c01:217f:efb2)
[14:32:37] *** Joins: Proxysna (~Proxysna@62.119.254.142)
[14:44:19] *** Joins: Atque (~Atque@user/atque)
[14:53:37] *** Quits: sincorchetes (~sincorche@2.red-79-146-41.dynamicip.rima-tde.net) (Quit: Konversation terminated!)
[14:53:43] *** Joins: artok (~azo@mobile-access-bcee5a-71.dhcp.inet.fi)
[15:05:28] *** Quits: nvmd (~nvmd@user/nvmd) (Ping timeout: 268 seconds)
[15:06:07] *** Quits: CombatVet (~c4@user/combatvet) (Remote host closed the connection)
[15:06:43] *** Joins: CombatVet (~c4@user/combatvet)
[15:14:17] *** Joins: Cameron (~Cameron@user/cameron)
[15:25:55] *** Joins: vidbina (~vid@dynamic-077-011-021-244.77.11.pool.telefonica.de)
[15:29:57] *** Joins: rewrit3 (~rewrit3@user/rewrit3)
[15:34:48] *** Quits: samuelbernardo (~samuelber@nata01.lip.pt) (Quit: ZNC 1.8.2 - https://znc.in)
[15:39:07] *** Joins: samuelbernardo (~samuelber@nata01.lip.pt)
[15:40:45] *** Joins: IceMichael (~IceMichae@2a0d:5940:6:163::ad7e)
[15:40:47] <IceMichael> hi
[15:40:54] <IceMichael> does anyone here use Docker together with C++?
[15:42:51] <artok> using api?
[15:43:13] *** Parts: patstoms (~patstoms@tzt.lv) (Leaving)
[15:44:04] <IceMichael> not necessarily, but why not
[15:44:28] <IceMichael> actually wondering if docker is a good choice if we don't expose some C++ service via a network api
[15:44:53] <IceMichael> more interested in some nice use cases here. It's clear and nice for exposed web APIs, but also without it?
[15:45:03] <artok> sure
[15:45:22] <artok> docker is way to run software on a isolated environment
[15:45:49] <artok> so c++ there is kind of... funny thing to add
[15:46:19] <artok> controlling docker daemon from c++ program, then it would be specific
[15:47:36] <IceMichael> I see, makes sense to me
[15:49:55] *** Joins: andycooper (uid246432@id-246432.brockwell.irccloud.com)
[15:50:40] *** Joins: iomari891 (~iomari891@105.112.138.38)
[15:52:25] *** Joins: raTHiopA (raTHiopA@gateway/vpn/airvpn/rathiopa)
[16:04:35] <artok> time critical web applications are usually done with c++ and run on containers, if you were thinking of that
[16:08:17] *** Joins: minimal (~minimal@user/minimal)
[16:12:13] <IceMichael> artok, ah interesting. Which API tool do these usually ... use?
[16:12:19] <IceMichael> tool=framework
[16:13:53] *** Quits: qilx (~quassel@62.201.21.8) (Remote host closed the connection)
[16:19:02] *** Quits: c10l (~c10l@89.34.167.207) (Read error: Connection reset by peer)
[16:21:16] *** Joins: c10l (~c10l@89.34.167.207)
[16:22:16] *** Quits: raTHiopA (raTHiopA@gateway/vpn/airvpn/rathiopa) (Quit: WeeChat 3.1)
[16:24:29] <ExeciN> Hi people. I'm having some trouble with my Dockerfile where I try to cat 2 files into a new one and set that as my entrypoint. docker complains that what is supposed to be my entrypoint file does not exist
[16:24:33] <ExeciN> https://termbin.com/s7ez
[16:25:53] <ExeciN> ^ this is my Dockerfile, and this is what I get when I try to use my built image: docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: "/code/entrypoint.bash": stat /code/entrypoint.bash: no such file or directory: unknown.
[16:29:04] <ExeciN> what am I doing wrong?
[16:31:05] *** Quits: Cameron (~Cameron@user/cameron) (Remote host closed the connection)
[16:31:39] *** Joins: Cameron (~Cameron@user/cameron)
[16:32:22] *** Quits: Cameron (~Cameron@user/cameron) (Remote host closed the connection)
[16:33:50] *** Joins: Cameron (~Cameron@user/cameron)
[16:34:53] *** Quits: rewrit3 (~rewrit3@user/rewrit3) (Remote host closed the connection)
[16:36:25] *** Quits: Cameron (~Cameron@user/cameron) (Remote host closed the connection)
[16:37:16] *** Joins: Cameron (~Cameron@user/cameron)
[16:43:55] <akik> ExeciN: maybe try with: RUN cat /code/functions.bash /code/rules > /code/entrypoint.bash
[16:45:01] <ExeciN> akik: you mean without using an array of strings?
[16:45:38] <akik> ExeciN: yes. although now that i look at my own dockerfiles, i don't think i've used > ever
[16:50:32] <akik> one option could be: cat /code/functions.bash /code/rules | tee -a /code/entrypoint.bash
[16:50:40] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Ping timeout: 240 seconds)
[16:54:23] *** Joins: ses (uid38151@id-38151.stonehaven.irccloud.com)
[17:03:34] <ExeciN> I changed it to this https://termbin.com/omr7 still the same error
[17:03:36] *** Quits: derpadmin (~derpadmin@cloudbase2.200013.net) (Ping timeout: 258 seconds)
[17:04:07] *** Quits: vidbina (~vid@dynamic-077-011-021-244.77.11.pool.telefonica.de) (Ping timeout: 240 seconds)
[17:04:12] <tabakhase> on a first glance that seems fine... pls show the "actual commands you ran" (build as well a test)
[17:08:33] <ExeciN> this is how I'm building docker build -t venidifier:latest -t venidifier:$(date +%Y%m%d%H%M%S) .
[17:08:56] <ExeciN> this is how I try to run docker run --rm -t -i -v $(pwd):/code venidifier:latest
[17:09:49] <tabakhase> -v $(pwd):/code
[17:09:54] <tabakhase> there you go
[17:10:10] <tabakhase> bind-mount shaddows everything inside the container
[17:10:26] <ExeciN> oh, right
[17:16:37] *** Joins: nomike (~nomike31_@vpn.vie.paysafecorp.net)
[17:18:59] *** Quits: nomike (~nomike31_@vpn.vie.paysafecorp.net) (Client Quit)
[17:20:05] <ExeciN> thanks for the help
[17:26:52] <artok> IceMichael: what ever they need, k8s clusters keep things up
[17:27:05] *** Joins: hazmi35 (~Hazmi35@36.74.47.42)
[17:29:15] *** Quits: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net) (Quit: If dreams are like movies, then memories are films about ghosts.)
[17:32:08] <IceMichael> artok, I mean from C++ side to create the services
[17:33:29] *** Quits: TomTom (uid45892@id-45892.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[17:34:47] *** Joins: vidbina (~vid@dynamic-077-011-021-244.77.11.pool.telefonica.de)
[17:36:34] *** Quits: hazmi35 (~Hazmi35@36.74.47.42) (Quit: Konversation terminated!)
[17:43:27] *** Quits: pvdp (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au) (Remote host closed the connection)
[17:47:36] <artok> still stands, what ever is needed, usually boost.beast is good starting point for websockets, and it uses boost.asio 
[17:49:38] *** Quits: flynn (~mcbloch@user/flynn) (Read error: Connection reset by peer)
[17:50:00] *** Joins: flynn (~mcbloch@user/flynn)
[17:55:25] *** Joins: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net)
[17:58:35] *** Joins: DevAntoine (~DevAntoin@78.196.234.32)
[17:58:42] <DevAntoine> Hello
[17:58:53] *** Joins: liefer (~liefer@user/liefer)
[17:59:18] <DevAntoine> when running "docker-compose exec ash" is it possible to have a login shell without passing it the "-l" flag? 
[17:59:31] <DevAntoine> Like, is it possible to configure the default behavior of using a shell to be a login shell?
[18:01:10] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 240 seconds)
[18:08:50] <programmerq> DevAntoine▸ https://stackoverflow.com/a/43743532/4930423 tldr; set an env var called ENV=/etc/profile to get ash to source /etc/profile (just like a login shell would)
[18:12:28] *** Joins: TomTom (uid45892@id-45892.charlton.irccloud.com)
[18:14:12] <DevAntoine> programmerq: ty!
[18:14:43] <programmerq> https://unix.stackexchange.com/a/46856/237832 - this answer goes through a little more low level detail on how a shell can determine that it's a login shell. It looks like the thing launching the first process in an interactive session passes a - in the first argument to the process. I don't think docker has a way to do that. I'm curious now whether you could do it with runc directly. hmmm
[18:17:32] <DevAntoine> programmerq: already read that, very interesting!
[18:17:43] <DevAntoine> but regarding the first link you posted programmerq:
[18:17:44] <DevAntoine> > Gotcha: /etc/profile is normally meant to only be sourced once! So, I would advise that you don't source it and instead source a /root/.somercfile instead.
[18:17:51] <DevAntoine> So I'm not sure what should I do
[18:18:29] <programmerq> in my quick test with a busybox ash, my /etc/profile was not getting sourced at all unless I either passed ash -l or set ENV=/etc/profile
[18:18:35] <programmerq> so it would source exactly once.
[18:18:43] <programmerq> maybe it means for subshells?
[18:21:51] <programmerq> I wouldn't worry about it unless you run into a problem. I think you can work around that concern by putting 'unset ENV' at the bottom of the /etc/profile file
[18:22:09] <programmerq> that way any sub shells will just inherit the vars of the main shell instead of running through the entire /etc/profile again
[18:42:51] *** Quits: uzee (~uzee@86.36.37.198) (Quit: Leaving)
[18:43:22] *** Joins: uzee (~uzee@86.36.37.198)
[18:46:17] <programmerq> IceMichael▸ basically docker is a think that runs stuff. if your stuff is in c++ or c# or python or php it doesn't really matter to docker. it's just a fancy way to run a process that gets you repeatability and consistency and isolation from other stuff running on a given host.
[18:54:17] <IceMichael> programmerq, I get that, but I was thinking from a product/use-case perspective if it makes sense here
[18:55:06] <IceMichael> if you don't rely on external services, you oftentimes can also compile/link a library statically to have all dependencies in one file
[18:55:17] <IceMichael> it only works on one platform then but it's quite self-contained
[18:57:30] <programmerq> you can definitely ship a docker container that is just a single statically compiled binary. It's a somewhat common pattern.
[18:58:07] <programmerq> I have an old example in a gist showing that with a hello world type statically compiled binary, in fact.
[18:58:21] <IceMichael> and what is the use of the container then?
[18:58:31] <IceMichael> you could just ship the binary, could you not?
[19:00:40] <ada_> the container still provides isolation
[19:00:57] *** Quits: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net) (Ping timeout: 248 seconds)
[19:01:02] <programmerq> the advantage to containerizing is that you get an interface that isn't tied to whatever is running inside it. I can fire up pretty much any language/framework using the same container procedure. Additionally, I get the security benefits of docker-- it drops a ton of capabilities by default so even if you are able to switch to uid0, you can't mount filesystems or manage iptables rules. The network
[19:01:04] <programmerq> isolation stack is also handy because each container has its own virtual network device so you don't get process a b and c stepping on eachother because of port conflicts.
[19:02:55] <programmerq> plus if you ever need to add any dependencies (database, cache, queue, etc) you can drop those in as containers and it's pretty easy to manage everything a given project needs. For your no-external-dependency project, it may not be a big deal, but if you adopt the container approach overall, you get an ecosystem of pre-packaged repeatable dependencies that you can fire up with little hassle.
[19:03:19] <programmerq> additionally, if you containerize, you can use resource requests and limits to help schedule where workloads should or shouldn't run if you use a system like swarm or kubernetes.
[19:09:31] <IceMichael> programmerq, thank you! This is very useful knowledge, almost every message
[19:09:39] <IceMichael> just a question about one statement:
[19:09:53] <IceMichael> "the advantage to containerizing is that you get an interface that isn't tied to whatever is running inside it" - not sure I understand this one
[19:10:03] <IceMichael> or not almost, each one, sorry :)
[19:11:19] <artok> you can have static binary, interperted script, what ever inside, for user it is only the connections that matter
[19:12:08] <programmerq> for example, if I set out to deploy a rails app, I might need to learn capistrano. If I deploy a python framework, I might need to use fabric. If I run cakephp, I might need to manually copy a bunch of files around and hope I don't miss a step. If an image author properly containerizes any of these technologies, I'd always use the same set of container-specific tools instead of framework specific
[19:12:10] <programmerq> tools to deploy things.
[19:12:32] <programmerq> so I could end up deploying 6 different projects using 6 different tech/frameworks, and each one would all be deployed with 'docker-compose up -d'
[19:13:41] <artok> in some cases you'll get less dependency conflicts
[19:13:53] <programmerq> much of my career has been more sysadmin/devops/deploy than development, but I would have to put serious time into learning a new deploy strategy with every single dev group I'd work with. Even two groups using the same framework might use wildly different deploy strategies. But with docker being a fairly familiar interface, I really only need to know docker-compose, docker run, docker stack
[19:13:55] <programmerq> deploy, helm, and maybe one or two other container-specific patterns.
[19:14:07] <programmerq> and they all have a TON of overlap with eachother
[19:15:59] <artok> seems that nodejs and go are now really enjoying about containers because projects can hard-set versions on dependencies
[19:16:03] <programmerq> I just need to know what config files to feed the container, what env vars to set, and that's about that. no learning a new deploy tool per project.
[19:16:10] *** Quits: jazzy (~jaziz@2600:380:8773:c113:1093:1c01:217f:efb2) (Ping timeout: 240 seconds)
[19:22:57] <IceMichael> programmerq, thanks for clarifying, this indeed makes all sense
[19:23:22] <artok> dev environments, hmmm
[19:23:26] *** Joins: NeoCron (~NeoCron@45.158.175.19)
[19:27:44] *** Joins: jacktar (~whiteshad@gateway/tor-sasl/jacktar)
[19:33:32] *** Quits: minimal (~minimal@user/minimal) (Quit: Leaving)
[19:39:35] <artok> that is basically vscodeserver container?
[19:44:57] <IceMichael> for dev you might really have many libs etc. that are later integrated into the build
[19:45:18] <IceMichael> but they are then not running as a service, so you could also just use usual dep mgmt for them
[19:45:34] *** Quits: manin (~X@185.242.190.95) (Ping timeout: 250 seconds)
[19:45:56] <IceMichael> what only annoys me is that docker seems to have tons of overload, it really slows down my system and takes tons of resources, so it's not really lean
[19:46:01] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[19:46:15] *** Quits: kijotex (~oscard@91.116.34.215) (Quit: WeeChat 3.2)
[19:46:18] <artok> IceMichael: what is your system then?
[19:46:40] <IceMichael> macOS big sur with 16G RAM, i7 proc
[19:46:43] <IceMichael> or what you mean?
[19:47:07] <artok> just that
[19:47:29] <artok> on docker desktop, you have vm that runs small linux with dockerd
[19:47:58] <IceMichael> yeah and that's eating away many resources
[19:48:07] <artok> if you put that on linux host and use docker engine there, there is no vm and it is close to non-container run
[19:48:08] <IceMichael> so just having one binary seems to be leaner
[19:48:14] <IceMichael> ah 
[19:48:33] <IceMichael> on macos can I also use non-desktop docker, so engine like on linux?
[19:48:41] <artok> no
[19:48:45] <IceMichael> damnit
[19:48:49] <IceMichael> on win?
[19:48:58] *** Quits: aead (~aead@user/aead) (Ping timeout: 252 seconds)
[19:49:08] <artok> there are windows containers
[19:49:31] <artok> macos is mainly for you to develop stuff for linux containers
[19:49:57] <IceMichael> hmm ok
[19:50:09] <IceMichael> maybe I should get my rasppi up again for such stuff
[19:50:10] <artok> and using bind mounts, your system needs to do apple filesystem - linux filesystem conversions on the fly, so it will slow things down
[19:50:19] <IceMichael> okay, makes sense
[19:50:38] <IceMichael> hm, if I have multiple containers, it seems it could make sense to actually have a LIN VM and put the docker containers there
[19:50:40] <artok> hence, using named volumes improves your speed
[19:50:48] *** Joins: aead (~aead@user/aead)
[19:51:02] <IceMichael> or is this insanity?
[19:51:20] *** Joins: brooks45 (~bswinnert@containers.neptunenetworks.org)
[19:51:37] <artok> docker desktop already launches that linux vm
[19:52:50] <artok> sure, for swarm tests and so on you can use docker-machine to start virtualbox vm's and then join them into one cluster, but for simple container-container communications that is not needed
[19:53:32] <ada_> rasppi is not a "great" platform since it's arm based.  you'll have to find arm compatible versions of all your images
[19:53:39] <ada_> if you have a specific use case in mind, then yeah
[19:53:48] <ada_> but as a general purpose machine to run containers, I'd probably stick to x86
[19:54:08] <IceMichael> okay, makes sense
[19:54:11] <ada_> cheap VPS providers exist - EC2 free tier, GCP $300 intro credit
[19:54:18] <ada_> ovh
[19:54:21] <IceMichael> so, if I have docker desktop and 100 containers, it's probably be fine because there is only one VM started?
[19:54:32] <ada_> can't really say
[19:54:44] <artok> cat docker.logs | grep ada | grep 'use case' | wc -l        "millions"
[19:54:46] <IceMichael> I mean "fine" is probably unclear, but at least not 100 VMs?
[19:54:55] <ada_> im confused by that question
[19:56:23] <artok> 100 containers per node is big number anyway
[19:56:47] <artok> even on production environments
[19:56:54] <artok> (again, depends on the node ofcoz)
[19:57:34] <IceMichael> you mean, the use case is usually rather that you have one container and spread it to many nodes for scaling?
[19:58:03] <ada_> yes and no
[19:58:03] <IceMichael> hm, thinking about just getting some linux notebook, would be even better for developing then
[19:58:09] <ada_> there are some use cases where that makes sense
[19:58:17] <ada_> consider a message queue and worker model
[19:58:17] <artok> for developing, your mac is totally good
[19:58:26] <ada_> you might have a single message queue, but many workers so you can pop jobs in parallel/
[19:58:35] <ada_> the message queue backend might not be scaled, but the workers might be
[19:59:10] <artok> if ada uses many times "use case", I use: "draw your infrasturcture as a picture" =)
[19:59:22] *** Joins: nvmd (~nvmd@user/nvmd)
[19:59:39] *** Joins: codebam (~codebam@user/codebam)
[20:00:12] <IceMichael> ada_, makes sense
[20:00:49] *** Parts: emanuele6 (~emanuele6@user/emanuele6) (WeeChat 3.2)
[20:01:16] <artok> concept of service is the key here. service is unit that can be handled by many containers
[20:01:34] *** Quits: dostoyev1ky2 (~sck@user/dostoyevsky2) (Quit: leaving)
[20:01:46] *** Joins: dostoyevsky2 (~sck@user/dostoyevsky2)
[20:03:19] <artok> db service that has replication/sharding and whatnot going on, but you just call to service and infrastructure will loadbalance and do magic for you
[20:03:42] *** Joins: kijotex (~kijotex@91.116.34.215)
[20:06:16] <IceMichael> hmmm
[20:06:31] <IceMichael> yeah, was also thinking about that a lot. In many applications, DB stuff seems to be the main load
[20:06:49] <IceMichael> but containers will not help there because a service does not distribute the DB automatically
[20:07:00] <IceMichael> so, if some service does tons of calculations, I get it
[20:07:05] <IceMichael> but if not?
[20:07:15] *** Quits: mikkel (~mike@208.110.120.167) (Quit: leaving)
[20:07:30] <IceMichael> I mean, a service doing many IP requests could also make sense of course
[20:08:34] <ada_> containers can still help solve deployment and isolation problems
[20:08:49] <IceMichael> indeed, that's clear
[20:08:51] <ada_> it might not be feasible to deploy mysql into a container and say "scale me" since mysql requires some internal config to do replicated properly
[20:09:05] <IceMichael> hm hm yes
[20:09:07] <artok> on development environment, usually running that single db server container is enough, but if you need to real metrics of the system, you need to launch your services into staging environment that is 1:1 to production
[20:09:12] <ada_> but there are projects that build on top of "traditional" dbs like postgres and mysql to enable that
[20:09:27] <IceMichael> ah I see, cool!
[20:10:34] <artok> and then there is mongos for mongodb, postgresql has it's own...
[20:11:13] <IceMichael> crunch e.g. it seems
[20:11:20] <IceMichael> crunchy, no?
[20:11:25] <IceMichael> ok, has its own, I see, nice
[20:11:31] <artok> before doing those, it might be wise to check out prices of managed db services that many providers have
[20:11:47] <IceMichael> hm okay
[20:12:14] <IceMichael> another question because I suck all your knowledge in at the moment (thanks again for it :)): I read that there should be only one DB per microservice
[20:12:33] <IceMichael> but hm, not sure if this makes sense always. There might be complex DBs with many intertwined parts
[20:12:55] <IceMichael> and if you cover a really huge bunch, it's not really a "micro"service anymore I guess?
[20:13:07] <artok> there you go
[20:13:56] <artok> architecture/infrastructure design is big part of today's services
[20:16:55] <ada_> lets use concrete examples.  If I want to deploy wordpress, that's httpd, mysql, and some static code.  I'd probably run an httpd and mysql as separate containers, with a volume to hold my static content for WP.  If I want to then deploy a 2nd wordpress stack, I would deploy 2 more containers - another httpd and another mysql specific to that WP site.
[20:17:22] <ada_> this decouples their dependencies, so if I want to upgrade the DB version on stack 1, it doesn't affect stack 2 and cause an outage
[20:18:40] *** Quits: iomari891 (~iomari891@105.112.138.38) (Quit: WeeChat 3.0.1)
[20:19:18] <ada_> generally, 1 process per container, and each "application stack" should have its own containers for each component.  Don't share containers between different applications as a rule of thumb.
[20:21:07] <IceMichael> okay, makes sense. But not sure about my microservices question with DB? I mean, here you have two applications
[20:21:14] <IceMichael> but multiple microservices could still belong to one app?
[20:21:26] <artok> I have feeling that if I'd need to combine data from two different databases, I'd make service that would do just that
[20:23:26] <IceMichael> hm yeah, but classically I would anyway just have one big db
[20:23:29] <IceMichael> with many tables
[20:23:29] *** Quits: TomTom (uid45892@id-45892.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[20:23:47] <IceMichael> so not sure how to apply microservices on that, it does not seem to make sense
[20:24:11] <IceMichael> and splitting all the tables into multiple databases also does maybe not make sense because the connections might be manifold and I need to keep integrity
[20:26:28] <artok> it is just that when that one db goes down, goes all the services that are dependent on that too
[20:27:02] <artok> and if updating service needs some db migration, it will happen only on that particular db, others stay up and run happily
[20:27:26] <artok> (as ada already said)
[20:27:34] <ada_> a microservice is just a small piece of a large application
[20:28:04] <ada_> same logic applies
[20:28:43] *** Joins: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net)
[20:29:39] <ada_> you might have multiple databases as part of the application
[20:29:43] <ada_> thats fine
[20:29:53] <ada_> but when you go to deploy another Application, it should have its own containers
[20:30:17] <ada_> classically, yes, you might have had a giant DB server that held all the databases (each database with multiple tables) for all your applications
[20:30:27] *** Quits: Atque (~Atque@user/atque) (Quit: ...)
[20:30:32] <ada_> the change is that each database (which may have multiple tables) runs ins separate database containers
[20:31:30] *** Joins: vinay1 (~vinay@user/vinay-keshava)
[20:31:45] <IceMichael> hm yeah, we have much intertwined
[20:31:49] <IceMichael> so it's only one big database
[20:31:54] <IceMichael> not just one big db server
[20:32:25] <IceMichael> it simplifies the problem a bit, but for me this means that multiple microservices will operatore on the same DB
[20:32:58] *** Quits: coc0nut (~coc0nut@user/coc0nut) (Ping timeout: 252 seconds)
[20:33:38] <ada_> if they're part of the same Application, then yes
[20:33:38] *** Quits: andypandy (~andypandy@h-178-174-148-234.A163.priv.bahnhof.se) (Quit: Bye)
[20:33:44] <ada_> or maybe not, depending on your architecture
[20:34:12] <artok> listing of one pros: db server needs to do just that particular work and optimizations kick in
[20:34:28] <ada_> my app might do login/authorization/authentication via some web code and mongodb/rethinkdb to set session data.  my application might also involve postgres to hold accounts.
[20:34:37] <ada_> or inventory
[20:34:48] *** Quits: vinay1 (~vinay@user/vinay-keshava) (Client Quit)
[20:35:10] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 252 seconds)
[20:35:31] <ada_> and maybe moving to containers means that temporarily you run a big giant db server that talks to everything; until you refactor the pieces to run separately.
[20:35:41] <IceMichael> hm hm
[20:35:42] <ada_> this ^ is a common pattern with enterprises that are doing a lift and shift from traditional to containers
[20:36:04] <IceMichael> but still. If I have master data that is underlying for each part of the application (could be something like tenant), then it needs to be visible everywhere?
[20:36:23] <IceMichael> (and thanks for this enterprise pattern, might come in handy for us actually :) )
[20:36:30] <ada_> not sure what you mean by "visible everywher" but your db server has a TCP/UDP port that it listens on, and things could connect to it
[20:36:38] <ada_> that can be handled in the layout of your docker container networks
[20:36:57] <IceMichael> I mean, it sounded now like I would like to split my giant db server later horizontally
[20:37:04] <IceMichael> like some tables in one db, some tables in another
[20:37:04] <ada_> maybe temporarily your db server sits on multiple networks so it can serve different applications
[20:37:08] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[20:37:31] <IceMichael> but tenant_id could be a field for practically every table
[20:37:42] <IceMichael> so to have integrity, I cannot really move the tenant table out into another db, right?
[20:37:47] <ada_> database design is a whole other story
[20:38:33] <ada_> maybe you need to refactor your database into 3rd normal form
[20:39:04] <IceMichael> hm, but this seems perpendicular
[20:39:33] <IceMichael> I will still have keys in my table relating to other tables
[20:39:50] <IceMichael> and if all tables "depend" on the tenant, then how to split these?
[20:39:58] <IceMichael> maybe I have misconceptions in my head but then not sure where
[20:40:11] *** Joins: andypandy (~andypandy@h-178-174-148-234.A163.priv.bahnhof.se)
[20:42:10] *** Quits: ztx (~ztx@user/ztx) (Quit: ztx)
[20:42:18] <ada_> you have primary keys and foreign keys
[20:42:34] <ada_> primary keys track the index in the current table and foreign keys link the row to the primary keys in OTHER tables
[20:43:11] *** Quits: aead (~aead@user/aead) (Quit: aead)
[20:43:13] <IceMichael> sure sure
[20:43:17] <IceMichael> I know these basics
[20:43:32] <ada_> ok 
[20:43:35] <IceMichael> but these other tables can probably not live in another database in another container/node?
[20:43:40] <ada_> why would you do that
[20:43:50] <IceMichael> again as said:
[20:43:57] <IceMichael> say, you have 1000 tables, which would be mostly independent
[20:43:59] <ada_> ikf the tables are related, they go in the same database
[20:44:01] <IceMichael> but ALL of them have a tenant_id
[20:44:07] <IceMichael> okay, yes
[20:44:23] <IceMichael> because if I have multiple customers, they might use all the data but all the data might be only visible for them
[20:44:34] <IceMichael> so practically each table might need to have a tenant_id or customer_id
[20:44:41] <IceMichael> so all the tables would need to go into one big database
[20:44:47] <ada_> normalizing the table data isn't the same question as separating database concerns
[20:45:00] <ada_> so, yes, all the tables might go into the same database if they are related 
[20:45:28] <IceMichael> yeah... so nothing we can do here to have multiple databases
[20:45:39] <IceMichael> so the target "each microservice should only work on one db" would not work here
[20:45:46] <IceMichael> or maybe is a stupid target in this case simply
[20:46:11] <ada_> im not saying each microservice should have one db
[20:46:16] <ada_> I'm talking about Application architecture
[20:46:25] <IceMichael> yeah, I just read that up and tried to verify/falsify it here with some pros like you :)
[20:46:34] <IceMichael> sorry if I mix up topics too much
[20:46:35] <artok> remembering that single db server can have multiple databases, single database can have multiple tables, but in microarchitecture design single server(cluster) will be populated with single database with multiple tables
[20:46:36] <ada_> and I'm not sayting that each application should have only one db either
[20:46:58] <artok> all depends on use case =)
[20:47:28] <IceMichael> artok, hm my day might be too long now, but not sure how this relates to my example with customer_id?
[20:48:02] <artok> just keeping concepts clear here 
[20:48:17] *** Quits: NeoCron (~NeoCron@45.158.175.19) (Remote host closed the connection)
[20:49:04] <IceMichael> okay, so it could be a fine design to have microservices that all operate on the same db apparently, thanks for clarification :)
[20:50:27] <artok> just check metrics that server will handle all requests and be prepared to scale horizontally when needed
[20:50:46] *** Joins: aead (~aead@user/aead)
[20:50:46] *** Quits: aead (~aead@user/aead) (Client Quit)
[20:50:54] *** Quits: dabbill (~dabbill@174.31.235.146) (Quit: ZNC - https://znc.in)
[20:52:13] *** Joins: aead (~aead@user/aead)
[20:52:18] *** Quits: betelgeuse (~betelgeus@94-225-47-8.access.telenet.be) (Ping timeout: 250 seconds)
[20:53:03] *** Quits: AnapodoPsalidaki (~AnapodoPs@2a02:587:2910:6a35:d5b6:1cec:7da8:af3e) (Quit: Leaving)
[20:55:20] <IceMichael> hm, so requests are more of a bottleneck than DB or what do you mean?
[20:55:35] <IceMichael> I also see that it seems that requests are what makes scaling necessary apparently
[20:55:41] <IceMichael> are requests so inefficient?
[20:55:55] <ada_> no, thats not the assertion
[20:56:03] <ada_> just saying "monitor your db performance and adjust as necessary"
[20:56:20] <IceMichael> okay, but scaling of nodes per se is needed because of slow requests oftentimes?
[20:56:28] <ada_> maybe?
[20:56:45] <ada_> but nginx can serve like millions of requests so this takes performance testing to determine if it's actually a problem
[20:56:49] *** Quits: andypandy (~andypandy@h-178-174-148-234.A163.priv.bahnhof.se) (Quit: Bye)
[20:57:13] <ada_> and each web request might not result in a db hit
[20:57:17] <ada_> maybe you have caching 
[20:57:29] <ada_> maybe you have some expensive requests and some inexpensive ones (in terms of cpu time)
[20:59:11] *** Joins: andypandy (~andypandy@h-178-174-148-234.A163.priv.bahnhof.se)
[20:59:47] <ada_> scaling the "web tier" is a pretty common use case though
[21:01:11] <artok> rough example: splitting up data like authentication (sql), accounting data(sql) and blog posts(nosql) would keep authentication and billing system working while conspiracy theory people keep posting their stuff and nosql is getting loaded =)
[21:02:32] *** Joins: TomTom (uid45892@id-45892.charlton.irccloud.com)
[21:02:59] <artok> then you just need to scale the nosql as two other db are doing fine
[21:03:08] *** Quits: DevAntoine (~DevAntoin@78.196.234.32) (Remote host closed the connection)
[21:04:15] <IceMichael> artok, not sure here, because auth needs to be done all the time. And another service needs to know that auth worked out
[21:04:29] <IceMichael> or is it like any service will "internally" first forward to auth service?
[21:04:40] <artok> session data is the key
[21:04:45] <IceMichael> ada_, hm but THEN why is web tier scaling a thing?
[21:04:49] <ada_> yes, service might have to forward to auth
[21:04:52] <ada_> get a success back
[21:04:54] <ada_> and then do something with it
[21:05:11] <IceMichael> ok, clear on that :)
[21:05:33] <IceMichael> ada_, ok then still question why web scaling is one of the most common use cases
[21:05:38] <IceMichael> if one service is actually strong enough
[21:05:43] <ada_> im not saying its the most common use case
[21:05:51] <ada_> if one service is enough, then great
[21:05:58] <ada_> it is A common use case
[21:06:05] <IceMichael> are there more common ones?
[21:06:14] <ada_> im not sure how to quantify that
[21:06:17] <ada_> its apples and oranges
[21:06:30] <IceMichael> okay, also fine
[21:06:38] <ada_> is it common for a business to have 2 different web servers in different regions for locality? yes
[21:06:44] <ada_> could this be extended to contaienrs? yes
[21:06:55] <ada_> is it common for a biz org to have several web servers for high availability? also yes
[21:07:01] <ada_> can this be extended to containers? yes
[21:07:08] <IceMichael> but if they access the same database that is at one place, it does not make sense hm
[21:07:15] <ada_> why not
[21:07:16] <IceMichael> unless database is also horizontally distributed of course
[21:07:25] <ada_> maybe it is
[21:07:30] <IceMichael> because database access is probably the bottleneck more than web requests?
[21:07:32] <ada_> maybe you end up using mysql replication across reqgions
[21:07:36] *** Quits: aead (~aead@user/aead) (Quit: aead)
[21:07:56] <ada_> I'm not going to say what probably is or isn't
[21:08:08] <ada_> it really depends on the app and your use case
[21:08:11] <IceMichael> okay, just thinking of a scenario where it makes sense
[21:08:12] *** Quits: dman777 (~dman777@76-253-74-225.lightspeed.austtx.sbcglobal.net) (Quit: Lost terminal)
[21:08:14] <ada_> there is not a golden rule here
[21:08:20] <IceMichael> but I need to run now. You already helped me a ton, thank you!
[21:08:26] <ada_> high availability is a use case that doesn't rely on performance
[21:08:35] <ada_> if you want HA, you want redundant entrypoints into your app
[21:08:41] <IceMichael> ah indeed
[21:08:52] <ada_> you might provide several web servers distributed so that one region outage in AWS doesn't take down your web server
[21:09:02] <ada_> that is a separate problem than "what if my db goes down"
[21:09:24] <ada_> if you want HA for your DB, then you have a different question;  maybe that can be served by mysql replication, or maybe you use a hot/cold backup strategy
[21:09:29] <ada_> or maybe you use filesystem snapshots
[21:09:48] <IceMichael> hm yes yes
[21:10:06] *** Joins: aead (~aead@user/aead)
[21:10:14] *** Joins: coc0nut (~coc0nut@user/coc0nut)
[21:10:50] *** Quits: coc0nut (~coc0nut@user/coc0nut) (Remote host closed the connection)
[21:11:49] *** Joins: coc0nut (~coc0nut@user/coc0nut)
[21:15:47] <ada_> IceMichael: https://12factor.net/ has some good rules of thumb for designing applications for distributed systems
[21:16:45] <IceMichael> thanks will have a look
[21:24:21] *** Joins: dabbill (~dabbill@174.31.235.146)
[21:26:07] <artok> + bunch of youtube talks
[21:26:43] *** Joins: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org)
[21:44:58] *** Quits: Trieste (T@user/pilgrim) (Ping timeout: 240 seconds)
[21:45:42] *** Joins: Trieste (T@user/pilgrim)
[21:47:13] *** Quits: aead (~aead@user/aead) (Ping timeout: 252 seconds)
[21:49:25] *** Joins: aead (~aead@user/aead)
[21:50:47] *** Quits: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net) (Ping timeout: 240 seconds)
[21:52:09] *** Quits: vidbina (~vid@dynamic-077-011-021-244.77.11.pool.telefonica.de) (Ping timeout: 248 seconds)
[22:01:27] *** Joins: fedenix (~fedenix@gateway/tor-sasl/fedenix)
[22:19:22] *** Quits: vxrx (~vxrx@proxy01.autarkic.org) (Quit: WeeChat 3.2)
[22:20:13] *** Joins: vidbina (~vid@dynamic-077-011-021-244.77.11.pool.telefonica.de)
[22:20:24] *** Joins: vxrx (~vxrx@proxy01.autarkic.org)
[22:26:06] *** Joins: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net)
[22:27:15] *** Quits: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net) (Read error: Connection reset by peer)
[22:28:24] *** Quits: rsx (~dummy@ppp-188-174-138-96.dynamic.mnet-online.de) (Quit: rsx)
[22:29:19] *** Joins: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net)
[22:30:55] *** Joins: ryu__ (~Ryu945@107.150.22.75.adsl.inet-telecom.org)
[22:33:07] *** Quits: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org) (Ping timeout: 240 seconds)
[22:35:27] *** Joins: goldfish (~goldfish@user/goldfish)
[22:40:47] *** Quits: carl- (~carl-@c-138ee555.02-180-73746f39.bbcust.telenor.se) (Ping timeout: 240 seconds)
[22:47:55] *** Joins: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org)
[22:50:17] *** Quits: ryu__ (~Ryu945@107.150.22.75.adsl.inet-telecom.org) (Ping timeout: 250 seconds)
[22:54:12] *** Joins: betelgeuse (~betelgeus@94-225-47-8.access.telenet.be)
[23:04:21] *** Joins: DoofusCanadensis (~DoofusCan@208.38.34.74)
[23:06:57] *** Quits: wibe (~wibe@213.159.81.4) (Quit: WeeChat 3.2)
[23:11:36] *** Joins: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469)
[23:11:38] *** Quits: DoofusCanadensis (~DoofusCan@208.38.34.74) (Quit: So as you can see from this flowchSQUIRREL!!)
[23:14:09] *** Joins: junktext (~junktext@109.201.152.169)
[23:27:40] *** Quits: ueberall (ueberall_l@user/ueberall) (Ping timeout: 240 seconds)
[23:27:49] *** Joins: m_ueberall (ueberall_l@user/ueberall)
[23:27:59] *** Quits: naos (~naos@user/naos) (Quit: -)
[23:28:07] *** Quits: lithium (~lithium@user/lithium) (Quit: Textual IRC Client: www.textualapp.com)
[23:29:43] *** Quits: junktext (~junktext@109.201.152.169) (Ping timeout: 250 seconds)
[23:32:06] *** m_ueberall is now known as ueberall
[23:33:20] *** Quits: fedenix (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[23:33:43] *** Joins: fedenix (~fedenix@gateway/tor-sasl/fedenix)
[23:37:27] *** Quits: mjbatty (~mjbatty@82.2.17.205) (Quit: Leaving)
[23:40:26] *** Joins: ryu__ (~Ryu945@107.150.22.75.adsl.inet-telecom.org)
[23:42:43] *** Quits: Ryu945 (~Ryu945@173.44.49.91.adsl.inet-telecom.org) (Ping timeout: 250 seconds)
[23:43:30] *** Quits: TomTom (uid45892@id-45892.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[23:44:29] *** Joins: naos (~naos@user/naos)
[23:44:53] *** Joins: DoofusCanadensis (~DoofusCan@2604:3d09:47c:f970:4082:25ec:2577:3a2f)
[23:59:53] *** Joins: wootehfoot (~wootehfoo@user/wootehfoot)
