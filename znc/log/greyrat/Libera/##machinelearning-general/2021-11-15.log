[00:01:10] *** Quits: georgios (~georgios@user/georgios) (Quit: Konversation terminated!)
[00:03:33] *** Quits: medium_cool (~medium_co@2605:a601:a9aa:f800:f1f8:4a6f:61d7:183) (Quit: My Mac Mini has gone to sleep. ZZZzzz…)
[00:26:52] <[itchyjunk]> https://cds.nyu.edu/deep-learning/
[00:26:53] <SigmoidFroid> ⇒  Yann LeCun’s Deep Learning Course at CDS – NYU Center for Data Science
[00:27:02] <[itchyjunk]> Unfortunately, i don't have the pre-req it seems. :)
[00:31:04] *** Joins: octav1a (~quassel@173.195.145.98)
[00:32:28] <octav1a> I'm trying to fully understand conv2d ; does anyone know of a pure python or other language implementation I could look at without all of the cuDNN or other optimizations?
[00:33:43] <[itchyjunk]> there are probably numpy implimentation of convs that might be close to what you want
[00:36:26] <octav1a> There is simple conv with a specified kern but there is not something with the options like kernsize, stride, padding like torch has that I would see.
[00:36:29] <octav1a> could see*
[00:38:01] *** Joins: jlrnick (~josephler@2a01cb040a1594007911975fbb5b9942.ipv6.abo.wanadoo.fr)
[00:49:55] *** Quits: hygl (uid16621@tinside.irccloud.com) (Quit: Connection closed for inactivity)
[01:29:54] *** Quits: jlrnick (~josephler@2a01cb040a1594007911975fbb5b9942.ipv6.abo.wanadoo.fr) (Ping timeout: 268 seconds)
[01:33:33] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[01:50:34] *** Quits: manti7 (~manti7@176.10.104.94) (Quit: WeeChat 3.3)
[01:51:38] *** Joins: Karel_ (~Karel@d51A4910F.access.telenet.be)
[01:51:38] *** Karel is now known as Guest9253
[01:51:38] *** Karel_ is now known as Karel
[01:56:35] *** Joins: marcello42 (~mp@p200300dfaf07ff01fa2e52f98b4dfc80.dip0.t-ipconnect.de)
[02:24:12] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[02:50:08] *** Joins: mefistof1les (~mefistofe@user/mefistofeles)
[02:58:42] *** Joins: tomeaton17 (~tomeaton1@51.195.150.49)
[02:59:19] *** Quits: Karel (~Karel@d51A4910F.access.telenet.be) (Quit: Leaving)
[03:11:23] *** Quits: marcello42 (~mp@p200300dfaf07ff01fa2e52f98b4dfc80.dip0.t-ipconnect.de) (Quit: WeeChat 3.3)
[03:30:52] *** Joins: tomeaton1779 (~tomeaton1@92.234.2.175)
[03:32:39] <tomeaton1779> so apparently boston house price data set has ethical issues, they "engineered a non-invertible variable “B” assuming that racial self-segregation had a positive impact on house prices"
[03:34:06] *** Quits: tomeaton17 (~tomeaton1@51.195.150.49) (Ping timeout: 256 seconds)
[03:35:38] *** Quits: Guest9253 (~Karel@d51A4910F.access.telenet.be) (Ping timeout: 260 seconds)
[03:35:45] *** tomeaton1779 is now known as tomeaton17
[03:38:25] <mefistof1les> tomeaton17: where do you get that from? (hopefully no the boston housing toy dataset that's included in many software packages)
[03:38:58] <tomeaton17> mefistof1les I was reading the sklearn docs here https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#rec2f484fdebe-2
[03:38:58] <SigmoidFroid> ⇒  sklearn.datasets.load_boston — scikit-learn 1.0.1 documentation
[03:39:42] <tomeaton17> the paper for the data set is here https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air/link/5c38ce85458515a4c71e3a64/download on page 17 they talk about variable "B"
[03:39:43] <SigmoidFroid> ⇒  (: No title)
[03:40:02] <HuntsMan> mefistof1les: scikit learn is removing that dataset
[03:40:23] <mefistof1les> I see, hopefully for the right reasons
[03:40:34] <mefistof1les> I mean, correlation is not causation
[03:40:56] <mefistof1les> and it's pretty clear that the african american population live in the worse areas in many cities in the US, specially in the north
[03:43:11] <tomeaton17> According to scikit learn "did not give adequate demonstration of the validity of this assumption."
[03:43:18] <HuntsMan> they have an alternative, a dataset in california, very similar one
[03:43:47] <tomeaton17> They don't give validation for the assumption of other variables either which are unrelated to race
[03:45:59] <mefistof1les> ok, well, hiding the issue doesn't solve it, but if there are already better alternatives I guess it's the right move
[03:48:22] *** Joins: medium_cool (~medium_co@2605:a601:a9aa:f800:2178:42cf:7342:ed4a)
[03:48:44] <HuntsMan> the big problem is that I am sure some people used the dataset for some real world application (even if its not meant for that and its a toy dataset)
[03:49:49] *** Joins: akevinhuang2 (~thekevinh@user/thekevinhuang)
[03:50:33] <mefistof1les> HuntsMan: I don't think that's the problem, that can be said basically about every dataset out there
[03:51:18] <HuntsMan> yes, but not every dataset contains racist assumptions
[03:51:31] <mefistof1les> and I agree that the hispanic/afro population can arguably be a good predictor
[03:51:48] <HuntsMan> there have been worse cases, like the tiny images dataset which now completely dissapeared
[03:51:54] <HuntsMan> some image datasets even have porn
[03:52:08] <HuntsMan> or misoginistic labels about women
[03:52:12] *** Quits: akevinhuang (~thekevinh@user/thekevinhuang) (Ping timeout: 256 seconds)
[03:52:24] <mefistof1les> that speaks a lot about the society, specially if the models work
[03:52:36] <mefistof1les> I don't think censoring these datasets are the way to go, tbh
[03:52:57] <mefistof1les> if anything they can actually be used to make the case in favor of minorities
[03:54:11] <HuntsMan> nah, its not censoring, in some cases this stuff is illegal
[03:54:11] <mefistof1les> I know it is tricky, but I just don't really agree witht he conception of this paper or dataset being racist. However, I DO agree that there are better alternatives and that it does have the "correlation is not causation" issue
[03:54:20] <mefistof1les> HuntsMan: yeah, nothing wrong with that
[03:54:30] <mefistof1les> I mean, if it's illegal, it shouldn't exist
[03:54:35] <mefistof1les> but it's not the case for this dataset
[03:54:39] <HuntsMan> it is
[03:54:48] <mefistof1les> how so?
[03:55:00] <HuntsMan> in the US it is illegal for some institutions to put some data together
[03:55:03] <HuntsMan> usually race and other things
[03:55:10] <HuntsMan> they need to treat sensitive data very very carefully
[03:55:14] <HuntsMan> which clearly they did not do
[03:55:27] *** Quits: Donitz (~Donitz@88-115-149-152.elisa-laajakaista.fi) (Read error: Connection reset by peer)
[03:55:31] <mefistof1les> HuntsMan: can you link to a source on that? I need to read that
[03:55:40] *** Quits: SiegeLord (~sl@user/siegelord) (Quit: WeeChat 2.8)
[03:56:01] <HuntsMan> when the GDPR came into effect in the EU, some datasets also dissapeared (by the own authors) due to privacy issues, as it was personally identifiable information and they did not have consent for that
[03:56:13] <HuntsMan> mefistof1les: its what I have heard, I do not have links specifically for that
[03:56:19] <mefistof1les> because almost everywhere I'm being asked about my gender and ethnicity, much more in the US than anywhere else, tbh
[03:56:27] <HuntsMan> mefistof1les: but I think its basically laws to prevent redlining
[03:56:56] <mefistof1les> so I find that surprising, if it's actually illegal, then why they need it so much? (I guess there are special cases(
[03:56:59] <mefistof1les> )
[03:57:32] <HuntsMan> maybe that institution is not regulated by law
[03:57:37] <HuntsMan> banks are much more regulated for example
[03:57:51] <mefistof1les> I'm pretty sure my bank asked for my ethnicity and gender
[03:57:53] *** Joins: SiegeLord (~SiegeLord@user/siegelord)
[03:57:59] <mefistof1les> in the US
[03:58:17] *** Joins: Donitz (~Donitz@88-115-149-152.elisa-laajakaista.fi)
[03:58:41] <mefistof1les> and I think that's good, they are by law to use this data etically, I don't think it should be illegal to have it at all, which is kinda the point I'm making
[03:58:58] <mefistof1les> since it actually helps to try to see if there is actually bias based on race/ethnicity or gender
[03:59:22] <HuntsMan> let's say I steal that data from your bank, your bank might have a lawful reason to have it, but if it leaks, then the copies are illegal
[03:59:35] <HuntsMan> yeah sure but in the past, banks used it for discrimination
[03:59:50] <HuntsMan> one thing is what theoretically can be done with the data, and another is what was actually done with it in the past
[04:00:14] <mefistof1les> sure, and now if we don't have it, we can't even say if it's used for discrimination or not, which is worse, imho
[04:00:27] <mefistof1les> btw, I think seggregation is pretty bad these days
[04:00:28] <HuntsMan> but the bank can't discriminate either
[04:00:39] <HuntsMan> because it does not have racial data or data to infer race
[04:01:20] <mefistof1les> that sounds easy to trick, whereas the other is easy to replicate
[04:01:30] <tomeaton17> I think the main problem is that the column is actually incorrectly calculated from the Boston census
[04:01:43] <mefistof1les> but yeah, I know US doesn't really care to audit banks as long as they keep capitalism thriving, which is another issue... somewhat related
[04:01:56] <mefistof1les> tomeaton17: that sounds like a real issue
[04:03:00] <tomeaton17> It seems like the paper is modelling racism, rather than having a racist viewpoint itself
[04:03:29] <mefistof1les> HuntsMan: I guess the point is that we really lack good laws for these things, we should also force public institutions to be more in the open side, instead of limiting the data, we should just make it publicly and openly available, easy to audit, etc.
[04:04:03] <mefistof1les> but I'm pretty sure these institutions are fighting for being more and more closed, so they can do whatever they want without many justifications
[04:04:09] <mefistof1les> and that's off-topic xD sorry
[04:04:52] <mefistof1les> tomeaton17: yes, that's what I think as well
[04:05:00] <mefistof1les> it's actually a pretty interesting paper and dataset
[04:05:58] <mefistof1les> now, if it has realy technical issues, that's bad, surely
[04:06:04] <mefistof1les> *real
[04:08:40] <tomeaton17> https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8 according to this there are
[04:08:40] <SigmoidFroid> ⇒  racist data destruction?. a Boston housing dataset controversy | by M Carlisle | Medium
[04:16:51] *** Quits: Codaraxis (~Codaraxis@user/codaraxis) (Quit: Leaving)
[04:25:47] *** Quits: tomeaton17 (~tomeaton1@92.234.2.175) (Quit: Client closed)
[04:30:26] *** Quits: mefistof1les (~mefistofe@user/mefistofeles) (Quit: Hay te huacho!)
[04:48:06] *** Quits: medium_cool (~medium_co@2605:a601:a9aa:f800:2178:42cf:7342:ed4a) (Quit: My Mac Mini has gone to sleep. ZZZzzz…)
[05:40:16] *** Quits: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de) (Ping timeout: 265 seconds)
[06:01:05] *** Joins: Karel (~Karel@d51a4910f.access.telenet.be)
[06:15:06] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Ping timeout: 245 seconds)
[06:32:20] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[06:36:50] *** Joins: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de)
[06:50:54] *** Quits: Malvolio (~Malvolio@user/malvolio) (Quit: brb)
[06:53:02] *** Joins: Coldblackice (~c@user/coldblackice)
[06:53:14] *** Joins: Malvolio (~Malvolio@user/malvolio)
[07:10:50] *** Quits: SiegeLord (~SiegeLord@user/siegelord) (Read error: Connection reset by peer)
[07:17:23] *** Joins: vftec (~8iIn0n@2a01:4b00:8e07:7900:ec57:73ad:ab0d:1d61)
[07:30:48] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Quit: Leaving)
[07:43:59] *** Joins: SiegeLord (~sl@user/siegelord)
[07:46:02] *** Quits: vftec (~8iIn0n@2a01:4b00:8e07:7900:ec57:73ad:ab0d:1d61) (Quit: Leaving)
[08:18:32] *** Joins: vftec (~8iIn0n@2a01:4b00:8e07:7900:ec57:73ad:ab0d:1d61)
[08:23:45] *** Quits: vftec (~8iIn0n@2a01:4b00:8e07:7900:ec57:73ad:ab0d:1d61) (Quit: Leaving)
[08:45:10] *** Quits: akevinhuang2 (~thekevinh@user/thekevinhuang) (Ping timeout: 256 seconds)
[09:23:40] *** Joins: palasso (~palasso@user/palasso)
[10:10:34] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[10:34:22] *** Quits: dostoyevsky (~sck@user/dostoyevsky) (*.net *.split)
[10:34:23] *** Quits: shr2 (~shrysr@user/shrysr) (*.net *.split)
[10:34:35] *** Joins: dostoyevsky (~sck@user/dostoyevsky)
[10:34:59] *** Joins: shr2 (~shrysr@user/shrysr)
[10:51:13] *** Joins: manti7 (~manti7@176.10.104.94)
[11:12:55] *** Joins: hygl (uid16621@tinside.irccloud.com)
[12:06:04] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi)
[12:09:14] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi) (Read error: Connection reset by peer)
[12:10:39] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi)
[12:28:31] *** Joins: jlrnick (~josephler@2a01cb040a1594007911975fbb5b9942.ipv6.abo.wanadoo.fr)
[12:35:35] *** Joins: cslr2 (~cslr2@mobile-access-567371-252.dhcp.inet.fi)
[12:42:03] *** Quits: cslr2 (~cslr2@mobile-access-567371-252.dhcp.inet.fi) (Ping timeout: 265 seconds)
[12:48:09] *** Joins: cslr2 (~cslr2@mobile-access-567371-252.dhcp.inet.fi)
[12:51:16] *** Quits: cslr2 (~cslr2@mobile-access-567371-252.dhcp.inet.fi) (Remote host closed the connection)
[13:12:27] *** Quits: SiegeLord (~sl@user/siegelord) (Quit: WeeChat 2.8)
[13:14:15] *** Joins: Klinda (~superleag@user/klinda)
[13:19:05] <Klinda> buongiorno
[13:26:20] *** Joins: Coldblackice_ (~c@user/coldblackice)
[13:30:10] *** Quits: Coldblackice (~c@user/coldblackice) (Ping timeout: 260 seconds)
[13:35:37] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi) (Read error: Connection reset by peer)
[13:36:58] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi)
[13:38:56] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi) (Read error: Connection reset by peer)
[13:39:41] *** Joins: tomeaton17 (~tomeaton1@92.234.2.175)
[13:40:08] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi)
[14:02:18] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi) (Read error: Connection reset by peer)
[14:02:46] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi)
[14:11:58] *** Quits: tomeaton17 (~tomeaton1@92.234.2.175) (Quit: Client closed)
[14:20:42] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi) (Read error: Connection reset by peer)
[14:21:38] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi)
[15:18:59] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[15:19:07] *** Joins: tomeaton17 (~tomeaton1@2a0c:5bc0:40:3e3a:2011:b785:a7e6:b558)
[15:21:11] *** Joins: georgios (~georgios@user/georgios)
[15:21:48] <tomeaton17> hi
[15:37:46] *** Joins: SageKhan (~Metanet@42.201.202.222)
[15:37:58] <SageKhan> Hi
[15:38:15] <SageKhan> Can anyone help me on using LUDWIG AI ... made by Uber AI
[15:40:19] <HuntsMan> you need to be specific
[15:46:53] <SageKhan> Hello huntsman
[15:48:58] <SageKhan> I need to make a multilingual Automatic Speech recognition system. I have collected the data set of about 200 GB. I want to know how to prepare/preprocess the data for training it offline on my system. After training I want to implment it on live calls and on recorded as well. Can anyone help me on doing this on LUDWIG-AI made by UBER AI
[16:08:34] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Read error: Connection reset by peer)
[16:09:53] *** Quits: tomeaton17 (~tomeaton1@2a0c:5bc0:40:3e3a:2011:b785:a7e6:b558) (Quit: Client closed)
[16:17:31] *** Joins: tomeaton17 (~tomeaton1@2a0c:5bc0:40:3e3a:2011:b785:a7e6:b558)
[16:17:37] <tomeaton17> How are you supposed to choose a non-linear transform without looking at the data first? I understand that looking at the data will lead to really bad generalisation error, but I don't understand how you are supposed to pick a reasonable non-linear transform without looking at the data first
[16:20:25] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[16:22:09] *** Quits: jlrnick (~josephler@2a01cb040a1594007911975fbb5b9942.ipv6.abo.wanadoo.fr) (Remote host closed the connection)
[16:24:42] *** Quits: georgios (~georgios@user/georgios) (Quit: Konversation terminated!)
[16:38:00] <SageKhan>  I need to make a multilingual Automatic Speech recognition system. I have collected the data set of about 200 GB. I want to know how to prepare/preprocess the data for training it offline on my system. After training I want to implment it on live calls and on recorded as well. Can anyone help me on doing this on LUDWIG-AI made by UBER AI
[16:38:51] <HuntsMan> SageKhan: that library has examples, have you looked at them?
[16:39:34] <SageKhan> Yeah I cant quite equate with an Urdu data set (comrpising of hours of calls)
[16:39:39] <SageKhan> in wave file
[16:40:01] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi) (Read error: Connection reset by peer)
[16:40:29] <[itchyjunk]> i think ludwig is a codeless toolbox
[16:40:39] <[itchyjunk]> you just have to follow the instruction on their site
[16:40:48] <[itchyjunk]> thought it was not maintained either
[16:40:55] <[itchyjunk]> maybe it is, i guess
[16:41:14] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi)
[16:42:11] <SageKhan> I have same question with using KALDI ASR and SPEECH BRAIN
[16:43:54] *** Joins: georgios (~georgios@user/georgios)
[16:44:44] <[itchyjunk]> does ludwig even take audio directly?
[16:44:56] <[itchyjunk]> how is your data structured?
[16:45:51] <[itchyjunk]> oh it does
[16:45:56] <[itchyjunk]> https://ludwig-ai.github.io/ludwig-docs/examples/
[16:45:57] <SigmoidFroid> ⇒  Examples - Ludwig
[16:46:14] <[itchyjunk]> they have examples of using an audio data set to train a pre train model
[16:46:47] <SageKhan> yes Ive gone through those. The file structure to set up is not there. I mean, do I have to keep sentences or words? Do I have to make speaker seperate file or not? Do I need to make sepereate folder for male and female?
[16:47:31] <[itchyjunk]> its talks about formats in getting started
[16:47:40] <[itchyjunk]> the user guide has some details
[16:48:29] <[itchyjunk]> you can't use the pretrained model api if you don't have network connection probably
[16:48:38] <[itchyjunk]> guessing you're making one from scratch?
[16:50:07] <[itchyjunk]> tells you how to get the pretrained model loaded as well, if you're going with just the retraining option
[16:50:08] <[itchyjunk]> https://ludwig-ai.github.io/ludwig-docs/user_guide/programmatic_api/
[16:50:08] <SigmoidFroid> ⇒  Programmatic API - Ludwig
[17:09:25] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi) (Read error: Connection reset by peer)
[17:10:39] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi)
[17:14:47] *** Quits: Karel (~Karel@d51a4910f.access.telenet.be) (Ping timeout: 264 seconds)
[17:26:08] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[17:26:25] *** Joins: Klinda (~superleag@user/klinda)
[17:45:05] *** Joins: Karel (~Karel@natx-145.kulnet.kuleuven.be)
[17:51:44] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[17:52:40] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi) (Read error: Connection reset by peer)
[17:53:38] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi)
[18:02:30] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df0c0-17.dhcp.inet.fi) (Read error: Connection reset by peer)
[18:02:59] *** Quits: Klinda (~superleag@user/klinda) (Ping timeout: 265 seconds)
[18:03:31] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi)
[18:12:53] *** Quits: SageKhan (~Metanet@42.201.202.222) (Quit: Leaving)
[18:33:53] *** Quits: tomeaton17 (~tomeaton1@2a0c:5bc0:40:3e3a:2011:b785:a7e6:b558) (Quit: Client closed)
[18:43:30] *** Joins: shoky (uuuggg@141.226.193.67)
[18:44:42] *** Quits: shoky_ (uuuggg@141.226.193.67) (Ping timeout: 260 seconds)
[18:45:26] *** Joins: kek_ (~kek_@2a02:168:200f:1f10:410b:731a:6592:864d)
[19:24:06] *** Joins: Klinda (~superleag@user/klinda)
[19:32:06] *** Joins: Coldblackice (~c@user/coldblackice)
[19:35:42] *** Quits: Coldblackice_ (~c@user/coldblackice) (Ping timeout: 256 seconds)
[20:30:05] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Read error: Connection reset by peer)
[20:36:05] *** Quits: Karel (~Karel@natx-145.kulnet.kuleuven.be) (Ping timeout: 250 seconds)
[20:36:52] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[20:47:57] *** Joins: Coldblackice_ (~c@user/coldblackice)
[20:52:09] *** Quits: Coldblackice (~c@user/coldblackice) (Ping timeout: 265 seconds)
[21:01:10] *** Joins: akevinhuang (~thekevinh@user/thekevinhuang)
[21:05:56] *** Quits: Samian (~s@user/samian) (Ping timeout: 245 seconds)
[21:10:19] *** Quits: Klinda (~superleag@user/klinda) (Ping timeout: 250 seconds)
[21:25:54] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-56734f-209.dhcp.inet.fi) (Read error: Connection reset by peer)
[21:35:32] *** Joins: Samian (~s@user/samian)
[21:36:19] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Ping timeout: 250 seconds)
[21:38:31] *** Joins: Karel (~Karel@ptr-9091p55l5qzdvorvtjt.18120a2.ip6.access.telenet.be)
[22:03:44] *** Joins: SiegeLord (~sl@user/siegelord)
[22:21:35] *** Joins: Klinda (~superleag@user/klinda)
[22:31:43] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[22:34:30] *** Joins: sinaowolabi_ (~SinaOwola@102.134.114.1)
[22:57:53] *** Joins: Bi1non (~8iIn0n@2a01:4b00:8e07:7900:aa4d:84b:c3c0:acbe)
[22:59:53] *** Quits: Bi1non (~8iIn0n@2a01:4b00:8e07:7900:aa4d:84b:c3c0:acbe) (Client Quit)
[23:00:08] *** Joins: Bi1non (~8iIn0n@2a01:4b00:8e07:7900:aa4d:84b:c3c0:acbe)
[23:25:31] *** Quits: Klinda (~superleag@user/klinda) (Ping timeout: 250 seconds)
[23:26:58] *** Quits: kek_ (~kek_@2a02:168:200f:1f10:410b:731a:6592:864d) (Quit: Leaving)
[23:38:54] *** Quits: Karel (~Karel@ptr-9091p55l5qzdvorvtjt.18120a2.ip6.access.telenet.be) (Ping timeout: 265 seconds)
[23:44:43] <mefistofeles> https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa
[23:44:45] <SigmoidFroid> ⇒  9 Distance Measures in Data Science | Towards Data Science
