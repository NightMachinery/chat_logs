[00:00:04] <JEEB> sure, your values are more limited within 16-235|240 across content since that's the limited range's value range, but I'm not sure you magically start compressing worse due to 1-255 becoming available
[00:00:42] <bartzy> I meant: limited + CRF 28 = 5MB video (as an example). full + CRF 28 = 5.5MB video. I can get to limited + CRF x = 5.5MB. That x would be a lower CRF with better quality probably
[00:00:43] <JEEB> not that I've done tests, but it sounds like something where compatibility is much higher on the care list than whether it causes slight compression differences
[00:01:01] <JEEB> same CRF is not the same quality
[00:01:12] <JEEB> it is similar, sure. but you've changed your content
[00:01:36] <JEEB> if you actually want to compare them you'll have to somehow calculate metrics over how well the original signal was kept
[00:01:49] <bartzy> oh, I tried and in one case full range was larger than limited by 500KB : 4.9MB vs. 4.4MB (it's really short videos where quality is¬†very important important but also file size :))
[00:03:07] <bartzy> yeah, I see. I'll maybe do that (with VMAF for example). I was just surprised that full was larger than limited (as you said why it magically compresses worse due to 1-255 becoming available)
[00:03:29] <JEEB> as I said, same CRF is not the same quality
[00:03:55] <JEEB> you have changed the content and thus it's not comparable (the other classic is to have changed encoding parameters between)
[00:04:08] <bartzy> ah, I see what you mean
[00:04:32] <JEEB> also the damage limited range can make is much more than just compression artifacts tbh
[00:04:44] <JEEB> you have the same top and bottom point in how that image is interpreted
[00:04:55] <bartzy> so you mean that besides the full range being probably "better" in whites/blacks than limited, maybe the file size increase I'm seeing is also due to x265 providing some more "quality" for the same CRF (and hence a larger file size)
[00:05:03] <JEEB> it's just that with limited range you have your lowest point at 16 and highest at 235|240
[00:05:12] <JEEB> just calculate how many values you miss :P
[00:05:40] <JEEB> compared to where the same bottom and top points now have the values between 1-255 available to show intermediate values
[00:06:04] <bartzy> it's actually 10-bit output so it's 64-940 vs 0-1023 I guess
[00:06:29] <JEEB> limited VS full range is not about having different lowest and highest points in the interpreted image, basically
[00:06:38] <JEEB> just that you have more intermediate values
[00:07:03] *** Joins: nillyhan (~00000000@user/nillyhan)
[00:07:10] <bartzy> i.e. more darker shades and more lighter shades, if I understand correctly
[00:07:18] <bartzy> but black will still be the same black and same for white
[00:07:28] <JEEB> across the whole gamut
[00:07:54] <JEEB> since what a player literally does after decoding is to stretch that 16-235|240 back to 0-255
[00:07:57] <JEEB> lol
[00:08:05] <bartzy> OK. so from what you're saying I think that going to full range in my case makes sense. your sentence "also the damage limited range can make is much more than just compression artifacts tbh" is quite convincing :)
[00:08:55] <JEEB> but yea with full range the only thing is to a) flag the stuff properly (which hopefully barring any bugs should be happenin by default with 4.4+) b) your clients need to actually habla espanol with regards to it
[00:09:18] <JEEB> basically, if you aim at plastic boxes that hard-code themselves to limited range you're going to get incorrect colors
[00:09:31] <bartzy> yeah here's to hoping that modern players and specifically AVFoundation on iOS are fine with it (99% they are)
[00:10:10] <bartzy> ok but how do I fix my 422HQ -> x265 420 in P3 issue ;(
[00:10:46] <bartzy> with your `-f null -frames:v 1 -` suggestion after the `-vf` flag I get this as the output stream: Stream #0:0(eng): Video: wrapped_avframe, yuv420p10le(tv, bt709, progressive), 1284x2778 [SAR 1:1 DAR 214:463], q=2-31, 200 kb/s, 30 fps, 30 tbn (default)
[00:11:05] <JEEB> not gonna go on with this any more, sorry. good night
[00:12:06] <bartzy> sure, thanks a lot though! really appreciate it.
[00:19:26] *** Quits: SimAV (~SimAV@ip1f10fb08.dynamic.kabel-deutschland.de) (Ping timeout: 260 seconds)
[00:19:26] *** Quits: kib (~kib@user/kib) (Ping timeout: 260 seconds)
[00:24:35] *** Parts: phinxy (~phinxy@78-71-229-90-no500.tbcn.telia.com) ()
[00:30:44] *** Joins: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de)
[00:37:14] *** Joins: chowbok (~quassel@207.181.244.106)
[00:40:18] *** Quits: Flabb (~Flabb@89.169.42.92) (Quit: Leaving)
[00:55:34] *** Quits: Hello71 (~Hello71@wireguard/contributor/hello71) (Remote host closed the connection)
[00:56:01] *** Joins: Hello71 (~Hello71@wireguard/contributor/hello71)
[00:56:14] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 258 seconds)
[00:56:40] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[01:30:45] *** Quits: jess (~jess@libera/staff/jess) (Quit: Lost terminal)
[01:31:11] *** Joins: jess (~jess@libera/staff/jess)
[01:32:28] *** Quits: LanDi (~landi@187.19.137.250) (Remote host closed the connection)
[01:40:17] *** Quits: mickey8 (~user@user/mickey) (Quit: Ping timeout (120 seconds))
[01:40:35] *** Joins: mickey8 (~user@user/mickey)
[01:41:46] *** Quits: durandal_1707 (~computer@95.168.120.92) (Read error: No route to host)
[01:46:14] *** Quits: cosimone (~user@93-47-230-89.ip115.fastwebnet.it) (Ping timeout: 260 seconds)
[02:02:36] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[02:13:20] *** Quits: ivanich_ (~ivanich@45-140-123-239.broadband.tenet.odessa.ua) (Read error: Connection reset by peer)
[02:13:33] *** Joins: ivanich_ (~ivanich@45-140-123-239.broadband.tenet.odessa.ua)
[02:21:18] *** Joins: causasui (~causasui@c-68-60-125-136.hsd1.mi.comcast.net)
[02:26:41] *** Quits: ivanich_ (~ivanich@45-140-123-239.broadband.tenet.odessa.ua) (Quit: Konversation terminated!)
[02:31:20] *** Quits: Seirdy (~Seirdy@sourcehut/user/seirdy) (Quit: exiting 3.2)
[02:31:42] *** Quits: alphalpha (~michael@dslb-088-077-182-234.088.077.pools.vodafone-ip.de) (Quit: Leaving)
[02:31:56] *** Joins: Seirdy (~Seirdy@sourcehut/user/seirdy)
[03:02:18] *** Quits: auth (~auth@user/auth) (Ping timeout: 260 seconds)
[03:05:12] *** Quits: iive (~iive@87.119.101.204.client.entry.bg) (Quit: They came for me...)
[03:06:44] *** Quits: omegatron (~some@p5b056a70.dip0.t-ipconnect.de) (Ping timeout: 268 seconds)
[03:26:22] *** Quits: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de) (Ping timeout: 252 seconds)
[03:41:18] <bartzy> When ffprobe doesn't show any color information (matrix/primaries/transfer) in the stream output - what does that mean exactly?
[03:42:59] *** Quits: wyatt8750 (~wyatt8740@209.58.146.165) (Remote host closed the connection)
[03:46:29] *** Joins: wyatt8740 (~wyatt8740@149.164.111.65)
[03:51:46] *** Quits: wyatt8740 (~wyatt8740@149.164.111.65) (Ping timeout: 260 seconds)
[03:53:14] *** Joins: wyatt8740 (~wyatt8740@23.81.114.227)
[04:04:57] *** Joins: Fohsap (~Muimi@2001:19f0:6001:e4d:5400:3ff:fe41:8d5b)
[04:13:07] *** Quits: aphysically (~aphysical@user/aphysically) (Ping timeout: 268 seconds)
[04:14:34] *** Joins: aphysically (~aphysical@user/aphysically)
[04:30:31] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[04:34:47] *** Quits: HumanG33k (~HumanG33k@2a01:e0a:95:5d90:215:c5ff:fe68:fb04) (Quit: WeeChat 3.0)
[04:35:06] *** Joins: vlm (~vlm@user/vlm)
[04:38:45] *** Joins: HumanG33k (~HumanG33k@2a01:e0a:95:5d90:215:c5ff:fe68:fb04)
[04:44:50] *** Quits: bartzy (~bartzy@5.29.33.36) (Quit: Connection closed)
[04:54:43] *** Quits: realies (~realies@user/realies) (Ping timeout: 265 seconds)
[05:01:43] *** Joins: realies (~realies@user/realies)
[05:02:23] *** Quits: realies (~realies@user/realies) (Client Quit)
[05:02:43] *** Joins: realies (~realies@user/realies)
[05:05:08] *** Joins: Yonle (~Yonle@user/yonle)
[05:07:47] *** Quits: realies (~realies@user/realies) (Quit: ~)
[05:08:06] *** Joins: realies (~realies@user/realies)
[05:08:52] *** Quits: realies (~realies@user/realies) (Client Quit)
[05:09:11] *** Joins: realies (~realies@user/realies)
[05:39:26] *** Joins: realies4 (~realies@user/realies)
[05:39:54] *** Quits: realies (~realies@user/realies) (Ping timeout: 258 seconds)
[05:39:54] *** realies4 is now known as realies
[05:46:55] *** Quits: fannagoganna (uid110488@id-110488.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[06:05:42] *** Quits: jos1 (~jos3@dyndsl-091-248-050-224.ewe-ip-backbone.de) (Ping timeout: 260 seconds)
[06:17:27] *** Joins: jos1 (~jos3@dyndsl-178-142-068-225.ewe-ip-backbone.de)
[06:44:56] *** Quits: thebombzen (~thebombze@c-68-41-54-207.hsd1.mi.comcast.net) (Quit: Quit)
[06:57:53] *** Joins: thebombzen (~thebombze@c-68-41-54-207.hsd1.mi.comcast.net)
[07:00:54] *** Joins: yeirr (~yeirr@user/yeirr)
[07:16:16] *** Quits: Yonle (~Yonle@user/yonle) (Remote host closed the connection)
[07:16:30] *** Joins: Yonle (~Yonle@user/yonle)
[07:17:01] *** Quits: Yonle (~Yonle@user/yonle) (Read error: Connection reset by peer)
[07:17:16] *** Joins: Yonle (~Yonle@user/yonle)
[07:17:47] *** Quits: Yonle (~Yonle@user/yonle) (Client Quit)
[07:25:47] *** Bertl_oO is now known as Bertl_zZ
[07:37:18] *** Joins: rainmanjam (~rainmanja@216.161.85.62)
[08:38:38] *** Joins: aa (~douglasco@200.146.85.128.static.gvt.net.br)
[08:41:21] *** Quits: fling (~fling@user/fling) (Ping timeout: 245 seconds)
[08:42:23] *** Quits: douglascorrea_io (~douglasco@200.146.85.128.static.gvt.net.br) (Ping timeout: 264 seconds)
[08:44:47] *** Joins: Gaboradon (~Gaboradon@cpe-86-58-57-5.static.triera.net)
[08:49:37] *** Quits: iconoclasthero (~quassel@pool-68-238-241-198.phlapa.fios.verizon.net) (Ping timeout: 265 seconds)
[08:58:15] *** Joins: iconoclasthero (~quassel@pool-68-238-241-198.phlapa.fios.verizon.net)
[09:03:25] *** Joins: Atsuko_ (~x@45.63.115.64)
[09:04:36] *** Quits: Atsuko (~x@45.63.115.64) (Ping timeout: 258 seconds)
[09:08:10] *** Quits: yeirr (~yeirr@user/yeirr) (Ping timeout: 260 seconds)
[09:27:39] *** Joins: yeirr (~yeirr@user/yeirr)
[09:36:32] *** Joins: palasso (~palasso@user/palasso)
[09:42:48] *** Joins: furrymcgee (~devuan@cgn-89-1-210-103.nc.de)
[09:47:57] *** Joins: SimAV (~SimAV@31.16.251.8)
[09:53:54] *** Quits: sbrown (~sbrown@66.44.16.44) (Quit: Leaving‚Ä¶)
[10:11:13] *** Joins: cosimone (~user@93-34-132-219.ip49.fastwebnet.it)
[10:14:55] *** Joins: kib (~kib@user/kib)
[10:15:04] <hyrcanus> a vague question doesn't become more precise with "exactly" appended
[10:17:18] *** Joins: Lazenca (Lazenca@user/lazenca)
[10:24:49] <galad> retagging a bt709 file to something else just because it feels better seems weird anyway
[10:26:27] *** Joins: ketas- (~ketas@0011-0000-0000-0000-d7dc-830e-07d0-2001.dyn.estpak.ee)
[10:28:49] *** Joins: Exagone313 (exa@irc.moe)
[10:29:38] *** Joins: auth (~auth@user/auth)
[10:30:20] *** Joins: eqw_ (~eqw@31.134.178.99)
[10:30:51] *** Joins: Buliarou1 (~gypsydang@185.207.166.57)
[10:33:39] *** Joins: kpuc- (1011@46-97-229-216.sr2.pon.net)
[10:33:59] *** Joins: synapt (NBishop@o.apocaleaps.com)
[10:34:00] *** Joins: Jan\2407 (~kvirc@104.204.200.116)
[10:38:47] *** Joins: bartzy (~bartzy@5.29.33.36)
[10:39:50] *** Quits: kpuc (1011@46-97-229-216.sr2.pon.net) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: Exa (exa@irc.moe) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: Jan\ (~kvirc@104.204.200.116) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: jemershaw[m] (~jemershaw@2001:470:69fc:105::b904) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: eqw (~eqw@31.134.178.99) (Ping timeout: 260 seconds)
[10:39:50] *** Exagone313 is now known as Exa
[10:39:50] *** Quits: nate (NBishop@o.apocaleaps.com) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: fructose (~fructose@user/fructose) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: gnurou (~gnurou@2001:470:69fc:105::c23b) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: yuu[m] (~yuumatrix@2001:470:69fc:105::8a6) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: Buliarous (~gypsydang@185.207.166.57) (Ping timeout: 260 seconds)
[10:39:50] *** Quits: ketas (~ketas@0011-0000-0000-0000-d7dc-830e-07d0-2001.dyn.estpak.ee) (Ping timeout: 260 seconds)
[10:39:51] *** synapt is now known as nate
[10:42:13] *** Joins: jemershaw[m] (~jemershaw@2001:470:69fc:105::b904)
[10:42:38] *** Quits: shokohsc8 (~shokohsc@161.88.195.77.rev.sfr.net) (Read error: Connection reset by peer)
[10:43:38] *** Quits: ttys000 (~ttys000@user/ttys000) (Ping timeout: 246 seconds)
[10:43:52] *** Joins: shokohsc8 (~shokohsc@161.88.195.77.rev.sfr.net)
[10:46:33] *** Joins: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de)
[10:46:51] *** Joins: gnurou (~gnurou@2001:470:69fc:105::c23b)
[10:48:09] *** Joins: yuu[m] (~yuumatrix@2001:470:69fc:105::8a6)
[10:49:35] *** Joins: durandal_1707 (~computer@95.168.120.92)
[10:51:49] *** Parts: gucky-chat-laden (~gucky-cha@46.41.28.214) ()
[10:54:52] *** Joins: gucky-chat-laden (~gucky-cha@46.41.28.214)
[10:59:23] *** Joins: cmp97 (~cmp@lputeaux-658-1-177-87.w92-154.abo.wanadoo.fr)
[10:59:38] *** Quits: nillyhan (~00000000@user/nillyhan) (Ping timeout: 265 seconds)
[11:07:08] *** Joins: ivanich (~ivanich@45-140-123-239.broadband.tenet.odessa.ua)
[11:11:06] *** Quits: Jerrk (~Jerrk@185.213.154.231) (Ping timeout: 258 seconds)
[11:11:14] *** Joins: nillyhan (~00000000@user/nillyhan)
[11:13:31] *** Joins: Volgaar (~volgaar@104.66.13.93.rev.sfr.net)
[11:16:05] <bartzy> so eventually I found a solution to my 422HQ in BT709 to P3 issue with this pipe: https://pastebin.com/pKMJ8bmK
[11:16:34] <bartzy> I couldn't figure out a way to do this with a single ffmpeg command. If anyone has an idea how, let me know
[11:26:03] *** Quits: auth (~auth@user/auth) (Ping timeout: 258 seconds)
[11:43:28] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[11:46:55] *** Quits: sfan5 (~sfan5@user/sfan5) (Quit: Quit)
[11:48:24] *** Joins: sfan5 (~sfan5@user/sfan5)
[11:48:44] *** Quits: therobin (~UserNick@45.72.211.155) (Quit: Going offline, see ya! (www.adiirc.com))
[11:49:03] *** Joins: therobin (~UserNick@2607:f2c0:9510:9e00:ac35:1edd:c7e6:67f4)
[11:56:08] *** Quits: Gaboradon (~Gaboradon@cpe-86-58-57-5.static.triera.net) (Quit: Shutdown)
[12:01:43] *** Quits: aleek (~aleeksand@user-5-173-0-46.play-internet.pl) (Ping timeout: 252 seconds)
[12:16:16] *** Joins: aleek (~aleeksand@user-5-173-0-46.play-internet.pl)
[12:19:51] <hyrcanus> good
[12:22:47] *** Quits: palasso (~palasso@user/palasso) (Ping timeout: 258 seconds)
[12:22:57] <thebombzen> bartzy: are you trying to re-tag it or just transcode it?
[12:23:44] <bartzy> thebombzen: if by re-tag you mean to change it to P3 (and hence change its appearance in players), then yes
[12:24:02] <thebombzen> why can't you just use those tag options without transcoding
[12:25:06] <bartzy> oh, I do want to transcode to HEVC as well. sorry. But I think that even without it, just re-tagging it and keeping it 422HQ doesn't work
[12:25:46] <galad> bartzy: but why? that would change the way the color is displayed, in a way that's not the one intended by the one who created the video
[12:26:05] <thebombzen> why wouldn't it? I mean it would not work equally as well as what you're doing. which is changing the colors.
[12:26:06] <bartzy> galad: I understand, but that's what I need to do
[12:26:20] <galad> oh well, if you are happy, than we all are
[12:26:24] <bartzy> :)
[12:26:28] <thebombzen> why do you want to trancode to HEVC
[12:27:04] <bartzy> galad: The person that creates the videos is on my team. We just decided on some workflow where they export everything in BT709, and for some videos we decide to change the colors like that. I know it's silly
[12:27:21] <thebombzen> what does that hae to do with transcoding to HEVC
[12:27:22] <thebombzen> ffmpeg -i masters/0284/master/0284.mov -map 0 -c copy -map_metadata -1 -color_range pc -colorspace bt2020c -color_primaries smpte432 -color_trc iec61966-2-1 -movflags +faststart -tag:v hvc1 exports/0284/colorspace_tests/1284x2778/0284-1284x2778-full.mov
[12:27:26] <thebombzen> try this, what happens?
[12:27:31] <galad> yup, that's extremely stupid, but ü§∑‚Äç‚ôÇÔ∏è
[12:27:55] <bartzy> galad: it's very short videos that are meant for a very specific purpose
[12:28:15] <bartzy> thebombzen: trying now. I want to transcode to HEVC because I want to deliver it to mobile devices
[12:28:42] <thebombzen> older mobile devices wont' support that
[12:28:49] <thebombzen> you're probably better off just using H.264
[12:29:16] <thebombzen> youtube doesn't deliver HEVC for context, it's just H.264, VP9, and AV1 for them.
[12:29:24] <bartzy> I'm only targeting devices that support HEVC in hardware :)
[12:29:57] <thebombzen> why don't you just have whoever is producing the video export it directly as HEVC
[12:30:31] <bartzy> I mean, I'm with you.. but that's what we decided and what I need to do :|
[12:30:41] <bartzy> so I'm just trying to get the correct result now
[12:30:52] <bartzy> thebombzen: your command didn't produce the desired output
[12:30:57] <thebombzen> what was not desired about it
[12:31:01] *** Joins: auth (~auth@user/auth)
[12:31:38] *** Quits: Lazenca (Lazenca@user/lazenca) (Remote host closed the connection)
[12:31:46] *** Joins: jkwnki2 (~jkwnki@p2e5793bc.dip0.t-ipconnect.de)
[12:31:47] *** Joins: jkwnki1 (~jkwnki@p2e5793bc.dip0.t-ipconnect.de)
[12:31:59] <thebombzen> If you're transcoding anyway, you should just use avfilter to edit the colors. Your goal is to produce a video that looks in a specific way on a specific device, so why can't you just do that with avfilter
[12:32:09] <bartzy> (colors are different). I think the reason is that it changes the color matrix and the transfer function without actually converting. and my piping command (which does produce the desired output) first converts to gbrp (which probably converts BT709 to the correct gbrp colors?) and then does the re-tagging.
[12:32:35] <thebombzen> So you're not actually trying to re-tag
[12:32:52] <thebombzen> you're trying to actually convert the colors
[12:33:37] <bartzy> Here's the full thing I'm trying to do: I'm trying to take a 422HQ mov in BT709 (mediainfo reports BT709 matrix/transfer/primaries), and convert it to Display P3 (SMPTE432). So literally make the colors more "vivid" on displays that support it. The same effect as it I were embedding the "Display P3" ICC profile to an sRGB image to make a new
[12:33:37] <bartzy> P3'fied image.
[12:33:49] <bartzy> but the colors are a bit off. I know that because if I take an sRGB PNG of the first frame and apply the P3 ICC profile on it, that's my reference.
[12:34:40] <thebombzen> how are you viewing said PNG
[12:35:07] <bartzy> With a color-managed app on a Mac on a calibrated wide-gamut (more than P3) display.
[12:35:27] <thebombzen> so you *are* trying to simply retag it then
[12:35:41] <thebombzen> you're trying to change the tags without changing the pixel data
[12:35:42] <bartzy> just copied this from a discussion here before. since then I've been able to get everything to work pixel-perfect with my piping command in the pastebin link. My question is basically only if doing that is possible in one command and without piping. I'm trying to understand when piping is necessary
[12:36:42] <SimAV> bartzy, I assume that "convert" should be replaced by "re-tag"?
[12:36:58] <thebombzen> bartzy: how big's the video?
[12:37:11] <bartzy> thebombzen: theoretically if I export all frames from the input video to sRGB images, embed the "Display P3.icc" profile in each image, then "play" it, that's the exact desired behavior.
[12:37:37] <bartzy> thebombzen: between 5-20 seconds, 1284x2778
[12:38:17] <thebombzen> why sRGB?
[12:38:31] <SimAV> bartzy, a correct "conversion" would alter the pixel values to result in identical perception. As I understand, you want to change perception without changing the pixel values?
[12:38:32] <thebombzen> sRGB and BT.709 use the same primaries and matrix but not the same transfer function
[12:38:45] <thebombzen> so that could be the cause of the issue
[12:38:55] <bartzy> SimAV: Yes. convert was the wrong word in that sentence. I don't want to "match" the input colors to P3 so they will look the same on a P3 display. I want to make them more vivid
[12:39:02] <thebombzen> well, same primaries. sRGB does not have a matrix
[12:39:26] <thebombzen> why don't you, just, use avfilter then to make them more vivid
[12:39:34] *** Quits: Jan\2407 (~kvirc@104.204.200.116) (Ping timeout: 260 seconds)
[12:39:46] <bartzy> thebombzen: Yep! that's what I think as well. but I just couldn't get either swscale or zscale to convert to RGB (and sRGB transfer function) and then back to YUV on the same command :|
[12:40:01] <thebombzen> you totally can
[12:40:22] <bartzy> I don't just want to make them more vivid. I want to very explicitly make them exactly "more vivid" as if I apply P3 to them.
[12:40:40] <thebombzen> you can chain filters together, or just do it in one zscale command
[12:40:51] <bartzy> thebombzen: again I know it maybe sounds really silly to do as a professional workflow
[12:41:13] <bartzy> thebombzen: let me share the zscale commands I tried and why they didn't work
[12:41:36] <SimAV> bartzy, you said, your source files are pngs, but your command uses a .mov as input?
[12:41:47] <SimAV> bartzy, how did you create that .mov?
[12:42:04] <bartzy> SimAV: no, for this case the input is a ProRes 422HQ mov in BT709.
[12:42:25] <bartzy> I have some other cases where the input is a PNG sequence in sRGB but I have another command that's already working for that.
[12:42:35] <bartzy> so I'm only talking about the case where the input is 422HQ BT709
[12:42:58] <durandal_1707> are you reporting that reencoding to prores changes colors when decoding with ffmpeg?
[12:43:26] *** deepin is now known as ffmpeg-cc
[12:43:30] <durandal_1707> have you make sure that colors metadata are same before and after in prores file?
[12:43:35] <hyrcanus> ///19
[12:44:54] *** Joins: Jan\2407 (~kvirc@104.204.200.116)
[12:46:13] <bartzy> thebombzen: for example this zscale filter fails: https://pastebin.com/59yBgeBz
[12:46:22] <bartzy> code 1026: YUV color family cannot have RGB matrix coefficients
[12:46:34] <thebombzen> matrix is the output matrix
[12:46:39] <thebombzen> you'd want matrix=none
[12:46:45] <thebombzen> since RGB doesn't have a matrix
[12:47:00] <bartzy> so matrix=none:transfer=iec61966-2-1,format=yuv420p10le ?
[12:47:19] <thebombzen> well, no
[12:47:29] <thebombzen> srgb doesn't have a matrix, but whatever YUV you're using does
[12:47:40] <bartzy> durandal_1707: I don't think that's what I'm reporting. I just have some colorspace/transfer issues
[12:48:31] <bartzy> thebombzen: OK, so what one zscale command (or multiple) can do what we discussed?
[12:48:50] <bartzy> that's what I was trying for a couple of hours yesterday and eventually settled on the two ffmpeg commands with piping
[12:52:03] <thebombzen> this sounds easier to do in vapoursynth, tbh
[12:52:33] <thebombzen> the zscale filter is missing the sRGB binding
[12:52:37] <thebombzen> even though z.img supports it
[12:53:58] <thebombzen> er wait, I lied, that's what this is 61966-2-1
[12:54:15] <bartzy> yeah, I had to look that up in the zscale filter code to figure out as well
[12:54:41] <thebombzen> what color space do you actually want the displayed video to be tagged as
[12:54:56] <thebombzen> the ICC profile you're embedding, what is that color space
[12:55:54] <bartzy> the ICC profile is in RGB so there's no colorspace or something
[12:55:58] <bartzy> like your matrix=none remark
[12:56:43] <bartzy> Is there anything wrong with doing it with the pipe btw? Is it weird to use a pipe like that for purposes that are not reading from a device or writing to network, etc?
[12:56:46] <thebombzen> RGB still has primaries and transfer characteristics
[12:56:47] <thebombzen> just not a matrix
[12:57:27] <bartzy> thebombzen: Ah, sure. The Display P3 primaries are SMPTE432 (it's DCI-P3 primaries with a D65 whitepoint), and sRGB transfer function
[12:58:14] <thebombzen> I figure your master is in 16-bit prores so converting to 8-bit rgb to do color correction doesn't make sense to me
[12:58:28] <thebombzen> So, you just want it to be sRGB.
[12:58:50] <bartzy> I can convert it to 16-bit rgb to do color correction
[12:58:52] *** Joins: ne2k (~andy@212.250.187.98)
[12:58:55] *** Quits: jkwnki2 (~jkwnki@p2e5793bc.dip0.t-ipconnect.de) (Ping timeout: 252 seconds)
[12:59:10] *** Quits: jkwnki1 (~jkwnki@p2e5793bc.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[12:59:18] <bartzy> it's in 422HQ btw so I think it's 10-bit? ffprobe says: Stream #0:0(eng): Video: prores (HQ) (apch / 0x68637061), yuv422p10le(tv, bt709, progressive)
[13:00:07] <thebombzen> yea, that's 10-bit
[13:00:43] <thebombzen> why don't you just try retagging it as srgb intead of 709
[13:00:44] <thebombzen> see what happens
[13:01:55] <thebombzen> ffmpeg -i master.mov -map 0 -c copy -color_trc iec61966-2-1 test.mov
[13:02:40] <ne2k> how can I make ffmpeg output a single jpeg frame to stdout? I can do it to a file but trying to modify the things I'm finding online with image2pipe, I'm getting Unknown encoder 'jpeg' or 'jpg'
[13:02:42] <bartzy> and then take it to P3 (retag) in another command?
[13:08:29] <bartzy> thebombzen: thanks for the help btw. Do you see an issue/weirdness with using the pipe method which kinda just works?
[13:09:07] <thebombzen> I don't know what "works" means on your display. It's something to do with how you're completely stripping metadata and how you're converting it to RGB and back
[13:09:09] <bartzy> I tried searching for when one should use the pipe vs. a single chain of filterchains or something. really only found mentions of piping when it's for input or output devices, not just ffmpeg filters
[13:10:04] <thebombzen> I suspect that the bt709 tagged video as well is being converted to RGB with the 709 matrix, and then interpreted as some other matrix
[13:10:20] <thebombzen> I still don't see why you need RGB. try just outputting and inputting yuv422p10le
[13:11:03] <thebombzen> in your pipe that is
[13:11:06] <thebombzen> and see if that changes anything
[13:11:14] <thebombzen> if it does, that means that there's a matrix at fault here
[13:11:35] *** Joins: fling (~fling@user/fling)
[13:11:40] <ne2k> well I've discovered that -f image2 - outputs a jpeg file, but this seems rather to be by luck. how do I explicitly specify the format?
[13:11:56] <thebombzen> codec. something like -c png -f image2
[13:12:17] <thebombzen> also mjpeg is the jpeg encoder in FFmpeg
[13:12:54] <thebombzen> so in your case you'd do -c mjpeg -f image2pipe although I don't really know why you'd want to save JPEG frames
[13:13:22] <ne2k> thebombzen, I'm using it to grab a still from a network camera and pipe it something else
[13:13:31] <thebombzen> codec copy it then
[13:13:49] <thebombzen> also probably want to pipe into mpegts
[13:15:01] <thebombzen> well, not with jpeg I suppose, but in general it's a good idea
[13:15:02] <bartzy> thebombzen: what do you mean matrix at fault? where exactly? and regarding the pipe do you have an opinion? or if it works, it works... :|
[13:15:32] <thebombzen> I think if you have a production where you are highly sensitive to exact color then "it works" is not good enough if you lose precision
[13:16:16] <thebombzen> you also have no guarantee that the final video you use, which you mis-tagged intentionally, si going to look the same on these mobile devices you're targeting
[13:16:27] <bartzy> with YUV422 -> gbrp16 -> YUV420 10-bit, I don't think I lose precision?
[13:16:33] <ne2k> if I specify -c:v mjpeg -f image2 I get the same output as when I don't specify -c:v, o I guess that works. oddly, file seems to think it has three frames...
[13:16:44] <thebombzen> bartzy: how are you scaling the chroma planes?
[13:17:07] <thebombzen> ne2k: if the input is already jpeg then use -c copy
[13:17:15] <bartzy> thebombzen: Specifically in my very narrow usecase, I can kinda guarantee the player/client part. Only iOS from specific versions onwards
[13:17:21] <ne2k> thebombzen, the input is h264 over rtsp
[13:17:34] <thebombzen> ... why not just pass h264
[13:17:38] <bartzy> thebombzen: scaling from YUV422 -> gbrp16 or gbrp16 -> YUV420 10-bit ?
[13:17:41] <ne2k> thebombzen, because I want a still
[13:17:50] <thebombzen> -frames 1
[13:18:02] <thebombzen> bartzy: the chroma planes, yes
[13:18:08] <ne2k> thebombzen, yes... I'm doing that.
[13:18:19] <thebombzen> bartzy: you can't just go from 4:2:2 to RGB without going to 4:4:4 first
[13:18:32] <bartzy> zscale is doing it for me
[13:18:39] <thebombzen> and zscale defaults to bilinear
[13:18:41] <thebombzen> do you want that?
[13:18:48] <thebombzen> cause I believe you do not
[13:18:58] <thebombzen> a bilinear upscale followed by a bilinear downscale is not a no-op
[13:19:15] <bartzy> it's doing bilinear-something even when no resize is in the mix?
[13:19:23] <thebombzen> you are resizing the chroma planes
[13:19:29] <thebombzen> since 4:2:2 is subsampled
[13:19:34] <bartzy> I see. I didn't think about it
[13:19:43] <thebombzen> and that's the issue with your "it works" solution
[13:19:46] <bartzy> so what do I want here?
[13:20:03] <thebombzen> Something as highly color-senitive as your particular application should be done properly
[13:20:25] <thebombzen> If you're gonna go "it works" then you're basically making a statement that you don't care about all those things you didn't think of cause what you saw at that time looked okay
[13:20:33] <thebombzen> which is fine, but I suspect it's not what your end goal is
[13:20:44] <bartzy> yeah I just made the "it works" comment as a question for the pipe method
[13:20:50] <bartzy> and you're right, it's not my end goal
[13:20:55] <thebombzen> you still haven't explained why you have to convert it to rgb
[13:21:26] <thebombzen> just leave it as yuv422p10le, and if that makes it stop working, then it gives you information
[13:21:38] <bartzy> so can I still use zscale here and the YUV422 -> RGB -> YUV420 10-bit, but tell zscale to use something other than bilinear that is a no-op from YUV422 to RGB to YUV420 ?
[13:21:43] <thebombzen> no, just
[13:21:43] <thebombzen> don't
[13:21:53] <thebombzen> you still haven't explained why you have to convert it to rgb
[13:21:55] <bartzy> OK. I'll try now. But still with the pipe method?
[13:22:02] <thebombzen> sure
[13:22:08] <bartzy> will try now
[13:22:31] <thebombzen> and no, upscales and then downscales are never no-ops
[13:22:40] <thebombzen> but bilinear is particularly not good
[13:25:04] <bartzy> thebombzen: trying to construct my pipe command with YUV422 only. Not sure how to do the first part though. When going from yuv422 -> gbrp16 with zscale, something "good" happens with the matrix/transfer/primaries conversion. I don't exactly know what to give to zscale as matrix/primarties/transfer
[13:25:18] <thebombzen> nothing "good" happens
[13:25:31] <bartzy> lol
[13:25:37] <roxlu> I'm updating some deprecated code and I'm looking into `av_init_packet()` which shouldn't be used anymore. Previously I had a stack var `AVPacket pkt`, then called `av_packet_init(&pkt)`. What is the "new" way to init an AVPacket?
[13:25:43] <thebombzen> just try it without forcing the pixel format to gbrp
[13:26:18] <roxlu> Do I use `av_packet_alloc()` instead?
[13:26:40] <SimAV> thebombzen, if you copy-fill/discard (dumbest possible interpolation) you can have a no-op for at least a few values ;)
[13:26:56] <bartzy> thebombzen: ffmpeg -i 422hq_master.mov -vf zscale -f rawvideo - | ffmpeg -f rawvideo -pixel_format yuv422p10le -video_size 1284x2778 ... - that first ffmpeg seems kinda useless?
[13:27:28] <thebombzen> bartzy: yup, you're just stripping metadata
[13:27:31] <thebombzen> try it and see what happens
[13:27:40] <thebombzen> if you get the same colors, contratz! drop it
[13:27:44] <thebombzen> if you don't, then you know why
[13:30:08] <thebombzen> I suspect your BT.709-tagged video is having its matrix inverted properly when being converted to RGB, but then when you then did RGB -> YUV again it used a different matrix, so you ended up changing the pixel data
[13:30:44] <bartzy> I'm not getting the same colors. sharing an image
[13:30:45] <thebombzen> if this is what you want you can just do this with zcale=min=709:m=bt2020c
[13:31:19] <thebombzen> no need for a pipe
[13:32:22] <thebombzen> I do need to sleep tho
[13:32:38] <bartzy> lol ok :)
[13:32:46] *** Quits: SimAV (~SimAV@31.16.251.8) (Ping timeout: 260 seconds)
[13:32:53] <bartzy> this is the output from the pipe yuv-only method: https://we.tl/t-TxbXHNi3ZP , on the right.
[13:33:29] <bartzy> the left is the P3 image that is my reference. I want to get to these exact colors (which my YUV422 -> RGB -> YUV420 pipe method is achieving exactly).
[13:33:42] *** Quits: causasui (~causasui@c-68-60-125-136.hsd1.mi.comcast.net) (Ping timeout: 258 seconds)
[13:36:29] *** Joins: bradh (~bradh@ppp115-205.static.internode.on.net)
[13:38:56] *** Quits: ivanich (~ivanich@45-140-123-239.broadband.tenet.odessa.ua) (Quit: Konversation terminated!)
[13:38:57] *** Joins: ivanich_ (~ivanich@45-140-123-239.broadband.tenet.odessa.ua)
[13:39:32] <roxlu> Why was the `av_packet_init()`  deprecated? Now it seems you have to use `av_packet_alloc()` which means there can potentially be many allocations?
[13:40:19] <JEEB> roxlu: the idea is that your component or whatever has a single allocated AVPacket if you need one
[13:40:38] *** Quits: bradh (~bradh@ppp115-205.static.internode.on.net) (Quit: Konversation terminated!)
[13:40:39] <JEEB> then unreffing is all you need to do when you no longer need the specific packet
[13:40:53] *** Joins: bradh (~bradh@ppp115-205.static.internode.on.net)
[13:41:09] <roxlu> Ah that's great, thanks.
[13:41:37] <roxlu> Though I still need to call av_packet_free()? or only unref it?
[13:42:44] <haasn> Moving this here; I'm not getting any displaymatrix side data on my decoded frames (even though `ffprobe` on the same sample shows them). This is my decoding loop: https://0x1.st/Lu.txt
[13:42:46] <JEEB> you only free it when you shut down that component
[13:42:47] <haasn> What am I doing wrong?
[13:42:53] <bartzy> thebombzen: `min=709:m=bt2020c` doesn't work btw. output is extremely vivid/bright colors. I think it has to do with the transfer function. zscale doesn't allow bt2020c with sRGB transfer function. says it's invalid (I don't think so).
[13:43:02] <haasn> and my setup code: https://0x1.st/LU.txt
[13:43:05] <roxlu> JEEB: ok, thanks
[13:44:16] <thebombzen> bartzy: did you combo it with your pipe thing
[13:44:22] <thebombzen> cause if you did, then don't, cause you're doing it twice
[13:44:35] <JEEB> haasn: does ffprobe and your API code utilize the same FFmpeg version? does it actually show the side data with f.ex. JSON output?
[13:44:54] <haasn> yes to former, how can I tell for latter?
[13:45:08] <JEEB> `ffprobe -of json -show_streams -show_format -show_frames -i INPUT > dump.json`
[13:45:14] <thebombzen> if you actually want to change how it's displayed then you really should just be changing the pixel data and tagging it properly rather than just trying to cludge together incorrect tags
[13:45:17] <JEEB> there was some way of limiting the amount of frames
[13:45:21] <bartzy> I didn't: `ffmpeg -i scratch/masters/0284/master/0284.mov -vf zscale=min=709:m=bt2020c,format=yuv420p10le -colorspace bt2020c -color_primaries smpte432 -color_trc iec61966-2-1 -c:v libx265 -crf 28 -preset fast output.mov`
[13:45:32] <JEEB> I never recall with ffprobe :P
[13:46:22] <haasn> JEEB: https://0x1.st/LE.txt
[13:46:25] *** Quits: nikos (~nikos@104.248.205.38) (Quit: "Quit")
[13:47:00] <haasn> seems like that's attached to the stream, but not the frames
[13:47:46] *** Joins: nikos (~nikos@104.248.205.38)
[13:47:46] <bartzy> thebombzen: Changing the pixel data and then tag properly - Tagging properly is easy. Changing the pixel data - I know what I want - BT709 that will look exactly the same as if I would have converted it to sRGB and showed side-by-side. Then, tag it with bt2020c + sRGB transfer + P3 primaries.
[13:48:20] <thebombzen> that's not tagging it properly
[13:49:43] *** Joins: olspookishmagus (~pookie@snf-137798.vm.okeanos.grnet.gr)
[13:50:20] <haasn> JEEB: https://0x1.st/LG.json
[13:50:27] <bartzy> if the input was a sequence of PNGs in sRGB, here's a working command that provides the exact output I want: https://pastebin.com/erqZ69KQ . No precision loss as far as I can tell (besides obviously RGB to YUV420 but I have to use 420 at the delivery end.
[13:50:34] <roxlu> JEEB: do you know why ffmpeg moved away from av_packet_init()?
[13:51:06] <bartzy> so that's basically my issue, I think. Taking a YUV422 BT709 stream and changing the pixel data to look exactly like sRGB would for that pixel value in BT709.
[13:53:12] *** Parts: ne2k (~andy@212.250.187.98) (Ex-Chat)
[13:53:42] <haasn> on my end it's not even attached to the packet though
[13:53:48] <haasn> av_packet_get_side_data(packet, AV_PKT_DATA_DISPLAYMATRIX, &size) // always NULL
[14:01:06] <haasn> this is weird
[14:01:18] <haasn> ff_decode_frame_props gets called but even inside ffprobe it doesn't have the pkt side data during this call
[14:02:14] <bartzy> thebombzen: I think my core issue is that zscale doesn't like `matrix=bt2020c:transfer=iec61966-2-1`. I'll try to catch you later. thanks.
[14:02:43] <haasn> av_stream_get_side_data finds it, but ffprobe never calls that
[14:03:24] <haasn> oh it does
[14:03:37] <haasn> so I guess my issue is that AVStream side data does not get forwarded to the packets/frames in that stream
[14:04:52] <haasn> is this a bug? where is stream side data supposed to be handled in ffmpeg?
[14:05:13] *** Quits: sfan5 (~sfan5@user/sfan5) (Quit: Quit)
[14:05:27] *** Joins: sfan5 (~sfan5@user/sfan5)
[14:05:29] <durandal_1707> haasn: provide command line and input?
[14:06:34] <haasn> durandal_1707: https://0x1.st/Lj.mp4
[14:06:39] <durandal_1707> bartzy: please read zscale and zimg documentation
[14:06:49] <haasn> durandal_1707: ffprobe -read_intervals "%+#1" -of json -show_streams -show_format -show_frames -i Lj.mp4
[14:07:00] <haasn> you can see that the displaymatrix side data is attached to the stream but not the frame
[14:07:06] <bartzy> durandal_1707: I did (as far as I can tell), and also tried to read some of the relevant zimg/vf_zscale.c source code
[14:07:25] <haasn> this is very counter-intuitive to me, I was expecting this side data to propagate to the frames (the way it does for side data on packets)
[14:07:59] <haasn> it's also very annoying because my API only takes AVFrame and does not know anything about the streams they came from
[14:08:08] <haasn> so losing this information along the way is, well, an issue
[14:09:13] *** Quits: bradh (~bradh@ppp115-205.static.internode.on.net) (Quit: Konversation terminated!)
[14:16:48] *** Bertl_zZ is now known as Bertl
[14:16:55] *** Parts: gucky-chat-laden (~gucky-cha@46.41.28.214) ()
[14:17:11] *** Joins: gucky-chat-laden (~gucky-cha@46.41.28.214)
[14:17:52] *** Quits: jerome- (~jerome@78.193.84.130) (Remote host closed the connection)
[14:18:13] <durandal_1707> haasn: hmm, it av_packet_get_side_data() return always (nil)
[14:18:30] <haasn> av_stream_get_side_data finds it
[14:19:03] <durandal_1707> but that are different things
[14:19:35] <durandal_1707> shouldnt there be a way to copy it from stream to packets?
[14:20:32] <haasn> I can't find any
[14:22:48] <JEEB> so it's container stream level metadata I guess, but yea it's not fun when in some cases you auto-get it at AVFrames and in other cases not
[14:28:42] <haasn> JEEB: think I should open a bug for this?
[14:29:04] <haasn> I mean why does AV_FRAME_DATA_DISPLAYMATRIX even exist if frames never get it
[14:29:35] <haasn> I remember we used to have a similar issue for HDR metadata where it was changed so that frames get it as well
[14:32:31] *** Joins: jerome- (~jerome@78.193.84.130)
[14:33:45] <bartzy> thebombzen: so I have some weird updates: I literally tried the following command while changing `matrix` in zscale to every possible option, and testing to see if I get the desired colors in the video:
[14:34:46] <bartzy> `ffmpeg -i 422hq_bt709_input.mov -vf zscale=matrix=bt2020c,format=yuv420p10le -colorspace bt2020c -color_primaries smpte432 -color_trc iec61966-2-1 -c:v libx265 -crf 28 -preset fast output.mov`
[14:35:46] <bartzy> surprisingly, `matrix=470bg`, `matrix=170m` and `matrix=fcc` all provided perfect color results. Just like my previous pipe with YUV422 -> RGB -> YUV420-10-bit did. what does that even mean...
[14:38:08] <bartzy> what is even `fcc` as a color matrix :|
[14:40:37] <hyrcanus> if it's any consolation, that confuses me even more than you
[14:40:58] *** Joins: Vonter (~Vonter@user/vonter)
[14:42:13] <durandal_1707> haasn: which commit fixed it for HDR?
[14:44:46] *** Quits: sfan5 (~sfan5@user/sfan5) (Quit: Quit)
[14:45:23] *** Quits: Vonter (~Vonter@user/vonter) (Ping timeout: 258 seconds)
[14:45:53] <haasn> durandal_1707: oh I think I misremembered and that was only about the metadata persisting inside the codec
[14:46:02] <haasn> not about copying container-level metadata to frames
[14:47:01] <bartzy> hyrcanus: lol you meant me?
[14:47:02] *** Joins: sfan5 (~sfan5@user/sfan5)
[14:47:11] <durandal_1707> haasn: cant you just use stream side data and override it with frame when available?
[14:47:15] <haasn> indeed looking at e.g. The World in HDR.mkv it has the same issue, mastering metadata is attached to the container (.mkv) but not the frames itself
[14:47:18] <hyrcanus> yes sorry just trying to lighten the mood
[14:47:22] <haasn> durandal_1707: I can but that requires invasive API change
[14:47:30] <haasn> my current API only ingests AVFrame and does not know anything about streams
[14:47:31] *** Quits: foonix (1004@ip-86-49-65-192.net.upcbroadband.cz) (Quit: leaving)
[14:47:36] <durandal_1707> ok
[14:48:47] <bartzy> hyrcanus: sure no worries :)  I'm literally this dog right now: https://i.kym-cdn.com/entries/icons/original/000/008/342/ihave.jpg
[14:49:16] <haasn> durandal_1707: also shouldn't the container metadata override the frame metadata if both are present?
[14:49:20] <bartzy> I think that's an honest depiction of me throughout my ffmpeg journey in the last few weeks
[14:49:22] <haasn> not sure what makes more sense there
[14:50:47] <haasn> I remember mpv deciding this same question but I can't remember where in the code that decision was made
[14:51:25] <durandal_1707> haasn: logically, it should be other way around
[14:54:38] <JEEB> some containers are where metadata trumps codec level stuff, and then you have others where the codec level stuff is to be trusted - it's a fun thing
[14:54:53] <JEEB> like for example if you have a H.264 stream with incorrect aspect ratio, and then someone remuxed it with the correct value
[14:55:05] <JEEB> the video stream will still have the incorrect one, but the container level one will be correct :D
[14:55:09] <JEEB> (this with mkv/mp4 f.ex.)
[14:56:18] *** Joins: foonix (1004@ip-86-49-65-192.net.upcbroadband.cz)
[14:57:42] <haasn> hang on
[14:57:49] <haasn> if HDR metadata is still only applied to the stream and not the frames
[14:57:56] <haasn> how can filters like vf_tonemap even operate properly?
[14:58:04] <haasn> since they also only ingest AVFrame with no clue about the stream they come from
[15:00:23] <durandal_1707> by setting options
[15:00:27] <haasn> it calls ff_determine_signal_peak() which only looks at frame-level data
[15:00:30] <JEEB> yup
[15:00:49] <JEEB> I think H.264/HEI sei things are in avpackets
[15:00:51] <haasn> I'm now 99.9% sure this is a bug and ffmpeg should be forwarding this side data to the frames
[15:00:59] <JEEB> so they then get converted by decoder into AVFrame stuff
[15:01:01] <JEEB> I think?
[15:01:01] <haasn> because even its own internal filters get it wrong
[15:01:34] <JEEB> so it Might Just Work with codec level SEI
[15:01:43] <JEEB> but then if you add the same stuff into container?
[15:01:44] <JEEB> :D
[15:02:10] <JEEB> but yea, I agree this should be overall looked end-to-end
[15:02:20] <JEEB> since people become accustomed to one thing, and then it doesn't hold true
[15:02:54] <JEEB> best intentions, too wide range of things etc
[15:03:23] *** Quits: pntaylor (~quassel@101.113.66.204) (Ping timeout: 264 seconds)
[15:03:25] *** Joins: pntaylor_ (~quassel@2405:6e00:48d:f967::3)
[15:05:03] *** Quits: nillyhan (~00000000@user/nillyhan) (Quit: Ping timeout (120 seconds))
[15:05:22] *** Joins: nillyhan (~00000000@user/nillyhan)
[15:13:22] *** Quits: pntaylor_ (~quassel@2405:6e00:48d:f967::3) (Ping timeout: 258 seconds)
[15:16:35] *** Quits: yeirr (~yeirr@user/yeirr) (Ping timeout: 264 seconds)
[15:16:40] *** Joins: pntaylor (~quassel@101.113.157.105)
[15:17:42] <bartzy> Anyone has a clue if a colorspace of bt470bg, transfer + primaries of bt709 makes any sense? Is it some "formal" definition of something?
[15:17:49] <bartzy> I'm trying to figure out why it gives me correct results
[15:18:41] <bartzy> I think it's just a bug in ffmpeg/zscale or some unknown (to me) default value that is somehow injected into the pipeline because of 470bg
[15:21:05] <durandal_1707> bartzy: how it is bug? if you just want more vivid colors?
[15:21:35] <bartzy> I don't want "just more vivid colors". But a very specific P3 colorspace
[15:22:03] <bartzy> and for some reason re-tagging BT709 as bt2020c + P3 primaries + sRGB transfer (which is Display P3 transfer) doesn't give the correct results.
[15:22:29] <durandal_1707> bartzy: first, is your input P3?
[15:22:32] <bartzy> but going from BT709 matrix to BT470BG (still with BT709 primaries and transfer!), and then re-tagging as BT2020c + P3 Primaries + sRGB transfer - that does work
[15:22:44] <bartzy> durandal_1707: No. It's BT709
[15:23:31] <durandal_1707> so what cmd line you use to convert/transfer to P3?
[15:24:18] <bartzy> the one that makes sense but provides a wrong result, or the one that doesn't make sense but provides the correct result? :)
[15:25:01] <durandal_1707> first one
[15:25:27] <bartzy> makes sense, wrong result: `ffmpeg -i 422hq_bt709_input.mov -vf zscale,format=yuv420p10le -colorspace bt2020c -color_primaries smpte432 -color_trc iec61966-2-1 -c:v libx265 -crf 28 -preset fast output.mov`
[15:25:53] <bartzy> doesn't make sense, correct result: `ffmpeg -i 422hq_bt709_input.mov -vf zscale=matrix=470bg,format=yuv420p10le -colorspace bt2020c -color_primaries smpte432 -color_trc iec61966-2-1 -c:v libx265 -crf 28 -preset fast output.mov`
[15:26:26] <bartzy> diff between them is just the conversion from input bt709 to matrix=470bg in zscale
[15:26:47] <durandal_1707> your both comamnds are nonesense
[15:27:20] *** Joins: yeirr (~yeirr@user/yeirr)
[15:27:41] <bartzy> I have a hunch - Is it possible that with specifying just `zscale,filter=yuv420p10le`, ffmpeg doesn't let zscale do the YUV->YUV conversion and instead is using swscale to do it, and in the second example, it is using zscale because I gave it a matrix?
[15:27:46] <durandal_1707> you convert from one to another colorspace but tags with third one
[15:28:23] <bartzy> durandal_1707: Well that's the second command that doesn't make sense. In the first command I don't convert. Just BT709 as input, and tagging as P3.
[15:28:27] <durandal_1707> zscale,format=... does not use swscale
[15:28:56] <durandal_1707> bartzy: that does not makes sense to tag something as P3 when it is bt709
[15:29:24] <bartzy> durandal_1707: again it depends on my need which I described
[15:29:53] <bartzy> I thought about the zscale no-op thing because of this comment from sekrit: https://github.com/sekrit-twc/zimg/issues/109#issuecomment-515552048
[15:31:28] *** Quits: sfan5 (~sfan5@user/sfan5) (Quit: Quit)
[15:32:05] *** Joins: sfan5 (~sfan5@user/sfan5)
[15:32:48] <bartzy> durandal_1707: that remark is not relevant in my case where I do add `,format=...` ?
[15:34:00] <durandal_1707> yes
[15:35:30] <durandal_1707> bartzy: use -v debug, and you will see if scale in inserted
[15:35:54] <durandal_1707> also now is there option to disable auto insertion of filters like scale
[15:37:27] <bartzy> why is it auto-inserted? And what's the option? :)
[15:37:54] <durandal_1707> bartzy: it there is no path from one filter to another
[15:38:12] <durandal_1707> say one filter supports only rgb24 format and another only yuv420p format
[15:38:57] <bartzy> ah, nice. so like zscale which only supports planar rgb and you want rgb24 for example
[15:39:53] <durandal_1707> bartzy: yes
[15:39:58] <durandal_1707> -noauto_conversion_filters
[15:40:00] <durandal_1707> is option
[15:40:37] <durandal_1707> then to convert from planar rgb from zscale to packed one you need to add explicit scale,format filter
[15:40:40] *** Joins: minimal (~minimal@user/minimal)
[15:42:58] *** Quits: sfan5 (~sfan5@user/sfan5) (Quit: Quit)
[15:43:13] *** Joins: sfan5 (~sfan5@user/sfan5)
[15:47:13] <iconoclasthero> is there a quick and dirty way to try to reduce background hiss from e.g., a bootleg album?
[15:52:08] <iconoclasthero> here's the file (but you need to be a member of LL): https://www.shnflac.net/index.php?page=torrent-details&id=db4f79a019f3c91da3564702eead23c7b7f5d0e2
[15:55:49] <durandal_1707> seriously, need to download full album?
[16:07:42] *** Quits: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[16:08:17] *** Joins: Vonter (~Vonter@user/vonter)
[16:11:33] *** Joins: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de)
[16:12:47] *** Quits: Vonter (~Vonter@user/vonter) (Ping timeout: 258 seconds)
[16:14:05] *** Quits: nillyhan (~00000000@user/nillyhan) (Ping timeout: 260 seconds)
[16:17:36] *** Joins: SimAV (~SimAV@bt-nac-q107.nac.uni-bayreuth.de)
[16:20:55] *** Joins: nillyhan (~00000000@user/nillyhan)
[16:21:11] <roxlu> JEEB: do you know why ffmpeg moved away from av_packet_init()? 1
[16:21:27] <roxlu> oh sorry ... pressed enter on accident
[16:22:51] *** Joins: vqueiroz (uid340368@id-340368.hampstead.irccloud.com)
[16:31:58] *** Quits: cmp97 (~cmp@lputeaux-658-1-177-87.w92-154.abo.wanadoo.fr) (Ping timeout: 260 seconds)
[16:38:12] <JEEB> roxlu: to get sizeof(AVPacket) away from teh API
[16:38:34] <JEEB> since alloc/unref resets the state of a given struct
[16:39:25] <roxlu> why would using sizeof() be an issue?
[16:40:00] <JEEB> if only the library allocates the structure, it's easier to add stuff to the struct
[16:41:45] <roxlu> ok, sorry for firing these questions, but I'm trying to understand the reasoning... using sizeof() doesn't prevent adding new stuff to the struct right?
[16:46:16] <JEEB> your sizeof in your API client will differ to the one that the library might expect
[16:46:24] <JEEB> since the sizeof is from when you last rebuilt
[16:46:36] *** Quits: sfan5 (~sfan5@user/sfan5) (Remote host closed the connection)
[16:46:52] *** Joins: sfan5 (~sfan5@user/sfan5)
[16:47:32] *** Quits: sfan5 (~sfan5@user/sfan5) (Client Quit)
[16:47:51] *** Joins: sfan5 (~sfan5@user/sfan5)
[16:48:29] *** Parts: gucky-chat-laden (~gucky-cha@46.41.28.214) ()
[16:49:42] *** Joins: gucky-chat-laden (~gucky-cha@46.41.28.214)
[17:18:06] *** Joins: cmp10 (~cmp@lputeaux-658-1-177-87.w92-154.abo.wanadoo.fr)
[17:21:16] *** Quits: Fohsap (~Muimi@2001:19f0:6001:e4d:5400:3ff:fe41:8d5b) (Ping timeout: 252 seconds)
[17:21:56] *** Joins: bradh (~bradh@2001:8004:1400:c0b:284a:a287:2562:2b55)
[17:27:35] *** Quits: SimAV (~SimAV@bt-nac-q107.nac.uni-bayreuth.de) (Ping timeout: 260 seconds)
[17:34:58] *** Joins: superkuh (~superkuh@user/superkuh)
[17:37:08] <superkuh> Hi. I am trying to concatenate three .mp4 videos I just encoded exactly the same way. I am trying to use "ffmpeg -f concat -safe 0 -i mylist.txt -c copy output.mp4" where mylist.txt contains a newline separated list of file paths to the mp4 files without spaces or anything that'd mess with it.
[17:37:26] <superkuh> But no matter what I try I just get, "[concat @ 0x55a1cef87f40] Line 1: unknown keyword '/home/superkuh/videos/World.of.Tomorrow-HD-1.mp4'"
[17:37:54] <superkuh> Where that is the first line of mylist.txt. I am attempting to follow the instructions in example #2 from, https://stackoverflow.com/questions/7333232/how-to-concatenate-two-mp4-files-using-ffmpeg
[17:38:00] <hyrcanus> doesn't mylist need to have lines in the form: file 'myvideo.mp4'
[17:38:05] *** Quits: mickey8 (~user@user/mickey) (Quit: Ping timeout (120 seconds))
[17:38:13] <superkuh> Oh duh.
[17:38:23] <superkuh> Thanks for pointing that out.
[17:38:26] <hyrcanus> np
[17:38:37] *** Joins: mickey8 (~user@user/mickey)
[17:38:49] <hyrcanus> it would be more convenient if it didn't!
[17:39:31] <hyrcanus> what *else* is going to go into a concatenation list besides a file to concatenate?
[17:39:32] <superkuh> Wow. That was near instant. It worked. Thanks.
[17:39:36] <hyrcanus> a cookie recipe?
[17:44:40] *** Joins: Flabb (~Flabb@89.169.42.92)
[17:52:04] *** Quits: vqueiroz (uid340368@id-340368.hampstead.irccloud.com) (Ping timeout: 258 seconds)
[17:52:05] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[17:54:08] *** Joins: vqueiroz (uid340368@hampstead.irccloud.com)
[17:56:28] *** Quits: nillyhan (~00000000@user/nillyhan) (Ping timeout: 252 seconds)
[18:16:58] <roxlu> JEEB: So lets say in general the issue is: if I build my app that uses a sizeof() of some type from a lib with version V0, then it could get e.g. 64bytes, but then the lib gets updated and the type changes to e.g. 128bytes, then my app would still think it's 64bytes?
[18:17:10] <JEEB> yes
[18:17:17] <JEEB> and then you pass that 64 byte struct to the API
[18:17:28] <JEEB> API expects there to be more fields
[18:17:29] <JEEB> boom
[18:18:05] <roxlu> Ha I see! I actually had that issue long time ago with libpng ... took me a week to figure out why my app was crashing (ofc. I was a lot less experienced then)
[18:18:44] <roxlu> This is only relevant when dynamically linking right?
[18:19:29] <sfan5> yes
[18:23:18] <roxlu> Thanks for explaining this!
[18:40:03] *** jake[m] is now known as babysurgery[m]
[18:45:26] *** Quits: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[18:46:30] *** Quits: kib (~kib@user/kib) (Ping timeout: 258 seconds)
[18:46:30] *** Joins: Yonle (~Yonle@user/yonle)
[18:46:44] *** Joins: kib (~kib@user/kib)
[18:52:39] *** Quits: vqueiroz (uid340368@hampstead.irccloud.com) (Quit: Connection closed for inactivity)
[18:55:03] *** Joins: zerodefect (~zerodefec@cpc78637-glfd7-2-0-cust61.6-2.cable.virginm.net)
[18:59:05] <zerodefect> Using the C API, I want to preserve some custom data through the decode process (avcodec_send_packet/avcodec_receive_frame).  I see AVPacket has an 'opaque' data member but I don't see how to tie that to an AVFrame.
[18:59:22] <zerodefect> I did find this, but it doesn't feel very nice: https://stackoverflow.com/questions/51856505/user-custom-private-data-in-avpacket
[18:59:39] <zerodefect> I'd have to write some serialise/deserialise functions to store as string.
[19:10:27] *** Joins: LeoNice1981 (~LeoNice19@cpe-173-175-126-71.satx.res.rr.com)
[19:11:23] *** Joins: blaze (~blaze@user/blaze)
[19:14:58] <JEEB> zerodefect: AVFrame::opaque_ref also exists
[19:15:03] <bartzy> Can anyone recommend an accurate video player for the mac with regards to colors?
[19:15:16] *** Quits: softworkz (~softworkz@user/softworkz) (Killed (lead.libera.chat (Nickname regained by services)))
[19:15:22] *** Joins: softworkz (~softworkz@user/softworkz)
[19:15:23] <bartzy> QuickTime Player has this weird gamma issues on some files
[19:15:30] *** Quits: LeoNice1981 (~LeoNice19@cpe-173-175-126-71.satx.res.rr.com) (Ping timeout: 260 seconds)
[19:16:00] <JEEB> QT has a different result on effectively BT.1886 transfer content
[19:16:19] <galad> well the difference is minimal
[19:16:20] <JEEB> granted, BT.1886 by itself is a relatively new (2011 or so?)
[19:16:37] <JEEB> QT does an inverse BT.709 with then some gamma adjustment
[19:16:43] <JEEB> while iOS f.ex. just does BT.1886
[19:16:47] *** Quits: Arokh (~MoveAlong@ip-88-153-209-30.hsi04.unitymediagroup.de) (Ping timeout: 240 seconds)
[19:16:52] <minimal> galad: yes I'm different :-)
[19:17:11] <galad> minimal: hello, you must be a friend of while and another :)
[19:17:11] *** Quits: Yonle (~Yonle@user/yonle) (Ping timeout: 264 seconds)
[19:17:39] <bartzy> JEEB: is BT.1886 considered "BT709 2.4 gamma" ?
[19:18:03] <JEEB> let me quote teh spec
[19:18:19] <bartzy> what should a mac user use to test videos then
[19:18:42] <JEEB> http://up-cat.net/p/2c189416
[19:19:11] <hyrcanus> linux
[19:19:14] <galad> nothing, get a reference monitor
[19:19:49] <JEEB> I'd probably go for something libplacebo based, or mpv :P
[19:20:07] <JEEB> although for latest libplacebo I think just plplay exists
[19:20:35] <JEEB> anyways, that is what the spec says f.ex. for the BT.709 transfer value
[19:20:36] <galad> yes, but that requires a properly calibrated display profile if I remember correctly, at least used too
[19:20:48] *** Quits: bradh (~bradh@2001:8004:1400:c0b:284a:a287:2562:2b55) (Quit: Konversation terminated!)
[19:20:52] <JEEB> you can just say your screen is of type X
[19:20:59] <JEEB> if you want the conversion to sRGB f.ex.
[19:21:05] <JEEB> instead of leaving the transfer untouched
[19:21:14] *** Joins: Nact (~l@2a02:2788:11c4:6e6:cebc:f487:efd8:173)
[19:21:29] <JEEB> I think libplacebo might have opted for sRGB transfer by default
[19:21:34] <galad> anyway I remember from that loooong mpv github thread that the difference wasn't noticeable
[19:23:28] <haasn> what galad said
[19:23:42] <bartzy> I still don't quite understand if QuickTime Player supports 1-2-1 or not
[19:24:29] <JEEB> what is the first, second and third :P
[19:25:16] <bartzy> it's the quicktime code-point thing - matrix-transfer-primaries
[19:26:33] <JEEB> sp BT.709, unspecified transfer, BT.709
[19:26:35] <JEEB> *so
[19:26:41] <JEEB> (see H.273 for the values)
[19:26:56] <JEEB> or at least I assume that's what they are and not something custom :P
[19:27:38] <JEEB> but yea, unspecified probably means BT.709 or something by default, which thus leads to what should be BT.1886
[19:27:46] <JEEB> but QT does the inverse BT.709 thing
[19:28:02] <bartzy> yes, that's right
[19:28:15] <JEEB> to be honest with QT I'd just output with sRGB transfer and specify that :P
[19:28:18] <bartzy> so the answer is just "Don't use QT on Mac for checking if colors are 'right'" ?
[19:29:08] <JEEB> of course with the sRGB transfer then you might hit issues with other players, but at least it would give a consistent output with iOS and QT :P
[19:29:26] <bartzy> yeah but I'm having that whole P3 shenanigan issue from yesterday if you recall. And I'm now figuring out that I was using QT to test against a P3 reference image to see if the colors match, and perhaps QT is completely wrong here.
[19:29:58] <bartzy> I really don't mind about QT. It's not something users will view in. Only iOS will be used. But I don't want to test on iOS every second
[19:30:13] <JEEB> then check with something that does BT.1886
[19:30:16] <JEEB> like mpv or something :P
[19:30:20] <JEEB> or plplay
[19:30:26] <bartzy> mpv is a good guy? :p
[19:30:55] <bartzy> I had a thought (obviously wrong) that QT on Mac and AVFoundation on iOS would behave the same. Wrong! :)
[19:30:59] *** Quits: wyatt8740 (~wyatt8740@23.81.114.227) (Remote host closed the connection)
[19:31:18] <JEEB> yes, QT and AVFoundation on it do it the pre-BT.1886 way
[19:31:27] <JEEB> *on it -> on Macs
[19:31:30] <bartzy> why don't they change
[19:31:35] <JEEB> iOS on the other hand seems to have gotten newer code
[19:31:40] <JEEB> which follows BT.1886
[19:31:54] <haasn> plpay can't load monitor ICC profiles
[19:32:06] <haasn> mpv only does BT.1886 emulation if you have a device ICC profile
[19:32:13] <haasn> and even then I kinda trust plplay more than mpv these days
[19:32:25] <bartzy> but if it doesn't load the monitor profile then what's the point?
[19:32:28] <haasn> $somebody should really get back to vo_gpu_next
[19:32:40] <haasn> bartzy: exactly.
[19:32:46] <haasn> well it can load embedded ICC profiles in images :)
[19:32:49] <bartzy> so, mpv?
[19:32:54] <bartzy> lol I'm a bit lost
[19:32:57] <haasn> you can also configure the target colorspace explicitly (e.g. DCI-P3)
[19:33:01] <JEEB> yea
[19:33:21] *** Joins: wyatt8740 (~wyatt8740@149.164.111.65)
[19:33:22] <bartzy> I'm using IINA which is a Mac app that's using mpv internally. But I'll install mpv directly and just use that
[19:33:28] <JEEB> haasn: yea I hate myself that I have my hands full on with so much random crap :P feels like I never get to the stuff I actually would like to hack on
[19:33:44] <bartzy> is mpv usually used from the command-line or there's some nicer GUI for opening it from finder files etc?
[19:33:51] <JEEB> it has a bundle
[19:33:59] *** softworkz is now known as Guest3018
[19:33:59] *** Quits: Guest3018 (~softworkz@user/softworkz) (Killed (sodium.libera.chat (Nickname regained by services)))
[19:34:00] *** Joins: softworkz (~softworkz@user/softworkz)
[19:34:00] <JEEB> at least part of the build system
[19:34:11] <JEEB> but I think homebrew decided it's not gonna enable that
[19:34:21] <JEEB> so brew is not gonna give you that, lol
[19:34:40] <JEEB> we might get official builds later, I need to get to working on sysroots :P
[19:35:09] <bartzy> so brew install mpv?
[19:35:12] <bartzy> and just use the cli?
[19:36:23] <JEEB> that should give you a binary. there are some 3rd party builders
[19:36:39] <haasn> https://github.com/libsdl-org/SDL/issues/4279 https://github.com/glfw/glfw/issues/1893
[19:36:41] <haasn> crickets
[19:37:20] <JEEB> yea
[19:37:29] <JEEB> the usual case of "if you don't do it yourself nobody else will"
[19:37:43] <JEEB> which is why I just get more and more shit on my TODO q_q
[19:37:46] <haasn> there's a PR for the SDL issue but it's unmerged for.. no reason
[19:38:12] <bartzy> JEEB: Are you free for my colorspace craziness perhaps? :)
[19:40:22] <bartzy> understood :P
[19:40:53] *** Joins: SimAV (~SimAV@ip1f10fb08.dynamic.kabel-deutschland.de)
[19:41:41] *** Joins: Arokh (~MoveAlong@ip-88-153-209-30.hsi04.unitymediagroup.de)
[19:42:08] <JEEB> &34
[19:44:30] <bartzy> so when ffprobe says bt709 (for matrix/transfer/primaries), does it mean 1-1-1 or BT.1886? I would guess 1-1-1 i.e. explicit BT.709 transfer?
[19:45:03] <bartzy> and BT709 with 1886 is bt709/unknown/bt709 ?
[19:46:00] <durandal_1707> isnt that just gamma 2.4?
[19:46:01] <JEEB> see the quote I linked from BT.273 :P which is where the definitions were moved after they got to the third spec utilizing them
[19:46:27] <JEEB> in other words, BT.709 transfer is to be interpreted as BT.1886
[19:46:38] <JEEB> there is a separately an sRGB transfer
[19:47:24] <JEEB> also I'm getting tired
[19:47:27] <JEEB> H.273 of course
[19:47:28] <JEEB> not BT.
[19:47:29] <JEEB> https://www.itu.int/rec/T-REC-H.273/en
[19:48:11] <JEEB> with transfers you specifically have Note 1
[19:48:46] <JEEB> where it listst 1,6,14,15 as "actually that when converting from is to be interpreted as BT.1886"
[19:49:43] <JEEB> unspecified is just unspecified, where I would expect things to default to sRGB or so for RGB, and BT.1886 for YCbCr
[19:52:05] *** Joins: ttys000 (~ttys000@user/ttys000)
[20:00:19] *** Quits: zerodefect (~zerodefec@cpc78637-glfd7-2-0-cust61.6-2.cable.virginm.net) ()
[20:02:10] <bartzy> JEEB: Thanks
[20:04:46] <aphysically> JEEB: I think the next place to go with learning Python and maybe ffmpeg in general (in a way that could help transition into actually being comfortable enough with the codebase to write a patch?) is probably to try using the API directly with cffi or something
[20:05:12] <aphysically> C <-> Python interfaces are things I haven't messed with yet and that seems as good an excuse to learn it as any
[20:05:29] *** Quits: kib (~kib@user/kib) (Quit: WeeChat 3.3)
[20:09:15] <JEEB> aphysically: as with things like golang etc as well, you probably want to make your own simpler API for your use case(s) first in C, then wrap specifically that thing in python etc
[20:10:15] <aphysically> hmm, probably yeah
[20:10:51] <aphysically> I'm not completely unfamiliar with C; I used almost exclusively C or C++ throughout grad school, but in the worst most horrendous way you can think of
[20:12:01] <aphysically> in high energy physics the de facto standard plotting and data processing library is "ROOT" (funded by CERN). And basically every dataset is made in such a way that it hard depends on it, so if you want to work with the data, you have to use ROOT
[20:12:24] <aphysically> and ROOT is a C++ *interpreter* (made via clang somehow), so it's used as a scripting language to process data
[20:12:42] <aphysically> it's actually even more horrifying than it sounds
[20:14:23] *** Quits: mickey8 (~user@user/mickey) (Quit: Ping timeout (120 seconds))
[20:14:29] *** Bertl is now known as Bertl_oO
[20:14:38] <aphysically> the entire experience mostly left me wanting to use anything except C++, but mostly just by association of my experiences with ROOT and not cause of the language
[20:14:45] *** Joins: mickey8 (~user@user/mickey)
[20:14:47] <JEEB> that for some reason reminds me of those frameworks that make automagic C(++) ffi wrappers for java/python
[20:15:00] <JEEB> I actually tested it at my previous dayjob
[20:15:17] <JEEB> it just generated a /lot/ of stuff
[20:15:41] <aphysically> ROOT is okay at what it does; it doesn't choke when you feed it multi-terabyte datasets etc etc, but good lord it's horrendous
[20:20:31] *** Joins: zsoltiv_- (~zsoltiv@fibhost-67-12-35.fibernet.hu)
[20:20:47] *** Quits: zsoltiv_ (~zsoltiv@fibhost-67-12-35.fibernet.hu) (Ping timeout: 265 seconds)
[20:20:52] *** Quits: pong (~beaver@user/pong) (Remote host closed the connection)
[20:21:45] *** zsoltiv_- is now known as zsoltiv_
[20:22:15] *** Quits: Nact (~l@2a02:2788:11c4:6e6:cebc:f487:efd8:173) (Remote host closed the connection)
[20:22:35] *** Joins: Nact (~l@2a02:2788:11c4:6e6:cebc:f487:efd8:173)
[20:25:59] *** Joins: Vonter (~Vonter@user/vonter)
[20:30:45] *** Quits: Vonter (~Vonter@user/vonter) (Ping timeout: 260 seconds)
[20:34:38] *** Quits: yeirr (~yeirr@user/yeirr) (Quit: yeirr)
[20:35:18] *** Joins: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net)
[20:36:35] *** Quits: gucky-chat-laden (~gucky-cha@46.41.28.214) (Ping timeout: 260 seconds)
[20:41:54] <bartzy> JEEB: So QT also uses the wrong gamma when the color matrix/transfer is not BT709?
[20:42:16] <JEEB> matrix and primaries are separate from transfer
[20:42:23] <JEEB> I think matrix and primaries QT does right
[20:42:37] <bartzy> and transfer it just doesn't do right *whatever the transfer is* ?
[20:42:54] <bartzy> because I'm getting different results between VLC and QT for example, even for sRGB transfer
[20:43:02] *** Quits: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net) (Ping timeout: 260 seconds)
[20:43:04] <JEEB> vlc I have no idea how it handles it
[20:43:11] <JEEB> sorry
[20:43:23] <bartzy> OK
[20:43:53] <bartzy> well MPV and QT, are different as well
[20:45:22] <intrac> bartzy: very random thought from me (iirc) many years ago, the Quicktime sometimes didn't get the video levels correct
[20:45:38] <bartzy> what do you mean exactly by levels?
[20:45:39] <intrac> 0-255 range vs 16-235 range
[20:45:43] <bartzy> ah
[20:45:49] <intrac> so it might appear as lost shadow details
[20:45:52] <intrac> or grey shadows
[20:45:58] <intrac> depending on which way it got things wrong
[20:46:11] <intrac> most broadcast video has black at 8 bit value of 16
[20:47:09] <intrac> just thought I'd mention in case it wasn't a gamma issue
[20:47:26] <intrac> video testcards can help determine that
[20:47:36] <bartzy> I'll check it, thanks
[20:50:38] <galad> I wouldn't assume vlc output is correct, or mpv either if you don't configure it correctly
[20:51:33] <bartzy> yeah so really there's 0% I can find a player I can actually use and trust
[20:51:39] <bartzy> which is extremely weird, lol
[20:52:12] <intrac> yes, and on top of that the media player output method (the way it writes to the screen can have an impact)
[20:52:20] <intrac> (at least with Windows/Linux)
[20:52:53] <galad> like I said before, quicktime output is good enough for bt709
[20:53:17] <intrac> bartzy: I *think* the issue I describe was fixed with Quicktime, but I'm not 100% sure
[20:53:17] <galad> but where you setting the transfer characteristics to 2?
[20:53:31] <intrac> but it's difficult to have confidence with the complexity of things
[20:53:54] <galad> intrac: the issue was in quicktime 7, apple rewrote everything from scratch 10 years ago or so
[20:54:52] <galad> quicktime x doesn't have it, the only issue is that BT.709 is an approximation and is not BT.1886
[20:56:03] *** Quits: Atsuko_ (~x@45.63.115.64) (Remote host closed the connection)
[20:57:08] <intrac> galad: ah, ok. I vaguely remember reading that it was fixed.
[21:01:24] *** Joins: Atsuko (~x@45.63.115.64)
[21:13:19] *** Joins: softworkz_ (~softworkz@user/softworkz)
[21:13:19] *** softworkz is now known as Guest3156
[21:13:19] *** softworkz_ is now known as softworkz
[21:15:20] *** Joins: fannagoganna (uid110488@id-110488.tinside.irccloud.com)
[21:16:19] *** Joins: Narrat (~omnius@p200300df5f0ec4d206ea56fffe2e7cdc.dip0.t-ipconnect.de)
[21:16:38] *** Quits: Guest3156 (~softworkz@user/softworkz) (Ping timeout: 260 seconds)
[21:18:02] <bartzy> what's the best quality option in zscale for chroma upsampling (422 -> rgb)?
[21:18:48] *** Quits: blaze (~blaze@user/blaze) (Quit: WeeChat 3.3)
[21:23:46] *** Joins: omegatron (~some@p5484903d.dip0.t-ipconnect.de)
[21:25:33] *** Joins: dreamon (~dreamon@p54b149af.dip0.t-ipconnect.de)
[21:39:11] *** Joins: softworkz_ (~softworkz@user/softworkz)
[21:39:11] *** Quits: softworkz (~softworkz@user/softworkz) (Killed (lead.libera.chat (Nickname regained by services)))
[21:39:11] *** softworkz_ is now known as softworkz
[21:43:11] *** softworkz is now known as Guest3635
[21:43:20] *** Joins: softworkz (~softworkz@user/softworkz)
[21:46:35] *** Quits: Guest3635 (~softworkz@user/softworkz) (Ping timeout: 260 seconds)
[21:49:39] *** Joins: rsx (~dummy@ppp-188-174-147-17.dynamic.mnet-online.de)
[21:50:41] *** Joins: softworkz_ (~softworkz@user/softworkz)
[21:50:41] *** softworkz is now known as Guest6895
[21:50:41] *** Quits: Guest6895 (~softworkz@user/softworkz) (Killed (sodium.libera.chat (Nickname regained by services)))
[21:50:41] *** softworkz_ is now known as softworkz
[21:56:29] *** Quits: Keshl (~Purple@idlerpg/player/Keshl) (Read error: Connection reset by peer)
[21:57:03] *** Joins: Keshl (~Purple@idlerpg/player/Keshl)
[21:58:28] *** Quits: Keshl (~Purple@idlerpg/player/Keshl) (Read error: Connection reset by peer)
[21:58:46] *** Joins: Keshl (~Purple@idlerpg/player/Keshl)
[22:05:54] *** Joins: iive (~iive@87.119.101.204.client.entry.bg)
[22:08:47] *** Quits: rsx (~dummy@ppp-188-174-147-17.dynamic.mnet-online.de) (Quit: rsx)
[22:11:30] *** Quits: Nact (~l@2a02:2788:11c4:6e6:cebc:f487:efd8:173) (Remote host closed the connection)
[22:11:50] *** Joins: Nact (~l@2a02:2788:11c4:6e6:cebc:f487:efd8:173)
[22:24:10] *** Joins: Buster_ (~Buster@buster-net.ru)
[22:27:11] *** Joins: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de)
[22:28:58] *** Quits: dreamon (~dreamon@p54b149af.dip0.t-ipconnect.de) (Quit: Leaving)
[22:43:55] <roxlu> hey, when I want to transcode as many streams as possible what system/solution would you recommend? Just pure h264 in -> h264 our (different bitrate/resolution).
[22:44:25] <roxlu> would you recommend using cpu, gpu, fpga, ...? I'm really curious what's out there
[22:45:04] *** Joins: Neon (~Neon@94.15.113.18)
[22:46:50] <SimAV> roxlu, if efficiency is a concern and you don't want to spent quite some money on asics, I suggest to use a gpu.
[22:47:16] <SimAV> I've been using integrated intel gpus and dedicated nvidia gpus
[22:47:47] <roxlu> SimAV: I've quickly looked at the nvidia gpus and notices a p40 can do 24 sessions; buty they are pretty price :)
[22:47:50] *** Quits: jkwnki (~jkwnki@p2e5793bc.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[22:47:54] <SimAV> the latter are rather expensive if you want to have multiple streams in parallel (without hacking your driver)
[22:47:59] <roxlu> SimAV: are you using intel xeons?
[22:48:14] <SimAV> no, just ordinary intel i7-8700k i7-9700k
[22:48:42] <SimAV> I use them because i have these cpus here
[22:49:06] <roxlu> ok. do you know how many simultaneous encoding sessions you can do? lets say full HD/30fps?
[22:49:11] <SimAV> for nvidia I use Quadro P2000 and P4000.
[22:49:12] <roxlu> yeah makes sense
[22:49:18] <SimAV> for the intel I never checked that
[22:49:35] <roxlu> ah I've used the intel p4000 too, I think I did 3xUHD/30fps
[22:49:38] <roxlu> (decoding)
[22:49:38] <JEEB> I am really puzzled at how people actually make GPU-based encoding scalable :)
[22:49:52] <JEEB> you have very darn expensive GPUs with ASICs
[22:49:58] <JEEB> of course CPUs are expensive too
[22:50:13] <roxlu> JEEB: yeah, the nvidias are pretty expensive indeed
[22:50:23] <SimAV> IIRC the c3voc once reported something like 10 parallel sessions on an mobile intel gpu
[22:50:39] <SimAV> roxlu, i'm talking about a nvidia quadro P4000.
[22:50:45] <roxlu> I have done zero research but I would expect there to be very cheap specialized hardware based h264 encoders
[22:51:14] <roxlu> SimAV: oh sorry, I meant nvidia p4000
[22:51:44] <SimAV> http://web.archive.org/web/20190505115654im_/https://developer.nvidia.com/sites/default/files/akamai/designworks/images-videocodec/VCSDK_TU003a.png
[22:51:48] <SimAV> http://web.archive.org/web/20180913160347im_/https://developer.nvidia.com/sites/default/files/akamai/designworks/images-videocodec/nvenc_perf_B_001.png
[22:51:52] <SimAV> http://web.archive.org/web/20170214143849im_/https://developer.nvidia.com/sites/default/files/akamai/designworks/images/VidEncode_HP_002.png
[22:52:06] <SimAV> roxlu, these are numbers published by nvidia
[22:52:14] <roxlu> ah! that's great
[22:52:32] <SimAV> I haven't looked for more recent numbers since beginning of 2020 when prices exploded
[22:53:16] <JEEB> so far somehow it seemed to me that ASIC encoding is great when you don't have a lot of stuff to scale, and when you just don't want to think about computation requirements
[22:53:16] <SimAV> Pascal/Volta should give you 	9 HighQuality 	13 LowLatency	21 HighQuantity
[22:53:45] <JEEB> because I have seen dual CPU boxes from by now like 5 years ago do things
[22:53:49] <SimAV> (1080p30 streams in parallel in realtime)
[22:53:49] <JEEB> and those were expensive, sure
[22:54:05] <JEEB> but those GPUs that come with ASICs are also expensive :D
[22:54:12] <roxlu> yeah, so how to read this https://developer.nvidia.com/sites/default/files/akamai/designworks/images-videocodec/nvenc_perf_B_001.png ? do I need to multiply the P40/maxwell-2nd numbers by 2?
[22:54:19] <JEEB> and CPUs let you do various things
[22:54:28] <JEEB> while the ASIC is just gonna do what it has been designed for
[22:54:32] <SimAV> JEEB, and very likely required a very powerful powersupply?
[22:54:42] *** Quits: Neon (~Neon@94.15.113.18) (Quit: Connection closed)
[22:55:22] <JEEB> anyways, let's just say I struggle to see where the sweet points are for when you want to actually create an encoding farm out of nvidias or so
[22:55:37] <JEEB> be it live or VOD
[22:55:55] *** Quits: cosimone (~user@93-34-132-219.ip49.fastwebnet.it) (Quit: ERC (IRC client for Emacs 27.1))
[22:55:59] <JEEB> somehow it felt like the thing that was easy to utilize in cloud because someone got XYZ USD grant onto azure or amazon or so :D
[22:56:54] <SimAV> JEEB, if you want to encode on premise 8 1080p30 streams, you probably save A LOT of energy if you use the hardware encoder in your GPU
[22:57:37] <SimAV> IIRC the c3voc encoded 10 1080p25 streams on an integrated GPU of a mobile intel processor with 45 W power budget
[22:57:52] <SimAV> beat that with your CPU-encoding-farm :P
[22:58:16] <roxlu> SimAV: maybe this is way to simplistic; but would using a RPI 4 be feasible to encoder several streams?
[22:58:24] <roxlu> I've not looked into the limitations/specs yet
[22:59:07] <SimAV> roxlu, I have never checked myself, but the quality by the raspberry hardware encoder is reported to be inferior
[22:59:11] <hyrcanus> jetson nano is surprisingly fast with h265 encodes on gpu
[22:59:32] <hyrcanus> for a 6 year old 15w device
[22:59:50] <SimAV> more recent nvidia architectures were marketed and praised for delivering "excellent" quality
[23:00:11] <JEEB> most HW encoder ASICs are crap, and nvidia is one of the better ones
[23:00:23] <SimAV> I'm already very content with the pascal generation, but i can't afford newer ones anyway.
[23:00:50] <roxlu> :)
[23:01:11] <SimAV> roxlu, maxing out a P4000 nvenc chip is powerwise in a comparable range to the c3voc test with the intel gpu.
[23:01:22] <SimAV> maybe 10 W less, maybe 15 more...
[23:01:47] <SimAV> the P2000 has the same nvenc block as the P4000, but a total power budget of 75W max
[23:02:41] <SimAV> and IIRC it was reported to draw about 50% of its power budget when just maxing out the nvenc block (without doing 3D/opengl/...-stuff at the same time)
[23:02:48] <JEEB> SimAV: fair. given that 8 x 1080p30 isn't too much you'll be able to do with a single CPU, though. so I guess it's a case of balancing of those two and how much the upfront and cost of ownership will be
[23:03:37] <SimAV> JEEB, 8x 1080p30 with preset slow is quite something for my cpus... but yes, they aren't the newest...
[23:03:57] <JEEB> well not like you get preset slow quality with nvenc :)
[23:04:56] <JEEB> I do see the niceness of ASICs in being able to know exactly how much a single thing can do
[23:05:04] <JEEB> no need to attempt to calculate
[23:05:15] <JEEB> you know (given stats are available) how much you need
[23:05:30] *** Quits: thebombzen (~thebombze@c-68-41-54-207.hsd1.mi.comcast.net) (Quit: Quit)
[23:05:40] <JEEB> for CPU based things you actually need to think a bit more unless you have a method already set :)
[23:05:47] *** Joins: thebombzen (~thebombze@c-68-41-54-207.hsd1.mi.comcast.net)
[23:24:41] *** Quits: minimal (~minimal@user/minimal) (Quit: Leaving)
[23:28:09] *** Joins: pong (~beaver@user/pong)
[23:39:44] <bartzy> `ffmpeg -i prores422_bt709_input.mov -vf zscale,format=gbrp16 -f rawvideo -` - Would this filter get the matrix/transfer/primaries defined in the input correctly, and convert to RGB ones because the format is gbrp16?
[23:40:22] *** Quits: Volgaar (~volgaar@104.66.13.93.rev.sfr.net) (Ping timeout: 260 seconds)
[23:42:53] *** Joins: zumba_addict (~zumba_add@c-71-194-58-34.hsd1.il.comcast.net)
[23:43:11] *** Quits: zumba_addict (~zumba_add@c-71-194-58-34.hsd1.il.comcast.net) (Client Quit)
[23:43:20] *** Joins: zumba_addict (~zumba_add@c-71-194-58-34.hsd1.il.comcast.net)
[23:50:52] *** Quits: SimAV (~SimAV@ip1f10fb08.dynamic.kabel-deutschland.de) (Ping timeout: 258 seconds)
[23:50:55] *** Quits: durandal_1707 (~computer@95.168.120.92) (Read error: Connection reset by peer)
[23:52:33] *** Quits: Flabb (~Flabb@89.169.42.92) (Quit: Leaving)
