[00:02:29] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[00:08:40] *** Joins: `Tim (~zenguin@user/zenguin)
[00:18:35] *** Joins: miique_ (~miique@181.46.139.166)
[00:19:31] *** Quits: miique (~miique@181.46.139.166) (Ping timeout: 256 seconds)
[01:00:07] *** Joins: sonny (~sonny@bras-base-london1483w-grc-32-70-52-175-166.dsl.bell.ca)
[01:07:31] *** Joins: trace987 (~trace@dynamic-002-247-248-171.2.247.pool.telefonica.de)
[01:13:14] *** Joins: test__ (flooded@gateway/vpn/protonvpn/flood/x-43489060)
[01:16:11] *** Joins: flooded (flooded@gateway/vpn/protonvpn/flood/x-43489060)
[01:16:19] *** Quits: _flood (flooded@gateway/vpn/protonvpn/flood/x-43489060) (Ping timeout: 256 seconds)
[01:18:27] *** Quits: test__ (flooded@gateway/vpn/protonvpn/flood/x-43489060) (Ping timeout: 256 seconds)
[01:42:47] *** Joins: HuntsMan (~hunts@p200300c1ff03c00032e171fffec8909c.dip0.t-ipconnect.de)
[01:55:51] *** Quits: trace987 (~trace@dynamic-002-247-248-171.2.247.pool.telefonica.de) (Ping timeout: 256 seconds)
[02:05:08] *** Quits: manti7 (~manti7@176.10.104.94) (Quit: WeeChat 3.3)
[02:26:33] *** Quits: palasso (~palasso@user/palasso) (Read error: Connection reset by peer)
[02:38:26] *** Joins: black_13_ (~jjosb@209.221.58.171)
[03:29:40] *** Quits: miique_ (~miique@181.46.139.166) (Read error: Connection reset by peer)
[03:44:13] *** Quits: sinaowolabi__ (~SinaOwola@169.159.67.85) (Ping timeout: 256 seconds)
[03:45:20] *** Joins: miique (~miique@181.46.139.166)
[04:10:51] *** Quits: sonny (~sonny@bras-base-london1483w-grc-32-70-52-175-166.dsl.bell.ca) (Ping timeout: 256 seconds)
[04:13:15] *** Joins: sonny (~sonny@bras-base-london1483w-grc-32-70-52-175-166.dsl.bell.ca)
[04:32:57] *** Quits: marcello42 (~mp@2001:1a81:12d6:fe00:339f:db3c:2449:7044) (Ping timeout: 268 seconds)
[04:34:19] *** Joins: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447)
[04:48:26] *** Quits: Donitz (~Donitz@88-115-149-215.elisa-laajakaista.fi) (Read error: Connection reset by peer)
[04:53:58] *** Joins: Donitz (~Donitz@88-115-149-215.elisa-laajakaista.fi)
[04:56:23] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[05:02:22] *** Joins: sinaowolabi (~SinaOwola@160.152.114.42)
[05:26:09] *** Quits: jerome- (~jerome@88.173.24.196) (Remote host closed the connection)
[05:27:35] *** Joins: jerome- (~jerome@88.173.24.196)
[05:55:07] *** Quits: sonny (~sonny@bras-base-london1483w-grc-32-70-52-175-166.dsl.bell.ca) (Ping timeout: 256 seconds)
[06:19:59] *** Joins: sinaowolabi__ (~SinaOwola@102.134.114.1)
[06:52:14] *** Joins: sonny (~sonny@bras-base-london1483w-grc-32-70-52-175-166.dsl.bell.ca)
[06:52:59] *** Parts: sonny (~sonny@bras-base-london1483w-grc-32-70-52-175-166.dsl.bell.ca) ()
[07:03:20] *** Quits: `Tim (~zenguin@user/zenguin) (Quit: Leaving)
[07:04:58] *** Joins: arjun (~arjun@user/arjun)
[07:49:29] *** Joins: [_] (~itchyjunk@user/itchyjunk/x-7353470)
[07:50:05] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Killed (molybdenum.libera.chat (Nickname regained by services)))
[07:50:05] *** [_] is now known as [itchyjunk]
[08:07:20] *** Parts: arjun (~arjun@user/arjun) (Leaving)
[08:54:56] *** Joins: hygl (uid16621@id-16621.tinside.irccloud.com)
[09:42:02] *** Quits: miique (~miique@181.46.139.166) (Read error: Connection reset by peer)
[09:45:37] *** Joins: miique (~miique@181.46.139.166)
[09:54:56] *** Quits: SiegeLord (~sl@user/siegelord) (Quit: WeeChat 2.8)
[09:58:00] *** Joins: SiegeLord (~SiegeLord@user/siegelord)
[10:13:55] *** Joins: jlrnick (~josephler@2a01cb040a159400e89369dfc959fe4f.ipv6.abo.wanadoo.fr)
[10:38:27] *** Quits: sinaowolabi (~SinaOwola@160.152.114.42) (Ping timeout: 256 seconds)
[10:52:24] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[11:02:15] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Read error: Connection reset by peer)
[11:05:16] *** Joins: Codaraxis_ (~Codaraxis@user/codaraxis)
[11:08:37] *** Quits: Codaraxis (~Codaraxis@user/codaraxis) (Ping timeout: 240 seconds)
[11:34:03] *** Joins: palasso (~palasso@user/palasso)
[12:08:44] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Read error: No route to host)
[12:09:22] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[12:09:29] *** Quits: sinaowolabi__ (~SinaOwola@102.134.114.1) (Read error: Connection reset by peer)
[12:10:35] *** Joins: sinaowolabi__ (~SinaOwola@102.134.114.1)
[12:56:10] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Ping timeout: 256 seconds)
[13:04:20] *** Joins: Codaraxis__ (~Codaraxis@user/codaraxis)
[13:04:37] *** Joins: trace987 (~trace@dynamic-002-247-248-171.2.247.pool.telefonica.de)
[13:07:13] *** Joins: manti7 (~manti7@176.10.104.94)
[13:08:03] *** Quits: Codaraxis_ (~Codaraxis@user/codaraxis) (Ping timeout: 256 seconds)
[13:12:35] *** Quits: sinaowolabi__ (~SinaOwola@102.134.114.1) (Ping timeout: 256 seconds)
[13:13:53] *** Joins: Codaraxis_ (~Codaraxis@user/codaraxis)
[13:17:41] *** Quits: Codaraxis__ (~Codaraxis@user/codaraxis) (Ping timeout: 256 seconds)
[13:25:59] *** Joins: spaceseller (~spacesell@31.147.205.13)
[13:26:06] *** Joins: sinaowolabi__ (~SinaOwola@160.152.114.42)
[13:32:05] *** Quits: spaceseller (~spacesell@31.147.205.13) (Quit: Leaving)
[13:52:04] *** Quits: SiegeLord (~SiegeLord@user/siegelord) (Read error: Connection reset by peer)
[14:12:29] *** Quits: sinaowolabi__ (~SinaOwola@160.152.114.42) (Read error: No route to host)
[14:21:18] *** Joins: sinaowolabi (~SinaOwola@160.152.114.42)
[14:27:52] *** Joins: sinaowolabi__ (~SinaOwola@41.58.231.227)
[14:29:31] *** Quits: PTapioK (~PTapioK@84-231-164-204.elisa-mobile.fi) (Ping timeout: 256 seconds)
[14:30:05] *** Joins: PTapioK (~PTapioK@84-231-166-137.elisa-mobile.fi)
[14:52:17] *** Quits: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447) (Ping timeout: 240 seconds)
[15:11:47] *** Quits: trace987 (~trace@dynamic-002-247-248-171.2.247.pool.telefonica.de) (Quit: Leaving)
[16:55:52] *** Quits: sinaowolabi (~SinaOwola@160.152.114.42) (Ping timeout: 256 seconds)
[16:58:11] *** Quits: miique (~miique@181.46.139.166) (Read error: Connection reset by peer)
[17:00:59] *** Joins: miique (~miique@181.46.139.166)
[17:07:57] *** Joins: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447)
[17:10:30] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[17:17:17] *** Joins: trace987 (~trace@dynamic-002-247-251-145.2.247.pool.telefonica.de)
[17:26:57] *** flooded is now known as _flood
[17:57:21] *** Joins: `Tim (~zenguin@user/zenguin)
[18:41:01] *** Quits: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447) (Ping timeout: 240 seconds)
[18:42:12] *** Joins: Jong (~Jong@174.27.0.61)
[18:43:22] *** Joins: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447)
[18:56:37] *** Quits: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447) (Ping timeout: 240 seconds)
[18:56:43] <lericson> if you plot perplexity on a logarithmic y axis, isn't that basically just entropy with the tick marks moved a bit?
[18:58:25] *** Joins: blackpawn (~blackpawn@c-73-73-53-23.hsd1.il.comcast.net)
[19:00:37] *** Quits: miique (~miique@181.46.139.166) (Ping timeout: 240 seconds)
[19:00:43] <lericson> i believe so
[19:20:31] <Jong> Is anyone here familiar with the "Attention is all you need paper"... I have some ideas inspired by that paper that may be paper publication worthy.
[19:20:46] <lericson> do tell
[19:22:09] <Jong> Basically, you if look at the paper, the new idea is that activations values are multiplied by other activation values.
[19:22:55] <lericson> well
[19:23:01] <lericson> not really?
[19:23:04] <lericson> lstms do that
[19:23:08] <Jong> In a vanilla neural network, like a multilayer perceptron,
[19:23:37] <Jong> activations make contact with each other via addition
[19:23:50] <Jong> a_1*w_1 + a_2*w_2
[19:23:52] <Jong> for example
[19:25:33] <Jong> But in multihead attention, there are feature maps that matrix multiply with other feature maps
[19:27:09] <xs> attention is all you need is interesting as they show that by replacing LSTMs with attention, you get good performance. that paper did not introduce attention, but proposes an attention-based architecture (transformers) that works well.
[19:27:43] <lericson> right
[19:27:48] <lericson> but let's hear your idea
[19:28:02] <xs> bahdanau et al introduced this form of attention in 2014. fwiw.
[19:28:11] <xs> idea of what?
[19:28:50] <lericson> the man said he had some groundbreaking ideas and i'm on pins and needles over here
[19:28:56] <xs> oh
[19:29:27] <xs> Jong: i'm familiar with the literature if that helps you
[19:29:28] <Jong> lericson my idea is to replace multiplication with e^x and addition.   Multiplication in log space becomes addition.
[19:30:30] <xs> so you have h = e^(sigma(e^(k + q)) + v)?
[19:30:40] <Jong> so one idea is for test modifying a bunch of neural nets by inserting an e^x between input layer and next layer, and invert back using log(x) right before the output. The question is whether results will be better for any kind of neural net
[19:31:18] <Jong> Another idea is to have some e^x layers and some regular, and see what happens
[19:31:32] <xs> Jong: you might be interested in Gated Linear Networks by Joel Veness et al 2019, who do something like this but using sigmoid and inverse sigmoid between the layers.
[19:32:25] <xs> there's a few follow up papers that show various applications of this trick
[19:32:34] <Jong> anyone who knows anything about neural nets better know about sigmoid, I sure do.  You make a good point.
[19:33:49] <xs> e^x can be a bit nasty when it comes to gradients, numerically, which is why sigmoid might be more stable for your idea
[19:34:49] <xs> i guess one interesting part is that transformers typically use some kind of normalization
[19:36:08] <Jong> My other idea, maybe paper publication worthy, is to have some activations represent how many times to loop through a layer where the layer calls itself N times, and some activation value represents N.   And I was thinking what if some activation values could represent which layer to forward activations through next?  Then instead of a fixed feed forward net, the wiring is totally flexible
[19:36:46] <Jong> What do you think xs?
[19:37:31] <xs> ah, there are two papers you might like to read in this direction: 1) universal transformers by mostafa dehghani et al 2018, and memo by andrea banino et al 2020.
[19:38:03] <xs> both explore related ideas to this, although not exactly what you describe, i think
[19:38:10] <Jong> thanks xs! THat's  impressive you have the citations memorized !
[19:38:15] <xs> tl;dr: both get sota results, and the memo results are better
[19:38:18] <lericson> also i think neural turing machines are related
[19:38:25] <xs> heh, it's my day job.
[19:38:34] <Jong> xs, if it's not exactly what i described, then maybe my idea is paper publication worthy if the results aren't trash!
[19:39:00] <xs> paper = idea + write up + execution
[19:39:20] <lericson> + roll of the reviewer dice
[19:39:22] <xs> definitely worth looking into, there's not a lot of work on this idea atm
[19:39:31] <Jong> + *NEW IDEA*
[19:39:38] <lericson> ha
[19:39:40] <xs> new idea isn't necessary, see gpt-3
[19:39:42] <Jong> it can't be any idea. It must be a new idea, otherwise it's a waste
[19:40:09] <Jong> if it's not a new idea then at least it must be new information on an already known idea
[19:40:27] <xs> or maybe just something someone else did, better executed and written up
[19:40:51] <Jong> true
[19:41:22] <xs> also, new idea can be very small. e.g., adam is a very minor tweak to rmsprop to deal with initial bias at the start of learning. it also helped that rmsprop wasn't really published...
[19:41:38] <xs> most ideas die at the experiment stage, so prioritise that.
[19:42:08] <lericson> who was it that talked about this recently though? this idea that the human thinking process knows when it's done, and that does not take a constant amount of time, so any system that reasons must similarly be dynamic
[19:42:34] <xs> i don't know, i would be interested to know.
[19:43:04] <lericson> hmmm
[19:43:34] <lericson> they also mentioned that you can try to remember something, be unable to remember it, and then an hour late, you exclaim RICKY LAKE! that's her name!
[19:43:38] <Jong> xs my ideas raised the question "Is there a way to know how much information can be stored in something? how does information theory play into this? Aren't my ideas really about trying to use every ounce of the net usefully? If so, then aren't questions about knowing how to pack as much useful knowledge into the net as can be"
[19:43:47] <lericson> as if the "echoing" continues inside your mind even though your attention turned elsewhere
[19:45:53] <xs> Jong: are you aware of the work on this question for hopfield networks? if you look for information capacity and hopfield networks you should find some stuff. not aware of anything as concrete for more recent networks.
[19:46:07] <xs> lericson: like big loop recurrence?
[19:47:17] <lericson> mm don't know that term
[19:48:07] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[19:48:51] <Jong> If a neural net simulates conditional statements, then a neural net's architecture is vastly underused, similar to how the majority of a piece of code isn't used when the code has many if statements and only one of them are taken. The other if statements were never used.   So I asked the question, "How can try to get every part of the net always doing something useful?"
[19:49:38] <Jong> xs, nope I'm not knowledge of hopfield networks. I heard the word before but htat's it.
[19:50:27] <xs> Jong: you may also be interested in "neural algorithmic reasoning", it's also along the lines you are thinking and quite recent.
[19:50:38] <Jong> thanks!
[19:51:38] <Jong> btw, all these thoughts occured when I was taking a shower. Something about showers trigger ideas surfacing to my consciousness
[19:51:57] <xs> that's normal :D
[19:52:16] <lericson> my trigger is walks
[19:52:25] <lericson> shower it happens but it's hard to write stuff down in there…
[19:52:36] <Jong> yep, I've googled and read about why ideas pop up in the showers
[19:52:55] <Jong> lericson  latest iphone is waterproof enough to have in the shower. That's what i use
[19:53:05] <lericson> really?
[19:53:12] <lericson> it truly is 2022
[19:53:12] <Jong> Yes. I have an iphone 11.
[19:53:33] <lericson> i have an iphone x, but screen is replaced so not watertight - found it's very difficult to use the touch screen when wet anyway
[19:53:33] <Jong> it's waterproof. YOu can submerge it in your toilet and it won't get damaged
[19:54:08] <Jong> you can see youtube videos proving it
[19:54:25] <lericson> i don't doubt it
[19:55:30] <hodapp_> Jong: *scalar* multiplication is addition in log space. matrix multiplication is not. so, I'm not sure what computational advantage you're hoping to get out of that with scaled dot-product attention
[19:56:16] <Jong> xs if my ideas result in nets that outperform current SOTA, will that make me famous in the machine learning world? Will I have companies like Google and OpenAI contacting me?
[19:56:44] <lericson> you can't outperform SOTA as a one-man-band
[19:56:50] <lericson> too expensive
[19:57:35] <hodapp_> Jong: also, even if you can successfully replace the annoyances of the numerator in softmax, the denominator is often still a gigantic pain
[19:57:57] <xs> Jong: maybe, maybe not. a lot of papers achieve sota, so it's not necessarily the strongest signal.
[19:58:34] <xs> hodapp_: these are vectors, not matrices...
[19:58:36] <hodapp_> Jong: but take a look at Linformer, Performers, and SimpleTron if you want to see existing attempts at rejiggering scaled dot-product attention
[19:59:05] <xs> ah! linformer, i was trying to remember that.. but iirc, it very much underperforms, no?
[19:59:07] <hodapp_> xs: what product defined over vectors ends up being addition in log space?
[19:59:11] <lericson> lol yes me too xs
[19:59:51] <lericson> which one is it where they do like a fourier mix?
[19:59:51] <hodapp_> xs: my reason for not doing more with Linformers is that, as far as I can tell, they end up training the network to a specific fixed sequence length
[20:00:26] <hodapp_> xs: and as I was curious how it works with things like ViT, this obviates pre-training with MAE as that uses 1/4 the sequence in pre-training
[20:01:24] <Jong> hodapp_  thanks! Will do!
[20:04:59] <xs> hodapp_: just saw your question, my comment was on these being vectors not matrices, rather than this helping with log. you can, of course use matrix exponential and logarithm to do this.
[20:07:57] <hodapp_> xs: can use matrix exponential and logarithm to do what exactly?
[20:08:26] <lericson> are they differentiable and easy to compute though?
[20:14:15] <lericson> it does not look like it, neither (a) nor (b)
[20:14:31] <hodapp_> lericson: what a and b are you talking about?
[20:14:40] <lericson> differentiable, and easy to compute
[20:14:48] <hodapp_> ahh
[20:15:32] <lericson> it looks like you can do some funny tricks though to keep it easily computed and perhaps even differentiable, at least the exp map
[20:15:50] <hodapp_> to what end though?
[20:16:04] <lericson> idk i'm not at all convinced by the original idea, i'm just curious if it can be done :p
[20:16:59] <hodapp_> the hard part in scaled dot-product attention isn't really the exponential in the softmax - it's the normalization in the softmax that wrecks everything because it's the sum of a bunch of exponentials
[20:18:57] <hodapp_> but Performers sort of try to get around this by re-expressing softmax in an approximated kernelized (ish) form that can be done as a dot product in some space, letting it re-distribute the matrix multiply to avoid the n^2 attention matrix
[20:19:27] <hodapp_> SimpleTron does the same by just going "softmax? what softmax?" and simply not doing it
[20:21:33] <Jong> What if instead of activations matrix muliplied by each other, one set of activations were used as an exponent number? Instead of q_1*k_1 + q_2*k_2, we tried q_1 ^ k_1 + q^2^k_2.    Any chance this would be a new idea ?
[20:23:29] *** Quits: stefan-_ (~cri@42dots.de) (Ping timeout: 250 seconds)
[20:24:13] <hodapp_> probably more of a chance that q ~= 0 and negative k, or q < 0 and k < 1, would cause you some pretty ugly stability issues
[20:24:30] <Jong> yeah that's what you've been saying above too
[20:25:03] <hodapp_> I didn't say anything prior about stability issues
[20:26:27] <hodapp_> it would also probably complicate the gradients in annoying ways
[20:26:47] <lericson> i think you should test instead of spitballin' on irc, Jong
[20:27:17] *** Joins: stefan-_ (~cri@42dots.de)
[20:27:42] <lericson> like xs said, most ideas die in the experiment phase because they just simply don't give good results
[20:28:22] <Jong> one last idea to share, if you don't mind!   Let's say you train a net and it's 99.9% accurate. Now you train subparts of the net using autoencoders in an attempt to shrink the net while achieving same results. For example, try to simulate Layer N  to Layer N + 5 using less layers or the same # of layers but with less neurons in each, like the autoencoder bottle neck uses few.
[20:28:40] <lericson> coincidentally this is why you often see papers present a neat idea, then on page 3 somewhere, they go "and we added these arbitrary things for good measure" and it completely makes/breaks the stated metrics
[20:28:48] <hodapp_> it isn't clear to me what specific problem this experiment would even be aiming to solve
[20:30:02] <xs> Jong: are you familiar with distillation?
[20:30:04] <hodapp_> Jong: it looks like you're talking about some conglomeration of network distillation and the Lottery Ticket Hypothesis
[20:30:53] <Jong> xs  distillation? Don't think so, but my idea does remind me of Nvidia's TensorRT, even though it probably works far differently
[20:33:16] <xs> check out "distilling the knowledge in a neural network" by hinton et al from 2015.
[20:33:30] <Jong> oh distillation  appears to be about ensemble networks?
[20:33:38] <xs> not really, no
[20:34:00] <lericson> didn't they show in simclr or something that distillation with the same network size can improve performance beyond the teacher network?
[20:34:06] <Jong> okay. I'll be quiet and read what i need to read. You guys put a lot of unknown material before me I must learn
[20:34:09] <hodapp_> no, closest thing you'll see to ensemble networks is student-teacher models
[20:36:02] *** Joins: pyeveryt_ (~pyeveryth@64-18-153-56.starry-inc.net)
[20:36:07] <pyeveryt_> hi does anyone know sklearn? I need some help in creating 5-fold training, test, and validation files. Sklearn typically allows for that using KFold method however it only does for train and test. How can i do that for train and test and val sets? https://stackoverflow.com/questions/70617794/5-fold-cross-validation-from-sklearn-with-train-val-and-test-sets-and-ratio-of
[20:36:07] <SigmoidFroid> ⇒  python - 5-fold cross validation from sklearn with train, val, and test sets and ratio of 60/20/20 - Stack Overflow
[20:36:59] <hodapp_> ordinarily if you have train, val, and test you don't do it that way
[20:37:32] <hodapp_> your folds will provide train/val, test will remain completely separate and unused except until you want a 'final' evaluation of performance
[20:38:35] <xs> pyeveryt_: i would use train_test_split to get your training and test set, then use just the training data with kfold.
[20:39:22] <pyeveryt_> xs i am not exactly following you.
[20:40:18] <hodapp_> test should not be part of your folds at all - so split your data into one set for training/val (and use kfold on this), and one set for test
[20:40:33] <pyeveryt_> hodapp_: so given a dataframe of 1084 rows, how should i go about 60/20/20 splits for 5 folds for train/test/val?
[20:40:55] <hodapp_> you shouldn't be doing folds at all for test.
[20:41:19] <pyeveryt_> ok gotcha hodapp_  do you mean that test set should always be the same for all of these?
[20:41:36] <pyeveryt_> hodapp_: thanks for explanation
[20:42:18] <pyeveryt_> does 60/20/20 make sense then? If I choose 20% for test, wouldn't 5 fold cross validation forcefully pick 20% of remaining for val? and 80% of remaining for train?
[20:42:44] <lericson> treat your test set as a fine wine, pyeveryt_, you put it away until your wedding
[20:43:29] <pyeveryt_> hodapp_: does 60/20/20 make sense then? If I choose 20% for test, wouldn't 5 fold cross validation forcefully pick 20% of remaining for val? and 80% of remaining for train?
[20:44:24] <hodapp_> 60/20/20 would force it to be 3-fold, not 5-fold
[20:46:03] <pyeveryt_> still a 3-fold would cause 33% of remaining (80% remaining) to be val and 66% to be train. basically 66% of remaining 80% is not 60% hodapp_
[20:46:18] <pyeveryt_> lericson: yeah agreed
[20:46:41] <hodapp_> sorry, I meant 4-fold
[20:49:06] <pyeveryt_> hodapp_: awesome yeah re-did the calculations and 4-fold works greatly. one final question for you, is 4-fold conventional? I have seen a lot of 3, 5, and 10 fold experiments and not really 4-fold. Wouldn't be questionable?
[20:49:29] <hodapp_> 3, 5, and 10 are common conventions; nothing is wrong with 4-fold
[20:50:32] <pyeveryt_> hodapp_: thanks a lot. just to reiterate, for the initial 20% for test, I am gonna do train-test split from sklean and then for the rest continue with the code i have for 5 fold train/val, right?
[20:51:22] <hodapp_> I think that sounds right
[20:52:08] *** Joins: trace (~trace@91.66.151.109)
[20:53:19] <pyeveryt_> very great instructor hodapp_ :)
[20:54:13] *** Quits: trace987 (~trace@dynamic-002-247-251-145.2.247.pool.telefonica.de) (Ping timeout: 240 seconds)
[20:54:52] <pyeveryt_> is there another ML channel? why this one has -general attached to it?
[20:55:43] <hodapp_> because ##machinelearning is run by a petty tyrant who bans people for even mentioning this channel or for criticizing him in the slightest
[20:56:22] <pyeveryt_> i joined the channel by using machinelearning tho not using machinelearning-general
[20:56:32] <Jong> pyeveryt_  ##machinelearning is ran by some weirdo who doesn't even know anything about AI and has lame bots spamming the chan
[20:56:40] <pyeveryt_> hmm do you mean there's another ML channel actually? hodapp_ :D
[20:56:47] <hodapp_> last I checked
[20:57:04] <lericson> fyi ##machinelearning forwards to this channel
[20:57:11] <hodapp_> I was banned from there after the guy showed up in #libera and was throwing a tantrum, and I told staff about his history
[20:57:19] <hodapp_> lericson: wait, what? since when?
[20:57:27] <lericson> idk, i joined ##machinelearning also
[20:57:33] <lericson> or #machinelearning
[20:57:39] <pyeveryt_> this is weird. have you thought about reporting to libera? I was harrassed in Linux channel a while back and reported it. lericson and hodapp_
[20:57:43] <hodapp_> I'm still banned from ##machinelearning
[20:57:47] <lericson> oh
[20:57:52] <lericson> how did i end up here then
[20:58:00] <pyeveryt_> do you know why i am banned? I barely even use this channel :D
[20:58:06] <pyeveryt_> I had no idea I am banned
[20:58:09] <lericson> yeah it's #machinelearning that forwards to here
[20:58:14] <hodapp_> pyeveryt_: wait, you are banned too?
[20:58:42] <hodapp_> pyeveryt_: but staff do not intervene much if someone is not violating network policy; further, most of this drama happened back at freenode
[20:58:49] <pyeveryt_> use #libera and then report the person. Before reporting tell you want to report someone to admin of libera and then tell to admin. I don't suggest to publicly say it to libera channel
[20:59:07] <pyeveryt_> I honestly don't know how to know if I am banned hodapp_
[20:59:13] <lericson> life's too short init
[20:59:18] <jootoi-> most of the drama happened back on freenode because no one is talking on the channel anymore :D
[20:59:18] <hodapp_> if you're banned and you try to join, it'll tell you
[20:59:47] <pyeveryt_> i got this 12:29 <libera> Error(443): pyeveryt_ #machinelearning is already on channel
[20:59:59] <hodapp_> ##machinelearning, two pound signs
[20:59:59] <lericson> yes beacuse you're already here in ##machinelearning-general
[21:00:05] <hodapp_> pyeveryt_: #libera already knows and they've seen him throw a giant tantrum, it doesn't matter
[21:00:44] <pyeveryt_> hodapp_: shouldn't they do something about it? The person I mentioned in Linux continuously ridicule and harass people (not just me)
[21:01:35] <pyeveryt_> btw what's the actual number of people in the other ML channel?
[21:01:39] <lericson> 109
[21:01:40] <hodapp_> he wasn't really violating network policy, he's just being a narcissistic mini-dictator
[21:01:47] <pyeveryt_> i mean 91 here is not that bad after all :D
[21:01:58] <hodapp_> this channel has seen a lot more activity as of late
[21:01:59] <hodapp_> not sure why
[21:02:50] <lericson> as i said, #machinelearning redirects to this channel
[21:02:51] <pyeveryt_> I think the last time I joined (definitely more than a month ago) i was in the normal ML channel that's why -general caught my eyes and I thought it's because they might have subchannels such as ML-RL or ML-DL etc
[21:02:58] <lericson> this is 100% the reason
[21:03:14] <pyeveryt_> i guess their channel is now invitation onlt?
[21:03:14] <hodapp_> lericson: curious if this is a recent thing
[21:03:20] <pyeveryt_> invitation only
[21:03:23] <lericson> believe so, i was in ##machinelearning before
[21:03:33] <lericson> no, pyeveryt_, it is there
[21:03:47] <lericson> open to all
[21:03:53] <lericson> but you need to be authenticated with nickserv
[21:03:59] <hodapp_> (and not banned)
[21:04:00] <pyeveryt_> so lericson what did you do to get banned? :D
[21:04:06] <lericson> i was not banned
[21:04:14] <lericson> 18:33 -!- mode/##machinelearning [+b *!~Jong@*] by Evolver
[21:04:16] <lericson> lol
[21:04:16] *** Joins: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447)
[21:04:22] <pyeveryt_> I think I am authenticated since i am in Python channel
[21:04:26] <lericson> Jong: he banned you after you left for no reason
[21:05:06] <lericson> easily avoided ban too
[21:05:09] <lericson> anyway, enough irc drama
[21:05:18] <Jong> lericson  probably he banned me because I just pm'd him "what are you trying to achieve? The only thing you've achieved is make the real ML channel that actually has chat activity by AI experts need to add "-general" to ##machinelearning.
[21:05:41] <pyeveryt_> :D lol so you are not supposed to leave the room for no reason! i mean I once got banned by a bot from the entire IRC and reason was my internet got flaky and got on and off a bunch of times. Luckily i had an insider who I contacted and he fixed it for me.
[21:06:29] <lericson> man don't go witchhunting Jong
[21:07:45] <pyeveryt_> ok now the description of your channel makes sense to me :D machine learning for human
[21:08:29] <lericson> irc is full of interesting characters like that
[21:08:37] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[21:10:01] <Jong> lericson  honestly, It's a genuine question.  I'm asking myself, if I were in his position, and wanted Libra to have an active AI chan, I'd see there IS an active ai channel, and that all I've done is hog the higher-value channel name for a lower-value channel, which does not benefit anyone.
[21:11:16] <hodapp_> he came into #libera and tried to whine to staff that dostoyevsky was squatting on #machinelearning and demanded that they make him hand it over
[21:11:46] <Jong> and libera staff gave me? Why would they?
[21:11:57] <Jong> s/me/in
[21:12:00] <hodapp_> likely when they saw him throw a tantrum in response to even mild criticism, and start PMing people to harass them, this is why they ignored his request and quieted him instead
[21:12:15] <hodapp_> #machinelearning, not ##machinelearning
[21:12:22] <Jong> ohh I see
[21:12:59] <Jong> brb I'll test the name forwarding
[21:13:05] *** Parts: Jong (~Jong@174.27.0.61) (Textual IRC Client: www.textualapp.com)
[21:13:06] <hodapp_> dostoyevsky even made him a reasonable offer
[21:13:08] *** Joins: Jong (~Jong@174.27.0.61)
[21:13:11] <hodapp_> oh, you're gone, nvm
[21:13:15] <lericson> oh i remember why i left that channel
[21:13:25] <lericson> the damn FeedBot
[21:13:40] <Jong> nice: [01/07/2022 -:- 10:43:08 AM] Message(470): ##machinelearning-general Forwarding to another channel
[21:13:55] <Jong> That's what I see when trying to join #machinelearning
[21:15:29] *** Quits: pyeveryt_ (~pyeveryth@64-18-153-56.starry-inc.net) (Remote host closed the connection)
[21:20:10] *** Quits: marcello42 (~mp@2001:1a81:12ec:f000:b283:2eaa:9318:3447) (Quit: WeeChat 3.4)
[21:22:17] *** Quits: jlrnick (~josephler@2a01cb040a159400e89369dfc959fe4f.ipv6.abo.wanadoo.fr) (Ping timeout: 240 seconds)
[21:54:21] *** Quits: sinaowolabi__ (~SinaOwola@41.58.231.227) (Ping timeout: 256 seconds)
[21:57:37] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Ping timeout: 240 seconds)
[22:03:57] *** Quits: shoky (uuuggg@141.226.193.67) (Ping timeout: 240 seconds)
[22:07:53] *** Joins: shoky (uuuggg@141.226.193.67)
[22:08:40] *** Quits: brand0 (~brandon@user/brand0) (Ping timeout: 256 seconds)
[22:13:14] *** Joins: sinaowolabi (~SinaOwola@160.152.114.42)
[22:15:39] *** Joins: sinaowolabi__ (~SinaOwola@102.134.114.1)
[22:19:40] *** Joins: SiegeLord (~sl@user/siegelord)
[22:26:14] *** Quits: sinaowolabi__ (~SinaOwola@102.134.114.1) (Ping timeout: 256 seconds)
[22:39:21] *** Joins: sinaowolabi__ (~SinaOwola@41.58.244.37)
[23:00:29] *** Joins: georgios (~georgios@user/georgios)
