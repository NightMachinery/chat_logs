[00:03:32] <hodapp> so I'm *assuming* that if they say it's 800 epochs, cosine decay, 40 warmup epochs, base LR of 1e-4... then that's linear warmup from LR=0 at epoch 1, up to LR=1e-4 at epoch 40, and from epoch 40 to epoch 800 it follows cosine decay with (800-40) as the period (such that it ends at LR=0)
[00:09:37] <acresearch> HuntsMan: i didn't understand your question,   yeh i am augmenting the data, not sure if i am augmenting correctly though
[00:10:13] <acresearch> tried with a CNN with 41,509 parameters    maybe resnet may not work
[00:18:02] <HuntsMan> acresearch: I mean which augmentations are you applying
[00:36:34] *** Quits: HuntsMan (~hunts@p5494d423.dip0.t-ipconnect.de) (Quit: Konversation terminated!)
[00:37:02] <acresearch> HuntsMan: all of them, rotation, width shift, height etc...    https://paste.debian.net/1224239/
[00:37:04] <SigmoidFroid> ⇒  debian Pastezone
[00:51:42] *** Joins: HuntsMan (~hunts@p5494d423.dip0.t-ipconnect.de)
[00:54:47] *** Quits: CaCode (~CaCode@user/cacode) (Quit: Leaving)
[01:06:46] <hodapp> wtf, think I somehow got myself into a case where a *higher* learning rate was causing me to severely *underfit*, not overfit
[01:06:59] <hodapp> either that or some kind of collapse
[01:07:03] * hodapp flips table again
[01:14:17] *** Quits: hygl (uid16621@id-16621.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[01:23:00] <acresearch> HuntsMan: all of them, rotation, width shift, height etc...    https://paste.debian.net/1224239/
[01:23:02] <SigmoidFroid> ⇒  debian Pastezone
[01:24:54] <dostoyevsky2> hodapp: is your main problem the intrinsic of floating point vs what the math says should work?
[01:38:34] *** Joins: CaCode (~CaCode@user/cacode)
[01:56:43] <HuntsMan> acresearch: did you tune the augmentations, or just use them all without evaluating each?
[01:58:03] *** Joins: georgios (~georgios@user/georgios)
[02:09:43] *** Joins: CaCode_ (~CaCode@user/cacode)
[02:10:07] *** Quits: manti7 (~manti7@185.107.94.249) (Quit: WeeChat 3.3)
[02:12:24] *** Quits: CaCode (~CaCode@user/cacode) (Ping timeout: 256 seconds)
[02:19:59] <hodapp> dostoyevsky2: no, it has nothing to do with floating point
[02:20:28] <hodapp> this just looks like transformers training weird and my habits on convnets not being applicable
[02:59:04] *** Joins: miique (~miique@181.46.139.166)
[03:04:44] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[03:16:01] *** Quits: georgios (~georgios@user/georgios) (Quit: Konversation terminated!)
[03:24:03] *** Joins: AbleBacon_ (~AbleBacon@user/AbleBacon)
[03:26:37] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Ping timeout: 240 seconds)
[03:42:25] *** AbleBacon_ is now known as AbleBacon
[04:04:36] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 256 seconds)
[04:31:14] *** Quits: CaCode_ (~CaCode@user/cacode) (Ping timeout: 256 seconds)
[04:37:28] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[04:45:39] *** Quits: defjam (~eb0t@90.210.94.161) (Ping timeout: 250 seconds)
[04:47:20] *** Joins: [_] (~itchyjunk@user/itchyjunk/x-7353470)
[04:47:57] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Ping timeout: 240 seconds)
[04:51:18] *** Joins: defjam (~eb0t@90.198.61.46)
[04:58:45] *** [_] is now known as [itchyjunk]
[05:20:42] *** Joins: foul_owl (~kerry@94.140.8.107)
[05:21:15] *** Joins: akevinhuang2 (~thekevinh@user/thekevinhuang)
[05:23:22] *** Quits: akevinhuang (~thekevinh@user/thekevinhuang) (Ping timeout: 256 seconds)
[05:47:10] *** Quits: SiegeLord (~sl@user/siegelord) (Quit: WeeChat 2.8)
[05:49:00] *** Joins: SiegeLord (~SiegeLord@user/siegelord)
[07:15:48] <acresearch> HuntsMan: well i tuned it a bit only to make sure i do not get crazy images, but i am not sure how to tune augmentation to an optimal level,
[07:49:57] *** Quits: akevinhuang2 (~thekevinh@user/thekevinhuang) (Ping timeout: 240 seconds)
[07:51:57] *** Quits: shoky (uuuggg@141.226.193.67) (Ping timeout: 240 seconds)
[07:55:10] *** Joins: shoky (uuuggg@141.226.193.67)
[08:04:03] *** Joins: shoky_ (uuuggg@141.226.193.67)
[08:05:57] *** Quits: shoky (uuuggg@141.226.193.67) (Ping timeout: 240 seconds)
[08:18:14] *** Quits: SiegeLord (~SiegeLord@user/siegelord) (Read error: Connection reset by peer)
[08:20:53] *** Joins: SiegeLord (~sl@user/siegelord)
[09:22:04] *** Quits: miique (~miique@181.46.139.166) (Quit: Leaving)
[09:23:26] *** Joins: miique (~miique@181.46.139.166)
[09:48:16] *** Quits: `Tim (~zenguin@user/zenguin) (Quit: Leaving)
[10:02:41] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Read error: Connection reset by peer)
[10:07:18] *** Joins: hygl (uid16621@id-16621.tinside.irccloud.com)
[10:28:16] *** Joins: manti7 (~manti7@176.10.104.94)
[10:49:44] *** Joins: sinaowolabi (~SinaOwola@41.58.240.230)
[10:56:36] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[11:18:02] *** Joins: palasso (~palasso@user/palasso)
[11:18:27] *** Joins: Klinda (~superleag@user/klinda)
[11:23:10] *** Quits: rvalue (~rvalue@user/rvalue) (Quit: ZNC - https://znc.in)
[11:44:11] <Klinda> as I can see if the dataset is unbalanced, the accuracy score should not take into account
[11:44:27] <Klinda> but auc, classification report are more useful
[11:44:42] <Klinda> confusion matrix too
[11:45:01] <Klinda> in youtube you see all saying "oh wow 99% accuracy"
[11:45:10] <Klinda> but they don't mention if the dataset is balanced or not
[11:45:17] <Klinda> all noobs or what?
[11:45:42] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
[11:51:41] *** Joins: rvalue (~rvalue@user/rvalue)
[11:54:56] *** Quits: jlrnick (~josephler@42.118.113.78.rev.sfr.net) (Ping timeout: 256 seconds)
[12:09:16] *** Joins: sinaowolabi_ (~SinaOwola@102.134.114.1)
[12:09:19] <acresearch> Klinda: true, but my dataset is ballanced 300 images for all 5 classes
[12:16:01] <Klinda> I was talking in general, not your case, I study cnn in the next year
[12:16:21] <Klinda> are you doing a cnn right?
[12:16:28] *** Quits: sinaowolabi_ (~SinaOwola@102.134.114.1) (Ping timeout: 256 seconds)
[12:16:30] *** Quits: sinaowolabi (~SinaOwola@41.58.240.230) (Ping timeout: 260 seconds)
[12:20:16] <acresearch> Klinda: yes i am
[12:20:52] <Klinda> I will do with the teacher HuntsMan like
[12:22:10] <acresearch> :-)
[12:22:53] <Klinda> with him this semster I did the comparison with the histograms
[12:23:18] <Klinda> you can actually predict the real image by doing the histograms and compute the distance
[12:23:42] <Klinda> (object identification)
[12:24:22] <Klinda> if you have one image that represent an apple, if you have more images in different positions you can predict what image is with the histograms
[12:25:11] <Klinda> then he explained also the convolution of images and apply some blur/smooth effects to an image
[12:25:16] <acresearch> Klinda: interesting, i have trained several object detection datasets with YOLO but did not face any issues, can you link me to this article, i would like to understand
[12:25:18] <Klinda> kernel etc
[12:29:43] *** Joins: sinaowolabi_ (~SinaOwola@160.152.55.191)
[12:33:31] <Klinda> acresearch: here you can see the full course of the next year: https://github.com/GioFic95/AML-19-20-notes/blob/master/AML_notes.pdf is done by someone that did it
[12:33:32] <SigmoidFroid> ⇒  AML-19-20-notes/AML_notes.pdf at master · GioFic95/AML-19-20-notes · GitHub
[12:33:56] <Klinda> actually the first part he did with "fundamentals of data science" is about the first part
[12:34:34] <Klinda> this talk about cnns too
[13:03:01] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
[13:03:56] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[13:07:28] *** Quits: sinaowolabi_ (~SinaOwola@160.152.55.191) (Ping timeout: 256 seconds)
[13:09:44] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Ping timeout: 256 seconds)
[13:20:37] *** Quits: jlrnick (~josephler@42.118.113.78.rev.sfr.net) (Remote host closed the connection)
[13:21:38] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
[13:22:06] *** Joins: sinaowolabi (~SinaOwola@41.58.202.218)
[13:31:27] *** Quits: jlrnick (~josephler@42.118.113.78.rev.sfr.net) (Remote host closed the connection)
[13:46:53] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
[13:52:52] *** Quits: jlrnick (~josephler@42.118.113.78.rev.sfr.net) (Remote host closed the connection)
[13:59:39] *** Joins: jinsun__ (~quassel@user/jinsun)
[14:00:37] *** Quits: jinsun (~quassel@user/jinsun) (Ping timeout: 240 seconds)
[14:03:38] *** Joins: jinsun (~quassel@user/jinsun)
[14:04:52] *** Joins: jinsun___ (~quassel@user/jinsun)
[14:07:17] *** Quits: jinsun__ (~quassel@user/jinsun) (Ping timeout: 240 seconds)
[14:07:17] *** Quits: Klinda (~superleag@user/klinda) (Ping timeout: 240 seconds)
[14:07:37] *** Quits: jinsun (~quassel@user/jinsun) (Ping timeout: 240 seconds)
[14:14:20] *** Joins: Klinda (~superleag@user/klinda)
[14:17:40] *** Joins: jinsun (~quassel@user/jinsun)
[14:21:42] *** Quits: jinsun___ (~quassel@user/jinsun) (Ping timeout: 256 seconds)
[14:29:02] *** Quits: jinsun (~quassel@user/jinsun) (Ping timeout: 260 seconds)
[14:31:48] *** Quits: SiegeLord (~sl@user/siegelord) (Quit: WeeChat 2.8)
[14:33:51] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[14:48:17] *** Quits: Klinda (~superleag@user/klinda) (Ping timeout: 240 seconds)
[14:59:48] *** Joins: Klinda (~superleag@user/klinda)
[15:02:30] *** Quits: sinaowolabi (~SinaOwola@41.58.202.218) (Ping timeout: 256 seconds)
[15:19:03] <Klinda> acresearch: did you find it useful?
[15:29:42] *** Joins: jinsun (~quassel@user/jinsun)
[15:46:42] *** Quits: jinsun (~quassel@user/jinsun) (Read error: Connection reset by peer)
[15:48:28] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
[15:48:35] *** Joins: jinsun (~quassel@user/jinsun)
[16:18:37] *** Quits: jlrnick (~josephler@42.118.113.78.rev.sfr.net) (Ping timeout: 240 seconds)
[16:20:25] *** Joins: CaCode (~CaCode@user/cacode)
[16:28:00] *** Joins: CaCode_ (~CaCode@user/cacode)
[16:30:54] *** Quits: CaCode (~CaCode@user/cacode) (Ping timeout: 256 seconds)
[16:53:11] *** Joins: `Tim (~zenguin@user/zenguin)
[17:32:22] <acresearch> Klinda: i am not sure how to use this in my current project, but it seems interesting
[17:45:21] *** Quits: acresearch (~acresearc@user/acresearch) (Ping timeout: 245 seconds)
[17:45:52] *** Quits: CaCode_ (~CaCode@user/cacode) (Quit: Leaving)
[18:07:15] *** Joins: acresearch (~acresearc@user/acresearch)
[18:18:09] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[18:37:11] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
[18:37:57] *** Quits: jinsun (~quassel@user/jinsun) (Ping timeout: 240 seconds)
[18:39:35] *** Joins: georgios (~georgios@user/georgios)
[18:43:00] *** Joins: jinsun (~quassel@user/jinsun)
[18:45:08] *** Joins: tomeaton17 (~tomeaton1@92.234.2.175)
[18:49:04] *** Quits: jinsun (~quassel@user/jinsun) (Ping timeout: 268 seconds)
[18:54:02] *** Joins: jinsun (~quassel@user/jinsun)
[19:06:41] *** Joins: sobobobobo (~sobobobob@85-76-74-73-nat.elisa-mobile.fi)
[19:07:56] *** Quits: sobobobobo (~sobobobob@85-76-74-73-nat.elisa-mobile.fi) (Client Quit)
[19:23:47] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[19:29:20] <hodapp> hrmph. still running into an effect on my transformers (ViT) in which setting a *higher* LR causes the training loss to plateau
[19:31:43] <hodapp> which is bizarre to me since ordinarily I'd expect that if you push LR too high, you will see the training loss drop much further, but without a corresponding improvement in validation
[19:37:02] *** Quits: hygl (uid16621@id-16621.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[19:48:02] *** Joins: hygl (uid16621@id-16621.tinside.irccloud.com)
[19:58:31] *** Joins: Klinda (~superleag@user/klinda)
[20:04:53] <dostoyevsky2> hodapp: if you have small local optimums a larger LR might just skip over them...
[20:06:06] <hodapp> this is possible
[20:06:54] <hodapp> it's just bizarre to me that two completely different networks (different parameters, different internal # dimensions on something, separate pre-training runs) both somehow end up plateauting at almost exactly the same loss
[20:07:41] <hodapp> I'm also not doing something the papers mentioned, as I've not figured out how yet - they use layer-wise learning rate decay with factor of 0.75
[20:08:09] <hodapp> so I guess 'last' layer gets the real LR, previous layer to that is lr*0.75, before that is lr*(0.75^2), ...
[20:08:39] <hodapp> which makes sense if it's for fine-tuning and they don't want the earlier layers to have catastrophic forgetting
[20:31:27] *** Joins: akevinhuang (~thekevinh@user/thekevinhuang)
[20:37:24] *** Quits: Klinda (~superleag@user/klinda) (Ping timeout: 256 seconds)
[20:41:35] *** Quits: georgios (~georgios@user/georgios) (Quit: Konversation terminated!)
[20:55:59] *** Joins: Klinda (~superleag@user/klinda)
[21:09:37] *** Quits: tomeaton17 (~tomeaton1@92.234.2.175) (Quit: Client closed)
[21:10:15] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[21:15:03] *** Joins: sinaowolabi (~SinaOwola@41.58.210.189)
[21:24:45] *** Joins: shoky (uuuggg@141.226.193.67)
[21:24:57] *** Quits: shoky_ (uuuggg@141.226.193.67) (Ping timeout: 240 seconds)
[21:50:06] *** Joins: acresearch1 (~acresearc@user/acresearch)
[21:51:25] *** Quits: acresearch (~acresearc@user/acresearch) (Ping timeout: 240 seconds)
[22:46:29] *** Joins: georgios (~georgios@user/georgios)
[22:51:20] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[23:04:57] *** Joins: nagefire (~nagefire@66-219-236-165.dynamic.ip.veracitynetworks.com)
[23:05:20] *** Parts: nagefire (~nagefire@66-219-236-165.dynamic.ip.veracitynetworks.com) (WeeChat 3.3)
[23:13:07] *** Joins: SiegeLord (~sl@user/siegelord)
[23:39:59] <dostoyevsky2> https://github.com/vivekhsridhar/GODM -- decision making models for fruit flies and other insects...
[23:40:00] <SigmoidFroid> ⇒  GitHub - vivekhsridhar/GODM
[23:41:18] <hodapp> only decision I make with fruit flies is where to move my hand to swat them
[23:41:34] *** Quits: jlrnick (~josephler@42.118.113.78.rev.sfr.net) (Remote host closed the connection)
[23:42:19] <mefistofeles> dostoyevsky2: interesting
[23:57:17] *** Joins: jlrnick (~josephler@42.118.113.78.rev.sfr.net)
