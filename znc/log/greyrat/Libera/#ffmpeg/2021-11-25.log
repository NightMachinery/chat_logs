[00:00:55] <SamHenderson> Is there a way I can compile just the ffmpeg tools (ffplayer, ffprobe, etc etc) without building the ffmpeg libs?
[00:01:13] <furq> well they all depend on those libs
[00:01:35] <SamHenderson> Or I guess I could just build ffmpeg from source on my Fedora 27 machine and see if that works
[00:01:59] <SamHenderson> Yeah.  I have all the libs installed thanks to dnf install ffmpeg ffmpeg-devel
[00:03:18] <furq> well then you already have ffmpeg linked against those versions of the libs
[00:06:35] <SamHenderson> Yep.  But for some reason, when I try to compile and link my own code against those libs I get that weird "Invalid data found when processing input" ...  But the ffplayer program does play the video (or .txt file)
[00:06:44] *** Quits: wootehfoot (~wootehfoo@user/wootehfoot) (Quit: Leaving)
[00:06:45] *** Quits: Volgaar (~volgaar@193.137.116.78.rev.sfr.net) (Quit: WeeChat 3.3)
[00:07:19] <SamHenderson> I don't believe Fedora compiles anything when installing with dnf ... it just grabs pre-built rpm files and installs them right?
[00:08:06] <SamHenderson> So that's why I wanted to compile ffplayer.c to see if my compiled ffplayer.c also fails the same way as my demo program.
[00:08:20] <SamHenderson> I suspect it would.
[00:12:06] <SamHenderson> Now I do know that my demo program works fine in Fedora 35.
[00:12:30] <SamHenderson> But I presume that Fedora 35 is using much newer libraries etc.
[00:13:10] <furq> well git head probably won't build against such old libraries in the first place
[00:18:48] <SamHenderson> Yeah I'd probably need to download an older version of ffmpeg
[00:19:55] <SamHenderson> I guess any version from the 2017 era would probably be fine.
[00:21:19] <SamHenderson> On my fedora 27 box I see 3.3.9
[00:21:45] *** Quits: arbitercoin (~Rheanna@218.78.53.13) (Remote host closed the connection)
[00:22:28] *** Joins: Moinsen (~Moinsen@port-92-201-104-202.dynamic.as20676.net)
[00:23:44] *** Joins: arbitercoin (~Rheanna@218.78.105.67)
[00:24:33] <Moinsen> Hello, does anyone have an idea how to get FFMPEG to first reset the metadata of a .flac file and then set Artist & Title, preferably in just one command?
[00:34:12] *** Quits: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net) (Ping timeout: 260 seconds)
[00:35:37] <SamHenderson> Hmm I guess the problem with my plan would be that the dependency projects (x264, x265, mp3lame, opus, vpx etc) are all way newer in their git repositories.  I'd have to hunt down older source trees of each project...
[00:39:18] *** Joins: ttys000 (~ttys000@user/ttys000)
[00:40:30] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[01:01:56] *** Quits: Moinsen (~Moinsen@port-92-201-104-202.dynamic.as20676.net) (Quit: Connection closed)
[01:02:28] *** Quits: cosimone (~user@93-47-230-47.ip115.fastwebnet.it) (Quit: ERC (IRC client for Emacs 27.1))
[01:11:49] *** Quits: fkaa (~fkaa@81-226-20-99-no256.tbcn.telia.com) (Remote host closed the connection)
[01:11:50] *** Quits: arbitercoin (~Rheanna@218.78.105.67) (Remote host closed the connection)
[01:13:36] *** Joins: arbitercoin (~Rheanna@218.78.53.13)
[01:14:14] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[01:18:50] *** Quits: admal (~admal@gateway/tor-sasl/admal) (Remote host closed the connection)
[01:20:48] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[01:30:00] *** Quits: alban771 (~alban@37.165.215.213) (Quit: WeeChat 3.3)
[01:31:53] *** Joins: GuiToris (~GuiToris@user/guitoris)
[01:32:16] <GuiToris> hello, hopefully my question makes sense; does ffmpeg handle iTunSMPB?
[01:33:15] <GuiToris> I'm not sure if I should use no-delay with qaac if I'd like to remux with ffmpeg
[01:45:29] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[01:50:46] *** Joins: Moinsen (~Moinsen@port-92-201-104-202.dynamic.as20676.net)
[01:52:13] *** Joins: tlacatlc6 (~tlacatlc6@097-101-132-062.res.spectrum.com)
[01:58:30] *** Joins: jarthur (~jarthur@cpe-70-114-198-37.austin.res.rr.com)
[02:01:42] <jarthur> Getting "Codec frame size is not set" copying an AC3 track from Matroska to mp4 container in 4.4.1. Known issue? I know there was a similar problem Niedermayer supposedly fixed years ago.
[02:01:46] *** Quits: arbitercoin (~Rheanna@218.78.53.13) (Remote host closed the connection)
[02:01:50] *** Quits: luni-4 (uid453292@id-453292.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[02:02:58] *** Joins: arbitercoin (~Rheanna@101.89.150.168)
[02:03:40] *** Quits: l4yer (~l4yer@195.181.170.210) (Read error: Connection reset by peer)
[02:05:51] *** Quits: Besnik_b (~qymyrxhiu@2a02:587:de0f:ab00:3ef3:f7c8:ea4a:9519) (Ping timeout: 264 seconds)
[02:06:13] *** Quits: Fusl (fusl@1.0.0.127.in-addr.arpa.li) (Excess Flood)
[02:06:31] *** Joins: Fusl (fusl@1.0.0.127.in-addr.arpa.li)
[02:08:15] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[02:25:16] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[02:27:56] *** Quits: shibboleth (~shibbolet@user/shibboleth) (Quit: shibboleth)
[02:28:05] *** Quits: auth (~auth@user/auth) (Ping timeout: 250 seconds)
[02:30:21] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[02:32:26] *** Quits: Guest9482 (~Buster@46.160.36.66) (Ping timeout: 245 seconds)
[02:37:59] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[02:44:52] *** Quits: Moinsen (~Moinsen@port-92-201-104-202.dynamic.as20676.net) (Quit: Connection closed)
[02:49:40] *** Quits: Flat (~flat@35.137.99.241) (Quit: Rip internet)
[02:52:59] *** Joins: Flat (~flat@35.137.99.241)
[02:56:40] *** Quits: GuiToris (~GuiToris@user/guitoris) (Quit: Sieben Acht Gute Nacht!)
[03:03:39] *** Quits: waagrr (~waagrr@220.85.70.23) (Ping timeout: 256 seconds)
[03:09:39] *** Quits: minimal (~minimal@user/minimal) (Quit: Leaving)
[03:18:54] *** Joins: waagrr (~waagrr@220.85.70.23)
[03:23:28] *** Joins: Guest9482 (~Buster@46.160.36.66)
[03:28:01] *** Quits: Guest9482 (~Buster@46.160.36.66) (Ping timeout: 256 seconds)
[03:35:21] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[03:38:44] *** Joins: h4d3443 (~h4d3443@14.202.211.51)
[03:39:37] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[03:46:04] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[04:00:20] *** Quits: h4d3443 (~h4d3443@14.202.211.51) (Remote host closed the connection)
[04:03:26] *** Quits: iive (~iive@87.119.101.204.client.entry.bg) (Quit: They came for me...)
[04:08:47] *** Joins: h4d3443 (~h4d3443@14.202.211.51)
[04:18:41] *** Quits: dreamon (~dreamon@pd9503f0b.dip0.t-ipconnect.de) (Ping timeout: 245 seconds)
[04:24:45] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[04:30:36] *** Joins: softworkz (~softworkz@user/softworkz)
[04:42:57] <tm512> does anyone know whether the scale filter functions as a no-op if the input and output resolutions are identical? I use ffmpeg within a script for video capture, and need to scale down occasionally, but then other times I don't. in the latter case I've just been removing the scale filter from the filter chain under the assumption that it might be pointlessly taking up CPU cycles
[04:44:00] <kepstin> note that the scale filter might be needed even if you're not resizing, in order to do pixel format conversions (e.g. rgb screen capture to yuv420p for video encoding)
[04:44:02] <tm512> but if it recognizes that the input and output resolutions are identical and just skips the whole scaling process, it'll save me from having to modify my script so frequently
[04:44:09] <kepstin> so it'll probably autoinsert one if you remove it
[04:44:17] <kepstin> (it'll use the one you had if you have one)
[04:46:33] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[04:52:03] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[05:00:18] *** Quits: h4d3443 (~h4d3443@14.202.211.51) (Remote host closed the connection)
[05:03:35] *** Joins: h4d3443 (~h4d3443@14.202.211.51)
[05:13:43] *** Quits: lucaswang (~lucaswang@58.246.19.98) (Quit: Connection closed)
[05:14:23] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[05:15:06] *** Joins: lucaswang (~lucaswang@58.246.19.98)
[05:20:00] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[05:27:15] <tm512> kepstin: hmm alright. in that case I'm guessing it knows not to try applying interpolation when the input and output resolution is the same
[05:30:13] *** Quits: h4d3443 (~h4d3443@14.202.211.51) (Remote host closed the connection)
[05:30:27] *** Joins: Guest55 (~Guest55@207.244.89.161)
[05:30:50] <Guest55> Hi, how can i loop the overlay
[05:30:51] <Guest55> ffmpeg -i mergedVideo.mp4 -vf  "movie=../dddd.mp4, scale=150: -1 [inner]; [in][inner] overlay =10: 10 [out]" completed.mp4
[05:31:02] <Guest55> the dddd.mp4 is the overlay
[05:31:56] <Guest55> What is the correct way to place the overlay and loop it forever until the mergedVideo.mp4 is end
[05:36:22] *** Joins: h4d3443 (~h4d3443@14.202.211.51)
[05:37:21] *** Joins: vlm (~vlm@user/vlm)
[05:46:17] *** Quits: af (~af@awalgarg.me) (Ping timeout: 256 seconds)
[05:49:21] *** Quits: SamHenderson (~SamHender@209.226.83.235) (Ping timeout: 250 seconds)
[05:50:16] *** Joins: SamHenderson (~SamHender@bras-base-ssmron9421w-grc-33-184-148-69-234.dsl.bell.ca)
[05:53:30] *** Joins: af (~af@awalgarg.me)
[05:56:20] *** Quits: ttys000 (~ttys000@user/ttys000) (Quit: Textual IRC Client: www.textualapp.com)
[06:02:01] *** Quits: c7s (~c7s@user/c7s) (Ping timeout: 245 seconds)
[06:03:57] *** Quits: Guest55 (~Guest55@207.244.89.161) (Quit: Client closed)
[06:05:20] *** Quits: iconoclasthero (~quassel@pool-68-238-241-198.phlapa.fios.verizon.net) (Ping timeout: 268 seconds)
[06:09:16] *** Joins: darkapex_ (~darkapex@user/darkapex)
[06:09:31] *** Quits: darkapex (~darkapex@user/darkapex) (Ping timeout: 245 seconds)
[06:19:33] *** Quits: h4d3443 (~h4d3443@14.202.211.51) (Remote host closed the connection)
[06:27:31] *** Joins: h4d3443 (~h4d3443@14.202.211.51)
[06:32:25] *** Joins: Guest55 (~Guest55@207.244.89.161)
[06:34:26] *** Quits: h4d3443 (~h4d3443@14.202.211.51) (Ping timeout: 256 seconds)
[06:34:39] <Guest55> any idea
[06:48:10] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[06:53:10] *** Quits: SamHenderson (~SamHender@bras-base-ssmron9421w-grc-33-184-148-69-234.dsl.bell.ca) (Ping timeout: 256 seconds)
[06:53:36] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[06:55:50] *** Joins: YuGiOhJCJ (~YuGiOhJCJ@gateway/tor-sasl/yugiohjcj)
[07:04:54] <Guest55> Hi, how can i loop the overlay
[07:04:55] <Guest55> ffmpeg -i mergedVideo.mp4 -vf  "movie=../dddd.mp4, scale=150: -1 [inner]; [in][inner] overlay =10: 10 [out]" completed.mp4
[07:04:57] <Guest55> ?
[07:09:16] *** Joins: mugli (~mugli@94-21-129-136.pool.digikabel.hu)
[07:12:06] *** Joins: SamHenderson (~SamHender@209.226.83.235)
[07:12:26] *** Quits: jos1 (~jos3@dyndsl-178-142-071-099.ewe-ip-backbone.de) (Ping timeout: 245 seconds)
[07:15:45] *** Joins: lavaball (felix@31.204.155.215)
[07:18:02] *** Quits: Guest55 (~Guest55@207.244.89.161) (Quit: Client closed)
[07:18:09] <SamHenderson> Hi everyone ... would it be possible to compile the ffmpeg libraries on an a very old version of Fedora?  (Fedora 27 ... which was current in around 2017)
[07:18:38] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[07:18:42] <SamHenderson> I have successfully built the static version of the ffmpeg libraries for ffmpeg 3.3.6
[07:19:54] <SamHenderson> But I realize I was a dummy and actually needed the shared versions ...  So rather than redo what I already did I was wondering if the most recent 4.x ffmpeg stuff would compile ... I am guessing no?
[07:23:45] <mugli> SamHenrerson GCC, glibc versions please
[07:24:58] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[07:25:38] *** Joins: jos1 (~jos3@dyndsl-091-248-048-046.ewe-ip-backbone.de)
[07:26:57] *** Joins: Vonter (~Vonter@user/vonter)
[07:30:41] <SamHenderson> glibc 2.26
[07:30:55] <SamHenderson> gcc 7.2.1
[07:31:05] *** Joins: Fohsap (~Muimi@2401:c080:1c02:ed3:5400:3ff:feb1:90a2)
[07:33:15] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[07:40:06] <youmustrust> Hi, guys. I'm piping an RTMP publish to FFmpeg, but I got these messages: "Non-monotonous DTS in output stream 0:1; previous: 299018743, current: 298995751; changing to 299018744. This may result in incorrect timestamps in the output file". I think forcibly rewriting timestamps to be monotonic would incur audio <> video desynchronization. Can I avoid that with `-copyts`?
[07:43:16] *** Quits: haihao (~haihao@192.55.46.56) (Quit: WeeChat 2.8)
[07:44:47] *** Joins: haihao (~haihao@192.102.204.55)
[07:45:13] <grovestreet> does anyone have any info on what affects operating time the most? trying to figure out how a shared server i used took 2 hours to encode while a private one took 12 hours for the same file with the same commands
[07:46:38] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[07:46:41] <tar_xvf> in my experience the bottleneck is almost always video encoding unless you use hardware accelerated graphics
[07:47:12] <tar_xvf> so if you used a powerful machine that had a lot of threads it may have been able to split up the video encoding between different cores/threads
[07:52:29] <youmustrust> is there a way to drop a non-monotonically increasing packet?
[07:56:49] *** Quits: waleee (~waleee@h-82-196-111-63.NA.cust.bahnhof.se) (Quit: WeeChat 3.3)
[08:04:42] *** Joins: l4yer (~l4yer@195.181.170.210)
[08:05:35] *** Quits: a0z (~a0z@90.244.184.28) (Ping timeout: 268 seconds)
[08:06:01] *** Joins: wyatt8750 (~wyatt8740@37.19.196.214)
[08:06:12] *** Quits: wyatt8740 (~wyatt8740@149.164.111.65) (Ping timeout: 268 seconds)
[08:06:32] <jarthur> grovestreet I agree with tar_xvf. Cores/threads make a big difference if you're transcoding with x264 or x265. Also worth seeing which CPU instructions are available on one vs the other, e.g. not having avx and avx2 can make a difference in per-core performance. Worth checking your OS' swap size during an encode too. If the OS is swapping any part of the ffmpeg process, CPU operations will be going back and forth to your (slow) disk.
[08:07:20] <tar_xvf> jarthur: yes, ram also makes a difference, not only RAM i/o, but if you have enough or if it is going on and off swap.
[08:07:45] <furq> none of that will make a 6x difference
[08:08:00] <jarthur> swapping definitely can
[08:08:02] <furq> most likely the shared server has a lot of cores and you annoyed everyone else on the server
[08:08:37] <furq> or they're all busy reluctantly travelling to see their families
[08:09:39] <grovestreet> yeah i'm looking for alternatives but for personal so i don't hog the cpu usage lol
[08:10:15] <grovestreet> i was running encode after encode and 2 at once sometimes 😂
[08:12:29] *** Quits: l4yer (~l4yer@195.181.170.210) (Ping timeout: 256 seconds)
[08:13:16] <SamHenderson> If I want to compile ffmpeg with dynamic linking would my configure look like this:
[08:13:37] <SamHenderson> PATH="$HOME/bin:$PATH" PKG_CONFIG_PATH="$HOME/ffmpeg_build/lib/pkgconfig" ./configure \
[08:13:37] <SamHenderson>   --prefix="$HOME/ffmpeg_build" \
[08:13:38] <SamHenderson>   --pkg-config-flags="--dynamic" \
[08:13:38] <SamHenderson>   --extra-cflags="-I$HOME/ffmpeg_build/include" \
[08:13:39] <SamHenderson>   --extra-ldflags="-L$HOME/ffmpeg_build/lib" \
[08:13:39] <SamHenderson>   --extra-libs=-lpthread \
[08:13:40] <SamHenderson>   --extra-libs=-lm \
[08:13:40] <SamHenderson>   --bindir="$HOME/bin" \
[08:13:41] <SamHenderson>   --enable-gpl \
[08:13:41] <SamHenderson>   --enable-libfdk_aac \
[08:13:42] <SamHenderson>   --enable-libfreetype \
[08:13:42] <SamHenderson>   --enable-libmp3lame \
[08:13:43] <SamHenderson>   --enable-libopus \
[08:13:43] <SamHenderson>   --enable-libvpx \
[08:13:44] <SamHenderson>   --enable-libx264 \
[08:13:44] <SamHenderson>   --enable-libx265 \
[08:13:45] <SamHenderson>   --enable-nonfree
[08:13:45] <SamHenderson> make
[08:13:59] <SamHenderson> oops, disregard the make and make install ;)
[08:17:34] <SamHenderson> Nope.  Unknown option
[08:18:53] *** Joins: Fohsap_ (~Muimi@2401:c080:1c02:ed3:5400:3ff:feb1:90a2)
[08:19:52] <SamHenderson> Seems the solution to my problem was to just omit the pkg-config-flags line
[08:22:22] <jarthur> Yeah, I'd be shocked to find the default build is anything but dynamic.
[08:22:30] *** Quits: Fohsap (~Muimi@2401:c080:1c02:ed3:5400:3ff:feb1:90a2) (Ping timeout: 260 seconds)
[08:24:00] *** Joins: l4yer (~l4yer@2a07-a880-3101-1051-649b-e893-926b-2a0e.pool6.ovpn.com)
[08:24:43] *** Quits: tlacatlc6 (~tlacatlc6@097-101-132-062.res.spectrum.com) (Quit: Leaving)
[08:25:50] *** Quits: rvalue (~rvalue@user/rvalue) (Ping timeout: 260 seconds)
[08:34:47] *** Quits: Icycle (~icedream@hzn-b.serverkomplex.de) (Quit: A lol made me boom.)
[08:36:47] <kepstin> indeed, you only need to do special things if you want a staticly linked ffmpeg binary.
[08:37:02] <SamHenderson> Good to know
[08:37:44] *** Joins: Icedream (~icedream@144.76.223.175)
[08:39:56] *** Quits: l4yer (~l4yer@2a07-a880-3101-1051-649b-e893-926b-2a0e.pool6.ovpn.com) (Ping timeout: 245 seconds)
[08:41:30] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[09:16:45] *** Quits: YuGiOhJCJ (~YuGiOhJCJ@gateway/tor-sasl/yugiohjcj) (Quit: YuGiOhJCJ)
[09:18:56] *** Joins: l4yer (~l4yer@195.181.170.210)
[09:34:57] *** Joins: rvalue (~rvalue@user/rvalue)
[09:46:48] *** Joins: yeirr (~yeirr@user/yeirr)
[10:06:41] *** Joins: c7s (~c7s@user/c7s)
[10:18:53] *** Joins: Fohsap__ (~Muimi@119.112.253.239)
[10:21:45] *** Quits: arbitercoin (~Rheanna@101.89.150.168) (Remote host closed the connection)
[10:22:01] *** Quits: Fohsap_ (~Muimi@2401:c080:1c02:ed3:5400:3ff:feb1:90a2) (Ping timeout: 245 seconds)
[10:22:20] *** Joins: arbitercoin (~Rheanna@218.78.105.67)
[10:31:37] *** Quits: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com) (Quit: Bye...)
[10:37:56] *** Joins: demon__ (~user@197.54.97.208)
[10:38:19] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[10:44:21] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[10:45:43] *** Joins: kib (~kib@user/kib)
[10:47:40] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[10:49:53] *** tinystoat is now known as typonese
[10:50:59] *** typonese is now known as tinystoat
[10:57:51] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 245 seconds)
[11:07:18] *** Joins: auth (~auth@user/auth)
[11:09:34] *** Joins: nillyhan (~00000000@user/nillyhan)
[11:09:53] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[11:10:10] *** Quits: xkuru (~xkuru@user/xkuru) (Read error: Connection reset by peer)
[11:13:41] *** Quits: l4yer (~l4yer@195.181.170.210) (Ping timeout: 245 seconds)
[11:14:32] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[11:19:52] *** Joins: dreamon (~dreamon@ppp-88-217-65-149.dynamic.mnet-online.de)
[11:37:20] *** Joins: palasso (~palasso@user/palasso)
[11:37:41] *** Quits: jarthur (~jarthur@cpe-70-114-198-37.austin.res.rr.com) (Quit: jarthur)
[11:45:00] *** Quits: thebombzen_ (~thebombze@c-68-41-54-207.hsd1.mi.comcast.net) (Quit: Quit)
[11:58:07] *** Quits: yeirr (~yeirr@user/yeirr) (Quit: yeirr)
[12:03:08] *** Joins: cmp (~cmp@lputeaux-658-1-177-87.w92-154.abo.wanadoo.fr)
[12:05:40] *** Quits: roman_ (~roman@mob-194-230-147-119.cgn.sunrise.net) (Remote host closed the connection)
[12:06:03] *** Joins: roman_ (~roman@mob-194-230-147-119.cgn.sunrise.net)
[12:20:01] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 250 seconds)
[12:28:26] *** Joins: luni-4 (uid453292@id-453292.ilkley.irccloud.com)
[12:35:25] *** Quits: SamHenderson (~SamHender@209.226.83.235) (Quit: Connection closed)
[12:39:09] *** Joins: cosimone (~user@2001:b07:ae5:db26:a7aa:8027:6b4e:2fb3)
[12:44:09] *** Joins: GuiToris (~GuiToris@user/guitoris)
[12:44:19] *** Quits: grovestreet (~grovestre@92.119.18.7) (Ping timeout: 268 seconds)
[12:44:33] <GuiToris> hello, hopefully my question makes sense; does ffmpeg handle iTunSMPB?
[12:44:41] <GuiToris> I'm not sure if I should use no-delay with qaac if I'd like to remux with ffmpeg
[12:50:27] *** Quits: beaver (~beaver@user/pong) (Ping timeout: 276 seconds)
[12:52:01] *** Quits: arbitercoin (~Rheanna@218.78.105.67) (Remote host closed the connection)
[12:52:55] *** Joins: arbitercoin (~Rheanna@218.78.104.50)
[12:56:53] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[13:02:22] *** Joins: beaver (~beaver@user/pong)
[13:06:04] <Lynne> yes, it supports is
[13:07:52] <GuiToris> Lynne, does it matter if I use no-delay with qaac? Should I leave it out?
[13:08:17] <GuiToris> I wouldn't like the audio to not be in sync with the video
[13:14:11] *** Joins: Blacker47 (~Blacker47@user/blacker47)
[13:20:19] <Lynne> no idea what that option does, but everything will be in sync as long as qaac outputs a correct m4a/mp4 container
[13:29:38] *** Quits: pit (~quassel@v22016102921539034.goodsrv.de) (Ping timeout: 260 seconds)
[13:39:50] <GuiToris> Lynne, --no-delay 'Compensate encoder delay by prepending 960 samples of silence, then trimming 3 AAC frames from the beginning (and also tweak iTunSMPB). This option is mainly intended for resolving A/V sync issue of video.'
[13:41:25] <GuiToris>  in case of movie you remux the resulting .m4a to another container file. So, the delay information can be lost in the remuxing process. Even when it is not lost, player might not take care of the audio delay very well. Therefore, --no-delay comes as the easiest way to avoid tiny A/V sync issue due to the delay (it is 40ms or so). --no-delay option simply compensates the delay.
[13:41:27] <GuiToris> However, using --no-delay means that necessary priming samples are not encoded in the result, so first 20ms or so cannot be correctly reconstructed.
[13:41:31] <GuiToris> I have no clue now
[13:41:46] *** Quits: arbitercoin (~Rheanna@218.78.104.50) (Remote host closed the connection)
[13:42:00] <GuiToris> (I copied them from qaac's website)
[13:43:33] *** Joins: arbitercoin (~Rheanna@218.78.53.13)
[13:43:38] <Lynne> disable it, sounds like a hack for bad devices that don't support trimming
[13:46:27] *** Quits: Kei_N_ (~Kei_N@user/kei-n/x-2886111) (Ping timeout: 265 seconds)
[13:47:01] <GuiToris> thank you for your help :)
[13:47:16] *** Joins: Kei_N (~Kei_N@user/kei-n/x-2886111)
[13:56:34] *** Joins: pit (~quassel@v22016102921539034.goodsrv.de)
[14:05:42] *** Joins: grovestreet (~grovestre@92.119.18.58)
[14:06:59] *** Quits: kib (~kib@user/kib) (Quit: WeeChat 3.3)
[14:23:37] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 268 seconds)
[14:25:22] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 256 seconds)
[14:27:14] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[14:28:37] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[14:35:25] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 250 seconds)
[14:58:46] *** Quits: darkapex_ (~darkapex@user/darkapex) (Ping timeout: 260 seconds)
[14:59:01] *** Joins: darkapex (~darkapex@user/darkapex)
[15:01:35] *** Joins: admal (~admal@gateway/tor-sasl/admal)
[15:03:36] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 260 seconds)
[15:10:16] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[15:15:14] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 256 seconds)
[15:16:49] *** Joins: wootehfoot (~wootehfoo@user/wootehfoot)
[15:19:35] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[15:26:52] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[15:29:24] *** Quits: Jerrk (~Jerrk@193.138.218.218) (Read error: Connection reset by peer)
[15:33:19] *** Joins: Jerrk (~Jerrk@45.83.220.194)
[15:36:30] *** Joins: yuri6037 (~quassel@yuristudio.net)
[15:37:51] <yuri6037> Hi, I have a question about FFMPEG: is FFMPEG capable of replacing ALL frames of a video by a set of images named frame%d.png where %d is the frame index?
[15:49:44] <emcodem> @yuri6037 replace all frames essentialy means that you first generate a video by reading the image sequence and then you map the audios from the source files to your newly generated video stream i guess
[15:49:52] <gnoo> yuri6037: maybe something like this? ffmpeg -i video.mp4 -i 'frame%d.png' -r 1 -map 1:v -map 0:a -c:a copy -c:v libx265
[15:51:13] <yuri6037> The problem is for a AI application. I have a bunch of processing which works on individual video frames (that I extract by OpenCV). The issue is once you reassemble sound it's out of sync: reassembling wav file with a mkv file produces out of sync audio
[15:54:08] <yuri6037> Currently my procedure is like this:
[15:54:08] <yuri6037> - OpenCV extract mov frames to individual PNG files
[15:54:08] <yuri6037> - FFMPEG extract mov to wav file
[15:54:08] <yuri6037> - OpenCV reassemble video in FFV1 (can't use H264 go ask why the fuck opencv-python decided to use improper license)
[15:54:08] <yuri6037> - FFMPEG reassemble audio wav file into FFV1 and transcode to H264 mkv
[15:55:03] <yuri6037> FFV1 is unusable except on high end machines whereas H264 is much easier to play back
[15:55:35] <yuri6037> The problem is the final mkv output has its audio out of sync
[15:57:04] <yuri6037> So I'd like to replace this procedure or some parts of it to fix audio out of sync
[15:57:09] <BtbN> You'll need to make sure to carry the frames timestamps through that process
[15:57:25] <BtbN> otherwise the guesswork when putting it back together in the end will always be a inaccurate
[15:58:01] <yuri6037> and how do I do this is there any way FFMPEG takes the source video and auto finds those timestamps?
[15:58:21] <BtbN> ffmpeg will never give you a frame without timestamp attached.
[15:58:59] <BtbN> You just have to somehow attach it and carry it through the non-ffmpeg stuff you're doing. And put it on the frame you finally give back to ffmpeg.
[15:59:06] <yuri6037> For my bunch of processing after it I need frames to be named frame0 frame1 etc
[15:59:19] <BtbN> Oh, you're decoding to files, and not using the API
[15:59:24] <BtbN> yeah, that's gonna be impossible then
[15:59:33] <yuri6037> what is API?
[15:59:37] <yuri6037> What API?
[15:59:39] <BtbN> The FFmpeg API
[15:59:55] <BtbN> mostly libavformat and libavcodec in this case probably
[15:59:56] <yuri6037> Is this callable from Rust or C?
[16:00:04] <BtbN> It's literally a C library...
[16:02:05] <yuri6037> Do you some doc/example I can use to extract frames, and reassemble video with audio?
[16:02:36] <BtbN> There's a ton of examples in the ffmpeg docs directory
[16:02:42] <yuri6037> I've never used libavformat and libavcodec. I know C however
[16:02:50] *** Quits: haihao (~haihao@192.102.204.55) (Ping timeout: 256 seconds)
[16:02:57] *** Joins: Kei_N_ (~Kei_N@user/kei-n/x-2886111)
[16:03:00] <BtbN> https://git.videolan.org/?p=ffmpeg.git;a=tree;f=doc/examples;hb=HEAD
[16:03:10] *** Quits: rvalue (~rvalue@user/rvalue) (Ping timeout: 260 seconds)
[16:04:33] *** Joins: haihao (~haihao@192.55.46.56)
[16:05:33] *** Quits: Kei_N (~Kei_N@user/kei-n/x-2886111) (Ping timeout: 250 seconds)
[16:06:58] <yuri6037> I see in these examples they hardcode some codec is there any way to make it auto detect codec from source video container?
[16:09:10] <roxlu> I've just started implementing a thread that I use to write `AVPacket`s that I get from `avcodec_receive_packet()`.  But I must be doing something wrong as .. https://imgur.com/a/5OqzPOD :).
[16:09:52] *** Joins: lavaball (felix@31.204.155.215)
[16:10:02] <roxlu> I suspect that a buffer is used before it's should be. Does a AVPacket maybe references the encoded frame?
[16:10:50] <BtbN> You can probe the file for its codec, sure
[16:11:02] <yuri6037> and how to do that?
[16:11:21] <BtbN> There's a probe function somewhere. I'm sure at least one example uses it?
[16:11:44] *** Quits: arbitercoin (~Rheanna@218.78.53.13) (Remote host closed the connection)
[16:13:08] *** Joins: tlacatlc6 (~tlacatlc6@097-101-132-062.res.spectrum.com)
[16:13:30] *** Joins: arbitercoin (~Rheanna@61.171.38.68)
[16:14:18] <yuri6037> I've found a ffmpeg-sys in Rust which seem to be some kind of lib package combining avcodec and avformat
[16:17:13] <yuri6037> The thing is there's info on whatever format is the AVFrame data in? Is it a RGB pixel array or some other type of format?
[16:17:20] <yuri6037> *no
[16:18:01] *** Joins: beshoo (~beshoo@94.47.2.79)
[16:18:18] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 268 seconds)
[16:18:25] <beshoo> how can i Loop the overlay
[16:18:26] <beshoo> ffmpeg -i   Wildlife.wmv -vf   "movie=input3.mp4, scale=250: -1 [inner]; [in][inner] overlay =10: 10 [out]" completed.mp4
[16:19:15] <beshoo> the overlay input3.mp4 lenth is 10 sec but the  Wildlife.wmv is 5 min, i need the overlay to loop
[16:25:42] <BtbN> yuri6037, every AVFrame has a pixel format attached to it
[16:25:55] <BtbN> if you need a specific one, you'll also need swscale
[16:26:09] <BtbN> FFmpeg is a C library though, so can't help you with anything rust.
[16:26:15] <yuri6037> I need a pixel format compatible with PNG
[16:26:29] <BtbN> Why do you need png to begin with?
[16:26:33] <yuri6037> and the conversion has to be lossless
[16:26:41] <BtbN> Can't you just send the frame to opencv?
[16:26:51] <BtbN> conversion between yuv and rgb is never lossless
[16:27:00] <yuri6037> Because the processing is using images as input
[16:27:03] <BtbN> it's not exactly lossy, but never perfect
[16:27:12] <BtbN> An AVFrame is an image
[16:27:25] <BtbN> I'm sure it's possible to give it to opencv directly
[16:27:45] <yuri6037> the thing the processing doesn't use opencv
[16:27:56] *** Joins: Kei_N (~Kei_N@user/kei-n/x-2886111)
[16:28:05] <yuri6037> the processing uses Pytorch and Tensorflow
[16:28:20] *** Quits: morpheuz (~morpheuz@user/morpheuz) (Ping timeout: 256 seconds)
[16:28:27] <yuri6037> and it operates on RGB
[16:28:27] <BtbN> I'm sure those will able be able to take an image without first dumping it to disk
[16:28:43] <BtbN> swscale convert to RGB then, and find out how to pass the buffer to those libraries
[16:28:47] *** Joins: morpheuz (~morpheuz@user/morpheuz)
[16:29:02] <yuri6037> I can't pass from memory it has to be saved to disk
[16:29:28] <yuri6037> there's not one processing there's multiple and they use totally incompatible languages
[16:29:46] <BtbN> Well, what you want is impossible then
[16:29:58] <BtbN> png images have no timestamps attached. So that information is inevitably going to get lost.
[16:30:32] <yuri6037> yeah but nobody said that using additional files isn't allowed
[16:30:43] <BtbN> I don't think I follow
[16:30:46] *** Quits: Kei_N_ (~Kei_N@user/kei-n/x-2886111) (Ping timeout: 245 seconds)
[16:31:24] <yuri6037> if you can give me a way to get those timestamps from AVFrame I can save them using another file format of my own invention
[16:31:36] <BtbN> It's literally a field in the AVFrame that carries it
[16:32:04] <yuri6037> assuming these timestamps can be integers or floats but ideally integers are better because they sure to never loose any precision
[16:32:20] <BtbN> It's 64 bit integers, in time_base units.
[16:32:27] <BtbN> time_base is a fraction
[16:32:37] <yuri6037> how do you time_base
[16:32:44] <BtbN> timestamps without their timebase are meaningless, so you need that as well
[16:32:48] <yuri6037> I've checked https://docs.rs/ffmpeg-sys/4.3.3/ffmpeg_sys/struct.AVFormatContext.html
[16:32:59] <BtbN> you just get it from the decoder/demuxer just like you get the timestamps
[16:33:02] <yuri6037> but there is no way to get frame rate and time base
[16:33:09] *** Quits: Hackerpcs (~user@user/hackerpcs) (Quit: Hackerpcs)
[16:33:16] *** Quits: morpheuz (~morpheuz@user/morpheuz) (Ping timeout: 245 seconds)
[16:33:22] <BtbN> No idea what that doc is, it's not the official ffmpeg docs
[16:34:08] <yuri6037> it's a rust binding that I'll need because I have to save to PNG and rust is much easier in that reguard
[16:34:12] <BtbN> https://git.videolan.org/?p=ffmpeg.git;a=blob;f=libavformat/avformat.h;h=0343825aa085a5afc321d065091d9d7098e0ecc0;hb=HEAD#l167
[16:34:25] <BtbN> Why would rust be "Much easier in that regard"?
[16:34:36] *** Joins: morpheuz (~morpheuz@user/morpheuz)
[16:34:45] <BtbN> If you call ffmpeg from C or Rust makes no difference for it, except that you put another layer of indirection between your code and it
[16:34:49] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[16:34:58] *** Joins: Hackerpcs (~user@user/hackerpcs)
[16:35:07] <yuri6037> But how do you get these info from AVFormatContext
[16:35:17] <BtbN> See the link
[16:35:23] <BtbN> it tells you which fields
[16:36:00] <BtbN> AVCodecContext also has a time_base field, and you need to fill it with what you got from avformat
[16:36:31] <BtbN> And it'll then eventually give you frames that have a timestamp attached to them, which is in that time_base
[16:36:44] <yuri6037> but how do I get AVFormat out of AVFormatContext
[16:37:08] <BtbN> That's where you either read the library documentation carefully, or just look at one of the examples that use it
[16:37:20] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[16:37:30] <BtbN> I also don't think plain "AVFormat" is a thing?
[16:37:35] <yuri6037> I've looked at examples and they're far from being complete
[16:38:01] <BtbN> They each demonstrate one specific aspect of the libraries. None of them will be a cookie cutter complete solution for your exact problem.
[16:38:07] <BtbN> You need to piece that together yourself.
[16:38:23] <yuri6037> I have no idea how to get the frame rate, time_base and all these fields from AVFormatContext which is my only way to load a video file not knowing inadvance what codec was used
[16:38:45] <BtbN> I also still think you don't need the roundabout way through files. There has to be a way to directly feed frames to those libs from memory.
[16:39:01] <BtbN> There is no frame rate.
[16:39:04] <BtbN> There's timestamps
[16:39:15] <yuri6037> well then it's impossible to encode a video
[16:39:17] <BtbN> The framerate then is what those timestamps make it to be
[16:39:21] <BtbN> No, not at all
[16:39:26] <yuri6037> according to the examples you require frame rate
[16:39:36] <yuri6037> https://git.videolan.org/?p=ffmpeg.git;a=blob;f=doc/examples/encode_video.c;h=939ed68324e101d058cd19df5524d6e988fd21c7;hb=HEAD
[16:39:58] <yuri6037> c->framerate = (AVRational){25, 1};
[16:40:07] <BtbN> It's just making the framerate up for convenience...
[16:40:52] <BtbN> Really not sure what else to tell you. I can't write your code for you, and there is no simple solution for what you're asking for. So you got to put the work of understanding stuff in yourself.
[16:40:53] <yuri6037> and this as well c->time_base = (AVRational){1, 25};
[16:41:06] <BtbN> It's just setting an arbitrary timebase as demo...
[16:41:19] <BtbN> since it's _only_ encoding, and has no input which would provide one
[16:41:22] <yuri6037> Yeah but I need to get these values from the source video
[16:41:37] <BtbN> Then look at an example that actually has a source video
[16:41:42] <yuri6037> So I need these values from AVFormatContext
[16:42:21] <yuri6037> I need to encode a video by reusing the info from a source video which I can't find any way to get these info from AVFormatContext
[16:42:52] <yuri6037> The only thing that AVFormatContext can give me is bit_rate NOTHING else
[16:43:12] <yuri6037> so how do I get time_base and frame_rate from this AVFormatContext
[16:43:24] <BtbN> Did you even read the link I gave you at all?
[16:43:30] <BtbN> It literally tells you which struct, and which field
[16:43:46] <BtbN> And there's also an example putting it all together to a complete transcoding example
[16:43:57] <yuri6037> What am I supposed to find in your link it's a big C file of a library I have no idea how to use
[16:44:41] <BtbN> I linked you to the exact line that tells you where to find the time base
[16:44:42] *** Joins: Kei_N_ (~Kei_N@user/kei-n/x-2886111)
[16:45:38] <yuri6037> You've sent me something about AVPacket wtf is AVPacket and again I don't have AVPacket I have AVFormatContext
[16:45:48] <BtbN> My god...
[16:45:58] <BtbN> I can't really help you if you insist on being that ignorant, sorry.
[16:46:40] *** Quits: teebz (~tcb@66.51.154.90) (Quit: The Lounge - https://thelounge.chat)
[16:46:57] *** Joins: teebz (~tcb@66.51.154.90)
[16:47:40] *** Quits: Kei_N (~Kei_N@user/kei-n/x-2886111) (Ping timeout: 260 seconds)
[16:49:25] <gnoo> i still think it should be possible with just ffmpeg binary. maybe not one single call but multiple ones to ffplay and ffmpeg? 1. get the framerate, 2. arrange the images in that framerate, make a video without sound. 3. map video of the new file with audio of the old ones. but i don't have much experience with ffmpeg to be honest...
[16:50:16] <BtbN> It's not that simple
[16:50:44] <BtbN> the audio can start before or after the video, so if you do it like that, you will almost always end up with them out of sync
[16:51:02] <BtbN> Only way to preverse sync is to preserve the timestamps of both
[16:51:15] <BtbN> *preserve
[16:51:51] <yuri6037> I'm not sure I can use this API in a limited time it's a huge code base documentation is absolutely terrible examples do not represent actual use cases and I also have no idea if it's usable from my remote machine
[16:52:30] <BtbN> Well, seems like you're out of luck then. The examples demonstrate very specific usecases of the libraries in an as conscise way as possible.
[16:52:41] <BtbN> If you call that "terrible examples", well... good luck with your project
[16:52:59] <yuri6037> They don't: no example is able to deocde a video with arbitary codec
[16:53:07] <BtbN> Yes they are
[16:53:17] <BtbN> the transcoding example at the very least opens arbitrary files
[16:53:26] <yuri6037> a typical example for me is to be able to decode from any codec most examples hardcode codecs so I can't use them
[16:53:49] <BtbN> They are examples for something else, that's why.
[16:55:25] <BtbN> You just have very messed up expectations. Dealing with A/V processing is one of the most complex things you can dive into. So expecting magic cookie cutter examples that demonstrate exactly your highly specific usecase is not something that's going to happen.
[16:56:32] <yuri6037> For me if I'm dealing with a lib which can decode video files I'm not interested in decoding only one type of file I'm interested in decoding any type
[16:56:58] <BtbN> Look at the example that opens arbitrary files then...
[17:02:19] *** Quits: arbitercoin (~Rheanna@61.171.38.68) (Remote host closed the connection)
[17:02:34] <yuri6037> At least this example is much more like what all other examples should look like https://git.videolan.org/?p=ffmpeg.git;a=blob;f=doc/examples/transcoding.c;h=badfba62cb3ec184f516a2b96189c8102edef085;hb=HEAD
[17:03:24] <BtbN> No, they should not look like that.
[17:03:51] <BtbN> If you want a complete example that does EVERYTHING, look at the ffmpeg.c CLI tool
[17:03:51] <yuri6037> litteraly this is the only example I found which shows how to decode arbitary video files
[17:03:54] *** Joins: arbitercoin (~Rheanna@218.78.94.61)
[17:04:10] <BtbN> The other examples are exactly what their name says. Examples for that specific aspect of the libraries.
[17:04:40] <BtbN> You need to put things together into an actual application yourself
[17:04:45] <yuri6037> yeah but like you take decode which looks like what I want to do but in fact not at all because it does not support arbitary videos
[17:05:08] <BtbN> It demonstrates precisely what it says. Decoding. And only decoding.
[17:05:24] <BtbN> Specifically not format probing and demuxing
[17:05:46] <yuri6037> I think I'll just keep opencv as frame extractor and use ffmpeg for re-assembly by reading data from input video and infering frame data from the PNG files generated by opencv
[17:06:30] <BtbN> You can't infer timestamps and time_base from a bunch of png images
[17:06:39] <BtbN> That just puts you back at square one
[17:06:46] <yuri6037> this way all time_base and other values are kept from source video I'll just replace frame data and frame size by whatever the processings generated
[17:07:30] *** Quits: Fohsap__ (~Muimi@119.112.253.239) (Remote host closed the connection)
[17:07:47] <yuri6037> You didn't understand I'll use opencv only as first step (extracting frames) I will then use the transcode example and replace just the part which write frame data by the corresponding PNG
[17:08:16] <BtbN> That's most likely not gonna work
[17:08:23] <yuri6037> why?
[17:08:24] <BtbN> frames can and will be re-ordered in real life video
[17:08:47] <yuri6037> why would I change the order?
[17:08:52] <BtbN> The codec does
[17:09:09] <BtbN> h264 will happily re-order frames to make encoding more efficient
[17:09:32] <BtbN> libavcodec then puts them back into their intended order
[17:09:37] <yuri6037> then I need some way to tell ffmpeg the exact index of the frame
[17:10:25] <yuri6037> like I have 140 frames numbered from 0 to 139. They should be injected in the video in that exact order from frame 0 to 139
[17:11:02] <yuri6037> I need FFMPEG to create a video from these frames numbered from 0 to 139
[17:11:25] <yuri6037> and using audio band from another .mov file
[17:12:41] <yuri6037> Like I need FFMPEG to keep frame rate, bit rate audio bit rate and audio data from a source .mov file and create a video keeping this data but using some PNG files as frame data
[17:13:18] <BtbN> Why do you even need that whole roundabout an inefficient way over png images?
[17:13:29] <BtbN> That's an entirely pointless and super slow roundtrip via the HDD
[17:13:42] <BtbN> I'm sure someone made an ffmpeg wrapper for Python
[17:14:04] <yuri6037> I already explained to you because the processing I do uses complicated machine learning some process also uses distributed machine learning
[17:14:38] <yuri6037> and most of these processes only accepts image data in RGB format
[17:14:38] <BtbN> ... and?
[17:14:49] <BtbN> Yes, ffmpeg will happily provide that
[17:15:07] <BtbN> Google points me to at least 3 python wrapper for it. Some more low level than others.
[17:15:29] <BtbN> I'm sure it's possible to decode to frames, convert them to RGB, and then pass to whatever other library you use
[17:15:48] <BtbN> And keeping the other frame metadata intact will also be a whole lot easier with that
[17:16:54] <yuri6037> In memory processing would be far too complicated for many of these processes and with distributed machine learning it's even worse without counting on higher RAM consumption
[17:17:27] <yuri6037> The ideal solution is to have FFMPEG read metadata from input video and frame data from input images
[17:17:42] <BtbN> I don't see how it's more complicated than first converting to png, writing it to disk, then reading it again in another process, only to write to some image AGAIN, and open it in another process again
[17:17:55] <BtbN> _that_ is what seems too complicated to me
[17:18:23] <yuri6037> because thoses processes are only designed to read from disk that's all
[17:18:35] <BtbN> But you're writing them yourself, right?
[17:18:35] <yuri6037> not from FFMPEG or memory
[17:18:40] <yuri6037> no I'm not
[17:18:44] <yuri6037> not all of them
[17:19:11] <BtbN> Well, if you need to insist on writing to png images, that information is inevitably going to get lost.
[17:19:12] <yuri6037> I'm not writing all these processes myself it's a combination of processes that operates on images
[17:19:32] <BtbN> Best you can do is manually stick an itsoffset in when stitching it back together, and hope the audio sync does not drift over time
[17:19:45] <yuri6037> then FFMPEG needs to write some db file alongside the PNG to store the additional info
[17:19:53] <BtbN> That's not something it does or can do, no
[17:20:39] <yuri6037> why not?
[17:20:55] <BtbN> Because nobody ever implemented anything like that.
[17:22:22] <BtbN> Not like it's impossible to write, but it's of limited use and seems like nobody so far needed it enough to actually write it.
[17:22:54] <BtbN> The proper way of doing this is to not pointlessly do a massive round trip over slow HDDs
[17:23:05] <BtbN> Or even SSDs. Still comparatively slow
[17:25:03] <yuri6037> According to this example: https://git.videolan.org/?p=ffmpeg.git;a=blob;f=doc/examples/encode_video.c;h=939ed68324e101d058cd19df5524d6e988fd21c7;hb=HEAD there's no timestamp needed when recording frames
[17:26:09] <BtbN> Where does it make that claims?
[17:26:20] <BtbN> It sets timebase and it sets the timestamp on every single frame
[17:26:34] <BtbN> It makes the timestamps up on the fly (it just counts up), but it very much does set them
[17:26:49] <yuri6037> but where do you see this
[17:26:59] <BtbN> See what?
[17:27:10] <yuri6037> is it frame->pts = i; which sets the timestamp?
[17:27:14] <BtbN> yes
[17:27:24] <yuri6037> oh well then this is the frame index
[17:27:29] <BtbN> Nope
[17:27:34] <BtbN> It's a timestamp in timebase units
[17:27:54] <BtbN> timebase was set to 1/25 before. So incrementing the timestamp by one advances time 1/25th of a second
[17:28:02] <yuri6037> in the example they just set it to the frame index
[17:28:18] <BtbN> They just count up by one, yes. The chosen timebase enables that
[17:28:31] <BtbN> in reality the timebase can be something like 1/90000 or other values
[17:28:45] <BtbN> If you just count up by 1 then, you get a very very slow video
[17:29:46] <yuri6037> can ffmpeg command line give time base?
[17:29:56] <yuri6037> for some random mov file?
[17:29:59] <BtbN> Pretty sure it prints the timebase somewhere when you transcode
[17:30:20] <BtbN> ffprobe might even have it somewhere in its json output
[17:31:17] <BtbN> In the most simple cases, which is what usually happens, the timebase actually is the inverse of the framerate. But that is by no means a given you can just rely on.
[17:31:33] <BtbN> And there is also no obligation for frames to start at timestamp 0
[17:31:45] <BtbN> They can start at some negative value, or at 200, or whatever they feel like
[17:34:57] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[17:36:58] *** Quits: morpheuz (~morpheuz@user/morpheuz) (Ping timeout: 260 seconds)
[17:38:01] <yuri6037> Is there any way to get more than 1 video stream in a AVFormatContext?
[17:38:11] *** Quits: GuiToris (~GuiToris@user/guitoris) (Remote host closed the connection)
[17:38:18] <yuri6037> Or is it always gonna be 1 stream audio and 1 stream video
[17:38:50] <BtbN> There can be pretty much arbitrary numbers of streams
[17:39:14] <BtbN> video is rather uncommon to have more than one, but it's not impossible
[17:39:24] <BtbN> audio with multiple languages you see much more often
[17:40:24] <yuri6037> can you detect in advance how many video streams are there without iterating AVStream and loading av codec context?
[17:40:27] <DHE> just keep calling avformat_new_stream()
[17:40:51] <yuri6037> My plan is to fail early if more than 1 video stream exists
[17:41:14] <yuri6037> I know none of my inputs will have more than 1 video stream in the same file
[17:43:00] *** Joins: lavaball (felix@31.204.155.215)
[17:43:38] <DHE> int i; for (i=0; i < avfctx->nb_streams; i++) { if (avfctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) { /*  Count and handle */ } }
[17:44:05] <DHE> are you using avformat_find_stream_info ?
[17:46:10] <yuri6037> yet I'm not using anything I'm searching for a way that can both keep track of those timestamps, infer metadata from source video and also copy audio stream which I have no idea how to copy audio stream as is from one file into another encoder
[17:48:59] *** Joins: SamHenderson (~SamHender@209.226.83.235)
[17:50:08] *** Joins: SamHenderson43 (~SamHender@bras-base-ssmron9421w-grc-51-184-147-30-14.dsl.bell.ca)
[17:53:53] *** Quits: SamHenderson (~SamHender@209.226.83.235) (Ping timeout: 268 seconds)
[17:53:59] *** Joins: minimal (~minimal@user/minimal)
[17:55:40] *** Joins: ttys000 (~ttys000@user/ttys000)
[17:55:50] <BtbN> You'll want to not re-encode audio. No point. Just straight from one avformat contact to another
[17:57:08] <yuri6037> can you move streams?
[18:04:06] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 256 seconds)
[18:04:15] *** Joins: rvalue (~rvalue@user/rvalue)
[18:08:22] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[18:08:37] *** Quits: rvalue (~rvalue@user/rvalue) (Ping timeout: 250 seconds)
[18:11:24] *** Joins: rvalue (~rvalue@user/rvalue)
[18:15:29] *** Joins: morpheuz (~morpheuz@user/morpheuz)
[18:15:53] <beshoo> @yuri6037 can you help with my problem ?
[18:16:03] <beshoo> how can i Loop the overlay
[18:16:06] <beshoo> the overlay input3.mp4 lenth is 10 sec but the  Wildlife.wmv is 5 min, i need the overlay to loop
[18:16:10] <beshoo> ffmpeg -i   Wildlife.wmv -vf   "movie=input3.mp4, scale=250: -1 [inner]; [in][inner] overlay =10: 10 [out]" completed.mp4
[18:17:38] <tar_xvf> are you missing something beshoo ? I don't see where you get the [in] from, it's not from any input and it's not an ouptut of a complex function
[18:19:37] <beshoo> Am not sure how to do it correctly, I have a move  and i want to place another move at the top right corner, scale it to 250. and keep it loop till the main move  end
[18:20:27] <beshoo> so kinldy may you help me with the correct command. ?
[18:20:49] <beshoo> @tar_xvf :)
[18:21:39] <tar_xvf> beshoo: ok, so assuming you only want the video from input3.mp4
[18:21:44] <tar_xvf> try this: (typing)
[18:23:01] <beshoo> The main video is the  Wildlife.wmv and the input3.mp4 will be the small overlay video.
[18:23:59] <tar_xvf> `ffmpeg -i Wildlive.wmv -i input3.mp4 -filter_complex "[1:v:0]scale=X:Y,loop=size=90[inner];[1:v:0][inner]overlay=X,Y[videoout]" -map "[videoout]" -map "0:a:0" output.mp4`
[18:24:08] <beshoo> I need this small overlay video to place on the top left corner, scaled to 250. and jeep playing till the end of the main vedio
[18:24:09] <tar_xvf> let me know if that works, i just typed this out on irc i didnt test it
[18:24:20] <beshoo> lol let me test
[18:24:21] *** Joins: yeirr (~yeirr@user/yeirr)
[18:24:26] <tar_xvf> also, replace the X:Y in scale= and overlay= with the appropriate size and coordinates
[18:24:48] <tar_xvf> and also, in loop=size=90 you need to enter how many FRAMES you want to loop, so multiply the number of seconds by the framerate
[18:25:36] <beshoo> how can i tell ffmpeg to loop forever regardless the count of the farames
[18:25:58] <beshoo> we want to loop the overlay till the end of the main video
[18:26:05] <tar_xvf> that automatically loops forever without specifying how many times but
[18:26:12] <tar_xvf> you need to specify how many frames of the video gets looped
[18:26:28] <tar_xvf> ah, i forgot, add a `-shortest- flag just before output.mp4 in the command
[18:27:04] <beshoo> the problem i dont know the number of the frames. so what should i do in this case...
[18:27:23] <tar_xvf> run ffprobe on the file you want to loop, see how many FPS it is, multiply the fps by the number of seconds
[18:27:27] <beshoo> waht i understand, place this at the top left and keep it playing :) lol
[18:29:24] <beshoo> ffmpeg -i Wildlive.wmv -i input3.mp4 -filter_complex "[1:v:0]scale=250:100,loop=size=90[inner];[1:v:0][inner]overlay=20,20[videoout]" -map "[videoout]" -map "0:a:0" -shortest output.mp4
[18:29:34] <beshoo> is this corect ?
[18:30:05] *** Quits: dreamon (~dreamon@ppp-88-217-65-149.dynamic.mnet-online.de) (Ping timeout: 250 seconds)
[18:31:21] <beshoo> [AVFilterGraph @ 0x763af80] No such filter: '20'
[18:31:22] <beshoo> Error initializing complex filters.
[18:31:22] <beshoo> Invalid argument
[18:32:24] <tar_xvf> no, instead of 20,20 you need 20:20
[18:32:35] <tar_xvf> seperate arguments to the filter with colons :
[18:33:03] <tar_xvf> and seperate filters with commas ,
[18:33:19] <beshoo> ok
[18:36:32] <beshoo> the output strange, take the sound from the mian vedio. and make the overlay video main and overlay
[18:38:27] <emcodem> use -map "1:a:0" for the sound
[18:38:35] <emcodem> in -map
[18:39:30] <beshoo> the sound is correct, but the output is not, the main Wildlive.wmv is not appearing at all
[18:39:53] <emcodem> https://www.irccloud.com/pastebin/9gajWKpJ/
[18:39:59] <beshoo> what i see as out put : input3.mp4 become the mian and the overlay
[18:40:13] <tar_xvf> input3.mp4 is the looping video i assumed you wanted to use the other video for audio
[18:40:39] <tar_xvf> oops, you're right, after the semicolon write [0:v:0][inner] instead of [1:v:0]innter
[18:41:02] <beshoo> can you please send me the final ccommand :) please
[18:41:31] <emcodem> oh come on, you can do it, i believe in you :D
[18:41:39] <beshoo> lool
[18:41:41] *** Quits: arbitercoin (~Rheanna@218.78.94.61) (Remote host closed the connection)
[18:42:05] <tar_xvf> ffmpeg -i Wildlive.wmv -i input3.mp4 -filter_complex "[1:v:0]scale=250:100,loop=size=90[inner];[0:v:0][inner]overlay=20:20[videoout]" -map "[videoout]" -map "0:a:0" -shortest output.mp4
[18:42:20] <beshoo> let me test
[18:42:24] <beshoo> tnak )
[18:42:37] <emcodem> ah, the other way around.. sorry :D
[18:44:47] *** Joins: arbitercoin (~Rheanna@218.78.104.50)
[18:46:05] <beshoo> the poroblem is once the overlay end it disappear
[18:46:06] <beshoo> https://beshoo.com/tiktok_download/%23funny_cats/output.mp4
[18:46:25] <beshoo> and i dont knwo why the overlay keep resized
[18:47:20] *** Joins: rsx (~dummy@ppp-188-174-135-237.dynamic.mnet-online.de)
[18:49:06] <beshoo> how can we keep the dimention of the mian vedio not changed. i can see it changed ! the mian vedio you can see it as following https://beshoo.com/tiktok_download/%23funny_cats/Wildlive.mp4
[18:52:21] <yuri6037> beshoo: sorry I was away. I don't know enough about FFMPEG to help here I cam here just to get help for video decomposition and recomposition
[18:52:21] <beshoo> and a lot of errors while send the command :
[18:52:24] <beshoo> https://i.imgur.com/RFrPdne.png
[18:52:36] <beshoo> lol
[18:52:48] <beshoo> thanks anyway but i trust in you :)
[18:54:04] <yuri6037> I'm tempted to tell you to use the C API to overlay a video onto another one
[18:54:23] <yuri6037> or the Rust API
[18:54:27] <beshoo> how!
[18:54:38] <beshoo> is there any easy doc !
[18:55:01] <beshoo> am not a developer , if there is any easy command line ... let me test
[18:55:09] <yuri6037> you could decode the video following something similar to https://git.videolan.org/?p=ffmpeg.git;a=blob;f=doc/examples/decode_video.c;h=18ee90a6c05b755ca4a2341ed5a2d21cf8a4c234;hb=HEAD and https://git.videolan.org/?p=ffmpeg.git;a=blob;f=doc/examples/transcoding.c;h=badfba62cb3ec184f516a2b96189c8102edef085;hb=HEAD
[18:55:53] <beshoo> ops --- we dont do that here lol
[18:56:08] <yuri6037> and decode to RGB using sws_getContext and sws_scale on each image and then use any image manipulation tool to overlay an image on another one
[18:56:47] <beshoo> i will use aftereffect , it will be more easy LOL
[18:57:09] <tar_xvf> rip, sorry i couldn't help you there
[18:57:10] <beshoo> am sure ffmpeg has an easy command but we need to know the how to
[18:57:54] <yuri6037> I'm not ffmpeg has a command to do that
[18:58:01] <yuri6037> *sure
[18:58:09] <tar_xvf> im not sure why the overlayed video gets resized but i wonder if you entered in more frames to loop than how many frames the video has
[18:59:35] <tar_xvf> i thought this would be right up ffmpeg's alley, a looping video resclaled and overlayed on another. Weird
[19:01:02] <tar_xvf> if i had the original files i could test this a little more. Oh well, good luck to you beshoo
[19:02:09] *** Quits: beshoo (~beshoo@94.47.2.79) (Ping timeout: 250 seconds)
[19:04:57] *** Joins: iive (~iive@87.119.101.204.client.entry.bg)
[19:13:02] *** Quits: rsx (~dummy@ppp-188-174-135-237.dynamic.mnet-online.de) (Quit: rsx)
[19:17:12] *** SamHenderson43 is now known as SamHenderson
[19:21:30] *** Joins: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com)
[19:25:57] *** Joins: kib (~kib@user/kib)
[19:26:08] *** Quits: yeirr (~yeirr@user/yeirr) (Remote host closed the connection)
[19:26:33] *** Quits: kib (~kib@user/kib) (Client Quit)
[19:29:40] *** Joins: kib (~kib@user/kib)
[19:30:13] *** Quits: Helmholtz (~leibnizma@2001:470:69fc:105::3124) (Quit: You have been kicked for being idle)
[19:31:46] *** Quits: arbitercoin (~Rheanna@218.78.104.50) (Remote host closed the connection)
[19:34:45] *** Joins: arbitercoin (~Rheanna@218.78.67.149)
[19:36:36] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 245 seconds)
[19:37:05] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[19:38:39] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Ping timeout: 276 seconds)
[19:44:54] *** Quits: kib (~kib@user/kib) (Quit: WeeChat 3.3)
[19:45:42] *** Joins: softworkz_ (~softworkz@user/softworkz)
[19:45:42] *** softworkz is now known as Guest5776
[19:45:42] *** Quits: Guest5776 (~softworkz@user/softworkz) (Killed (tungsten.libera.chat (Nickname regained by services)))
[19:45:42] *** softworkz_ is now known as softworkz
[19:50:20] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[19:52:31] *** Joins: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr)
[20:01:17] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Remote host closed the connection)
[20:07:03] *** Joins: gioyik (~gioyik@gateway/tor-sasl/gioyik)
[20:07:22] <roxlu> hey, maybe there's someone around now how might know this ... When I get a AVPacket from `avcodec_receive_packet()` and I put this packet onto a queue (where it queue item has it's own packet that was passed inot `avcodec_recieve_packet()`) and the queue is written out via `av_interleaved_write_frame()`, I shouldn't matter that I'm writing from another thread right? (if the
[20:07:24] <roxlu> av_interleaved_write_frame()` is protected by a mutex).
[20:09:34] <roxlu> I'm asking because the output I see when "writing" to a dash output, is incorrect as in: https://imgur.com/a/5OqzPOD , and I'm not sure what is causing this. It's like either the data is overwritten/re-used maybe OR the output (dash/cmaf) is worng.
[20:10:08] <roxlu> When I write the packet.data to a .h264 file manually (via fopen/fwrite), it's fine and I can playback the video w/o issues.
[20:10:19] <roxlu> Any thoughts what might cause this?
[20:17:37] *** Quits: cosimone (~user@2001:b07:ae5:db26:a7aa:8027:6b4e:2fb3) (Remote host closed the connection)
[20:17:52] *** Joins: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20)
[20:30:49] <DHE> that's fine, as long as no single object is used by multiple threads at the same time. like, av_interleaved_write_frame() must always be called from the same thread
[20:31:00] <DHE> (or do your own locking)
[20:31:15] <DHE> or any other avformat_* functions on the same AVFormatContext, etc
[20:31:38] *** Quits: cmp (~cmp@lputeaux-658-1-177-87.w92-154.abo.wanadoo.fr) (Quit: Connection closed)
[20:34:19] *** Quits: gioyik (~gioyik@gateway/tor-sasl/gioyik) (Quit: WeeChat 3.1)
[20:36:34] <yuri6037> btw nobody answered my last question: can you move streams between 2 AVFormatContext?
[20:41:44] <DHE> sure. just like -c copy
[20:42:16] <DHE> update the stream_index field of the AVPacket to reflect which stream in the receiving context it belongs to, and av_interleaved_write_frame()   # name is quite misleading...
[20:42:42] *** Quits: demon__ (~user@197.54.97.208) (Ping timeout: 260 seconds)
[20:48:17] <yuri6037> how do I read a packet from a AVFormatContext stream index?
[20:48:45] <yuri6037> can I use av_read_frame?
[20:48:53] *** Joins: l4yer (~l4yer@2001:ac8:31:6e:1011:aaea:946c:9a98)
[20:53:14] <DHE> yes
[20:53:19] <DHE> I don't know of any other function that does it
[20:54:38] *** Joins: dreamon (~dreamon@pd9503939.dip0.t-ipconnect.de)
[20:57:55] <yuri6037> for avformat_alloc_output_context2 what kind of format_name does it take? Does it accept MP4/MKV?
[21:00:08] <DHE> anything that ffmpeg would accept for an -f option.
[21:00:35] <DHE> or if you have an AVOutputFormat object, you can specify that instead. only need 1 option set as long as the desired format is obvious from it
[21:01:30] <yuri6037> Do you have a list on what ffmpeg takes in -f?
[21:01:38] *** Joins: a0z (~a0z@90.244.184.28)
[21:01:55] <yuri6037> or do you know a command that makes ffmpeg prints all of its supported output formats?
[21:02:27] <DHE> ffmpeg -muxers
[21:02:39] *** Joins: Kei_N (~Kei_N@user/kei-n/x-2886111)
[21:04:43] <yuri6037> ok if I recall matroska is mkv
[21:04:53] <yuri6037> so that should work
[21:05:44] *** Quits: Kei_N_ (~Kei_N@user/kei-n/x-2886111) (Ping timeout: 260 seconds)
[21:06:05] *** Quits: microchip_ (~neutrino@user/microchip/x-0766185) (Quit: There is no spoon!)
[21:06:30] *** Joins: microchip_ (~neutrino@user/microchip/x-0766185)
[21:12:18] *** Joins: microchip__ (~neutrino@user/microchip/x-0766185)
[21:12:19] *** Quits: arbitercoin (~Rheanna@218.78.67.149) (Remote host closed the connection)
[21:14:32] *** Quits: microchip_ (~neutrino@user/microchip/x-0766185) (Ping timeout: 240 seconds)
[21:14:42] *** Joins: arbitercoin (~Rheanna@218.78.79.129)
[21:17:24] *** Quits: dreamon (~dreamon@pd9503939.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[21:19:14] *** Quits: Volgaar (~volgaar@nat-wifi-eduroam.reseau.univ-paris13.fr) (Ping timeout: 268 seconds)
[21:28:08] *** Quits: SamHenderson (~SamHender@bras-base-ssmron9421w-grc-51-184-147-30-14.dsl.bell.ca) (Ping timeout: 260 seconds)
[21:29:56] *** Quits: foonix (1004@ip-86-49-65-192.net.upcbroadband.cz) (Quit: leaving)
[21:38:52] *** Joins: Guest9482 (~Buster@46.160.36.66)
[21:42:23] *** Joins: foonix (1004@ip-86-49-65-192.net.upcbroadband.cz)
[21:43:37] *** Joins: dreamon (~dreamon@ppp-88-217-67-53.dynamic.mnet-online.de)
[21:44:18] *** Quits: Vonter (~Vonter@user/vonter) (Ping timeout: 260 seconds)
[21:45:08] *** microchip__ is now known as microchip_
[21:52:41] *** Joins: nd_ (~nd@user/nd)
[21:52:41] *** Quits: nd (~nd@user/nd) (Ping timeout: 265 seconds)
[21:53:15] *** nd_ is now known as nd
[21:56:09] *** Joins: Narrat (~omnius@p200300df5f0df16c06ea56fffe2e7cdc.dip0.t-ipconnect.de)
[22:01:57] *** Joins: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net)
[22:01:58] *** Quits: arbitercoin (~Rheanna@218.78.79.129) (Remote host closed the connection)
[22:03:47] *** Joins: arbitercoin (~Rheanna@218.78.99.237)
[22:07:12] *** Quits: nd (~nd@user/nd) (Ping timeout: 256 seconds)
[22:10:16] *** Quits: rpthms (~rpthms@user/rpthms) (Remote host closed the connection)
[22:13:55] *** Joins: rpthms (~rpthms@user/rpthms)
[22:14:14] *** Joins: nd (~nd@user/nd)
[22:14:19] <roxlu> Thanks DHE
[22:18:26] *** Quits: dreamon (~dreamon@ppp-88-217-67-53.dynamic.mnet-online.de) (Ping timeout: 268 seconds)
[22:18:27] *** Quits: nd (~nd@user/nd) (Ping timeout: 250 seconds)
[22:22:14] *** Joins: xkuru (~xkuru@user/xkuru)
[22:34:10] *** Quits: rpthms (~rpthms@user/rpthms) (Remote host closed the connection)
[22:36:13] *** Joins: rpthms (~rpthms@user/rpthms)
[22:38:43] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[22:40:58] *** Joins: nd (~nd@user/nd)
[22:42:02] *** Joins: dreamon (~dreamon@pd9503939.dip0.t-ipconnect.de)
[22:42:57] <yuri6037> I have a small problem: sws_scale uses a concept called image plane. What is an image plane exactly? Is it a channel (like R, G or B)? If so how is the format stored? Is it stored like a pixel array (RGB, RGB, RGB etc)? If it is stored differently can you please explain the memory layout?
[22:46:07] <furq> yes to all of those
[22:46:50] <furq> rgb is stored rgbrgbrgbrgbrgb but gbrp is stored gggg...bbbb...rrrr....
[22:47:23] <furq> rgb24 that is
[22:47:34] <furq> rgb24 is packed and gbrp is planar
[22:47:35] <yuri6037> when I create the SwsContext I force AV_PIX_FMT_RGB24
[22:47:44] <furq> well in that case it's rgbrgbrgb
[22:47:56] <furq> if the pixel format ends in a p then it's planar
[22:48:14] <kepstin> a format is called "planar" when all the components of a single type (e.g. Y in YUV or R in RGB) are stuck together into a contiguous bit of memory separate from the other components
[22:48:44] <furq> and those planes might not be all the same size
[22:48:57] <furq> e.g. the u and v planes in yuv420p are 1/4 the size
[22:49:02] <furq> of y
[22:49:29] <yuri6037> oh ok in that case what do I give as strides and dst buffer because in this case there are no planes (AV_PIX_FMT_RGB24)?
[22:49:52] <yuri6037> sws_scale requires an array of dst buffers and strides
[22:50:10] <yuri6037> but if there's no planes then how do I build this array
[22:50:17] <kepstin> a packed fromat is stored as a single plane, so there's only going to be one buffer/one stride
[22:51:07] <yuri6037> is sws_scale able to handle a dst array where the stride is exactly the image width or does it need some alignment?
[22:52:01] *** Quits: arbitercoin (~Rheanna@218.78.99.237) (Remote host closed the connection)
[22:53:19] <kepstin> I believe the situation is that it'll complain about it, but work anyways? should double-check that.
[22:53:57] *** Joins: arbitercoin (~Rheanna@218.78.99.237)
[22:54:04] <kepstin> (it might have a fallback to a slower non-assembly-optimized path or so, depending on the particular operation you're doing)
[22:56:21] <yuri6037> well I'm doing this to the RGB data in a format which is optimized for Rust interop and image-rs
[22:57:08] <yuri6037> but if allignment is a necessity I can try to apply that I just need to know what alignment it needs
[22:58:02] *** Joins: SamHenderson (~SamHender@bras-base-ssmron9421w-grc-51-184-147-30-14.dsl.bell.ca)
[22:58:43] <yuri6037> do you know the alignment value that is prefered?
[22:59:04] <yuri6037> multiple of 16 like GL?
[22:59:12] *** Joins: nicko88 (~nicko88@024-177-117-066.res.spectrum.com)
[22:59:34] <nicko88> does anyone know why when i do -c copy -map 0, the output mkv has a different subtitle track set as default?
[23:00:17] <furq> maybe -map_metadata 0
[23:00:58] <nicko88> https://imgur.com/a/mGLLUQT
[23:01:04] <nicko88> let me try that
[23:01:56] <nicko88> i guess what seems to be happening is there is no [default] on the source
[23:02:07] <nicko88> but the after set the first one as default
[23:02:34] <nicko88> there's auto, not sure the difference between auto and default but it seems default supersedes auto
[23:02:42] <nicko88> ill try metadata
[23:03:21] <kepstin> yuri6037: 16 bytes (128bits) is probably a good alignment choice for most systems, yeah, corresponds to common vector instruction types. I think that's what ffmpeg's built-in aligned buffer allocation ends up doing on most systems?
[23:03:40] <yuri6037> ok fine I'll do this then
[23:04:24] <nicko88> hmm map_metadata 0 doesn't seem to have changed the result
[23:11:21] *** Quits: rpthms (~rpthms@user/rpthms) (Remote host closed the connection)
[23:15:56] *** Joins: nyuszika7h_ (nyuszika7h@lykos/dev/nyuszika7h)
[23:16:24] *** Quits: nd (~nd@user/nd) (Ping timeout: 268 seconds)
[23:17:04] *** Joins: rpthms (~rpthms@user/rpthms)
[23:17:37] *** Joins: Volgaar (~volgaar@193.137.116.78.rev.sfr.net)
[23:29:29] <roxlu> DHE: when I pass a AVPacket into the interleaved write function, do I also need to unref it myself?
[23:31:05] *** Quits: foonix (1004@ip-86-49-65-192.net.upcbroadband.cz) (Quit: leaving)
[23:33:10] *** Quits: nyuszika7h_ (nyuszika7h@lykos/dev/nyuszika7h) (Quit: ZNC 1.8.2+deb2+b1 - https://znc.in)
[23:33:28] *** Joins: foonix (1004@ip-86-49-65-192.net.upcbroadband.cz)
[23:34:29] *** Quits: rpthms (~rpthms@user/rpthms) (Remote host closed the connection)
[23:35:11] *** Joins: nd (~nd@user/nd)
[23:36:21] *** Joins: rpthms (~rpthms@user/rpthms)
[23:41:50] *** Quits: arbitercoin (~Rheanna@218.78.99.237) (Remote host closed the connection)
[23:42:55] *** Quits: nd (~nd@user/nd) (Ping timeout: 268 seconds)
[23:44:22] *** Joins: arbitercoin (~Rheanna@61.171.21.169)
[23:48:50] *** Quits: nrg (~NRG@user/nrg) (Ping timeout: 260 seconds)
[23:53:51] *** Joins: nrg (~NRG@user/nrg)
