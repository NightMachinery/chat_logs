[00:02:53] <feepbot> <gwern> https://twitter.com/ankesh_anand/status/1457711659565322250
[00:02:55] <|dbotdan> Ankesh Anand (@ankesh_anand, 2021-11-08 14:08): ‘Model-based RL promises generalization by design, but do MBRL agents like MuZero generalize better than model-free, and benefit from self-supervision? | The answer is yes! MuZero+SSL gets SotA on Procgen with 10x less data, implicit meta-RL on MetaWorld: https://arxiv.org/abs/2111.01587 ’ Images:
[00:02:55] <|dbotdan> https://nitter.domain.glass/pic/media%2FFDrSjDRXoAU8xU5.png%3Fname%3Dorig (description: text; confidence: 0.99) | https://nitter.domain.glass/pic/media%2FFDrSpHuWQAAQfQw.jpg%3Fname%3Dorig
[00:07:52] <kiboneu> can you kill a mosquito by drinking enough alcohol and enticing it to suck your high abv blood?
[00:10:20] <gwern> dunno, but I'd point out it's getting a small dose of alcohol. your blood is less than 1% even if you're drunk, it'll be digesting what it steals slowly, and has all its regular blood/bodyfluid to diffuse it over
[00:11:05] <kiboneu> yeah
[00:11:07] <kiboneu> makes sense
[00:11:37] <kiboneu> it'll probably spit it out if it's high enough in alcohol anyway
[00:11:58] <kiboneu> i think insects generally do not favor alcohol
[00:12:27] <rmmh> https://nv-tlabs.github.io/editGAN/
[00:12:44] <feepbot> EditGAN
[00:13:02] <two2thehead> "...and the performance of a single d1 is irrelevant because they're really designed to work as a tile which contains 25 of these systems and each tile is built on one single wafer of silicon which again seems to be unprecedented as far as anyone can tell"
[00:13:23] <adiabatic> I read "d1" in isolation above and thought "marble"
[00:13:56] <two2thehead> ah, a wristwatch
[00:14:13] <two2thehead> this is about the tesla dojo supercomputer
[00:17:44] <rmmh> https://www.reddit.com/r/dataisbeautiful/comments/qpekw1/oc_my_daughters_complete_first_year_of_sleep/
[00:17:57] <feepbot> [OC] My daughter's complete first year of sleep : dataisbeautiful (27,609 votes and 907 comments so far on Reddit)
[00:22:44] <feepbot> <gwern> https://twitter.com/NLRG_/status/1457510976375427076
[00:22:45] <|dbotdan> Nice Little Rat Girl (@NLRG_, 2021-11-08 00:51): ‘fuck it im saying it | regulating, opposing, and just generally posturing against Big Tech is a socially acceptable form of systemic transphobia | anyone with a basic understanding of intersectionality should understand this’
[00:23:30] <feep> lol
[00:23:38] <adiabatic> do I need to add "brain" and "worm" emoji to my TextExpander list
[00:26:00] <rmmh> >  I had a boss once who did find and replace on a massive document that changed "I" to "we" because it was supposed to be written from the perspective of the company not the individual. There were gems like "socweal mobwelwety". It couldn't be rolled back for some reason.
[00:26:22] <feep> socweal mobwelwety uwu
[00:26:23] <rmmh> gwern: given how many trans people work in big tech, lol
[00:26:26] <adiabatic> s/we/I/g, clearly. what's the worst that could happen
[00:26:33] <gwern> rmmh: that's the joke</mcbain>
[00:26:45] <mst> rmmh: a clbuttic mistake
[00:27:28] <gwern> 'In June 2008, a news site run by the anti-LGBT American Family Association filtered an Associated Press article on sprinter Tyson Gay, replacing instances of "gay" with "homosexual", thus rendering his name as "Tyson Homosexual".[34][35] This same function had previously changed the name of basketball player Rudy Gay to "Rudy Homosexual".[36] The word or string "ass" may be replaced by...
[00:27:34] <gwern> ..."butt", resulting in "clbuttic" for "classic", "buttignment" for "assignment", and "buttbuttinate" for "assassinate".[37]' https://en.wikipedia.org/wiki/Scunthorpe_problem
[00:28:00] <rmmh> buttbuttinate
[00:28:53] <rmmh> even s/\bI\b/we/ will be wrong since tense is a thing
[00:28:58] <two2thehead> "Tesla's new format is called configurable float 8 or c float 8. An 8-bit floating point format. So it's just a further reduced pressure on memory storage and bandwidth compared to google's machine learning format, by using an even smaller and less precise number. Configurable aspect essentially gives the flexibility to rearrange that 8-bit number according to the specific task it's being used for within the deep learning environment.
[00:28:59] <two2thehead> "The end result being that tesla can train larger ai models with larger amounts of input which is going to work out really well for their specific task of teaching robot cars how to drive on city streets.
[00:28:59] <two2thehead> "So this is a very important point to make. dojo will only ever run at full capacity using these low bit rate formats. that means that it will be the best super computer in the world for ai training and machine learning, but it will never be the best super computer in the world for general purpose applications like forecasting climate change or making vaccines or launching a cyber attack on the us government"
[00:29:10] <two2thehead> kuudes, s0ph1a feep gwern : Is the speaker correct when he states the following? 'that means that it will be the best super computer in the world for ai training and machine learning'
[00:29:43] <two2thehead> I think he should have added 'best in the world for training autonomous cars', but I am uncertain
[00:34:44] <feepbot> <gwern> https://www.fastcompany.com/90693444/jony-ives-first-major-design-since-leaving-apple-isnt-what-youd-expect if someone other than ives did this, the designeratti would be sneering at it as sentimental, chintzy, schmaltz, hopelessly victorian and/or Little England
[00:34:44] <feepbot> Jony Ive's first major design since leaving Apple is unexpected. (Ive spoke with Fast Company about how his design collective LoveFrom developed an intricate, organic logo mark and a new typeface called LoveFrom Serif. )
[00:36:29] <rmmh> Amazon, Salesforce, Among 45 Companies Awarded Terra Carta Seal From Prince Charles
[00:36:38] <rmmh> lol
[00:37:51] <adiabatic> nice, I'm happy he's doing good work and not ruining my computers
[00:37:56] <adiabatic> win-win
[00:41:34] <rmmh> old man doodling on collectible plates
[00:45:02] *** Quits: Urchin[emacs] (~user@user/urchin) (Ping timeout: 240 seconds)
[00:46:34] <feepbot> <gwern> Obormot\Arcturus: ok, one interesting bit here is Ives's firm has revived Baskerville as 'Love Serif'. you can see it typeset at https://www.lovefrom.com/ it's provided as... data-uris lol
[00:46:34] <feepbot> LoveFrom, (A creative collective.)
[00:49:11] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[00:51:34] <feepbot> <gwern> https://twitter.com/redrawnoxen/status/1457018877532123140
[00:51:36] <|dbotdan> Roxy🌹 (@redrawnoxen, 2021-11-06 16:15): ‘As it gets colder, I am begging u: make your hot chocolate w hot milk (or hot milk alternative), not boiling water. We only have so much time on this earth and should enjoy it occasionally’
[00:52:20] <rmmh> https://twitter.com/trevorgrogers/status/1456756962239131651
[00:52:23] <|dbotdan> Trevor Rogers (@trevorgrogers, 2021-11-05 22:54): ‘Eight years ago I entered the local library’s library card design contest not knowing it was for children and absolutely dominated. | Then they made me accept the award at city hall with the kids I beat. 😂’ Images: https://nitter.pussthecat.org/pic/media%2FFDdwvHPWYAQ97gl.jpg%3Fname%3Dorig (description: a group of people holding up paintings;
[00:52:23] <|dbotdan> confidence: 0.47)
[00:53:03] <rmmh> gwern: that ampersand is awful
[00:59:09] <Obormot\Arcturus> I gotta agree with rmmh
[00:59:40] <rmmh> "what if our ampersand doesn't identifiably look like an et??"
[01:00:07] <rmmh> oh it's an ~italic~ ampersand
[01:00:14] <rmmh> there's a reason nobody uses that
[01:00:38] <Obormot\Arcturus> What? Plenty of people use italic ampersands
[01:01:05] <rmmh> https://upload.wikimedia.org/wikipedia/commons/8/83/Italic_ampersands.png
[01:01:49] <Obormot\Arcturus> gwern: Man that paper version of the seal looks *stylish as fuck*
[01:02:16] <Obormot\Arcturus> That is some Patrick Bateman grade shit
[01:03:37] <rmmh> it's even embossed
[01:18:52] * Obormot\Arcturus was just looking through his stuff and remembered this https://share.obormot.net/misc/A_Study_in_Numbers.pdf
[01:21:26] <Obormot\Arcturus> Also https://share.obormot.net/misc/Blackletter_Sample.pdf
[01:27:30] <ggreer> today I learned about the legal term "directed verdict". it's when a judge orders the jury how to rule: https://en.wikipedia.org/wiki/Verdict#Directed_verdict
[01:27:48] <feepbot> In law, a verdict is the formal finding of fact made by a jury on matters or questions submitted to the jury by a judge. In a bench trial, the judge's decision near the end of the trial is simply referred to as a finding.
[01:28:18] <ggreer> they're rare, but the rittenhouse case is so ridiculous that it might happen for one of the charges (attempted murder of grosskreutz)
[01:28:49] <Betawolf> "The prosecution may never seek a directed verdict of guilty, as the defendant has a constitutional right to present a defense and rebut the prosecution's case and have a jury determine guilt or innocence (where a defendant has waived his/her right to a jury trial and allowed the judge to render the verdict, this still applies). "
[01:51:41] <gwern> Obormot\Arcturus: yeah, I think it's somewhat busy but the paper seal is awesome. nevertheless, without the pedigree, the designeratti would sneer
[01:52:06] <Obormot\Arcturus> gwern: Well, good on Ive for using his name recognition to do something cool, I say
[01:52:16] <gwern> it's such a heelface turn
[01:52:21] <Obormot\Arcturus> Quite
[01:55:27] *** Joins: voltage_ (voltage@user/voltage)
[01:57:22] <feepbot> <gwern> https://twitter.com/mattparlmer/status/1457766435355340809 aww
[01:57:23] <|dbotdan> mattparlmer 🌷 (@mattparlmer, 2021-11-08 17:46): ‘If your academy isn't designed from the ground up to support ppl like @gwern it's probably lower utility than a hypothetical institution that could fund and provide infrastructure to scholars without interfering with their work’
[02:02:23] <feepbot> <gwern> https://www.nytimes.com/2021/11/08/us/police-crime.html this discusses the randomized and natural experiments for non-policing interventions, but somehow can only weasel-word around correlational evidence about policing -_-
[02:02:24] <feepbot> Does Adding Police Officers Reduce Crime? The Results Are Mixed - The New York Times (Other anti-crime measures might be more effective, experts say, and avoid the downsides of policing.)
[02:11:49] <feepbot> <gwern> https://www.lesswrong.com/users/jacob_cannell oddly minor comment for cannell to resurface with
[02:11:51] <feepbot> jacob_cannell - LessWrong (jacob_cannell's profile on LessWrong — A community blog devoted to refining the art of rationality)
[02:14:30] <Obormot\Arcturus> https://www.datasecretslox.com/index.php/topic,4965.msg313.html#new
[02:14:42] <feepbot> French immigrants to Quebec find the place refreshingly open, but a bit of a culture shock
[02:15:12] <Obormot\Arcturus> (btw Robomot isn't defunct, I'm just fixing a slew of concurrency and other bugs atm)
[02:16:39] <Obormot\Arcturus> "Most importantly, the Quebec economy feels more open, with fewer restrictions on hiring, firing and starting businesses. The French labour market is famously rigid, whereas in Montreal, a philosophy grad can make a living writing video game scripts or baking bread."
[02:16:48] <Obormot\Arcturus> "> in Montreal, a philosophy grad can make a living writing video game scripts
[02:16:49] <Obormot\Arcturus> In case you were wondering why Assassins Creed is super woke now!"
[02:18:00] <gwern> gee, I'm amazed the french videogame writing union allows that
[02:19:03] <Obormot\Arcturus> "Bradley Cooper recently announced his intent to produce a film adaptation of Hyperion (Dan Simmons)." ... whaaaat
[02:19:10] <gwern> yeah, I linked it
[02:21:51] <dv^_^> Is nothing sacred any more
[02:26:52] <feepbot> <gwern> https://pandaily.com/alibaba-damo-academy-creates-worlds-largest-ai-pre-training-model-with-parameters-far-exceeding-google-and-microsoft/ https://www.infoq.cn/article/xIX9lekuuLcXewc5iphF a new MoE record huh
[02:26:54] <feepbot> Alibaba DAMO Academy Creates World's Largest AI Pre-Training Model, With Parameters Far Exceeding Google and Microsoft - Pandaily (On Monday, the Alibaba DAMO Academy announced the latest development of a multi-modal large model M6, whose parameters have jumped from 1 trillion to 10 trillion.)
[02:27:36] <gwern> no, turns out it's from may, and pandaily is just *way* behind
[02:32:37] <feepbot> <gwern> https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4874898/
[02:32:39] <feepbot> Language and thought are not the same thing: evidence from neuroimaging and neurological patients (Is thought possible without language? Individuals with global aphasia, who have almost no ability to understand or produce language, provide a powerful opportunity to find out. Astonishingly, despite  [snip])
[02:43:03] <feepbot> <gwern> https://danluu.com/culture/
[02:43:03] <feepbot> Culturally trasnmitted skills and values
[02:48:23] *** Quits: gproto23 (~gproto23@user/gproto23) (Remote host closed the connection)
[02:51:05] <feepbot> <gwern> https://arxiv.org/abs/2111.01243
[02:51:06] <feepbot> [2111.01243] Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey (Large, pre-trained transformer-based language models such as BERT have)
[02:52:11] <Gurkenglas> Obormot\Arcturus, https://www.bloomberg.com/opinion/articles/2021-11-08/elon-musk-did-some-tweets disables scrolling on AKS
[02:52:22] <feepbot> Will Elon Musk Actually Sell 10% of His Tesla Stock? - Bloomberg (Also Theranos due diligence, ransomware errors and crypto education.)
[02:52:56] <Obormot\Arcturus> Gurkenglas: Browser/version/platform? I do not see any such issue
[02:55:19] <Gurkenglas> Obormot\Arcturus, Chrome. If I unkill stickies, F5, accept cookies, kill stickies and F5, the issue goes away until I reopen that incognito window.
[02:56:24] <Obormot\Arcturus> Hm
[02:56:28] * Obormot\Arcturus tries it in a private window
[02:58:36] <Obormot\Arcturus> Gurkenglas: Nope, can't replicate. Works fine in FF regular window, FF private window, Chromum regular window, Chromium private window. Correctly kills the cookie popup thingies and restores scrollability. All working perfectly and as intended
[02:58:50] <Obormot\Arcturus> If anyone else can replicate this issue, please speak up
[02:58:53] <Gurkenglas> Am on 1.3.4. Replicated it a few times.
[02:59:27] <Gurkenglas> Same issue on Firefox.
[02:59:44] <Gurkenglas> Maybe it's a country thing? Installing AKS on Tor.
[03:01:58] <Gurkenglas> replicates on Tor.
[03:03:31] <Gurkenglas> Although! On Tor, when I turn on killing stickies and then F5, it works fine.
[03:03:45] <Gurkenglas> It loses scrollability when I kill stickies without F5
[03:04:18] <kuudes> iirc it might be a random bloomberg e-mail ad popup
[03:04:43] <kuudes> because I have had that issue with umatrix+requestpolicy+ublock origin sometimes
[03:05:14] <Obormot\Arcturus> kuudes: I see that popup and then AKS properly kills it
[03:05:16] <Gurkenglas> Whereas, doublechecked, on chrome F5 does not make it work
[03:05:29] <Obormot\Arcturus> (I assume "F5" is reload?)
[03:05:56] <Gurkenglas> yes
[03:06:03] <Gurkenglas> that a germany thing??
[03:06:13] <Gurkenglas> maybe a windows thing...
[03:06:32] <Gurkenglas> I too see the popup and then AKS kills it - on Chrome. In Tor, I never see the popup with AKS on
[03:07:03] <Gurkenglas> aaaand this time Tor doesn't scroll after F5..
[03:07:16] <Gurkenglas> and this time it does.
[03:08:06] <Obormot\Arcturus> I dunno what to tell you :\
[03:08:08] <Gurkenglas> and these three F5s on Firefox it's fine.
[03:08:14] <Obormot\Arcturus> I'll test on Windows later
[03:08:16] * Obormot\Arcturus bbl
[03:09:06] <Gurkenglas> Well, it's less sanity-eroding to see that the only difference between him and me appearing to be the user turns out to perhaps be related to nondeterminism.
[03:09:07] <Gurkenglas> phew
[03:14:08] <feepbot> <gwern> 'The book also argues for a number of interesting upshots for decision theory (e). I’ll leave those for the reader to investigate. These upshots, however, lead to the idea that we should avoid time travel even if we know how to do it. The reasoning is roughly this. We know that there are not a lot of time travellers around here, just as I know that I will not kill
[03:14:08] <feepbot> grandfather. Consider grandfather. Suppose I plan to just keep travelling back in time and trying to kill grandfather. Something must prevent me from doing so each time. But jointly, these events have low chance. Likewise, if we have access to time machines, then it is unlikely that each of us will for some reason decide not to travel to this time, or that each of our machines will
[03:14:08] <feepbot> stop working (and so on). It is much more likely that a single (still low chance) event will bring it about that I do not travel back to kill my grandfather, and another single low chance event will prevent all of us from using our time machines. So if I am planning to go back and repeatedly try to kill grandfather, what is most likely is that I suffer a devastating heart attack,
[03:14:13] <feepbot> or that I am murdered, and so on, rather than that each time I try, some different event prevents his death. Similarly, if we all had access to time machines, then it is most likely that there is some cataclysmic event (nuclear war, detonation of the sun) that prevents all of us from using them. And, given the upshots for decision theory, Effingham argues that we should decide not
[03:14:13] <feepbot> to travel back in time, because in doing so we avoid bringing about any of those cataclysmic events.
[03:15:41] <kuudes> "If he was going to sell the stock anyway to pay taxes on options exercise, but did this poll as a distraction, is that somehow fraud? “You were going to sell stock to pay your tax bill like a rational person, but instead you pretended to sell stock based on a Twitter poll like a reckless weirdo, and I believed you and was deceived”? Would that be a misrepresentation of a material fact? Who would have a claim for damages against him?"
[03:16:16] <Gurkenglas> Neat, I was reading that same paragraph as you pasted it.
[03:17:04] <Gurkenglas> (it's the obvious question, of course.)
[03:17:47] <RiversHaveWings> gwern: danbooru sfw 128x128 is out https://github.com/crowsonkb/v-diffusion-jax
[03:17:58] <feepbot> GitHub - crowsonkb/v-diffusion-jax: v objective diffusion inference code for JAX. Contribute to crowsonkb/v-diffusion-jax development by creating an account on GitHub.
[03:18:13] <kuudes> "If he sells $20 billion of stock he will have to pay let’s say $4 billion of capital gains taxes (on the gains he realizes in that sale) and will have about $16 billion or so left over. (Assume — counterfactually? — that he does this without, or rather before, exercising any stock options, so he won’t need that money to pay taxes on his stock-option exercise. 3 ) Should he use that $16 billion to buy (1) Bitcoin, (2) Dogecoin, (3) Shiba In
[03:18:13] <kuudes> u coin, (4) Hertz Global Holdings Inc. (market cap $16.2 billion!), (5) GameStop Corp. (market cap $16.3 billion!), (6) a tasteful collection of non-fungible tokens, (7) more Tesla stock, or (8) other?"
[03:18:20] <kuudes> ;DDDD
[03:20:17] <kuudes> https://twitter.com/BillyM2k/status/1457764015325712386
[03:20:21] <|dbotdan> Shibetoshi Nakamoto (@BillyM2k, 2021-11-08 17:36): ‘simulation confirmed’ Images: https://nitter.net/pic/media%2FFDsEj-nXMAMqNML.jpg%3Fname%3Dorig (description: a computer screen with a person on it; confidence: 0.41)
[03:20:43] <Gurkenglas> wasn't some of the gamestop anomaly that it doesn't count as market manipulation because it was a meme, while if Musk bought up all GME because he saw the short squeeze it'd be abuse?
[03:21:42] *** Quits: src (~src@user/src) (Quit: Leaving)
[03:23:40] <gwern> RiversHaveWings: ooh
[03:28:41] <feepbot> <gwern> 'These upshots, however, lead to the idea that we should avoid time travel even if we know how to do it. The reasoning is roughly this. We know that there are not a lot of time travellers around here, just as I know that I will not kill grandfather. Consider grandfather. Suppose I plan to just keep travelling back in time and trying to kill grandfather. Something must
[03:28:41] <feepbot> prevent me from doing so each time. But jointly, these events have low chance. Likewise, if we have access to time machines, then it is unlikely that each of us will for some reason decide not to travel to this time, or that each of our machines will stop working (and so on). It is much more likely that a single (still low chance) event will bring it about that I do not travel back
[03:28:41] <feepbot> to kill my grandfather, and another single low chance event will prevent all of us from using our time machines. So if I am planning to go back and repeatedly try to kill grandfather, what is most likely is that I suffer a devastating heart attack, or that I am murdered, and so on, rather than that each time I try, some different event prevents his death. Similarly, if we all had
[03:28:46] <feepbot> access to time machines, then it is most likely that there is some cataclysmic event (nuclear war, detonation of the sun) that prevents all of us from using them. And, given the upshots for decision theory, Effingham argues that we should decide not to travel back in time, because in doing so we avoid bringing about any of those cataclysmic events.'
[03:28:46] <feepbot> https://ndpr.nd.edu/reviews/time-travel-probability-and-impossibility/ DO NOT MESS WITH TIME
[03:28:47] <feepbot> Time Travel: Probability and Impossibility | Reviews | Notre Dame Philosophical Reviews | University of Notre Dame (Nikk Effingham&#8217;s book is an exploration of all things time travel (where time travel is to be read as  backwards time travel, that is, travel ...)
[03:33:42] <feepbot> <gwern> https://sapienjournal.org/a-third-of-children-in-the-us-dont-know-how-meat-gets-to-the-table/
[03:33:43] <feepbot> More than a third of children in the US (aged 4-7) think cheese, bacon, hot dogs, chicken nuggets, shrimp, and hamburgers come from plants. Researchers who asked children to categorize food items into ‘animal-based’ and ‘plant-based’, also found that nearly half of the children in this age-[snip]
[03:43:01] <kuudes> I guess time travel could be as simple as travelling near light speed and "colliding" with your antimatter self to annihilation, and that antimatter self travelling to negative time direction near light speed and "colliding" with matter-forward self
[03:44:39] <kuudes> I mean, you would need to travel fast enough so that your electrons will not collide with any other positrons but their pair, and in the end your positive-self's matter cloud would be so close to your negative-self's antimatter cloud that it would seem quite odd for perfect annihilation to happen
[03:45:05] <gwern> RiversHaveWings: how many epoches/n and gpu-days is this, and what loss? should also add samples to the README
[03:45:23] <RiversHaveWings> gwern: 31 epochs
[03:45:35] <RiversHaveWings> i have the loss curve, let me look
[03:46:57] <kuudes> I guess whatever it is that causes there to be more entropy in the future than in the past in practice prevents time travel by making such mirror collisions infinitely impropable
[03:47:41] <kuudes> you would need to hit your antimatter-matter collision with equivalent light from future, I suppose, and when turning back, from the past
[03:49:16] <RiversHaveWings> gwern: mean train loss for the last epoch was 0.0174970
[03:49:20] <kuudes> as we can make antimatter, I suppose you just need first to make an antimatter-matter pair of you and then deliver than antimatter-you in future to collide with the other matter-you so you effectively have at that point of time duplicated yourself sort of anticausally
[03:50:18] <kuudes> I wonder if star trek teleporter would also send the person a little while into past in effect
[03:50:58] <RiversHaveWings> gwern: training time was 17.81 days on 8x 32GB V100
[03:51:28] <kuudes> given the antimatter must travel slower than light, so when it travels to negative time, the location where it will again annihilate to matter, the born teleported you is within light distance from you, ie future you on enterprise could observe past-you on the planetside
[03:51:29] <gwern> so 142 gpu-days? pretty chonky
[03:55:21] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[03:55:32] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 240 seconds)
[03:56:38] *** Lord_of_Life_ is now known as Lord_of_Life
[03:56:57] <kuudes> ... is it physically possible to create a true void, ie spacetime volume where there is not anything, even photons etc in it?
[03:58:30] <gwern> I don't think you can, because you still have quantum mechanical effects and the vacuum energy
[03:59:48] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:a490:5fc9:63d:72a6)
[03:59:57] <gwern> https://en.wikipedia.org/wiki/Zero-point_energy
[04:00:09] <feepbot> <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096" /><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096" />Zero-point energy (ZPE) is the lowest possible energy that a quantum mechanical system may have.
[04:01:57] <CoJaBo> feepbot: <wat n="ternation" />
[04:03:16] <kuudes> yeah, I suppose
[04:03:36] <gwern> RiversHaveWings: did you manage to overfit?
[04:03:39] <CoJaBo> Was this the one that crashed on http/2 lol
[04:04:28] <Filipepe> hi kuudes
[04:06:59] <kuudes> hi Filipepe :)
[04:07:05] <kuudes> how are you?
[04:07:10] <kuudes> did you recover your face?
[04:07:47] <Filipepe> not really, it's still paralyzed
[04:07:52] <Filipepe> otherwise I'm ok
[04:09:56] <kuudes> :-(
[04:10:02] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 240 seconds)
[04:10:06] <kuudes> good to hear no worse stuff has happened though
[04:10:49] <Filipepe> thanks
[04:15:01] <gwern> a strange incident
[04:15:25] <Obormot\Arcturus> CoJaBo: You're thinking of Robomot
[04:15:43] <Obormot\Arcturus> CoJaBo: Which is absent right now because it's undergoing maintenance, for that issue among others :p
[04:16:15] <CoJaBo> Obormot\Arcturus: I think the HTML mess needs some "maintenance" too lol
[04:16:44] <Obormot\Arcturus> Well, that's not my department
[04:17:21] <Obormot\Arcturus> Render unto Obormot bugs with Obor-things, render unto feep bugs with feep-things
[04:20:51] <Obormot\Arcturus> Meanwhile, can anyone help me figure out whether https://www.facebook.com/duncan.sabien/posts/4232363480131670 is visible (i.e., the content) without logging into Facebook?
[04:21:03] <feepbot> Log into Facebook to start sharing and connecting with your friends, family, and people you know.
[04:21:21] <Obormot\Arcturus> Reference thread is https://www.greaterwrong.com/posts/D5BP9CxKHkcjA7gLv/speaking-of-stag-hunts#comment-oeEX5Q4fzmmjCdggH (contains some records of people testing on various platforms)
[04:21:34] <feepbot> Speaking of Stag Hunts - LessWrong 2.0 viewer (This is an essay about the current state of the LessWrong community, and the broader EA/rationalist/longtermist communities that it overlaps and bridges, inspired mostly by the dynamics around these three posts.  The concepts and claims laid out in Con [snip])
[04:23:17] <Obormot\Arcturus> https://www.greaterwrong.com/posts/D5BP9CxKHkcjA7gLv/speaking-of-stag-hunts#comment-t6oeDd9ZHYHKjc9uB ... flawless comment
[04:23:29] <Obormot\Arcturus> Possibly the ideal possible comment
[04:23:37] <feepbot> Speaking of Stag Hunts - LessWrong 2.0 viewer (This is an essay about the current state of the LessWrong community, and the broader EA/rationalist/longtermist communities that it overlaps and bridges, inspired mostly by the dynamics around these three posts.  The concepts and claims laid out in Con [snip])
[04:23:37] <Obormot\Arcturus> saturn2, quanticle, nshepperd2: ^
[04:24:08] <RiversHaveWings> so apparently the NFT controversy has taken over Twitter?
[04:24:30] <gwern> Obormot\Arcturus: I get a login wall on my logged out ff/chrome, and also through a remote IP
[04:24:38] <Obormot\Arcturus> RiversHaveWings: "the" NFT controversy?
[04:24:44] <Obormot\Arcturus> gwern: thx
[04:24:56] <kuudes> hmm. I just thought: can you use kevin bacon -theory to get prior on secondhand observation likelihood?
[04:25:00] <RiversHaveWings> Well I see so many anti-NFT tweets now
[04:25:31] <kuudes> ie if everyone isd 6 hops from everyone else, then each hop must bring on average 45 new contacts, more on start, less on end likely
[04:26:32] <kuudes> so if anyone you know personally has observed an event, then it updates toward the prior for the event to be ~ 1/45, if someone they know has observed the event then it is 1/2000, if someone they knew knows someone who has observed the event, then it is 1/90000
[04:27:34] <gwern> RiversHaveWings: it comes and goes. the issue-attention cycle, y'know. I haven't noticed all that much different this time
[04:27:37] <kuudes> and you know who you know, and you could ask the person who told you about another person what is the first name of the person who observed the event, and if they know the name immediately, then it is 1/2000, and if they know it by asking from someone, then it is 1/90000 and if they don't know, it should be less
[04:28:45] <kuudes> ie "how many persons have had something fall on them from another floor?" ask your friends if they know anyone such, then if they do, query if they can name the person, and you have fermi prior on the probability that a person has something fall on them from another floor
[04:30:05] <gwern> what if they live on the top floor
[04:30:18] <kuudes> who?
[04:30:29] <gwern> you or the person you ask
[04:30:52] <kuudes> I don't see how that matters on the question, as the framing includes such people as well?
[04:31:41] <kuudes> you could change the question to, how frequently persons drown, ie "do you know anyone who has drowned?"
[04:31:45] <gwern> the probability you ask someone on the top floor seems a lot higher than 1 in 2000, much less 1 in 9000
[04:32:13] <kuudes> but you are estimating the frequency in the general population
[04:32:41] <kuudes> I guess if you have a strong selection for a penthouse social bubble, then indeed your results will be biased that way?
[04:33:58] <kuudes> and indeed random questions such as "how large fraction of people have a billion?" on this channel gives biased results this way
[04:37:59] *** Quits: two2thehead (~user@124.195.209.131) (Quit: Leaving)
[04:38:01] <Obormot\Arcturus> https://www.bloomberg.com/opinion/articles/2021-11-08/elon-musk-did-some-tweets ... the "Ransomware" section is a-fucking-mazing
[04:38:12] <feepbot> Will Elon Musk Actually Sell 10% of His Tesla Stock? - Bloomberg (Also Theranos due diligence, ransomware errors and crypto education.)
[04:39:42] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:a490:5fc9:63d:72a6) (Quit: Client closed)
[04:39:53] <gwern> 'WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)' oh no
[04:40:00] <Obormot\Arcturus> Oh by the way I guess we have a new mayor(-elect)
[04:40:19] <Obormot\Arcturus> It's Eric Adams! (absolutely no one anywhere is surprised even a little bit)
[04:40:46] <Obormot\Arcturus> He got 66.5% of the vote. The other guy got 28.8%
[04:41:24] <gwern> the blasio is dead. long live the blasio
[04:41:31] <gwern> https://www.gwern.net/docs/www/misc/xwd-16364202311130959.png /sigh
[04:41:42] <Obormot\Arcturus> Second black mayor of NYC ever
[04:41:51] <Obormot\Arcturus> Hopefully won't be as absolutely shitty as the first one
[04:42:20] <Obormot\Arcturus> Of course after de Blasio there's *almost* nowhere to go but up...
[04:43:07] <Obormot\Arcturus> "New York Mayor-elect Eric Adams said schools should teach about cryptocurrency and its technology, as he vows to build a crypto-friendly city when he takes office in January. 
[04:43:07] <Obormot\Arcturus> “When I talked about blockchain and Bitcoins, young people on street stopped and asked me, ‘What is that?’” Adams said on CNN’s “State of the Union” on Sunday. Asked if he could explain Bitcoin, he laughed, saying that’s a challenge even for experts. "
[04:43:11] <RiversHaveWings> gwern: you need to install gpu jax probably
[04:44:27] <gwern> it doesn't even use more than one core?!
[04:44:58] <RiversHaveWings> not yet
[04:45:06] <RiversHaveWings> it is super basic
[04:47:14] <gwern> 'The jaxlib version must correspond to the version of the existing CUDA installation you want to use: For CUDA 11.1 or newer use cuda11. The same wheel should work for CUDA 11.x releases from 11.1 onwards. Older CUDA versions are not supported.' uh oh
[04:47:37] <gwern> I'm not sure ubuntu 20.04 LTS has CUDA 11.x at all
[04:47:57] <RiversHaveWings> i install it from nvidia
[04:48:00] <RiversHaveWings> using the runfile
[04:48:02] <RiversHaveWings> into /usr/local
[04:48:37] <RiversHaveWings> you also need recent cudnn
[04:50:47] <RiversHaveWings> when you get it working be warned that the default CLIP guidance scale of 1000 can be too high for the danbooru model and drag it too far off distribution/make things that don't look like anime
[04:50:52] <RiversHaveWings> if this happens try 500
[04:51:06] <RiversHaveWings> also it helps if you put "anime" in the prompt
[04:51:22] <RiversHaveWings> I'd like to guide it with deepdanbooru but need a JAX version of it.
[04:51:44] <gwern> looks like a single core is about 8.5s/iteration, you need like 1000 in the standard ddpm schedule, right? that's a lot
[04:51:59] <gwern> what's reasonable for using ddim, --eta/--steps wise?
[04:52:08] <RiversHaveWings> --steps 250 --eta 0
[04:52:24] <gwern> I thought DDIM used way fewer, like 20?
[04:52:52] <RiversHaveWings> the quality degrades too much imo, also you just totally can't do CLIP guidance with such short schedules.
[04:53:11] <RiversHaveWings> you can try 20 steps eta 0 with unconditional sampling
[04:53:15] <gwern> bleh. well, I am definitely not up to upgrading nvidia drivers today
[04:53:21] <RiversHaveWings> but it's gonna be super bad with CLIP.
[04:54:39] <gwern> let's see, does batch-size parallelize over cores...
[04:54:41] <RiversHaveWings> future models will probably be pytorch bc people started throwing 8x gpu boxes at me once i demonstrated that i could train diffusion models from scratch
[04:54:49] <RiversHaveWings> gwern: i bet no
[04:55:38] <gwern> looks like no
[04:56:13] <gwern> wait, it does
[04:56:28] <gwern> it's just the compilation/jit/whatever which is single-core (also bad)
[04:56:36] <RiversHaveWings> oh
[04:57:18] <gwern> or... hm. it output a single image?
[04:58:02] <RiversHaveWings> it won't actually do more than one image unless you do -n too
[04:58:13] <gwern> -_-
[04:58:21] <RiversHaveWings> it loops in batches of at most -bs until it has done the number you specify with -n
[04:58:34] <RiversHaveWings> the last batch is the remainder
[05:00:34] <gwern> https://www.gwern.net/docs/www/misc/xwd-16364213871157612.png threadripper go brrr
[05:00:58] <RiversHaveWings> eheh~
[05:01:57] <nshepperd2> \o/
[05:03:35] <gwern> (so looks like it's about 25 minutes per batch of 32. decent throughput, bad latency)
[05:04:29] <gwern> does DDIM converge with DDPM at larger steps or does it fall short qualitatively so the 1000 steps DDPM gives the best possible results?
[05:05:33] <nshepperd2> https://irc.zlkj.in/uploads/c9e59fa103f8e28b/out_00000.png got a cute robot!
[05:05:55] <gwern> if you squint. wikiart model?
[05:05:56] <nshepperd2> RiversHaveWings: this is very usable, good job :)
[05:06:10] <nshepperd2> that was danbooru hehe
[05:10:31] <gwern> hm. I guess clip is good at pulling watercolor out of danbooru
[05:11:49] <gwern> wonder how yo'd quantify a base model being better than another... you can't use the CLIP loss, because that's what you optimized in the first place. perhaps one of the other CLIP models?
[05:12:10] <gwern> wouldn't be fully independent of the blindspots of the original CLIP but at least partially
[05:14:48] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[05:17:11] <feepbot> <gwern> https://twitter.com/l4rz/status/1457783810947305472 cyberpunk af
[05:17:13] <|dbotdan> lab member 001 (@l4rz, 2021-11-08 18:55): ‘'город ночью в свете неона' by ruDALL-E’ Images: https://twitr.gq/pic/media%2FFDsWo2ZaIAAn8Q-.jpg%3Fname%3Dorig
[05:22:02] <saturn2> kuudes: https://en.m.wikipedia.org/wiki/Quantum_vacuum_state
[05:22:20] <feepbot> <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096" />In quantum field theory, the quantum vacuum state (also called the quantum vacuum or vacuum state) is the quantum state with the lowest possible energy.
[05:24:30] <gwern> https://www.gwern.net/docs/www/misc/2021-11-08-ddim-25steps-danbooru2020-128px-randomsamples.png doubled with esrgan for clarity. using the longer schedule is probably a good idea
[05:26:59] <gwern> gonna try an overnight run with 'nice ./clip_sample.py "Asuka Souryuu Langley, Neon Genesis Evangelion, in a black-red plugsuit, facing the viewer (Artstation CGI portrait; blond hair, blue eyes, red hairclips)" --batch-size 34 --model danbooru_128 --seed 0 --steps 1000  -n 1024' to see how that does
[05:28:26] <saturn2> should you specify which side her eye patch is on?
[05:29:02] <gwern> nah. it's not like humans can get it straight either. geometry, how does it work. also, I didn't say Rebuild
[05:29:48] <saturn2> oh ok
[05:29:52] <gwern> (that would be Asuka *Shikinami* Langley)
[05:33:42] <gwern> hm. 180s/it for guided, 1000 steps, so... 50 hours for the first batch? that's not gonna work
[05:33:56] <gwern> guess I'll wait for the colab
[05:35:36] <gwern> 'Honestly the only part of this story which surprises me at all is that the Mother was a Sephardic Jew; usually it’s us Ashkenazi who end up in these kinds of situations.'
[05:39:44] <gwern> RiversHaveWings: I've mirrored the danbooru model at rsync://176.9.41.242:873/biggan/2021-11-08-rivershavewings-vdiffusionjaxddpm-danbooru2020sfw128px-32epochs.pkl if you want to use that in a colab instead of your current AWS, which I imagine might get expensive
[05:44:45] <feepbot> <gwern> https://twitter.com/danielrussruss/status/1457699402336800772 terrifying
[05:44:48] <|dbotdan> Daniel Russell (@danielrussruss, 2021-11-08 13:19): ‘`'Necromancer' - Steven Belledin` | CLIP Guided Diffusion (100 DDPM steps) | 1024x1024’ Images: https://nitter.namazso.eu/pic/media%2FFDrJK8jVkAQctCx.jpg%3Fname%3Dorig (description: a person holding a skull; confidence: 0.42) | https://nitter.namazso.eu/pic/media%2FFDrJMKSVUAs0MH5.jpg%3Fname%3Dorig |
[05:44:48] <|dbotdan> https://nitter.namazso.eu/pic/media%2FFDrJNDnVgAMhNVN.jpg%3Fname%3Dorig
[05:49:49] <feepbot> <gwern> https://twitter.com/ggreenwald/status/1457850442298314754
[05:49:51] <|dbotdan> Glenn Greenwald (@ggreenwald, 2021-11-08 23:20): ‘I hope anyone who plans on opining on the Kyle Rittenhouse verdict, whatever it may be, spends significant time watching most or all of the trial, not relying on media accounts.  | Almost no trial can be credibly assessed without watching it, but especially one this fraught.’
[05:54:51] <feepbot> <gwern> https://twitter.com/advadnoun/status/1457563636495388684 it *almost* spells out 'amber'
[05:54:53] <|dbotdan> Adverb (@advadnoun, 2021-11-08 04:20): ‘Preserved’ Images: https://nitter.domain.glass/pic/media%2FFDpNQmnUYAMjz9N.png%3Fname%3Dorig (description: map; confidence: 0.23)
[05:59:54] <feepbot> <gwern> https://colab.research.google.com/drive/1Tb7J4PvvegWOybPfUubl5O7m5I24CBg5?usp=sharing  https://twitter.com/l4rz/status/1457702687303090180
[05:59:54] <|dbotdan> lab member 001 (@l4rz, 2021-11-08 13:32): ‘a colab for ruDALL-E finetuning  https://colab.research.google.com/drive/1Tb7J4PvvegWOybPfUubl5O7m5I24CBg5?usp=sharing thx to the usual suspects!’
[05:59:55] <feepbot> Google Colab
[06:00:13] <RiversHaveWings> gwern: ty :)
[06:00:46] <RiversHaveWings> gwern: ddim and ddpm are not the same even w/ large numbers of steps
[06:01:26] <RiversHaveWings> idk if they are the same for *infinite* steps (it's late and i would have to think about it, i think they aren't offhand)
[06:01:59] <RiversHaveWings> like they correspond to different continuous forward processes
[06:04:31] <gwern> hm, but if they converge to different distributions, surely one of them is wrong? and I hadn't heard of that
[06:09:32] <feepbot> <gwern> https://openreview.net/forum?id=Vzh1BFUCiIX hi google
[06:09:32] <feepbot> ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning | OpenReview (Despite the recent success of multi-task learning and transfer learning for natural language processing (NLP), few works have systematically studied the effect of scaling up the number of tasks...)
[06:12:53] <RiversHaveWings> gwern: the ddim forward process is picked so you can use its corresponding reverse process with a model trained with the same objective as for ddpm
[06:13:29] <RiversHaveWings> specifically, with ddim the noise you add during the forward noising process is the *same* each timestep
[06:13:34] <RiversHaveWings> it's non-markovian
[06:13:51] <gwern> yeah, they can be different processes, but I'm saying they ought to sample from the same distribution. if they don't converge on the same distribution and sample every point with the same proportion, that's kinda weird
[06:13:53] <RiversHaveWings> like, once you pick the noise tensor at random you just add it over and over again.
[06:13:59] <RiversHaveWings> gwern: ah
[06:15:25] <RiversHaveWings> i would have to think further if they do the same thing in the limit of infinite timesteps
[06:20:13] *** _koolazer is now known as koolazer
[06:20:25] <feepbot> <gwern> https://twitter.com/emollick/status/1457881726294822917 :(
[06:20:29] <|dbotdan> Ethan Mollick (@emollick, 2021-11-09 01:24): ‘What makes art great? Connections. | This paper examines 500,000 artists and finds long-term success is determined by the prestige of their first exhibits & how connected those galleries are. It is hard to break into fame if you don’t start with high status https://www.science.org/doi/full/10.1126/science.aau7224 ’ Images:
[06:20:29] <|dbotdan> https://nitter.skrep.in/pic/media%2FFDtvPPeXMAgKi0B.jpg%3Fname%3Dorig (description: chart, map, scatter chart; confidence: 0.82) | https://nitter.skrep.in/pic/media%2FFDtvR6LWYAUK86D.jpg%3Fname%3Dorig | https://nitter.skrep.in/pic/media%2FFDtvUM2WEAYKpxM.jpg%3Fname%3Dorig
[06:25:30] <feepbot> <gwern> 'This is not, by and large, a pandemic-related supply problem: as we’ll show, supply of almost everything is at all-time highs. Rather, this is mostly an MP3-driven upward demand shock. And while some drivers of higher inflation have been transitory, we see the underlying demand/supply imbalance getting worse, not better.'
[06:25:30] <feepbot> https://www.bridgewater.com/its-mostly-a-demand-shock-not-a-supply-shock-and-its-everywhere DAMN YOU NAPSTER
[06:25:30] <feepbot> It’s Mostly a Demand Shock, Not a Supply Shock, and It’s Everywhere (Monetary Policy 3 created a self-reinforcing demand explosion that is getting harder, not easier, for supply to keep up with.)
[06:30:30] <feepbot> <gwern> 'Then a user called `phonequail` joined and began posting bizarre threads. Bizarre relative to the typical discussions of workplace drama, Mormon theology, 24, and indie rock, anyway. As an example, he started a thread in which he GM'd a Belle & Sebastian-based RPG. In another instance he satirized a thread called "Shooting the Breeze", which functioned as a pre-Twitter for
[06:30:30] <feepbot> short thoughts and observations not worthy of their own thread. He declared it had too many words and too much discussion. Conesequently, he started his own thread "Muting the Breeze", in which users were only allowed to converse using images—except images of baby ultrasounds, which were too violent for polite conversation. His magnum opus was another series of threads in which
[06:30:30] <feepbot> he played out a sci-fi RPG he called "Spacelab". Participants traveled around the galaxy, and he gave paragraphs of vivid, hilarious descriptions of strange worlds and aliens. Each post ended with an arbitrary, seemingly meaningless choice, which would ultimately propel the player into another offbeat adventure. E.g., "Do you pick up the calendar on the desk, or relax on your bed
[06:30:35] <feepbot> with a magazine". Meanwhile other users participated as "fans" of Spacelab imagining it to be a long-running sci-fi universe in the mold of Star Trek, with ego-driven stars, fan conventions, and a children's show spinoff.' https://news.ycombinator.com/item?id=29142915 oh my god _why invented forum quests
[06:30:37] <feepbot> _why's Estate | Hacker News
[06:39:10] <feepbot> <gwern> https://twitter.com/TheCaptain_Nemo/status/1457863616128950283/photo/1
[06:39:13] <|dbotdan> Captain Nemo (@TheCaptain_Nemo, 2021-11-09 00:12): ‘feeling sassy, might delet’ Images: https://nitter.pussthecat.org/pic/media%2FFDtfGCMVUAEqxlf.jpg%3Fname%3Dorig (description: diagram; confidence: 1.00)
[06:49:01] <Obormot_\Gaia> gwern: _why didn't invent forum quests, play-by-forum roleplaying has been around since the '80s -_-
[06:49:07] *** Obormot_\Gaia is now known as Obormot\Gaia
[06:54:03] <feepbot> <gwern> https://arxiv.org/abs/2111.04204 I always enjoy natural adversarial examples. regular ones are just too weird, but natural ones are fun
[06:54:04] <feepbot> [2111.04204] Natural Adversarial Objects (Although state-of-the-art object detection methods have shown compelling)
[06:59:03] <feepbot> <gwern> https://twitter.com/nobu_hibiki/status/1457695376996114439
[06:59:04] <|dbotdan> the boats will save us (@nobu_hibiki, 2021-11-08 13:03): ‘oh fuck im reading lesswrong and it's really good’
[07:13:19] <Obormot\Arcturus> https://www.datasecretslox.com/index.php/topic,4970.msg0.html#new
[07:13:28] <Obormot\Arcturus> "Honestly the only part of this story which surprises me at all is that the Mother was a Sephardic Jew; usually it’s us Ashkenazi who end up in these kinds of situations."
[07:13:38] <feepbot> Model City Monday 11/8/21: Liberty! Prosperity! Giant gold golf balls!
[07:14:11] <Obormot\Arcturus> (For example, https://en.wikipedia.org/wiki/Max_Th%C3%A9on )
[07:14:23] <feepbot> Max Théon (17 November 1848 – 4 March 1927) perhaps born Louis-Maximilian Bimstein, was a Polish Jewish Kabbalist and Occultist.
[07:18:22] <gwern> today's weird metadata: not '1.11%' but '1.11‰'. a PER MILLE SIGN
[07:20:43] <gwern> I am *pretty* sure it's erroneous:    'the excess procurement ratio of provinces governed by alternate members of the Central Committee was about 3% higher than in provinces governed by full members, or there was an approximate 1.11‰ increase in the excess death rate.' <-- reading https://en.wikipedia.org/wiki/Per_mille it's for absolute fractions, but the death rate is already a small...
[07:20:49] <gwern> ...fraction
[07:20:54] <feepbot> Per mille - Wikipedia
[07:21:03] <gwern> and it's the Great Famine, so meaning like '0.011%' or whatever also sounds absurdly small
[07:26:04] <feepbot> <gwern> https://www.gwern.net/docs/www/misc/xwd-16364296241179634.png hm. might need examples for this
[07:31:05] <feepbot> <gwern> https://www.gwern.net/docs/www/misc/xwd-16364300761192687.png this one also works, but GPT-3 undesirable rephrases the abstract. the paraphrase is correct, but still, undesirable
[07:33:30] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[07:35:34] <gwern> the first one would be fine (I think my regexps already handle that) except for the paraphrasing... darn it gpt-3
[07:36:12] <gwern> the problem is that I can't even insert the linebreaks into the original if gpt-3 paraphrases, because it might run together or split sentences
[07:36:21] <gwern> so how do you align them easily?
[07:39:25] <energizer> what if you give it more examples?
[07:42:03] <gwern> you'll start to run out of context window
[07:42:17] <gwern> that'll also cost a factor more
[07:45:23] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Remote host closed the connection)
[07:53:48] <feepbot> <gwern> https://www.reddit.com/r/evangelion/comments/qpnmei/alright_who_tf_did_this/ "Man of culture's pick-up
[07:53:50] <feepbot> alright, who tf did this : evangelion (729 votes and 18 comments so far on Reddit)
[07:58:49] <feepbot> <gwern> https://www.biorxiv.org/content/10.1101/2021.11.05.467434v1.full https://www.biorxiv.org/content/10.1101/2021.11.05.467388v1.full
[07:58:49] <feepbot> Please Wait... | Cloudflare
[08:03:49] <feepbot> <gwern> https://en.wikipedia.org/wiki/Wallenberg_family wow
[08:03:51] <feepbot> The Wallenberg family are a prominent Swedish family, Europe's pre-eminent, most powerful business family and dynasty, renowned as bankers, industrialists, politicians, bureaucrats, and diplomats. The Wallenberg sphere's holdings employ about 600,000 people and have sales of $154 billion a year.
[08:08:31] <rmmh> https://twitter.com/noamscheiber/status/1457907174571708417
[08:08:31] <|dbotdan> Noam Scheiber (@noamscheiber, 2021-11-09 03:05): ‘"Schultz noted that only a small portion of prisoners in German concentration camps received blankets but often shared them with fellow prisoners. 'So much of that story is threaded into what we have tried to do at Starbucks,' Schultz said, according to a transcript."’
[08:13:33] <feepbot> <gwern> https://www.nobelprize.org/prizes/chemistry/1993/mullis/lecture/ I should not be surprised
[08:13:33] <feepbot> Kary B. Mullis - Nobel Lecture: The Polymerase Chain Reaction - NobelPrize.org (The Nobel Prize in Chemistry 1993 was awarded "for contributions to the developments of methods within DNA-based chemistry" jointly with one half to Kary B. Mullis "for his invention of the polymerase chain reaction (PC [snip])
[08:14:24] *** Quits: _inky (~inky_@46.36.112.208) (*.net *.split)
[08:14:24] *** Quits: Obormot\Arcturus (~obormot@user/obormot) (*.net *.split)
[08:14:24] *** Quits: dv^_^ (~dv@eclipse.oxfordfun.com) (*.net *.split)
[08:14:24] *** Quits: niko (~niko@libera/staff/niko) (*.net *.split)
[08:14:24] *** Quits: dx (~dx@irssi/staff/dx) (*.net *.split)
[08:14:24] *** Quits: mortehu (mortehu@178.79.163.96) (*.net *.split)
[08:14:24] *** Quits: shawwwn (uid6132@helmsley.irccloud.com) (*.net *.split)
[08:14:24] *** Quits: SomeBrashAtom (sid391184@hampstead.irccloud.com) (*.net *.split)
[08:15:12] *** Joins: _inky (~inky_@46.36.112.208)
[08:15:12] *** Joins: Obormot\Arcturus (~obormot@user/obormot)
[08:15:12] *** Joins: dv^_^ (~dv@eclipse.oxfordfun.com)
[08:15:12] *** Joins: niko (~niko@libera/staff/niko)
[08:15:12] *** Joins: dx (~dx@irssi/staff/dx)
[08:15:12] *** Joins: mortehu (mortehu@178.79.163.96)
[08:15:12] *** Joins: shawwwn (uid6132@helmsley.irccloud.com)
[08:15:12] *** Joins: SomeBrashAtom (sid391184@hampstead.irccloud.com)
[08:18:33] <feepbot> <gwern> I've never seen a naked polar bear
[08:20:41] <Obormot\Arcturus> https://en.wikipedia.org/wiki/Naegleriasis
[08:20:53] <feepbot> Naegleriasis (also known as primary amoebic meningoencephalitis; PAM) is an almost invariably fatal infection of the brain by the free-living unicellular eukaryote Naegleria fowleri.
[08:21:00] <Obormot\Arcturus> https://en.wikipedia.org/wiki/Naegleria_fowleri
[08:21:11] <feepbot> Naegleria fowleri - Wikipedia
[08:22:03] <Obormot\Arcturus> "Naegleria fowleri, colloquially known as a "brain-eating amoeba", is a species of the genus Naegleria, belonging to the phylum Percolozoa, which is technically not classified as true amoeba, but a shapeshifting amoeboflagellate excavate.[1] It is a free-living, bacteria-eating microorganism that can be pathogenic, causing an extremely rare sudden, severe and usually fatal brain infection called naegleriasis or primary amoebic
[08:22:03] <Obormot\Arcturus>  meningoencephalitis (PAM).[2]"
[08:22:09] <Obormot\Arcturus> "Although infection occurs very rarely,[6] it almost inevitably results in death.[7][8] Of the 450 or so naegleriasis cases in the past 60 years, only seven have survived,[9] for a case fatality rate of 98.5%. "
[08:22:20] *** Quits: gwern (~gwern@user/gwern) (Ping timeout: 268 seconds)
[08:27:10] <feepbot> <gwern> https://www.dailymail.co.uk/news/article-1225042/Germanys-bald-bears-Fur-disease-afflicts-Dolores-baffles-vets.html I've changed my mind based on these. like sphinx cats, naked bears are something no one should ever see
[08:27:11] <feepbot> Germany's bald bears: Fur disease afflicts Dolores and baffles vets | Daily Mail Online (You'd have thought a fur coat would have been the ultimate bear necessity.)
[08:32:34] *** Joins: gwern (~gwern@user/gwern)
[08:42:32] *** Quits: Rubba (~Kol@d75-157-122-186.bchsia.telus.net) (Remote host closed the connection)
[08:42:53] *** Joins: Kol (~Kol@d75-157-122-186.bchsia.telus.net)
[08:44:24] *** Quits: rmmh (~none@user/rmmh) (Ping timeout: 260 seconds)
[08:44:40] <ggreer> oh there's drone footage of the rosenbaum shooting: https://files.catbox.moe/m44f1j.mp4 rosenbaum was really close when rittenhouse open fire
[08:46:32] <ggreer> (the action happens in the well lit parking lot)
[08:46:53] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[08:47:23] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[08:50:08] *** Joins: rmmh (~none@user/rmmh)
[08:51:30] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 244 seconds)
[09:00:32] *** Quits: srhm (~srhm@user/srhm) (Quit: Konversation terminated!)
[09:03:01] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[09:07:02] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[09:20:44] *** Quits: grandrew__ (~grandrew@c-73-71-100-231.hsd1.ca.comcast.net) (Remote host closed the connection)
[09:22:21] *** Quits: mala (~mala@user/malaclyps) (Quit: ZNC 1.6.1 - http://znc.in)
[09:24:37] *** Quits: spxtr (~spxtr@user/spxtr) (Remote host closed the connection)
[09:38:57] *** Joins: feep[work] (~mathis@217.64.163.97)
[10:15:44] *** Joins: spxtr (~spxtr@user/spxtr)
[10:17:44] *** Joins: mala (~mala@user/malaclyps)
[10:19:43] *** Joins: grandrew (~grandrew@c-73-71-100-231.hsd1.ca.comcast.net)
[10:27:32] *** Quits: thlnz (~thln@user/thlnz) (Ping timeout: 240 seconds)
[10:32:48] *** Joins: thlnz (~thln@user/thlnz)
[11:00:01] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[11:03:51] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[11:04:29] *** Quits: Obormot\Arcturus (~obormot@user/obormot) (Read error: Connection reset by peer)
[11:05:27] *** Joins: Obormot\Arcturus (~obormot@user/obormot)
[11:06:27] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[11:08:02] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[11:12:45] <Obormot\Arcturus> .note Gurkenglas Tested the Matt Levine column with AKS on Windows. Works flawlessly on Chrome, equally flawlessly on Firefox.
[11:15:02] *** Quits: thlnz (~thln@user/thlnz) (Ping timeout: 240 seconds)
[11:24:05] *** Joins: phill (uid429774@id-429774.ilkley.irccloud.com)
[11:24:59] <kuudes> thanks saturn2
[11:26:18] <kuudes> btw, https://www.instagram.com/lottaylihukkala/ is a person over here who graduated from secondary with top degrees of her year two years ago and graduated as master of law this year, running through master's degree in 1 year
[11:26:30] <feepbot> @lottaylihukkala is on Instagram • 1,234 people follow their account (1,234 Followers, 654 Following, 219 Posts - See Instagram photos and videos from Lotta Yli-Hukkala (@lottaylihukkala))
[11:26:59] <kuudes> so... on level 1/50000 I guess or above, given cohort size of ~50000
[11:28:15] <kuudes> .z 0.000002
[11:28:15] <feepbot> kuudes: z(0.000001) = -4.611382
[11:29:32] <feep[work]> that seems wrong..
[11:29:38] <feep[work]> probably cause we're on the border of float math precision
[11:29:45] <feep[work]> or printf precision
[11:30:05] <kuudes> maybe e-notation would work better?
[11:30:10] <feep[work]> doubt it?
[11:30:26] <feep[work]> hm, the function is defined as double
[11:30:34] <kuudes> libreoffice calc says -4,10747965458625
[11:30:42] <feep[work]> okay, so basically right?
[11:30:50] <feep[work]> what's libreoffice of z(0.000001)?
[11:30:51] <kuudes> 0,5 difference
[11:31:06] <kuudes> -4,26489079392282 for 1/100k
[11:31:18] <kuudes> something's fucky
[11:31:20] <feep[work]> yeah
[11:31:49] <feep[work]> man I gotta port feepbot to the current compiler *sometime*.
[11:32:32] <feep[work]> atof is supposed to return doubles, despite the name
[11:32:39] <kuudes> she would on priors have about iq 200 on 100:24
[11:32:57] <kuudes> 162 on 100:15
[11:33:05] <feep[work]> .z 2e-6
[11:33:06] <feepbot> feep[work]: z(0.000001) = -4.611382
[11:33:12] <feep[work]> .z 2e-5
[11:33:12] <feepbot> feep[work]: z(0.000020) = -4.107479
[11:33:16] <feep[work]> okay, works in principle
[11:33:50] <kuudes> hmm, so I had a calculation error there?
[11:34:02] <feep[work]> I just throw the double into printf
[11:34:10] <kuudes> .z 0.00002
[11:34:11] <feepbot> kuudes: z(0.000020) = -4.107479
[11:34:13] <kuudes> yeah
[11:34:16] <kuudes> my bad
[11:34:51] <kuudes> though that is still truncated string, not rounded number
[11:34:52] <feep[work]> I think the 0.000001 thing is a printf weirdness then.
[11:35:27] <kuudes> for 1/1_000_000 libreoffice calc gives -4,7534243088229
[11:35:40] <feep[work]> 2/1_000_00?
[11:35:50] <kuudes> -4,61138236230267
[11:35:57] <feep[work]> okay, so the output is correct.
[11:36:05] <feep[work]> good, I'll live with the z(0.000) error.
[11:36:16] <kuudes> I guess it deals internally with 0.0000019...
[11:36:19] <feep[work]> yeah
[11:36:25] <kuudes> and then truncs that to 0.000001
[11:36:56] <feep[work]> lemme try..
[11:37:45] <feep[work]> .reload
[11:37:46] <feepbot> feep[work]: Unauthorized!
[11:38:06] <feep[work]> feepbot-- I have ssh on your machine, you realize that, right--
[11:38:25] * feep[work] ctrl-c
[11:38:38] <feep[work]> owait now it needs to drop first.
[11:38:40] * feep[work] siigh
[11:38:55] *** Quits: feepbot (~feepbot@ppp-93-104-168-36.dynamic.mnet-online.de) (Killed (NickServ (GHOST command used by feep[work]!~mathis@217.64.163.97)))
[11:39:27] *** Joins: feepbot (~feepbot@ppp-93-104-168-36.dynamic.mnet-online.de)
[11:39:40] <feep[work]> .z 0.000002
[11:39:40] <feepbot> feep[work]: z(0.000001) = -4.611382
[11:39:49] <feep[work]> hm, printf ignoring my %e
[11:40:08] <feep[work]> lame
[11:40:17] <feep[work]> oh well XD
[11:40:18] <kuudes> feep[work], it appears to be rounding to even
[11:40:19] <kuudes> https://linuxgazette.net/144/misc/lg/a_question_of_rounding_in_issue_143.html
[11:40:30] <feepbot> "A Question Of Rounding" in issue #143
[11:40:30] <feep[work]> kuudes: right, I changed it to use exponential notation for small numbers
[11:40:37] <feep[work]> except it appears printf doesn't like me today
[11:41:32] <kuudes> banker's rounding or rounding to even seems rather unexpected to me. though I guess it has advantages such as the error being half time up and half time down uniformly
[11:41:46] <feep[work]> :iiam:
[11:41:53] <feep[work]> anyway, build finished, back to work
[11:41:55] <kuudes> ie 0.15 -> 0.2, 0.25 -> 0.2
[11:47:07] <feep[work]> my reviewer: "why is this class named HashMap rather than AssocArray? we already have a class named SomethingAssocArray"
[11:47:13] <feep[work]> my brain, immediately: "It is required now..."
[11:47:36] <feep[work]> The Northern Code Review
[11:54:14] *** Quits: milanandreew (uid500468@user/milanandreew) (Quit: Connection closed for inactivity)
[12:06:39] <PlanckWalk> 0.000002 is not 1/50,000  it's 1/500,000.
[12:06:43] <PapuaHardyNet> https://news.ycombinator.com/item?id=29144074
[12:06:54] <feepbot> Linux on the M1, with GPU Acceleration | Hacker News
[12:09:14] <kuudes> PlanckWalk, yes, corrected above
[12:12:12] <kuudes> saturn2, I presume zero-point energy prevents tachyonic teleportation, as if you managed to somehow bouncer particles to tachyonic direction (faster than light movement) then they would just collide to those invisible particles in the volume they pass through. if you could get a volume truly empty, then maybe you could imagine to move tachyonic matter through it
[12:12:33] <kuudes> but again random rambling, I don't know anything about it
[12:36:11] <nshepperd2> any interaction with virtual particles has to preserve the momentum and energy of the real particles entering and leaving, so i don't think it can present an obstacle in that particular way
[12:58:52] <saturn2> kuudes: i don't actually understand most of what's on that wikipedia page :p
[12:59:30] *** Joins: gproto23 (~gproto23@user/gproto23)
[13:04:50] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[13:09:02] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[13:21:49] <rsaarelm> Tried to figure out from backlog why we're talking about tachyons and zero-point energy all of a sudden.
[13:22:08] <rsaarelm> TIL the thing about antimatter being what matter travelling backwards in time would look like.
[13:33:51] *** Quits: phill (uid429774@id-429774.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[14:02:55] <kuudes> hmm, how do you guys see https://www.cambridge.org/core/journals/epidemiology-and-infection/article/closing-lower-secondary-schools-had-no-impact-on-covid19-incidence-in-1315yearolds-in-finland/41C00483107DA38550445C6B7E310B51 ?
[14:03:06] <feepbot> Closing lower secondary schools had no impact on COVID-19 incidence in 13–15-year-olds in Finland - Volume 149
[14:10:07] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[14:22:44] <Gurkenglas> !tell me my notes mkay?
[14:22:44] <feepbot> Gurkenglas: Obormot\Arcturus left a note 3 hours, 9 minutes ago: Tested the Matt Levine column with AKS on Windows. Works flawlessly on Chrome, equally flawlessly on Firefox.
[14:41:18] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[14:54:43] *** Quits: _inky (~inky_@46.36.112.208) (Ping timeout: 244 seconds)
[15:05:35] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[15:10:02] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[15:11:04] *** Joins: _inky (~inky_@5.77.139.14)
[15:19:01] *** Joins: Urchin[emacs] (~user@user/urchin)
[15:44:32] <PapuaHardyNet> !tell
[15:44:44] <PapuaHardyNet> ?
[15:48:38] <dutchie> not a real command, just saying anything triggers feepbot to spew notes
[15:54:02] <PapuaHardyNet> https://philosophynow.org/issues/45/The_Last_Messiah
[15:54:14] <feepbot> The Last Messiah | Issue 45 | Philosophy Now (The first English version of a classic essay by Peter Wessel Zapffe, originally published in Janus #9, 1933. Translated from the Norwegian by Gisle R. Tangenes.)
[15:58:06] <PapuaHardyNet> "If the giant deer, at suitable intervals, had broken off the outer spears of its antlers, it might have kept going for some while longer. Yet in fever and constant pain, indeed, in betrayal of its central idea, the core of its peculiarity, for it was vocated by creation’s hand to be the horn bearer of wild animals.
[15:58:13] <PapuaHardyNet> What it gained in continuance, it would lose in significance, in grandness of life, in other words a continuance without hope, a march not up to affirmation, but forth across its ever recreated ruins, a self-destructive race against the sacred will of blood."
[16:09:37] <Gurkenglas> meanwhile, deer dying from antlers: "doesnt matter had sex"
[16:14:58] <Gurkenglas> Is there a species with expensive status symbols whose appreciation was fixated before some innovation rendered them cheap so now everyone has them forever?
[16:32:22] *** Joins: voltage_ (voltage@user/voltage)
[17:05:02] <feepbot> <gwern> 'By the Spring, Zillow became fixated on another issue. The forecasting models it used to generate offers had underestimated breakneck home price appreciation in the early months of the year, meaning its pricing algorithms spit out relatively weak offers, preventing it from buying as many homes as it would’ve liked. Zillow turned up the dials in the second quarter,
[17:05:03] <feepbot> according to a person familiar with the decision, who asked not to be named because the matter is private. The move put Zillow out of step with competitors that had begun to take a more cautious stance, including Redfin Corp., which started making more conservative offers in March. But it also translated into rapid gains in the number of offers that Zillow’s customers accepted.
[17:05:03] <feepbot> Zillow bought almost 10,000 homes in the third quarter, more than double the number from the previous quarter.' https://www.bloomberg.com/news/articles/2021-11-08/zillow-z-home-flipping-experiment-doomed-by-tech-algorithms
[17:05:08] <feepbot> Zillow (Z) Home-Flipping Experiment Doomed by Tech Algorithms - Bloomberg (How the real estate company’s innovation became a $569 million cautionary tale.)
[17:06:25] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[17:10:39] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 250 seconds)
[17:13:41] <Gurkenglas> Aww, the German Geometer is geometrician in English? Geometer is such a better word.
[17:15:06] *** Quits: CoJaBo (~aztec@user/CoJaBo) (Ping timeout: 245 seconds)
[17:16:30] <Betawolf> geometer would be understood
[17:16:49] <gwern> I've seen 'geometer' a lot more than 'geometrician'
[17:18:56] <Betawolf> https://en.wikipedia.org/wiki/Geometrid_moth cute name collision
[17:18:57] <Gurkenglas> Online dictionaries disagree, but google result counts and my soul agree - done.
[17:18:58] <feepbot> <!--
[17:21:00] <Gurkenglas> ah, duckduckgo finds English encyclopedia results :)
[17:21:10] <nshepperd2> feepbot's been shot through the heart, and that link's to blame
[17:22:12] <nshepperd2> https://en.wikipedia.org/wiki/Geometer_moth#/media/File:Synchlora_aerata_caterpillar.jpg ehehe
[17:22:23] <feepbot> The geometer moths are moths belonging to the family Geometridae of the insect order Lepidoptera, the moths and butterflies.
[17:27:12] <feepbot> <gwern> https://twitter.com/alyssamvance/status/1457952231785787397 it what
[17:27:13] <|dbotdan> Alyssa Vance (@alyssamvance, 2021-11-09 06:04): ‘If you can read this, Xfinity/Comcast Internet appears to be down for the entire SF Bay Area. This happened to me two weeks ago - it lasted four days, and I couldn't even talk to a human (their phone robot detects if there's an outage at your address, then hangs up if there is)’
[17:32:13] <feepbot> <gwern> 'It became clear there was a case of mistaken identity when Run Run began to chase guinea pigs, chickens and ducks to kill or eat them, provoking the anger of neighbours. "About a month ago, a woman from around here said that it ate three of her guinea pigs. And then two or three days ago, a local grandmother came and said that it killed guinea pigs," owner Maribel Sotelo
[17:32:14] <feepbot> told Reuters news agency.' https://www.bbc.com/news/world-latin-america-59220074 at least it's not cats
[17:32:14] <feepbot> Peruvian family dog turns out to be a fox - BBC News (A family who thought they had bought a dog realised their mistake after it attacked other animals.)
[17:37:14] <feepbot> <gwern> https://colab.research.google.com/drive/1YqXnjwayh_LukZkfhkYbUuHPhGBQzcMQ https://twitter.com/danielrussruss/status/1458046787172790272 https://twitter.com/danielrussruss/status/1458062538906603525  RiversHaveWings: he's using the AWS download link. I hope you're good for the bandwidth...
[17:37:15] <feepbot> Google Colab
[17:37:21] <|dbotdan> Daniel Russell (@danielrussruss, 2021-11-09 12:20): ‘Here's an unofficial colab for @RiversHaveWings' newly trained CLIP guided diffusion models, put together by @BoneAmputee and modified by myself to allow for batch_size>1, displaying progress and saving a progress video: | https://colab.research.google.com/drive/1YqXnjwayh_LukZkfhkYbUuHPhGBQzcMQ | `[...] a top tier waifu.`’ Images:
[17:37:22] <|dbotdan> https://nitter.vxempire.xyz/pic/media%2FFDwFXJAVIAM9yYu.jpg%3Fname%3Dorig (description: a collage of a cat; confidence: 0.39)
[17:37:22] <|dbotdan> Daniel Russell (@danielrussruss, 2021-11-09 13:22): ‘I was just now noticing this too. | It clearly worked earlier... here was: | `an anime illustration of a goose girl. a girl that looks like a goose.` | Investigating’ Images: https://nitter.domain.glass/pic/media%2FFDwUHo1VIAY1Csy.jpg%3Fname%3Dorig (description: a collage of a person; confidence: 0.52)
[17:37:54] <RiversHaveWings> gwern: it's ok, the compute donor is paying for that bucket w/ AWS credits
[17:38:19] <RiversHaveWings> It is not on my personal AWS or anything. ^^;
[17:41:10] * gwern wrinkles his nose. still wasteful
[17:41:40] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[17:43:07] <RiversHaveWings> ffhq 256x256 diffusion, 200k training steps https://usercontent.irccloud-cdn.com/file/EwrT5IEA/demo_00200000-2.png
[17:43:51] <gwern> if you transfer from imagenet, would you getbetter backgorunds?
[17:44:03] <RiversHaveWings> gwern: maybe but i would have to do 128x128
[17:44:14] <RiversHaveWings> well, unless i trained a 256x256 imagenet first
[17:44:20] <gwern> still haven't figured out how to tack on an upscaling block or do net2net?
[17:44:42] <RiversHaveWings> eh not really, i tried a thing on cifar-10 but it wasn't really better
[17:44:49] <RiversHaveWings> otoh cifar-10 is probably too tiny for it to help
[17:45:11] <gwern> yeah, with cifar-10 it's a regularization and transfer game these days, too small
[17:50:11] <feepbot> <gwern> https://en.wikipedia.org/wiki/Science_fiction_opera
[17:50:12] <feepbot> Science-fiction opera is a subgenre of science fiction. It refers to operas whose subject-matter fits in the science fiction genre.
[17:50:39] *** Joins: CoJaBo (~aztec@user/CoJaBo)
[17:55:11] <feepbot> <gwern> https://twitter.com/AgnesCallard/status/1457887785382199303
[17:55:12] <|dbotdan> Agnes Callard (@AgnesCallard, 2021-11-09 01:48): ‘My kids, who are big Jeeves & Wooster fans, refusing to believe I read all the novels as a kid & never realized they were supposed to be funny. | (I thought they showcased the touching heroism and grace of a man tasked with managing the life of an idiot.)’
[18:01:44] *** Joins: two2thehead (~user@124.195.209.131)
[18:23:36] <gwern> Obormot\Arcturus: 'Feedback? :: Your Docs Listings are a bit of a mess currently. The up-arrow symbol in front of every "parent directory" link is disproportionately big.' <-- unicode bites again
[18:34:34] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 260 seconds)
[18:36:35] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[18:41:45] <Obormot\Arcturus> gwern: At this point it would be well simply to assume such things will happen when using Unicode icons in any way whatsoever
[18:42:02] <Obormot\Arcturus> I'll look into it
[18:43:54] <gwern> 'The first "link", 2.1 in case of IQ, is always divided it into two parts, 1st the name of paper which gets listed beside TOC, and 2nd the description/abstract which is below TOC. Not huge problem for other listings but IQ TOC is very BIG.' <-- but you knew about that one, it's hard to miss on pages like newsletters or indexes...
[18:46:03] <Obormot\Arcturus> Hm?
[18:46:18] <Obormot\Arcturus> What is this...?
[18:46:27] <gwern> it's the block overflow thing. you said it'd be pretty hard to fix
[18:46:57] <gwern> https://www.gwern.net/docs/www/misc/xwd-163647100041169.png that
[18:47:34] <Obormot\Arcturus> Oh. Yeah.
[18:48:08] <Obormot\Arcturus> Not 100% sure having the TOC there even makes sense, actually
[18:48:28] <gwern> it hits on other pages too
[18:48:38] <Obormot\Arcturus> Sure, just saying
[18:48:44] <Obormot\Arcturus> Unrelatedly to block overflow
[18:48:57] *** Joins: voltage (voltage@user/voltage)
[18:49:02] <Obormot\Arcturus> That use case of TOC entries is awkward and of very questionable use
[18:49:20] *** Quits: voltage_ (voltage@user/voltage) (Killed (NickServ (GHOST command used by voltage)))
[18:49:22] *** voltage is now known as voltage_
[18:59:31] <Obormot\Arcturus> https://www.wired.com/story/the-teeny-tiny-scientific-screwup-that-helped-covid-kill/
[18:59:42] <feepbot> The 60-Year-Old Scientific Screwup That Helped Covid Kill | WIRED (All pandemic long, scientists brawled over how the virus spreads. Droplets! No, aerosols! At the heart of the fight was a teensy error with huge consequences.)
[19:03:59] *** Quits: feep[work] (~mathis@217.64.163.97) (Ping timeout: 256 seconds)
[19:05:31] <gwern> https://www.gwern.net/docs/www/misc/xwd-163647210742313.png an asuka was attempted
[19:05:39] <kuudes> Obormot\Arcturus, that.
[19:05:51] <kuudes> and they still cling to that as well
[19:05:58] <kuudes> because "airborne" means "no hope"
[19:06:18] <kuudes> even though we could just use more ventilation and air cleaning, like in germany
[19:06:39] <rmmh> or SEA
[19:06:41] <Obormot\Arcturus> And UV lamps... 
[19:06:53] <Obormot\Arcturus> rmmh: What's that
[19:06:57] <rmmh> southeast asia
[19:07:02] *** Quits: _inky (~inky_@5.77.139.14) (Ping timeout: 240 seconds)
[19:07:04] <Obormot\Arcturus> Ah
[19:07:08] <catern> Obormot\Arcturus: what was the origin of the OGL that would undermine that article about capitalism ruining D&D?
[19:07:16] <rmmh> lots of schools, hospitals, apartments, etc invested in ventilation after SARS
[19:07:16] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[19:08:41] <Obormot\Arcturus> catern: First of all, just a matter of historical completeness and credit where it's due, it's really proper to mention that the OGL was explicitly designed as the TTRPG analogue of the GPL, and was specifically inspired by Stallman, ESR, and Linux
[19:11:35] <Obormot\Arcturus> catern: Second of all, and more relevantly to the capitalism point, the guy who came up with the idea of the OGL was WotC's business & marketing guy in charge of the RPG department (Ryan Dancey), and he put forth the OGL as a way to increase WotC's revenues! His whole idea was that an open license would cause a flowering of third-party products, grow the TTRPG market, and that benefits of this would accrue to the market leader
[19:11:35] <Obormot\Arcturus>  most of all (WotC)
[19:11:35] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 246 seconds)
[19:12:32] <gwern> and it probably did given the uptake: https://www.gwern.net/docs/economics/2006-lecocq.pdf
[19:12:55] <catern> nice
[19:13:07] <Obormot\Arcturus> But of course that *thoroughly* undermines the narrative, because it shows that the thing the article holds up as the one hope of a truly democratic D&D that's in the people's hands etc. etc., came from a for-profit company as a way to make money money
[19:14:37] *** Quits: ToyKeeper (~ToyKeeper@user/toykeeper) (Ping timeout: 265 seconds)
[19:15:45] *** Joins: ToyKeeper (~ToyKeeper@74-95-113-201-Colorado.hfc.comcastbusiness.net)
[19:17:20] *** Joins: src (~src@user/src)
[19:19:14] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[19:20:29] <Obormot\Arcturus> http://web.mit.edu/~yandros/rpg/ogf-interview.html ... here's the famous ENWorld interview with Ryan Dancey where he discusses this stuff, from when the OGL was first released (in 2000, with the publication of the 3rd edition of D&D, i.e. the first WotC edition)
[19:21:15] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Quit: Leaving)
[19:21:16] <Obormot\Arcturus> "Stallman left MIT and started an organization called GNU. Old-school programmers are a funny bunch, and one thing they like are nonsense acronyms that are self-referencing. "GNU" means "GNU's Not Unix". Trust me, if you don't get the joke, you're not missing anything."
[19:22:09] *** Joins: voltage_ (voltage@user/voltage)
[19:22:17] <gwern> (both the paper and interview are linked in https://www.gwern.net/Complement ofc)
[19:22:28] <feepbot> Laws of Tech: Commoditize Your Complement · Gwern.net (A classic pattern in technology economics, identified by Joel Spolsky, is layers of the stack attempting to become monopolies while turning other layers into perfectly-competitive markets which are commoditized, in order to harvest most of the [snip])
[19:22:38] *** Joins: _inky (~inky_@46.36.112.208)
[19:24:14] <Obormot\Arcturus> So yeah. All of this came directly out of market competition. (We could add that TSR never did anything remotely like this; it took them getting acquired by WotC for this to happen...)
[19:25:03] <Obormot\Arcturus> Whereas when that article was like "well socialist countries have movies and games and stuff too!", the one example they give (hyperlinked from "games" in that line I quoted the other day) is ... Tetris
[19:25:14] <Obormot\Arcturus> Cool, guys. Good comparison.
[19:29:21] <gwern> it's a pretty good game
[19:29:36] <Obormot\Arcturus> It is! But it's ... one game.
[19:30:00] <Obormot\Arcturus> One single arcade/puzzle computer game.
[19:36:31] <feep> home~
[19:36:47] <pompolic> i think the developer was not allowed to sell Tetris
[19:37:04] <pompolic> i'm not entirely clear on the story, but here https://en.wikipedia.org/wiki/Tetris#Acquisition_of_rights_by_Mirrorsoft_and_Spectrum_HoloByte
[19:37:16] <feepbot> Tetris (Russian: Тéтрис [ˈtʲɛtrʲɪs]) is a tile-matching video game created by Soviet software engineer Alexey Pajitnov in 1984. It has been published by several companies for multiple platforms, most prominently during a dispute over the appropriation of the rights in the late 1980s.
[19:37:26] <gwern> the business history of tetris is astonishingly convoluted. you should read filfre on that. I particularly admire https://www.filfre.net/2017/07/a-tale-of-the-mirror-world-part-5-the-inflection-point/
[19:37:38] <feepbot> » A Tale of the Mirror World, Part 5: The Inflection Point The Digital Antiquarian
[19:43:24] <gwern> https://www.gwern.net/docs/www/misc/xwd-163647436880153.png got a better asuka after decreasing eta and increasing the clip weight. but this still takes an absurd amount of time
[19:44:53] <rmmh> has someone computer CO2e of GANs vs starving artists
[19:44:58] <rmmh> computed*
[19:45:01] *** Quits: gproto23 (~gproto23@user/gproto23) (Read error: Connection reset by peer)
[19:45:41] *** Joins: gproto23 (~gproto23@user/gproto23)
[19:49:59] <feepbot> <gwern> https://twitter.com/nabeel/status/1457944325816406022 NFTs are assurance contracts implemented acausally by bubbles
[19:50:01] <|dbotdan> Nabeel Hyatt (nabeelo.eth) (@nabeel, 2021-11-09 05:33): ‘Discord naysayers can hate crypto. But speak to artists who do what they love thanks to NFTs, and you change from "how is this broken" to "how do we make it work"  | Web2 reduced the value of a creator's work to begging for likes, Web3 restores it. 🧵 | ’
[20:05:01] <feepbot> <gwern> https://arxiv.org/abs/2111.04007#microsoft
[20:05:02] <feepbot> [2111.04007] Varuna: Scalable, Low-cost Training of Massive Deep Learning Models (Systems for training massive deep learning models (billions of parameters))
[20:07:17] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[20:11:32] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[20:14:30] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[20:14:46] <ggreer> it's neat to see new evidence show up in the rittenhouse trial, but it's odd that they didn't get most of this evidence until a week or so ago. both the prosecution and defense seem a little surprised by the drone footage (both the FBI footage and someone's consumer drone)
[20:14:56] <ggreer> *FBI infrared footage
[20:15:27] <gwern> might just be the huge piles and piles of evidence in discovery. hard to go through everything, especially video
[20:15:36] <two2thehead> hm
[20:16:04] <two2thehead> someone needs to organize all this evidence so I can see what the Feds have in terms of drone capability
[20:17:42] <ggreer> IIRC, the FBI didn't release the highest resolution version of their footage at first. they suddenly "found" it a few days ago
[20:18:05] <ggreer> two2thehead: it's typical FLIR footage. drones are just cheaper to operate than manned helicopters
[20:18:09] <two2thehead> ah
[20:18:14] <two2thehead> ggreer, +1
[20:18:29] <two2thehead> Parallel Construction strikes yet again!
[20:18:32] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[20:19:08] <kiboneu> good morning
[20:19:40] <kiboneu> i have bad short term memory today :( this happens every winter, especially around daylight savings transition
[20:21:26] <ggreer> the aerial footage makes it super obvious that the first shooting was self defense. rittenhouse doesn't fire until rosenbaum is a few feet away
[20:23:31] <rmmh> gwern: you'd think video evidence would be some of the *easiest* to go through
[20:23:39] <rmmh> how many videos of an event would you even have to dig through?
[20:23:52] <ggreer> there were a lot in this case
[20:24:06] <gwern> hard to keyword search
[20:37:21] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[20:52:19] <gwern> https://arxiv.org/abs/2111.03042 I admit, I am amused to see my anime dataset in a paper co-authored by Joshua B. Tenenbaum
[20:52:30] <gwern> it'd be sorta like stephen hawking citing Blueberry Earth
[20:52:30] <feepbot> [2111.03042] Unsupervised Learning of Compositional Energy Concepts (Humans are able to rapidly understand scenes by utilizing concepts extracted)
[20:53:42] <rmmh> what volume more anime-style images do you think have been drawn vs western cartoons
[20:55:35] <gwern> are you including comic books and everything like disney's output?
[20:55:42] <rmmh>  yes
[20:56:07] <gwern> I don't know that anime is bigger. it has a much later start, and japan is much smaller than the west
[20:56:24] <rmmh> imagine summing up every published drawing in comic books and frame in movies, and compare it to the same for anime
[20:56:26] <gwern> keep in mind how many thousands of comics were being pumped out every year even in like 1920
[20:56:59] <rmmh> is there a danbooru for comics, or does american copyright enforcement smash that?
[20:57:03] <gwern> you may never have read krazy kat or little nemo in dreamland or even the action comics superman, but they all existed on regular daily/weekly/monthly schedules
[20:57:41] <gwern> I think anime stuff is way more legible simply because so much of it is new, and anime copyright holders have always had a vastly laxer attitude (by culture and necessity) than, say, disney
[20:57:58] <rmmh> normalization of deviance, eh https://twitter.com/sarahjeong/status/1457902308692353034/photo/1
[20:58:02] <|dbotdan> sarah jeong (@sarahjeong, 2021-11-09 02:46): ‘I think this is the post that explains the most for me, a post that is basically crying out to be shown in court’ Images: https://nitter.pussthecat.org/pic/media%2FFDuCa9yUcAgbpgW.jpg%3Fname%3Dorig (description: a screenshot of a computer; confidence: 0.53)
[20:59:32] <gwern> even uses 'normalizes'
[21:01:03] <pompolic> NoDREAM (normalization of deviance rules everything around me)
[21:01:30] *** Joins: thlnz (~thln@user/thlnz)
[21:06:04] <feepbot> <gwern> https://deepmind.com/research/publications/2021/unsupervised-deep-learning-identifies-semantic-disentanglement-in-single-inferotemporal-face-patch-neurons https://twitter.com/DeepMind/status/1458123234407297026
[21:06:04] <feepbot> Unsupervised deep learning identifies semantic disentanglement in single inferotemporal face patch neurons | DeepMind (To answer the question of how the brain perceives faces, we model neural responses to faces in the macaque inferotemporal (IT) cortex with a deep self-supervised generative model, [snip])
[21:06:07] <|dbotdan> DeepMind (@DeepMind, 2021-11-09 17:24): ‘Can the visual brain learn to represent faces by disentangling?  | Today in @NatureComms, our team finds that novel faces can be reconstructed from as few as 12 neurons, encoding interpretable attributes like eye size or age: http://dpmd.ai/disentanglement 1/’ Images: https://nitter.mailstation.de/pic/media%2FFDxK51QXoAAtT3H.png%3Fname%3Dorig
[21:06:07] <|dbotdan> (description: shape; confidence: 0.98)
[21:08:38] <Obormot\Arcturus> Oh no, Dean Stockwell died
[21:08:42] <two2thehead> hm
[21:08:54] <Obormot\Arcturus> https://en.wikipedia.org/wiki/Dean_Stockwell
[21:09:03] <two2thehead> My kingdom for face recognition ability
[21:09:05] <feepbot> Robert Dean Stockwell (March 5, 1936 – November 7, 2021) was an American film and television actor with a career spanning over 70 years.
[21:11:29] <gwern> I thought for a moment, "Dr Stockwell? he gave me a lot of trouble in that TMNT NES game"
[21:11:51] <two2thehead> lol
[21:12:10] <two2thehead> Proof that intelligence is hereditary :V
[21:17:10] <feepbot> <gwern> https://www.nature.com/articles/s41588-021-00839-6 ehhh
[21:17:11] <feepbot> Ultraconservation of enhancers is not ultranecessary | Nature Genetics (Nature Genetics - Stretches of non-coding DNA that have remained identical across millions of years of evolution are typically assumed to have functional regulatory roles that would be compromised...)
[21:21:38] <two2thehead> kuudes, s0ph1a feep : Behold! A beautiful study that answers my question (can you use sonar to detect ghost fishing nets? Yes) and is well written and has copious amounts of references : https://www.frontiersin.org/articles/10.3389/fmars.2020.505134/full
[21:21:49] <feepbot> Frontiers | How to Deal With Seafloor Marine Litter: An Overview of the State-of-the-Art and Future Perspectives | Marine Science (Marine litter is a significant and growing pollutant in the oceans. In recent years, the number of studies and initiatives trying to assess and tackle the global threat [snip])
[21:26:39] <feepbot> <gwern> https://www.wsj.com/articles/usc-online-social-work-masters-11636435900?page=1 sounds like they basically just target stupid people
[21:26:40] <feepbot> USC Pushed a $115,000 Online Degree. Graduates Got Low Salaries, Huge Debts. - WSJ (The prestigious private university hired a for-profit firm to recruit low-income students to its social-work master’s program. ‘You don’t feel like you’re part of an elite school.’)
[21:30:07] <pompolic> paywalled
[21:30:14] <pompolic> https://archive.fo/Wx7mx archived version here
[21:30:25] <feepbot> archive.fo
[21:35:15] <feepbot> <gwern> 'For height, the prediction accuracy was 47% in a UK Biobank hold-out sample, which was 76% of the estimated SNP-heritability.' https://www.biorxiv.org/content/10.1101/2021.08.12.456099v2.full
[21:35:15] <feepbot> Please Wait... | Cloudflare
[21:47:06] <feepbot> <gwern> uploads https://www.gwern.net/docs/silk-road/2021-bogensperger-2.pdf
[21:52:18] <feepbot> <gwern> 'To demonstrate extreme scale, we also ran a 200 billion parameter model on Varuna, with 100 layers and hidden size of 12960 on 102 GPUs with 102 pipeline stages and no data parallelism. Because of the large layer size, we run this with a micro-batch size of 1 and total batch-size of 512. For this model, Varuna keeps the optimizer state in CPU and performs GPU-CPU transfers
[21:52:18] <feepbot> at the end of mini-batch; the numbers reported include this cost. This ran at 0.022 ex/s/GPU, or 27.3 TFlops/s/GPU.'
[22:02:33] <feepbot> <gwern> https://www.wired.com/story/the-long-search-for-a-computer-that-speaks-your-mind/
[22:02:34] <feepbot> The Long Search for a Brain Computer Interface That Speaks Your Mind | WIRED (The trick is to use data from the brain to synthesize speech in real time so users can practice and the machine can learn. New BCI systems are getting there.)
[22:06:46] *** Quits: mala (~mala@user/malaclyps) (Quit: ZNC 1.6.1 - http://znc.in)
[22:07:32] *** Joins: mala (~mala@user/malaclyps)
[22:07:48] <feepbot> <gwern> https://twitter.com/AmandaAskell/status/1458131477204389891
[22:07:49] <|dbotdan> Amanda Askell (@AmandaAskell, 2021-11-09 17:56): ‘In a room full of blazered people in DC, someone chuckled and said "people from Silicon Valley always dress so casually". I laughed, but inside I thought "this is literally the fanciest outfit I own".’
[22:15:27] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Quit: WeeChat 3.2)
[22:36:21] <two2thehead> https://www.bbc.com/news/world-us-canada-59186655
[22:36:32] <feepbot> Metallurgist admits faking steel test results for US Navy subs - BBC News (A metallurgist has pleaded guilty to fraud after faking the results of strength tests on steel.)
[22:36:35] <two2thehead> "When confronted with the falsified results, Ms Thomas suggested that in some cases she gave metal positive results because she thought it was "stupid" that the Navy required the tests to be conducted at -100F (-70C)"
[22:36:57] <two2thehead> Nice to see USGOV pays and gets its money's worth
[22:37:41] <two2thehead> I'm trying to think of a scenario where a navy ship or boat would encounter -70C temperatures
[22:38:39] <rmmh> arctic
[22:38:52] *** Quits: gproto23 (~gproto23@user/gproto23) (Remote host closed the connection)
[22:39:27] <two2thehead> hmm
[22:40:15] <two2thehead> "Average January temperatures range from about −40 to 0 °C (−40 to 32 °F), and winter temperatures can drop below −50 °C (−58 °F) over large parts of the Arctic. Average July temperatures range from about −10 to 10 °C (14 to 50 °F), with some land areas occasionally exceeding 30 °C (86 °F) in summer."
[22:40:35] <two2thehead> Ah, I see. Margin of error would be a lot in the design
[22:41:02] <gwern> so the water isn't that cold but the air can get cold
[22:41:14] <Obormot\Arcturus> rmmh: Uh, negative 70°C? That's *well* below freezing
[22:41:14] <gwern> which is problematic inasmuch as vessels do not spend 100% of the time submerged
[22:41:29] <two2thehead> makes sense
[22:42:48] <Obormot\Arcturus> I do not think a *ship* is ever going to encounter -70°C
[22:42:57] <Obormot\Arcturus> Temperatures only get that low well inland at the poles
[22:43:01] <gwern> 'Extraordinarily cold weather continues to grip the Antarctic Plateau. Maximiliano Herrera, a climatologist who monitors world weather extremes, tweeted that temperature at Russia’s Vostok Station sunk to minus-110.9 degrees (minus-79.4 Celsius) on Thursday, which was just one degree (0.6 Celsius) from the world’s lowest temperature on record during October. The current temperatures are...
[22:43:07] <gwern> ...still some distance from the coldest ever observed on the continent. In July 1983, Vostok plummeted to minus-129 degrees (minus-89.6 Celsius). Satellites have detected temperatures as low as minus-144 degrees (minus-98 Celsius).' https://www.washingtonpost.com/weather/2021/10/01/south-pole-coldest-winter-record/
[22:43:23] <Obormot\Arcturus> gwern: Right, but look where Vostok Station is.
[22:43:35] <Obormot\Arcturus> Ain't no sub gonna get there!
[22:44:24] <Obormot\Arcturus> The air temperature above actual water, that a ship can travel through, won't ever get that low
[22:45:14] <gwern> subs do visit the other pole which is of more military interest, one imagines. so if you can get that cold not even at the south pole, then the air at the north pole might be that low and a surfaced sub, or a ship, might be in trouble. that's why you test to extremes, not because you expect them to pop up but to ensure no problems ever. sub hulls shouldn't fail because of mere heat
[22:45:29] <two2thehead> gwern, huh. TIL (.__.)?
[22:46:12] <Obormot\Arcturus> gwern: You're missing my point... the relevant feature of Vostok Station isn't how close to the pole it is, it's *how far inland* it is, away from the temperature-moderating influence of the ocean!
[22:46:12] <gwern> (-129F, eh. that must've had interesting effects on their equipment. very few things are ever tested at a temp like that.)
[22:46:42] <gwern> Obormot\Arcturus: I understood it perfectly, and I pointed out that it's a moderate case on a factor where american subs could easily be at an extreme, ie literally at the north pole
[22:47:03] <Obormot\Arcturus> The North Pole is *not* more extreme on that axis than Vostok Station
[22:47:04] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[22:47:08] <Obormot\Arcturus> It's just the opposite
[22:47:25] <gwern> vostok isn't at the south pole. it's quite a ways off
[22:47:34] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[22:47:40] * Obormot\Arcturus facepalm
[22:47:51] <Obormot\Arcturus> On the "distance inland" axis, gwern
[22:48:12] <Obormot\Arcturus> Note that the South Pole is *much* colder than the North Pole
[22:48:25] <Obormot\Arcturus> Precisely because of all that *land* that's present at the former and not the latter
[22:49:08] <Obormot\Arcturus> The South Pole is in double-digit-negative temperatures even in the summer, while at the North Pole during the summer it's only like *just* freezing
[22:49:33] <Obormot\Arcturus> And in their respective winters there's like a 40°F difference
[22:50:32] <Obormot\Arcturus> Look at any list of like "the coldest places in the world"; the North Pole doesn't even come close to cracking the top 10!
[22:50:46] <Obormot\Arcturus> Many places much colder than it, are also much closer to the equator
[22:50:49] *** Joins: gproto23 (~gproto23@user/gproto23)
[22:50:59] <gwern> the north pole also has insulation from the icepacks. I don't know that this excludes the extremes, and as I said, it's possible for a vessel to go a lot closer to one pole than the other. 40 degrees is not that much for extremes variation, and this is assuming no safety factors, which there are supposed to be. who's this metallurgist going 'well Imma just going to endanger these multibillion...
[22:51:05] <gwern> ...dollar boomers because I'm lazy and anyway the o-rings haven't actually burned through so why are you whining'
[22:52:17] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[22:52:56] <Obormot\Arcturus> There's no way that any sub is going to get to any place that's colder than Vostok, that's what I am saying
[22:53:02] <Obormot\Arcturus> Or even as cold
[22:53:09] <Obormot\Arcturus> The North Pole doesn't come close
[22:53:23] <Obormot\Arcturus> You need a landmass to get temperatures that cold on Earth
[22:53:39] <Obormot\Arcturus> And it can be much closer to the equator, too
[22:56:01] <saturn2> https://nitter.net/Meta/status/1456269728687689738 ?????
[22:56:15] <feepbot> Meta (@Meta): "Enter a world of imagination with Meta and explore endless possibilities in 3D. 🚀 🎨
[22:58:51] <rmmh> Quill video probably
[23:02:16] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[23:03:52] <feepbot> <gwern> 'The second is that it uses the upvotes and downvotes to generate a kind of map of all the participants in the debate, clustering together people who have voted similarly. Although there may be hundreds or thousands of separate comments, like-minded groups rapidly emerge in this voting map, showing where there are divides and where there is consensus. People then naturally
[23:03:52] <feepbot> try to draft comments that will win votes from both sides of a divide, gradually eliminating the gaps. “The visualization is very, very helpful,” Tang says. “If you show people the face of the crowd, and if you take away the reply button, then people stop wasting time on the divisive statements.”...Within a few days, the voting had coalesced to define two groups, one
[23:03:52] <feepbot> pro-Uber and one, about twice as large, anti-Uber. But then the magic happened: as the groups sought to attract more supporters, their members started posting comments on matters that everyone could agree were important, such as rider safety and liability insurance. Gradually, they refined them to garner more votes. The end result was a set of seven comments that enjoyed almost
[23:03:57] <feepbot> universal approval, containing such recommendations as “The government should set up a fair regulatory regime,” “Private passenger vehicles should be registered,” and “It should be permissible for a for-hire driver to join multiple fleets and platforms.” The divide between proand anti-Uber camps had been replaced by consensus on how to create a level playing field for
[23:03:57] <feepbot> Uber and the taxi firms, protect consumers, and create more competition. Tang herself took those suggestions into face-to-face talks with Uber, the taxi drivers, and experts, which led the government to adopt new regulations along the lines vTaiwan had produced.' https://www.technologyreview.com/2018/08/21/240284/the-simple-but-ingenious-system-taiwan-uses-to-crowdsource-its-laws/
[23:03:57] <feepbot> this is interesting: extracting clusters, specifically to try to incentivize people to find new niches in between clusters
[23:03:57] <feepbot> The simple but ingenious system Taiwan uses to crowdsource its laws | MIT Technology Review (vTaiwan is a promising experiment in participatory governance. But politics is blocking it from getting greater traction.)
[23:05:07] <gwern> UMAP/PCA on votes
[23:05:23] *** Quits: Urchin[emacs] (~user@user/urchin) (Ping timeout: 256 seconds)
[23:05:40] *** Joins: Urchin[emacs] (~user@user/urchin)
[23:05:57] <adiabatic> what and principal-component analysis?
[23:07:16] <ggreer> "Another group of latino americans arrived in the parking lot with melee weapons, telling us that they could watch that location for us for that night." 🇺🇸 🦅
[23:07:25] <gwern> ~umappu~ https://arxiv.org/abs/1802.03426
[23:07:37] <adiabatic> danke
[23:07:37] <feepbot> [1802.03426] UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction (UMAP (Uniform Manifold Approximation and Projection) is a novel manifold)
[23:07:46] <ggreer> it's like the warriors movie except all the gangs are working together to stop riots
[23:12:47] <feepbot> <gwern> https://blog.xkcd.com/2008/01/14/robot9000-and-xkcd-signal-attacking-noise-in-chat/
[23:12:47] <feepbot> ROBOT9000 and #xkcd-signal: Attacking Noise in Chat – xkcd (Edit 2: Oh God Oh God 4chan has Robot9000. soup /r9k/. Have fun with the bot and do one last barrel roll for me. Edit: As expected, with the huge flood of new traffic after this post went up, the c…)
[23:17:32] *** Joins: soapes_ (~soapes@46-126-108-131.dynamic.hispeed.ch)
[23:18:46] *** Quits: soapes (~soapes@46-126-108-131.dynamic.hispeed.ch) (Ping timeout: 260 seconds)
[23:21:26] *** Joins: grandrew_ (~grandrew@c-73-71-100-231.hsd1.ca.comcast.net)
[23:21:30] *** Joins: gproto23_ (~gproto23@user/gproto23)
[23:21:56] *** Joins: Obormot_\Arcturu (~obormot@user/obormot)
[23:23:05] *** Quits: Urchin[emacs] (~user@user/urchin) (Killed (NickServ (GHOST command used by Urchin[emacs]`)))
[23:23:10] *** Joins: kaizen__ (sid60510@id-60510.tinside.irccloud.com)
[23:23:10] *** Joins: dove_ (~jordan@li1158-85.members.linode.com)
[23:23:16] *** Joins: cyberjunkie_ (~cyberjunk@wireguard/tunneler/cyberjunkie)
[23:23:17] *** Joins: malaclyps (~mala@user/malaclyps)
[23:25:26] *** Joins: otoburb_ (~otoburb@user/otoburb)
[23:25:28] *** Joins: edf0_ (edef@panther.nathan7.eu)
[23:25:45] *** Joins: aweinsto1k (~aweinstoc@cpe-67-248-65-250.nycap.res.rr.com)
[23:25:49] *** Joins: brand0x (~brandon@user/brand0)
[23:26:18] *** Joins: quanticle_ (~quanticle@user/quanticle)
[23:30:25] <ggreer> according to the current witness (a former car source employee), the owners offered to pay him and his buddies (including rittenhouse) several hundred dollars to protect their property
[23:30:28] *** Joins: rmmh_ (~none@user/rmmh)
[23:30:46] *** Quits: gproto23 (~gproto23@user/gproto23) (*.net *.split)
[23:30:46] *** Quits: mala (~mala@user/malaclyps) (*.net *.split)
[23:30:46] *** Quits: Obormot\Arcturus (~obormot@user/obormot) (*.net *.split)
[23:30:46] *** Quits: grandrew (~grandrew@c-73-71-100-231.hsd1.ca.comcast.net) (*.net *.split)
[23:30:46] *** Quits: rmmh (~none@user/rmmh) (*.net *.split)
[23:30:46] *** Quits: otoburb (~otoburb@user/otoburb) (*.net *.split)
[23:30:46] *** Quits: edf0 (edef@panther.nathan7.eu) (*.net *.split)
[23:30:46] *** Quits: kaizen_ (sid60510@tinside.irccloud.com) (*.net *.split)
[23:30:46] *** Quits: cyberjunkie (~cyberjunk@wireguard/tunneler/cyberjunkie) (*.net *.split)
[23:30:46] *** Quits: koolazer (~koo@user/koolazer) (*.net *.split)
[23:30:47] *** Quits: aweinstock (~aweinstoc@cpe-67-248-65-250.nycap.res.rr.com) (*.net *.split)
[23:30:47] *** Quits: dove (~jordan@li1158-85.members.linode.com) (*.net *.split)
[23:30:47] *** Quits: brand0 (~brandon@user/brand0) (*.net *.split)
[23:30:47] *** Quits: quanticle (~quanticle@user/quanticle) (*.net *.split)
[23:30:47] *** kaizen__ is now known as kaizen_
[23:32:02] *** aweinsto1k is now known as aweinstock
[23:34:31] <two2thehead> kuudes, s0ph1a feep : The fact that www.mp3tag.de is being updated is inspiring to me
[23:37:15] *** Joins: koolazer (~koo@user/koolazer)
[23:39:22] *** otoburb_ is now known as otoburb
[23:40:07] <dv^_^> "Someone who knows your password is attempting to sign-in to your account." Yeah. Me.
[23:50:15] <RiversHaveWings> gwern: interpolation https://usercontent.irccloud-cdn.com/file/njafQTcr/image.png
[23:52:46] <RiversHaveWings> also, vostok is so cold bc of its elevation too
[23:53:04] <RiversHaveWings> it is 11,444 ft above sea level
[23:59:18] *** rmmh_ is now known as rmmh
