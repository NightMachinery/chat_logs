[00:22:33] *** Quits: kevingal (~quassel@2001:770:c0:401:2d47:2f9b:c1be:64a0) (Remote host closed the connection)
[00:34:13] <hayley> https://www.youtube.com/watch?v=kngX1Ojb1PM
[00:34:14] -ixelp- 1969-06-26 Pink Floyd - The End Of The Beginning - Royal Albert Hall, Kensington, London, England - YouTube
[00:34:16] <hayley> Good morning everyone!
[00:38:28] *** Quits: aeth (~aeth@user/aeth) (Ping timeout: 265 seconds)
[00:39:55] *** Joins: aeth (~aeth@user/aeth)
[00:53:23] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:f0cf:5664:8ee5:8e87) (Ping timeout: 250 seconds)
[01:14:19] <sham1> Good evening
[01:36:22] *** Quits: shka (~herr@109.231.0.226) (Ping timeout: 260 seconds)
[01:43:56] *** selwynning is now known as selwyn
[01:48:41] <hayley> https://www.youtube.com/watch?v=AUZtEQ_IFDs
[01:48:42] -ixelp- Regret (2015 Remaster) - YouTube
[02:24:53] *** Quits: djuber (~user@65.79.128.64) (Ping timeout: 256 seconds)
[02:36:05] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 250 seconds)
[02:40:43] * hayley asked Richard Jones about concurrent weak reference processing, and he thinks it is unnecessary unless you are going hard real time.
[03:05:18] <kakuhen> i got my commutative algebra grade today; i somehow passed the clas
[03:05:25] <kakuhen> class*; it was the hardest math class i've taken yet
[03:05:32] <ck_> you mean the class passed you, surely
[03:06:19] <hayley> 🎉
[03:07:10] <kakuhen> now i get to choose between 9am algebraic geometry class or 2pm homological algebra class
[03:07:20] <kakuhen> two-edged sword
[03:08:58] <hayley> https://www.youtube.com/watch?v=Nf27pL6SnrI
[03:08:58] -ixelp- Mr. Jones - YouTube
[03:12:08] <selwyn> hardest course i ever took was black holes
[03:12:30] <selwyn> congratulations on passing
[03:27:45] <hayley> https://github.com/sponsors/no-defun-allowed is a thing now.
[03:27:45] -ixelp- Sponsor @no-defun-allowed on GitHub Sponsors · GitHub
[03:28:32] <selwyn> i would sponsor but theré doesn't seem to be an option to accept reddit gold
[03:28:52] <hayley> lol
[03:29:34] * hayley sets a goal of $1/month
[03:29:49] <moon-child> '$5 a month: Get a Sponsor badge on your profile'  what if that embarrasses me?  May I pay extra to get rid of the badge?
[03:30:14] <selwyn> be arrogant, set a higher goal
[03:30:27] <hayley> moon-child: $420/month
[03:30:27] <selwyn> imo people undersell themselves with this sort of thing
[03:31:19] <hayley> IMO I can't take it seriously. I'd like to hack for free, since at the least I can do whatever and not annoy people with it, but that is infeasible since things cost money.
[03:35:09] <selwyn> perhaps i can be sponsored, if i ever develop anything
[03:35:32] <Alfr> kakuhen, do both?
[03:35:38] <hayley> selwyn: https://youtu.be/Gh0bczrw4NU?t=536
[03:35:39] -ixelp- [Vinesauce] Joel - Windows 10 Destruction - YouTube
[03:35:42] <moon-child> selwyn: best I can do is a full case of unfinished projects
[03:36:50] <kakuhen> Alfr: i don't want to
[03:36:51] <Alfr> kakuhen, or take homological algebra, and algebraic topology later; if the AT course follows Hatcher then it degenerates quite quickly into diagram chasing.
[03:37:14] <selwyn> http://www.savewalterwhite.com/
[03:37:15] -ixelp- Save Walter White
[03:37:17] <kakuhen> im still an undergrad and i've heard horror stories of taking too many grad classes at one
[03:37:22] <kakuhen> once*
[03:38:08] <hayley> BTW there is also a 1 bus fare option which I guess is less than $5
[03:38:56] <hayley> walter whit I require methe
[03:39:30] <ck_> that's still up? nice
[03:39:49] <selwyn> i hope walter white gets better
[03:40:09] <hayley> https://www.youtube.com/watch?v=YZ9WfnvcX5Y
[03:40:10] -ixelp- breaking good episode 1 - YouTube
[03:41:40] <ck_> me too. I mean there are so many options -- for example, supposing you brought the light inside the body, which you can do either through the skin or in some other way.
[03:41:55] <ck_> We'll see, but the whole concept of the light, the way it kills it in one minute - that's pretty powerful
[04:10:53] *** Quits: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 252 seconds)
[04:11:10] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:297c:42b:53ca:ec88)
[04:12:06] *** Joins: notzmv (~zmv@user/notzmv)
[04:17:54] *** Quits: random-nick (~random-ni@87.116.181.93) (Ping timeout: 265 seconds)
[04:43:22] <hayley> https://www.youtube.com/watch?v=_tHIieA7TBc
[04:43:23] -ixelp- We Have A Technical (Remastered) - YouTube
[04:48:32] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:297c:42b:53ca:ec88) (Ping timeout: 240 seconds)
[05:02:53] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:80ee:faa6:7302:e610)
[05:24:56] <hayley> I just beat my sponsorship goal by 500%
[05:45:38] <moon-child> congratulations!
[06:06:39] * hayley guesses stylewarning wants a lexer. Isn't gilberth supposed to make that?
[06:10:12] <hayley> *5000% now
[06:52:44] <hayley> gilberth: Eyeballing https://github.com/quil-lang/quilc/blob/master/src/parser.lisp#L111-L185 I'm convinced the only use of lookahead is just to AND two grammars together (for the float rule).
[06:52:44] -ixelp- quilc/parser.lisp at master · quil-lang/quilc · GitHub
[06:59:48] <hayley> https://www.youtube.com/watch?v=k3ApcNOAUPM
[06:59:48] -ixelp- portal 2 in a nutshell - YouTube
[07:19:20] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[07:21:17] <dave0> maw
[07:24:25] <hayley> maw
[07:25:57] <dave0> hi hayley 
[07:39:13] <dave0> how are you?
[07:39:53] <dave0> coffee was half price at the store so i got some
[07:58:28] <hayley> Fine, just got back from shopping.
[07:58:34] * hayley got 60 small spring rolls for $7
[07:58:58] <dave0> ~10 cents each, nice!
[08:01:17] * moon-child too
[08:01:22] <moon-child> I got cheese
[08:03:24] <hayley> https://www.youtube.com/watch?v=AwZl_DYSvdo
[08:03:25] -ixelp- Gary Numan - We Take Mystery (Early Version) - YouTube
[08:03:37] *** Quits: semz (~none@user/semz) (Ping timeout: 265 seconds)
[08:04:54] <dave0> i learned that macaroni is merely a cheese delivery system :-p
[08:15:56] *** Joins: semz (~none@user/semz)
[08:46:31] *** Quits: Catie (~user@user/catie) (Quit: sQuit)
[08:57:15] <moon-child> 'based on term rewriting (I think it’s just implemented using regular expressions)'
[08:57:20] <moon-child> some term rewriter
[08:58:17] * hayley wants to complain
[09:53:42] *** Joins: treflip (~user@95.79.32.99)
[10:33:02] <mfiano> Anyone experienced with using libc termcap routines? The manual is pretty convoluted when I just want to do one simple thing.
[10:36:02] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 240 seconds)
[10:55:09] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[10:56:46] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[11:15:30] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 265 seconds)
[11:20:14] *** Quits: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de) (Quit: Leaving)
[11:26:57] *** Joins: shka (~herr@109.231.0.226)
[11:34:29] <gilberth> Apropos "fearless" multi-threading. As Rust forces you to lock mutexes all the time and the mutexes are not recursive, you have unexpected trouble when you just lock sth to take a peek at its nature and then want to dispatch recursively. The lock is still held by the caller, although you don't need it at all. I just had a "dead" lock this way, where I wasn't expecting one.
[11:35:05] <shka> well, unlike hayley i don't hate rust
[11:35:08] <shka> but i must admit
[11:35:22] <shka> community there is full of shit
[11:35:45] <hayley> https://www.youtube.com/watch?v=8TEAMHgrxi0
[11:35:46] -ixelp- JJ Burnel - Crabs - YouTube
[11:35:52] <gilberth> The root cause is that an unlock does happen at the next close brace bracket, not when an expression would be done. Say foo(x.lock().unwrap()) within a { } block and the lock is held until you exit the block and not until you're done with foo().
[11:36:24] <hayley> Sadly I might know what you're supposed to do.
[11:36:29] <gilberth> Rust is an April's fools day prank. A bad one.
[11:36:52] <hayley> { let y = x.lock(); let z = foo(y.unwrap()); drop(y); z }
[11:37:23] <gilberth> hayley: Yes, milady. I need to manage all of that manually.
[11:37:31] <hayley> gilberth: Better or worse than the They Live sunglasses manufactured by Applied Language in April 2020?
[11:37:35] *** Quits: Alfr (~Alfr@user/alfr) (Killed (molybdenum.libera.chat (Nickname regained by services)))
[11:37:39] *** Joins: Alfr (~Alfr@user/alfr)
[11:38:16] <gilberth> hayley: Sunglasses? I don't need sunglasses I sleep while the sun is up.
[11:38:47] <hayley> gilberth: Remember the ones that I demoed on matrix.org and parast.at? And you mentioned that my clock was in the background.
[11:38:50] <gilberth> I believe my immune system is busy with the vaccine. Good.
[11:39:38] <gilberth> hayley: I am afraid, I have no clue what you are talking about. Do I suffer from Alzheimer? This soon?
[11:40:01] <hayley> https://www.youtube.com/watch?v=060D_zM9PJI
[11:40:01] -ixelp- GO FK YOURSELF (actual mod lmao) - YouTube
[11:40:07] <hayley> Well, it was 1.5 years ago.
[11:40:42] <gilberth> Which is not too long ago.
[11:42:43] <kakuhen> hayley: now i want to play hl2
[11:43:16] <gilberth> So for every .lock() forced upon me, I need to think about where to .drop() it. Terrific.
[11:44:16] <moon-child> WITH-LOCK-HELD when
[11:45:05] <gilberth> It's like with-lock-held all over the place. With the scope being wherever you put braces.
[11:46:15] <gilberth> It would be fine when foo(x.lock().unwrap()) == (foo (with-lock-held ..)) which it is not. The with-lock-held is around your current block, what ever that might be.
[11:47:47] <gilberth> This is most silly and a guarantee for unexpected disaster.
[11:48:57] *** Quits: treflip (~user@95.79.32.99) (Remote host closed the connection)
[11:49:44] <gilberth> Those "destructors" should not be implicit. In CL we always have a WITH-FOO construct and not the clean-up inserted whereever the compile sees fit.
[11:50:44] *** Joins: treflip (~user@95.79.32.99)
[11:52:54] <shka> gilberth: well, objects live within the lexical scope, so it is pretty understandable actually
[11:54:37] <gilberth> Is it? I create those in the middle of an expression.
[11:59:58] <shka> yeah, and they will exist as long as variable exists
[12:00:04] <shka> so it is not terrible
[12:00:20] <shka> but it gets time to used to it
[12:01:24] <gilberth> shka: I am not talking about a variable, but about a sub-expression. No variable there.
[12:04:29] <gilberth> shka: How to fix this? <http://clim.rocks/gilbert/tyi-trouble.rs.txt> idk
[12:06:09] <gilberth> Also error() is a function dropping you into a break loop and all locks must be released there too.
[12:07:22] <gilberth> The lock is needed for reading per see. And in this case actually useful for lookahead.
[12:07:39] <hayley> Can't afford a recursive lock?
[12:07:48] <gilberth> Reading the variant type of that node.
[12:08:01] <gilberth> hayley: This won't fix the problem.
[12:08:49] <gilberth> As I don't want to hold a lock on a random stream, just because I am in the debugger. I wanted to do the damn match.
[12:10:18] <gilberth> And: drop(x.clone()) doesn't work for some reason. I don't know why.
[12:12:13] <gilberth> I came up with <http://clim.rocks/gilbert/tyi-dance.rs.txt> I'm still a noob, there sure is a better way.
[12:12:54] <gilberth> Anyhow my point was that this was a surprising behavior, I didn't expect at all.
[12:14:13] <gilberth> And it was not me wanting to actually lock the object, but Rust. All I wanted was to see an un-teared version.
[12:14:58] <gilberth> So why isn't it foo.atomic_read() without holding the lock for the whole damn function.
[12:15:19] <moon-child> is that READ-CHAR?  PEEK-CHAR?  I can't tell behind all of the  match clone().lock().unwrap()
[12:15:46] <gilberth> moon-child: That is old school TYI which is (read-char stream nil nil).
[12:16:16] <moon-child> what does tyi stand for?
[12:16:30] <gilberth> TYpe In?
[12:16:43] <gilberth> flush() is FORCE-OUTPUT
[12:17:19] <gilberth> There also is TYO TYpe Out. These is how Maclisp calls the primitives.
[12:17:45] * moon-child nods
[12:19:42] <gilberth> Anyhow, I redesign and have every lisp object be an Arc<Mutex<T>> to see if that would be faster.
[12:20:31] <gilberth> This will give me boxed numbers though. But EQ should be way faster.
[12:23:17] <gilberth> I don't know why I continue doing this. Rust is just a very bad fit for working with DAGs, yet behold cyclic ones.
[12:24:12] <Alfr> cyclic DAGs? That's a strange one.
[12:24:35] <gilberth> Indeed. ;)
[12:25:14] <gilberth> "globally directed"? Anyone?
[12:36:15] <shka> gilberth: add another {} 
[12:36:21] <shka> explicit scope 
[12:45:15] <gilberth> shka: Around where?
[12:45:57] *** Joins: notzmv (~zmv@user/notzmv)
[12:45:58] <mfiano> I think I might need gilberth's help here
[12:46:42] <gilberth> mfiano: Do I need a fresh cup of coffee for that?
[12:46:58] <mfiano> ansi color escape sequences
[12:47:18] <gilberth> Ok. Go ahead.
[12:47:22] <moon-child> mfiano: do not bother with termcap
[12:47:38] <mfiano> https://i.lisp.cl/hQwTsT.png
[12:47:50] <mfiano> I am curious why printf works and my program doesn't
[12:48:22] <moon-child> what is your program?
[12:48:50] <mfiano> The second 2 invocations
[12:49:02] <moon-child> I mean, what is the code to your program
[12:49:13] <moon-child> e.g. this prints in green for me: (format t "~c[32mhelloooo~c[0m" #\Esc #\Esc
[12:49:25] <moon-child> )
[12:49:26] <mfiano> (princ "^[[31m") followed by some format string
[12:49:52] <moon-child> ^[ is a caret followed by an open bracket?  Or a literal escape character in your source code?
[12:49:57] <gilberth> Is that a verbatim ESC character there?
[12:50:03] <mfiano> It should be...
[12:50:17] <moon-child> what happens if you change to using format "~c" #\Esc?
[12:50:39] <gilberth> I always fo (format "~A[....." #\escape) I don't like control characters in my code.
[12:50:50] <gilberth> moon-child: You were faster.
[12:51:14] <mfiano> Ah that works. maybe my control code got reformatted on save? i dunno
[12:51:27] <mfiano> i have to check the bytes
[12:51:27] <moon-child> probably
[12:51:32] <moon-child> https://0x0.st/-F5V.lisp does this work?
[12:52:51] <mfiano> I'm sure it does looking at the codes.
[12:53:07] <mfiano> Makes me wonder why 38 is missing, and 39 is reset color.
[12:53:29] <mfiano> 30-37, 39=reset color, 0=reset style
[12:53:37] <mfiano> where did 38 go?
[12:59:07] *** Quits: treflip (~user@95.79.32.99) (Read error: Connection reset by peer)
[13:05:14] <shka> gilberth: yeah, good point
[13:05:53] <gilberth> shka: ? I didn't say anything.
[13:06:07] <shka> gilberth: "around where?"
[13:06:49] <gilberth> That was a serious question. I am still a Rust noob.
[13:10:46] <shka> gilberth: yeah, this is exactly the same problem in C++
[13:14:19] <gilberth> Way smaller example: <http://clim.rocks/gilbert/buggy-car.rs.txt>
[13:22:21] <hayley> "This is exactly the reason why I am still using C. Garbage collector and proactive optimization crap."
[13:22:23] <gilberth> It is kind of reasonable what happens here. My point just is: It's evil.
[13:22:42] <hayley> This person has posted cringe, they are going to https://www.youtube.com/watch?v=PcsumKaIXEs
[13:22:43] -ixelp- Gary Numan (London 1981) [07]. The Aircrash Bureau - YouTube
[13:22:49] *** Joins: treflip (~user@95.79.32.99)
[13:23:29] <hayley> How weird, there's another one saying the same thing but C++.
[13:23:43] * hayley uploaded an image: (33KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/EONlxvNXOXrOEolvUQXykCLo/Screenshot%20from%202021-12-15%2020-53-34.png >
[13:24:21] * hayley gets to bully C weenies, C++ weenies, and Rustaceans in one comments section? Excellent value!
[13:26:15] *** Quits: pjb (~pjb@user/pjb) (Remote host closed the connection)
[13:29:48] <dave0> i'm a c weenie :-(
[13:31:13] <gilberth> Here is my fix: <http://clim.rocks/gilbert/fixed-car.rs.txt> And I don't like it at all. It covers up too much evidence.
[13:32:00] <gilberth> dave0: C is ok. (For a PDP-11.)
[13:35:46] <dave0> :-)
[13:36:02] <gilberth> Frankly I like C. You just have to take it as it is: A thin layer above assembler. And you need to be very careful with it.
[13:36:10] <hayley> "Of course, you can always do 'apply' of 'compile' of consed stuff instead of 'eval'. This 'JIT' compilation solves the speed problem. (You _do_ have a builtin compiler, don't you?)" — Henry Baker
[13:36:23] <hayley> Ah, yes, the assembler with no LOGCOUNT
[13:36:52] <gilberth> Heh, has the PDP-11 a LOGCOUNT instruction?
[13:37:13] <moon-child> gilberth: the problems with that are two
[13:37:19] <moon-child> first: why do you need such a layer?
[13:37:33] <moon-child> second: there are some simple, obvious problems with that layer
[13:37:41] <gilberth> Which layer?
[13:37:48] <moon-child> c
[13:37:51] <moon-child> as a layer above assembly
[13:38:33] <gilberth> You'd rather hack in assembly itself?
[13:39:20] <moon-child> in inner loops, I may have to.  Otherwise, why can I not use a nice language?
[13:39:34] <moon-child> if you need something without gc for a microcontroller, why not go with, say forth?
[13:40:25] <gilberth> I would prefer CL everyday no questions asked. But when you face bare metal with just 16k of RAM, C would be the right tool.
[13:40:34] * hayley would just GC on the microcode.
[13:40:40] <hayley> s/microcode/microcontroller
[13:40:57] <moon-child> with 16k of ram?
[13:41:26] * pl considers the NES game written using CL
[13:41:54] <moon-child> ooh, that sounds fun; link?
[13:42:08] <hayley> How many words does an IBM 704 have?
[13:42:29] <gilberth> moon-child: For some reason, I would still prefer C over Forth.
[13:44:43] <sham1> FORTH is lower abstraction level than C in many ways, although in some ways it's higher
[13:44:47] <gilberth> hayley: Well, I doubt my embedded applications would fit on an IBM 704 with LISP. Only because you barely manage to run a LISP, does not imply you could run full applications there.
[13:44:57] <hayley> 'Bastard Sex Therapist from Hell: "Read the F*cking Manual!"' - Erik Naggum
[13:45:23] <hayley> gilberth: You could buy an RP2040 chip for not a lot of money, and have more RAM than a Xerox Alto. 
[13:45:38] <sham1> Also, fitting stuff into 8K or 16K really depends on how much data you can put into program memory
[13:45:49] <sham1> You of course want to leave as much space in the RAM as possible
[13:46:06] <gilberth> hayley: For like EUR 3.00 a piece in 2004? I doubt it.
[13:46:31] <hayley> $1.52 AUD with tax in 2021.
[13:46:47] <hayley> Basically €1 by my calculations.
[13:47:02] <gilberth> sham1: Correct. My Flash ROM was like 128k or so.
[13:47:24] <gilberth> hayley: And in 2004?
[13:49:28] <hayley> idk, do I look like I was doing embedded design in 2004?
[13:49:46] <gilberth> Do I know how you look?
[13:50:17] <hayley> By my poor recollection of things I got a crappy clamshell MacBook for my birthday in 2004.
[13:51:15] <shka> pl: you are aware of story lisp and nintendo had together?
[13:51:22] <shka> even zetalisp
[13:51:57] <gilberth> And when you application must not crash and be repsonsive within milliseconds all the time, and because there just is nobody there who would power-cycle, you take a different perspective.
[13:51:59] <sham1> I thought that the only notable developer with a Lisp story was Naughty Dog and GOAL
[13:52:42] <Duuqnd> The only connection between Nintendo and Lisp I know of is that they used to use 3D modelling software written in CL
[13:53:03] <sham1> Games developer
[13:53:20] <shka> Duuqnd: also, they had compilers written in lisp
[13:53:30] <gilberth> hayley: And btw, why did they build the Lisp Machine, again?
[13:53:35] <hayley> IIRC even the stop-the-world MicroPython GC can collect the "official" microcontroller's heap in 5ms or so.
[13:53:49] <hayley> gilberth: Ran out of RAM, wanted to compress programs into bytecode.
[13:54:15] <gilberth> Yep, so 2^18 words where too tight.
[13:54:41] <hayley> Now, it is 2021, and gilberth is not a rustacean, and even better, he lives in #lispcafe, so he has surely heard of on-the-fly collection and/or Baker's incremental semispace collector.
[13:55:08] <gilberth> hayley: Well I have an interrupt routine running at 32kHz. But perhaps that could be isolated. There was just not enough RAM for a Lisp.
[13:55:21] <shka> https://www.youtube.com/watch?v=AUEIgfj9koc
[13:55:21] -ixelp- Andrew Sengul: April, an APL compiler for Common Lisp - YouTube
[13:55:53] <shka> another powerful, bald lisper
[13:56:09] <gilberth> Would I have like 256kB or more, I would perhaps implement the high-level application logic in a Lisp.
[13:56:15] <sham1> Well some MCUs are probably just impossible to run any sort of lisp stuff on. For example: https://www.st.com/en/microcontrollers-microprocessors/stm8s-value-line.html although I'd like to see someone try
[13:56:26] <hayley> phantomics: "another powerful, bald lisper" — shka
[13:56:52] <shka> hayley: i mean, there is a pattern here! :D
[13:58:05] <Duuqnd> Things that apparently make programmers more powerful: Baldness, beards, socks
[13:58:23] * hayley uploaded an image: (145KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/KDaViPcFDlLSiRfpnbMhfuVW/siclos.png >
[14:00:19] <gilberth> Well, MCUs get cheaper and larger. In 2003 as I started 32-bit was still not wide spread. And at EUR 7.00 a piece our MCU was very expensive, but 32-bit. Which is a major leap from 8-bit MCUs with funny address spaces. I don't regret that early move to an expensive MCU for more productivity.
[14:00:50] <shka> https://www.youtube.com/watch?v=8X69_42Mj-g
[14:00:51] -ixelp- Clasp: Common Lisp using LLVM and C++ for Molecular Metaprogramming - YouTube
[14:01:00] <shka> maybe that's the secret
[14:01:23] <shka> if you want to make compiler somehow adjacent to lisp 
[14:01:32] <shka> you gotta sacrifice your hair
[14:01:38] <gilberth> But: It depends on your margins and volume. We were pretty low value with like 10k devices sold a year.
[14:01:45] <sham1> Oh no, not my hair :(
[14:01:49] <hayley> shka: Wrong, I haven't had a haircut for 3 years now.
[14:01:50] <moon-child> gilberth: 32khz?  That is quite a lot
[14:02:07] <phantomics> shka: you're the second person to make that comparison
[14:02:10] <shka> hayley: so maybe that's the key to faster regexs? :D
[14:02:11] <phantomics> I think phoe was the first
[14:02:22] <gilberth> moon-child: Yes, I manage a 4-way PCM bus and do DSP while doing so.
[14:02:38] <shka> phantomics: and don't let me start on beach :P
[14:02:47] <hayley> How is gilberth's hair?
[14:03:02] <phantomics> Never seen what he looks like
[14:03:07] <hayley> BurntSushi has pretty short hair, no wonder his RE engine is crap.
[14:03:16] <shka> phantomics: also completely bald :D
[14:03:35] <moon-child> hmm, then probably no haircut in a while
[14:03:46] * gilberth has pretty long hair. That's my Corona cut.
[14:03:53] * moon-child has not had a haircut in probably upwards of five years
[14:04:01] <shka> can't be a bald goth
[14:04:02] <moon-child> logically, my regex engine should trounce all of yours
[14:04:27] * moon-child gazes into the mirror, and finds his reflection pointing and cursing at text
[14:05:45] <shka> phantomics: i just find this funny, no offense 
[14:05:49] <shka> the compiler monks
[14:05:51] <sham1> You underestimate my power
[14:05:53] <phantomics> none taken
[14:06:45] <phantomics> Vector language compilation is a gateway to many abilities some consider... unnatural
[14:07:15] <sham1> Is it possible to learn this power?
[14:07:21] <shka> i usually quote this line for lisp 
[14:07:26] <phantomics> Not in a cube farm
[14:07:36] <hayley> lol compiling map-reduce
[14:07:39] <shka> "how do you change-class of an object"?
[14:07:41] <moon-child> phantomics: I still want to do apl jit since hayley linked that one paper
[14:07:42] <Duuqnd> Abelson and Sussman have (and had) pretty minimal hair too, right?
[14:08:08] <hayley> phantomics: do u even PMOVMSKB
[14:08:13] <moon-child> i bet you could do a lot of things much faster than with an interpreter or a static compilation strategy
[14:08:13] <shka> ok, so need to design a language? gotta have a beard 
[14:08:33] <shka> and for compiler you will need a shaved head
[14:08:49] <shka> perfectly balanced
[14:08:52] <phantomics> hmm
[14:08:55] <Duuqnd> What are the socks needed for then?
[14:09:08] <shka> Duuqnd: to be comfy 
[14:09:17] <sham1> To keep the feet warm
[14:10:16] * moon-child wore boring socks today; perhaps that is why he got nothing done
[14:10:23] <shka> yup, can't do hacking with a cold feet
[14:11:48] * hayley doesn't wear socks when possible.
[14:12:06] <shka> australia is like that
[14:12:37] * shka is sitting here wearing winter shirt and a sweater
[14:13:24] <shka> but temperature outside is above the 0
[14:14:37] *** Joins: kevingal (~quassel@2a02:8084:4140:f300:6c5b:ab76:207a:5858)
[14:18:45] <phantomics> moon-child: what paper was that?
[14:19:30] <moon-child> i don't remember ask hayley
[14:19:40] <phantomics> I've thought about ways to extend April to build an interpreter, could potentially be pretty simple
[14:19:47] <hayley> http://www.softwarepreservation.org/projects/apl/Papers/DYNAMICINCREMENTAL
[14:19:49] <moon-child> basically they had an inline cache for name classes, shapes, and data types
[14:20:03] <phantomics> thanks hayley
[14:20:25] <moon-child> they also described--I forget; it was either laziness, or fusing of operations
[14:20:30] <moon-child> whichever it was, I want both
[14:20:47] <phantomics> someone in an APL chat was saying "APL compilers are nice but interpreters are better because you can do iterative development with a REPL"
[14:20:53] <moon-child> lul
[14:21:44] <phantomics> Laziness is something I've been thinking about, I already have optimization patterns that fuse operations: https://github.com/phantomics/april/blob/function-variable-scoping-change/patterns.lisp
[14:21:44] -ixelp- april/patterns.lisp at function-variable-scoping-change · phantomics/april · GitHub
[14:22:06] * moon-child nods
[14:22:42] <moon-child> problem I foresee with laziness is you start reading from the beginning of an array but switch to a different datatype partway through
[14:22:47] <moon-child> but it is attractive as it is more general than fusing
[14:22:53] <phantomics> I was thinking in terms of having operations return functions instead of values, leveraging first-class functions
[14:23:39] <hayley> Petalisp returns a data flow graph, which is then lowered to IR by PETALISP:COMPUTE, last I checked.
[14:23:42] <phantomics> Those functions would basically pick up parameters from successive operations until a condition arose where they had to return a value, or when their output was to be given to the process calling April
[14:24:12] <moon-child> oh.  Maybe we were thinking of different things.  My thought was that when you say something like '1+2×x' (and for some reason you don't fuse it), '2×x' would result in a lazy array.  Then 1+that would materialize some chunk at a time--4k, say--and add 1 to it
[14:24:20] <phantomics> For example, 5 5↑20⌽200 200⍴⍳9
[14:24:29] <moon-child> since 1+2×x is memory-bound, that way you don't have to page all of x through memory multiple time
[14:24:33] <phantomics> Take the 200x200 array to start with, don't mind how it's created
[14:25:14] <phantomics> If you know that only a 5x5 take out of it is going to be used, doing 20⌽ for all its elements is pointless
[14:25:28] <moon-child> yeah given laziness you can also avoid materializing parts of an array entirely
[14:25:45] <hayley> Yes, the APL\3000 compiler flows what subarrays are actually used.
[14:25:47] <phantomics> So instead, the 20⌽ returns a function that can either return the processed array or be given more parameters
[14:25:57] <hayley> So does Petalisp, too.
[14:26:29] <phantomics> If you give it the :take #(5 5) parameter, it will only calculate the rotation for a 5x5 take, obviously I'd need to figure out logic for stacking operations in this way
[14:26:56] <phantomics> APL2 had a type called "integer progression vectors" representing the output of ⍳
[14:27:34] <phantomics> So instead of a big vector, ⍳1000 would be "vector to 1000, starting point 1, multiple 1"
[14:27:55] <moon-child> there is a NARS2000 paper I have been meaning to read that talks about something similar
[14:28:37] <phantomics> Lots of options, the question is what's the most flexible model to use, hard to tell without a lot of work implementing
[14:28:44] <moon-child> yes
[14:29:35] <phantomics> And what  would be the lower-hanging fruit: this kind of lazy evaluation or implementing SIMD? I'd prefer to use sb-simd once it's complete
[14:30:13] <phantomics> Seems heisig has been quite busy lately
[14:30:14] <hayley> Well, I did data flow analysis on regexens before SIMD.
[14:30:42] <phantomics> What made a bigger difference for you?
[14:31:00] <phantomics> Of course it depends on application
[14:31:04] <moon-child> regex is very different from apl
[14:31:13] <moon-child> even if phantomics adds dfa _and_ simd, I bet dyalog will be faster
[14:31:42] <phantomics> I don't know that they're that magic
[14:31:53] <moon-child> not magic; elbow grease
[14:32:23] <phantomics> For example, they've considered but never built a scalar function composer like I have. A lot more will be needed to get close to them though
[14:32:32] <hayley> The former is more generally applicable, but the latter kicks butt when it's applicable.
[14:32:55] <hayley> Well, methinks Dyalog got a head start. I wasn't really planning to go faster than Hyperscan, but here I am (occasionally).
[14:32:59] <hayley> In any case, I don't think doing the "what do I actually need to materialize" analysis is too hard. For a start, you could handle the obvious stuff first, and just bail out whenever it gets non-obvious.
[14:33:33] <moon-child> 'what do I need to materialize'  can be done at runtime with no penalty
[14:33:44] <hayley> e.g. it might not be too terrible to only constrain using take and reshape, and then propagate through reductions and maps.
[14:33:46] <moon-child> here in array land we've got no stinkin loops, thank you very much
[14:33:57] <phantomics> Their search functions do a lot of hash optimizing, however tools for this exist in CL like cl-custom-hash-table
[14:34:28] <hayley> Yes, but APL\3000 merged loops, and you might want to unroll entirely for small ranges.
[14:34:52] <moon-child> phantomics: yes, but index-of is not a hash table
[14:35:05] <moon-child> read 'hashing for tolerant index-of'?
[14:36:02] <phantomics> One thing I was thinking of was an "autotuning" system that would test a computer April is running on and produce a profile file that would tell it at what point to split an operation into multiple threads
[14:36:30] * hayley really needs to make her OpenCL Petalisp backend suck less. Surely it shouldn't be so hard to make each work unit handle multiple elements of an array.
[14:37:06] <moon-child> I was thinking of something similar recently.  Was comparing different types unrolling for some simd loops, and I bet that stuff is cpu-dependent
[14:37:46] <phantomics> It could do these tests for every function, since they would all have different parallel overhead
[14:38:56] <hayley> I'd like to try something with some low-overhead statistical profiler, but idk what. Perhaps if one-third-re-nightmare generates smaller machines, each a separate function, I could use profiles to self-tune.
[14:39:59] * moon-child starts writing a benchmark for fused vs lazy ops, notices the time, heads off to bed
[14:40:00] <phantomics> hayley: deciding what to materialize would probably work with an iterative dev approach as you describe, been thinking about the model: a list of parameter sets for each function to be applied to a value?
[14:40:04] <hayley> Ideally I'd have a meter already for false positives in SIMD prefix matching, and eventually the compiled code decides it's going shit, and bails out to scalar code.
[14:40:48] <moon-child> phantomics: btw, another thing that would be really cool: automatically transposing arrays based on access patterns
[14:40:53] <hayley> I was thinking of it as a compile-time concern, since that is what Petalisp and APL\3000 do.
[14:41:34] <hayley> "Beating" in the APL\3000 paper. What a nice name.
[14:42:01] * hayley is a hypocrite, as GCs have "infant mortality" and we speak of "killing" in compilers.
[14:42:10] <phantomics> hmm, so if I have a function that's taking A[;X-Y] of array A a lot, I could create a transposed copy of A that would be implicitly used so that the access would be sequential?
[14:42:24] <moon-child> yeah
[14:42:44] <phantomics> Interesting idea
[14:42:47] <moon-child> i think it could be especially nice for interactive use
[14:42:53] <moon-child> do it in idle time on an off-core
[14:43:06] <moon-child> (though I think most of the heavyweight interactive stuff people are doing is time-series which is flat.  STILL)
[14:43:33] <phantomics> The annoying thing about CL arrays is that it's possible to attach arbitrary metadata to an array... but it requires that the array be T-type so it precludes optimizing the type
[14:44:07] <moon-child> well.  You don't have to expose that part to the cl interface
[14:44:24] <moon-child> (though obviously there would be problems when you pass data through cl functions back to apl ones)
[14:44:27] *** Joins: random-nick (~random-ni@87.116.167.143)
[14:44:47] <hayley> Unfun fact: early versions of oclcl-petalisp used CL arrays of element-type NIL to shut up Petalisp scheduler code, which really wanted arrays for some reason, and there would be a hash table of CL array -> OpenCL array.
[14:44:57] <phantomics> There are other ways to do it, but the most elegant way is to have arrays internally stored with 1 more than their "actual" length
[14:45:35] <moon-child> that is the _most_ elegant way?
[14:45:41] <phantomics> The first element of the array contains a ptree or atree with metadata, and the rest is the actual content, the the "actual" array is displaced to it with a 1 offset
[14:45:56] <moon-child> it seems to me far more elegant to stop pretending that cl's builtin data structures are a superset of apl's
[14:45:58] <moon-child> hayley: :<
[14:46:02] <phantomics> That way you can easily get the metadata by finding the array's displacement
[14:46:33] <hayley> Nowadays, I pass around OpenCL arrays, since heisig helped some guy at his university with a CUDA backend, and he realised forcing CL arrays didn't make sense.
[14:47:01] <phantomics> For general APL use, this is enough, because the only real need for array metadata in APL beyond what CL offers is prototypes for empty arrays, for which this works fine because you don't need to optimize storage for empty arrays
[14:47:42] <moon-child> I didn't say it wasn't enough.  Just saying, if you are looking for elegance--
[14:49:56] <phantomics> what do you prefer, OpenCL? With my method you can pass the arrays around and their metadata goes with them, and the arrays can be processed with standard CL functions
[14:50:56] <phantomics> One of my goals in April was to have its output usable natively within CL, unlike say NumPy, and also giving the ability to easily import functions from CL into April
[14:51:42] <phantomics> So while April has no file read/write functions by default, for example, you can trivially add them if you want
[14:51:55] <moon-child> right.  I have no interest in creating an apl system which is integrated with cl.  I'm not saying your approach is _bad_, only that it sacrifices elegance (and I think that is reasonable)
[14:53:35] <phantomics> I'd say they're elegant in different ways. Tight integration with the language opens many possibilities
[14:55:29] <moon-child> I suppose.  It is not the type of elegance that appeals to my eye.  But, gustibus non est disputandum
[14:57:07] <shka> phantomics: btw, how do i even learn APL?
[14:57:09] <phantomics> hayley: are there any writings from heisig about his thought process vis a vis OpenCL?
[14:57:17] <shka> any pro tips?
[14:57:46] <hayley> phantomics: Not aware of any, I just wrote the OpenCL backend cause I was bored.
[14:57:49] <moon-child> shka: I suggest the j learning materials, as I found them far superior to those commonly available for apl
[14:58:31] <phantomics> shka: here's a good tutorial: https://xpqz.github.io/learnapl/intro.html
[14:58:31] -ixelp- Introduction — Learning APL
[14:58:50] <phantomics> I got started with this tutorial: https://tutorial.dyalog.com/
[14:58:50] <moon-child> I did not think that was a very good resource
[14:59:04] <shka> phantomics: also, what should i do to input all those funny characters?
[14:59:16] <phantomics> The APL tutor is very primitive technologically but pedagogically it's superb
[14:59:19] <sham1> Emacs has an input mode for them as well
[14:59:19] <shka> i honestly wish i would have APL keycaps set 
[14:59:25] <phantomics> I may also have an update for you in APL resources soon
[14:59:39] <moon-child> (the xpqz thing, that is.)  It doesn't have a good sense of scope; it doesn't introduce things in a way that's useful to a beginner
[14:59:42] <moon-child> shka: setxkbmap something
[14:59:45] <phantomics> For input, Linux has an APL input mode you can switch to
[14:59:53] <moon-child> more annoying without x
[15:00:09] <moon-child> I use setxkbmap -layout us,apl -variant dyalog -option grp:rwin_switch.  That takes over your right super key, in case you use it for something else
[15:00:11] <shka> i have a programmable keyboard, maybe i can have APL layer 
[15:00:27] <shka> moon-child: oh, that's cool
[15:00:44] <moon-child> phantomics: yeah, apl tutor was nice
[15:00:58] <phantomics> tutorial.dyalog.com has a great progression, you just have to deal with its interface
[15:01:37] <moon-child> I still think the j books are better though.  And deeper, from my (vague) recollection of apl tutor
[15:18:02] <shka> i think i ought to print apl charset and put it on the screen
[15:18:15] <hayley> gilberth: uLisp does a full GC on a Pi Pico in 3.7ms. Wouldn't mind dropping that into the hundreds of microseconds though. 
[15:20:26] <selwyn> apl keycaps would be pretty
[15:20:51] <shka> e
[15:20:53] <shka> eh
[15:21:07] <shka> if i could get triple dyesubs or something like that
[15:21:47] <shka> lol, unicomp sells apl keycaps 
[15:21:53] <shka> for the model m
[15:21:57] <shka> how funny is that
[15:27:07] *** Quits: kevingal (~quassel@2a02:8084:4140:f300:6c5b:ab76:207a:5858) (Remote host closed the connection)
[15:33:22] <phantomics> It's not that hard to memorize the APL key positions, I kept the Emacs gnu-apl-mode keyboard buffer open for a while and then didn't need it anymore
[15:48:53] *** Joins: Achylles (~Achylles_@2804:431:d725:5f74:726:267b:60a8:3cf6)
[15:49:13] <shka> phantomics: i fee like i would be tempted to write ASCI->APL translation table 
[15:49:51] <phantomics> Could help as a learning tool
[16:01:10] *** Joins: pjb (~pjb@user/pjb)
[16:06:47] *** Quits: Achylles (~Achylles_@2804:431:d725:5f74:726:267b:60a8:3cf6) (Remote host closed the connection)
[16:30:39] *** Joins: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de)
[16:31:33] *** Quits: Posterdati (~posterdat@host-87-19-166-231.retail.telecomitalia.it) (Ping timeout: 250 seconds)
[16:44:34] *** Joins: Posterdati (~posterdat@host-87-19-166-231.retail.telecomitalia.it)
[17:18:40] <phoe> :(
[17:18:54] <selwyn> everything ok?
[17:19:03] <phoe> no - TIL that (defmethod print-object ((object (eql 69)) stream) (format stream "Nice.")) does not conform
[17:20:10] <shka> oh
[17:20:18] <shka> that's unusual 
[17:20:27] <shka> not nice
[17:24:49] <selwyn> but why
[17:25:05] <phoe> selwyn: 11.1.2.1.2 point 19
[17:25:36] <selwyn> oh
[17:25:40] <phoe> PRINT-OBJECT is a standardized generic function and its argument, 42, is a direct instance of a standardized class
[17:25:46] <selwyn> yes
[17:26:18] <dave0> nite all
[17:26:48] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[17:29:39] <selwyn> perhaps they thought it would be 'antisocial' to specialise functions in that way
[17:29:59] <phoe> more like "that should be reserved for the implementation"
[17:30:16] <phoe> like, calling print-object on an integer should be possible to inline or something
[17:30:25] <selwyn> right
[17:30:35] <phoe> and such a method would not then be called
[17:33:57] <selwyn> surprised at how well kefir holds up outside of the fridge
[17:34:04] <selwyn> starting to believe that refridgeration is a meme
[17:34:18] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[17:35:11] <sham1> Refrigeration is not a meme, although some foods are more dependent on it than others
[17:35:41] <phoe> a conspiracy to sell more fridges
[17:36:16] <ck_> together with big climate
[17:36:18] <sham1> Surely
[17:36:51] <ck_> it's not refridgeration. it's "heat inoculation"
[17:37:48] <sham1> Yeet the heet
[17:38:07] <shka> selwyn: try that in the summer
[17:38:49] <shka> but yeah, no sugars, so it is not that good 
[17:38:58] <shka> for microbs
[18:58:26] <gilberth> It's about modularity as you could break other software, when you think you're smart and define nifty print-object method. For that there is *print-pprint-dispatch*. I used it to let RODs, which are (unsigned-byte 16) vectors used as UCS-2 strings print as such.
[18:59:38] <gilberth> A bit like olde LISP w/o strings, which would read "foo bar" as a symbol named |foo bar| with a special property^Wflag to let it print back using double quotes.
[19:00:23] <gilberth> I still find it ironic that Lisp used to use symbols for strings, while JavaScript uses strings for symbols essentially.
[19:02:39] <shka> gilberth: not only JS
[19:02:51] <gilberth> Who else?
[19:02:58] <shka> but yeah, i think that symbol data type should be more widespread then it really is
[19:03:07] <shka> gilberth: R is a shining example of that
[19:03:22] *** Quits: ratzkewatzke (~ec2-user@ec2-34-217-87-98.us-west-2.compute.amazonaws.com) (Ping timeout: 265 seconds)
[19:03:28] <shka> and it is a very lispy language implementation-wise
[19:03:38] <selwyn> hm
[19:03:41] <shka> which makes it weird
[19:04:01] <gilberth> What kind of language is R?
[19:04:49] <gilberth> Ah, Lispy, you mentioned that already.
[19:05:06] <shka> dynamic, dynamically typed, statistic oriented, has first class expressions and first class environments  
[19:05:32] <shka> you can have unevaluated expression object
[19:05:49] <shka> and evaluate it given an environment object
[19:05:52] <selwyn> there was a js to js compiler on hn today
[19:05:52] <shka> but no macros 
[19:06:26] <shka> but you don't even need macros that much because CL:IF can be a function in R
[19:06:58] <gilberth> Ah. ok. Like with PostScript or IIRC Smalltalk?
[19:07:17] <shka> i don't know about postscrpit
[19:08:18] <shka> oh sorry, R language says that there is a sybmol
[19:08:27] <gilberth> You can pass a "block" to a function. This is a stream of instructions which can be executed, if you wish, or not if you don't. Bare-bone "closure".
[19:08:31] <shka> which is weird to me because typeof returns string
[19:08:58] <gilberth> Of course in PS it does not close over anything as there is no lexical environment.
[19:09:54] <gilberth> Is R somehow related to, how was it called?, XLispStat?
[19:15:47] <shka> gilberth: i don't know what xlispstat is
[19:16:09] <shka> but IIRC R is variant of older language called S
[19:16:48] <selwyn> i heard recently that the python monoculture is displacing r even in the stats world
[19:16:51] <selwyn> which is sad
[19:17:24] <shka> R is good for stats but it is also pretty poor for your standard programming stuff
[19:18:02] <shka> but yeah, i don't like python 
[19:18:06] <shka> or monoculture
[19:18:17] <shka> unless it is CL monoculture :-)
[19:18:20] <selwyn> haha
[19:18:32] <shka> because CL is actually really general purpose 
[19:19:08] <pl> selwyn: "data science" people can write python in any language, but they prefer python (with occassional Bank Python)
[19:19:27] <gilberth> And we have reasonable compilers, a spec and it can be morphed into anything you want or need.
[19:19:29] <selwyn> is that proprietary extensions to python?
[19:19:53] <shka> gilberth: multiple implementations as well, for instance, ABCL and ECL
[19:20:04] <shka> something that python HAD and LOST
[19:20:35] <shka> so yeah, CL is a very flexible language
[19:20:37] <gilberth> And CCL, ACL, LispWorks as well.
[19:20:45] <selwyn> it's amusing that python reinvented fragmentation in that way
[19:21:12] <shka> gilberth: yeah, i mention those because python had something like ECL called shedskin and it is long dead
[19:21:31] <shka> as well as it had java implementation and it is completely obsolete now
[19:21:38] <shka> while ABCL just keeps on trucking
[19:21:45] <gilberth> I see.
[19:22:08] <shka> https://github.com/shedskin/shedskin
[19:22:09] -ixelp- GitHub - shedskin/shedskin: Shed Skin is a Python to C++ compiler. Read the introduction below to learn about the restri [...]
[19:22:12] <gilberth> ABCL is pretty slow, but I guess it running on the JVM could be invaluable, if you need that.
[19:22:25] <shka> yeah
[19:22:42] <shka> or just write CL as extensions to your java programs, while not
[19:22:44] <shka> *why not
[19:23:00] <shka> IIRC it was designed to be a scripting implementation for editor written in Java
[19:23:16] <selwyn> i wrote a discord bot in abcl
[19:23:19] <gilberth> This is what I meant. Facing a huge existing Java infrastructure and sneak some Lisp in.
[19:23:30] <selwyn> unsure how a larger project would feel
[19:23:57] <shka> regardless
[19:24:14] <shka> CL has some real major advantages
[19:24:29] <shka> it pains me that it is perceived the way it is 
[19:24:47] *** Joins: ratzkewatzke (~ec2-user@ec2-34-217-87-98.us-west-2.compute.amazonaws.com)
[19:25:10] <gilberth> For one thing, CL is the only language that doesn't make me constantly think .oO(Oh, well, I wish XYZ would not be forbidden here.)
[19:25:46] <selwyn> bank python lol
[19:25:53] <selwyn> i know someone who probably uses this 
[19:26:05] <gilberth> Steel Bank Python?
[19:26:13] <selwyn> https://calpaterson.com/bank-python.html
[19:26:14] -ixelp- An oral history of Bank Python
[19:26:21] <shka> also, in cl you can usually run 20+ years code without much of a problem
[19:26:40] <shka> which is surprisingly useful 
[19:26:48] <gilberth> That's true.
[19:27:10] <shka> csv files and the likes didn't change much 
[19:27:34] <gilberth> I still use my Closure-HTML and Closure-XML, which is 20 years old. And it runs fine even with Unicode.
[19:27:35] <shka> but that old cl code sure looks weird to me
[19:27:52] <shka> common programming style in cl changed a lot 
[19:28:39] <gilberth> You believe so? Ok, you see more CLOS these days, and more LOOP, but otherwise?
[19:29:35] <gilberth> And some code in McCLIM is more twenty years old, too.
[19:29:35] <shka> it looks like that to me
[19:29:46] <gilberth> * than
[19:30:00] <shka> but it does not mean that it is wrong
[19:30:06] <pl> a lot more CLOS compared to some old code
[19:30:09] <shka> it is just different 
[19:30:19] <pl> but then some old code has homebrew OOP
[19:31:15] <gilberth> Well, machines were slower and smaller and CLOS was huge.
[19:31:44] <pl> CLOS was also late
[19:32:13] <gilberth> Yes. Heck, even LOOP was once new to me, although LOOP is really old.
[19:32:20] <shka> i also think that being late was a good thing for CLOS
[19:32:46] <pl> shka: but not necessarily good for implementations
[19:32:56] <gilberth> shka: I agree. Suppose we would be stuck with Flavours.
[19:33:16] <pl> isn't there flavours module in ACL specifically for that one CAD program?
[19:33:31] <gilberth> Or the evil forerunner as on the CADR.
[19:33:54] <gilberth> pl: I once have seen a Flavours for ACL. Long, long ago.
[19:34:24] <pl> gilberth: it's still in the docs
[19:34:27] <pl> IIRC
[19:34:32] <shka> because there was a lot of practical experimentation in OO clos design could  benefit from the opinions formed around the homebrew systems
[19:34:51] <gilberth> pl: Sure, why not, when they have customers who still use it.
[19:35:34] <pl> I think at this point given that ICAD is probably dead as doornail, it's still there simply because it didn't break yet
[19:35:49] <gilberth> This is the nice thing with CL: We could have two OOP systems at once, if we wish. Try that with another language.
[19:36:03] <selwyn> in abcl you get 3
[19:37:11] <gilberth> What is the third?
[19:37:21] <shka> the one thing that i struggle to accept in programming
[19:37:23] <shka> gilberth: java
[19:37:33] <selwyn> clos, java, and this flavours thing i guess
[19:37:42] <gilberth> Ah, ok.
[19:37:59] <shka> anyway, i struggle to accept that every first version of a given design usually sucks
[19:38:37] <shka> but i think that this is sadly the reality 
[19:38:41] <selwyn> shka: i appreciate that but what does it have to with programming
[19:38:43] <selwyn> it is life
[19:38:50] <shka> yeah
[19:38:53] <selwyn> hm
[19:39:00] <gilberth> Hmm, isn't it hard to get it right on the first take without prior experience?
[19:39:02] <shka> the good thing about CL is that it is not the first lisp
[19:39:07] <selwyn> designing prog langs does seem to be particularly difficult though
[19:39:34] <shka> there were dozens of lisp before CL
[19:39:36] <gilberth> selwyn: Hugh? It is difficult, because otherwise we won't see so many shitty languages.
[19:40:10] <selwyn> the world's best motorbike designers can probably build a very good bike if they try first time
[19:40:53] <gilberth> selwyn: Without having ever build a bike before?
[19:41:15] <selwyn> well ofc not
[19:42:28] <gilberth> Wrt programming languages I always have the feeling that most languages besides CL are full of arbitrary lazy restrictions.
[19:55:25] <semz> not sure that's laziness rather than "we didn't even consider X as a possibility"
[19:56:41] <semz> look at how many people don't even consider something like the condition system, even though choosing your error strategy at runtime seems obvious in retrospect
[19:56:46] <semz> this includes past me btw
[19:56:56] <selwyn> +1
[19:58:11] <shka> that's the value of the experimentation 
[20:02:21] <gilberth> My favorite is lexical closures. Real one where variables could be written to and TAGBODY tags and BLOCK tags been jumped/exited from.
[20:03:18] <gilberth> This is like most modern languages not even having a GOTO for political reasons. Those things are building blocks towards a somewhat universal language.
[20:06:33] *** Joins: makomo (~makomo@user/makomo)
[20:06:52] <gilberth> This lack of GOTO is just trying to force a GOTO-free programming style on you. And I just don't like languages which try to force a particular programming style on you.
[20:07:57] <gilberth> And this is what often the reason for new languages: Push the author's idea of the new holy grail on you.
[20:09:10] <White_Flame> as opposed to exploring a new paradigm
[20:09:27] <White_Flame> CL really is peak imperative
[20:09:30] <White_Flame> and OO
[20:10:00] <White_Flame> but functional, declarative, dataflow, etc etc all are ripe for further exploration.  But everybody sticks to imperative with different syntax/restrictions
[20:10:37] <shka> White_Flame: i would use CL for dataflow exploration to be honest :P
[20:10:51] <White_Flame> sure, as prototyping
[20:11:47] <shka> i have a sneaking suspicion that it would be completely fine for implementation
[20:12:35] <selwyn> why wouldn't it be
[20:14:35] *** Joins: iquites (sid77830@id-77830.lymington.irccloud.com)
[20:15:34] <White_Flame> fine-grained interthread communication primitives at the ABI level?
[20:18:16] <shka> White_Flame: MOP
[20:18:30] <shka> i suspect that it is feasible 
[20:18:59] <White_Flame> hmm, not sure how mop and threading intersect
[20:19:31] <White_Flame> (although yeah you can put any code into your oo model that way, but I'm not sure OO is right for dataflow efficiency)
[20:19:45] <iquites> Anybody ever hear of a BEAM (The Erlang/Elixir virtual machine) interprocess communication written in Lisp.
[20:20:02] <iquites> I should do a search before asking, but hey, it’s a cafe
[20:21:09] <pl> there was port, iirc
[20:21:19] <White_Flame> I wrote an erlang node in CL, but it didn't have the exact mailbox semantics of erlang (specifically snooping the mailbox for the most recent message matching a pattern)
[20:21:28] <pl> also, there was direct port to elisp, as in Emacs could join Erlang cluster as a node
[20:21:47] <pl> (it just didn't accept jobs)
[20:21:47] <iquites> Cool. Emacs is even neater for me right now.
[20:22:12] <iquites> I have a notion that the BEAM interprocess communication, with a few extensions, may be ALL we ever need for communicating over the web.
[20:22:25] <White_Flame> epmd sux, tho.  I wish nodes just joined some udp broadcast instead of needing that separate daemon
[20:22:26] <pl> iquites: easy mistake to make
[20:22:36] <iquites> But I doubt I’ll get my technical chops together again in this life enough to make it so
[20:22:45] <pl> White_Flame: I think there was newer discovery systems added other than epmd
[20:22:53] <pl> actually unsure if it wasn't pluggable
[20:22:57] <White_Flame> cool, it's been quite a few years since I last used erlang
[20:23:32] <pl> iquites: different networking modes have different behaviours and "best approaches"
[20:23:34] <iquites> I’m not fluent in Erland or Elixir, but I’ll do Elixir first, if I ever go there. I may just write the communication code in Elm, that being my favorite language right now.
[20:24:04] <pl> for example, TCP has some *hilarious* issues on drop-heavy wireless links like mobile phones
[20:24:37] <iquites> But that’s the beauty of the Erlang ecosystem. It’s built for any node to fail at any time, and to gracefully recover, as much as is possible.
[20:24:40] <pl> to the point that it's common to have special TCP-mangling middlewares to prevent bad behaviour at network edges
[20:25:16] <iquites> And other than latency, you can’t distinguish local and remote communication
[20:25:21] <White_Flame> iquites: clearly you favor languages starting with #\E ;)
[20:25:26] <iquites> Heh
[20:25:35] <iquites> I made my living writing Lisp, though
[20:25:51] <pl> at the same time, there's benefit to using TCP on mobile, due to hw acceleration in radios and long session timeouts 
[20:25:56] <iquites> And, for nine years, Progress 4GL and Java
[20:26:00] <pl> so you have a situation where the sucky protocol is useful :D
[20:26:17] <White_Flame> the downside of erlang comms is that everything needs to be serialized
[20:26:17] <pl> (TCP is also arguably pretty bad protocol, but it unfortunately escaped the lab)
[20:26:35] <iquites> I haven’t even looked at the protocol. It’s old, but it appears to work, for thousands of processes at a time
[20:27:00] <White_Flame> it does take advantage of the pure-functional characteristic in terms of just sending data itself, including closures where the closed over data is immutable and can just be sent literally
[20:27:04] <iquites> It was built for Ericson’s cell phone network
[20:27:23] <White_Flame> right, and there's a lot of compile-time staticness in what they built
[20:27:45] <iquites> The pure functional nature of Elm is one reason I like it. It, of course, shares that with BEAM languages. Look ma, no locks!
[20:27:47] <White_Flame> in telephony, there's very little state to maintain in an active connection, and things can be thrown away and restarted easily
[20:27:52] <White_Flame> that can be difficult to map onto more complex problems
[20:28:19] <iquites> Right. So that part of the equation takes more time there, and may not even be possible.
[20:28:54] <pl> Erlang's protocol was honestly built for internal server backplane
[20:29:01] <pl> and it shows in places (it does badly with lossy links)
[20:29:12] <pl> but if the underlying network fits, it can shine
[20:29:24] <White_Flame> my final takeway was that erlang is a great language to learn from, and apply its concepts elsewhere :-P
[20:29:34] <White_Flame> especially things like supervision
[20:29:37] <pl> bits from OTP are also used in oxide.computer design for the BMCs
[20:30:03] <White_Flame> and the notion of tasks restarting from checkpoints
[20:30:46] <White_Flame> the hot code update is a bit clunky, though, because the semantics are very implicit on the points at which to update
[20:30:55] <iquites> Many people think of lisp that way, and most of lisp is now pretty standard in a lot of languages.
[20:31:06] <iquites> Hot code update in Slime rocks
[20:31:22] <White_Flame> yep, except for homoiconicity, which everybody is still afraid of, and thus they can't codegen easily
[20:31:25] <iquites> But it’s easy to shoot yourself in the foot
[20:31:42] <White_Flame> right, erlang's is more organized and is for pushing new deployments
[20:31:55] <White_Flame> as opposed to monkeying around with the running system for dev
[20:31:56] <iquites> Yep. Slime works great for development.
[20:32:02] <iquites> As designed
[20:32:51] <iquites> I DO poke at my lisp web server with slime, or just by typing at its built-in REPL, via a screen session
[20:33:56] <gilberth> Yep, it's nice when you could "login" into your running application and inject small patches, without needing to restart it.
[20:34:37] <White_Flame> or launch internal things, generate reports & monitoring, etc
[20:34:47] <iquites> I haven’t yet tried doing development with an Emacs on my web servrer, via an iPad SSH client.
[20:34:57] <iquites> But it should work, just not as nice as a native Emacs
[20:35:39] <iquites> Except for Steve Jobs’s weirdness, we would HAVE a native iPad Emacs
[20:35:52] <iquites> Well, there is one, but you have to jailbreak to use it
[20:36:14] <iquites> SBCL works nicely on my M1 iMac
[20:36:31] <selwyn> emacs on an ipad sounds awkward to use anyway
[20:36:36] <selwyn> but i know i would try that as well
[20:36:45] <iquites> Not with a keyboard.
[20:36:45] <White_Flame> unless you need things like cl+ssl :-P
[20:37:06] <iquites> I let Apache do the SSL part and reverse proxy to a user port for the lisp server
[20:37:34] <selwyn> me too
[20:37:55] <iquites> Same for WebSocket servers
[20:38:18] <White_Flame> if lisp is the wss client, though, you kinda need it
[20:38:48] <iquites> The reverse proxy via Apache works fine for my Elm ws clients
[20:39:37] <iquites> I sent JSON over the wire.
[20:40:27] <iquites> The most developed exampls is my son’s board game, A Game of Golems, https://agog.ninja
[20:40:53] *** Quits: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 252 seconds)
[20:41:59] <selwyn> https://www.theguardian.com/science/2021/dec/15/why-do-so-many-people-struggle-to-say-omicron
[20:42:00] -ixelp- ‘Omni is everywhere’: why do so many people struggle to say Omicron? | Language | The Guardian
[20:42:48] <gilberth> I use SLIME to have c-c c-c working in a JS buffer to send JavaScript redefinitions to the browser. The SLIME goes to the web server, which in turn is connected to the client via sth AJAX-like.
[20:43:46] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[20:45:22] <iquites> Cool. I don’t write plain JS any more, except as little additions to Elm, so I rebuild my entire app, and reload, relying on LocalStorage to preserve state.
[20:45:59] <iquites> They’re too moronic to say omicron
[20:47:04] <gilberth> I also wondered why I see "omnicron" so often. My guess is that most are not accustomed to the Greek alphabet and just don't know any better.
[20:47:42] <gilberth> But I fear it'll become omnipresent, so omnicron might be a fitting name.
[20:47:46] <White_Flame> I'm just going to start calling it the Unicron virus
[20:47:55] <White_Flame> as it eats the planet
[20:48:09] <gilberth> Unicrons do that?
[20:49:21] <selwyn> hornicron
[20:49:50] <gilberth> .oO(Do I need to call the police?)
[20:50:06] * selwyn won't be taken alive
[20:50:28] <gilberth> More importantly: Is that related to cron jobs?
[20:51:34] <gilberth> I mean UNIx, OMIx? cron? job? That sure is the devil's work.
[20:53:56] <edgar-rft> at least you can say that omicron does its job
[20:54:00] <selwyn> lol
[20:54:33] <White_Flame> gilberth: https://www.youtube.com/watch?v=cJRfABxL4R8
[20:54:34] -ixelp- Transformers G1 The Movie Unicron Destroys Lithone - YouTube
[20:56:13] <White_Flame> (wrong aspect ratio, though.  the theatrical movie was actually animated in 4:3)
[21:02:02] *** Quits: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 240 seconds)
[21:13:49] *** Quits: sifi (~sifisega@101.100.130.75) (Ping timeout: 240 seconds)
[21:24:34] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[21:31:41] *** Joins: djuber (~user@65.79.128.64)
[21:54:21] <gilberth> Wow! My immune system is really doing some work. I am impressed.
[21:55:13] *** Joins: Inline (~Inline@aftr-37-201-240-204.unity-media.net)
[21:55:26] <pl> Ever felt like a CS professor's astralized form was screaming "DYNAMIC PROGRAMMING (ya bitch)" at you?
[22:06:31] *** Quits: treflip (~user@95.79.32.99) (Quit: good night ✨)
[22:09:59] *** Quits: Posterdati (~posterdat@host-87-19-166-231.retail.telecomitalia.it) (Ping timeout: 252 seconds)
[22:11:51] *** Joins: waleee-cl (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[22:11:57] *** Quits: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Read error: Connection reset by peer)
[22:12:28] *** Quits: waleee-cl (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Client Quit)
[22:13:17] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[22:23:43] *** Joins: Posterdati (~posterdat@host-87-19-166-231.retail.telecomitalia.it)
[22:40:57] *** Quits: shka (~herr@109.231.0.226) (Ping timeout: 256 seconds)
[22:55:29] *** Joins: lisp123 (~lisp123@5.30.23.247)
[22:59:32] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 240 seconds)
[23:00:40] *** Quits: notzmv (~zmv@user/notzmv) (Read error: Connection reset by peer)
[23:07:23] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[23:08:07] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[23:18:33] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Ping timeout: 276 seconds)
[23:22:40] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[23:31:49] *** Parts: djuber (~user@65.79.128.64) (ERC 5.4.1 (IRC client for GNU Emacs 29.0.50))
[23:32:07] *** Joins: djuber (~user@65.79.128.64)
[23:42:35] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
