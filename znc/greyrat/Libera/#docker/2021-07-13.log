[00:01:07] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[00:12:02] <varaindemian> on what IP can I find this docker? https://github.com/blacktop/docker-cuckoo
[00:12:21] <varaindemian> started it but I cannot find its ip to access it
[00:14:00] <ada_> varaindemian: when you run a docker container, generally you'd publish a port with the -p flag
[00:14:42] <ada_> varaindemian: then you could access your service on your docker host's primary IP and the published port
[00:14:55] <ada_> varaindemian: usually you never need to look up a container's IP
[00:15:28] *** Joins: dudek (~dudek@185.150.236.155)
[00:15:54] <varaindemian> I started it with docker-compose up :
[00:16:17] <ada_> did you write a ports: section for your service publishing some ports?
[00:17:17] <varaindemian> i did git pull
[00:17:19] <varaindemian> cd
[00:17:23] <varaindemian> docker-compose..
[00:17:36] <ada_> varaindemian: ok, but still what I said 
[00:17:46] <ada_> varaindemian: the fact you did git pull and cd doesn't change ^ that part
[00:18:01] <varaindemian> I didn't use anthing after docker-compose 
[00:18:02] <ada_> you could use pastebin and show your compose file
[00:18:07] <ada_> ok, again, 
[00:18:11] <ada_> the compose file says what should be published
[00:18:27] <ada_> you should read the compose file, look for the ports: section according to the documentation, and find out what ports are being published
[00:18:36] <ada_> you could also look at the status of your containers in "docker ps" and find out that way
[00:18:36] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-10-70-54-112-49.dsl.bell.ca) (Ping timeout: 256 seconds)
[00:18:38] <varaindemian> I see
[00:18:42] <varaindemian> thank you!
[00:21:18] *** Quits: rawtaz (~rawtaz@user/rawtaz) (Ping timeout: 255 seconds)
[00:23:14] *** Joins: scaleww (~scaleww@77-41-20-31.ftth.glasoperator.nl)
[00:25:58] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[00:31:47] <Lutin> ada_ iptables -A INPUT -i eth0 -s sub.domain.tld -j DROP works perfectly on docker :D
[00:32:15] <ada_> you'd have to explain what you mean and show test results
[00:32:37] <ada_> pretty sure that iptables only sees packet info
[00:32:41] <ada_> and packets don't container "source domain "
[00:32:48] <ada_> thats just not part of the IP header so, idk 
[00:33:14] <ada_> pretty sure the iptables client may just resolve the domain to an IP on the spot and then program it by IP
[00:35:56] *** Quits: bouncy_ (~ben@user/benoit) (Ping timeout: 272 seconds)
[00:36:03] <Lutin> ada_ mhh maybe something ele happened but got a timeout... 
[00:36:26] <Lutin> ada_ could do it on bridge
[00:36:30] *** Joins: thiras (~thiras@user/thiras)
[00:37:11] *** Joins: bouncy_ (~ben@user/benoit)
[00:37:46] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[00:37:58] <iffraff> Hi could someone take a look at my gist?  I have a nice notes section at the bottom that explains what is happening. 
[00:37:58] <iffraff> https://gist.github.com/reharik/270a16bc93ea5c989f6796747f545025
[00:40:44] *** Joins: hackers (~self@bras-base-sttrpq3809w-grc-19-184-144-208-177.dsl.bell.ca)
[00:40:49] <hackers> hi
[00:41:33] <hackers> how can I copy a file from a docker image not container to its host system?
[00:41:37] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Quit: Leaving this bitch.)
[00:42:00] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[00:42:03] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[00:43:34] <tabakhase> hackers do you count "docker run --rm THING cat /file > file" as container or image? :P
[00:43:55] <tabakhase> its almost a docker cp :|
[00:44:16] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Remote host closed the connection)
[00:44:17] <tabakhase> (tarpipe it if needed more than 1)
[00:44:21] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Client Quit)
[00:44:41] *** Joins: rgl (~rgl@bl12-47-147.dsl.telepac.pt)
[00:44:42] <hackers> the image won't run so I can't have a container right?
[00:45:05] *** Quits: Haxxa (~Haxxa@122-199-59-136.ip4.superloop.com) (Quit: Haxxa flies away.)
[00:45:23] <hackers> tabakhase: I count anything that can let me read the file as a solution that's more the problem I'm trying to solve
[00:46:10] <tabakhase> wont run, usually has a reson, and anything should be able to run sh/cat or such, you may need to unset the entrypoint or such
[00:46:19] <tabakhase> (so add a --entrypoint "" in there)
[00:47:27] <hackers> tabakhase: the container does not have utilities like "cat"
[00:47:34] *** Joins: Haxxa (~Haxxa@122-199-59-136.ip4.superloop.com)
[00:47:34] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[00:47:37] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-10-70-54-112-49.dsl.bell.ca)
[00:48:18] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 255 seconds)
[00:48:19] <tabakhase> hackers put it in a volume, this should populate on the first boot, then run another container on this volume to exfil maybe?
[00:48:37] <ada_> hackers, docker run, override the command to sleep the container, and use "docker cp"
[00:48:41] <hackers> ok I get the gist
[00:49:25] <hackers> ada_: that's a bit the issue I'm having, I'm trying to run a distro-less container so there's nothing left on the image other than what's needed to run the main process
[00:49:36] <hackers> it just makes it harder to troubleshoot
[00:49:48] <hackers> I was hoping I could simply `docker cp ...`
[00:50:12] <tabakhase> ye if you dont have cat, you likely dont have sleep either - doublestepping it over a volume is certainly ugly, but should work...
[00:52:30] *** Joins: tang^ (~doofus@2604:3d09:47c:f970:645c:d696:92ff:99d9)
[00:52:39] <ada_> does the container run at all?
[00:52:43] <ada_> or does it crash immediately?
[00:53:04] <ada_> i mean when you run it like normal
[00:53:13] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[00:54:34] <ada_> kludgy solution I see here involves a new Dockerfile that says "FROM $image" and adds a RUN step to install a shell or some other debug tool.  then build & run it.
[00:54:51] *** Quits: jpmh (uid445439@id-445439.stonehaven.irccloud.com) (Quit: Connection closed for inactivity)
[00:57:11] <hackers> it crashes
[00:57:24] <hackers> I was able to just copy the file from the overlay2 filesystem
[00:57:58] <hackers> the file is what I expected it to be and I'm unable to find out why it crashes inside the container
[01:04:54] <hackers> http://ix.io/3sNk
[01:05:05] <Lutin> ada_ need to investigate the domain block but it must be possibe somewhere
[01:05:27] <hackers> I'm getting this error when running a python3.7 interpreter with `docker run -ti container /usr/bin/python3.7`
[01:07:40] *** Joins: pvdp (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au)
[01:08:42] *** Joins: cloaked1 (~cloaked1@174-126-226-132.cpe.sparklight.net)
[01:09:33] *** Quits: varaindemian (~varaindem@86.124.22.31) (Quit: Client closed)
[01:10:53] *** Quits: cloaked1 (~cloaked1@174-126-226-132.cpe.sparklight.net) (Remote host closed the connection)
[01:13:14] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Quit: Leaving)
[01:22:24] <hackers> it's weird to me that `COPY --from=build /app /` copies the content of /app into / and not the directory /app in / as /app
[01:27:23] <artok> hackers: you tell it to do that, so what is weird?
[01:29:36] <devslash> I think that he is getting cvonfused by the syntax of it 
[01:29:56] <hackers> yeah the syntax is different than `cp`
[01:29:57] <devslash> but I believe that / and /app refer to 2 different layers in your compose file
[01:30:52] <hackers> ah so you copy a layer not the actual directory
[01:32:42] *** Joins: zoredache (sid295808@id-295808.brockwell.irccloud.com)
[01:42:26] *** Joins: haniaF (~haniaF@79.191.100.82.ipv4.supernova.orange.pl)
[01:43:57] *** Quits: beob (beob@user/beob) (Remote host closed the connection)
[01:44:28] *** Quits: fedenix_ (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[01:45:33] <Lutin> --dns-127.0.0.1 shouls "always" override the resolv.conf of a container ?
[01:45:37] <Lutin> *should
[01:56:00] *** Joins: beob (beob@user/beob)
[01:59:21] <gordonjcp> hm
[01:59:25] <gordonjcp> daft question for you all
[01:59:43] <gordonjcp> if I'm in a container, is there a "convenient" name for the hostname of the host machine?
[02:02:12] <gordonjcp> ah, disregard, I've found a better way to do it
[02:02:31] <tabakhase> gordonjcp lookup the gateway of eth0 pretty much
[02:02:51] <tabakhase> some/newer docker also has docker.host.internal as dns or such, doesnt work everywhere tho
[02:03:26] <tabakhase> and remember to allow the user to overwrite ;-) 
[02:05:46] *** Joins: Davidian1024 (~Davidian1@d118-75-135-110.clv.wideopenwest.com)
[02:07:19] *** Quits: jwr (~jwr@pool-71-182-194-5.pitbpa.fios.verizon.net) (Remote host closed the connection)
[02:09:07] <Lutin> ada_ cool! I just run a pseudo traefik server which only loads the acme.json :D
[02:10:04] <Lutin> now I need to figure out if I can dummy load it succesfully on external connected one
[02:10:08] *** Quits: hackers (~self@bras-base-sttrpq3809w-grc-19-184-144-208-177.dsl.bell.ca) (Quit: leaving)
[02:11:57] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[02:21:52] <Lutin> it seems that docker with traefik is able to route to not-connected networks, wow
[02:26:36] *** Quits: c10l (~c10l@89.34.167.207) (Read error: Connection reset by peer)
[02:27:05] *** Joins: c10l (~c10l@89.34.167.207)
[02:27:36] <gordonjcp> tabakhase: I was going to pass an environment variable to my app but I can just say $HOSTNAME for that
[02:29:02] *** Joins: jazzy (~jaziz@2600:380:c114:2d85:2030:17e6:b76f:c1fa)
[02:29:33] *** Quits: thecoder (~mrrobot@c-73-27-71-147.hsd1.fl.comcast.net) (Ping timeout: 255 seconds)
[02:30:10] <Lutin> ok that problem is solved
[02:30:32] <Lutin> gordonjcp I'm testing a pseudo traefik proxy for internal usage using the json only
[02:39:28] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[02:45:04] *** Joins: NGen15 (~NGen15@ns397065.ip-178-32-220.eu)
[02:51:12] *** Quits: TomTom (uid45892@id-45892.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[02:52:43] *** Quits: Atum_ (IRC@user/atum/x-2392232) (Quit: Atum_)
[02:54:11] *** Quits: dudek (~dudek@185.150.236.155) (Quit: Leaving)
[02:57:58] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 252 seconds)
[02:58:24] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[02:59:09] *** Quits: Davidian1024 (~Davidian1@d118-75-135-110.clv.wideopenwest.com) (Quit: Client closed)
[03:01:50] *** Quits: vidbina (~vid@dynamic-077-011-134-093.77.11.pool.telefonica.de) (Ping timeout: 272 seconds)
[03:06:06] <Lutin> gordonjcp this is fun,traefik listens so good that if you don't add a network to your service1 which is on service2 service2 shows the errors of service1
[03:06:36] *** Joins: keypusher (keypusher@user/keypusher)
[03:08:43] <artok> just draw your network so that people can see it, I still don't understand how you're supposed to connect to what ever service you have
[03:08:46] <artok> =D
[03:10:43] <Lutin> artok I have 2 traefiks one connected on hostport and just a network and one to my internal network only... both are sharing the same json :)
[03:11:46] <Lutin> now I'm figuring out why the staging cert won't be upgraded because traefik says it's OK.. I think I need to remove those again..that should be automated
[03:11:58] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[03:12:52] <artok> LE system is handling cert thingies yeah
[03:13:20] *** Quits: scaleww (~scaleww@77-41-20-31.ftth.glasoperator.nl) (Quit: Leaving)
[03:14:45] *** Quits: iffraff (~quassel@136.49.178.170) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[03:16:56] *** Quits: rewrit3 (~rewrit3@user/rewrit3) (Quit: rewrit3)
[03:16:57] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[03:19:36] <Lutin> artok yeah but to live is sometimes a challenge or so
[03:19:45] <Lutin> staging goes pretty fine
[03:34:31] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[03:34:49] <Lutin> artok do you know if traefik supports dummy hostnames for certs on it's own container ?
[03:35:34] *** Quits: Ivyy (~Ivyy@2001:a62:41d:fa01:4f5f:6d80:11ff:b930) (Remote host closed the connection)
[03:36:06] *** Quits: Arwalk (~Arwalk@lfbn-dij-1-263-107.w86-235.abo.wanadoo.fr) (Ping timeout: 252 seconds)
[03:40:54] *** Quits: tang^ (~doofus@2604:3d09:47c:f970:645c:d696:92ff:99d9) (Quit: Bye)
[03:41:55] *** Joins: Arwalk (~Arwalk@lfbn-dij-1-263-107.w86-235.abo.wanadoo.fr)
[03:46:53] *** Quits: thc202 (~thc202@user/thc202) (Quit: thc202)
[03:48:16] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[03:54:39] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 276 seconds)
[04:02:38] *** Quits: bouncy_ (~ben@user/benoit) (Ping timeout: 272 seconds)
[04:04:01] *** Joins: bouncy_ (~ben@user/benoit)
[04:13:30] *** Quits: goldfish (~goldfish@user/goldfish) (Ping timeout: 255 seconds)
[04:19:07] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[04:23:51] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[04:36:12] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[04:39:50] *** Quits: hposca (~hposca@node-1w7jr9phoke2ssp3k5wcuo3j9.ipv6.telus.net) (Ping timeout: 256 seconds)
[04:52:18] *** Quits: incognito (~relativit@user/incognito) (Ping timeout: 256 seconds)
[04:54:00] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[04:54:06] *** Quits: vincent- (~vincent-@cpc87559-seve28-2-0-cust94.13-3.cable.virginm.net) (Remote host closed the connection)
[04:55:42] *** Quits: jazzy (~jaziz@2600:380:c114:2d85:2030:17e6:b76f:c1fa) (Ping timeout: 256 seconds)
[04:57:12] <akik> how do i see if a docker hub image has been scanned for vulnerabilities?
[04:57:55] *** Joins: Jimmy_H (~Jimmy_H@119.136.152.25)
[04:58:31] <akik> they should've just required people to put their Dockerfiles there
[04:58:49] <BtbN> That scan is useless anyway
[04:58:55] <BtbN> don't trust random images from the hub
[04:59:59] <akik> it's so frustrating that that service exists in its current form
[05:00:45] <BtbN> hm?
[05:01:00] <BtbN> It's a place for anyone to store images. It's not its job to curate them.
[05:01:40] <akik> it's a huge security problem
[05:02:04] <akik> just like python pip
[05:02:47] <BtbN> Just don't use stuff that's not trustworthy. With the same logic applied to everything, you could just go offline and hide in some cave.
[05:13:04] *** Joins: keypusher (keypusher@user/keypusher)
[05:23:11] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[05:23:45] *** Quits: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net) (Quit: Textual IRC Client: www.textualapp.com)
[05:24:02] <Lutin> akik that is the biggest problem to solve there
[05:24:40] <Lutin> akikonly use ones that have a github link... but even companies like percona don't have them displayed there
[05:25:21] <Lutin> meh it's difficult to find a way to have a container responsible for 2 certificates with traefik
[05:28:15] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[05:30:20] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:34:03] *** Joins: vlm (~vlm@user/vlm)
[05:40:40] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[05:41:35] *** Joins: pete443_ (~pete@user/pete443)
[05:44:22] *** Quits: pete443 (~pete@user/pete443) (Ping timeout: 272 seconds)
[05:57:27] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[06:04:47] *** Quits: Sasazuka (~Sasazuka@user/sasazuka) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[06:13:06] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Quit: Leaving this bitch.)
[06:13:42] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[06:24:18] *** Quits: iomari891 (~iomari891@105.112.138.38) (Quit: WeeChat 3.0.1)
[06:26:17] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[06:39:41] <zoredache> Google isn't giving me anything, is there some kind of image that acts as a smtp relay into other containers, kinda like how traefik works? Where I can setup mail routes with labels?
[06:45:36] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[06:53:45] *** Joins: CodeSpelunker (~CodeSpelu@user/codespelunker)
[06:54:19] *** Joins: iomari891 (~iomari891@105.112.138.38)
[06:55:35] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-10-70-54-112-49.dsl.bell.ca) (Remote host closed the connection)
[07:13:24] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[07:18:45] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[07:26:53] <Lutin> I think I have internal/external treafik working :D
[07:30:05] *** Quits: finsternis (~X@23.226.237.192) (Remote host closed the connection)
[07:30:08] *** Quits: Arwalk (~Arwalk@lfbn-dij-1-263-107.w86-235.abo.wanadoo.fr) (Quit: The Lounge - https://thelounge.chat)
[07:30:37] *** Joins: Arwalk (~Arwalk@lfbn-dij-1-263-107.w86-235.abo.wanadoo.fr)
[07:31:24] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[07:39:19] <Lutin> gordonjcp dns-01 it is! MUCH faster
[07:43:03] *** Quits: factor (~factor@c-66-30-67-217.hsd1.ma.comcast.net) (Read error: Connection reset by peer)
[07:48:09] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[07:49:13] *** Joins: factor (~factor@c-66-30-67-217.hsd1.ma.comcast.net)
[07:53:36] *** Joins: ac5tin (~ac5tin@user/ac5tin)
[07:57:38] *** Quits: CodeSpelunker (~CodeSpelu@user/codespelunker) (Quit: CodeSpelunker)
[08:01:22] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[08:04:14] *** Joins: majdal (~majdal@bras-base-toroon0954w-grc-63-142-113-216-11.dsl.bell.ca)
[08:04:31] *** Parts: majdal (~majdal@bras-base-toroon0954w-grc-63-142-113-216-11.dsl.bell.ca) ()
[08:06:09] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[08:17:44] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[08:17:45] <Lutin> artok wow this is sexy! I have 2 traefik clusters in my docker cluster, both know about the routes but only one can serve what is connected :) So I seperated internal/external ssl offloaded boxes with the same certificate file!
[08:22:32] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[08:34:22] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[08:52:03] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[08:56:38] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Quit: Leaving this bitch.)
[08:56:57] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[08:57:42] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Client Quit)
[08:58:32] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[09:03:35] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Quit: Leaving this bitch.)
[09:03:55] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[09:04:41] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Client Quit)
[09:05:03] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[09:06:02] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[09:11:04] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[09:18:19] *** Quits: ac5tin (~ac5tin@user/ac5tin) (Quit: WeeChat 3.1)
[09:22:29] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[09:24:35] *** Quits: Lutin (~Lutin@user/lutin) (Quit: Lutin)
[09:26:42] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[09:31:11] *** Quits: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com) (Quit: Leaving this bitch.)
[09:32:16] *** Joins: TastyCorn (~TastyCorn@ec2-52-10-164-55.us-west-2.compute.amazonaws.com)
[09:39:26] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[09:51:36] *** Quits: artok (~azo@mobile-access-bcee63-55.dhcp.inet.fi) (Ping timeout: 272 seconds)
[09:52:24] *** Joins: Milos (~Milos@user/milos)
[09:53:05] <Milos> How do I get something eval'd into every sh process (when using RUN) without sourcing on every line?
[09:57:00] *** Quits: xep (~xep@76-210-4-7.lightspeed.sntcca.sbcglobal.net) (Remote host closed the connection)
[09:57:10] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[09:57:44] <Milos> Never mind, I see my question kind of sounds crazy when put in the context of Docker, I found a workaround which doesn't require sourcing this particular file. Thanks.
[10:02:36] *** Joins: mihael (~mihael@2001:4454:2c6:b000:d14b:4683:aa80:97c9)
[10:02:44] <mihael> Is it possible to copy a file via docker-compose?
[10:04:38] *** Joins: arinov (~arinov@213.194.126.155)
[10:09:31] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[10:12:49] *** Joins: incognito (~relativit@user/incognito)
[10:13:57] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[10:22:44] *** Quits: trevors (~trevors@c-65-96-171-157.hsd1.ma.comcast.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[10:24:30] *** Quits: BobbyJr (~BobbyJr@robsworld.plus.com) (Quit: Leaving)
[10:26:49] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[10:26:55] *** Joins: xep (~xep@76-210-4-7.lightspeed.sntcca.sbcglobal.net)
[10:27:58] *** Joins: dmalteseknight (~dmaltesek@user/dmalteseknight)
[10:30:00] *** Joins: BobbyJr (~BobbyJr@robsworld.plus.com)
[10:35:17] *** Joins: artok (~azo@mobile-access-bcee63-55.dhcp.inet.fi)
[10:35:40] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Remote host closed the connection)
[10:46:04] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[10:49:03] *** Quits: russjr08 (~russjr08@fw.internal.russ.network) (Quit: Ping timeout (120 seconds))
[10:49:19] *** Joins: russjr08 (~russjr08@fw.internal.russ.network)
[10:50:04] *** Quits: etiennem- (~etienne@176-149-215-214.abo.bbox.fr) (Quit: ZNC 1.8.2 - https://znc.in)
[10:50:23] *** Joins: etienneme (~etienne@176-149-215-214.abo.bbox.fr)
[10:51:00] *** Quits: artok (~azo@mobile-access-bcee63-55.dhcp.inet.fi) (Ping timeout: 256 seconds)
[10:54:35] *** Joins: artok (~azo@mobile-access-bcee63-55.dhcp.inet.fi)
[10:56:36] *** Quits: BobbyJr (~BobbyJr@robsworld.plus.com) (Quit: Leaving)
[10:57:11] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[10:59:05] *** p_stampy is now known as mrs_mwsb
[11:01:39] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[11:04:37] *** Quits: Hackerpcs (~user@user/hackerpcs) (Quit: Hackerpcs)
[11:08:19] *** Joins: Hackerpcs (~user@user/hackerpcs)
[11:09:16] *** Joins: RV (~RV@lfbn-nic-1-430-119.w90-116.abo.wanadoo.fr)
[11:12:37] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[11:13:36] *** Quits: thanas (~thanas@user/thanas) (Quit: ZNC - https://znc.in)
[11:14:58] *** Joins: thanas (~thanas@user/thanas)
[11:17:38] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[11:26:26] *** Joins: fedenix (~fedenix@gateway/tor-sasl/fedenix)
[11:31:32] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[11:44:03] *** Quits: etienneme (~etienne@176-149-215-214.abo.bbox.fr) (Changing host)
[11:44:03] *** Joins: etienneme (~etienne@user/etienneme)
[11:44:05] *** Quits: mihael (~mihael@2001:4454:2c6:b000:d14b:4683:aa80:97c9) (Quit: Client closed)
[11:46:36] *** Joins: davidv7 (~davidv7@user/videogameenjoyer)
[11:48:46] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[11:53:11] *** Joins: phalanx (~thelounge@user/phalanx)
[11:58:53] *** Joins: TomTom (uid45892@id-45892.charlton.irccloud.com)
[12:00:42] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[12:01:34] *** Joins: iauc (~iauc@ti0061a400-1478.bb.online.no)
[12:02:42] *** Quits: CombatVet (~c4@user/combatvet) (Remote host closed the connection)
[12:03:07] *** Joins: CombatVet (~c4@user/combatvet)
[12:05:14] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[12:07:22] *** Joins: thc202 (~thc202@user/thc202)
[12:11:02] *** Quits: dmalteseknight (~dmaltesek@user/dmalteseknight) (Quit: WeeChat 3.2)
[12:11:14] *** Joins: dmalteseknight (~dmaltesek@user/dmalteseknight)
[12:12:34] *** Quits: kevr (~kevr@user/kevr) (Ping timeout: 240 seconds)
[12:14:11] *** Joins: BobbyJr (~BobbyJr@robsworld.plus.com)
[12:14:55] *** Quits: BobbyJr (~BobbyJr@robsworld.plus.com) (Remote host closed the connection)
[12:15:37] *** Joins: BobbyJr (~BobbyJr@robsworld.plus.com)
[12:17:01] *** Quits: [diablo] (~diablo]@user/diablo/x-9068044) (Ping timeout: 246 seconds)
[12:18:03] *** Joins: kevr (~kevr@user/kevr)
[12:19:01] *** Quits: gschanuel (~gschanuel@user/gschanuel) (Quit: Ping timeout (120 seconds))
[12:21:35] *** Joins: gschanuel (~gschanuel@user/gschanuel)
[12:24:42] *** Quits: arinov (~arinov@213.194.126.155) (Read error: Connection reset by peer)
[12:24:57] *** Joins: arinov (~arinov@213.194.126.155)
[12:29:58] *** Joins: fedenix_ (~fedenix@gateway/tor-sasl/fedenix)
[12:30:29] *** Joins: TomyWork (~TomyLobo@p200300e80f133c006537dd3022c1c4c4.dip0.t-ipconnect.de)
[12:31:48] *** Quits: fedenix (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[12:31:57] *** Joins: varaindemian (~varaindem@86.124.22.31)
[12:33:17] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[12:43:08] *** Quits: XpineX (~XpineX@5.103.80.64.dhcp.fibianet.dk) (Read error: Connection reset by peer)
[12:43:09] *** Quits: samuelbernardo (~samuelber@nata01.lip.pt) (Excess Flood)
[12:43:28] *** Joins: XpineX (~XpineX@5.103.80.64.dhcp.fibianet.dk)
[12:44:56] *** Joins: samuelbernardo (~samuelber@nata01.lip.pt)
[12:51:54] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[13:00:34] *** Joins: scaleww (~scaleww@77-41-20-31.ftth.glasoperator.nl)
[13:04:22] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[13:06:45] *** Joins: mbuf (~Shakthi@122.178.18.181)
[13:07:11] <mbuf> By default the docker daemon can use all CPUs? If I specify --cpuset-cpus, is there a guarantee that docker daemon may not run on these cores?
[13:08:35] *** Joins: AnapodoPsalidaki (~AnapodoPs@2a02:587:2910:6a35:a553:91e6:398:1b01)
[13:09:00] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[13:10:45] <BtbN> A cpuset defines on which cores a process may run, not the other way round
[13:17:22] *** Joins: Lutin (~Lutin@user/lutin)
[13:21:52] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[13:26:33] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[13:34:00] *** Joins: vincent- (~vincent-@cpc87559-seve28-2-0-cust94.13-3.cable.virginm.net)
[13:34:20] *** Quits: dalan6 (~dalan@110-175-157-170.tpgi.com.au) (Ping timeout: 252 seconds)
[13:37:51] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[13:41:44] *** Joins: thiras (~thiras@user/thiras)
[13:56:04] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[14:01:56] *** Quits: Xat` (~Xat`@ns300217.ip-91-121-29.eu) (Quit: Lost terminal)
[14:08:07] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[14:11:19] *** Quits: arinov (~arinov@213.194.126.155) (Quit: Konversation terminated!)
[14:11:37] *** Joins: arinov (~arinov@213.194.126.155)
[14:11:47] *** Joins: Xat` (~Xat`@ns300217.ip-91-121-29.eu)
[14:12:44] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[14:15:04] *** Quits: svm_invictvs_ (~svm_invic@2600:8801:9300:5d:a2db:bdc5:18c1:1186) (Ping timeout: 272 seconds)
[14:18:18] *** Joins: svm_invictvs (~svm_invic@ip72-220-162-92.sd.sd.cox.net)
[14:19:23] *** Joins: SomeWeirdAnon (~shwn@2a02:8109:abf:ffb4:cd28:b713:833e:afa8)
[14:23:26] <mbuf> BtbN, so there is no guarantee of exclusive CPU access?
[14:26:36] *** Quits: c10l (~c10l@89.34.167.207) (Read error: Connection reset by peer)
[14:26:45] *** Joins: [diablo] (~diablo]@user/diablo/x-9068044)
[14:27:15] *** Joins: c10l (~c10l@89.34.167.207)
[14:30:02] <BtbN> What do you mean?
[14:30:21] <BtbN> All you can do with a cpuset is restrict which cores/threads the processes under that cgroup have access to
[14:30:38] <BtbN> unless you apply the opposite cpuset to literally everything else, you by no means are the only user of those cores.
[14:33:44] *** Joins: dalan6 (~dalan@27-32-31-114.tpgi.com.au)
[14:38:08] *** Joins: lemonzest (~lemonzest@user/lemonzest)
[14:39:31] *** Joins: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[14:40:32] *** Joins: Atum_ (IRC@user/atum/x-2392232)
[14:44:50] *** Joins: vidbina (~vid@dynamic-046-114-035-006.46.114.pool.telefonica.de)
[14:58:04] *** Quits: sudomann (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[14:59:04] <mbuf> BtbN, I am coming from isolcpus, and I would like to know if we can do something similar with exclusive CPU cores for running Docker containers
[15:03:09] <BtbN> Not without manually managing cpusets for the whole system
[15:07:38] <mbuf> BtbN, is there some documentation or reference that I can read on the same?
[15:08:02] *** Quits: tazle (tazle@kapsi.fi) (Ping timeout: 272 seconds)
[15:08:39] <BtbN> https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpuset
[15:11:36] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[15:15:51] *** Quits: dmalteseknight (~dmaltesek@user/dmalteseknight) (Ping timeout: 276 seconds)
[15:18:14] <mbuf> BtbN, thanks!
[15:31:04] *** mrs_mwsb is now known as p_stampy
[15:42:54] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[15:44:32] *** Quits: vidbina (~vid@dynamic-046-114-035-006.46.114.pool.telefonica.de) (Ping timeout: 256 seconds)
[15:47:56] *** Quits: luvalon (~luva@178.239.167.169) (Ping timeout: 256 seconds)
[15:49:19] *** Joins: vidbina (~vid@dynamic-046-114-035-006.46.114.pool.telefonica.de)
[15:51:52] *** Quits: mino (~mino@user/mino) (Quit: Bye)
[15:55:47] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[15:55:48] *** Joins: luvalon (~luva@178.239.167.170)
[15:56:24] *** Joins: trevors (~trevors@c-65-96-171-157.hsd1.ma.comcast.net)
[16:00:27] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[16:00:56] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-10-70-54-112-49.dsl.bell.ca)
[16:02:44] *** Quits: arinov (~arinov@213.194.126.155) (Ping timeout: 272 seconds)
[16:12:58] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[16:17:24] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[16:21:27] *** Joins: arinov (~arinov@213.194.126.155)
[16:24:50] *** Joins: rewrit3 (~rewrit3@user/rewrit3)
[16:29:00] *** Quits: vikonen (vikonen@seri.fi) (Quit: Ping timeout (120 seconds))
[16:29:18] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[16:30:20] <Lutin> mhh my swarm healed itself again... weird
[16:39:48] *** Quits: iauc (~iauc@ti0061a400-1478.bb.online.no) (Quit: Client closed)
[16:40:10] <Lutin> Mhh it actually didn't... it doesnt start containers on one of my nodes
[16:40:17] <Lutin> when deploying
[16:41:53] <aab_> every time i look in here your the last person always to speak
[16:41:54] <aab_> lol
[16:48:09] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[16:48:37] <Lutin> aab_ I'm just always online
[16:48:42] <Lutin> or at least a lot
[16:48:48] <Lutin> and I like to babble
[16:49:02] <Lutin> if you spawn it some other have the same issues
[16:49:05] <Lutin> share
[16:51:15] *** Quits: varaindemian (~varaindem@86.124.22.31) (Quit: Client closed)
[16:54:03] <Lutin> aab_ evertime I see someone responding without any context it's just you :P
[16:54:26] *** Joins: wolfshappen (~waff@irc.furworks.de)
[16:59:56] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[17:01:09] *** Quits: arinov (~arinov@213.194.126.155) (Ping timeout: 276 seconds)
[17:01:57] *** Quits: wolfshappen (~waff@irc.furworks.de) (Quit: later)
[17:02:14] *** Quits: mbuf (~Shakthi@122.178.18.181) (Quit: Leaving)
[17:02:22] *** Joins: wolfshappen (~waff@irc.furworks.de)
[17:03:53] *** Quits: OPK (~OPK@user/opk) (Ping timeout: 252 seconds)
[17:04:26] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[17:05:21] *** Joins: vikonen (vikonen@seri.fi)
[17:09:20] *** Joins: Trieste (T@user/pilgrim)
[17:13:56] *** Joins: Trieste_ (T@user/pilgrim)
[17:15:27] *** Quits: Trieste (T@user/pilgrim) (Ping timeout: 276 seconds)
[17:20:00] *** Joins: OPK (~OPK@user/opk)
[17:22:18] *** Quits: vidbina (~vid@dynamic-046-114-035-006.46.114.pool.telefonica.de) (Ping timeout: 272 seconds)
[17:24:46] <Lutin> artok ping
[17:32:37] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[17:51:55] *** Quits: thiras (~thiras@user/thiras) (Remote host closed the connection)
[17:52:30] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 276 seconds)
[17:54:17] *** Joins: thiras (~thiras@user/thiras)
[18:00:31] *** Quits: pvdp (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au) (Remote host closed the connection)
[18:03:47] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[18:08:46] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[18:18:35] *** Joins: sebastianos (~sebastian@user/sebastianos)
[18:19:43] *** Quits: bsf (~bsf@user/bsf) (Quit: wing wang wow)
[18:19:58] *** Quits: OPK (~OPK@user/opk) (Ping timeout: 258 seconds)
[18:20:03] *** Joins: bsf (~bsf@user/bsf)
[18:23:20] *** Quits: travisghansen (~travisgha@192.74.130.86) (Quit: Ping timeout (120 seconds))
[18:23:39] *** Joins: travisghansen (~travisgha@192.74.130.86)
[18:26:09] *** Quits: dlam (~dlam@dlam.me) (Ping timeout: 268 seconds)
[18:31:49] <Lutin> has anyone seen that --dns is not respected and resolv.conf is still 127.0.0.11 ?
[18:34:58] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[18:39:32] <programmerq> --dns sets what the upstream resolvers will be, but 127.0.0.11 is still used so that service discovery works.
[18:46:16] *** Joins: oxum (~oxum@136.185.133.224)
[18:48:23] *** Joins: Atum__ (IRC@user/atum/x-2392232)
[18:51:00] *** Quits: oxum (~oxum@136.185.133.224) (Ping timeout: 276 seconds)
[18:52:18] *** Quits: Atum_ (IRC@user/atum/x-2392232) (Ping timeout: 276 seconds)
[18:53:08] *** Joins: dlam (~dlam@dlam.me)
[18:53:13] *** Joins: arinov (~arinov@213.194.126.155)
[18:57:18] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 272 seconds)
[18:58:10] *** Quits: yamchah2 (~yamchah2@user/yamchah2) (*.net *.split)
[18:58:10] *** Quits: fspy (~fspy@user/fspy) (*.net *.split)
[18:58:10] *** Quits: toinen (~kvirc@user/yksi) (*.net *.split)
[18:58:10] *** Quits: twiclo (~twiclo@2604:7b80:2000:1069:52fc:cedd:fbeb:10c) (*.net *.split)
[18:58:10] *** Quits: Alina-malina (~Alina-mal@user/alina-malina) (*.net *.split)
[18:58:10] *** Quits: sshine (~simon@hubris.eta.solutions) (*.net *.split)
[18:58:10] *** Quits: Vazomi (~Vazomi@i100135.upc-i.chello.nl) (*.net *.split)
[18:58:10] *** Quits: nebiros (nebiros@user/nebiros) (*.net *.split)
[18:58:10] *** Quits: dostoyevsky2 (~sck@user/dostoyevsky2) (*.net *.split)
[18:58:10] *** Quits: nrg (~NRG@user/nrg) (*.net *.split)
[18:58:10] *** Quits: foka (~foka@162.208.172.172) (*.net *.split)
[18:58:10] *** Quits: mossman93_ (~quassel@user/mossman93) (*.net *.split)
[18:58:10] *** Quits: L0j1k (~L0j1k@user/l0j1k) (*.net *.split)
[18:58:10] *** Quits: Church (~aleph@pool-98-116-232-112.nycmny.fios.verizon.net) (*.net *.split)
[18:58:10] *** Quits: bastelfreak (~bastelfre@basteles-bastelknecht.bastelfreak.org) (*.net *.split)
[18:58:10] *** Quits: wyre (~wyre@user/wyre) (*.net *.split)
[18:58:10] *** Quits: Byteflux (~byte@byteflux.net) (*.net *.split)
[18:58:15] *** Joins: dostoyevsky2 (~sck@user/dostoyevsky2)
[18:58:18] *** Joins: sshine (~simon@hubris.eta.solutions)
[18:58:24] *** Joins: mossman93 (~quassel@user/mossman93)
[18:58:28] *** Joins: yamchah2 (~yamchah2@user/yamchah2)
[18:58:28] *** Joins: Byteflux (~byte@byteflux.net)
[18:58:37] *** Joins: nebiros (nebiros@user/nebiros)
[18:58:37] *** Joins: wyre_ (~wyre@user/wyre)
[18:58:37] *** Joins: n000g (~NRG@user/nrg)
[18:58:53] *** Joins: Vazomi (~Vazomi@i100135.upc-i.chello.nl)
[18:59:15] *** Joins: Church (~aleph@pool-98-116-232-112.nycmny.fios.verizon.net)
[18:59:26] *** Quits: arinov (~arinov@213.194.126.155) (Ping timeout: 272 seconds)
[18:59:33] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[19:00:09] *** Joins: foka (~foka@162.208.172.172)
[19:00:25] *** Joins: toinen (~kvirc@user/yksi)
[19:00:28] *** Joins: Alina-malina (~Alina-mal@user/alina-malina)
[19:03:20] <aab_> Lutin Good comeback I like it lol
[19:06:30] *** Quits: gschanuel (~gschanuel@user/gschanuel) (Read error: Connection reset by peer)
[19:24:41] <artok> pong
[19:34:06] *** Joins: The_Loko (~The_Loko@86.127.235.231)
[19:39:53] *** Joins: mattchis (~mattchis@c-73-243-45-46.hsd1.co.comcast.net)
[19:42:32] *** Quits: CB_JD (~Code_Bleu@user/code-bleu/x-6939963) (Ping timeout: 256 seconds)
[19:44:34] *** Joins: CB_JD (~Code_Bleu@user/code-bleu/x-6939963)
[19:47:01] *** Joins: vidbina (~vid@dynamic-089-012-234-121.89.12.pool.telefonica.de)
[19:54:40] *** Quits: AnapodoPsalidaki (~AnapodoPs@2a02:587:2910:6a35:a553:91e6:398:1b01) (Quit: Leaving)
[19:55:20] *** Quits: trevors (~trevors@c-65-96-171-157.hsd1.ma.comcast.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[20:02:09] *** wyre_ is now known as wyre
[20:20:06] *** Quits: Trieste_ (T@user/pilgrim) (Ping timeout: 255 seconds)
[20:20:44] *** Joins: varaindemian (~varaindem@86.124.22.31)
[20:25:58] *** Joins: mearp (~mearp@154.13.1.102)
[20:26:16] <mearp> anyone know the most common cause for seeing these errors inside containers: "getaddrinfo ENOTFOUND"
[20:26:28] <mearp> ?
[20:26:54] <ada_> mearp: if your containers fail to resolve DNS queries, usually that's iptables related
[20:27:10] <ada_> mearp: potentially firewall or outgoing proxy
[20:27:55] <mearp> this all happening on a local machine
[20:28:03] <ada_> ok
[20:28:12] <ada_> that doesn't negate the above
[20:28:19] <ada_> but its good data point
[20:28:33] <mearp> I thought it might be related to a local dns server I was using (dnsmasq) but I've disabled that
[20:28:40] <ada_> well it could and couldn't
[20:29:40] <ada_> you haven't shown enough information to fully debug the problem. generally, a container that makes a dns request would get forwarded to the docker daemon, which reads your host's /etc/resolv.conf to find your upstream nameservers
[20:29:49] <ada_> so ostensibly, something in that pathway is not working correctly
[20:30:16] <ada_> what is in your /etc/resolv.conf?  can you show copy-paste from your terminal showing how you encountered this error?  how did you run your container?  is it a container or is it a swarm replicated service?
[20:30:26] <ada_> use pastebin/gist and share any relevant info you can
[20:31:07] <mearp> I should add...
[20:31:23] <mearp> this is happening when containers on the same network are trying to communicate
[20:31:39] <mearp> I can ping by ip address but not by name
[20:31:42] <ada_> so instead of my having to play the game of 20 questions, just put all the info into a paste up front
[20:33:06] *** Quits: svm_invictvs (~svm_invic@ip72-220-162-92.sd.sd.cox.net) (Read error: Connection reset by peer)
[20:34:08] *** Joins: svm_invictvs (~svm_invic@2600:8801:9300:5d:e451:8cd8:c964:82fd)
[20:37:56] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[20:41:44] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Quit: WeeChat 3.0.1)
[20:49:49] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[20:59:04] <Lutin> is it possible to log why a node doesn't get deployed with a container in swarm?
[21:08:04] <ada_> Lutin: docker service ps --no-trunc $service
[21:08:16] <ada_> should show you scheduling-related reasons why a task isn't running
[21:09:10] <ada_> but the question is confusing as written: why doesn't a node get deployed....  I think you mean, is it possible to find out why swarm chose to schedule a task on a certain node, to which the answer is "not really"
[21:09:35] <ada_> if a task fails to schedule because of some reason, it may be in the manager daemon logs for certain reasons, but it may be in the "service ps" output for Other reasons
[21:09:56] <ada_> the reasons why a task may fail to schedule are varied, and depending on the problem, it may or may not get logged or surfaced to the user
[21:10:46] <ada_> and the version of docker matters, too;  early versions of docker would not show an error when you ran out of IP address space on the network.  you'd just see tasks stuck in "Creating" forever.
[21:11:01] <ada_> if you dug into the daemon logs of teh managers you might find the IP space exhaustion IF you had your log level turned up
[21:11:13] <ada_> but ex post facto, not its not very easy to find out why task scheduling failed sometimes
[21:14:59] *** Quits: TomyWork (~TomyLobo@p200300e80f133c006537dd3022c1c4c4.dip0.t-ipconnect.de) (Remote host closed the connection)
[21:20:56] *** Joins: libcat (~quassel@2a01:4f8:c2c:2b3a::1)
[21:20:59] *** Joins: hposca (~hposca@node-1w7jr9phoke2td1e507xtdn5o.ipv6.telus.net)
[21:21:13] <Lutin> ada_ ok good that explains a lot :D
[21:21:24] <Lutin> thanks
[21:21:36] <Lutin> never refactor a cluster :D
[21:25:16] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Remote host closed the connection)
[21:31:44] *** Joins: Jimmy_H_ (~Jimmy_H@119.136.152.25)
[21:34:44] *** Quits: Jimmy_H (~Jimmy_H@119.136.152.25) (Ping timeout: 256 seconds)
[21:36:47] *** Quits: Jimmy_H_ (~Jimmy_H@119.136.152.25) (Ping timeout: 245 seconds)
[21:39:33] *** Joins: trevors (~trevors@c-65-96-171-157.hsd1.ma.comcast.net)
[21:44:59] *** Joins: SJrX (~sjr@S0106302303dfb018.vf.shawcable.net)
[21:46:08] *** Quits: varaindemian (~varaindem@86.124.22.31) (Quit: Client closed)
[21:50:55] <artok> I still guess you've not drawn your cluster as a map ;)
[22:01:53] *** Quits: scaleww (~scaleww@77-41-20-31.ftth.glasoperator.nl) (Quit: Leaving)
[22:03:41] *** Joins: CodeSpelunker (~CodeSpelu@user/codespelunker)
[22:05:25] *** Joins: Sasazuka (~Sasazuka@user/sasazuka)
[22:06:44] *** Joins: blackwood821_ (~blackwood@user/blackwood821)
[22:07:53] <blackwood821_> Hi, I have a docker-compose.yml file with an nginx service and nginx-prometheus-exporter service but the nginx-prometheus-exporter service can't reach nginx via the URL that I'm passing in via -nginx.scrape-uri
[22:08:19] <blackwood821_> I'm using htpp://nginx/stub since the nginx container name is "nginx" and inside the nginx container I can curl that URL
[22:09:53] <ada_> what kind of error message do you get from the exporter
[22:10:07] <blackwood821_> "Could not create Nginx Client: failed to get http://nginx:80/stub: Get "http://nginx:80/stub": dial tcp: lookup nginx on 127.0.0.11:53: no such host"
[22:10:10] <ada_> in other words, what does "can't reach" mean.  connection reset, 50x error, etc.
[22:10:18] <ada_> ah so "no such host" is a dns failure
[22:10:34] <ada_> are you deploying using swarm or plain old containers?
[22:10:41] <blackwood821_> I don't have a link defined in my docker compose file but isn't that only necessary if I want to use a hostname other than the nginx container name?
[22:10:52] <blackwood821_> Currently just plain old containers
[22:10:59] <ada_> you don't need to use --link ever anymore
[22:11:01] <programmerq> links are deprecated and you can completely ignore them.
[22:11:10] <ada_> any two containers on the same docker network can resolve each other by their service name
[22:11:20] <ada_> compose will put your containers on the same network by default, if you're using compose
[22:11:31] <ada_> if you wanted to use a hostname other than the service name, there's a key for that
[22:11:37] <blackwood821_> Ok good to know
[22:11:55] <programmerq> make sure you're using v2 or v3 syntax for the compose file too.
[22:12:31] <ada_> yeah you might as well show us your compose file and your app config where you set up the hostnames
[22:14:45] <blackwood821_> Ok I was missing the docker compose version in the compose file since the documentation said it's no longer needed but I just added back in "version: '3'
[22:14:47] <blackwood821_> Now I get "connect: no route to host"
[22:14:52] <blackwood821_> I'll post the file now
[22:15:44] <blackwood821_> https://gist.github.com/blackwood821/3f1ab6b4cc7a06e1882f13578512262d
[22:16:52] <ada_> use soemthing like 3.7
[22:17:03] <ada_> 3.0 is a quite old version number
[22:17:26] *** Quits: luvalon (~luva@178.239.167.170) (Ping timeout: 272 seconds)
[22:17:31] <ada_> you may not be using the most recent features of the newer syntaxes, but to eliminate potential issues, use the most recent version that's available
[22:18:42] <ada_> if you `docker exec` into your nginx container and get a shell, can you `ping nginx-exporter` and vice versa
[22:19:53] <blackwood821_> Just tried version 3.9 and get the same result.
[22:19:56] <blackwood821_> It says ping is not installed
[22:20:02] <ada_> install it
[22:21:12] <Lutin> are there some people running swarm with 2 nodes ? I tested it, seems to go fine but I'm not 100% sure. Quorem is always nicer but I might have a latency issue between DC's ...
[22:21:30] <ada_> Lutin: you don't have to qualify your question with "does anyone do X"
[22:21:31] <Lutin> *Quorum
[22:21:40] <ada_> it may work until one of your managers goes down then it wont
[22:21:58] <ada_> your services will continue to work but you won't be able to make changes to the cluster anymore
[22:22:13] <Lutin> ada_ that is why I asked if someone does it... because in IT most people are shy to tell what they did and actually should not do :)
[22:22:29] <Lutin> ada_ yeah that is the issue
[22:22:32] <ada_> what is the issue...
[22:23:07] *** Joins: luvalon (~luva@178.239.173.200)
[22:23:33] *** Quits: vidbina (~vid@dynamic-089-012-234-121.89.12.pool.telefonica.de) (Ping timeout: 276 seconds)
[22:23:34] <Lutin> I wonder what max latency could be between swarm nodes. Sure you depend on mounts but that is the issue. cannot gluster replicate over more then 10ms because everything becomes slow like crazy on files but what about just mount remote, that could be doable
[22:23:36] <ada_> "quorum is always nicer" a quorum is the condition of having a majority of members present and available to vote;  there's no "niceness" about having a quorum, you are either in the condition of having a quorum or you are not;  if you do not, you cannot make changes to the cluster. 
[22:23:44] <ada_> max latency between nodes should be as low as possible
[22:23:51] <Lutin> My latency is ~25ms on the 3rd node
[22:23:57] <Lutin> ada_ sure
[22:24:31] <Lutin> ada_ yeah I like quorums but always looking further :)
[22:24:44] <Lutin> or does size matter ?I thought it didn't
[22:24:52] <ada_> 1,3,5;  pick one
[22:25:02] <Lutin> yeah I know
[22:25:06] <Lutin> 1 is not a quorum
[22:25:11] <Lutin> it's a singleron :)
[22:25:16] <Lutin> *singleton
[22:25:24] <ada_> 1 is a quorum when 1 is the size of the party
[22:25:33] <ada_> 2 is a quorum when the party size is 3
[22:25:36] <Lutin> in IT that is not a party at all!
[22:26:25] <Lutin> ada_ would you mount over 25ms ? mhh I don't feel comforatable actually. I use it for gluster GEO replication but that's about it...
[22:28:16] *** Quits: levifig (~levi@mt.levifig.com) (Ping timeout: 250 seconds)
[22:28:31] <blackwood821_> ada_: I added a second nginx container named "nginx2" and when I exec into that container I can `ping nginx` without issue but neither nginx container can `ping nginx-exporter` because that container exits right away due to the error I encounter
[22:29:25] <blackwood821_> So if the nginx2 container can ping the nginx container, I'm not sure why the nginx-exporter container can't unless "-nginx.scrape-uri" is supposed to be a URI from the Docker host's perspective?
[22:29:59] <ada_> what is "A URI from the docker host's perspective"?
[22:30:10] <ada_> like, what do you imagine that looks like and how is it different from what you are using now
[22:30:50] <ada_> suffice it to say, that command is going to get executed inside the container, so whatever you use for URI should be in the context of the container network
[22:31:11] <ada_> are you sure that flag takes a single - ?  are there other things to look at like the ccontainer logs of the exporter?
[22:31:27] *** Joins: Trieste (~T@user/pilgrim)
[22:31:47] *** Quits: luvalon (~luva@178.239.173.200) (Ping timeout: 245 seconds)
[22:32:46] *** Quits: fedenix_ (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[22:32:55] *** Joins: fedenix_ (~fedenix@gateway/tor-sasl/fedenix)
[22:34:06] *** Joins: ras_manny (~ras_manny@196.24.136.255)
[22:34:46] *** Joins: luvalon (~luva@178.239.167.170)
[22:35:28] <blackwood821_> ada_: I got the original error I posted from the nginx-exporter container logs. Seems like the correct URI then
[22:35:54] <blackwood821_> The examples on https://hub.docker.com/r/nginx/nginx-prometheus-exporter use "-nginx.scrape-uri=http://<nginx>:8080/stub_status"
[22:36:32] <blackwood821_> Only difference for me is that I'm using port 80 in the nginx container and my nginx config exposes the status page at /stub
[22:36:48] <blackwood821_> So http://nginx/stub or http://nginx:80/stub should work
[22:38:25] <ada_> well you didn't get a 404
[22:38:36] <ada_> so I wouldn't assume it's because of a problem with the web server returning a resource that doesn't exist
[22:39:09] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 255 seconds)
[22:39:12] <ada_> what was the error again?
[22:39:32] <ada_> nginx-exporter fails with: no route to host.  so to me, that
[22:39:54] <ada_> that's a more fundamental problem with container networking
[22:40:06] <blackwood821_> "2021/07/13 18:03:44 Could not create Nginx Client: failed to get http://nginx/stub: Get "http://nginx/stub": dial tcp 172.240.8.4:80: connect: no route to host"
[22:40:46] <ada_> yeah, so, why can't this container route to other...  maybe start up nginx-exporter and override the command to run something like "sleep 3600"
[22:40:54] <ada_> that would give you time to `docker exec` into it and debug a little bit
[22:41:12] <blackwood821_> Ok I'll try that out
[22:41:20] <ada_> I would be doing 1) ping nginx and 2) make a tcp connection to nginx, so something like `curl http://nginx/stub`
[22:42:01] <ada_> oh oh
[22:42:07] *** Joins: jamiejackson (~jamiejack@207.172.87.34)
[22:42:16] *** Joins: finsternis (~X@23.226.237.192)
[22:42:16] <ada_> you are publishing port 80, but that's not necessarily what the server is configured to do inside the container.  
[22:42:27] <ras_manny> My volume isn't persisted when I run "docker-compose up -d --build && docker-compose logs -f"....meanwhile "docker volume ls" returns "up-web_postgres_data" along with the other volumes. How can I start debugging this?
[22:42:31] <ada_> why do the examples on that page use 8080? is it because by default, the status endpoint is set up on 8080?
[22:43:15] <ada_> remenber that your port publishing rules only affect connections coming from outside the docker network;  so any ports that the app listens on "internally" w/r to the docker network are the same
[22:43:50] <ada_> ras_manny: show some evidence from your termianl with before/after comparison and the commands you ran -showing- that the volume isn't persisted
[22:43:52] *** Quits: luvalon (~luva@178.239.167.170) (Ping timeout: 256 seconds)
[22:44:39] <ada_> ras_manny: think of all the things that someone like me would want to see on a screen share, and put them in a pastebin
[22:45:20] *** Joins: luvalon (~luva@178.239.173.201)
[22:46:16] <ras_manny> ok
[22:46:55] <blackwood821_> ada_: I'm not sure why the examples use port 8080 for NGINX but my nginx container is configured to listen on port 80 internally inside the container. I can run `curl http://nginx:8080/stub` inside both the nginx and nginx2 containers and get the results back so port 80 should be correct
[22:47:12] *** Quits: Trieste (~T@user/pilgrim) (Ping timeout: 245 seconds)
[22:48:01] *** Joins: Trieste (T@user/pilgrim)
[22:48:10] <blackwood821_> ada_: I just found this https://stackoverflow.com/a/65070019 but I'm not sure why that 3rd port mapping is necessary and why 127.0.0.1 is used instead of the container name
[22:49:02] <ada_> lots of bad answers out there
[22:50:09] <ada_> you just said "I ran curl http://8080/stub" but said "port 80 should be correct"
[22:50:12] <ada_> that doesn't add up
[22:50:27] <ada_> you have a server block that listens on port 80
[22:50:55] <ada_> but docs say teh stub_status page is available on port 8080 by default
[22:51:14] <ada_> I would change your compose file to use the URI http://nginx:8080/stub and see what happens
[22:51:31] <blackwood821_> Sorry, I pasted the wrong URL. I can curl http://nginx/stub but not http://nginx:8080/stub
[22:52:08] <ada_> then maybe it has to do with a race condition on container startup
[22:52:19] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[22:52:23] <ada_> add a depends_on: section to your nginx-exporter and make it depend on nginx;  that way compose will try to get the nginx container up first.
[22:52:51] <ada_> it won't actually wait for nginx to be ready, but it will try to make sure the container exists before starting nginx-exporter, which may help with the "no route" issue
[22:53:12] *** Joins: neilhwatson (~neilhwats@cpe44d9e7ffded8-cm68b6fcf73540.cpe.net.cable.rogers.com)
[22:55:02] <neilhwatson> What does this error mean? "failed to get top layer from image: layer does not exist"
[22:55:19] <ada_> neilhwatson: how did you encounter it?
[22:55:30] <ada_> there's a layer that should be part of your image that you do not have.
[22:55:35] <doc> neilhwatson: during a pull or a build?
[22:55:35] <ada_> I'd rebuild or re-pull the image
[22:55:39] <neilhwatson> context https://gist.github.com/neilhwatson/6828a7d509b7647a4c1bc61a96391ccb
[22:56:18] <blackwood821_> ada_: adding `depends_on` worked
[22:56:21] <blackwood821_> Thanks!
[22:56:35] <ada_> blackwood821_: nice
[22:56:54] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 256 seconds)
[22:57:07] <ada_> neilhwatson: is the registry really at $url/neil/neil?  or is it at $url?
[22:57:13] <ada_> and is neil/neil the image namespace 
[22:57:18] <neilhwatson> yep
[22:57:27] <ada_> there was 2 questions in there
[22:57:44] <neilhwatson> yes x 2
[22:57:50] <ada_> it can't be both
[22:58:05] <neilhwatson> These exact commands worked yesterday.
[22:58:21] <ada_> ok
[22:58:47] <neilhwatson> Is the error from docker or the registry?
[22:59:11] <ada_> looks like docker engine
[23:01:37] <ras_manny> @ada_ this is an update gist https://gist.github.com/theSekyi/8ba0df52551b9b401492986754ffc789
[23:03:00] <ada_> ras_manny: so you said it's not being persisted
[23:03:22] <ada_> ras_manny: how do you know it's not being persisted?  i assume something happens in between "docker-compose up" and then ... then your volume is missing?  
[23:03:37] <ras_manny> yes
[23:04:12] <neilhwatson> The docker host had a power outage yesterday. Could there be trouble with docker image records? But it says it pulled. And I tried a system prune too. :/
[23:04:17] <ada_> ras_manny: can you fill in the blanks for me
[23:04:31] <ada_> neilhwatson: its just a manifest that describes layers by hash
[23:04:38] <ada_> neilhwatson: theres not a db or anything internally
[23:04:40] <ras_manny> ada_ When i run docker-compose up -d --build, the data is lost
[23:04:48] <ada_> ras_manny: you'd have to show me 
[23:04:54] <ada_> ras_manny: I can't see any "lost data" from this gist
[23:04:58] <ada_> ras_manny: what does lost data mean?
[23:05:08] <ada_> ras_manny: like, the volume exists... at any point does the volume not exist?
[23:05:19] <ada_> ras_manny: if postgres starts, it should write some files.  are the files still there after your event ?
[23:05:32] <ada_> ras_manny: you need to show me a before/after state showing that something changed after you run some command
[23:05:39] <ras_manny> I think I am skipping steps. Let me go systematically.
[23:05:56] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[23:07:50] <ras_manny> I have a postgres db in a container for a web app. The attached a data volume as shown in the gist above. Assuming I have registered user accounts in my database, anytime I run "docker-compose up -d --build" and a new container is created, I lose the user accounts.
[23:08:07] <ada_> that doesn't jive with the expectations of the postgres image
[23:08:20] <ada_> if postgres starts with no db, it creates one;  if it starts and finds a db already in the volume, it reuses it
[23:08:40] <ada_> but this is not the standard postgres image
[23:08:48] <ada_> you may need to do research about this exact image you're using
[23:09:01] <ada_> maybe there is some implicit behaviour that causes what you're seeing to happen during container startup
[23:09:51] *** Joins: Cleverness (~clevernes@pool-108-54-152-186.nycmny.fios.verizon.net)
[23:09:51] <blackwood821_> ada_: actually, it doesn't work every time with depends_on. Interesting..
[23:10:06] <ada_> blackwood821_: im still thinking it's race condition related, especially if it's intermittent
[23:10:12] <ada_> blackwood821_: curious
[23:10:19] <ras_manny> alright. So you're saying the standard postgres image is likely not to exhibit this behaviour?
[23:10:31] <ada_> ras_manny: well, I know what to expect from the library/postgres image
[23:10:50] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 265 seconds)
[23:10:57] <ada_> ras_manny: but mdillon/postgis:10-alpine may have different expectations
[23:11:39] <ras_manny> ok
[23:11:41] <ada_> the image says it's based on the official postgres
[23:11:47] <ada_> but since it adds things, I can't say any more
[23:11:57] <ada_> you may want to read through the source code of this dockerfile to understand what it's doing
[23:11:58] <ras_manny> I will use the official one
[23:12:06] <ada_> do you need postGIS extensions?
[23:12:48] <ras_manny> Thing is, the prod database uses "image: postgres:12.0-alpine" yet it exhibits the exact same behavior
[23:12:55] <ras_manny> yes I do
[23:13:28] <ada_> so thats 2 data points that form a pattern
[23:13:35] <ada_> ah wait
[23:13:38] <ada_> I misread your comment
[23:13:56] <ada_> I can't really say what goes on with that other image without data
[23:14:10] <ada_> but yeah, I am failry certain you have a problem somewhere
[23:14:17] <ada_> the postgres official image doesn't clean itself up
[23:14:23] <ada_> also, it doesn't clean up on startup
[23:14:43] <ada_> like, the way it's supposed to work is postgres container starts, if there is no database there, it creates a new one.  at no point does it delete itself, that would break any existing database
[23:15:14] <ada_> so something in your assumptions must be wrong, because we know that the expectation is that the postgres image should just start and read from /var/lib/postgres and start up the db
[23:15:34] <ada_> maybe you need to define a database and database user?
[23:15:48] <ras_manny> ok
[23:16:48] <ada_> I'd review https://registry.hub.docker.com/_/postgres/
[23:16:50] <ada_> the readme
[23:20:32] <ras_manny> alright, thanks
[23:20:33] <ada_> its interesting nonetheless
[23:20:42] <ada_> I haven't run into that before with the library/postgres image
[23:24:03] <ras_manny> I found the problem on the local machine. I have a line in my Dockerfile's entrypoint which cleared the database on the host. That was the issue so even with "mdillon/postgis" the data persists. I will now investigate that of production
[23:24:09] <ras_manny> Thanks for the leads
[23:24:11] <ada_> sure thing
[23:25:33] <neilhwatson> Definitely on the docker side.  Tried via docker build, no push https://gist.github.com/neilhwatson/3ca9c8f94db6bd44f286c936bcd3ab34
[23:28:51] <neilhwatson> It says the image is up to date, but docker images -a lists zero images O_o
[23:29:11] *** Quits: fedenix_ (~fedenix@gateway/tor-sasl/fedenix) (Quit: Good bye everyone!)
[23:29:27] *** Joins: fedenix_ (~fedenix@gateway/tor-sasl/fedenix)
[23:29:33] *** fedenix_ is now known as fedenix
[23:30:42] <programmerq> neilhwatson▸ is this a normal docker install, or is this running inside some sort of cicd system? Could each docker command be routed to a different dockerd backend or something?
[23:31:33] <programmerq> run 'docker info' several times and make sure the ID in the server section is the same on each invocation?
[23:31:38] <neilhwatson> only one docker host. And can duplicate from the shell.
[23:32:17] <neilhwatson> In the shell 'docker pull alpine' says it's up to date.  'docker images -a' returns no images.
[23:38:42] *** Joins: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net)
[23:44:54] <programmerq> what version of docker? what storage backend?
[23:45:20] <neilhwatson> Docker version 20.10.2, build 20.10.2-0ubuntu1~20.04.2
[23:45:45] <neilhwatson> probably default backend, but how to check?
[23:50:10] *** Quits: thegodsquirrel (~thegodsqu@ec2-34-224-15-9.compute-1.amazonaws.com) (Changing host)
[23:50:10] *** Joins: thegodsquirrel (~thegodsqu@user/thegodsquirrel)
[23:50:27] *** Joins: mino (~mino@user/mino)
[23:51:53] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-10-70-54-112-49.dsl.bell.ca) (Quit: ERC (IRC client for Emacs 27.2))
[23:52:38] <neilhwatson> if docker images returns nothing, should /var/lib/docker/image/ be empty?
[23:55:13] *** Joins: wolfdale (~wolfdale@ec2-3-1-90-26.ap-southeast-1.compute.amazonaws.com)
[23:57:37] *** Quits: sudomann_ (~sudomann@c-73-133-131-19.hsd1.md.comcast.net) (Ping timeout: 245 seconds)
