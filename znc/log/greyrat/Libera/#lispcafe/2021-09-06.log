[00:02:06] *** Joins: APic (apic@apic.name)
[00:10:38] *** Joins: selwyn (~selwyn@user/selwyn)
[00:10:49] <selwyn> https://nitter.net/Kevin_Church/status/1434568713735340035#m vibing
[00:10:50] -ixelp- Kevin Church (@Kevin_Church): "Look at this fancy lad." | nitter
[00:13:21] <selwyn> https://nitter.net/WilliamShatner/status/1434563850930511874#m lol
[00:13:22] -ixelp- William Shatner (@WilliamShatner): "🙄#nerd" | nitter
[00:21:47] *** Joins: selwyn12 (~selwyn@user/selwyn)
[00:24:17] *** Quits: selwyn (~selwyn@user/selwyn) (Ping timeout: 245 seconds)
[00:30:09] <edgar-rft> this is how assembly magic looks like -> https://ibb.co/YLH0CQR
[00:30:09] -ixelp- the-universal-code-of-computer-law — ImgBB
[00:39:00] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[00:53:01] *** Quits: robin (~robin@user/terpri) (Read error: Connection reset by peer)
[01:13:02] *** Quits: SAL9000 (~SAL9000@shirakumo/sal9000) (Quit: WeeChat 3.1)
[01:13:16] *** Joins: SAL9000 (~SAL9000@shirakumo/sal9000)
[01:13:52] *** Quits: shka (~herr@109.231.62.239) (Ping timeout: 252 seconds)
[01:17:24] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[01:32:21] *** Quits: selwyn12 (~selwyn@user/selwyn) (Quit: Connection closed)
[02:24:10] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 240 seconds)
[02:39:59] *** Quits: lisp123 (~lisp123@5.30.23.247) (Remote host closed the connection)
[02:40:38] *** Joins: lisp123 (~lisp123@5.30.23.247)
[02:45:43] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[02:48:33] *** Joins: dec0d3r (~dec0d3r@2001:8003:4810:9600:7275:1afb:1707:8eaa)
[02:52:30] <hayley> Now Gil Tene follows me on Twitter.
[02:55:32] *** Joins: kakuhen (~kakuhen@user/kakuhen)
[02:57:02] <hayley> So, hypothetically, the Immix collector runs acceptably without compacting. If we still have a compacting newspace, I think fragmentation won't be much of an issue.
[02:58:10] <hayley> One may ask why I want a mark-region collector then; it's so that I can basically just hand off a region to the global GC without having to move objects as part of changing the heap layout.
[02:58:35] <hayley> And thus no read barrier, of course.
[02:59:28] <edgar-rft> can we have a mark-region collector for the internet please?
[03:06:01] <hayley> Distributed GC is another pile of pain.
[03:11:17] <hayley> OTOH my trick is that I can pull competely free regions to use for thread-local heaps out of thin air, which can't be reused without compaction (assuming that it's quite rare for a region to be completely empty, cause it is).
[03:16:28] *** Joins: lisp123 (~lisp123@5.30.23.247)
[03:26:17] <hayley> https://www.youtube.com/watch?v=LbVvYuzbk-A
[03:26:17] -ixelp- Warriors (Full Length Version) - YouTube
[03:33:08] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 256 seconds)
[03:45:02] *** Quits: dra (~dra@2a04:4540:6405:600:149e:23ae:c2d3:52a7) (Ping timeout: 256 seconds)
[03:53:24] *** Joins: dra (~dra@2a04:4540:640e:9b00:149e:23ae:c2d3:52a7)
[04:02:56] <hayley> .oO( Doesn't a branch predictor basically do type inference if you branch on the type tag? )
[04:05:44] <hayley> .oO( So...we rely on the branch predictor and out of order/speculative execution to assume the read barrier won't trip still? )
[04:10:30] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Ping timeout: 276 seconds)
[04:12:08] *** Quits: dra (~dra@2a04:4540:640e:9b00:149e:23ae:c2d3:52a7) (Quit: Leaving)
[04:12:50] *** Quits: emacsomancer (~emacsoman@136.60.128.68) (Quit: WeeChat 3.2)
[04:13:25] *** Joins: recordgroovy (~recordgro@50.35.20.8)
[04:13:54] *** Joins: emacsomancer (~emacsoman@136.60.128.68)
[04:14:14] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[04:35:30] <hayley> It seems that my laptop simply does not care for the bogus memory read, even with a tag test.
[04:36:54] <hayley> https://plaster.tymoon.eu/view/2620
[04:37:56] <gilberth> The bogus read should cause a page fault?
[04:39:15] <hayley> If I needed to compact, yes.
[04:40:33] <hayley> And (with GCC 9.3.0) the bogus read remains in disassembly output, even when cdr is inlined.
[04:40:47] <gilberth> Ok. I doubt speculation would continue in that version of the universe in case of a fault.
[04:41:22] <hayley> Right. But I don't mind, as that is the slow "path".
[04:41:45] <hayley> "Anyone have any programming experience, if not Python?" "We did Java in bootcamp. Yeah, Java... Big C fan here--SELF!"
[04:42:27] <gilberth> hayley: You said volatile. There shouldn't be any need for inline assembler though. Have you tried *(volatile int *)(...)?
[04:42:53] <hayley> Didn't know you could do that. And last time someone used volatile, they made a broken benchmark.
[04:43:19] <gilberth> hayley: Well, that speculation stops is a good thing, because it won't hog resources for the fast path being computed in parallel.
[04:43:36] <hayley> Yes, that's the aim of the game.
[04:43:46] <gilberth> hayley: volatile is volatile :)
[04:43:49] <hayley> It's hardware acceleration when you can't get new hardware.
[04:47:11] <hayley> "PyCharm is the best" "How did you misspell Emacs that badly?"
[04:47:21] <gilberth> But what you read is the car, isn't it?
[04:47:37] <gilberth> How could that fault?
[04:47:53] <hayley> It would fault if I had protected the page.
[04:48:20] <gilberth> Reading the cdr would fault then before that.
[04:48:59] <gilberth> The asm is like "bogus = list->car", isn't it?
[04:49:11] <hayley> I assume objects don't straddle regions, and that memory is protected at region granularity. So reading either would fault if the other would. 
[04:49:14] <hayley> Yes.
[04:51:18] <gilberth> Then, I don't get it. What's the point to have a conditional second fault?
[04:52:17] <hayley> The point is to implement a "load value barrier", so that the program (outside cdr) can't see a pointer which points to regions we need to relocate.
[04:52:34] <gilberth> [I prefer "int *x" to "int* x", because the "*" is attached to "x" not "int" syntax-wise]
[04:54:51] <gilberth> hayley, both the car and cdr are in the same region, I presume. So either can read both or none. Still don't get it. How does reading the car itself prevent code outside to see a pointer to the cons? I mean, the pointer to the cons is already passed to the 'cdr' routine.
[04:55:51] <hayley> Oh, that is supposed to be a read to bare->car (where I was considering swizzling bare to force a read, but decided against it).
[04:56:34] <gilberth> Well, bare->car would make sense to me. But list->car does not.
[04:57:00] <hayley> Yeah, it is meant to be bare->car. That doesn't make anything slower either, though I also test that bare != NULL now.
[04:59:46] <gilberth> Ok. Tried it. "*(void * volatile *)(bare);" isn't removed by GCC.
[05:00:39] <gilberth> Neither by clang.
[05:01:09] <hayley> Nice.
[05:01:42] <hayley> I changed the definition of cdr in the previous paste link.
[05:05:25] <gilberth> [And notice that *(volatile void **)(bare) won't work. This is why I don't like "int* x". :-p ]
[05:07:12] *** Quits: random-nick (~random-ni@87.116.179.72) (Ping timeout: 256 seconds)
[05:10:35] <gilberth> But I now get a page fault. Hmm.
[05:11:00] <hayley> Interesting, I can get a $10,000 kick starter prize for pitching some business idea.
[05:12:03] <hayley> "CLOSOS money please" "How can you commercialise it?" "...put it on servers I guess?"
[05:13:20] *** Quits: MichaelRaskin (~MichaelRa@ipb21b6221.dynamic.kabel-deutschland.de) (Quit: MichaelRaskin)
[05:14:20] <hayley> OTOH my test is probably best-case because we use every object we load into cache. If it were only some symbols that we only compare by EQ and not read slots of, it'd go slower.
[05:14:59] <gilberth> Anyhow, I don't see any difference in time either. But then the branch will be predicted correct almost every time.
[05:15:00] <hayley> https://openjdk.java.net/jeps/400
[05:15:02] -ixelp- JEP 400: UTF-8 by Default
[05:15:23] <hayley> Exactly!
[05:16:11] <gilberth> Yes, what will happen, if most of the branches are unknown?
[05:17:31] <hayley> I don't know, but why would most branches be unknown?
[05:18:06] <gilberth> When you're outside of just one single loop?
[05:18:57] <gilberth> And as you want to inline a lot, there could be plenty of those branches.
[05:19:48] <hayley> There's still hot paths, surely. As long as those are predicted and speculated I'm fine.
[05:21:03] <gilberth> Hmm, how would GCC tell an AMD64 CPU that a branch is more likely to be not taken?
[05:21:07] <hayley> So the Pi 4 is only 50% slower than my laptop, and it also does not seem to care about the read barrier.
[05:21:26] <hayley> __builtin_expect?
[05:21:35] <hayley> But yes, idk how it affects the compiler.
[05:22:21] <hayley> The SICL register allocator picks one path to use for register allocation, and then "glues" other paths with a virtual adaptation instruction. But GCC uses a graph-colouring allocator surely.
[05:23:14] <gilberth> That's isn't an instruction. What would gcc output? I mean, AFAIK the AMD64 ISA has no provision for that. Does the old default-prediction that backward jumps are assumed to be taken and forward not still hold?
[05:23:22] *** Joins: robin (~robin@user/terpri)
[05:23:40] <hayley> IIRC the RISC-V book specifies something like that. But, of course, that's no AMD64.
[05:24:41] <hayley> Apparently the P4 used backwards taken/forwards not.
[05:24:55] <hayley> https://www.agner.org/optimize/microarchitecture.pdf part 3 might shed some light...
[05:26:36] <hayley> God dammit, Urs Hölzle did indirect branch prediction work too?
[05:27:54] <hayley> gilberth: See 3.17 "Static prediction" - Core 2 seems to pick randomly, and AMD picks not taken.
[05:28:42] <gilberth> GCC indeed does produce different code.
[05:29:24] <gilberth> hayley: So what they taught be at uni still holds. Good.
[05:29:30] <gilberth> * me
[05:30:08] <hayley> "All too often, the culprit is extremely wasteful software development tools, frameworks, virtual machines, script languages, and abstract many-layer software designs." don't care Mr Agner, didn't ask
[05:30:17] *** Joins: lisp123 (~lisp123@5.30.23.247)
[05:32:24] <gilberth> Ironically the mis-__builtin_expect'ed case runs faster on my Xeon. Hmm.
[05:34:30] *** Joins: molson (~michael@2001-48F8-704A-CA1-0-0-75F-1007-static.midco.net)
[05:35:41] <gilberth> But then we always face the very same branch, so the default prediction the CPU chooses does not matter.
[05:35:59] <moon-child> there used to be branch prediction hint prefixes.  But I think they're ignored on newer parts
[05:36:17] <gilberth> Anyhow, I never imagined that read barriers are that cheap.
[05:36:29] <gilberth> moon-child: With AMD64?
[05:36:36] <moon-child> yeah
[05:36:58] <hayley> Yes, I think it is a best-case as all cache lines we pointlessly load are used quickly.
[05:37:43] <hayley> If we only used EQ on the objects we loaded, it'd be a waste to load any slots.
[05:38:05] <moon-child> https://www.agner.org/optimize/microarchitecture.pdf p. 37
[05:38:17] <gilberth> And: The CPU sees the very same branch each iteration and would not mis-predict. At least I assume so, as you usually would predict the same way as it was last time. Which is reasonable.
[05:38:40] *** Quits: cross (~cross@spitfire.i.gajendra.net) (Quit: leaving)
[05:39:02] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[05:39:15] *** Joins: cross (~cross@spitfire.i.gajendra.net)
[05:41:20] <hayley> "If your dataset has more than 5000 rows, you may want to take a random sample so you don't fry your laptop" Only 5000?
[05:42:53] <hayley> We only do linear and logistic regression, what are you frying?
[05:45:41] <gilberth> moon-child: Oh, it says segment prefixes were misused for that.
[05:50:29] <hayley> https://www.youtube.com/watch?v=HuXl5LUN7TE
[05:50:30] -ixelp- Stories (Live 1980) - YouTube
[05:51:01] <hayley> They put both lectures for maths^Wlinear regression and programming on Monday, as well as a practise class for linear regression.
[05:55:29] <hayley> The Pi 1 also assumes backward branches are taken, though I have a 2 and 4 and haven't found a plain answer for those.
[05:58:14] <hayley> So the Pi 4 does deeply out of order 3-way superscalar execution.
[06:07:11] <gilberth> hayley: Could SICL turn (let ((q (cons 1 2))) (car q)) into just 1? That is: Do away with the cons cell?
[06:11:08] <moon-child> that seems like straightforward constant folding
[06:11:31] <moon-child> (plus dce)
[06:11:45] <gilberth> Not exactly, how about (let ((q (cons nil nil))) (rplaca q 42) q)?
[06:12:15] <gilberth> Nah, (let ((q (cons nil nil))) (rplaca q 42) (car q)), rather. Sorry
[06:12:44] <moon-child> that is harder!  Requires alias analysis
[06:15:01] <gilberth> The former does, too. You have to prove that (car q) can't be modified between the CONS and the (CAR Q). Then you have to realize that the cons cell could live in the lexical environment.
[06:15:48] <moon-child> ah, yeah
[06:15:49] <gilberth> That is, that both (car q) and (cdr q) could be just like lexical variables.
[06:16:06] <gilberth> I was curious, because GCC can do that.
[06:16:23] <gilberth> with malloc(3), of course.
[06:20:12] <moon-child> related: also turns e.g.  struct { int x, y; } z;  into just  int x, y
[06:22:18] <gilberth> Sure, that part is trivial. 'z' is on the stack already. No &z seen => could live in registers too.
[06:24:20] <moon-child> not for codegen, but analysis.  In ssa, you have to turn e.g.  z.x++  into  z' = {z.x+1, z.y},  which is not so nice compared with x' = x + 1
[06:28:10] <gilberth> Hmm. What's the point in the former? Either it's at fixed location on the stack and bets are off or it isn't in which case the latter is suffice.
[06:29:59] <gilberth> Or rather: You may temporary copy z.x to somewhere else, when you spill it into place, when needed.
[06:31:25] <gilberth> In that regard it isn't any different from what could happen with a value a pointer points to. As long as nobody watches, nobody cares if the current value is there or somewhere else.
[06:31:48] <moon-child> I was going to say, you need to pass its address to another function, but you have a guarantee that the other function maintains the uniqueness.  But I guess in that case you would want to synthesize that struct on-the-fly and let the register allocate constraint solver remove spurious copies
[06:31:58] <moon-child> *allocator
[06:34:35] <gilberth> I am not sure what the guarantees are the C standard applies to pointers to lexicals. Or: Is a pointer, once given away, to an auto variable valid, as long as the activation frame is still there?
[06:35:10] <moon-child> yes, it is valid.  But with IPO you could infer that the callee treats its parameter linearly
[06:37:06] <gilberth> in foo.c: int *stash; void foo (int *p) { stash = p; } int bar (void) { return *stash; } In bar.c: extern void foo(int*); extern int bar(void); void quux (void) { int k = 42; foo (&k); return bar(); } // Is quux() defined?
[06:38:14] <gilberth> I would think so.
[06:38:22] <moon-child> yeah
[06:39:58] <gilberth> I wish CL compilers would be as smart as C compilers.
[06:40:19] <moon-child> you can see this e.g. here https://0x0.st/-wmn.txt because we reused the variable, the compiler generates less efficient code
[06:40:28] <moon-child> if the second x shadows the first, it can be put in a register
[06:41:07] <hayley> Scalar replacement of aggregates? I guess so.
[06:41:36] <moon-child> gilberth: there was some text on the topic re gccemacs; because they use ssa, they were able to get better type inference than sbcl in some cases
[06:41:37] <hayley> gilberth: Well, Clasp uses LLVM, i.e. a C compiler to compile CL and it's...slower.
[06:42:20] <gilberth> moon-child: Ok. so gcc does not know, that &x does not escape beyond scanf(3)?
[06:42:33] <moon-child> hayley: ghc would also make slow code if you fed it c, but no one says ghc is not a smart compiler
[06:43:38] <moon-child> gilberth: yeah.  But I would not be surprised if it could infer that if you were passing to a function whose source code you also had.  Or if doing lto.  There is also a gcc annotation for it, I think, though I think that's for static analysis not optimization?
[06:44:13] <hayley> gilberth: But currently SICL doesn't do many optimisations.
[06:44:20] <gilberth> moon-child: That was my hunch. That if you would write a compiler by the book for CL, it would be better than what we have. That all is not rocket science and taught for years. I mean, SSA is how old? Gosh, I have been taught that at uni and that's long ago.
[06:45:16] <hayley> The only optimisations used are crucial to getting the compiler to work, which are partial inlining to avoid making closures, and a pass to eliminate CATCH instructions that are never used.
[06:47:02] <moon-child> 'partial inlining' that also covers lambda lifting?
[06:47:27] <gilberth> Well, it makes me sick reading CCL code for the CL parts. It's full of hand-optimizations a Sufficiently Smart Compiler(TM) could do. I would guess, SBCL sources aren't much better, also it has a smarter compiler than CCL has.
[06:47:56] <gilberth> * although
[06:55:19] <hayley> moon-child: I think so?
[06:56:26] <hayley> I know (SETF X Y) generates something weird like ((LAMBDA () (SETQ X Y))) and so partial inlining is used to eliminate the closure and boxing of X. However, it doesn't remove the instructions to set up return values, which is harmless but annoying.
[06:58:36] <gilberth> This boxing of lexical is another thing, which would go away by itself when a compiler could store structures (the box here) in lexicals.
[06:59:06] <hayley> Thought I said that before.
[07:00:28] <gilberth> There is a difference between an analysis, whether a closure needs to be build and lexicals forced into boxes to putting all lexicals into boxes and let the compiler later figure out those boxes could live in lexicals (registers).
[07:01:24] <hayley> https://www.youtube.com/watch?v=w6T_X7MXg40
[07:01:25] -ixelp- Born Under Punches (The Heat Goes On) (2005 Remaster) - YouTube
[07:01:30] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[07:03:01] <hayley> All the lecturers here do machine learning apparently.
[07:03:22] <gilberth> That's where the money is.
[07:04:33] <gilberth> Like it was with Java at my time as a student. Easy to get funds for a research project, when you would mention it.
[07:04:38] *** Quits: recordgroovy (~recordgro@50.35.20.8) (Remote host closed the connection)
[07:04:57] <hayley> I guess my last idea for thread-local escape detection was machine learning.
[07:05:46] <gilberth> Was ML ever applied to automatic theorem proving?
[07:06:35] <hayley> IIRC Cyc used it to guide state search.
[07:07:29] <gilberth> I was pretty much into automatic proving in the 90s and always had the hunch that a good heuristic was missing. It's like chess playing, where a heuristic is used to prune the search tree down.
[07:10:41] <hayley> Any theorem prover running on a Zen processor uses a perceptron for branch prediction, so...
[07:10:46] <gilberth> Somewhat related: Couldn't an application optimize itself while running? Use spare cycles and measurements to optimize sw while it runs.
[07:11:13] <hayley> Calm down, Craig Chambers!
[07:11:47] <gilberth> Hugh?
[07:12:06] <hayley> JITs do measurements and profile-guided optimisation, no?
[07:12:35] <hayley> "Emphasis: Everybody likes machine learning." First, no. Second, they use a code block to emphasise "machine learning"? Seriously?
[07:13:32] <gilberth> Would they also measure, that say a function is called with fixnum arguments only, and JIT a fast path version of a function on that assumption?
[07:13:56] <hayley> I thought JS already did that, but of course not with fixnums.
[07:14:49] <gilberth> Hmm, with what then?
[07:15:27] <hayley> I forgot.
[07:15:28] *** Joins: CrashTestDummy2 (~CrashTest@ool-ad02813b.dyn.optonline.net)
[07:15:55] <hayley> https://stackoverflow.com/questions/46122344/are-there-type-inference-optimizations-on-v8
[07:15:56] -ixelp- javascript - Are there type inference optimizations on V8? - Stack Overflow
[07:18:28] <gilberth> I see.
[07:18:31] *** Quits: CrashTestDummy (~CrashTest@ool-ad02813b.dyn.optonline.net) (Ping timeout: 252 seconds)
[07:34:28] *** Quits: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd) (Ping timeout: 252 seconds)
[07:38:56] <hayley> Better is to use brackets to make the order clear: "10/(2*50)" Better again is to use postfix notation: "echo '10 2 50 mul div =' | gs -q -"
[07:48:21] <hayley> gilberth: https://www.reddit.com/r/ProgrammerDadJokes/comments/pi7yiy/what_is_a_hardware_engineers_job_title_when_the/
[07:48:22] -ixelp- What is a hardware engineer's job title when the project is really boring? : ProgrammerDadJokes
[07:55:08] <copec> I'm not sure if you would find this relevant to anything that you are doing hayley, but you should add Solaris Internals 2nd Ed. to your reading list.
[07:56:05] <copec> I went through it when it came out, and at the time the Linux kernel had nothing close to the level of design and abstractions
[07:57:14] <copec> It has come a long way since then. Also you could dtrace everything live. Of course they have ebpf in Linux now, and in most things it has probably bypassed the solaris kernel
[07:57:31] <moon-child> solaris was the last proper piece of os research.  Netted us dtrace and zfs
[07:58:07] <moon-child> and I hear good things about its init system
[07:58:37] <copec> I use smartos for all my own stuff
[07:58:46] <copec> Debian unstable as my workstation os
[07:59:27] <copec> What https://oxide.computer/ is doing is pretty awesome, imo
[07:59:27] -ixelp- Oxide
[08:00:59] <hayley> The bad Symbolics 2
[08:02:11] *** Quits: robin (~robin@user/terpri) (Remote host closed the connection)
[08:03:50] * hayley uploaded an image: (148KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/ucvZMjRlNZlPOjleGXNbeLyI/symbolics-series.png >
[08:03:51] <hayley> Symbolics 1-4 on the alignment chart
[08:05:24] *** Joins: robin (~robin@user/terpri)
[08:07:26] <copec> Azul is center?
[08:08:09] <hayley> IMO yes, Java is tolerable
[08:08:43] <gilberth> hayley: Have aliens replaced you at night?
[08:08:57] <hayley> gilberth: https://www.youtube.com/watch?v=lhMX8f64hh0
[08:08:57] -ixelp- Tubeway Army - Praying To The Aliens - YouTube
[08:09:03] <hayley> As compared to Rust or C, Java is tolerable.
[08:09:36] <hayley> Reminds me, Azul did use LLVM as a JVM compiler, but it was only shown off for better vectorisation.
[08:09:40] <gilberth> Compared to assembler, C is bearable. Oops, wait a second!
[08:09:55] <copec> The only reason I'm interested in Rust and C is from learning about low level systems
[08:10:11] <hayley> https://stuff-gil-says.blogspot.com/2017/05/zing-hits-trifecta.html
[08:10:12] -ixelp- Stuff Gil Says: Zing hits the trifecta
[08:10:19] <hayley> gilberth: Compared to microcode, assembler is...shit.
[08:10:25] <hayley> So it does stop somewhere.
[08:10:50] <gilberth> Gates? Logic Gates?
[08:10:59] <moon-child> transistors!
[08:11:15] <kakuhen> i dont like writing java but i do have to admit i like how i can drop a jar file wherever i want and it just runs on any platform
[08:11:19] <moon-child> also do you include all the gates?  Or just the symmetric ones people actually use?  Or just nand?
[08:11:21] <kakuhen> or at least that used to be the case
[08:11:38] <kakuhen> apparently JRE doesnt exist anymore so idk how running java software actually works in $current_year
[08:12:07] <hayley> gilberth: And given that it is socially acceptable to say you like C and not so much assembler...
[08:14:27] <copec> I dealt with Java desktop applications in an enterprise for a decade, that would depend on a specific version of Java and windows libraries, with the next application on a different version of Java and libraries
[08:14:43] <copec> So my impression of Java is that it is used to make the worst of the worst garbage
[08:15:32] <copec> Like, the PHP I deal with across all the websites for my day job now is 100x better
[08:16:38] <copec> I realize backend Java is probably much better
[08:20:21] <gilberth> I don't like languages which pretend a residue ring would be suffice to represent integers.
[08:21:48] <gilberth> Ironically this goes hand in hand with static typing which is perceived as being more safe, while in fact is less safe.
[08:22:54] <moon-child> out of curiosity, what are your thoughts on floating-point?
[08:23:31] <gilberth> What you mean?
[08:24:26] <hayley> I think it sometimes gets messy to not mess up with inaccuracy, but you can get away with it usually.
[08:24:26] <moon-child> floating-point seems to me as poor a representation of real numbers as fixed-with numbers are of integers
[08:24:28] <moon-child> or worse
[08:25:36] <gilberth> No, you don't compute in a residue ring with FP. You just have fixed precision. That is a difference.
[08:25:39] <hayley> I had to transcribe a notebook about Python and one of the statements was "We can use subtraction to show that 8.0e-2 and 0.08 read the same: 8.0e-2 - 0.08" so I threw in the olde 0.3 + 0.6 demonstration.
[08:25:44] <moon-child> hayley: exactly the same is true of fixed-width integers.  Moreover, better representations have been devised for each: bignums and balls (or intervals)
[08:26:48] <moon-child> gilberth: I didn't say they were the _same_.  I just said they are both widespread representations which have essential defects (but are nevertheless useful)
[08:27:02] <kakuhen> moon-child: intervals...so a 1-ball? ;)
[08:27:22] <kakuhen> also for some reason i notice that programmers tend to use half-closed intervals a lot
[08:27:34] <kakuhen> i.e. they prefer [x,y) rather than (x,y) or anything else
[08:27:52] <moon-child> kakuhen: hm?  A ball is a value accompanied by a radius; an interval is a pair of values which comprise a bound
[08:28:29] <kakuhen> my brain interprets "balls (or intervals)" as in the usual sense of the word 'ball' in math
[08:28:45] <kakuhen> i.e. {y\in R^n \mid |x-y|<r}
[08:28:51] <kakuhen> so i made a lame joke about intervals
[08:29:04] <kakuhen> in the case n=1 this definition gives you (x-r,x+r)
[08:29:12] <gilberth> moon-child: I believe 'int' is more dangerous. Most languages don't throw an exception on overflows, and unlike reals, integers have finite precise representations. And in practice people are aware that FP have a fixed precision.
[08:29:20] <hayley> https://www.youtube.com/watch?v=U7nYUD3dlWM
[08:29:20] -ixelp- The Romance Of The Telescope (Architecture & Morality - Dazzle Ships - Live At The Royal Albert... - YouTube
[08:29:32] <moon-child> kakuhen: oh, yes
[08:29:37] <hayley> Also see https://twitter.com/KenHatesSoftwar/status/1389329166785384448
[08:30:49] <kakuhen> oh also i really like the  idea behind bignums
[08:30:53] <gilberth> On that topic. CLISP once did single-float + double-float => single-float on the argument, that the specified way single + double => double would pretend precision where there is none.
[08:30:58] <kakuhen> common lisp is the only programming language whose arithmetic doesn't make me want to split hairs
[08:31:10] <kakuhen> or i guess "specified programming language"
[08:32:27] <hayley> gilberth: According to perf, the read barrier inflates the instruction count by like 50% or so, and the number of branches doubles, but the page fault count remains the same, and the branch miss count is slightly lower.
[08:32:48] <gilberth> And again: With FP this becomes mood, when you use iterative algorithms to compute, say a sine. The result is approximate in anyway, all you want to know is that it is within certain bounds of the true, potentially irrational, value.
[08:33:46] <hayley> This leads to the hypothesis I think was made for the C4 collector, that you don't tend to hit maximum instructions-per-cycle, so it doesn't hurt to throw in a few more.
[08:33:53] <moon-child> 'all you want to know is that it is within certain bounds of the true, potentially irrational, value'  yes, but how will you know what those bounds are?  If you perform many calculations, how will you know?  Using balls or intervals, it will be right there in the value
[08:34:18] <moon-child> the 'extreme example' given here is illustrative http://wiki.nars2000.org/index.php?title=Ball_Arithmetic#Calculating_With_Ball_Arithmetic
[08:34:29] <hayley> LENGTH has an IPC of about 0.7 without the barrier and 1.2 with.
[08:39:05] <gilberth> moon-child: Interval arithmetic is nothing new. But for iterative algorithms you usually don't use it. You have a fixed point you iterate towards and while you go, you approach it, even when off a little while you go. Sorry, I found that a boring lecture and can't recall the details on how you do that analysis, i would need to look that up. And, yes, I had a quite longish argument with the prof giving that lecture over interval arithmet
[08:39:53] <gilberth> hayley: So all that happens to us is, that we produce more waste heat in exactly the same time?
[08:40:05] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Remote host closed the connection)
[08:40:05] <hayley> Hm, so I found a 3% overhead on a larger test with the read barrier. ZGC reports 4% overhead on a real test.
[08:40:10] <hayley> gilberth: Yes.
[08:40:27] <copec> I came from a math perspective too, and like CL and Julia
[08:40:27] *** Joins: chiselfuse (~chiselfus@user/chiselfuse)
[08:40:43] <gilberth> hayley: 3% isn't much.
[08:41:03] <copec> A year of numerical analysis using matlab in 2003ish
[08:41:04] <hayley> gilberth: Also note that all we're doing is chasing pointers. So things could vary wildly.
[08:43:38] <gilberth> hayley: Yes, but isn't chasing pointers already the worst case? I mean in contrast to simple crunching on vectors, like looking for nightmares?
[08:44:15] <hayley> gilberth: I guess, though another factor is that we potentially pollute cache with bogus reads, would the program not load slots. For example, we might only compare symbols by EQ.
[08:44:57] *** Quits: APic (apic@apic.name) (Read error: Connection reset by peer)
[08:45:10] <gilberth> Once your are all for yourself in a loop crunching down an octet vector, you'll should be safe, shouldn't you?
[08:45:11] <hayley> Though if you only use a loaded value for EQ, one trick would be to guess that the pointer isn't stale and do EQ on the raw pointer, then if EQ fails only correct.
[08:45:19] <hayley> Right.
[08:45:23] *** Joins: APic (apic@apic.name)
[08:45:54] <gilberth> hayley: Do we pollute caches by bogus reads?
[08:46:34] <hayley> In this test program, no, because we use all the objects we read (to CDR again).
[08:47:01] <gilberth> Yep, I was about to say that.
[08:47:58] <hayley> Hence the three optimisations I want to do: don't test type tags if the user provided a test already, if the object is loaded from immediately, use that as the "read barrier", and if we only test EQ, then have a guess before doing corrections.
[08:48:10] <gilberth> For larger objects, like vectors, we might also afford a dedicated slot for a self-pointing pointer.
[08:49:10] <gilberth> hayley: Makes sense. The first thing is sth I would expect the compiler to do anyway.
[08:49:22] <hayley> The trick on Pauseless/C4/ZGC/whatever else is that, once you protect a page for relocation, you can free the page after everything is copied, provided you have relocation information elsewhere. And that relocation information would be smaller, as there are fewer objects on fragmented pages.
[08:50:17] <gilberth> You mean internal fragmentation?
[08:50:36] <hayley> Yes.
[08:51:23] <gilberth> The reverse also is true: When storing a list of intervals moves, a page with just one "hole" (that is free space) could have a very small reloc information.
[08:51:45] <hayley> Yes, beach's sliding GC does something like that.
[08:54:09] <gilberth> Remind me that I still have to read that book. I am not up to date with GCs.
[08:54:35] <hayley> IIRC the book came out before http://metamodular.com/SICL/sliding-gc.pdf but sure.
[08:56:30] <hayley> Huh, beach recommends the concurrent and parallel Compactor for global compacting GC.
[08:58:43] <gilberth> GC is a curious problem. Simple at its heart, yet tricky in its implementation. It's more a technical problem actually.
[08:59:05] <hayley> Still. Isn't a branch predictor just doing type inference when it branches on type tag tests?
[08:59:52] <gilberth> What does it infer?
[09:00:08] <hayley> It infers that the tag tends to be of a particular value, I guess.
[09:01:03] <gilberth> No. It predicts it, from previous branches. It doesn't care at all what is tested. That's not inference.
[09:01:06] <moon-child> if a value has some type in one place, the branch predictor may infer that; but it will not infer that the same value has the same type in another place
[09:02:36] <gilberth> Well, what it does is: .oO(Oh that particular jump went that way, most of the time, I bet it does this time, too.)
[09:04:01] <gilberth> This even is done for indirect jumps at times. Which is nice for method dispatch is object^Wsubject oriented languages.
[09:04:56] *** Joins: Zianic (~12602@user/zianic)
[09:20:27] *** Quits: robin (~robin@user/terpri) (Remote host closed the connection)
[09:20:46] <hayley> Also, Baker had a paper on making the quadratic algorithm less sucky with floating point numbers.
[09:21:06] <hayley> https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.111.4448&rep=rep1&type=pdf
[09:22:19] <hayley> Huh, there's a sequel too https://dl.acm.org/doi/10.1145/274930.274935
[09:22:21] -ixelp- You could learn a lot from a quadratic: II: digital dentistry: ACM SIGPLAN Notices: Vol 33, No 2
[09:24:57] *** Quits: APic (apic@apic.name) (Read error: Connection reset by peer)
[09:25:07] *** Joins: lisp123 (~lisp123@5.30.23.247)
[09:26:08] <hayley> "In floating point arithmetic, there exist numbers ... i.e. y 'drowns' in x (why do you think they call it 'floating point'?)"
[09:29:39] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[09:30:12] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 250 seconds)
[09:30:16] *** Joins: APic (apic@apic.name)
[09:34:26] <gilberth> Apropos FP: I still don't grok floating point printing. I came up with a nice and simple routine which uses less bits, yet have no idea how to prove that it is correct.
[09:38:40] <dave0> maw
[09:43:07] <gilberth> And btw, if (= 8e-2 0.08) doesn't hold, get a new Lisp.
[09:43:14] <gilberth> Hello dave0!
[09:43:37] <dave0> hi gilberth ! space
[09:43:51] <gilberth> Thanks!
[09:43:57] <hayley> https://www.youtube.com/watch?v=jY7dbRyoHfE
[09:43:58] -ixelp- King Crimson - Islands - YouTube
[09:46:02] *** Joins: shka (~herr@109.231.62.239)
[10:29:57] *** Quits: APic (apic@apic.name) (Read error: Connection reset by peer)
[10:30:14] *** Joins: APic (apic@apic.name)
[10:30:57] *** Joins: selwyn (~selwyn@user/selwyn)
[10:39:57] *** Quits: APic (apic@apic.name) (Read error: Connection reset by peer)
[10:40:15] *** Joins: APic (apic@apic.name)
[10:55:07] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Ping timeout: 245 seconds)
[10:57:47] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[11:00:15] *** Joins: lisp123 (~lisp123@5.30.23.247)
[11:04:40] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Ping timeout: 250 seconds)
[11:27:11] *** Quits: selwyn (~selwyn@user/selwyn) (Quit: Connection closed)
[11:29:57] *** Joins: razzy (~razzy@user/razzy)
[11:29:57] <pjb> The Lisperati1000 computer <http://www.lisperaticomputers.com/>
[11:31:04] <hayley> Not lisp machine, don't care
[11:45:39] <edgar-rft> "its most striking feature is the 8.8inch display, which has an ultra-wide aspect ratio" but what is that good for without Dolby Surround Lisp?
[11:45:56] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[11:52:11] <shka> it kinda is lisp machine :D
[11:53:12] <hayley> CADR on FPGA or go home
[11:53:30] <shka> really nice keycaps
[11:53:32] <dave0> maw
[11:53:39] <shka> triple dyesub 
[11:53:56] <aeth> I was going to buy AMD and make them make Lisp machines for #lispcafe but then instead of going bankrupt they came up with Zen and I don't think they're ever going to be in my budget at this rate
[11:54:43] <hayley> aeth: https://twitter.com/nodefunallowed/status/1335503051554078721/photo/1
[11:54:52] <shka> lisp optimized hardware seems to be outdated concept anyway
[11:55:00] <dave0> i think i have a spare billion hidden in my mattress
[11:55:09] <aeth> hayley: yeah, that could have been AMD
[11:55:54] <dave0> hayley: it's a tweet by hayley patton! that's you!
[11:56:10] <hayley> dave0: Nah, there is more than one Hayley Patton on the planet.
[11:56:13] <aeth> hayley isn't nodefunallowed
[11:56:15] <aeth> she said so
[11:57:05] <dave0> but it's the same avatar
[11:57:44] <hayley> Yeah, there aren't that many unique avatars too.
[11:58:13] <hayley> Only 2^393216 or so...
[11:58:19] <hayley> assuming 8 bits per pixel and 128x128 with no alpha channel.
[11:58:49] <aeth> possible avatars? yes. Avatars-in-practice? On the entire internet? Probably fewer than 1 trillion
[11:58:57] <hayley> *8 bits per channel rather...
[12:00:08] <dave0> maybe she's a chatbot
[12:04:31] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[12:05:14] *** Joins: treflip (~user@95.79.32.99)
[12:17:55] <kakuhen> shka: outdated, but i still want a lisp optimized hardware
[12:27:30] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[12:28:12] <shka> what for?
[12:28:36] <shka> general purpose hardware is now fine for running lisp code
[12:28:49] <shka> GC is not all a problem
[12:29:02] <shka> *GC is not at all a problem
[12:34:13] <moon-child> hw supported barriers would be nice...
[12:34:14] <shka> anyway, https://www.lexaloffle.com/bbs/?pid=pico8lisp1-0 
[12:34:15] -ixelp- Pico8Lisp
[12:34:37] <shka> moon-child: these are supported on newer Intels
[12:34:58] <shka> it used to work on the Haswell, but intel is intel and disable it because of bug
[12:36:37] *** Joins: hendursa1 (~weechat@user/hendursaga)
[12:36:45] <moon-child> you mean the stm stuff?
[12:36:49] <moon-child> err, htm :P
[12:36:54] <moon-child> transactions
[12:39:27] *** Quits: hendursaga (~weechat@user/hendursaga) (Ping timeout: 276 seconds)
[12:43:51] *** Joins: dra (~dra@2a04:4540:640e:9b00:5a7:7a68:df84:eb4e)
[12:45:20] <shka> yes
[12:45:21] *** Joins: Qwnavery (~Qwnavery@user/qwnavery)
[12:45:34] *** Joins: razzy (~razzy@user/razzy)
[12:47:26] <dra> lotuseater: Thanks for asking. It can interpret recursive functions now. And it has the read macro for #\`, although the corresponding transforms are not yet there.
[12:49:15] <dra> lotuseater: Oh, and it has OPEN now, and a very simple variant of WITH-OPEN-FILE, which opens for writing in mode 0755. And it has WRITE-BYTE. So technically, it can do... everything? ;)
[12:50:58] <hayley> Well, some actual barriers in hardware would help. I consider the out of order barrier trick I found to be a hack, because it takes processor resources and there isn't really a barrier execution unit or whatever.
[12:52:26] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 252 seconds)
[12:54:14] *** Joins: razzy (~razzy@user/razzy)
[12:55:31] *** Quits: dec0d3r (~dec0d3r@2001:8003:4810:9600:7275:1afb:1707:8eaa) (Remote host closed the connection)
[13:00:22] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[13:01:59] *** Joins: razzy (~razzy@user/razzy)
[13:12:38] <lotuseater> cool, more than i could ever do
[13:14:41] <dra> lotuseater: Nah, it's all decently simple. I'll write about it eventually, so stick around (for a few months/years).
[13:14:59] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 252 seconds)
[13:16:26] <lotuseater> for *you* it's "decently simple" :)
[13:16:52] *** Joins: razzy (~razzy@user/razzy)
[13:17:01] <Qwnavery> hiyo lotuseater 
[13:17:18] <lotuseater> hi Qwnavery 
[13:17:32] <Qwnavery> how are you?
[13:18:36] <lotuseater> ok
[13:22:23] *** Joins: vats (~vats@180.149.226.8)
[13:31:45] <dra> lotuseater: Ok, fair enough. ;)
[13:35:55] *** Parts: razzy (~razzy@user/razzy) ()
[13:36:01] <lotuseater> for me infinitely unachievable as most things too
[13:48:15] *** Joins: lisp123 (~lisp123@5.30.23.247)
[13:48:57] *** Quits: shka (~herr@109.231.62.239) (Quit: Konversation terminated!)
[13:54:58] *** Quits: kakuhen (~kakuhen@user/kakuhen) (Quit: Leaving...)
[14:02:33] <hayley> https://www.youtube.com/watch?v=ZswJoAvbuzY
[14:02:33] -ixelp- Finally a good usage for Hoverboards! (charge your powerbank by cranking) - YouTube
[14:04:27] <hayley> gilberth 2 creates a Sechspuls-Brücken-Schaltung
[14:15:53] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[14:16:30] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[14:42:40] *** Quits: lisp123 (~lisp123@5.30.23.247) (Remote host closed the connection)
[15:15:01] *** Quits: APic (apic@apic.name) (Read error: Connection reset by peer)
[15:15:20] *** Joins: APic (apic@apic.name)
[15:16:30] *** Joins: lisp123 (~lisp123@5.30.23.247)
[15:26:59] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[15:29:14] <hayley> https://i.redd.it/5sx9dysk6ml71.jpg
[15:34:05] *** Joins: random-nick (~random-ni@87.116.180.118)
[15:50:41] <hayley> To make matters worse, if I remove the "type tag test" from my test program and just check for NULL, it goes faster. I guess the bogus read amounts to prefetching?
[16:13:11] *** Quits: Qwnavery (~Qwnavery@user/qwnavery) (Read error: Connection reset by peer)
[16:15:25] *** Joins: cranium (~cranium@user/cranium)
[16:22:42] * gilberth found some 74F831DW for less than EUR 1.00 each.
[16:23:42] <hayley> Huh, I got concurrent allocation failures on ZGC by removing the soft heap size target.
[16:28:48] <hayley> Granted, I gave it a target of 1GB for Minecraft, which it sort of achieved by pinning two (of six) cores basically.
[16:54:43] <hayley> gilberth: So isn't that funny, that out of order execution gives you "hardware" for doing the read barrier in parallel.
[17:09:32] <gilberth> hayley: Indeed. And "hardware read barriers" wouldn't be any faster. I always thought that read barriers would be slow.
[17:10:36] <gilberth> So I will need to take speculative execution into account for future thinking about those kind of things.
[17:11:02] <hayley> All questions of manufacturing and budget aside, I still think that we are still only lucky to have spare execution resources, else we can't keep up the throughput with our IPC tax.
[17:11:47] <hayley> Going from 0.7 to 1.2 IPC is no big deal. Say our machine can do 4 IPC on a good day, then 3.5 to 4.2 IPC is a tad more concerning.
[17:13:38] <gilberth> Still: That extra work needs to be done somehow. It's more like what was microcode once now is our ISA.
[17:13:39] *** Joins: lisp123 (~lisp123@5.30.23.247)
[17:14:46] <hayley> But a hardware read barrier implies additional hardware, i.e. some sort of barrier "unit" which we really have and don't rent out from some ALU or similar.
[17:15:01] <gilberth> On that topic: I have not yet found a way to use the spare IPC for a byte code interpreter. But then my TTL CPU emulator run at more than 800MIPS, which is fair.
[17:16:10] <gilberth> hayley: Still, as long as we have spare IPC, we're fine. Should I contemplate a read barrier for my RISC TTL design?
[17:16:26] <hayley> Well, IMO a linked list limits your IPC as you have to wait to get a response from memory before continuing to CDR.
[17:16:41] <hayley> gilberth: do you have multiple execution units and out of order execution?
[17:17:24] <hayley> I think those are crucial to pretending like you have a hardware read barrier.
[17:17:27] <gilberth> hayley: With 74xx's? I'm crazy, but not that crazy. Though I contemplated to have two ALUs.
[17:17:48] <dave0> nite all
[17:17:59] <gilberth> dave0: Take care!
[17:18:07] <dave0> byes gilberth 
[17:18:10] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 240 seconds)
[17:18:17] <hayley> So, I guess you should if you really want incremental compacting GC for some reason?
[17:18:25] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[17:18:55] <gilberth> Can't I have a dedicated GC co-processor?
[17:19:20] <hayley> You need to synchronise mutator and collector. Do you have a CAS instruction?
[17:19:47] <hayley> And that is orthogonal to barriers, though generally the collector needs to be informed of changes.
[17:20:04] <gilberth> Nope. But: I could route any memory access through the GC unit.
[17:20:49] <gilberth> But: Any kind of cache won't happen in 74xx. On an FPGA? Maybe.
[17:21:38] <gilberth> But FPGAs are boring.
[17:22:01] <hayley> Then I suppose you still need for the GC unit to inform the CPU to flip registers to tospace.
[17:23:52] <gilberth> Do I? When GC is due, I could do this once any further reads would be through that unit.
[17:24:43] <gilberth> Would be fine with TTL and no cache. Unreasonable design for anything more modern.
[17:24:45] <hayley> I guess then. But surely it gets messy to remap on the scale of individual objects.
[17:25:12] <gilberth> .oO(Pointer swizzling)
[17:26:42] <gilberth> I once contemplated to have a CPU with a small word width and have a swizzling unit inbetween. Never got anywhere with that.
[17:28:39] <gilberth> hayley: Anyhow, I am delighted, that read barrier are now in our arsenal.
[17:29:04] <hayley> Suppose so, though I am still cautious.
[17:29:32] <gilberth> Real benchmarks will show.
[17:29:51] <hayley> And I guess branch prediction means that, even if I didn't use the MMU and just used more instructions to fix up, we can still speculate the same.
[17:30:43] <gilberth> I would expect both ways to be taken, when units are idle.
[17:32:49] <gilberth> Also I would expect the bogus read to stall a bit, so that the branch itself would be decided while the load/store unit is idle. And when the destination of the read is some unused register, both ways merge after the bogus read.
[17:33:39] <hayley> There is still a performance hit of 3 to 7% or so. But of course, you can make that up with smarter compacting and a better compiler in general.
[17:33:41] <gilberth> What we have these days are essentially data flow machines.
[17:34:44] <hayley> But then again, what I measured was a type tag check I added, whereas C of course doesn't have them otherwise.
[17:34:50] <gilberth> hayley: Yes, cache effects by staying in the nursery and compaction are perhaps worth the hassle. I'm optimistic.
[17:35:14] <hayley> Just the bogus load actually made the program marginally faster, probably as we prefetched basically.
[17:36:48] *** Joins: shka (~herr@109.231.62.239)
[17:37:33] *** Joins: makomo (~makomo@user/makomo)
[17:38:00] <gilberth> hayley: Yes, this is why I suggest for vectors to have an extra slot just for the bogus read. Small memory overhead. That slot could point to the object itself, or if indirection for the storage vector is involved, just there. Whatever.
[17:39:05] <gilberth> And when it's a cons cell, we would chase pointers most of the time, I guess. Also no harm done.
[17:39:38] <hayley> A bogus pointer is called that cause I don't use the value loaded, only the effect of trapping. Unless you mean a Brooks forwarding pointer?
[17:40:07] <hayley> Following the forwarding pointer produces a data dependency and so would serialize AIUI.
[17:40:40] <gilberth> No, I don't. But the bogus pointer could be made to point to something worth of pre-fetching, when the memory overhead won't be too large.
[17:41:37] <hayley> I guess, though we end up with...multiple bogus loads to do that in the load value/read barrier?
[17:42:44] <gilberth> multiple? why? All you want to test is whether the object really is there, where you think it is. At least I understood it that way.
[17:43:45] <gilberth> Wait a second. No, you want to test whether the pointers in the object are up-to date?
[17:44:09] <hayley> We check if the pointer we just loaded is up to date.
[17:44:39] <gilberth> The 'list' or 'list->car'?
[17:45:46] <gilberth> Or cdr, doesn't matter.
[17:45:59] <hayley> The CAR.
[17:46:37] <hayley> The test is done on the loaded value, i.e. load value barrier. Quite the same as Baker's copying iirc.
[17:47:13] <gilberth> ok.
[17:48:21] <gilberth> That what I said does not make sense. Scratch that.
[17:49:23] <hayley> Precisely the same as Baker, though Pauseless is "self healing" and writes back the pointer from where it came from too.
[17:50:53] <gilberth> Can't we generate another exception? Division by zero? Overflow? Bounds check? Sth like that.
[17:51:30] *** Quits: gko (~user@user/gko) (Remote host closed the connection)
[17:51:59] <hayley> I guess, but the page table is a convenient index for region protection, and so we get "segfault if region is protected" in one instruction by loading.
[17:52:08] *** Joins: lisp123 (~lisp123@5.30.23.247)
[17:53:05] <hayley> (And FWIW I refuse to trap on every reference after starting marking like Pauseless or ZGC, so I am fine with the somewhat slower trap handler time.)
[17:53:22] <gilberth> Sure. And I am still all for type check by alignment traps. Or using the MMU for type checks. I talked about that in like '99 or so.
[17:55:22] <gilberth> Reminds me, I still need to figure out how to mmap(2) NaNs. When QEMU can do that, so can I.
[17:56:37] <hayley> "Back in CADR there was you, there were GCs every morning, fuck those abstract syntax trees, never used to be that way..." - Brian Eno, Back In Graydon's Jungle
[17:57:37] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[18:02:33] <hayley> And as we only protect pages to move, and Immix is clever at reusing pages, ideally we'd rarely trap.
[18:03:32] <hayley> That means the frequency that a read barrier actually trips is tiny, but of course it tripping is when we do the magic.
[18:06:46] <gilberth> Reminds me of <https://www.youtube.com/watch?v=3vJWVyEBcdE&t=994s> ;note the time index. Took me a while to find it.
[18:06:46] -ixelp- Garbage the Video - YouTube
[18:07:18] <hayley> .oO( I only had to send it to gilberth before. )
[18:07:56] <gilberth> I love the scene.
[18:09:15] * hayley uploaded an image: (488KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/hbczLmeqhXHVWFSGdzcpSiEL/trade-offer.png >
[18:09:43] *** Joins: gko (~user@user/gko)
[18:10:59] <gilberth> Heh, is that an egoist offer?
[18:11:26] <hayley> It is a wait-free offer technically, but also yes.
[18:11:47] * hayley uploaded an image: (231KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/TCHMLPFuepPojgqqggEtmIEk/82033es53xs61(1).jpg >
[18:11:49] <hayley> Here is an egoist offer.
[18:13:43] <gilberth> I read your article about post open source. It was not easy to get through. Yet, I would have hoped you debunked that, even if some task is hard, people still attack that task without being bribed.
[18:14:31] <gilberth> Or rather debunk, that people won't do without being bribed. that way around.
[18:15:29] <hayley> I would say I wrote that "some task is hard" is less of the case to a motivated person with the right tools. So it would not exactly fit in.
[18:15:41] <gilberth> This also has something to do with external and internal motivation which in turn is connected to perfection-oriented and performance-oriented in some loose way.
[18:16:58] <hayley> I see, yes.
[18:18:04] <hayley> The first part is about why most people may have an internal motivation to program  as well.
[18:18:55] <hayley> But I had better begin GCing as I need to be (online) at university in like 9 hours.
[18:19:09] <gilberth> hayley: It didn't come across that way to me, sorry. I read "author debunks that programming is hard." I take it that those "post open software" argued on the axiom "programming is hard" and the consequence that it would need money to make people doing that. I don't question the premise in principle, I question the conclusion.
[18:19:47] <hayley> Right, fair enough.
[18:19:55] <gilberth> hayley: We talk tomorrow then. Take care.
[18:21:11] <hayley> I don't think they had an implication arrow, though. Just that people getting fed also tends to help, though their idea of insulated communities basically mean that everyone has to run their own little company with advertising and shitty competitive practices  (from experience).
[18:21:16] * gilberth could need some GCing also.
[18:22:09] <hayley> One scrapped statement was rude admittedly. The person who wrote the original POS article apparently does not like computers, so I wrote that if they want to be free, they could start by finding a new profession.
[18:23:46] <hayley> I can appreciate that people work jobs they don't like by necessity, but if we're talking about better times, and one has no internal motivation to program...well, just don't?
[18:24:05] <gilberth> hayley: Yes. And I was thinking: You don't need a company to organize people. Those guys in the quote of yours, hitting the tavern to have fun, haven't founded a company either. Also free software projects can have a kinda hierarchy and different people contributing different skills.
[18:25:04] <hayley> Yes, this is what I mean by "a union of egoists or an affinity group or whatever else you want to call it".
[18:26:21] <gilberth> hayley: Sure. In an ideal world people would act on their internal motivation. But that won't happen, not because of money, but because of people believing in that money would make them happy or superior in any kind. Oh, and then women still love successful men. Also part of the equation.
[18:26:53] <hayley> Though having different skills does not imply a hierarchy to me. To use a networking analogy, you put too much information down one wire (the manager), which is a bit like the community problem in a way.
[18:26:55] <gilberth> hayley: Your quote is a very, very good quote to transport what is happening.
[18:27:51] <hayley> Goodnight!
[18:27:58] <gilberth> Well, there will always be people who are more of a leader than others. That's natural.
[18:28:06] <gilberth> Sleep tight!
[18:37:00] <shka> upgrade complete
[18:37:05] <shka> new cpu cooler installed
[18:37:34] <gilberth> Lift off, when?
[18:39:56] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[18:40:33] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[18:42:16] <shka> gilberth: enough of that for now
[18:43:04] <shka> old cooler, baked itself to the cpu and when i was trying to unstick it
[18:43:09] <shka> i landed on the floor
[18:43:12] <shka> CPU that is
[18:43:26] <shka> and after reinstalling, computer would not boot...
[18:43:38] <gilberth> Sounds bad.
[18:43:39] <shka> luckly turned out to be something related to GRUB
[18:44:02] <shka> but to fix that i had to make bootable pendrive
[18:44:22] <gilberth> How would grub stop working just because of a new fan?
[18:44:26] <shka> and THEN stupid bios decided to not see my main drive
[18:44:58] <shka> gilberth: dunno, but bios complained about the new hardware spec in the meantime 
[18:45:11] <shka> that was first for me
[18:45:21] <gilberth> Is that one of those machines, which are power cycled only for hw upgrades?
[18:45:25] <shka> perhaps that's because i had to remove cpu from the socket 
[18:45:37] <gilberth> Strange.
[18:47:53] <shka> i know
[18:48:07] <shka> and it almost triggered heart attack :P
[18:48:11] <shka> but it works
[18:48:22] <shka> humbling experience 
[18:48:30] <gilberth> Is the new fan a silent one?
[18:49:19] <shka> well, i should stress test it
[18:50:32] <gilberth> Reminds me, that my linux box somehow has insufficient cooling when all cores run under full load, it would throttle the clock.
[18:50:59] <shka> well, running stress -c 8 it is reasonably quiet
[18:51:11] <shka> and temperatures peaks at 70
[18:51:32] <gilberth> Which is fair, isn't it?
[18:51:57] <shka> it is acceptable 
[18:52:22] <gilberth> Still below 125°C when CMOS fries.
[18:52:34] <shka> cooler in my old machine was much more powerful
[18:52:41] <shka> but i wanted something smaller
[18:53:45] <gilberth> Does it have fancy RGB LEDs? /me ducks
[18:53:52] <shka> less hassle when changing computer case, accessing RAM slots and the likes
[18:54:12] <shka> no, i HATE rgb stuff
[18:54:25] <gilberth> I see. You don't believe in GC and rather plug in more RAM?
[18:54:44] <shka> AMD stock cooler had rgb leds for some reason
[18:54:45] <gilberth> shka: Me too. My machine should not glow in the dark.
[18:54:59] <shka> and no way to disable it on linux :D
[18:55:16] <gilberth> shka: It's so kewl! That's why it is called a "cooler".
[18:55:30] <shka> well, regardless
[18:55:47] <shka> it is just 3700x
[18:55:51] <shka> which has modest tdp
[18:56:31] <shka> so i figured i would rather have smaller cooler, makes everything easier 
[18:57:17] <shka> as for the RAM, yeah, i stick as much RAM as i can into my machines
[18:57:25] <gilberth> I once got a new mouse, which is pretty fine, but it glows blue! Can't stand that. And no hint about that in the product description, perhaps mice are supposed to do that. Particular bad, when you sleep in the same room.
[18:58:03] <gilberth> shka: Nothing beats RAM. Didn't Cray say that?
[18:58:37] *** Joins: selwyn (~selwyn@user/selwyn)
[19:00:35] <shka> dunno
[19:00:51] <shka> what i know, is that i often use large heaps
[19:00:59] <shka> so my data can fit into that
[19:01:57] <shka> anyway, smaller cooler = easier to find suitable computer case, less weight hanging on the motherboard, less problem accessing motherboard
[19:02:16] <shka> but also reduced efficiency
[19:04:55] <shka> for the 3700X it seems to be sufficient
[19:06:58] *** Joins: CrashTestDummy (~CrashTest@ool-ad02813b.dyn.optonline.net)
[19:09:40] *** Quits: CrashTestDummy2 (~CrashTest@ool-ad02813b.dyn.optonline.net) (Ping timeout: 252 seconds)
[19:12:59] <selwyn> i guess i just put up with the massive size of the processor/heatsink
[19:17:57] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[19:24:00] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 256 seconds)
[19:34:51] <selwyn> what reputation does dyson have abroad?
[19:39:52] <shka> selwyn: large heatsink is just limiting :/
[19:39:58] *** Joins: robin (~robin@user/terpri)
[19:40:05] <selwyn> wrt to the size?
[19:40:32] <shka> as is: you need to make sure that stuff FITS
[19:40:36] <selwyn> yes
[19:40:41] <selwyn> pcpartpicker is good for that
[19:40:44] <selwyn> https://noctua.at/en/nh-d15 i have one of these
[19:40:46] -ixelp- NH-D15
[19:40:50] <selwyn> and it is so fucking big
[19:41:00] <selwyn> but what else am i going to put inside a computer case lol
[19:41:15] <selwyn> actually, i was worried that it wouldn't fit when i was assembling the computer
[19:42:55] <shka> that was other cooler i was considering 
[19:43:13] <shka> but i decided that 3700X should not requires this beast
[19:43:22] <selwyn> it is very well engineered and does the job well
[19:43:34] <selwyn> i chose it over water cooling which was the right choice i think
[19:44:10] <selwyn> i have a i9-9900k, perhaps it was overkill but i wanted the best thing around for the job
[19:45:38] <selwyn> dyson spent $700m on designing an electric car which seems like an awful lot
[19:46:23] <shka> oh, yes i9 requires a lot of cooling
[19:46:38] <shka> but 3700X is just half of the TDP
[19:47:31] <shka> gabe fucking newel, why the hell CS:GO replays are so jank
[19:47:34] *** Quits: hendursa1 (~weechat@user/hendursaga) (Quit: hendursa1)
[19:47:38] <selwyn> yeah i want amd next time
[19:48:16] *** Joins: hendursaga (~weechat@user/hendursaga)
[19:48:19] <selwyn> nvidia has this thing to automatically capture fortnite/other games replays of key moments and it works really well
[19:48:35] <selwyn> do you have a new cs go project?
[19:48:46] <shka> old one, trying to debug a problem
[19:49:19] <shka> i have a magic shot that apparently hurts the same player twice
[19:52:28] <shka> if you go back one tick in the cs go replay, it seems to insists on loading up all the data from the start
[19:52:29] <shka> FUN
[19:53:17] <shka> and while it performs the lookup, freezes the app
[19:56:34] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Remote host closed the connection)
[19:58:28] *** Joins: chiselfuse (~chiselfus@user/chiselfuse)
[20:14:40] *** Joins: makomo (~makomo@user/makomo)
[20:14:56] *** Joins: makomo_ (~makomo@user/makomo)
[20:15:25] <shka> oh, and the weapon fire occurs after the damage has been applied
[20:15:28] <shka> fucking UDP
[20:20:47] <selwyn> as in user datagram profile?
[20:22:13] <shka> yeah
[20:22:22] <shka> events are not in order
[20:22:26] <shka> which is... fine
[20:22:40] <shka> but they don't even have sensible ticks
[20:22:44] <shka> which is... not fine
[20:28:19] <shka> selwyn: as for the AMD, yeah, intel is currently simply behind
[20:28:38] <shka> which is funny, because who would expect that before zen
[20:28:44] <selwyn> yeah
[20:28:47] <selwyn> i think it's healthy
[20:28:52] <selwyn> intel/nvidia are not nice
[20:33:15] <shka> i wonder if intel can make any return
[20:33:56] <shka> lol, noctua included a "low noise adapter"
[20:34:05] <shka> which has to be just a resistor
[20:34:06] <selwyn> uh
[20:34:19] <selwyn> trying to remember if i used one of them
[20:35:35] <selwyn> oh lol. yeah don't remember that. possible that they shipped me one anyway
[20:36:06] <selwyn> i mean, you can install just one fan if you want, and the fans are quiet anyway
[20:43:49] <shka> yeah, or you can use bios setting to the same thing
[20:44:02] <shka> which is: reduce voltage on the fan :P
[20:44:43] <shka> yeah, it is resistor
[20:44:50] <shka> silly 
[20:46:23] <selwyn> why use a software solution when you could use hardware :p
[20:47:40] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Remote host closed the connection)
[20:47:58] *** Joins: chiselfu1e (~chiselfus@user/chiselfuse)
[20:51:19] <shka> join the resistance :P
[20:52:13] <lotuseater> https://www.youtube.com/watch?v=B9DouAlkZlc
[20:52:14] -ixelp- New! Stupid C++ Tricks: Most Dangerous C Functions (E02) - YouTube
[20:52:43] <selwyn> lol
[20:52:47] <lotuseater> :D
[20:54:42] <lotuseater> selwyn: are you still in italy?
[20:55:52] <selwyn> yes
[20:55:59] <lotuseater> :)
[20:56:14] <selwyn> but still on the computer after a long day
[20:56:42] <lotuseater> so i learn from the video, when hanging a suffix _s at function symbols all is safe
[20:57:12] <selwyn> iirc clasp makes heavy use of #define private public
[20:57:28] <lotuseater> great :D
[20:57:49] <lotuseater> so it would be faster to list the safe C functions than those that are not
[20:58:00] <selwyn> they concluded that it was just not possible to do sth like clasp any other way
[20:58:31] <lotuseater> yeah to fit the nearly not so flexible
[20:59:49] <selwyn> well, they have c++ code that can refactor itself, or something
[21:00:03] <lotuseater> ah and then a quote from a microsoft book about writing secure code "never mix code and data"
[21:00:18] <lotuseater> selwyn: i bet Bike could tell more about it
[21:00:38] <selwyn> i heard about this from bike iirc
[21:00:50] <lotuseater> oki
[21:01:48] <shka> lotuseater: oh, obviously MS engineer
[21:01:53] <shka> this explains a lot
[21:02:31] <selwyn> i like this guy
[21:04:06] <lotuseater> it's sympathic that he admits to only now after 30 years really understanding certain stuff
[21:04:23] <selwyn> well, everyone i know who has ever dealt with c++ has been very upfront about that
[21:04:52] <lotuseater> good
[21:05:04] <copec> C++ is a language that should be used a certain way, but hides what that way is really well imo
[21:05:58] <dra> Been learning C++ for close to 25 years. And there are many things I'll never remember...
[21:06:21] <lotuseater> names seem mostly not being very mnemonic
[21:06:35] <shka> been using C++ for decade, but i would rather not do that anymore
[21:06:37] <selwyn>  i briefly considered learning c++ in order to become a 'real' programmer but fairly quickly concluded it wouldn't be worth it
[21:06:39] <lotuseater> dra: but that's indeed a long time ._.
[21:07:02] <dra> shka: I know what you mean. It does pay my bills though.
[21:07:16] <selwyn> what's the point in filling your head with arcane complexity if you aren't going to use it (i don't have to)
[21:07:35] <shka> dra: quit that rockstar developer lifestyle
[21:07:49] <shka> quit cocaine, less hookers
[21:07:51] <lotuseater> selwyn: and just things others have thought are the right way
[21:08:03] <shka> and it is fine, you won't need that C++ money ;-)
[21:08:11] <copec> You know you want to just play folk music instead
[21:08:14] <dra> shka: The rockstar stuff is what I do outside of work. ;)
[21:08:31] <selwyn> lotuseater: yes exactly
[21:09:25] <lotuseater> or you start yodeling like the awesome japanese guy
[21:09:37] <copec> I've "learned" C++ several times, still have no idea what I'm doing
[21:10:20] <dra> C++ has a very braindead way to do compile-time computation. It's complex, hard to debug, so what can be done with a Lisp macro in 10 minutes requires a week or more.
[21:11:50] <lotuseater> copec: I'm too dumb for it at all.
[21:12:12] <shka> #.(+ 2 2)
[21:12:18] <selwyn> drmeister seems to enjoy c++ at times
[21:12:49] <dra> selwyn: I guess that can only be the case if you've written enough Lisp on top of it so you can escape the tar pit.
[21:13:08] <lotuseater> shka: does it count also as readtime when i evaluate that in my mind when reading it with my eyes? ^^
[21:13:11] <selwyn> well he has certainly done that
[21:13:17] <dra> selwyn: Exactly. :)
[21:13:37] <shka> the way C++ compile time stuff is the way it is because type system is the only thing that really exists at compile time in C++
[21:13:48] <shka> while in lisp, lisp exists
[21:14:23] <shka> dynamic languages are cool like that
[21:14:52] <dra> shka: Yes. And because of that, it takes a while to figure out how to do stuff in template metaprogramming, so of course it can feel like a great accomplishment when it finally works.
[21:15:22] <shka> it can, until you know how this would look in lisp
[21:15:32] <shka> and then it is just silly
[21:15:39] <dra> Exactly.
[21:16:21] <shka> you feel like you are just a hamster in hamster wheel
[21:16:32] <lotuseater> but good that you understand it
[21:16:48] <lotuseater> or a wheel in a hamster
[21:16:53] <shka> while in cl you can even use generic functions at macroexpand
[21:16:53] <dra> >::type>::type>::type>::type;
[21:17:20] <shka> also, this can result in a HORRIBLE compilation times
[21:17:29] <selwyn> hamsters appear to enjoy sisphyean labour though
[21:18:02] <dra> shka: That, and it fills up your RAM.
[21:18:26] <shka> i vividly remember project
[21:18:39] <shka> that was templated into oblivion
[21:18:59] <shka> most of the code was in the headers
[21:20:27] <dra> That sounds scary.
[21:20:48] <shka> not even the worst part
[21:21:18] <shka> the worst part is how this project did not understand the hardware 
[21:21:42] <shka> it was supposed to be distributed memory system
[21:21:59] <shka> plan was to use infiniband i heard 
[21:22:26] <shka> but all of the code was written using sockets and IP
[21:22:32] <shka> TCP IIRC even
[21:23:00] <dra> Lisp is better even for NIH. ;)
[21:23:01] <shka> lead assumed that this is how you use infiniband 
[21:23:29] <shka> yeah, NIH written all over it
[21:24:10] <shka> oh, and the initial idea was to use this for big data
[21:24:33] <shka> issue was that although you could distribute the memory, you had to pull it all into the localhost to do anything
[21:25:29] <shka> while remaining nodes were all just glorified RAM storage 
[21:26:05] <shka> and the whole thing was in development for years
[21:26:21] <shka> fractal of failure, really
[21:26:32] <shka> failure within a failure
[21:28:07] <dra> The way to use C++, in my opinion, is to stay close to C, use C++ constructs where it reduces boilerplate, use templates sparingly, and template metaprogramming very sparingly, if at all.
[21:28:44] <lotuseater> that sounds like good advice (from experience)
[21:28:56] <shka> my personal rule was to always have interface for the template types 
[21:29:10] <shka> and the interface would be a real class
[21:29:29] <shka> and use pointers to interfaces, as much as possible 
[21:29:48] <dra> shka: Pfft. Real C++ programmers would use the curiously recurring template idiom. ;)
[21:29:52] <dra> (Not!)
[21:30:18] <shka> that can also inherit an interface :P
[21:31:01] <shka> anyway, i think that templates are useful, sure, but should be tightly controlled and prohibited from infecting the whole system
[21:31:13] <shka> because that's how they work
[21:31:21] <shka> they are viral
[21:31:29] <shka> worse then the covid(tm)
[21:32:20] <lotuseater> when did it came in?
[21:33:11] <shka> overall, C++ made me dislike static typing
[21:33:29] <shka> which is horrible, but true
[21:41:46] <selwyn> what does #lispcafe think of the hypothesis that c++ is converging on becoming lisp
[21:45:05] <shka> i don't track it all that much honestly
[21:45:12] <shka> but this does not sound right
[21:45:37] <shka> C++ is, and remains to be a static language
[21:45:57] <shka> which is the most unlispy aspect there is
[21:56:44] <shka> though perhaps the templates language will become lisp at some point
[21:56:54] <shka> don't quote me on that
[22:03:17] <dra> Lisp and C++ are somewhat opposites. In C++, you add stuff to function definitions to make them generic. In Lisp, you add type declarations to make functions non-generic.
[22:03:33] <selwyn> they have lambda declarations
[22:03:46] <selwyn> *lambda expressions
[22:04:23] <shka> so is java
[22:05:52] <dra> shka: As soon as it becomes lispy enough someone will get rid of what's left of C++ within a few days. ;)
[22:16:12] <shka> dra: imagine that
[22:16:53] <shka> "so, first you start RTEL (read template execute loo), then you start programming"
[22:17:18] <shka> "we used to use gcc for other purposes, but that was kinda stupid"
[22:19:27] <shka> "we also replaced <> with () because of operator confusions"
[22:19:53] <shka> "we also moved operator within parenthesis so it is easier on the eyes"
[22:21:47] * lotuseater is confused
[22:23:57] <shka> "oh, and we added restarts to handle compilation errors"
[22:24:12] <shka> the most hilarious possible world
[22:25:09] <selwyn> shka: that will be the day
[22:26:38] <selwyn> it would be even funnier if even after all that they denounce common lisp as unworkable and impracticall
[22:29:03] <shka> they would all move to JS instead
[22:29:13] <shka> the true industry strength language!
[22:30:04] <shka> and the former C++ programmers would lament on the long lost era when graphics where easily composed with hardware support
[22:30:30] <shka> and libraries could be linked in
[22:30:41] <shka> and thus, full circle
[22:32:24] <shka> the most important thing about the programming history teaches us
[22:32:33] <shka> is that history of programming teaches us nothing
[22:32:37] <shka> :P
[22:33:03] <selwyn> like in fallout
[22:33:08] <selwyn> programming... programming never changes
[22:34:04] <lotuseater> "it can just be interpreted and has no types"
[22:34:20] <lotuseater> to be fair, in another reality we would say such things to them
[22:36:23] <lotuseater> "you can just run your fortran programs from punch cards!"
[22:43:51] <selwyn>  am reminded of the fun theory that programming is descended from knitting machines
[22:45:36] *** Quits: makomo (~makomo@user/makomo) (Quit: WeeChat 3.2)
[22:47:21] <shka> selwyn: that's where the punch cards originate from
[22:47:26] <selwyn> yes
[22:47:32] <selwyn> but can you call it programming
[22:47:40] <selwyn> well, still an ancestor i suppose
[22:49:50] <shka> technology connections
[22:50:08] <selwyn> the labour party wants its employees to use 'agile methodologies', all while planning to lay most of them off
[22:50:33] <selwyn> > It goes on to say Labour will work “collaboratively” in “multidisciplinary teams”, which will “adopt a product-mindset using agile ceremonies, be empowered to make decisions and encouraged to focus on rapid prototyping, deployment and iteration”.
[22:51:03] <selwyn> they really have copy pasted that from somewhere lol
[22:51:55] <selwyn> gnuxie: ^
[23:05:11] <shka> https://miro.medium.com/max/700/1*gZnDbPfedgZCi3IaXwCOUg.png
[23:05:19] <Gnuxie> Wtf 
[23:06:01] <selwyn> shka: this is not a bad analogy for the labour party itself
[23:06:35] <lotuseater> nice
[23:07:06] <Gnuxie> That's genuinely what some MPs think it means 
[23:08:11] <shka> yes, that's why it seemed to be relevant
[23:08:27] <shka> anyway, leftists using the corpo-talk
[23:09:37] <shka> they want to become even less relevant
[23:11:44] <selwyn> sort of
[23:12:22] <selwyn> the current faction in power believe in the inevitability of centrist victory
[23:12:29] <selwyn> if that means purging their own party, then so be it
[23:12:36] <shka> uh
[23:12:38] <selwyn> but they are not honest about their own vacuousness and lack of ideas
[23:12:50] <shka> centrists always win because whoever wins become the new center
[23:13:53] <selwyn> i suppose, but these guys are the 'old centre' of tony blair
[23:14:30] <selwyn> even though they have pivoted towards accepting brexit they are not centrists in the sense of actually being an average of what people think
[23:15:30] <shka> that was the last guy who won, right? :P
[23:15:41] <selwyn> yes
[23:15:49] <shka> my point stands!
[23:18:17] <selwyn> well, i agree that he became the new centre
[23:19:25] <selwyn> but apart from that, there is not much worth copying from him
[23:20:00] <selwyn> he has one of the least popular legacies of any democratic politician, apart from maybe g w bush
[23:21:01] <selwyn> imo he helped brexit to win the referendum by campaigning for remain, that's how toxic he is
[23:23:23] <shka> tony was essentially British Clinton, right?
[23:24:49] <selwyn> i guess but i am not familiar enough with clinton to make a detailed comparison
[23:26:26] <selwyn> short answer yes, they were end of history guys who privatised more of the economy
[23:27:51] <shka> have you read that book anyway?
[23:28:03] <selwyn> end of history? no
[23:28:39] <selwyn> i am aware that fukuyama did not mean exactly what people think he meant, but i am referring to the popular interpretation
[23:29:06] <shka> it is pretty interesting book honestly
[23:29:15] <shka> i recommend it
[23:29:21] <shka> fukuyama was wrong
[23:29:28] <shka> but he was wrong in a interesting way
[23:31:13] <selwyn> he has been fairly active recently
[23:40:45] *** Quits: treflip (~user@95.79.32.99) (Remote host closed the connection)
[23:41:24] <lotuseater> wtf https://www.youtube.com/watch?v=AXltCA1n6T8
[23:41:24] -ixelp- RICK AND MORTY LIVE ACTION Teaser Trailer (2021) Christopher Lloyd, Jaeden Martel - YouTube
[23:57:47] <selwyn> what
