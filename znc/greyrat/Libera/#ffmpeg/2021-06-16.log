[00:00:19] <Tosin> So does there exist av_filter then called "silencedetectsink" ?
[00:01:21] <JEEB> no
[00:01:40] <JEEB> a filter chain consists of buffer, buffersink and then any real filters in the middle
[00:02:07] <JEEB> buffer being what I just called buffersrc, buffersink being the sink
[00:04:05] <Tosin> I'm just confused where the AVFrames are being sent to then
[00:04:54] <JEEB> on that level you never handle single filters other than when initializing a filter chain
[00:05:22] <JEEB> or well, technically I guess I lie - since you feed and receive from those two special filters
[00:05:29] <JEEB> which are the entry and exit points of the filter chain
[00:06:07] <Tosin> Hmm, so I always have to work with two filters?
[00:06:17] <Tosin> Because all I want is the output of just one
[00:07:45] <JEEB> yes, since you never handle just one filter, you handle them as a filter chain
[00:08:09] <JEEB> which starts at a buffer (which is what's called buffersc), and then a buffersink on the output side
[00:08:24] <Tosin> Ahh i think I know know
[00:08:38] <Tosin> *now
[00:09:05] <Tosin> so in this case I should use a variable const AVFilter* abuffersink = avfilter_get_by_name("abuffersink"); to store the output right?
[00:10:16] <JEEB> I thought there was an API where you could just pass a filter chain string? although personally I found it much more understandable stitching the filters together
[00:10:56] <Tosin> I would prefer to go down the route of stitching the filters together
[00:11:34] <Tosin> I think that's the route I'm doing currently
[00:12:12] <JEEB> then you first grab the required AVFilters, then you avfilter_graph_create_filter to create a AVFilterContext instance of it
[00:12:35] <JEEB> then you utilize avfilter_link to link together two filter contexts
[00:12:49] <JEEB> AVFilter is a description of a filter, AVFilterContext is an instance of that described filter
[00:14:35] <Tosin> Okay, I'm confused what the second filter it is I need to use then
[00:14:47] <Tosin> Based on what you're saying
[00:14:54] *** Joins: NoName_ (~idk@8.20.127.195)
[00:15:16] <Tosin> I'll just try abuffersink for now
[00:15:18] *** Quits: kurosu (uid342582@id-342582.stonehaven.irccloud.com) (Quit: Connection closed for inactivity)
[00:16:47] <JEEB> abuffer -> ACTUAL_FILTERS_YOU_REQUIRE -> abuffersink
[00:17:02] <JEEB> that's the basis of a filter chain
[00:18:10] <Tosin> Ahhhh
[00:18:17] <JEEB> for audio that is
[00:18:39] <JEEB> for video that'd be the ones without a in the beginning :)
[00:18:59] <Tosin> I really appreciate your help JEEB forgive my questions, but I really feel I'm on the verge of creating the program I intended from the start and am very close
[00:19:31] <Tosin> So I need to create three different filters Contexts then, abuffer -> silencedetect -> abuffersinl
[00:19:35] <Tosin> Link them together
[00:19:53] <JEEB> and then finally avfilter_graph_config
[00:19:59] <JEEB> which attempts to configure all the links
[00:20:25] <JEEB> after which you can call avfilter_graph_dump and get a nice string representation of the filter chain that you can print or otherwise debug :)
[00:20:50] <Tosin> Awesome, and I'll be able to run the filter on audio files in main?
[00:21:06] <Tosin> I think I have the idea, I'll update you along the way
[00:24:28] *** Quits: NoName_ (~idk@8.20.127.195) (Quit: https://www.endfgm.eu/what-can-you-do/donate/)
[00:29:11] *** Quits: Riviera (Riviera@user/riviera) (Quit: leaving)
[00:29:27] *** Joins: Riviera (Riviera@user/riviera)
[00:31:13] <Tosin> Does abuffersrc always take in the parameters of time_base, sample_rate, sample_fmt, and channel_layout?
[00:31:14] *** Joins: Flabb (~Flabb@89.169.84.117)
[00:31:20] <Tosin> Or is there a way to avoid that
[00:31:34] *** Quits: Flabb_ (~Flabb@89.169.84.117) (Read error: Connection reset by peer)
[00:32:35] *** Quits: Blacker47 (~Blacker47@user/blacker47) (Quit: Life is short. Get a V.90 modem fast!)
[00:35:49] *** Quits: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu) (Quit: zsoltiv)
[00:38:37] *** Quits: Brocker (~Libera@vmi552115.contaboserver.net) (Changing host)
[00:38:37] *** Joins: Brocker (~Libera@user/brocker)
[00:41:38] <Tosin> Okay, I think I've figured that part out
[00:43:22] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/63e4c3f6ed9748a78406b6eef26bdadd/image.png
[00:44:03] <Tosin> Okay so I now I've created the three filters that I intend to chain together, abuffersrc -> silencedetect -> abuffersink
[00:47:36] *** Quits: gloomy_desktop (~ldorigo@81.161.149.37) (Ping timeout: 268 seconds)
[00:48:04] <Tosin> Is there a function to chain all three filters JEEB ?
[00:48:25] <JEEB> pretty sure I mentioned avfilter_link
[00:49:06] *** Quits: TheSashmo (~TheSashmo@207.35.238.34) (Read error: Connection reset by peer)
[00:49:38] *** Joins: TheSashmo (~TheSashmo@207.35.238.34)
[00:49:52] <Tosin> And should that be done before working on inputs and outputs or after?
[00:50:37] <JEEB> 1) create instances (contexts) for all filters 2) link filters 3) configure graph
[00:51:11] <Tosin> Okay, thank you
[00:53:12] <Tosin> Ah so av_link only links two filters together, so I'm assuming I need to link abuffersrc to silencedetect, and after that link the concatenation to abuffersink
[00:53:18] *** Joins: p9 (~p9@83.31.194.45)
[00:53:23] <JEEB> that sounds correct yes
[00:53:46] *** Parts: apteryx (~maxim@dsl-10-141-183.b2b2c.ca) ()
[00:56:21] *** Joins: dAm2K (~dAm2K@77.39.166.169)
[00:57:01] <Tosin> But after link them, how can I access the new filter created from it?
[00:57:09] <Tosin> av_link only returns an int
[00:57:27] <Tosin> Ah nevermind, I'm stilly
[00:57:29] <Tosin> *sily
[00:57:34] <Tosin> Figured it out
[00:58:06] <JEEB> http://svn.ffmpeg.org/doxygen/trunk/avfilter_8h.html
[00:58:13] <JEEB> the documentation is there
[00:58:30] <Tosin> Thank you
[00:58:52] *** Quits: TanoMarcelo (~TanoMarce@179.63.242.126) (Quit: WeeChat 3.1)
[00:59:28] *** Quits: Flabb (~Flabb@89.169.84.117) (Quit: Leaving)
[01:03:04] <Tosin> Seems I may have to go a different route since I cant link to const AV Filters, even after removing the const from before variable declaration
[01:03:11] *** Joins: luni-4 (uid453292@id-453292.charlton.irccloud.com)
[01:07:06] <JEEB> I'm pretty sure I explained the difference between filters and filter contexts
[01:07:13] <JEEB> please go scroll up and re-read
[01:08:05] <Tosin> Will do
[01:08:54] <Tosin> Ahh.. lol Thank you, I see what I need to do now
[01:17:12] *** Quits: p9 (~p9@83.31.194.45) (Ping timeout: 268 seconds)
[01:32:47] *** Joins: babyface (~babyface@user/babyface)
[01:33:06] *** Quits: shibboleth (~shibbolet@gateway/tor-sasl/shibboleth) (Quit: shibboleth)
[01:42:18] *** Quits: babyface (~babyface@user/babyface) (Quit: babyface)
[01:43:20] *** Quits: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd) (Quit: WeeChat 3.1)
[01:43:49] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[01:43:55] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/c3a7a3de8e8c94b3ebdd34ed2201b4e3/image.png
[01:44:12] <Tosin> Seems I keep running into the problem with everything I've tried
[01:45:55] *** Quits: galad (~galad@2605:6400:30:fb0b:56b5:20c1:fdb5:df37) (Quit: ZNC 1.9.x-git-111-f2cdc3db - https://znc.in)
[01:46:08] *** Joins: Vonter (~Vonter@user/vonter)
[01:46:14] *** Joins: galad (~galad@2605:6400:30:fb0b:56b5:20c1:fdb5:df37)
[01:52:23] *** Joins: Buster_ (~Buster@buster-net.ru)
[01:54:36] <Tosin> Got it
[01:55:23] *** Joins: dcompoze (~dcompoze@5E98D6D9.static.tld.pl)
[02:01:36] *** Quits: Vonter (~Vonter@user/vonter) (Ping timeout: 268 seconds)
[02:12:40] *** Quits: Buster_ (~Buster@buster-net.ru) ()
[02:13:46] *** Joins: babyface (~babyface@user/babyface)
[02:17:11] *** Quits: TheSashmo (~TheSashmo@207.35.238.34) (Remote host closed the connection)
[02:17:28] *** Joins: TheSashmo (~TheSashmo@207.35.238.34)
[02:20:00] <Tosin> After successfully running the new program, I run into some undefined behavior in the console.
[02:20:10] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/ece5235466052f95364a45eaef2bc123/image.png
[02:20:34] <Tosin> JEEB do you happen to know what could be the cause of something like this?
[02:20:46] <Tosin> I didn't even print anything
[02:21:21] *** Parts: dAm2K (~dAm2K@77.39.166.169) (Ciao!)
[02:34:56] *** Joins: finsternis (~Y@23.226.237.192)
[02:35:30] <Tosin> BtbN have you ever encountered something like this before?
[02:36:08] <BtbN> hm?
[02:36:44] <BtbN> looks like you're dumping binary data
[02:37:05] *** Joins: budo (~budo@c-24-62-207-85.hsd1.ma.comcast.net)
[02:39:01] <Tosin> I'm confused why this is even happening because I didn't even make any calls to this data
[02:39:39] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/7381124bed4f2fb61baebc146bc7dbdb/image.png
[02:40:16] <Tosin> This is the majority of what I have done in the static int init_filters() function
[02:40:56] *** Quits: mega (~iglosiggi@129-73-17-190.fibertel.com.ar) (Quit: cya!)
[02:41:12] *** Joins: mega (~iglosiggi@129-73-17-190.fibertel.com.ar)
[02:42:40] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/c79445c45a750e2c8783e2fc1c0b1e41/image.png
[02:42:55] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/5d30046ecf04ee0e6f06a6c4645cd3c6/image.png
[02:43:24] <Tosin> And this is my main function, I don't believe there is any where in my code where I attempt to dump binary data to the console
[02:43:32] *** Quits: mega (~iglosiggi@129-73-17-190.fibertel.com.ar) (Client Quit)
[02:45:34] *** Joins: mega (~iglosiggi@129-73-17-190.fibertel.com.ar)
[02:46:06] <BtbN> Can you please stop taking pictures of plain text? Use a pastebin please.
[02:47:38] *** Quits: amahl (~amahl@dsl-jklbng12-54fbca-64.dhcp.inet.fi) (Remote host closed the connection)
[02:49:30] <Tosin> Oh yes, my apologues
[02:50:54] <Tosin> https://pastebin.com/Rk96wjfD
[02:50:58] <Tosin> BtbN
[02:52:26] <BtbN> You're literally writing the frames binary data to stdout. So that console output looks exactly what I'd expect?
[02:52:41] *** Joins: arkanoid (~jack@2-238-151-49.ip244.fastwebnet.it)
[02:52:45] <arkanoid> hello!
[02:53:19] <BtbN> Not sure what you're trying to achive, but just printing the raw bytes to stdout will give you exactly that, garbled binary output
[02:53:44] <Tosin> My goal is to just print out the metadata from running the silencedetect filter on the audio
[02:54:10] <Tosin> I just want to be able to see the start, end, and duration of each interval of silence
[02:54:15] <BtbN> I don't know how it attaches that. But right now, you are printing the raw data of the frame.
[02:54:42] <Tosin> Oh I see, with the print frame function
[02:54:42] <BtbN> Might be in side data? I never checked how that filter works.
[02:54:54] <Tosin> I'll check working on it
[02:55:11] <arkanoid> I've a question. I'm currently muxing h264 + aac via mpegts as I like to have playable files even after partial transmission. Are there alternatives with similar capabilities? Is there any advantage in switching muxer?
[02:55:43] <BtbN> arkanoid, what are the exact requirements?
[02:56:04] <BtbN> Playable if you have only the beginning of the file? Or entirely random chunks of it?
[02:56:20] <BtbN> Or is it a livestream even
[02:56:49] *** Quits: budo (~budo@c-24-62-207-85.hsd1.ma.comcast.net) (Quit: Leaving)
[02:57:27] *** Joins: budo (~budo@c-24-62-207-85.hsd1.ma.comcast.net)
[02:58:13] <arkanoid> BtbN: I'm streaming, but also saving it in chunks to disk for replay later
[02:58:38] <BtbN> mpegts is probably the best choice then
[02:59:06] <arkanoid> ok, thanks
[02:59:49] *** Joins: p9 (~p9@83.31.194.45)
[03:00:29] <arkanoid> are there other formats you think I should study and consider as potential replacement? I prefer open and free formats, don't really like to stay on h264+aac|mpegts
[03:01:14] *** Quits: budo (~budo@c-24-62-207-85.hsd1.ma.comcast.net) (Client Quit)
[03:01:50] <BtbN> Not sure what you mean with "open and free"
[03:01:52] <arkanoid> I've tried theora+opus|mkv but it was not as good as the previous combination. Smaller files yes, but not playable if chunked in two parts
[03:02:02] <BtbN> literally everything in ffmpeg is open source and free
[03:02:04] *** Joins: MrZeus__ (~MrZeus@2a02:c7f:a0aa:4400:a5f4:bbcd:f4f6:ff6b)
[03:02:30] <BtbN> If you are recording a livestream, and don't want the file to be toast if anything goes wrong, mpegts is your only sane choice.
[03:02:48] <BtbN> Can remux it to something more compact and seekable after the fact
[03:02:48] *** Quits: Nact (~l@host-85-27-123-155.dynamic.voo.be) (Read error: Connection reset by peer)
[03:03:23] <arkanoid> ok thanks
[03:03:55] *** Joins: LanDi (~landi@187.19.143.243)
[03:04:08] *** Quits: fkaa (~fkaa@81-226-20-99-no256.tbcn.telia.com) (Remote host closed the connection)
[03:04:12] *** Joins: linjie (~linjie@58.247.210.251)
[03:04:12] <arkanoid> I guess I could split the pipeline after encoding: ts mux for the stream and maybe mkv for the local storage
[03:05:43] <BtbN> If your PC or recording program crashes, the file will be damaged
[03:05:51] <BtbN> mkv needs to write a lead-out at the end
[03:05:54] *** Quits: MrZeus_ (~MrZeus@37.120.198.153) (Ping timeout: 240 seconds)
[03:06:19] <BtbN> not as badly as mp4, which will outright be unuseable, but still not ideal
[03:06:23] <BtbN> hence mpegts
[03:08:11] <arkanoid> mh, ok. It is hard to find these details while skimming different formats. You were talking about muxers that requires only an header part
[03:08:19] <BtbN> hm?
[03:08:27] <arkanoid> it is much easier to get the header right, than the tail
[03:08:44] <arkanoid> I mean, you said "Playable if you have only the beginning of the file? Or entirely random chunks of it?"
[03:08:49] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 268 seconds)
[03:08:54] <BtbN> Can't write the seek index before you know the contents of the whole file
[03:09:03] <BtbN> so writing it at the start is a bit complicated, specially when live recording
[03:09:09] <arkanoid> got it
[03:09:24] <arkanoid> well, I guess I should change nothing, then
[03:09:33] <BtbN> You can move it to the front in a second step after the file is finished recording
[03:09:43] <BtbN> but anything goes wrong before it's written while recording, and the file is damaged
[03:11:17] <arkanoid> so mpegts is the only reasonable solution for this kind of problem. Cool. I've naively picked the right solution, then
[03:11:38] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Quit: Connection closed)
[03:12:50] <BtbN> flv also doesn't really care, but it also doesn't have any advantage
[03:13:19] <arkanoid> I'm curious to test the overhead of it. How to quickly convert a bunch of .ts into another container format that could let me calculate the ts overhead?
[03:13:44] <BtbN> ffmpeg literally tells you the container overhead at the end
[03:13:44] <arkanoid> without reencoding, possibly (it would invalidate the test)
[03:14:24] <BtbN> Just -c copy to the desired container to check different ones
[03:14:30] <arkanoid> ok let me re-enable the logs. After finding the right pipeline I've disabled the output. gh
[03:14:46] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[03:17:12] <arkanoid> damn, the overhead of the mpegts is huge
[03:19:16] *** Joins: NoName_ (~idk@8.20.127.195)
[03:21:48] <BtbN> well, it's designed for reliability and resilience over all else
[03:21:57] <BtbN> literally what's transmitted over the most lossy of links
[03:28:15] <arkanoid> I see that the overhead produced by ffmpeg mpegts muxer is lower than other processing pipelines like gstreamer. Point for ffmpeg
[03:29:49] <BtbN> It's just mpegts though. I don't see why different implementations would produce different sizes for the same bitstream
[03:30:07] <BtbN> a few bytes difference maybe, but nothing noteworthy
[03:31:41] <arkanoid> mkv 9.5 MB, ffmpeg mpegts 12 MB, gstreamer mpegtsmux 20 MB
[03:31:46] <arkanoid> it is quite relevant
[03:32:39] <BtbN> 9.5MB vs. 12MB sounds like normal mpegts overhead
[03:32:49] <BtbN> 12MB vs. 20MB for the exact same bitstream makes no sense though
[03:32:54] <BtbN> there has to be more data in that file
[03:33:26] <arkanoid> No, I'm actually remuxing with ffmpeg the 20 MB .ts file produced with gstreamer
[03:34:25] <BtbN> Does it have more than one video or something?
[03:34:34] <BtbN> ffmpeg by default would only map the first
[03:34:56] <arkanoid> no, just one audio channel and one video channel
[03:35:07] <BtbN> That's super weird
[03:35:30] <BtbN> either it's filling that up with garbage data, to reach a desired bitrate, or employs aggressive fec for some reason
[03:35:45] <BtbN> I'm not even sure if mpegts at that level has fec even
[03:35:55] <kepstin> looks like gstreamer's mpegts muxer defaults to retransmitting some data that ffmpeg doesn't by default
[03:36:05] <kepstin> dunno if that would account for all  the difference
[03:36:13] <BtbN> But an almost 100% size increase?
[03:38:45] <arkanoid> I've both files here, same content, gstreamer is 80% larger
[03:39:03] <znf> what does ffprobe on both files say?
[03:39:43] <znf> you sure it's only 1 video+1 audio?
[03:40:20] *** Quits: betelgeuse (~john2gb@94-225-47-8.access.telenet.be) (Read error: Connection reset by peer)
[03:40:23] <znf> maybe there's extra data like subtitles or dvb stuff? (if your source is dvb)
[03:40:25] *** Quits: der_richter (~Akemi@p2e580815.dip0.t-ipconnect.de) (Quit: Leaving.)
[03:41:20] <arkanoid> this is ffprobe on the gstreamer .ts: https://termbin.com/zxc0 , this is the ffprobe on ffmpeg .ts: https://termbin.com/gdbz
[03:41:35] *** Joins: betelgeuse (~john2gb@94-225-47-8.access.telenet.be)
[03:41:54] <arkanoid> no, just 2 channels, source is webcam and mic encoded with h264 and aac
[03:42:44] <arkanoid> I guess the wrong timestamps on the gstreamer one is due the fact that I'm chunking the live stream with multifilesink element
[03:43:04] <znf> h264 (High) (HDMV / 0x564D4448) vs. h264 (High) ([27][0][0][0] / 0x001B)
[03:43:33] <znf> no idea what HDMV is
[03:44:37] <arkanoid> well, the ffmpeg one is generated from the gstreamer one. Just "ffmpeg -i gstreamer_one.ts -c copy ffmeg_one.ts"
[03:45:17] <znf> Multiview Video Coding (MVC, also known as MVC 3D) is a stereoscopic video coding standard for video compression that allows for the efficient encoding of video sequences captured simultaneously from multiple camera angles in a single video stream.[1] It uses the 2D plus Delta method and is an amendment to the H.264 (MPEG-4 AVC) video compression standard, developed jointly by MPEG and VCEG,[2] with contributions from a number of companies, primarily
[03:45:17] <znf> Panasonic and LG Electronics.[3]
[03:45:20] <znf> is that HDMV?
[03:45:21] *** Joins: MrZeus_ (~MrZeus@2a02:c7f:a0aa:4400:a5f4:bbcd:f4f6:ff6b)
[03:45:38] <znf> As of April 2015, there is still no free and open-source software that supports software decoding of the MVC video compression standard. So popular open source H.264 and HEVC (H.265) decoders such as those used in the FFmpeg and Libav libraries simply ignore the additional information for the second view and thus do not show the second view for stereoscopic views.
[03:47:12] <arkanoid> well, not sure, the h264 feed comes from the webcam already encoded
[03:47:28] <arkanoid> this is the gstreamer -> ffmpeg output https://termbin.com/b6vy
[03:47:42] <Tosin> JEEB do you happen to remember which function it is that returns AVFrames when working with the creation of filters
[03:49:13] *** Quits: MrZeus__ (~MrZeus@2a02:c7f:a0aa:4400:a5f4:bbcd:f4f6:ff6b) (Ping timeout: 272 seconds)
[03:53:46] <arkanoid> do you see any difference between the two? How can I find out more about this problem? Is there an mpegts debugger out there?
[03:55:03] <znf> no idea, was just shooting in the dark :)
[03:57:38] <arkanoid> there's an elephant in the room and I don't see it
[03:59:52] *** Joins: TanoMarcelo (~TanoMarce@179.63.242.126)
[04:02:13] <arkanoid> I'm wrapping up a minimal example to expose the problem. It might be beneficial for both projects
[04:03:04] *** Quits: omegatron (~some@p5b056bc7.dip0.t-ipconnect.de) (Quit: What happened? You quit!)
[04:09:39] *** Joins: s0berage (~s0berage@135-23-213-77.cpe.pppoe.ca)
[04:17:06] *** Quits: p9 (~p9@83.31.194.45) (Ping timeout: 240 seconds)
[04:19:01] *** Quits: Seirdy (~Seirdy@sourcehut/user/seirdy) (Quit: exiting 3.2-dev)
[04:19:49] <Tosin> Does anyone happen to know how to log the output of a filter after running it on an audio file in C?
[04:24:55] *** Quits: LanDi (~landi@187.19.143.243) (Remote host closed the connection)
[04:26:06] *** Quits: MrZeus_ (~MrZeus@2a02:c7f:a0aa:4400:a5f4:bbcd:f4f6:ff6b) (Ping timeout: 264 seconds)
[04:26:42] *** Joins: pntaylor (~quassel@203-214-77-140.dyn.iinet.net.au)
[04:27:55] *** Quits: NoName_ (~idk@8.20.127.195) (Quit: https://www.endfgm.eu/what-can-you-do/donate/)
[04:32:58] *** Quits: luni-4 (uid453292@id-453292.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[04:35:01] *** Quits: Lynne (~lynne@ffmpeg/developer/lynne) (Quit: Lynne)
[04:36:55] *** Joins: Lynne (~lynne@ffmpeg/developer/lynne)
[04:39:42] <Tosin> Or does anyone know to process the an AVFrame with the filter?
[04:45:41] *** Quits: Lynne (~lynne@ffmpeg/developer/lynne) (Quit: Lynne)
[04:48:04] *** Joins: Lynne (~lynne@ffmpeg/developer/lynne)
[04:49:22] *** Joins: jkl (~jkl1337@2600:1700:2420:6d10::3f1)
[04:51:33] <DeHackEd> Tosin: you using silencedetect?
[04:51:39] <Tosin> Yes
[04:52:21] <DeHackEd> it logs to the av_log facility. You'll have to register your own logging handler and catch the output
[04:52:51] <kepstin> note that silencedetect sets metadata on the frames it processes, and if you're trying to use it programmatically you should be looking at that instead.
[04:53:27] <DeHackEd> oh, didn't know an AVFrame had a dictionary field
[04:53:42] <DeHackEd> even better
[04:54:03] <Tosin> Yeah I've been trying to use that too
[04:54:10] <Tosin> But I'm still stuck
[04:54:11] <DeHackEd> av_dict_* functions on the output AVFrame->metadata
[04:54:16] <Tosin> https://pastebin.com/LrDFJc4a
[04:54:20] <Tosin> Could you check out my code?
[04:55:54] <DeHackEd> so... this isn't doing anything yet, just giving an unconfigured frame to the filter chain...
[04:56:22] <Tosin> Okay, so I need to configure the frame first and then run the filter on it?
[04:58:52] <DeHackEd> you've opened the input file and set up the filter. now the usual loop is: while (av_read_frame(fmt_ctx, avpacketptr) >= 0) { avcodec_send_packet(dec_ctx, avpacket); avcodec_receive_frame(dec_ctx, frame); av_buffersrc_write_frame(ffersrc_ctx,frame); av_buffersink_get_frame(buffersink_ctx, filt_frame); /* Use filt_frame here */ }
[04:59:02] <DeHackEd> vastly oversimplified, obviously
[05:01:44] <Tosin> Ahh okay
[05:03:06] <Tosin> So in the area that you have commented , is that where I would put , ret = av_buffersrc_write_frame(buffersrc_ctx, frame);
[05:03:07] <Tosin>     ret = av_buffersink_get_frame(buffersink_ctx, frame); ?
[05:11:14] <Tosin> https://pastebin.com/SyVdTqbN
[05:11:38] <Tosin> Okay, DeHackEd this is what I've updated but after running it seems that it doesn't write the output
[05:13:13] <Tosin> Actually I think I have an idea
[05:15:28] <Tosin> Idea did not work
[05:17:15] <Tosin> I guess I just need to figure out how to display the filter_frame to console now
[05:25:32] *** xfnw is now known as vulpine
[05:26:36] *** Quits: dcompoze (~dcompoze@5E98D6D9.static.tld.pl) (Quit: WeeChat 3.2)
[05:29:01] <Tosin> DeHackEd So you'll see here that I tried using the dictionary technique that you spoke of just to get the start times to test it out, but nothing is outputted
[05:29:03] <Tosin> https://pastebin.com/dHKLGwXc
[05:30:29] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:34:55] *** Joins: vlm (~vlm@user/vlm)
[05:45:57] <DeHackEd> Tosin: have you tried replacing the string "lavfi.silencedetect.silence_start" with just the empty string in order to get any old string out of the dictionary?
[05:46:20] <Tosin> Let me try that now
[05:46:49] <Tosin> Nothing is outputted
[05:47:31] <Tosin> DeHackEd
[05:47:49] <DeHackEd> dang...
[05:48:09] <Tosin> yeah been working on it all day and I feel so close
[05:48:23] <Tosin> Just need to log the output after running the filter on the audio file
[05:49:04] <Tosin> I'm pretty confident that my init_filt has no errors or issues as I linked both the abuffersrc, silencedetect, and abuffersink all into one
[05:49:34] <Tosin> Along with that I believe the arguments passed in are correct as well
[05:50:08] <Tosin> It's just a matter of displaying the string output of the silence_start, silence_end, and silence_duration times to console
[06:04:42] *** Joins: parnikkapore (~parnikkap@user/parnikkapore)
[06:21:21] *** Quits: bencc1__ (~bencc1@5.29.11.197) (Ping timeout: 268 seconds)
[06:22:54] *** Joins: poorboy (~poorboy@104.131.46.87)
[06:23:06] *** Quits: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd) (Ping timeout: 240 seconds)
[06:44:55] <arkanoid> do you know the difference from a NAL aligned and an AU aligned h264 stream?
[06:58:51] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Ping timeout: 268 seconds)
[07:13:28] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[07:20:29] <Tosin> Hey DeHackEd do you think it could by chance be my filter description that's the issue
[07:47:22] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Quit: Ping timeout (120 seconds))
[07:48:10] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[07:51:55] <KombuchaKip> elenril: I've tried that and now I'm getting "[flac @ 0x560832783680] unable to rewrite FLAC header.".
[07:58:12] <KombuchaKip> elenril: Happens on the av_write_trailer call.
[08:00:34] <KombuchaKip> elenril: And I get a crash on the avio_closep(&ContainerContext->pb) call.
[08:00:50] *** Joins: Vonter (~Vonter@user/vonter)
[08:19:18] *** Joins: Asterisk (~asterisk@69.195.134.172)
[08:23:23] *** Quits: parnikkapore (~parnikkap@user/parnikkapore) (Remote host closed the connection)
[08:24:11] *** Quits: mega (~iglosiggi@129-73-17-190.fibertel.com.ar) (Read error: Connection reset by peer)
[08:24:28] *** Joins: mega (~iglosiggi@129-73-17-190.fibertel.com.ar)
[08:27:14] *** Quits: mega (~iglosiggi@129-73-17-190.fibertel.com.ar) (Remote host closed the connection)
[08:27:53] *** Joins: mega (~iglosiggi@129-73-17-190.fibertel.com.ar)
[08:30:21] *** Quits: mega (~iglosiggi@129-73-17-190.fibertel.com.ar) (Client Quit)
[08:31:29] *** Joins: mega (~iglosiggi@129-73-17-190.fibertel.com.ar)
[08:32:25] *** Quits: mega (~iglosiggi@129-73-17-190.fibertel.com.ar) (Client Quit)
[08:33:42] *** Joins: mega (~iglosiggi@129-73-17-190.fibertel.com.ar)
[08:33:54] *** Joins: sdueckert (~sdueckert@tmo-083-133.customers.d1-online.com)
[08:38:07] *** Quits: sdueckert (~sdueckert@tmo-083-133.customers.d1-online.com) (Remote host closed the connection)
[08:50:39] *** Joins: sdueckert (~sdueckert@tmo-083-133.customers.d1-online.com)
[08:52:50] *** Quits: sdueckert (~sdueckert@tmo-083-133.customers.d1-online.com) (Client Quit)
[08:59:01] *** Joins: viniciorl (~viniciorl@187-176-120-50.dynamic.axtel.net)
[09:01:27] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:3c1b:4db9:1174:2cd8)
[09:01:59] <zumba_addict> Good evening. My camera supports recording at 2.7k 30fps and 1080p 60fps natively. I'd like to convert the 30fps recording to 60fps but I still want the playback to make it look the original playback. Is that possible?
[09:06:58] *** Joins: linjie (~linjie@58.247.210.251)
[09:11:35] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 272 seconds)
[09:16:27] *** Joins: thomas_25 (thomas_25@pls.just.stfu-kthx.bnc4you.xyz)
[09:18:24] <Tosin> JEEB DeHackEd BtbN thanks for your help guys! I got it working , still putting finishing touches on it
[09:23:14] <elenril> KombuchaKip: that's just a warning because your IO context is not seekable
[09:29:05] <KombuchaKip> elenril: Yeah, I'm implementing that now. But there is still a crash on the avio_closep on L277: https://pastebin.com/jpFpeXCz
[09:29:06] *** Quits: arcatech (~arcatech@user/arcatech) (Ping timeout: 240 seconds)
[09:30:06] <elenril> the code for WriteIOContext is not there
[09:32:57] *** Joins: arcatech (~arcatech@user/arcatech)
[09:34:42] *** Quits: taliho (~taliho@c-73-149-98-40.hsd1.ma.comcast.net) (Quit: The Lounge - https://thelounge.chat)
[09:35:44] *** Joins: Flabb (~Flabb@89.169.84.117)
[09:41:53] <KombuchaKip> elenril: Finishing up implementing. May not be able to paste until tomorrow.
[09:44:34] *** Quits: zmt00 (~zmt00@user/zmt00) (Read error: Connection reset by peer)
[09:44:42] *** Quits: arcatech (~arcatech@user/arcatech) (Ping timeout: 240 seconds)
[09:45:25] *** Quits: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com) (Quit: Bye...)
[09:45:56] *** Joins: zmt00 (~zmt00@user/zmt00)
[09:46:06] *** Joins: s0beragee (~s0berage@135-23-213-77.cpe.pppoe.ca)
[09:47:49] *** Quits: s0berage (~s0berage@135-23-213-77.cpe.pppoe.ca) (Ping timeout: 268 seconds)
[09:56:36] *** Quits: TanoMarcelo (~TanoMarce@179.63.242.126) (Quit: WeeChat 3.1)
[10:00:21] *** Joins: dreamon (~dreamon@pd9503979.dip0.t-ipconnect.de)
[10:06:51] *** Joins: der_richter (~Akemi@p4fde494f.dip0.t-ipconnect.de)
[10:06:55] *** Quits: dreamon (~dreamon@pd9503979.dip0.t-ipconnect.de) (Ping timeout: 268 seconds)
[10:11:14] <Tosin> Does anyone know how to save the output as a string from running the function av_buffersink_get_frame() ?
[10:13:08] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Quit: Connection closed)
[10:16:33] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[10:20:59] *** Quits: zumba_addict (~zumba_add@2601:240:4500:8320:3c1b:4db9:1174:2cd8) (Quit: Client closed)
[10:26:09] *** Joins: dreamon (~dreamon@pd9503979.dip0.t-ipconnect.de)
[10:30:18] *** Quits: dreamon (~dreamon@pd9503979.dip0.t-ipconnect.de) (Ping timeout: 240 seconds)
[10:31:56] <KombuchaKip> elenril: Ok I fixed the missing seek callback that was breaking av_write_trailer for flac encoder. However, the avio_close still crashes on L272. You can see the custom AVIOContext for memory writing at L283: https://pastebin.com/fybTkVav
[10:39:34] *** Quits: Asterisk (~asterisk@69.195.134.172) (Ping timeout: 272 seconds)
[10:45:09] *** Joins: Asterisk (~asterisk@69.195.134.172)
[10:51:03] <Tosin> Does anyone know how to store the log from a filter in a string after getting the finished frame?
[10:54:37] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/7e4192359d9fd8a1d9b7954a70a98e55/image.png
[10:54:47] *** Joins: meklu (~meklu@holmes.meklu.org)
[10:55:01] <Tosin> My program produces the following output as expected after running av_buffersink_get_frame(buffersink_ctx, filt_frame)
[10:55:13] *** Joins: kurosu (uid342582@id-342582.stonehaven.irccloud.com)
[10:55:14] <Tosin> But my goal is the now store what is printed to the console in a string
[10:55:23] <Tosin> Does anyone happen to know how to do so?
[11:06:24] <galad> Tosin: set a callback: av_log_set_callback()
[11:06:37] *** pong is now known as beaver
[11:07:50] <Tosin> Do you know where I can find a reference to this function?
[11:07:57] <Tosin> I looked it up online but could not find it
[11:08:09] <galad> first result when you search it on google
[11:08:18] <Tosin> The stackoverflow link?
[11:08:27] <galad> the ffmpeg.org documentation one
[11:08:35] <Tosin> Ah thank you
[11:10:16] <Tosin> Hmm, how would this work with my program, it looks like it returns void
[11:10:23] <Tosin> galad
[11:14:53] <lilibox> hello, i have dss_sp (native) format related questions
[11:16:07] <lilibox> while i tried to convert it to mp3, some errors ocured and final .mp3 became unuseable
[11:16:36] *** Joins: houlei (uid497843@id-497843.stonehaven.irccloud.com)
[11:17:06] <lilibox> i tried dss_sp (native) to mp3 (libmp3lame), Lavc58.136.101 libmo3lame encoder
[11:17:20] <Tosin> Do I need to use av_log_set_level(AV_LOG_VERBOSE); first galad ?
[11:18:39] <lilibox> and many times i obtained [dss_sp @ 000002599a03e080] combined_pitch was too largepeed = 145x Last message repeated 32 times
[11:19:07] <lilibox> does already exist solution for this?
[11:20:08] <lilibox> unfortunatelly current .dss sample is nda, i am asking if i have to create .dss sample and send it over here to analyse
[11:34:12] *** Joins: Blacker47 (~Blacker47@user/blacker47)
[11:34:55] <elenril> KombuchaKip: ah right, avio_close() is supposed to be called only on IO opened with avio_open
[11:35:05] <elenril> so just stop calling it
[11:40:19] <Tosin> Or does anyone happen to know how to output the log to a file in C ?
[11:40:28] <Tosin> I'm not using the executable file
[11:46:26] <elenril> Tosin: log output is not meant to be parsed
[11:46:55] <Tosin> So there's no way to store it anywhere?
[11:47:04] <Tosin> elenril
[11:47:25] <elenril> there is a certainly a way, but it's not stable and may change at any time, so you should not do that
[11:47:40] <elenril> people already told you to get the information from frame metadata
[11:48:12] <Tosin> When I tried that it was unsuccessful
[11:48:40] <Tosin> I'll share the code that I tried to use
[11:52:03] *** Quits: Hackerpcs (~user@user/hackerpcs) (Quit: Hackerpcs)
[11:52:43] *** Joins: Hackerpcs (~user@user/hackerpcs)
[11:53:09] *** Joins: dreamon (~dreamon@ppp-88-217-65-69.dynamic.mnet-online.de)
[11:53:56] *** Quits: beaver (~loop@user/pong) (Quit: `test`)
[11:54:03] <Tosin> https://pastebin.com/WyYKrF82
[11:54:16] <Tosin> elenril you can see here this is the code that I implemented
[11:54:33] <Tosin> In the while look I access the dictionary, filt_frame -> metadata
[11:55:09] <Tosin> And after just testing out just the libav.silence_start key, nothing is returned even though their is detected silence
[11:55:29] <elenril> of course, you unref the frame just after getting it
[11:55:33] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/c4a4b3f684a262a2cb270cb37cdddaa4/image.png
[11:55:48] <elenril> so it's always empty when you access the metadata
[11:55:56] <Tosin> But even when I ran that while loop before it I didn't work
[11:56:06] <Tosin> Do you know where I should place that line of code then?
[11:56:19] <elenril> somewhere where the frame contains some useful content
[11:56:58] <elenril> av_frame_unref() clears the frame, so it contains nothing
[11:57:52] <Tosin> Ahhhh I think I got it
[11:58:16] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/807430df00fa65bfe813294679fc4750/image.png
[11:59:19] <Tosin> Is there a way to check for multiple keys, because I need to also get the end time
[12:00:33] <elenril> you can call av_dict_get with "lavfi.silence_"
[12:00:40] <elenril> that will iterate over all keys starting with lavfi.silence_
[12:01:28] <Tosin> You are awesome !!!
[12:01:32] <Tosin> Thank you so much
[12:01:37] *** Joins: beave (~loop@user/pong)
[12:01:49] *** Quits: beave (~loop@user/pong) (Client Quit)
[12:02:25] *** Joins: beaver (~loop@user/pong)
[12:02:29] *** Quits: beaver (~loop@user/pong) (Remote host closed the connection)
[12:02:38] <Tosin> Uploaded file: https://uploads.kiwiirc.com/files/97c4de8678a42f39c464ef5440697eaa/image.png
[12:02:44] *** Joins: MsPy (~MsPy@2402:e280:3d22:227:3178:c63c:767a:4ac4)
[12:03:41] *** Joins: beaver (~loop@user/pong)
[12:06:10] <Tosin> Now I need to figure out how to make a filter that creates an output file ... :]  appreciate everyone in the channel for all the help this week
[12:12:54] *** Quits: nd (~nd@user/nd) (Ping timeout: 264 seconds)
[12:19:23] *** Quits: beaver (~loop@user/pong) (Remote host closed the connection)
[12:22:14] *** Joins: nd (~nd@user/nd)
[12:25:30] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Ping timeout: 264 seconds)
[12:28:54] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[12:30:40] *** wacko_ is now known as wacko
[12:31:49] *** Joins: beaver (~loop@user/pong)
[12:36:08] *** Joins: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu)
[12:36:33] *** Joins: graphitemaster (~graphitem@user/graphitemaster)
[12:37:13] *** Parts: MsPy (~MsPy@2402:e280:3d22:227:3178:c63c:767a:4ac4) ()
[12:54:12] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[13:01:30] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Ping timeout: 240 seconds)
[13:03:06] *** Quits: jkl (~jkl1337@2600:1700:2420:6d10::3f1) (Ping timeout: 240 seconds)
[13:04:11] *** Quits: KombuchaKip (~kip@192.252.230.5) (Ping timeout: 252 seconds)
[13:05:49] *** Joins: fkaa (~fkaa@81-226-20-99-no256.tbcn.telia.com)
[13:06:05] *** Joins: KombuchaKip (~kip@192.252.230.5)
[13:08:43] *** Joins: linjie (~linjie@58.247.210.251)
[13:12:42] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 240 seconds)
[13:14:57] *** Joins: p9 (~p9@83.31.194.45)
[13:29:23] *** Joins: omegatron (~some@p5b056bc7.dip0.t-ipconnect.de)
[13:36:09] *** Joins: TanoMarcelo (~TanoMarce@179.63.242.126)
[13:38:27] *** qwedfg_ is now known as qwedfg
[13:48:55] *** Quits: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu) (Quit: zsoltiv)
[14:01:37] *** Quits: YakoYoku (~yakoyoku@2001:470:69fc:105::780) (Quit: Bridge terminating on SIGTERM)
[14:01:37] *** Quits: sixecho (~sixecho@2001:470:69fc:105::32) (Quit: Bridge terminating on SIGTERM)
[14:01:37] *** Quits: kepstin (~kepstin@user/kepstin) (Quit: Bridge terminating on SIGTERM)
[14:01:37] *** Quits: blue_penquin[m] (~bluepenqu@2001:470:69fc:105::829) (Quit: Bridge terminating on SIGTERM)
[14:01:37] *** Quits: idesmi[m] (~idesmitch@2001:470:69fc:105::f2b) (Quit: Bridge terminating on SIGTERM)
[14:01:37] *** Quits: memst[m] (~memst@2001:470:69fc:105::716) (Quit: Bridge terminating on SIGTERM)
[14:01:37] *** Quits: luc65r (~luc65r@2001:470:69fc:105::ee1) (Quit: Bridge terminating on SIGTERM)
[14:01:40] *** Quits: jai (~darkapex@user/darkapex) (Quit: Bridge terminating on SIGTERM)
[14:02:36] *** Quits: der_richter (~Akemi@p4fde494f.dip0.t-ipconnect.de) (Read error: Connection reset by peer)
[14:02:47] *** Joins: der_richter (~Akemi@p4fde494f.dip0.t-ipconnect.de)
[14:03:54] *** Joins: jai (~darkapex@user/darkapex)
[14:05:10] *** Joins: kepstin (~kepstin@user/kepstin)
[14:05:10] *** Joins: Guest2504 (~bluepenqu@2001:470:69fc:105::829)
[14:05:10] *** Joins: YakoYoku (~yakoyoku@2001:470:69fc:105::780)
[14:05:10] *** Joins: sixecho (~sixecho@2001:470:69fc:105::32)
[14:05:21] *** Joins: memst[m] (~memst@2001:470:69fc:105::716)
[14:05:21] *** Joins: luc65r (~luc65r@2001:470:69fc:105::ee1)
[14:05:24] *** Joins: idesmi[m] (~idesmitch@2001:470:69fc:105::f2b)
[14:07:07] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[14:07:10] *** Quits: beaver (~loop@user/pong) (Ping timeout: 252 seconds)
[14:09:28] *** Joins: beaver (~loop@user/pong)
[14:12:27] *** Quits: p9 (~p9@83.31.194.45) (Quit: Konversation terminated!)
[14:13:01] *** Quits: Guest2504 (~bluepenqu@2001:470:69fc:105::829) (Quit: Reconnecting)
[14:13:28] *** Joins: Guest2504 (~bluepenqu@2001:470:69fc:105::829)
[14:29:24] *** Guest2504 is now known as blue_penquin[m]
[14:29:43] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Ping timeout: 272 seconds)
[14:29:44] *** Joins: dionys (dionys@user/dionys)
[14:34:40] *** Joins: jos1 (~jos3@dyndsl-178-142-069-052.ewe-ip-backbone.de)
[14:53:41] *** Quits: a0z (~a0z@90.244.140.171) (Ping timeout: 268 seconds)
[15:01:01] *** Joins: luni-4 (uid453292@id-453292.charlton.irccloud.com)
[15:05:23] *** Joins: Deta (~Deta@HSI-KBW-46-223-162-222.hsi.kabel-badenwuerttemberg.de)
[15:06:45] *** Quits: Deta (~Deta@HSI-KBW-46-223-162-222.hsi.kabel-badenwuerttemberg.de) (Client Quit)
[15:07:58] *** Joins: iive (~iive@87.119.101.204.client.entry.bg)
[15:20:26] *** Quits: s0beragee (~s0berage@135-23-213-77.cpe.pppoe.ca) (Quit: Leaving)
[16:02:19] *** Quits: TanoMarcelo (~TanoMarce@179.63.242.126) (Quit: WeeChat 3.1)
[16:08:46] *** Joins: zapx (~neil@158.140.215.192)
[16:15:27] *** Quits: zapx (~neil@158.140.215.192) (Quit: leaving)
[16:16:28] *** Joins: zapx (~neil@158.140.215.192)
[16:36:52] *** beaver is now known as pong
[16:42:53] *** Joins: krjst (~krjst@2604:a880:800:c1::16b:8001)
[16:45:48] *** Joins: arcatech (~arcatech@user/arcatech)
[16:54:12] *** Joins: budo (~budo@c-24-62-207-85.hsd1.ma.comcast.net)
[16:59:49] *** Joins: TanoMarcelo (~TanoMarce@179.63.242.126)
[17:10:27] *** Joins: linjie (~linjie@58.247.210.251)
[17:14:54] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 268 seconds)
[17:30:51] *** Joins: taliho (~taliho@c-73-149-98-40.hsd1.ma.comcast.net)
[17:35:27] *** Joins: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com)
[17:40:18] *** Quits: krjst (~krjst@2604:a880:800:c1::16b:8001) (Quit: bye)
[17:41:56] *** Quits: Blacker47 (~Blacker47@user/blacker47) (Quit: Life is short. Get a V.90 modem fast!)
[17:42:25] *** Joins: Blacker47 (~Blacker47@user/blacker47)
[17:48:55] *** Joins: krjst (~krjst@2604:a880:800:c1::16b:8001)
[17:49:34] *** Quits: zapx (~neil@158.140.215.192) (Quit: leaving)
[17:50:58] *** Quits: krjst (~krjst@2604:a880:800:c1::16b:8001) (Client Quit)
[17:53:47] *** Joins: rsx (~dummy@ppp-188-174-130-150.dynamic.mnet-online.de)
[17:55:22] *** Joins: krjst (~krjst@2604:a880:800:c1::16b:8001)
[17:59:11] *** Joins: LanDi (~landi@187.19.143.243)
[18:08:10] *** Joins: toropisco (~toropisco@user/toropisco)
[18:10:52] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[18:22:44] *** Quits: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com) (Ping timeout: 268 seconds)
[18:34:09] *** Quits: Henry151 (~bishop@user/henry151) (Quit: leaving)
[18:37:09] *** Joins: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com)
[18:39:41] *** Joins: Henry151 (~bishop@user/henry151)
[18:40:36] *** Quits: Henry151 (~bishop@user/henry151) (Client Quit)
[18:41:41] *** Joins: Henry151 (~bishop@user/henry151)
[18:52:11] *** Joins: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu)
[18:52:23] *** Quits: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu) (Client Quit)
[18:52:38] *** Joins: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu)
[19:09:35] *** Joins: Tosin (~Tosin@097-085-185-009.biz.spectrum.com)
[19:10:17] <Tosin> Does anyone know if it's possible to create a filter chain of 4 different filters?
[19:10:34] *** Joins: blue_penquin (~blue_penq@gateway/tor-sasl/bluepenquin/x-11613850)
[19:10:51] <sfan5> I don't see why that would not be possible
[19:11:15] *** Joins: amahl (~amahl@dsl-jklbng12-54fbca-64.dhcp.inet.fi)
[19:13:41] <Tosin> Okay, I'm essentially trying to use the output of one and then pass them into the arguments of the next one, but I was unsure if that was possible because I need to run the second filter on the audio stream first to get the arguments for the third
[19:15:55] *** Joins: linjie (~linjie@58.247.210.251)
[19:17:07] <Tosin> sfan5 do you see where my issues lies ?
[19:18:08] <sfan5> look into -filter_complex
[19:18:40] <Tosin> I'm writing C++ code, not using the executable file
[19:19:01] <sfan5> well then do whatever is the library equivalent, I'm sure it's possible
[19:20:07] <kepstin> if you're looking at the silencedetect stuff, I'd probably do it by dropping the frames that you don't need in your own code outside the filter chain
[19:21:23] *** Quits: Henry151 (~bishop@user/henry151) (Quit: leaving)
[19:22:44] *** Joins: Henry151 (~bishop@user/henry151)
[19:23:13] <Tosin> Yeah kepstin that's exactly what I was planning to do
[19:23:19] *** Quits: Henry151 (~bishop@user/henry151) (Client Quit)
[19:23:37] <kepstin> (note that if you do that you'll probably have to clean up the timestamps yourself)
[19:23:38] <Tosin> Once I compile a list of the start and end times that I don't need, I need to run aselect to only get the frames that I do want
[19:23:50] <Tosin> That's fine kepstin
[19:24:09] <Tosin> I'm just trying to see if there's a way to do it all in one shot rather than having to write a seperate C++ file
[19:24:14] <kepstin> hmm? no, you can do it in one pass - the silencedetect filter returns the info on the frames as it does, so you can choose which frames to keep vs drop as they come out of the filter chain
[19:24:19] <kepstin> as it goes*
[19:25:42] *** Joins: Henry151 (~bishop@user/henry151)
[19:25:59] <Tosin> But the thing is I need to run the silencedetect filter on the audio first and get the output before I can run the aselect filter
[19:26:49] <Tosin> https://pastebin.com/EszJCuAP
[19:26:54] <Tosin> Here is the same of my code
[19:28:00] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[19:28:30] <Tosin> In the init_filters function, I create a chain of filters abuffersrc -> silencedetect -> abuffersink
[19:29:08] *** Quits: Henry151 (~bishop@user/henry151) (Client Quit)
[19:29:26] *** Joins: Henry151 (~bishop@user/henry151)
[19:29:36] <Tosin> After creating that, in main I run av_buffersink_get_frame(buffersink_ctx, filt_frame); to get the metadata of the intervals of silence detected
[19:29:51] *** Quits: Henry151 (~bishop@user/henry151) (Client Quit)
[19:30:30] <Tosin> My question is, is it possible for me to create a chain of filters abuffersrc -> silencedetect -> aselect -> abuffersink, And get the meta data of the intervals to pass in as arguments to aselect
[19:30:51] <Tosin> kepstin
[19:31:35] <kepstin> you don't need to use the aselect, you can just send the silencedetect to the abuffersink then do the decision on which frames to keep in your own code
[19:32:01] <BtbN> Why don't you just use silenceremove, if your goal is to remove silence?
[19:32:32] <kepstin> BtbN: discussion on this in past days - silenceremove uses a different algorithm that doesn't seem to work as well on the particular input conditions present
[19:32:49] <Tosin> The code for silenceremove is different from silencedetect, so it removes incorrect segments of silence
[19:33:04] <Tosin> Silencedetect is much better in my opinion
[19:33:18] *** Joins: Henry151 (~bishop@user/henry151)
[19:33:34] <BtbN> The easiest thing seem to be to fix the filter then
[19:33:44] *** Quits: linjie (~linjie@58.247.210.251) (Remote host closed the connection)
[19:33:56] *** Joins: linjie (~linjie@58.247.210.251)
[19:34:13] <Tosin> Is there a C example on the ffmpeg site about creating a program that produces a new output file?
[19:34:25] <Tosin> I checked filtering_audio.c but it doesn't seem to produce one
[19:34:29] *** Quits: Volgaar (~volgaar@104.66.13.93.rev.sfr.net) (Quit: WeeChat 3.1)
[19:34:30] <kepstin> there's some things that could be done to improve this in ffmpeg itself - for example the silencedetect filter could gain support for removing silence internally, or the aselect filter could get an option to operate on the metadata silencedetect produces (aselect already has code for working with metadata from the concat demuxer)
[19:34:36] <kepstin> look at the encoding examples
[19:35:02] <Tosin> Okay
[19:35:14] *** Quits: linjie (~linjie@58.247.210.251) (Remote host closed the connection)
[19:35:45] <Tosin> But kepstin I'm confused when you say "just send the silencedetect to the abuffersink" because isn't that already what's happening in my code?
[19:36:13] <kepstin> yes, and then in your code you get the AVFrames from silencedetect with metadata, right?
[19:36:22] <Tosin> Yes
[19:36:27] <kepstin> so right there you can pick which frames you want to drop, and which you want to pass to the encoder
[19:36:34] *** Joins: linjie (~linjie@58.247.210.251)
[19:37:09] <Tosin> Okay so I can use the encoder to parse of the segments I don't want rather than using aselect?
[19:37:21] <Tosin> *parse out
[19:37:21] <kepstin> no, do it yourself in your own code
[19:37:29] <kepstin> encoders just encode whatever you give them
[19:37:34] <kepstin> so you can pick what to give them
[19:38:30] *** Joins: maroloccio (~marolocci@200.243.99.194)
[19:38:52] <Tosin> Okay
[19:39:11] <Tosin> And I can pass in the frames by seconds correct? kepstin
[19:39:52] <kepstin> each audio frame contains some number of samples and is marked with the pts value indicating what time it corresponds to
[19:40:11] *** Quits: maroloccio (~marolocci@200.243.99.194) (Quit: Client closed)
[19:40:27] *** Quits: budo (~budo@c-24-62-207-85.hsd1.ma.comcast.net) (Quit: Leaving)
[19:40:56] <Tosin> Okay
[19:40:58] <Tosin> http://ffmpeg.org/doxygen/3.4/encode_audio_8c-example.html
[19:41:06] <Tosin> And is the example you were talking about?
[19:41:40] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 268 seconds)
[19:44:14] <Tosin> kepstin
[19:44:14] <kepstin> the encode_audio examples shows how to use the encoder, but in real usage you'll also need to mux it into a container
[19:46:18] <Tosin> Hmm
[19:47:45] <Tosin> So I need to be looking at both encode_audio.c and muxing.c in order to achieve this?
[19:49:39] *** Joins: maroloccio (~marolocci@200.243.99.194)
[19:50:06] <JEEB> see the transcoding example?
[19:50:17] <JEEB> that has reading, decoding, encoding and writing :P
[19:50:25] <JEEB> you might not need all of it
[19:50:37] <JEEB> but it should be an A->B example
[19:51:04] <JEEB> oh there's an audio only transcode example, too
[19:51:17] <JEEB> https://ffmpeg.org/doxygen/trunk/transcode_aac_8c-example.html
[19:51:48] <JEEB> although this seems to focus on not utilizing libavfilter for the audio resampling :)
[19:51:53] <JEEB> but should contain encoding :P
[19:51:58] <JEEB> (and writing)
[19:52:09] <JEEB> https://ffmpeg.org/doxygen/trunk/transcoding_8c-example.html
[19:52:14] <JEEB> is the full transcoding example :P
[19:52:43] <Tosin> Sheesh this going to have me busy today lol
[19:53:25] <Tosin> Okay so quick question, just to make sure I'm on the right track, and could you guys let me know if I'm missing anything I need to include
[19:56:17] <Tosin> 1) Store the intervals that I want to keep in a list or something , for example: [[3,4], [6,10], [45,68]], 2) Using these intervals pass the frames to the encoder 3) Mux them into a container 4) Output the audio file with only the frames that were selected
[19:56:56] <Tosin> I know its simplified here but is this the overall jist of what I need to do or is there more I need to take into account ? kepstin JEEB
[19:57:17] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Quit: WeeChat 3.0.1)
[20:03:02] <BtbN> Is something like this not enough? https://github.com/BtbN/FFmpeg/commit/e88a14cd79b7a0485af5af20b538e1cc2d0dfca6
[20:04:39] <kepstin> Tosin: you don't need to store the intervals? you just need to decide, as each frame comes out of the filter chain, whether you want to discard that frame or pass it onto the encoder.
[20:12:53] <BtbN> That patch seems to work fine from what I can tell
[20:20:18] *** Quits: dreamon (~dreamon@ppp-88-217-65-69.dynamic.mnet-online.de) (Ping timeout: 240 seconds)
[20:20:56] *** Joins: bencc1 (~bencc1@5.29.17.101)
[20:22:55] <Tosin> So will that patch allow me to do the goal that I have defined here? BtbN
[20:23:12] <BtbN> Since I'm very much lost what your actual goal is at this point, no idea
[20:23:29] <BtbN> But I can remove or leave over silence from audio files with it.
[20:32:40] <Tosin> That's exactly what I'm trying to do
[20:33:17] <Tosin> Just remove the intervals of silence detected with silencedetect filter BtbN
[20:33:38] <BtbN> there you go then
[20:36:13] *** Quits: houlei (uid497843@id-497843.stonehaven.irccloud.com) (Quit: Connection closed for inactivity)
[20:36:49] <Tosin> And this produces a separate output file correct?
[20:37:08] <BtbN> It just lets (a)select understand the silencedetect metadata
[20:37:11] <BtbN> what you do with it is up to you
[20:37:40] <kepstin> in particular, that patch would let you use the normal ffmpeg cli tool do to a transcode with filters removing the silence.
[20:39:51] <Tosin> How would I use this in my own code? Or do I need to create a new one using the patch?
[20:40:13] <BtbN> Just -af "silencedetect,aselect=not(silence_detected)" worked for me
[20:41:17] <Tosin> So I'm not using the command line interface, I'm writing a C++ program to eventually create a wrapper to use in C#
[20:41:58] <BtbN> Well then you can do the exact same thing, just via the API, invoking those same filters.
[20:42:52] *** Quits: maroloccio (~marolocci@200.243.99.194) (Quit: Client closed)
[20:43:02] <Tosin> Ahhhh awesome ! I really appreicate your help, forgive me for the questions but I'm really pleased with FFMPEG's services and trying to really understand and get better at it, so essentially this is what I would need to do
[20:43:27] <Tosin> Create a filter chain : abuffersrc -> silencedetect -> aselect -> abuffersink
[20:43:43] <Tosin> But for the args for aselect
[20:44:03] <Tosin> What would I pass in? "not(silence_detected)" ?
[20:44:09] <BtbN> If you're writing the code yourself anyway it's probably just as simple to discard frames when silencedetect says it's silent
[20:45:08] <Tosin> Is there an example on how to do that?
[20:45:17] <BtbN> Don't think so, way too specific
[20:45:26] *** Joins: linjie (~linjie@58.247.210.251)
[20:45:39] <Tosin> Or is there an example on how to discard frames in general?
[20:45:53] <Tosin> Like if I just wanted to discard the first 10 seconds of an audio file or something
[20:46:12] <BtbN> Just literally discard the frames and don't pass them on to the next step
[20:46:42] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[20:47:38] *** Quits: blue_penquin (~blue_penq@gateway/tor-sasl/bluepenquin/x-11613850) ()
[20:50:14] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 268 seconds)
[20:58:28] *** Joins: maroloccio (~marolocci@200.243.99.194)
[21:00:31] <Tosin> I'm just confused as to what function it is I can use to discard the frame.
[21:00:34] <Tosin> https://pastebin.com/KYwLXAgH
[21:00:46] <Tosin> here is my current loop I have where i get the frames back after running the silencedetect filter on the audio file. I think I have the general pseducocode down
[21:00:59] <Tosin> if(frame == lavfi.silence_start)
[21:00:59] <Tosin> 	while(frame != lavfi.silence_end)
[21:01:00] <Tosin> 		delete frame
[21:01:06] <Tosin> The function to delete the frame is what I do not know
[21:01:42] *** Joins: apteryx (~maxim@dsl-156-35.b2b2c.ca)
[21:01:53] <Tosin> BtbN
[21:02:04] <BtbN> None
[21:02:06] <BtbN> just don't use it
[21:02:24] <BtbN> Maybe free it if you are responsible for that
[21:03:49] <Tosin> Okay seems doable
[21:06:28] *** Quits: maroloccio (~marolocci@200.243.99.194) (Quit: Client closed)
[21:07:17] <Tosin> Okay and my final question in reference to what we were talking about earlier, suppose I wanted to create a new audio file of the same type (.wav) and wanted to pass in the frames from running this loop into the new audio file. That is when I would need to incorporate the encoding and muxing examples right? Or is there an easier way to do that?
[21:07:29] <Tosin> BtbN kepstin
[21:07:48] <BtbN> Not sure what you mean
[21:08:00] <BtbN> if you want to mux the frames, you got to use lavformat to do so
[21:08:17] <Tosin> Okay so, I basically just want to copy the frames into a new audio file
[21:08:31] <Tosin> How would I do that ?
[21:08:39] <kepstin> encoding and muxing the output is almost completely the inverse of demuxing and decoding
[21:09:03] <kepstin> very similar overall setup.
[21:09:52] <Tosin> I'm sorry I don't know what you mean by that
[21:10:13] <kepstin> and yeah, reference the audio transcoding example (transcode_aac i think?)
[21:10:24] <DeHackEd> encoding requires more decision making. select a codec, select compression options... since it's a .wav file this is preetty straight-forward and copying from the input might be enough.
[21:11:52] <Tosin> Okay
[21:12:20] <Tosin> I'll check out transcode_aac , I'll keep you all posted. Thank you
[21:12:55] <Tosin> Basically I'm just looking for an example where I can copy frames from one audio file to create another
[21:13:12] <Tosin> When I know how to do that I'll know how to achieve the current goal I have
[21:16:50] *** Joins: Narrat (~omnius@p200300df5f0a430006ea56fffe2e7cdc.dip0.t-ipconnect.de)
[21:20:10] <Hackerpcs> out of curiosity, what does the 0xfoo mean like "[https @ 0x55ea76db3600] Opening 'https"?
[21:20:32] <BtbN> The memory address of the context
[21:20:53] <BtbN> Just something that is different in case there are multiple https contexts
[21:21:20] <Hackerpcs> oh ok
[21:27:06] <KombuchaKip> elenril: Got it. No memory leaks then?
[21:27:07] *** Quits: Asterisk (~asterisk@69.195.134.172) (Ping timeout: 268 seconds)
[21:28:12] <elenril> shouldn't be, but it's always a good idea to check with valgrind
[21:28:18] *** Joins: Asterisk (~asterisk@69.195.134.172)
[21:45:29] *** Joins: jkl (~jkl@12.216.111.80)
[21:47:57] *** Quits: mickey (~user@user/mickey) (Quit: Ping timeout (120 seconds))
[21:48:09] *** Joins: mickey (~user@user/mickey)
[21:53:28] *** WereSquirrel is now known as NaviTheFairy
[22:10:48] *** Quits: luni-4 (uid453292@id-453292.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[22:25:27] *** Joins: dreamon (~dreamon@pd9503338.dip0.t-ipconnect.de)
[22:30:39] *** Quits: keypusher (keypusher@user/keypusher) (Remote host closed the connection)
[22:33:18] *** Quits: jkl (~jkl@12.216.111.80) (Ping timeout: 264 seconds)
[22:34:27] *** Joins: KittySaysMeow (~KittySays@46.39.45.125)
[22:34:32] <KittySaysMeow> Good evening, comrades
[22:34:43] <KittySaysMeow> ffmpeg -loop 1 -t 3.5 -i in1.png -loop 1 -t 3.5 -i in2.png -filter_complex "[0][1]xfade=transition=fadeblack:duration=0.5:offset=3" out.gif
[22:34:53] <KittySaysMeow> This command does a smooth transition between two frames
[22:35:10] <KittySaysMeow> But how to make a transition from last to first frame as well?
[22:36:18] *** Quits: Tosin (~Tosin@097-085-185-009.biz.spectrum.com) (Ping timeout: 264 seconds)
[22:39:06] <KittySaysMeow> Tried asking about that on freenode, lost 2 hours waiting and now I am here :D
[22:41:31] *** Quits: TanoMarcelo (~TanoMarce@179.63.242.126) (Quit: WeeChat 3.1)
[22:41:32] <znf> freewhat now?
[22:41:32] <znf> :P
[22:41:57] <znf> that being said - the docs do need updating in regards to freenode
[22:42:59] *** Joins: keypusher (keypusher@user/keypusher)
[22:44:39] *** Joins: fannagoganna (uid110488@id-110488.tinside.irccloud.com)
[22:46:22] *** Quits: pong (~loop@user/pong) (Ping timeout: 252 seconds)
[22:46:36] *** Quits: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu) (Quit: zsoltiv)
[22:46:54] *** Joins: zsoltiv (~zsoltiv@fibhost-67-12-35.fibernet.hu)
[22:48:46] <intrac> KittySaysMeow: I don't have a version of ffmpeg with xfade, but could you run it twice with the input sources reversed with a different offset time?
[22:48:48] <intrac> eg:
[22:48:59] <intrac> -filter_complex "[0][1]xfade=transition=fadeblack:duration=0.5:offset=0,[1][0]xfade=transition=fadeblack:duration=0.5:offset=3"
[22:49:22] <intrac> it quite probably won't work, but you might get lucky
[22:53:10] *** Joins: linjie (~linjie@58.247.210.251)
[22:54:39] *** Joins: TanoMarcelo (~TanoMarce@179.63.242.126)
[22:55:09] <KittySaysMeow> nope...
[22:55:27] <KittySaysMeow> i believe it is somehow done via conca and split filters
[22:56:52] <KittySaysMeow> Agggrrhhh, 247 users are here, come on. Collective wisdom, where are you :D
[22:57:46] *** Quits: linjie (~linjie@58.247.210.251) (Ping timeout: 268 seconds)
[22:57:48] <intrac> what happens if you run my last filter params?
[22:58:56] <KittySaysMeow> Too many inputs specified for the "xfade" filter.
[23:00:07] *** Joins: maroloccio (~marolocci@200.243.99.194)
[23:00:13] <KittySaysMeow> and even if i replace ,[1][0] to ;[1][0] there is another error:  GIF muxer supports only a single video GIF stream.
[23:00:44] <KittySaysMeow> No, guessing is not working, we just need someone who are familiar with how filters works
[23:01:23] <intrac> oh, right. yes ; is the separator. sorry
[23:01:50] <KittySaysMeow> I feel that is super, uber easy. Just some damn short command is missing.
[23:02:28] <intrac> did you get an error with your first command?
[23:03:18] <KittySaysMeow> No. Why? i clearly stated "This command does a smooth transition between two frames"
[23:04:10] <intrac> sorry. I didn't read that part. (very hot here and little sleep)
[23:04:18] *** Quits: nd (~nd@user/nd) (Ping timeout: 240 seconds)
[23:04:22] *** Quits: pntaylor (~quassel@203-214-77-140.dyn.iinet.net.au) (Ping timeout: 272 seconds)
[23:05:36] <KittySaysMeow> https://s3.rokket.space/t_eh7aOW.gif
[23:05:40] <KittySaysMeow> you can see the result
[23:05:44] <KittySaysMeow> smooth from 1 to 2
[23:05:49] <KittySaysMeow> and rough from 2 back to 1
[23:06:30] *** Joins: pntaylor (~quassel@ppp121-45-199-192.cbr-trn-nor-bras38.tpg.internode.on.net)
[23:07:37] <intrac> although that looks like a wipe transition has been chosen?
[23:08:02] <KittySaysMeow> just trying various transitions, it does not matter
[23:08:23] <KittySaysMeow> this one in particular is transition=diagbr
[23:09:06] <intrac> right. stick around and maybe someone with an up to date version of ffmpeg can help
[23:10:12] *** Quits: maroloccio (~marolocci@200.243.99.194) (Quit: Client closed)
[23:10:30] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 264 seconds)
[23:12:20] <KittySaysMeow> this one uses fadeblack if you're interested
[23:12:21] <KittySaysMeow> https://s3.rokket.space/t_8todLY.gif
[23:12:55] *** Quits: rsx (~dummy@ppp-188-174-130-150.dynamic.mnet-online.de) (Quit: rsx)
[23:13:38] <intrac> right, so you want that one to just fade back/forwards between the two images
[23:14:45] <intrac> perhaps explicitly sending the output of the first xfade as one of the sources to the second?
[23:15:03] <intrac> then making sure the output is mapped to a single video stream:
[23:15:20] <intrac> -filter_complex "[0][1]xfade=transition=fadeblack:duration=0.5:offset=0[mix1];[mix1][0]xfade=transition=fadeblack:duration=0.5:offset=3[out]" -map "[out]"
[23:17:40] *** Joins: nd (~nd@user/nd)
[23:44:47] <KittySaysMeow> let's see
[23:45:35] *** Quits: dreamon (~dreamon@pd9503338.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[23:47:35] <KittySaysMeow> damn, it works :D
[23:47:47] <KittySaysMeow> however it tuned it a bit
[23:47:55] <KittySaysMeow> offset=0 -> 3, offset=3 -> 6
[23:48:41] <KittySaysMeow> right, and what is I need to add one more image here?
[23:49:00] <KittySaysMeow> *what IF
[23:49:24] * KittySaysMeow is trying desperately to grasp the logic
[23:50:02] *** Quits: LanDi (~landi@187.19.143.243) (Read error: Connection reset by peer)
[23:50:52] *** Joins: Buster_ (~Buster@80.70.98.184)
[23:55:03] <KittySaysMeow> aha
[23:55:15] <KittySaysMeow> ffmpeg -loop 1 -t 3.5 -i in1.png -loop 1 -t 3.5 -i in2.png -loop 1 -t 3.5 -i in3.png -lavfi "[0][1]xfade=transition=fadeblack:duration=0.5:offset=3[mix1];[mix1][2]xfade=transition=fadeblack:duration=0.5:offset=6[mix2];[mix2][0]xfade=transition=fadeblack:duration=0.5:offset=9[out]" -map "[out]" -r 10 out10.gif
[23:55:21] <KittySaysMeow> it works
[23:55:41] <KittySaysMeow> however i am not sure if delays are set properly
[23:55:56] <KittySaysMeow> https://s3.rokket.space/t_8HEfi8.gif what do your eyes tell you?
