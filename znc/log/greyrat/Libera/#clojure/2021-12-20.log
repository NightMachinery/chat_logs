[00:17:57] *** Quits: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com) (Ping timeout: 240 seconds)
[00:22:15] *** Quits: shiranaihito_ (~textual@123-192-192-149.dynamic.kbronet.com.tw) (Quit: My MacBook Air has gone to sleep. ZZZzzz…)
[00:35:43] *** Quits: MajorBiscuit (~MajorBisc@62-52-102.netrun.cytanet.com.cy) (Quit: WeeChat 3.3)
[00:36:11] *** Joins: Ilyu (~quassel@166.215.82.79.rev.sfr.net)
[00:37:11] *** Joins: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com)
[00:48:58] *** Quits: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com) (Ping timeout: 260 seconds)
[01:03:03] *** Joins: matty_ma1 (~matt@129.222.239.110)
[01:04:01] *** Quits: Ilyu (~quassel@166.215.82.79.rev.sfr.net) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[01:05:25] *** Joins: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com)
[01:06:46] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[01:08:59] *** Joins: matty_matt (~matt@129.222.239.110)
[01:13:00] *** Quits: ToxicFrog (~ToxicFrog@198-200-100-178.cpe.distributel.net) (Ping timeout: 256 seconds)
[01:13:34] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[01:16:20] *** Joins: matty_matt (~matt@129.222.239.110)
[01:30:20] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 252 seconds)
[01:32:09] *** Joins: matty_matt (~matt@129.222.239.110)
[01:36:17] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[01:49:26] *** Joins: matty_matt (~matt@129.222.239.110)
[01:51:17] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[01:55:16] *** Joins: matty_ma1 (~matt@129.222.239.110)
[01:56:52] *** Joins: ToxicFrog (~ToxicFrog@198-200-100-178.cpe.distributel.net)
[02:07:58] *** Quits: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com) (Ping timeout: 256 seconds)
[02:40:17] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[02:46:22] *** Joins: matty_ma1 (~matt@129.222.239.110)
[02:56:06] *** Quits: TonyStone (~TonyStone@cpe-74-76-51-197.nycap.res.rr.com) (Remote host closed the connection)
[02:56:24] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 268 seconds)
[02:56:59] *** Quits: seschwar (~seschwar@user/seschwar) (Quit: :wq)
[02:58:57] *** Joins: TonyStone (~TonyStone@cpe-74-76-51-197.nycap.res.rr.com)
[03:00:17] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[03:06:31] *** Joins: matty_matt (~matt@129.222.239.110)
[03:35:41] *** Joins: matty_ma1 (~matt@129.222.239.110)
[03:40:20] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[03:44:06] *** Joins: wnh (~user@user/wnh)
[03:51:54] *** Quits: xsperry (~xs@user/xsperry) (Ping timeout: 268 seconds)
[03:54:21] *** Techcable_ is now known as Techcable
[04:09:38] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 260 seconds)
[04:15:09] *** Joins: xsperry (~xs@user/xsperry)
[04:18:52] *** Quits: mamapitufo (~mamapituf@188.30.140.224.threembb.co.uk) (Ping timeout: 256 seconds)
[04:26:00] *** Joins: matty_matt (~matt@129.222.239.110)
[04:35:13] *** Joins: matty_ma1 (~matt@129.222.239.110)
[04:43:48] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[05:28:58] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 260 seconds)
[05:30:28] *** Joins: matty_matt (~matt@129.222.239.110)
[05:35:30] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 268 seconds)
[05:46:12] *** Joins: matty_matt (~matt@129.222.239.110)
[06:12:03] *** Joins: mbuf (~Shakthi@223.178.83.73)
[06:32:51] *** Joins: matty_ma1 (~matt@129.222.239.110)
[06:45:49] *** Quits: xulfer (uid452788@id-452788.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[06:50:44] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[07:00:41] *** Joins: matty_matt (~matt@129.222.239.110)
[07:04:54] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[07:09:27] *** Quits: Nahra (~user@static.161.95.99.88.clients.your-server.de) (Remote host closed the connection)
[07:09:34] *** Joins: matty_matt (~matt@129.222.239.110)
[07:49:34] *** Joins: puchka (~marius@165.73.242.4)
[08:00:26] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[08:14:17] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[08:34:48] *** Joins: shiranaihito (~textual@123-192-192-149.dynamic.kbronet.com.tw)
[08:40:26] *** Joins: matty_matt (~matt@129.222.239.110)
[08:57:18] *** Joins: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com)
[09:17:51] *** Quits: jespada (~jespada@87.74.33.157) (Ping timeout: 245 seconds)
[09:19:41] *** Joins: jespada (~jespada@87.74.33.157)
[09:44:57] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[09:46:21] *** Joins: matty_matt (~matt@129.222.239.110)
[09:55:44] *** Quits: v3ga (~v3ga@2603-6080-5204-3b35-0000-0000-0000-18ad.res6.spectrum.com) (Ping timeout: 268 seconds)
[09:57:10] *** Joins: v3ga (~v3ga@cpe-98-25-21-91.sc.res.rr.com)
[10:17:00] *** Quits: dadinn (~dadinn@host86-134-44-103.range86-134.btcentralplus.com) (Ping timeout: 256 seconds)
[10:31:32] *** Joins: matty_ma1 (~matt@129.222.239.110)
[10:36:26] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 268 seconds)
[10:51:14] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 268 seconds)
[10:52:31] *** Joins: matty_matt (~matt@129.222.239.110)
[10:56:57] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[10:57:58] *** Joins: matty_matt (~matt@129.222.239.110)
[11:02:54] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 256 seconds)
[11:12:05] *** Joins: matty_matt (~matt@129.222.239.110)
[11:24:43] *** Joins: struchu (~struchu@62.87.192.114)
[11:48:53] *** Joins: MajorBiscuit (~MajorBisc@62-52-102.netrun.cytanet.com.cy)
[12:13:32] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[12:16:21] *** Joins: dadinn (~dadinn@82-132-213-74.dab.02.net)
[12:20:36] *** Quits: dadinn (~dadinn@82-132-213-74.dab.02.net) (Ping timeout: 240 seconds)
[12:23:59] *** Joins: matty_matt (~matt@129.222.239.110)
[12:28:09] <v3ga> ping
[12:32:18] *** Joins: egli (~user@193-47-178-139-pool.fiber.fcom.ch)
[12:39:58] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[12:41:38] *** Quits: AlaskanEmily (~AlaskanEm@user/alaskanemily) (Remote host closed the connection)
[12:42:02] *** Quits: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Ping timeout: 240 seconds)
[13:28:57] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[13:52:19] *** Joins: matty_matt (~matt@129.222.239.110)
[13:53:17] *** Quits: MajorBiscuit (~MajorBisc@62-52-102.netrun.cytanet.com.cy) (Ping timeout: 240 seconds)
[13:56:00] *** Joins: MajorBiscuit (~MajorBisc@62-52-102.netrun.cytanet.com.cy)
[13:56:37] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[14:09:45] *** Joins: matty_matt (~matt@129.222.239.110)
[14:25:31] <sobel>  pong
[14:32:02] <yeik-the-spik[m]> <tatsumaru> "v3ga: seems like selenium isn'..." <- I've used selenium from clojure a couple of times. But I just used the Java library through interop. It's not hard. But as ridcully said, scrapping is shady. Try to find an api, some endpoint meant from taking the requests you need... I think duck duck go has one that I used for something. But my memory is foggy there.
[14:35:14] <sobel> seconded
[14:35:29] <sobel> i scrape when i have to. it is my last resort.
[14:39:18] <yeik-the-spik[m]> Unfortunately I used to work with managers with scrapping as a first resort. If you are just scrapping for yourself, I guess is fine. But when you do it at an industrial scale, you are just asking for trouble.
[14:39:33] *** Joins: matty_ma1 (~matt@129.222.239.110)
[14:40:40] <yeik-the-spik[m]> We had something like 3 scrapping projects, one managed by external consultants. By the time they were briefing us on their solution, the webs we were scrapping had changed, and they had to start all over again
[14:43:20] *** Quits: puchka (~marius@165.73.242.4) (Ping timeout: 256 seconds)
[14:44:01] <yeik-the-spik[m]> Those developed in house needed constant maintenance. And that's just talking about the bad. Some of the greatest regrets of my life come from not saying "no" to scrapping projects.
[14:44:53] *** Joins: puchka (~marius@165.73.242.4)
[14:44:56] <yeik-the-spik[m]> Lawyer girlfriend recommends not sharing those regrets online...
[14:45:46] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 245 seconds)
[14:50:56] *** Joins: mamapitufo (~mamapituf@188.30.140.224.threembb.co.uk)
[14:51:12] <sobel> hehe
[14:53:20] <sobel> in my case, i scrape for clues about implementing tech of a particular collection of sites, so there definitely isn't a service that i could go to for the info.
[14:55:43] <sobel> this scrape project has resisted clean solutions for years. the dataset is too small to train any fancy automation, i suspect (~5k sites)
[14:57:50] <sobel> for lack of a better signal, we're doing keyword detection and it's not very durable or reliable (specifically keywords aren't very reusable across the site population)
[14:58:24] <sobel> not data science, but maybe data..cleverness?
[15:01:37] *** Joins: matty_ma1 (~matt@129.222.239.110)
[15:01:47] *** Joins: Ilyu (~quassel@166.215.82.79.rev.sfr.net)
[15:06:02] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[15:12:22] <v3ga> yeik-the-spik[m]: hmm fair enough, 
[15:12:57] *** Quits: matty_matt (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[15:13:24] <v3ga> truthfully i'm more of a hobbyist so i've only done minor scraping to amuse myself... and once to cheat at work(non  dev job).  
[15:25:11] <yeik-the-spik[m]> Oh, I do those all the time. If you are going to ping a server a couple of times a minute, you are probably fine.
[15:25:12] <yeik-the-spik[m]> The last time I used selenium, I had to check some items on an state run registry. Say I had to check 100. I had a script that would take the vector of the item's id, and SLOWLY open tabs and fill the registry form.
[15:25:56] <v3ga> yeah not even that much...usually once... or well it may be several as i figure it out but ive definitely never taxed anyones servers =P 
[15:26:00] *** Joins: matty_matt (~matt@129.222.239.110)
[15:33:49] <yeik-the-spik[m]> <sobel> "for lack of a better signal, we..." <- By not durable or reliable you mean the need of constant maintenance?
[15:36:10] <sobel> yeik-the-spik[m]: correct
[15:39:40] <sobel> yeik-the-spik[m]: usually a keyword is good for months or a year, but only for a specific site. i can't use the same keyword to make the same inference on multiple sites.
[15:40:02] <sobel> i mean, in practice, it's like 20-30% reusability and zero predictability on that.
[15:40:58] <sobel> so my solution is automate the 'manual' maintenance
[15:42:35] <yeik-the-spik[m]> sobel: now I am curious 
[15:46:58] <sobel> say each business you're interested in needs to buy 3rd party services for each of 2-10 products they might offer their clients
[15:47:24] <sobel> i want to know which business uses which 3rd party services
[15:48:58] <sobel> each business implements the 3rd party service on their site, but may not advertise anything specific (e.g. tell-tale endpoint URLs) on the public sites i scrape. i don't really know where i could scrape to find those in a reliable way.
[15:49:42] <sobel> so a human makes an initial inference, then we just use keywords to track when they change their implementation
[15:49:55] <sobel> it's kinda terrible
[15:53:34] <wink> is there some agreed upon practice when to use recur and when to use a helper function?
[15:53:35] <sobel> blew at least a man-month on custom parsers and attempting to look through css/js as well. i have thought about it since then, and now i believe i must use chrome/selenium and possibly also figure out how to find the right fingerprinting surfaces as the www sites are not great
[16:18:58] *** Joins: mwnaylor (~user@2601:5ce:4300:5560::68b3)
[16:21:44] *** Quits: struchu (~struchu@62.87.192.114) (Quit: WeeChat 3.3)
[16:23:39] <ridcully> wink: use recur in the helper function?  if you can make something smaller by giving it a useful new name, go for it
[16:25:54] <wink> I've never used loop and recur before and right now I don't see a lot of benefit over calling a recursive helper from inside a nicer wrapper
[16:26:16] <wink> but I guess either of the two can be nicer and/or shorter, depending on the situation
[16:31:57] *** Quits: nighcoder (~ciumbi@206.176.143.59) (Ping timeout: 240 seconds)
[16:33:09] *** Joins: dadinn (~dadinn@82-132-232-134.dab.02.net)
[16:34:42] <Solid> wink: the JVM doesn't have TCO
[16:34:52] <Solid> so that's a strong reason to use recur whenever possible :)
[16:34:53] <mwnaylor> Since before discovering Clojure, I'd gone through 𝘛𝘩𝘦 𝘓𝘪𝘵𝘵𝘭𝘦 𝘓𝘪𝘴𝘱𝘦𝘳, 𝘛𝘩𝘦 𝘓𝘪𝘵𝘵𝘭𝘦 𝘚𝘤𝘩𝘦𝘮𝘦𝘳, and some of 𝘚𝘐𝘊𝘗. With that background, recursive solutions are a natural mindset for me when in lisp mode. The recur form gives me a clear indicator in Clojure that recursion is taking place.
[16:35:01] <sobel> doesn't recur have to be in the scope of the loop to rebind the loop?
[16:35:37] <sobel> i use loop+recur pretty happily but am fuzzy on its real details
[16:36:57] <wink> good points, thanks
[16:38:50] <ridcully> wink: also to consider: loop/recur usually gives an eager result.  so if you can solve your problem with something lazy, that might be better too
[16:39:33] <wink> I guess I am (overly?) using list recursion instead of for-loops I'd write somewhere else
[16:41:14] <sobel> wink: i use map in lieu of for-loops, for the most part
[16:41:16] <ridcully> if you can share your code on some paste-site, we could give you more insight
[16:41:58] <wink> nothing in particular, I just used recur for redoing day 20 of aoc
[16:42:39] <Solid> I think for today's problem iterate is a natural fit
[16:42:40] <wink> in another lang I'd write for i=0; i<runs; i++ { foo = step(foo) } and then reuse foo
[16:42:48] <Solid> so you might want to look into that
[16:43:01] <wink> and what I have now is:  let .... im3 (loop [imx im2 r runs] (if (= 0 r) imx (recur (step imx algo) (dec r))))
[16:43:41] <mwnaylor> loop/fn recur seems to be more natural where the processing the data structure is a more dynamic process. Like depth first or breadth first tree traveresals.
[16:46:33] <mwnaylor> depth would be a stack, breadth a que. At any given node, you only know the chidren of it, plus the nodes yet to be examined. Child nodes get added to the collection of things to be seen.
[16:47:11] <ridcully> i have also used loop/recur for things like that.  but i also have for aoc a function around that basically is reduce-times (e.g. reduce over the range).  another option (but seldom seen) is reduce+reduced
[16:48:56] <mwnaylor> Is there pattern or example for reduce+reduced? 
[16:54:01] <ridcully> mwnaylor: https://clojuredocs.org/clojure.core/reduced contains examples (if you enable JS in your browser)
[16:55:05] <ridcully> it basically gives you an escape-hatch out of an reduce
[17:03:05] <mwnaylor> One I checked the docs site, I vaguely recall seeing reduced before. (I needed the JS tip, because I usually jump to links in erc via w3m.)
[17:06:08] <mwnaylor> s/One/Once/
[17:08:30] *** Joins: struchu (~struchu@62.87.192.114)
[17:10:26] *** Joins: cmiles74 (~miles@068-184-030-013.res.spectrum.com)
[17:18:58] *** Joins: matty_ma1 (~matt@129.222.239.110)
[17:23:08] *** Quits: dadinn (~dadinn@82-132-232-134.dab.02.net) (Read error: Connection reset by peer)
[17:23:24] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 240 seconds)
[17:41:36] <sobel> yeik-the-spik[m]: oh, to make matters even more fun for my scraper, the most interesting fingerprinting surfaces are all behind auth that is beyond the scope of this scraper to use ($)
[17:54:09] *** Joins: awb99 (~quassel@85-125-195-170.static.upcbusiness.at)
[18:02:07] <yeik-the-spik[m]> <sobel> "it's kinda terrible" <- Sounds like webscraping to me.
[18:03:33] <yeik-the-spik[m]> Its always such a waste of resources, on everyone's front...
[18:07:37] *** Quits: mamapitufo (~mamapituf@188.30.140.224.threembb.co.uk) (Ping timeout: 240 seconds)
[18:07:51] *** Joins: mamapitufo (~mamapituf@188.30.140.224.threembb.co.uk)
[18:33:46] <sobel> i view it like mining. if there weren't nuggets of gold in there, all that dirt would not be appealing to sift.
[18:36:57] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:995c:e86e:470c:8a37) (Ping timeout: 240 seconds)
[19:09:31] <Para> The discussions around webscraping always tend to be also quite ?_?
[19:10:40] <Para> "Hi, could we get an API for getting our data?" "Nah." "Okay, we'll just run a scraper then" "No, you can't!" Our TOS forbids it!" "Its our data, by laws in our country it belongs to us and we have full rights to access it." "Still no!" "Well we're scraping it anyways." ">:(" "...so are you going to do anything or not?" "Nah, all our customers scrape out website."
[19:22:30] <wink> ah well, I don't hate it https://github.com/winks/adventofcode/blob/master/2021/clojure/src/aoc/day20.clj
[19:22:30] <sobel> Para: Google has an API for scraping tables whole right into a Sheet
[19:22:41] <sobel> resistance become futile
[19:22:54] <wink> but it seems awfully slow, mutating all those strings
[19:24:36] *** Joins: schmudde (~schmudde@216.169.6.249)
[19:36:34] *** Quits: struchu (~struchu@62.87.192.114) (Quit: WeeChat 3.3)
[19:37:44] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:b7fd:fa95:80d6:f41)
[19:41:03] *** Joins: struchu (~struchu@62.87.192.114)
[19:41:43] *** Quits: struchu (~struchu@62.87.192.114) (Client Quit)
[19:46:56] *** Joins: ajoberstar (~user@97-116-72-197.mpls.qwest.net)
[19:56:41] *** Joins: seschwar (~seschwar@user/seschwar)
[20:14:18] *** Quits: Ilyu (~quassel@166.215.82.79.rev.sfr.net) (Read error: Connection reset by peer)
[20:14:51] *** Joins: Ilyu (~quassel@166.215.82.79.rev.sfr.net)
[20:21:58] <mwnaylor> A TOS that forbids scraping is as effective as the Black Knight in a Monty Python movie.
[20:28:25] *** Joins: atw (~user@2601:5c2:c500:76b0::8e13)
[20:30:29] <Para> I will produce an extermely vexed internal comment on our bulletin board if you do this!
[20:32:04] <mwnaylor> Is there a way generate a MapEntry other than pulling out components of a hash-map?
[20:32:29] <Para> Why would you?
[20:32:56] <Para> It's an implementation detail, you should't care about it at all :) All n-tuples are best represented by vectors.
[20:36:10] *** Quits: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[20:36:47] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[20:37:21] <yeik-the-spik[m]> I once worked at a bank. The bank had a product so you can manage multiple bank accounts from different banks. Those running that product were scraping, so lobbyist were sent to make scraping legal. But those running the actual bank web app were getting tons of scrapping. They did not like that, so lobbyist were sent to make scraping illegal...
[20:37:42] <yeik-the-spik[m]> I was not involved with either of those products
[20:39:54] <yeik-the-spik[m]> s/tons of scrapping/scrapped/
[20:40:22] <Para> These days EU has those data sharing banking directives probably for something like that.
[20:40:34] <Para> It had a very unattractive acronym as name so I don't remember what it was.
[20:40:50] <mwnaylor> I have generated vectors of key/value pairs. I can't merge those into a hash-map, without doing (apply hash-map …) over the collection.
[20:40:55] <Para> Interestingly my favorite personal finance managing app from years ago used scraping. It was insanely good in it what it does.
[20:41:19] <Para> And of course it was bought by a predatory loan company which promptly shut the whole thing down.
[20:42:07] <Para> mwnaylor: (into {} [[:a 1] [:b 2]])
[20:43:38] <yeik-the-spik[m]> Para: seems like some of the lobbying actually paid off xD
[20:43:58] <Para> PSD2
[20:44:05] <Para> Is the name of the directive.
[20:44:24] <Para> Sorry, regulation - semantics of these words are annoying.
[20:44:38] <mwnaylor> Para: Good tip. Is (into {} …) better than (apply merge {} …)
[20:44:55] <Para> Directive is basically "all countries within EU oughta change their laws to match this" while regulation is "all countries must comply to this"
[20:45:19] <Para> mwnaylor: `into` is micro-optimized for a surprisingly large set of use cases, including transducers
[20:46:30] <Para> Anyways. PSD2 has forced banks to publish certain things as open APIs which is cool, but the work is on-going and one can't do amazingly interesting things yet. But it's coming :)
[20:46:47] <Para> On the other side there's additional checks in verification so credit cards are somewhat more annoying to use now.
[20:47:46] <Para> Every seven uses require PIN code for debit style cards, for example, or if card hasn't been used for a while, 2FA verification is needed. There was a transitionary period when most webshops didn't support this and would just lock your order :D
[20:47:47] <ridcully> mwnaylor: i would expect it to be equally fast or faster.  where it really shines is, when you look at how your entries are built.  if you can build them up with a transducer you will get peak performance most likely
[20:49:36] *** Quits: mbuf (~Shakthi@223.178.83.73) (Quit: Leaving)
[20:50:32] <mwnaylor> The only time I created transducers is when I mismanage my parens and fail to include the collection in a map or filter s-exp. 🤣 🤣 🤣
[20:52:24] <ridcully> yeah, it's a bit "trappy" - kondo helps with that.
[20:54:59] <Solid> oh a linter!  that's neat
[20:56:48] <mwnaylor> I have paredit-mode enabled for my Clojure and cider buffers. That helps, but is not a perfect solution.
[21:00:34] <Para> paredit produces more broken parenthesis for me than it ever helps
[21:01:03] <Para> I'm fairly certain my mind just doesn't work the way that python-mode-for-Clojure is meant to be used.
[21:02:22] * Solid uses lispy
[21:02:29] <Solid> I couldn't survive without structural editing
[21:03:33] <ridcully> paredit is pretty much the only time where something doing a thing for me automatically does not make wanna ragequit
[21:03:42] <wink> I tried it once and hated it
[21:04:02] <wink> might want to retry, but recently I've been writing most of my "off" languages in VS Code
[21:04:06] <ridcully> this is the vim version... so no clue how good they stole goodies from emacs
[21:04:16] <wink> don't even have vim bindings enabled
[21:09:41] <mwnaylor> I thought had read something before about avoiding (into …). Turns out the advise was more tightly directed: prefer (vec …) to (into [] …).
[21:09:55] <mwnaylor> s/advise/advice/
[21:15:10] <ridcully> into is basically reduce+conj using a transient.  so you can assume, that it's roughly as good as something specialized for the task.  but where it usually wins is around the `...` in that example.
[21:15:25] <ridcully> most likely you will have a transformation to build up `...`
[21:16:49] <ridcully> if that transformation can be described with a transducer, you will not pay for some intermediate seqs if you do (into [] xf data)
[21:20:40] *** Joins: matty_ma1 (~matt@129.222.239.110)
[21:20:53] *** Joins: DasBrain (~DasBrain@user/dasbrain)
[21:24:54] *** Quits: egli (~user@193-47-178-139-pool.fiber.fcom.ch) (Remote host closed the connection)
[21:25:48] *** Quits: matty_ma1 (~matt@129.222.239.110) (Ping timeout: 268 seconds)
[21:48:13] *** Quits: raek (~raek@2.67.169.254.mobile.tre.se) (Ping timeout: 256 seconds)
[21:50:19] *** Joins: raek (~raek@2.65.8.10.mobile.tre.se)
[22:01:22] *** Quits: MajorBiscuit (~MajorBisc@62-52-102.netrun.cytanet.com.cy) (Ping timeout: 256 seconds)
[22:05:30] <sobel> yeik-the-spik[m]: last i checked, the list of bank routing numbers is still officially unpublished (we scraped for it)
[22:14:37] *** Quits: atw (~user@2601:5c2:c500:76b0::8e13) (Ping timeout: 240 seconds)
[22:21:52] <manicennui> sobel: In the US?
[22:21:58] <manicennui> It isn't public, but you can get it.
[22:23:51] <Para> Something about checks? Gah.
[22:24:25] <sobel> manicennui: yes
[22:24:32] <manicennui> https://www.frbservices.org/resources/routing-number-directory/faqs.html
[22:24:36] <manicennui> I believe that is the information.
[22:24:56] <sobel> that is probably the place i got it before
[22:27:35] <Para> Heh, reminds me how list of yearly banking holidays was for the longest time published on the website of Finland's Bank (as in the national one), and finally this year they published an API for that.
[22:27:49] <Para> Took only 103 years. *kneejerk*
[22:29:05] <sobel> tbf 70 or so of them were spent waiting for the advent of consumer networked computing
[22:29:52] <sobel> ...and also scraped a list of bank holidays to produce an API
[22:30:16] <Para> Finland got its first mainframe in 1954.
[22:30:43] <sobel> so the first demoscene meetup was what, 1955? =)
[22:30:47] <manicennui> sobel: Yeah, they require an account and you must be a financial institution now.
[22:30:50] <Para> I did a few years back ask them to create such an API, and got a response of "Hey great idea, dunno when we can add it to our backlog but it's there!"
[22:30:59] <Para> Which is also funny because Finland's Bank doesn't have any other APIs...
[22:31:08] <Para> hmmmm
[22:31:22] <Para> I would imagine first Finnish demo stuff happened in late 70s.
[22:38:37] *** Quits: mwnaylor (~user@2601:5ce:4300:5560::68b3) (Ping timeout: 240 seconds)
[22:43:25] *** Joins: ridcully_ (~ridcully@pd951f824.dip0.t-ipconnect.de)
[22:44:31] *** Quits: ridcully (~ridcully@p508ac9bf.dip0.t-ipconnect.de) (Ping timeout: 245 seconds)
[22:46:08] *** Joins: struchu (~struchu@31.183.167.255)
[22:53:38] *** Joins: son0p (~ff@181.136.122.143)
[22:56:47] *** Quits: puchka (~marius@165.73.242.4) (Quit: leaving)
[23:10:38] *** Quits: ajoberstar (~user@97-116-72-197.mpls.qwest.net) (Ping timeout: 268 seconds)
[23:21:33] *** Joins: MajorBiscuit (~MajorBisc@62-52-102.netrun.cytanet.com.cy)
[23:32:28] *** Quits: son0p (~ff@181.136.122.143) (Remote host closed the connection)
[23:37:25] *** Quits: mrmanner (29a724a13e@user/mrmanner) (Ping timeout: 240 seconds)
[23:45:24] *** Quits: struchu (~struchu@31.183.167.255) (Quit: WeeChat 3.3)
[23:50:16] *** Joins: mrmanner (29a724a13e@user/mrmanner)
