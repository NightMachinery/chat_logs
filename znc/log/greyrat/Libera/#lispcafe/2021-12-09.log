[00:13:37] <selwyn> i can't see a way to scale this design
[00:13:49] <selwyn> but doing a proof of concept in the lab would be an incredible achievement
[00:16:12] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[00:17:37] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[00:26:19] <selwyn> shka: this is a long shot but i read a speculative paper once that tried to figure out the prospects for inventing time travel/faster than light travel within the next 1000 years but can't find it
[00:26:22] <selwyn> ring any bells?
[00:26:38] <shka> nope, sorry
[00:27:41] *** Joins: random-nick_ (~random-ni@87.116.166.234)
[00:29:36] <hayley> https://www.youtube.com/watch?v=4mQYn5txqc0 ü¶ú
[00:29:36] -ixelp- Psycho Killer - YouTube
[00:30:02] *** Quits: rogersm (~rogersm@90.166.177.48) (Quit: Leaving...)
[00:32:46] *** Joins: Catie (~user@user/catie)
[00:45:11] <selwyn> well it was a fun paper
[00:50:12] <selwyn> it seems to be a common sci fi trope for some idiot to invent warp drive by themselves
[00:50:23] <selwyn> so we have to invest in that community i guess
[00:51:08] <ck_> yes, many such cases
[00:51:38] <ck_> what was that kid's movie where they create a spherical force field to fly around in? "explorers"?
[00:56:52] <selwyn> seems like it
[00:57:31] <ck_> are you still watching tng?
[01:03:19] <selwyn> not recently
[01:03:41] <selwyn> but will do soon
[01:07:10] <selwyn> i watched 'highlander' most recently
[01:08:19] <ck_> don't know whether I've ever seen it, all I can remember is a scene from the trailer. "do you feel the lightning? that's the divine energy!"
[01:09:27] <ck_> can the movie serve as a simile to view the pandemic situation through? every highlander a greek letter and so on
[01:13:04] * shka started the third season of the doom patrol
[01:29:44] <selwyn> well, they skipped 'xi'
[01:37:06] <ck_> out of cowardice probably
[01:37:38] <ck_> but I wouldn't have even noticed -- it's not like all the predecessors got equal representation in the news
[01:38:40] <ck_> didn't really hear of beta, epsilon, zeta, eta, theta, iota, kappa, or mu
[01:49:33] <Alfr> Good morning.
[01:50:39] <selwyn> good morning
[01:53:03] <sham1> Good late evening
[01:55:59] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[02:41:39] *** Quits: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 265 seconds)
[02:42:03] *** Joins: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
[02:50:46] *** Joins: dra (~dra@2a04:4540:6408:da00:a179:6502:b833:e628)
[02:50:48] <dra> Hello!
[02:52:32] <hayley> Hello!
[03:00:24] *** Quits: random-nick_ (~random-ni@87.116.166.234) (Ping timeout: 268 seconds)
[03:15:54] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 256 seconds)
[03:16:55] <gilberth> Moin #lispcafe!
[03:19:51] <hayley> Good morning beach!
[03:20:39] <gilberth> beach awake? I doubt it.
[03:24:19] <hayley> "Register for CIAIRI‚Äôs AI Skills Bootcamp and join the next generation of AI leaders! Running from 31 January ‚Äì 18 February 2022 at the low cost of $35 per unit, this is a unique opportunity to meet industry experts from <bloop> University, Microsoft, and Prodigy Learning including Rita Arrigo (CIAIRI), Lee Hickin (CTO Microsoft) and Michelle Sanford (Microsoft)."
[03:24:22] * gilberth is waiting for his keyboard to be shipped and get impatient.
[03:24:39] <hayley> Hmm, no.
[03:25:01] <gilberth> No?
[03:25:17] <hayley> "no" to the "AI skills bootcamp".
[03:26:20] <gilberth> You don't want to meet celebrities from Microsoft?
[03:26:35] <hayley> Shocking, but no.
[03:26:47] <gilberth> They once were a Lisp vendor.
[03:27:13] <hayley> Yes, they are not a Lisp vendor now.
[03:27:20] <hayley> Unless there's a Visual Common Lisp .NET now?
[03:27:29] <gilberth> Heh.
[03:27:43] <moon-child> I hold a grudge against microsoft; back in the late 90s/early 2000s, they solicited feedback from apl implementors on .net design and then ignored it
[03:27:55] <gilberth> I would have loved a Turbo Lisp back in the days. At least there was Turbo Prolog.
[03:27:57] <moon-child> (kinda like google/mozilla with cl and wasm.  ANyway.)
[03:28:00] <hayley> Speaking of, https://www.reddit.com/r/linux/comments/rb2xzk/dave_plummer_aka_daves_garage_former_microsoft/
[03:28:28] <hayley> First this guy does a video with a non-negligible part on .NET / JVM bytecode like it matters for performance, and now this. lol
[03:29:01] <hayley> Total confirmation bias, of course, but it supports my guess that he's a bit of a moron.
[03:30:37] <gilberth> A binary blob? Really?
[03:31:43] <gilberth> Doesn't matter, we should all use C to save the climate, don't we?
[03:33:49] <hayley> Yes, still pretty dumb to compare "100% ¬± \eps binary blobs" to "mostly not binary blobs" anyway.
[03:34:30] <gilberth> What's the fuzz? The firmware blobs? For WiFi?
[03:34:45] <hayley> Apparently Linus Torvalds wrote one himself.
[03:35:38] <gilberth> Ah, what for? Why?
[03:36:09] <hayley> Good question.
[03:37:43] <hayley> OTOH as blobs have no capabilities, it only takes one bad blob to pwn you.
[03:37:55] <gilberth> Your post has no information. It only claims that a certain Dave claimed something with no references.
[03:40:42] <hayley> Ok, here's a reference
[03:41:14] <hayley> https://www.youtube.com/watch?v=PqWjq2SdzpI&lc=UgwFYyE8lw0hQzBQj154AaABAg scroll to comments, then "view 45 replies from Dave's Garage and others"
[03:41:15] -ixelp- EXPOSED: The Windows Rootkit Scandal by Sony - YouTube
[03:44:44] <gilberth> Dammit, I opened that link without a opening a "private" window first.
[03:45:15] <hayley> Don't worry, the binary blobs in...XNU will rat you out anyway.
[03:46:21] <waleee> destroying a carefully tended youtube-algorithm state is annoying
[03:47:07] <gilberth> YT will now recommend silly videos out of a certain Dave's garage to me now. Still, I don't find a pointer to said blob. Where is the blob?
[03:47:21] <hayley> https://www.youtube.com/watch?v=mz_EeEN_YXQ
[03:47:22] -ixelp- Joe's Garage - YouTube
[03:47:32] <hayley> Yes, he probably can't provide one.
[03:48:03] <gilberth> So I still say: "Citation needed"(tm)
[03:49:17] <waleee> mindboggling that google doesn't do a paid premium-service to youtube, algorithm-state rollbacks
[03:49:38] <waleee> or is that a thing already
[03:50:17] <hayley> Everyone said [citation needed].
[03:52:28] <gilberth> waleee: They could do as amazon, whose recommendation I actually like to browse, does and have an option "No, I am really not interested, don't show me again."
[03:54:15] <gilberth> Albeit, Amazon believes I am a woman. It perhaps is wiser than I am.
[03:55:49] <hayley> https://www.youtube.com/watch?v=7_kIjBaxhO0
[03:55:49] -ixelp- Conversation (Remastered 2009) - YouTube
[03:59:22] <Alfr> hayley, you really should consider falling back on "someone said", as showing "everyone said" is a fair bit of work.
[04:00:03] <hayley> Everyone in the replies more or less said [citation needed].
[04:02:19] *** Quits: dra (~dra@2a04:4540:6408:da00:a179:6502:b833:e628) (Ping timeout: 252 seconds)
[04:10:37] <gilberth> Anyhow, isn't it a bit late to write^Wmake a video about the Sony root kit? And isn't is a bit cheap to place Amazon affiliate links?
[04:12:21] <gilberth> Especially to Sony products, which I boycott since that very root kit. And how long is that ago? 20 years?
[04:16:29] <hayley> Yes.
[04:19:26] <gilberth> For sth completely different, hayley, my Rust expert. Do I get this right, that would I dare to write a Lisp in Rust, I would need to hack my own GC?
[04:19:44] <hayley> Yes.
[04:20:03] <hayley> There might be libraries for it, but they are mediocre. And there is refcounting in the standard library if you are bored.
[04:20:35] <moon-child> write the whole implementation in terms of a big array of ints
[04:20:38] <gilberth> RC won't do.
[04:20:53] <moon-child> otherwise you will not be allowed to share things and it will be a big mess
[04:21:08] <hayley> e,g, https://github.com/Manishearth/rust-gc
[04:21:08] -ixelp- GitHub - Manishearth/rust-gc: Simple tracing (mark and sweep) garbage collector for Rust
[04:21:23] <gilberth> moon-child: That would have been my next question. And that's easy. I have a Lisp implementation in MBASIC-80 using arrays and a mark-sweep collector.
[04:22:03] <hayley> IIRC there is an Immix implementation or two as well.
[04:22:54] <gilberth> Yes, but that sure involves unsafe code, doesn't it?
[04:23:13] <hayley> Yes.
[04:23:28] <gilberth> Anyhow, I perhaps install Rust and learn it, so I get a better grasp.
[04:24:08] <gilberth> I mean using unsafe code for GC would be like using the Boehm collector for C and claim C would have GC.
[04:24:29] <hayley> Mutexes require unsafe code, RC requires unsafe code...
[04:25:10] <gilberth> Isn't RC a core feature of Rust?
[04:25:22] <moon-child> library feature afaik
[04:25:25] <hayley> It's in the standard library, but not "core".
[04:25:31] <moon-child> (which makes it even slower, probably...)
[04:25:49] <hayley> Like how a hash table isn't a core feature of CL, I guess. You could implement it yourself.
[04:25:59] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[04:26:22] <dave0> maw
[04:26:22] <gilberth> ok. I don't care about speed or implementation details here, rather if that is considered part of the language library or not.
[04:26:23] <moon-child> generic functions aren't a core feature of cl
[04:26:50] <Alfr> moon-child, just don't say that when beach is around.
[04:26:56] <gilberth> Apart from CL having no core. Unfortunately.
[04:27:12] <hayley> It's in the "std" library, so you tell me.
[04:27:19] <hayley> https://doc.rust-lang.org/std/rc/struct.Rc.html
[04:27:20] -ixelp- Rc in std::rc - Rust
[04:27:59] <gilberth> I would consider it then part of the language. As CLOS is part of CL, or malloc(3) is part of C.
[04:29:43] <gilberth> As in: You can't really implement <stdio.h> in just "core" C. Or a feasible malloc(3) unless you bet on over-commit.
[04:30:06] <gilberth> Yet, stdio.h and malloc(3) are part of ISO C99.
[04:31:30] * hayley wonders if RPLACA/RPLACD can be implemented with Rc<ConsCell> or equivalent. She doesn't remember the rules around Rc exactly.
[04:32:38] <gilberth> About CLOS: The only thing that would really hard to implement feasible with no CLOS being there are funcallable instances. The rest is easy.
[04:37:35] <gilberth> Anyhow, what I am after is to get a grasp of Rust's memory management. I fear there is none usable. I need to do some reading.
[04:38:57] <selwyn> hash tables aren't core features of cl?
[04:39:30] <pjb> not really.
[04:39:35] <pjb> just some data structure.
[04:39:36] *** Joins: kakuhen (~kakuhen@user/kakuhen)
[04:39:39] <gilberth> CL has no core. But once you have a primitive to get an EQ hash code, you could implement them with just the rest.
[04:40:28] <gilberth> You could without, but that won't be hash tables any longer.
[04:41:18] <gilberth> And: When you EQ hash by the address an object is stored at, you need a GC hook in case objects move.
[04:42:48] <moon-child> or put a hash slot in objects, as java does
[04:43:13] <moon-child> (though this is not such a good idea for conses...)
[04:43:13] <gilberth> Whatever. It still would be a primitive.
[05:10:25] <hayley> So that Node.JS Discord malware stuff I found was just an obfuscated version of <https://github.com/Stanley-GF/PirateStealer>.
[05:10:25] -ixelp- Sign in to GitHub ¬∑ GitHub
[05:10:29] * hayley grumbles
[05:11:14] <selwyn> why grumble
[05:11:43] <hayley> Because I could have just looked up the symbols that didn't get obfuscated, e.g. pwnBetterDiscord, and land on this code.
[05:12:19] <hayley> https://jfrog.com/blog/malicious-npm-packages-are-after-your-discord-tokens-17-new-packages-disclosed/ Someone put the code in a node library too? lol
[05:12:20] -ixelp- Malicious packages in npm enable theft of Discord tokens, other data
[05:17:57] <gilberth> Why do I need to sign in to github to see that link?
[05:18:13] <hayley> https://www.cvedetails.com/cve/CVE-2021-38759/ lol
[05:18:14] -ixelp- CVE-2021-38759 : Raspberry Pi OS through 5.10 has the raspberry default password for the pi account. If not changed, att [...]
[05:18:33] <hayley> Good question.
[05:18:42] <hayley> I'd suspect they want to block automated downloads for obvious reasons.
[05:21:47] *** Quits: Catie (~user@user/catie) (Quit: going home)
[05:30:59] <gilberth> Does Rust use C style error handling all around? That is, the return value of a function is an error code, I need to check?
[05:31:26] <moon-child> yes
[05:31:28] * gilberth takes a hello-world-ish tutorial.
[05:31:49] <gilberth> ok, well then.
[05:32:43] <hayley> Just do foo().unwrap(); rather than foo() || abort();
[05:35:25] <gilberth> I see .expect("Some error") in the toy examples.
[05:35:45] <hayley> Yes, unwrap doesn't name what went wrong.
[05:36:02] <gilberth> "Some error" doesn't either.
[05:36:13] <selwyn> i wonder what algorithm these ai generators use
[05:37:56] <hayley> gilberth: Which tutorial?
[05:39:37] <gilberth> About what shka said about polynomials. That made me thinking. You can sure build an artificial physicist. You give it a pile of experimental measurements and it perhaps could come up with a near optimal formula for predictions. By optimal, I mean small and nice and yet with a very high chance to predict.
[05:40:26] <gilberth> But that won't make this AI come up with a good model. In the sense that there is no good explanation of what happens.
[05:41:09] <gilberth> hayley: The first one I found: <https://doc.rust-lang.org/book/>
[05:41:09] -ixelp- The Rust Programming Language - The Rust Programming Language
[05:41:26] <hayley> Okay, that guide should be okay. Just have to stomach the language.
[05:42:14] <hayley> "Accessing data in the heap is slower than accessing data on the stack because you have to follow a pointer to get there." Vat ze fak
[05:42:42] <gilberth> Milady, I am bored and go through. Everyone talks about Rust and I want to get my own idea of what it is about and how it works or does not work.
[05:42:56] <gilberth> hayley: lol.
[05:43:15] <hayley> "Contemporary processors are faster if they jump around less in memory." mad cause no compacting
[05:43:31] <moon-child> tbf there is a 'stack engine'.  and zen2 has a memory renamer which only works on stuff aliasing the stack
[05:43:36] <moon-child> buuuuut...lol
[05:43:48] <gilberth> hayley: You almost owe me a new keyboard. Lucky you I already ordered one, I am still waiting for it to be shipped though. :(
[05:45:09] * hayley uploaded an image: (102KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/ucVzcyWmqWICSIoxfVuFqJiy/stack-allocation.jpeg >
[05:45:19] <gilberth> What perhaps was meant is the activation frame and compilers trying to stack allocate that frame and even put lexicals into registers.
[05:46:56] <gilberth> But: Even other data thought to live in the heap can wind up to live in registers.
[05:47:40] * gilberth shuts up and continues with that Rust book.
[05:49:09] <moon-child> moreover, the opposite can happen.  This is a very fun optimization I read about somewhere, where you can spill registers into atomic memory as long as you later have another write to that memory such that no other thread could observe the spilt values 
[05:49:29] <moon-child> (under c++ memory model, that is)
[05:49:53] <moon-child> (I am probably butchering it)
[05:49:58] <moon-child> is it worth it vs just stack-allocating?  Probably not, considering such memory is likely to be contended.  But it is still really fun
[05:51:24] <gilberth> What is atomic memory?
[05:51:30] <hayley> .oO( <https://shipilev.net/jvm/anatomy-quarks/11-moving-gc-locality/> though you can guess the guy is biased. )
[05:54:06] <moon-child> gilberth: _Atomic
[05:55:03] * gilberth is at the { Ok(num) => num, Err(_) => continue, } part now and don't know what that is and takes it as funny syntax for a conditional. And why the extra ","? /me shrugs and reads on.
[05:55:18] <gilberth> moon-child: ok.
[05:55:31] <hayley> match { ... } is pattern matching. And idk why they like the extra comma, but they do.
[05:57:35] <gilberth> I'll try to keep an open mind, no point in reading that book with a bias. .oO(Rust is great! Rust is great! Best since sliced bread!) .oO(RLY?) .oO(Shut up!) /me reads on.
[05:57:54] * hayley prepares hammer
[05:58:26] <gilberth> Milady! Now, you owe me a keyboard.
[05:58:41] <hayley> What, I haven't used it yet.
[05:58:54] * gilberth tries to removes spilled coffee from the keycaps.
[05:59:23] <gilberth> See. The 's' is hitsing bys istself.
[05:59:45] <dave0> s for space
[06:00:14] <gilberth> Yep, I only need more pace then.
[06:03:09] <hayley> gilberth: https://wordsandbuttons.online/so_you_think_you_know_c.html
[06:03:58] <gilberth> You don't want me to finish that Rust book, do you? Is that link safe?
[06:04:44] <hayley> It's safe, just 5 questions on C.
[06:05:04] * hayley got 3/5 and doesn't know much C arguably.
[06:06:15] <gilberth> Beings with, that you can't answer the first question. Only sizeof(char)=1 is defined, all other could be anything.
[06:06:28] * hayley nods
[06:06:33] <hayley> There is an "I don't know" option.
[06:06:35] <gilberth> See. My beykoard still hebaves funny.
[06:09:13] <dave0> doh i only got 1 point
[06:09:28] <gilberth> 5/5
[06:10:01] <gilberth> All questions refer to UB.
[06:10:18] <moon-child> not all are undefined, some are only unspecified
[06:10:29] <moon-child> e.g. the sizeof ones
[06:10:40] <gilberth> Though the answer "I don't know" is wrong. It should be "It's not defined."
[06:11:02] <moon-child> (and the char overflow one it is unspecified whether or not it is undefined, as char may be signed or unsigned)
[06:11:03] <gilberth> moon-child: sizeof(int) could as well be 1.
[06:11:11] <moon-child> gilberth: really 'it is not valid c'
[06:11:45] <gilberth> moon-child: chars could be of any width not less than 8 bit.
[06:13:03] <moon-child> yes.  But the _behaviour_ is not undefined in those cases, only unspecified
[06:13:17] <moon-child> UB means 'the standard places no constraints on the behaviour of' or something along those lines
[06:13:26] <gilberth> I'd say it's valid C, yet with undefined behavior. Or rather machine-specific behavior. The sizeof(a)==sizeof(a+b) is valid, yet the result might be 1 or 0.
[06:13:44] <dave0> that asks sizeof(short)==sizeof(int)
[06:15:01] <dave0> ' '*13 is a bit dodgy because everthing is ascii and space is 32
[06:15:07] <gilberth> moon-child: Exactly. But sizeof(a)==sizeof(b) is valid and legit. There are constraints, like sizeof(int) being a constant.
[06:15:41] <moon-child> dave0: 'everything'?
[06:16:05] <moon-child> gilberth: yes
[06:16:19] <dave0> okay kinda yeah abcdic
[06:16:28] <gilberth> There are more promises. void my_memcpy (char *d, char *s, size_t n) { while (n--) *d++=s++; } is guaranteed to work in { int a, b; ... my_memcpy (&a, &b, sizeof (int)); }
[06:17:33] <moon-child> gilberth: https://nhaehnle.blogspot.com/2021/06/can-memcpy-be-implemented-in-llvm-ir.html
[06:17:34] -ixelp- Tagebuch eines Interplanetaren Botschafters: Can memcpy be implemented in LLVM IR?
[06:18:12] <gilberth> See trap representation for char's. An implementation with sizeof(void*), sizeof(char), sizeof(int), sizeof(double) al being equal to 1 would be a legit C99 implementation, even if char would be just 8 bits.
[06:18:31] <moon-child> dave0: c explicitly distinguishes a 'source character set' and an 'execution character set'.  And even common lisp does not specify an encoding; CHAR-CODE and CODE-CHAR can do whatever they like
[06:18:44] <moon-child> gilberth: short and int must both be at least 16 bits
[06:18:58] <moon-child> long must be at least 32, and long long at least 64
[06:19:20] <gilberth> And? This does prevent sizeof(char)=sizeof(int) with char being just 8 bits.
[06:19:36] <gilberth> * does NOT
[06:19:46] <moon-child> ha
[06:19:51] <moon-child> good point
[06:20:19] <moon-child> hmm, char can not have trap representations, I think.  So if you access an int as a char, what do you get?
[06:21:56] <gilberth> Say you write a C to CL compiler. And all you have is Lisp objects. It would be natural to have just Lisp integers for char and int and just Lisp floating pointers for 'float' and just some other objects for points. You still can implement memcpy in C, as char may take a trap representation.
[06:22:53] <gilberth> That is what *s++ in memcpy reads does not need to be a value which could be otherwise used as a 'char' in arithmetic. It could be your Lisp object and *d++=*s++ will store that fine.
[06:23:09] <hayley> https://www.youtube.com/watch?v=_tHIieA7TBc
[06:23:09] -ixelp- We Have A Technical (Remastered) - YouTube
[06:23:44] <gilberth> And this is a pretty clever move of the ISO C standard.
[06:25:55] <gilberth> moon-child: Interesting article. Thanks!
[07:03:45] <mfiano> Purely from a user interface standpoint (Unix-style command line arguments), what would be a good way to denote "print the statistic N times" vs "print the statistic forever"? I'm tempted to split these options up into separate mutually-exclusive options, as denoting 0 <= forever is not very user-centric.
[07:04:20] <moon-child> 'Unix-style command line arguments'  :/
[07:07:05] <moon-child> mfiano: how about: a 'print statistics' toggle, and a 'limit statistics printing to n times' switch which, if not supplied, will allow the statistics to continue uninterrupted forever
[07:07:16] <moon-child> alternately, let the user specify that n=‚àû
[07:09:48] <mfiano> Well a toggle doesn't make a whole lot of sense, unless I'm misunderstanding. The bread and butter of this tool is to print at least 1 statistic and then exit, or N (with a delay period) statistics and then exit, or ‚àû statistics.
[07:11:34] <mfiano> The default case should be print one thing and exit.
[07:12:57] <moon-child> ok
[07:15:40] <gilberth> Why not then have one option to to print n lines, with a default of 1, and another for infinity. Like "-f" for tail(1)?
[07:17:23] <gilberth> It would then somewhat mimic tail(1) in behavior and thus be familiar.
[07:19:01] <mfiano> This program would be more like vmstat than tail, so maybe I'll go with something like their interface.
[07:47:45] * gilberth tries to install rust-mode for Emacs and finds a rust-toggle-mutability function. .oO(Rust is great! Rust is great! Chakachaka!) .oO(R..) .oO(Shut up!) There must be a good reason for this 'mut' thing, I'll learn.
[07:49:12] * hayley is reminded she can't come up with jokes on the fly.
[07:49:43] <hayley> "I'm a centrist, I get equally annoyed by leftists and post-leftists sometimes" The joke is that is _not_ the typical definition for centrism.
[07:54:54] <gilberth> So what is a centrist?
[07:55:24] <hayley> Someone who is not awfully attracted to the left or right politically.
[07:55:52] <hayley> There was a joke like "I'm a centrist, I like both anarchism and Marxism" but that is a dumb thing to do, so I made a better joke.
[07:57:23] <moon-child> https://www.kleinbottle.com/
[07:57:24] -ixelp- Acme Klein Bottle
[07:57:27] <hayley> gilberth: Do you need a hammer for your .oO(...) or not?
[07:58:55] <gilberth> hayley: I am still fine learning this very nice language. It will make me a better and more productive programmer. Thanks.
[07:59:27] <hayley> Alright
[07:59:30] * hayley lines up the hammer
[08:00:52] * gilberth continues reading enjoys the cargo cult. .oO(Chakchakachaka!)
[08:02:03] <gilberth> Seriously, they call their whatever manager "cargo"?
[08:02:38] <hayley> Yes.
[08:03:02] <waleee> cargo has 1 annoying issue, if you "clean your cache" aka  rm -rf .cargo, you wipe out the existence of rustup
[08:04:00] <waleee> (the rust roswell-tool)
[08:04:48] *** Joins: contrapunctus (a75f5b1571@jabberfr.org)
[08:08:52] *** Quits: semz (~none@user/semz) (Ping timeout: 265 seconds)
[08:21:32] *** Joins: semz (~none@user/semz)
[08:23:43] <hayley> https://wjwh.eu/posts/2021-10-01-no-syscall-server-iouring.html
[08:23:43] -ixelp- The blog of wjwh - Stupid tricks with io_uring: a server that does zero syscalls per request
[08:24:12] <moon-child> io_uring is cute, but dumb
[08:24:26] <moon-child> what if I _want_ sync?  Can you they make that fast too?
[08:26:02] <hayley> Yes, install üÜëüÖæÔ∏èüÜò
[08:32:50] <gilberth> Wait a second. *rubseyes* I need to check for integer overflow explicitly as it otherwise just happens, yet I can't pass an i8 to an i32? Hell, even Pascal, which does overflow checking, allows me to pass a say 0..100 to a 0..1000 variable. .oO(Shut up! Sing: Rust is great! Rust is our savior!)
[08:40:32] <gilberth> This. Makes. No. Sense. Not. At. All.
[08:45:44] *** Quits: Alfr (~Alfr@user/alfr) (Quit: Leaving)
[08:57:47] <gilberth> Ok. Rust does away with statements versus expressions and almost has block/return-from. Good. No goto still. Why don't have languages a goto anymore?
[08:58:53] <hayley> Nah, you can't "overflow" at compile time. e.g. if the compiler constant folds and overflows, it fails. And smth like (<some i8> as i32) is okay, but i32 to i8 needs something like foo::try_into<i32>().unwrap() methinks.
[09:00:45] <hayley> foo.try_into<i32>().unwrap() // fuck my life
[09:00:47] <gilberth> Yes, milady. But won't disallowing you to pass an i8 to an i32, which never does any harm while having modulo arithmetic lull you in a false sense of security?
[09:01:54] <hayley> All I know is McDonalds, charge my phone, twerk, be bisexual, eat hot chip, lie, and bignums. No integer type coercion semantics, sorry.
[09:02:01] <gilberth> I mean, while arithmetic happily prunes your bits? Or is that the reason why I can't pass i32 to i8? Arithmetic there won't be modulo 256 anymore?
[09:02:20] <hayley> I guess so.
[09:02:39] *** Joins: tophullyte (tophullyte@gateway/vpn/protonvpn/tophullyte)
[09:02:44] <hayley> Yes, someone mentioned that. i8 <: i32 would violate Liskov's substitution principle.
[09:03:06] <gilberth> This is backwards. The operators should be named +i8, +i32 etc, with + left to full overflow checking.
[09:03:30] <hayley> Here is the code I used to benchmark submatches, btw: https://gist.github.com/no-defun-allowed/c1e87743477865085b003e4127828ade
[09:03:30] -ixelp- foo.rs ¬∑ GitHub
[09:03:49] <waleee> zig did a compilation profile that enables a swath of checks, not sure if rust has something similar
[09:03:50] <hayley> Some functions wanted a usize, some others wanted u64 or something.
[09:04:04] <gilberth> You ported the RE nightmare to Rust?
[09:04:15] <hayley> No, I merely used that code to benchmark PCRE2 and Rust regex.
[09:04:32] <hayley> waleee: Yeah, but that's still a foot-gun waiting to happen, if you have separate checking or not modes.
[09:04:51] * hayley points to https://plover.com/~mjd/misc/hbaker-archive/letters/CACM-FactoringRedundancy.html
[09:06:47] <hayley> You have two different language semantics, where in one language, + overflowing crashes the program, and another where it computes mod 2^n. And I seriously doubt that you can snuff out where your program does the same thing in non-trivial programs.
[09:07:30] <hayley> Someone told me in Zig, you can fuzz test a program with bounds checks, then turn them off for production. Hello, aircrash bureau?
[09:09:07] <semz> I think a big part of this attitude is that many systems only let you disable bounds checks etc globally, not locally
[09:10:53] * gilberth continues reading and relies on hayley and her hammer as backup to save him, if needed.
[09:10:56] * hayley forgot what she was doing.
[09:11:23] <hayley> Oh yes, holding a hammer and complaining.
[09:11:35] <hayley> gilberth: There is return-from, but you can't return from a closure.
[09:13:43] <gilberth> hayley: I can name a loop, but not a block. Or? I said "almost". You can of course do let x = 'foo: loop { .... } Just don't forget to break eventually.
[09:13:57] <hayley> See https://play.rust-lang.org/?version=stable&mode=debug&edition=2021&gist=181c900a2875d516fd645ca0ccb38ed4
[09:14:14] <hayley> Press "run", "note: labels are unreachable through functions, closures, async blocks and modules"
[09:14:43] <hayley> "cannot `break` inside of a closure", etc.
[09:15:01] <gilberth> The || makes a closure?
[09:15:08] <hayley> Yes.
[09:15:46] <gilberth> Do I have the equivalent of CATCH/THROW?
[09:15:55] <hayley> Nope.
[09:16:04] <gilberth> setjmp(3)?
[09:16:06] <hayley> There is no interesting control flow in Rust.
[09:16:15] <moon-child> #[extern(C)] fn longjmp
[09:16:26] <gilberth> None? No non-local exits?
[09:16:37] <moon-child> oh, no, they use  extern "C"  like c++
[09:16:49] <hayley> Correct.
[09:17:05] <gilberth> moon-child: I am talking about Rust, not C.
[09:17:21] <moon-child> gilberth: extern "C" fn longjmp
[09:17:31] <moon-child> now you can c in your rust!
[09:17:45] <gilberth> hayley: Seriously? So when I want a Lisp in Rust I cannot even use the call stack and need to have my own?
[09:17:48] <hayley> That is going to break a lot of things.
[09:17:53] <hayley> gilberth: Correct again.
[09:18:07] <moon-child> gilberth: it seems easier to make your own stack anyway, for gc
[09:18:11] <gilberth> HAAAAYLEY! Pillow!
[09:18:20] <hayley> Apparently exceptions (as a special case of non local transfer of control) are too hard to make robust.
[09:18:26] * hayley delivers pillow
[09:18:49] <gilberth> moon-child: With C I could at least use the call stack just fine.
[09:18:53] <hayley> Never mind Joe's law ("CRASH CRASH CRASH CRASH CRASH!!!"), you have to handle everything. Or .unwrap()
[09:19:08] * gilberth 's head falls save.
[09:19:15] <moon-child> gilberth: native call stack and your own data stack?  I guess
[09:19:42] <hayley> But technically they can't crash like that, because they only use OS threads. So it's impractical to spawn a thread for every unit of lossage.
[09:20:01] <gilberth> moon-child: Or a linked list of frames "auto" (stack) allocated.
[09:21:13] * hayley has a very odd idea of how to write robust software.
[09:21:21] <moon-child> gilberth: I guess we've had this argument before.  Like nan-tagging. :)
[09:21:29] <gilberth> So Rust has no exception handling at all? No setjmp/longjmp either? Is that correct?
[09:21:44] <hayley> It's all propagated through values, yes.
[09:21:50] <gilberth> moon-child: yep, we had.
[09:22:00] <hayley> Make unwinding a special Lisp value. lol
[09:22:46] <moon-child> ._.
[09:23:03] <gilberth> And they advertise this as a system programming language?
[09:23:03] <hayley> gilberth: Hey, surely there's some Lisp interpreter in Rust that will give you very good design ideas.
[09:23:08] <hayley> Yes.
[09:23:33] <hayley> What is a system programming language, anyway? /me doesn't know, doesn't really care, but now wants to know.
[09:24:28] <gilberth> Good question.
[09:25:32] <hayley> Apparently you can program microcontrollers with it. Does that count?
[09:26:31] <gilberth> I can program MCUs in BASIC, too.
[09:27:16] <hayley> I can't imagine writing operating systems (which are usually supposed to be secure) if I have implicit integer overflows, but apparently you can do that too.
[09:27:59] <hayley> .oO(CL forces you to be explicit about integer overflow and how to handle it, whereas machine languages like C and Rust usually do the wrong thing...)
[09:28:01] <gilberth> Well, UNIX is written in mostly C, isn't it?
[09:28:08] <hayley> Yes.
[09:28:13] * hayley points to https://gitlab.freedesktop.org/polkit/polkit/-/issues/74
[09:29:32] * tophullyte starts wondering about plan 9 but written in cl again
[09:29:51] * hayley wonders why you would do Plan 9 then.
[09:30:13] <tophullyte> yes
[09:30:14] <gilberth> Plan 9 is UNIX on steroids. Everything a file.
[09:30:36] <hayley> Yeah, why would you do that?
[09:30:40] <gilberth> Though I like the idea that /dev/tty is your connection to the display server.
[09:31:31] <tophullyte> hayley: just because
[09:31:41] <gilberth> Imagine they designed X11 that way: Embed X11 into VT100. Every shell login over what ever channel would allow you for a GUI application.
[09:31:46] *** Joins: Alfr (~Alfr@user/alfr)
[09:32:07] <moon-child> 'operating systems are usually supposed to be secure'  eh, os security layer is not _super_ useful.  Sure, don't choke on malcrafted IP packets; but untrusted _code_ on trusted hardware Does Not Work
[09:32:24] <hayley> tophullyte: https://i.redd.it/corl9hctgny61.png
[09:32:36] <moon-child> (e.g. prominent recent examples rowhammer and spectre)
[09:36:11] <tophullyte> aaaa i waited 3 hours for clasp to compile only for it to error out on a missing CMakeLists.txt
[09:36:22] * tophullyte yeets laptop
[09:39:46] <hayley> I wonder if anyone talking about fragmentation in memory managers has done, say, a year's worth of malloc'ing. Even if beach doesn't want one, I bet a concurrent compactor would be needed to make CLOSOS persistent memory sustainable.
[09:40:08] <hayley> \eps fragmentation surely adds up with time.
[09:40:55] <moon-child> if you care about a year's worth of allocation, your compactor does not need to be concurrent
[09:41:39] <hayley> Hm, agree to disagree.
[09:41:53] <hayley> But you could make the same point for a non-concurrent compactor.
[09:42:09] <Alfr> moon-child, but what about eating and keeping cake?
[09:42:45] <hayley> e.g. https://www.cs.tufts.edu/~nr/cs257/archive/paul-wilson/fragmentation.pdf claims almost zero fragmentation, but none of the programs live awfully long.
[09:43:04] <moon-child> I mean, concurrent compactor is about 1) high-availability and 2) short-term fragmentation.  I assume closos does not need to be highly available, and the specific problem here is long-term fragmentation
[09:43:13] <moon-child> Alfr: the cake is a lie
[09:43:40] <Alfr> moon-child, okay. :(
[09:43:48] * hayley bakes moon-child 
[09:44:08] <dave0> is moon-child getting baked?
[09:44:23] <hayley> "You will be baked, then there will be cake" is more memorable to me.
[09:44:50] <Alfr> hayley, is he well-done yet?
[09:45:05] <hayley> I don't usually cook people, how do I know?
[09:45:07] <Alfr> Ah ... whatever.
[09:45:11] <semz> tophullyte, and they say long compile times aren't a problem in practice.
[09:45:13] <moon-child> place the device in the incinerator
[09:45:18] * semz currently struggles with rustc
[09:45:57] <dave0> hayley: poke him with a stick... he's ready if the juice comes out clear
[09:46:11] * Alfr cuts moon-child into slices and serves those pieces.
[09:46:44] <hayley> https://www.youtube.com/watch?v=48PJGVf4xqk
[09:46:45] -ixelp- One Of These Days - YouTube
[09:46:59] <Alfr> hayley, I thought you'll know, as you started baking him out of the blue.
[09:50:42] <hayley> moon-child: Could you define "high availability"? AIUI a GC crash would brick the system, and pausing would be annoying for interactive programs.
[09:52:15] <moon-child> you query my server.  I take 60ms to get back to you because my gc was not concurrent; I was unavailable for that time
[09:52:38] <hayley> That'd also be annoying, yes.
[09:52:50] <moon-child> re pausing, I was imagining something like a once-per-day compaction while you sleep
[09:53:01] <moon-child> not like g1 kind of thing
[09:53:12] <hayley> Like a "GC once every 8 years" thing?
[09:55:31] <hayley> To jog yer memory: http://3e8.org/pub/scheme/doc/lisp-pointers/v1i3/p17-white.pdf
[09:55:54] <hayley> It was 12 years, of course.
[09:56:58] <tophullyte> semz, it probably wouldnt have taken as long if i had used the nix file i edited instead of the unaltered one from nixpkgs
[09:57:04] <tophullyte> i am an idiot TuT
[10:01:01] <hayley> You don't really get sleeping time for servers though, and G1 has O(n^2) bits for remembered sets between regions (where n = region count).
[10:01:16] <hayley> For the latter, either you have large regions or a lot of regions.
[10:01:56] <hayley> Otherwise I like the idea of having a sort of "distributed GC" before doing a full tracing GC.
[10:01:58] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 265 seconds)
[10:06:45] <hayley> ...I just thought about it and it seems like a generational GC with more crap tacked on for no reason.
[10:17:21] *** Joins: treflip (~user@95.79.32.99)
[10:19:28] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:da4:9ec6:5ef5:74d6) (Ping timeout: 268 seconds)
[10:26:29] <semz> ...and the compilation failed again. I love it.
[10:26:38] <semz> I should bill them for my electricity costs
[10:27:06] <hayley> What the hell are you compiling?
[10:27:21] <semz> rustc
[10:27:44] <hayley> But why?
[10:27:56] <semz> Because for some godforsaken reason their OpenSSL bindings hardcode a list of supported OpenSSL/LibreSSL versions that isn't upwards compatible
[10:28:23] <hayley> Lovely.
[10:28:30] <semz> but apparently patching it is also a pain in the ass because cargo checks the integrity of bundled packages
[10:28:33] <semz> wtf is the point of checking those?
[10:28:33] <hayley> Surely you just rebuild the SSL library, or?
[10:28:38] <hayley> Oh.
[10:29:06] <semz> surely if I downloaded the right compiler source the bundled stuff is right too
[10:29:38] <semz> the best part is that Firefox doesn't even use OpenSSL
[10:31:23] <hayley> Maybe I'm thinking of the "train algorithm" for oldspace <https://beta.cs.au.dk/Papers/Train/train.html>
[10:41:04] *** Joins: |3b|` (bbb@user/3b/x-2324788)
[10:41:32] *** Quits: |3b| (bbb@user/3b/x-2324788) (Ping timeout: 240 seconds)
[10:44:29] *** |3b|` is now known as |3b|
[10:52:19] *** Quits: treflip (~user@95.79.32.99) (Read error: Connection reset by peer)
[10:52:47] *** Joins: treflip (~user@95.79.32.99)
[11:03:59] *** Quits: pjb (~pjb@user/pjb) (Ping timeout: 252 seconds)
[11:04:44] *** Quits: lagash (lagash@lagash.shelltalk.net) (Quit: ZNC - https://znc.in)
[11:07:57] *** Joins: lagash (lagash@lagash.shelltalk.net)
[11:16:34] * hayley remembers why "distributed" GC ‚â† generational GC: you can still collect/compact a tenured region without doing the rest.
[11:28:54] <shka> https://www.youtube.com/watch?v=sNwukK7Y8wQ
[11:28:54] -ixelp- Robert Rich Perpetual A Somnium Continuum 8h Complete Masterpiece 2014 - YouTube
[11:38:00] <hayley> https://sci-hub.st/https://dl.acm.org/doi/10.1145/3241624.2926701 "[The scheduling quantum] was changed because OS jitter outweighed GC latencies by an order of magnitude, making it difficult to plot the improvement."
[11:38:38] <gilberth> I am having trouble with the second paragraph here: <https://doc.rust-lang.org/book/ch04-01-what-is-ownership.html>
[11:38:39] -ixelp- What is Ownership? - The Rust Programming Language
[11:38:41] <gilberth> First it is stated that "All programs have to manage the way they use a computer‚Äôs memory while running." Good. Then they point to manual memory management and "constantly" running a GC as two solutions. Then the concept of "ownership" is mentioned. Although the author technically doesn't state that this would be a solution for memory management, this is implied.
[11:38:50] <gilberth> This is dishonest.
[11:39:32] <hayley> "Rust uses a third approach: ..."
[11:39:53] <gilberth> Doesn't help that the next subsection about "Heap versus Stack" has many false statements.
[11:40:27] <hayley> Indeed.
[11:40:39] <gilberth> heyley: Yes, milady. I am disappointed and angry. That book contains lies.
[11:41:15] <gilberth> I can't even type "hayley" straight anymore. Sorry.
[11:41:36] * gilberth takes a deep breath.
[11:41:45] <hayley> Don't worry, I only picked the name by misspelling "Halley's comet" in a joke.
[11:42:23] <hayley> ";;; This function is fubar! - Halley" ‚Üê Halley's comment
[11:43:22] <gilberth> lol. It's not "Helley's comet", right?
[11:43:34] <hayley> Right.
[11:43:47] <hayley> But I wrote "Hayley's comment" and thought it was a nice name.
[11:44:18] <gilberth> It is a nice name, no doubt.
[11:44:35] <hayley> :)
[11:45:38] <hayley> Funny that you get to see a parallel universe when you read olde papers. Except, of course, it's not a parallel universe, it's this one, and other people don't read.
[11:45:41] <gilberth> But tell me, is it accepted these days to publish lies on the internet in a book? I wonder if the author accepts erratas.
[11:46:38] <hayley> Like how idiots craps on Java for being single-threaded - um, Java had one of the first memory models, and there's java.util.concurrent. And people think we don't know about caches and multiple threads either.
[11:46:43] <gilberth> Yes, olde is issue. We have made no progress.
[11:47:40] <gilberth> Yes, and Lisp is an interpreted language, right?
[11:48:09] <hayley> One nice thing about CLOSOS that hasn't been mentioned (yet) is that you get more control over memory management than with Unixen. e.g. Azul Systems tried to merge a patch for Linux which would allow batching up mremap/mprotect/etc, but no one on the Linux end understood it.
[11:48:41] <hayley> Same for some researchers and their GC which handled paging pretty gracefully, "bookmarking" references going out of paged out pages, and prioritising finding garbage in memory.
[11:49:56] <gilberth> Speaking of which, Linus once thought that thread local store is a bad idea.
[11:50:55] <gilberth> Let's share the program counter and all other registers within all threads!
[11:54:35] <gilberth> The sad thing is, there will be people believing in those lies.
[11:56:55] <hayley> w.r.t the latter: https://marc.info/?l=linux-mm&m=113269306106370&w=2
[11:56:56] -ixelp- '[patch] vmsig: notify user applications of virtual memory events via real-time signals' - MARC
[11:58:23] <gilberth> "All data stored on the stack must have a known, fixed size. Data with an unknown size at compile time or a size that might change must be stored on the heap instead." Wrong.
[11:58:26] <hayley> "I wonder if it wouldn't work similarly well for the kernel to simply notify the registrered [sic] apps that memory is running low and they should garbage collect _something_, without caring which pages." No, a GC requires tracing a whole generation at least, whereas bookmarking requires just enumerating references going out of a page.
[11:58:43] <hayley> gilberth: Missing a few implicit "when writing Rust" then.
[11:58:49] <semz> Finally it worked.
[11:59:19] <hayley> Congratulations!
[11:59:21] <gilberth> "Pushing values onto the stack is not considered allocating. Because the pointer is a known, fixed size, you can store the pointer on the stack, but when you want the actual data, you must follow the pointer." Very poorly written and perhaps wrong.
[11:59:54] <gilberth> Heck. All my pointers are of the same fixed size, no matter what they point at.
[12:00:13] <hayley> Isn't it called "stack _allocation_"?
[12:00:24] <gilberth> This passage is garbled. Has the author any clue?
[12:00:38] <hayley> It is a Rust guide, the answer is no.
[12:00:47] <gilberth> ok
[12:03:06] <gilberth> I read: Because the data is of fixed size, the pointer has a fixed and can be stored on the stack, without allocation, and to access the data you would need to retrieve that pointer from the stack and follow it. Questions?
[12:03:32] <gilberth> I believe somebody confuses pointers with the objected being pointed to.
[12:03:53] <hayley> Appel also mentions making all threads jump to a stack scanning routine, rather than doing a handshake with each thread. I wonder if you can cut down the latency some more, would you have a pseudo-cooperative scheduling system. Try to get threads to yield at safepoints (which are not controlled by the programmer; they are just installed for concurrent GC), and then preempt if they still take too long.
[12:04:38] <hayley> Then the threads check if they need to GC after resuming from yielding. But, would we have an on the fly GC, no one really gives a crap as long as all threads get scanned relatively quickly.
[12:05:31] <gilberth> hayley: Rather, how fast could you poll an interrupt flag?
[12:05:58] <hayley> gilberth: If the data is of fixed size, then it can go directly on a C-ish stack without breaking much. But you're doing MOV RAX, [RSP + blah] rather than MOV RAX, [RBX + blah]*.
[12:06:38] <hayley> *I guess you have to load RBX from somewhere, still. But that's the same as getting a pointer to the stack!
[12:07:22] <gilberth> hayley: The author talks about double indirection, when you include the stack pointer in the indirection count.
[12:07:46] <hayley> So the problem is that you don't know the location just yet, which is orthogonal to stack allocation or not. But the author still hasn't explained why stack allocation isn't allocation.
[12:08:20] <gilberth> That is mov rbx, [rsp + 42] : mov rax, [rbx + 69]
[12:08:31] *** Quits: treflip (~user@95.79.32.99) (Quit: time to work)
[12:09:44] <gilberth> Milady, it begins with that the author confuses "pointer" with "data". A pointer usually is of fixed size, namely a machine word, no need to mention that.
[12:09:45] <hayley> I guess the compiler knows the locations of local variables which are allocated on the stack, and thus can constant fold to remove an indirection. But OTOH if we have value semantics, then there's no guarantee that it'll even be materialised on the stack! It could just be a pile of registers.
[12:10:32] <hayley> i.e. you wouldn't do LEA RBX, [RSP + 42]; MOV RAX, [RBX + 8]; you'd constant fold to MOV RAX, [RSP + 50]
[12:10:57] <gilberth> Sure. Or go away entirely, if it is dead e.g.
[12:10:59] <hayley> https://people.cs.umass.edu/~emery/pubs/f034-hertz.pdf
[12:11:13] <hayley> "It is also generally impractical to require that users purchase more memory in order to run garbage-collected applications."
[12:11:16] <hayley> <beach> Is that a challenge?
[12:12:01] <hayley> Once I mentioned that the page table in CLOSOS would take a non-negligible amount of primary memory, would it all be loaded in at once. So beach offered to pay for the additional memory to store it (I think about 1 GB primary/1 TB secondary).
[12:12:48] *** Joins: notzmv (~zmv@user/notzmv)
[12:13:29] <gilberth> I wonder if beach would be happy to pay for that each CLOSOS user?
[12:13:46] <hayley> All 2 of them?
[12:13:59] <gilberth> Right.
[12:14:13] <hayley> Still cheaper than Windows, I guess.
[12:16:18] <gilberth> Anyhow, the question rather is: How fast can you poll an interruption flag? I would prefer that to actually yielding. And you would need to decide when to yield and make a guarantee.
[12:17:39] <hayley> A concurrent GC tends to poll an interruption flag "frequently enough", like before a function call or backwards branch.
[12:18:10] <gilberth> IIRC CLISP checks for interrupts at each backwards jump and each function call in the BC interpreter since you can't do any syscalls while in the signal handler.
[12:18:40] <hayley> https://www.researchgate.net/publication/292669501_Stop_and_go_understanding_yieldpoint_behavior
[12:18:41] <gilberth> hayley: Yes, I can't read while I type.
[12:18:41] -ixelp- (PDF) Stop and go: understanding yieldpoint behavior
[12:19:52] <hayley> According to figure 1, between 1kHz and 100kHz is common for Java programs.
[12:21:27] <hayley> Oh no, I misread. They claim 100MHz.
[12:21:45] <gilberth> Well, if you're your own OS, this is an issue for multi-core systems only. /me just thinking.
[12:22:13] <hayley> Right.
[12:23:51] <hayley> However, apparently only 1 in every 20,000 safepoints is taken. The time overhead is apparently 2% at worst.
[12:24:01] <gilberth> And when you are your own OS, interrupt overhead could be low. Remind me that I continue with my fault handling latency tests.
[12:25:14] <gilberth> GC should be an OS service.
[12:26:53] <hayley> The paper also claims that time to safepoint for multi-threaded programs is around 100k \tau.
[12:27:34] <hayley> So...3¬µs for my desktop's 3.2GHz clock? Not bad.
[12:27:44] <hayley> lol, 31¬µs.
[12:27:52] *** Quits: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de) (Quit: Leaving)
[12:28:02] <gilberth> Still good.
[12:29:48] <gilberth> That whole damn subsection is full of errors. Why would people write about something they have no clue about? To demonstrate their ignorance?
[12:29:55] <hayley> IIRC Pauseless on Azul hardware had threads yield at locations where there was enough information to trace the thread, but the latency is...kinda shit by modern standards.
[12:31:09] <gilberth> Function arguments are pushed onto the stack? RLY? Not here, sorry. At least not all.
[12:31:25] <hayley> Where? lol
[12:31:31] <gilberth> Milady, I need to calm down. Any suggestions?
[12:32:16] <ck_> go outside, it's probably snowing
[12:32:19] <ck_> that should be cold enough
[12:32:29] <hayley> Their best worst pause was like 21ms, with a 1.5GB heap and 8 mutator cores. OTOH that was 2005.
[12:32:37] <gilberth> hayley: "When your code calls a function, [...]" butlast paragraph.
[12:33:14] <hayley> And they didn't bother to actually make their Pauseless implementation pauseless! Someone decided what they had eventually was good enough, which is probably a good move, but ironic.
[12:33:23] <hayley> Of what? Chapter 4 again?
[12:33:29] <gilberth> ck_: It's +2¬∞C here, but we have no snow fall. Unfortunately.
[12:33:47] <hayley> "When your code calls a function, the values passed into the function (including, potentially, pointers to data on the heap) and the function‚Äôs local variables get pushed onto the stack. When the function is over, those values get popped off the stack." LMAO
[12:37:16] <gilberth> Where is my P2P universal annotation feature, so I could scribble there?
[12:38:54] <hayley> Why are you looking at me? I retired from P2P half a year ago.
[12:39:41] <gilberth> Why do you believe I look at you? I read that fine book.
[12:40:23] * hayley uploaded an image: (102KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/caPCcGCzhbMPpzOyLHhfeCCE/stack-allocation.jpeg >
[12:40:26] <hayley> What I would do is create a GitHub issue, and link this image.
[12:40:53] <gilberth> The book is on github?
[12:41:01] <hayley> I believe so?
[12:41:31] <gilberth> Ah! That's nice.
[12:42:15] <hayley> https://github.com/rust-lang/book
[12:42:15] -ixelp- GitHub - rust-lang/book: The Rust Programming Language
[12:43:16] <gilberth> hayley: Trouble is: Your sign says "stack allocation". Haven't you read closely? There is no "stack allocation", storage is not allocated on a stack. It's just there or so. And goes away by magic or something similar.
[12:43:27] <hayley> Oh, my bad.
[12:43:50] <dave0> magic is so whimsical
[12:45:16] <hayley> gilberth: Spoilers, when you get into async programming in Rust, they can't maintain the illusion of having a stack at the language level, since there isn't one.
[12:45:54] <gilberth> Do you really need to spoil my fun?
[12:46:05] * hayley shrugs
[12:46:51] <Alfr> hayley, what face is used on that sign?
[12:47:04] <hayley> Computer Modern Roman, in italics.
[12:47:30] <Alfr> hayley, ah ... italics.
[12:48:29] <hayley> HENCE: stack allocation is an implementation issue, not a language issue. You just get stupid shit if you make it a language issue.
[12:51:57] <gilberth> I wonder when they will discover static allocation. On top of that ownership rule, you only have to outlaw reentrancy. The compiler could check that rule. Your program will never run out of memory, all known at compile time.
[12:52:34] <hayley> What if the binary is huge, so trying to load it fails?
[12:53:26] <gilberth> This is load time. I was talking about run time. :-p
[12:54:08] <hayley> Sure.
[12:54:11] <hayley> dlopen()?
[12:54:38] <gilberth> Cannot run out of memory. I have not said, I can't fail at all.
[12:55:30] <hayley> https://cs.adelaide.edu.au/users/dave/papers/incremental.gc.pdf GCing a persistent object store, eh?
[12:55:49] <gilberth> Actually static allocation has some merits for embedded systems. You might even want to know your maximum stack size at compile time.
[12:56:48] <dave0> there was a quote by a famous computer science guy that i cant remember that was along the lines of "if your program is even 1 word larger than memory it cannot run, and adding memory is always expensive"
[12:56:54] <gilberth> hayley: You would need to pass your own statically allocated memory array to dlopen().
[12:57:03] <dave0> expensive in time and money
[12:58:12] <gilberth> And practically impossible at times. Try to expand Voyager's memory.
[12:58:30] <ck_> swapping is tricky :)
[12:59:10] <gilberth> ck_: You could swap over the "network". But it will be damn slow.
[12:59:44] <hayley> Swap to VRAM?
[12:59:45] <ck_> that%27s-the-..
[12:59:53] <hayley> Not kidding: https://wiki.archlinux.org/title/Swap_on_video_RAM
[13:00:16] <dave0> lol
[13:00:31] <dave0> crickets have chirped up outside my window
[13:00:54] <sham1> Why oh why
[13:01:02] <sham1> Swap on VRAM just sounds horrible
[13:02:41] <gilberth> EMS? Was it any better?
[13:03:03] <gilberth> But why not just map the VRAM?
[13:03:39] <hayley> I don't remember if all systems allow it. Though I'd expect a CUDA implementation requires bridging primary and video memory somehow.
[13:04:32] <gilberth> Hmm, could I also swap to remote VRAM using X11?
[13:04:45] <sham1> Cloud swap
[13:05:19] <hayley> Maybe you should just buy a fancy SSD at this rate.
[13:05:25] <Alfr> gilberth, can we even decide whether a program (w/ input) only needs a bounded amount of (stack) space?
[13:05:52] <hayley> https://i.redd.it/ezfjip9irys71.jpg
[13:06:33] <gilberth> Alfr: Yes, when you outrule reentrancy. I did that with my embedded systems by statically analysis of the compiler output.
[13:06:56] <sham1> Doing that in general sounds like you'd end up with the halting problem
[13:07:28] <Alfr> gilberth, okay, guess it doesn't take every program as input.
[13:07:30] <gilberth> sham1: Not when functions can't be re-entered.
[13:07:30] <semz> you could probably add bullshit frames in every step of the computation to get halting iff bounded
[13:07:39] <sham1> Well that's a specific case
[13:08:02] <gilberth> It is, I have never claimed otherwise.
[13:08:23] <semz> Hm, how often does a function need to be reentrant?
[13:08:34] <gilberth> BTW FORTRAN is that way. As is e.g. Turbo Pascal for the 8080.
[13:09:09] <gilberth> semz: Not often unless you walk some trees.
[13:10:15] <gilberth> And 'reentrant' here means: "reentered within one process/thread".
[13:11:42] <gilberth> My experience is that I never ran into a situation where I went .oO(Gosh! I really want recursion here.) for this specific field of applications.
[13:11:50] * semz is reminded of this hellish way to walk trees in constant memory and without recursion by mutating the links
[13:12:37] <semz> I guess reentrancy is relatively easy to check at compile time too if you have global analysis huh? Just check what calls what
[13:12:42] <gilberth> semz: Yes, something that makes my brain hurt each time.
[13:12:45] <semz> didn't expect it to be so straightforward
[13:12:57] <semz> uh
[13:13:06] <semz> not checking reentrancy, but checking that nothing relies on it
[13:13:10] <semz> you get what I mean
[13:13:28] <gilberth> semz: Yes, I looked at the whole program. The tool was trivial to write.
[13:13:53] <hayley> I didn't use any recursion for the LC3 in LC3 implementation. But it is a relatively boring program, other than having to write LDB by hand with addition only.
[13:15:55] <gilberth> I looked at the assembly code, traced calls and returns and stack allocation (oops!). I assumed the code would come from the C compiler, so no access to the stack pointer otherwise. No messing with the return address.
[13:17:59] <gilberth> hayley: Most "real world" programs are more than boring. Recursion arises from recursive data structures most of the time. When those are not in your input domain, you have little use for recursion. Or: You could do fine without it.
[13:20:32] <gilberth> But back to allocation: Isn't single-ownership also a special case? Very much like "no recursion" is a special case?
[13:22:08] <hayley> Yes.
[13:22:31] <hayley> Single ownership is another name for linear typing, though Rust lets you violate linearity temporarily with "borrowing" references.
[13:22:45] <hayley> Like most things, Baker wrote about it.
[13:23:42] <hayley> https://plover.com/~mjd/misc/hbaker-archive/LRefCounts.html WITH-ANCHERED-POINTER is a borrow.
[13:27:28] <Gnuxie> o.o
[13:30:16] <gilberth> Is there a Rust spec that I could read?
[13:30:22] <sham1> Hahahaha, no
[13:30:27] <hayley> Nope.
[13:30:36] <sham1> The implementation is the spec‚Ñ¢
[13:31:11] <gilberth> ok, then. /me continues reading that fine book.
[13:31:39] *** Joins: OlCe (~user@lfbn-nic-1-117-213.w2-15.abo.wanadoo.fr)
[13:32:32] <gilberth> .oO(I have a hard time guessing things like e.g. value versus reference semantics from this author's garbled masterpiece.)
[13:33:20] <hayley> All is value semantics until you see a & methinks.
[13:34:59] <hayley> https://www.youtube.com/watch?v=9EuYn8xgF28
[13:34:59] -ixelp- The Glotch - Freddie Laker [Concorde & Eurobus] - YouTube
[13:35:56] *** Quits: White_Flame (~quassel@user/white-flame/x-6930243) (Remote host closed the connection)
[13:37:10] *** Joins: White_Flame (~quassel@user/white-flame/x-6930243)
[13:38:20] <gilberth> hayley: Perhaps. But you know what I mean. The author has no clue and talks of copies made, where none are made and perhaps vice versa. They confuse pointers with the objects itself. I need to carefully read between the lines as the information given in just plain inaccurate.
[13:38:58] * hayley nods
[13:40:11] <hayley> I didn't like Baker's introduction to linearity for that reason. "Much like the real world, an object cannot be duplicated or destroyed without the paperwork." Yes, but Gnuxie and I can both still talk about the one gilberth. The difference between value and reference semantics.
[13:45:08] <hayley> Now I can't find that one specifically, but https://plover.com/~mjd/misc/hbaker-archive/Use1Var.html claims "The intuition behind linear types is the¬†conservation of physical matter--a linear object cannot be created or destroyed without special permission, although it can be moved or transferred at will."
[13:45:28] <hayley> Sadly, I can't just stop looking at something to make it not exist.
[13:49:42] <hayley> Aha, that quote is from https://plover.com/~mjd/misc/hbaker-archive/ForthStack.html
[13:49:55] <hayley> "Linear logic¬†[Girard87] can be viewed as the latest attempt to bring back the physical object metaphor, but stripped of its polymorphic pretensions. For the first time in 50 years of computer science, a metaphor of programming has been proposed that most people can relate to--objects have true identity, and¬†objects are conserved."
[13:50:22] <shka> what is linear logic anyway?
[13:51:08] <hayley> Linear logic has it so that an object exists by only exactly one reference before being consumed.
[13:52:10] <shka> the quoted text makes it seem to be something different 
[13:53:45] <shka> also, isn't calling this approach with name a little bit to much?
[13:54:29] <hayley> Yes, I just said that the quote is not a good description, because it confuses references and values.
[13:54:41] <gilberth> Is 'x' in 'fn foo (x: &Blah) { ... }' like a call by reference parameter? Or is there more to it?
[13:54:42] <selwyn> you would prefer it not to have a name?
[13:55:10] <hayley> gilberth: Yes, but & is an immutable reference; &mut Blah would be mutable.
[13:55:44] <shka> selwyn: i think that calling "dude, just one reference so reference = value" "the latest attempt to bring back the physical object metaphor" really pretentious
[13:55:47] <gilberth> I take that as a "yes" to my first "?".
[13:56:12] <sham1> And a mutable reference means of course that the thing referenced is mutable. The reference itself isn't mutable
[13:56:21] <hayley> "Call by reference" doesn't indicate what you want to do with the reference.
[13:56:47] <shka> also, how the fuck this works even
[13:57:06] <sham1> What works
[13:57:12] <shka> i can't even do (when (predicate-p reference) (do-something reference))?
[13:57:25] <gilberth> sham1: Of course. In Pascal a "VAR X : INTEGER" parameter is also not modified itself, but the thing it refers to.
[13:57:28] <shka> because i "consumed" object twice?
[13:57:32] <hayley> Yes, you need to duplicate.
[13:57:54] <shka> hayley: ok, so why anybody would think that this is a good idea?
[13:58:01] <selwyn> lol
[13:58:12] <hayley> Cause you don't have to GC.
[13:58:28] <selwyn> it is like introducing the hassle of quantum mechanics for no reason
[13:58:31] <hayley> In a way, it's a reification of C "good" practise of defensive copying.
[13:58:35] <selwyn> destructive measurement of object properties
[13:58:40] <shka> yes, but i can't do much with that
[13:58:40] <selwyn> otoh, you can clone
[13:58:57] <shka> like for instance, use observer
[13:59:58] <shka> also, we have year 2021
[14:00:01] <shka> almost 2022
[14:00:18] <ck_> it's the year of the Pattern
[14:00:34] <gilberth> Ah, so Rust is made for quantum computers? Right.
[14:00:37] <shka> you would think that people would not insist on doing everything and anything just to avoid using GC
[14:01:09] <hayley> gilberth: Tell that to stylewarning.
[14:01:16] <shka> at this point almost anything was done using GC language
[14:01:17] <sham1> Rust is made for web programming people who want to write C
[14:01:27] * hayley uploaded an image: (58KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/DvahXfIhYWVsCmqUMqyazxVO/pauseless.png >
[14:01:40] <gilberth> hayley: Will I survive, when I do?
[14:01:46] <ck_> I'll take next year to implement https://github.com/pds54/Flyweight-Observer/blob/master/flyweight%20observer%20patterns/src/main/java/com/FlyweightObserverFactory.java in all my projects. looking forward to the planning phase in Q1
[14:01:47] -ixelp- Flyweight-Observer/FlyweightObserverFactory.java at master ¬∑ pds54/Flyweight-Observer ¬∑ GitHub
[14:01:54] <hayley> Hm, 50-50?
[14:02:18] <shka> hayley: ok, so those linear programming really makes sense or it is just another weird trend?
[14:02:40] <shka> because it feels like a weird trend
[14:02:49] <ck_> unrelated: I just noticed that github has xref links for the types and functions in that file. neat, didn't see that before
[14:02:50] <hayley> shka: Linear arrays can be updated "functionally" in O(1) time.
[14:03:15] <sham1> ck_: for some languages, yes
[14:03:28] <hayley> If your (setf aref) consumes the array and returns a "new" array, why not modify in place?
[14:03:50] <hayley> You can do that trick with na√Øve reference counting, too, but then you have reference counting.
[14:03:58] <sham1> A sufficiently smart compiler‚Ñ¢ can do that optimisation, especially with linearity yes
[14:05:04] <shka> hayley: eh, ok...
[14:05:09] <shka> is it worth it?
[14:05:52] <sham1> Yes. If you have immutable data structures
[14:07:05] <kakuhen> i submitted my hardest final exam ever
[14:07:11] <kakuhen> commutative algebra was a mistake
[14:07:25] <kakuhen> with that said i can finally focus on moving my irc stuff to matrix
[14:07:29] <sham1> If the side-effect is not observable, it should be fine to just mutate even in a language that doesn't have mutation
[14:07:56] <kakuhen> ok, well, commutative algebra wasn't a mistake, but cramming random shit about derived functors and making us compute things with them was a mistake
[14:08:32] *** Joins: treflip (~user@95.79.32.99)
[14:08:44] <hayley> sham1: someone did a demo of a SSC for Roc, which required some magic constraint solver. But I don't buy that many functional programs are linear.
[14:08:54] <hayley> At least hash consing and structure sharing are very non-linear.
[14:09:32] <sham1> But if it looks linear to the outside then it shouldn't matter
[14:09:45] <hayley> https://youtu.be/vzfy4EKwG_Y Also not a fan of the "LLVM make go fast" jerk (see e.g. Clasp) but to each their own.
[14:09:46] -ixelp- "Outperforming Imperative with Pure Functional Languages" by Richard Feldman - YouTube
[14:09:46] <shka> i personally think that immutability is overkill
[14:09:58] <shka> the point was always "controlled mutation"
[14:10:04] <shka> not "no mutation at all"
[14:10:34] <hayley> Yeah, but I tend to hash cons and share structure in immutable programs (e.g. the one-more-re-nightmare compiler). So linearity wouldn't help there.
[14:10:34] <shka> i just want SQL style atomic transactions 
[14:10:50] <hayley> Transactional memory is a thing.
[14:10:56] <shka> yes, it is
[14:11:27] <shka> and even if it would be not, it is not hard to actually use purely software techniques to achieve the same
[14:11:48] <shka> i, for instance, slap ownership tag on internals of data structures
[14:12:17] <shka> and mutate only those parts of the structure that are OWNED by said data structure
[14:12:21] <shka> otherwise COW
[14:12:24] <sham1> Immutability makes it easy to reason about stuff. Of course same can be said for limiting mutability. Limit side-effects within a single function and it's easy to see why stuff happens
[14:13:09] <shka> sham1: i think that the point is to have limited field of possible states
[14:13:23] <shka> that's it
[14:13:39] <shka> that's what at the end of the day matters
[14:14:41] <shka> unless you are trying to prove correctness of the program
[14:17:12] * shka thinks that correctness proving is not a bad idea for software that kills people on malfunction, but he is not writing such software
[14:18:24] <hayley> Well, I proved correctness of my fine grained locking scheduler so that I could narrow down the last 1-in-10 million race condition in decentralise2.
[14:19:12] <hayley> It wasn't a race condition, rather that my hash table + hash function combination would sometimes lose big time, and I had no randomization. So it'd resize indefinitely ):
[14:20:20] <shka> ok, parallel programming is another good use case for that
[14:20:56] <shka> and parallel programs that tend to kill people in malfunction is perhaps the best use case :P
[14:35:22] <selwyn> parallel killbots
[14:35:47] <sham1> Fail-safe, fail-secure, fail-deadly
[14:36:21] <hayley> Hm, if threads yield on a GC safepoint then I don't even need to context switch to scan them. Magic.
[14:36:22] <selwyn> 'it was simply a matter of getting the killbots to try to kill the same person at exactly the same time'
[15:13:29] *** Joins: pjb (~pjb@user/pjb)
[15:23:19] *** Quits: treflip (~user@95.79.32.99) (Remote host closed the connection)
[15:55:17] <shka> selwyn: in the original killbots game the point was to make killbots run into each other
[15:56:16] <shka> and in one of the futurama movies they employed the exact same method :D
[15:58:54] <selwyn> oh right lol
[16:00:01] <selwyn> kakuhen: congratulations
[16:00:13] <selwyn> if commutative algebra was a mistake
[16:00:20] <selwyn> then you don't want to know about noncommutative algebra :)
[16:18:52] *** Joins: random-nick_ (~random-ni@87.116.166.234)
[16:25:51] *** Joins: treflip (~user@95.79.32.99)
[16:34:12] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:cd28:ecf9:b8a2:d95a)
[17:09:30] *** Joins: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de)
[17:11:44] <shka> dear god https://www.xe.com/currencycharts/?from=TRY&to=USD&view=10Y
[17:11:45] -ixelp- Turkish Lira to US Dollar Exchange Rate Chart | Xe
[17:15:07] <selwyn> in which lowering interest rates fails to solve the problem of inflation
[17:17:09] <shka> i mean, holy fucking shit, from ~0.5 to ~0.07 and it is still going down
[17:17:18] <shka> and rapidly 
[17:33:01] <selwyn> the inverse view makes it more obvious https://www.xe.com/currencycharts/?from=GBP&to=TRY&view=10Y
[17:33:03] -ixelp- British Pound to Turkish Lira Exchange Rate Chart | Xe
[17:35:12] <selwyn> apparently spanish banks are overexposed to that economy
[17:36:04] <selwyn> eurozone crisis 2
[17:41:18] <sham1> Oh no, not again
[17:43:44] <sham1> I'm not ready for yet another god damn crisis
[17:52:05] <selwyn> what does it mean that an economy can tolerate this much abuse without completely collapsing
[17:52:13] <selwyn> good economic fundamentals?
[18:02:32] <dave0> nite all
[18:02:57] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[18:10:04] *** Quits: treflip (~user@95.79.32.99) (Remote host closed the connection)
[18:20:14] *** Joins: treflip (~user@95.79.32.99)
[18:46:59] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:cd28:ecf9:b8a2:d95a) (Ping timeout: 268 seconds)
[18:57:07] <ck_> what happened to you during the last one, sham1 ?
[18:58:24] <sham1> Well I got tired of the news for a whil
[19:01:55] <ck_> understandable. how are you enjoying the appeals for vaccination?
[19:15:17] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:1b4:2cec:47c3:871e)
[19:29:11] *** derelict is now known as tetrahedron
[20:00:20] <pjb> Nordic countries are restricting the use of Moderna‚Äôs Covid vaccine <https://www.cnbc.com/2021/10/08/nordic-countries-are-restricting-the-use-of-modernas-covid-vaccine.html>
[20:02:25] <shka> myocarditis again
[20:08:19] <pjb> Fall on walk from bed to desk is workplace accident German court rules <https://www.theguardian.com/world/2021/dec/09/fall-on-walk-from-bed-to-desk-is-workplace-accident-german-court-rules>
[20:08:19] -ixelp- Fall on walk from bed to desk is workplace accident, German court rules | Germany | The Guardian
[20:08:31] <pjb> Ain't you so happy to be protected, as a remote worker!?
[20:09:14] *** Joins: makomo (~makomo@user/makomo)
[20:23:00] <shka> pjb: yes
[20:37:00] *** Joins: Catie (~user@user/catie)
[20:43:25] <edgar-rft> pjb: the point is that only very few people here have an insurance for houshold accidents, but every employee has an insurance for workplace accidents
[20:54:53] *** Quits: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se) (Quit: WeeChat 3.3)
[20:57:23] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[21:12:28] *** Quits: amazigh (~amirouche@user/amirouche) (Quit: WeeChat 2.8)
[21:12:38] *** Joins: amazigh (~amirouche@user/amirouche)
[21:22:11] *** Quits: amazigh (~amirouche@user/amirouche) (Read error: Connection reset by peer)
[21:27:01] *** Quits: tophullyte (tophullyte@gateway/vpn/protonvpn/tophullyte) (Ping timeout: 240 seconds)
[21:27:34] <selwyn> wondering if covid will cancel christmas
[21:34:18] *** Joins: amazigh (~amirouche@user/amirouche)
[21:35:51] *** Quits: gko (~user@user/gko) (Remote host closed the connection)
[21:36:23] *** Joins: gko (~user@user/gko)
[21:43:18] *** Joins: tophullyte (~tophullyt@162.213.177.125)
[21:44:33] *** Quits: treflip (~user@95.79.32.99) (Quit: good night ‚ú®)
[21:46:08] *** Joins: phossil (tophullyte@gateway/vpn/protonvpn/tophullyte)
[21:49:05] *** Quits: tophullyte (~tophullyt@162.213.177.125) (Ping timeout: 265 seconds)
[22:25:53] <shka> selwyn: https://www.rcrwireless.com/20211208/telco-cloud/microsoft-adds-rigetti-quantum-computers-to-azure-quantum-service
[22:30:33] <selwyn> reading
[22:33:07] <selwyn> planning to do some stuff over the break on ibm quantum computers actually
[22:33:13] <selwyn> a side project
[22:34:02] <selwyn> nice to hear from microsoft on this side of things. they are usually very understated about what they fund/work on
[22:34:54] <selwyn> a big part of their philosophy is that quantum computers are useless until you have a lot of error corrected qubits
[22:35:03] <selwyn> which means millions of actually existing qubits
[22:35:20] <selwyn> so their investment profile/research tends to be geared towards that
[22:35:53] <selwyn> i wonder if anyone will shell out $900 per hour for this service damn
[22:36:03] <selwyn> investment banks maybe
[22:52:29] <lagash> selwyn: yeah that whole million qubit thing always get me - will we ever be able to get even CLOSE to that??
[22:52:39] <selwyn> imo yes
[22:52:57] <lagash> You a quantum physicist? :)
[22:53:03] <selwyn> hoping to be
[22:53:10] <selwyn> i am finishing a phd in it
[22:53:38] <selwyn> there are like 5 approaches to qc
[22:53:42] <lagash> Will you be the theoretician or the engineer side of things?
[22:54:06] <selwyn> photonic quantum computing is something of a dark horse - they are doing some very exciting things, and they do talk about this kind of scale
[22:54:37] <selwyn> i am definitely a theorist, but i work on the implementation side of things as opposed to algorithms
[22:54:54] <selwyn> i.e. how do we control this quantum system to compute something useful
[22:55:08] <lagash> Hmm yeah I see way too many "the rest is an engineering problem" copouts..
[22:55:18] <selwyn> if the photonics people can't pull it off soon, then we will have to wait quite a while
[22:55:54] <selwyn> great advantage of photonics is that you can make things in silicon now in top foundries
[22:56:25] <selwyn> you can benefit from decades of good engineering practices and equipment
[22:56:53] <lagash> Yeah I'm not too enthusiastic about the other approaches
[22:57:15] <lagash> I take it you're here because QC uses a lot of Lisp code? ;)
[22:57:34] <selwyn> whereas the average physics experiment is put together by phd students who have to learn on the job
[22:58:09] <selwyn> without disrepecting them, there is a massive, massive difference between those two worlds, and it shows given what they are talking about producing
[22:58:24] <selwyn> its like science fiction
[22:58:37] <selwyn> well, i do all of my numerical code in common lisp
[22:58:43] <selwyn> but mostly i just like to hang out here
[22:59:56] <pl> lagash: there's surprising amount of common lisp in QC, afaik
[23:00:09] <selwyn> to put it another way: if you are going to build it in a foundry, then, yes, it does become an engineering problem (at least after you have designed things like single photon sources and detectors)
[23:00:35] <selwyn> d-wave and rigetti are known users
[23:01:27] <lagash> selwyn: well good luck bringing about the (crypto) Apocalypse :P
[23:01:39] <selwyn> thanks!
[23:06:41] <semz> "i do all of my numerical code in common lisp" Interesting, numerics always seemed like a sore spot of CL to me (no extended precision on most impls and struggle against boxing). Do you use a specific library/impl that solves these problems?
[23:11:10] <selwyn> i always use sbcl
[23:11:19] <selwyn> precision has never been an issue for me
[23:12:08] <selwyn> unfortunately, i started my project while i was still learning cl, so i did not implement a proper solution to boxing/unboxing
[23:12:25] <selwyn> i think it just has to be a matter of proper type declarations, which i would not mind doing that much
[23:13:09] <moon-child> https://franz.com/careers/jobs/outside/LispJobs.html  Hello I would like one (1) job as a Java Buzzword-ist in Training
[23:13:10] -ixelp- Currently Available Lisp Jobs
[23:16:58] <selwyn> the real issues with doing numerics in common lisp are, roughly in order of decreasing importance 1) no ability to specialise on parametric types 2) lack of libraries, especially for plotting 3) lack of generics
[23:17:17] <selwyn> i understand why these are the case
[23:17:20] <selwyn> but they are the frustrations
[23:17:47] <selwyn> i like doing numerics in common lisp though
[23:18:19] <pjb> selwyn: it's easy to define generics (defgeneric plus (a b)) (defgeneric times (a b)) ‚Ä¶
[23:18:39] <selwyn> well, yeah, thats what i do
[23:18:45] <selwyn> hence why its number 3)
[23:18:50] <moon-child> 'specialise on parametric types'  meh you won't get it for free like with js, but can hack it yourself
[23:18:51] <selwyn> but i don't like it
[23:19:42] <selwyn> it also has an incredible explosion in complexity once you get to around 5 types
[23:20:43] <moon-child> you can put the exact same code in a TYPECASE and the compiler will generate specialised code
[23:20:43] <selwyn> (defmethod bld-gen::* ((a vector) (b number)) ... ) (defmethod bld-gen::* ((a matrix) (b number)) ...)
[23:21:10] <selwyn> admittedly i had not thought of just putting it in a typecase
[23:21:17] <selwyn> but i would prefer to not have to hack the language like that
[23:21:25] <moon-child> don't even need a macro; just #1= your way through
[23:21:57] <selwyn> anyway, for my application, i decided that speed was not the priority
[23:22:14] <selwyn> and i would happily take a 3x - 10x slowdown in return for being able to develop in lisp
[23:23:13] <selwyn> in the end, the time saved by not doing it in python outweighs any factor of code slowdown, and moreover i suspect that the code is not actually that slow
[23:23:53] <selwyn> uh
[23:24:15] <selwyn> isn't putting it in a typecase the kind of thing a compiler would do?
[23:30:06] <moon-child> it could
[23:30:14] <moon-child> but traditionally compilers have not
[23:30:29] <selwyn> i see
[23:31:26] <moon-child> js compilers will do that though
[23:31:34] <moon-child> java too
[23:32:23] *** Quits: minion (~minion@common-lisp.net) (Read error: Connection reset by peer)
[23:32:49] * selwyn ports everything to javascript
[23:33:45] *** Joins: minion (~minion@common-lisp.net)
[23:34:14] *** Quits: phossil (tophullyte@gateway/vpn/protonvpn/tophullyte) (Ping timeout: 256 seconds)
[23:35:29] <selwyn> i think that unoptimised lisp has a good chance of beating unoptimised python
[23:35:35] <selwyn> in the numerical domain
[23:36:16] <selwyn> because you can easily escape numpy to do stuff in python without noticing
[23:36:27] *** Quits: minion (~minion@common-lisp.net) (Remote host closed the connection)
[23:36:37] <selwyn> whereas sbcl sees all
[23:37:09] *** Joins: minion (~minion@common-lisp.net)
[23:37:39] *** Quits: minion (~minion@common-lisp.net) (Remote host closed the connection)
[23:38:26] *** Joins: minion (~minion@common-lisp.net)
[23:43:13] <GreaseMonkey> unoptimised vs unoptimised? i don't think it "has a good chance"
[23:43:26] <GreaseMonkey> i would be shocked if unoptimised Python were ever faster than unoptimised Lisp
[23:43:35] <GreaseMonkey> at least with a decent CL implementation
[23:43:40] <moon-child> GreaseMonkey: python has numpy; cl does not
[23:43:42] <selwyn> to be clear, i mean doing python in the standard way
[23:43:45] <selwyn> with numpy and friends
[23:43:59] <GreaseMonkey> right, OK at least in that case it's not a pushover
[23:48:21] <shka> selwyn: dude, python has no chance 
[23:48:31] <shka> for multitude of reasons
[23:48:57] <shka> unless you spent 99.9% of your time in C
[23:49:29] <moon-child> i bet graalpython beats cl
[23:49:36] <moon-child> for some non-ffi workloads
[23:49:43] <moon-child> because inline caching
[23:50:27] <selwyn> really?
[23:51:28] <GreaseMonkey> for python w/ numpy to beat CL, you'd need a workload which is almost entirely operating within arrays and you'd need a CPU that does SIMD which numpy supports and makes use of
[23:52:03] <selwyn> well, that does confirm my suspicions then lol
[23:52:05] <GreaseMonkey> that and you'd also want to make sure you aren't thrashing your CPU cache
[23:52:33] <selwyn> i was about to suggest a scipy v statistical-learning benchmark showdown :)
[23:52:58] <GreaseMonkey> which would you use to analyse the results?
[23:57:43] <selwyn> it would be funny to use scipy
[23:57:50] <selwyn> and then present the results at some python conference
[23:59:18] <GreaseMonkey> "SciPy: A tool that can argue its own defeat in a speed contest"
