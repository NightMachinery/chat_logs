[00:05:42] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Remote host closed the connection)
[00:13:21] <lisp123> CptKirk16: Abstraction is useful in every paradigm, why do you say that?
[00:23:22] *** Quits: lotuseater (~user@p200300e78715be00e2e5898694cab6cd.dip0.t-ipconnect.de) (Ping timeout: 252 seconds)
[00:32:46] *** Quits: lisp123 (~lisp123@5.30.23.247) (Quit: Leaving...)
[00:45:44] <CptKirk16> https://youtu.be/v7Mt0GYHU9A?t=372
[00:46:17] <CptKirk16> Given a particular definition of "abstraction", because "abstraction" is such an overloaded term that it perhaps seems quizzical to criticize such an umbrella term
[00:46:59] <CptKirk16> but what I hate is the form of abstraction to which he refers here. In APL it is ALWAYS better to confront the data representation itself, and understand the data representation, rather than trying to conceal the data representation through a representative set of functions or objects
[00:47:48] <CptKirk16> so in that sense, I really dislike "abstraction" that takes the form of trying to conceal, obfuscate the data and transformations being performed through an interface of functions or data
[00:48:31] <CptKirk16> which is often the form embodied by "object oriented abstraction" or "functional abstraction" 
[00:50:36] <CptKirk16> But this may be a specific benefit of APL's notation over arrays, and the fact that there is one solitary data structure the primitive functions operate over (arrays), and so prehaps APL simply makes it easier to deal with dealing with the data directly, but is difficult to accomplish in other languages
[00:51:06] <CptKirk16> (lol "deal with dealing with", whoops)
[00:53:06] <CptKirk16> but that's the same reason I said yesterday I loathe iteration. Recursion is much simpler mental tool to iteration requires you to "mentally parse/iterate" whatever expression you're orchestrating, and step through all hypothetical cases, but the recursive expression requires you to think only in the inductive case, which is typically a single step
[00:54:12] <CptKirk16> so if you can conceive of a single step, the recursive algorithm writes itself, but iteration can be a whole lot messier becaues it allows for all sorts of irregularly "shaped" data
[01:06:22] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-19-70-31-33-162.dsl.bell.ca)
[01:11:05] <CptKirk16> It's the 100 functions over 1 data structure, vs 10 functions over 10 data structures problem from SICP
[01:11:10] *** Quits: random-nick (~random-ni@87.116.165.220) (Ping timeout: 252 seconds)
[01:23:26] *** Quits: shka (~herr@109.231.6.176) (Ping timeout: 252 seconds)
[01:30:48] *** Joins: lotuseater (~user@p200300e7871bd300c158d62dc7544d08.dip0.t-ipconnect.de)
[01:52:32] *** Quits: macaw (~macaw@176.221.120.196) (Ping timeout: 256 seconds)
[02:05:11] *** Quits: greaser|q (greaser@antihype.space) (Changing host)
[02:05:11] *** Joins: greaser|q (greaser@user/greasemonkey)
[02:05:13] *** greaser|q is now known as GreaseMonkey
[02:10:31] *** Joins: CptKirk (~CptKirk@70-57-27-195.hlrn.qwest.net)
[02:14:38] *** Quits: CptKirk16 (~CptKirk@70-57-27-195.hlrn.qwest.net) (Ping timeout: 256 seconds)
[02:27:52] *** Joins: zazzerino (~user@2600:1700:6004:8470::13)
[02:45:54] *** Quits: zazzerino (~user@2600:1700:6004:8470::13) (Remote host closed the connection)
[03:08:02] *** Quits: rdrg109_ (~rdrg109@51.195.232.80) (Changing host)
[03:08:02] *** Joins: rdrg109_ (~rdrg109@user/rdrg109)
[03:48:30] *** Quits: hendursaga (~weechat@user/hendursaga) (Quit: hendursaga)
[03:48:58] *** Joins: hendursaga (~weechat@user/hendursaga)
[03:54:22] *** Quits: CptKirk (~CptKirk@70-57-27-195.hlrn.qwest.net) (Ping timeout: 256 seconds)
[04:10:41] *** Joins: CptKirk (~CptKirk@70-57-27-195.hlrn.qwest.net)
[04:10:52] <CptKirk> did I miss any remarks on my wall of text? I should really figure out how to stay logged in 
[04:19:21] *** Quits: Psybur (~Psybur@mobile-166-170-32-197.mycingular.net) (Remote host closed the connection)
[04:20:38] <mfiano> You didn't, but in reading it I would try to keep an open mind for different schools of thought, or I fear you may be wasting your time.
[04:23:00] <lotuseater> :)
[04:29:31] <CptKirk> I don't feel that I'm "closed minded" with regard to other schools of thought, I feel as though I've spent sufficiently equal amount of thought and time, comparing between the various schools of thought (a comparison that I engage with in perpetuity)
[04:30:40] <CptKirk> And I find that when I need to think about iteration it is so much more mentally encumbering, I feel like I'm bogged down in a mire uanble to move. I find that when I have 10 abstractions with which to deal with even the most basic of data types, I don't understand the data, its purpose, or how the values I'm using translate to meaningful decisions
[04:30:41] <CptKirk> in a program
[04:30:45] <mfiano> If you've thought about it a significant amount of time and still don't like the long history of Lisp's way of doing things, what do you expect to gain?
[04:30:51] <CptKirk> I find I spend more time unpacking abstractions that getting work done
[04:31:31] <CptKirk> I'm not saying I have a significant amount of time with "lisp's way of doing things" but "abstraction" in the form that I articulated before
[04:32:02] <CptKirk> and thus far in my lisp time, I find that the way scheme and clojure does things to be the most beneficial "way of doing things" in lisp
[04:32:17] <mfiano> Then use them?
[04:32:20] <CptKirk> becuase it is almost strictly recursion over data rather than iteration over abstractions
[04:32:26] <CptKirk> I can't, there's no April for clojure or scheme
[04:33:41] <lotuseater> write it if it's so much better
[04:33:48] <mfiano> Why use a Lisp compiler to APL rather than APL then?
[04:34:55] <CptKirk> Because Dyalog, being the only "complete" APL, and Kx/q or shakti being the only "complete" k, and J being... anitquated... and no longer a notation... I can't afford the first 2 and the last 2 is so full of warts and land mines I'm not interested
[04:35:03] <CptKirk> That leaves BQN, ngn/k or dzaima APL
[04:35:07] <CptKirk> non of them are anywhere near completion
[04:35:20] <CptKirk> April is not only fully APL, but I can use all of the common lisp ecosystem in tandem
[04:35:47] <CptKirk> So that means I need to understand effective ways to use Cl
[04:36:26] <CptKirk> If you took 1 word of my philosophizing about the design of languages as a criticism of CL, my apologies because that isn't the case
[04:36:29] <mfiano> Then you have a choice to embrace Common Lisp's flexibility and well-matched idioms for the language, or write a comparable solution for the host you actually want to submit to.
[04:36:40] <CptKirk> and "go make your own" or "go somewhere else" is not a conclusion one could draw from my intention
[04:37:11] <CptKirk> which is that I tend towards recursion and functions over data rather than abstractions
[04:37:24] <CptKirk> *or iteration
[04:38:20] <CptKirk> and I want to know if that's an effective use of CL, because it seems that recursion is simultaneously recommended and warned against
[04:39:49] <lotuseater> wasn't meant like that?
[04:39:51] <CptKirk> I've also been told that I'm writing CL like scheme, but I don't know the difference besides CL people seem to recommend imperative rather than declarative code, and the iteration macros over recursion, and CLOS or Structs with methods over straight functions
[04:40:15] <CptKirk> and *mutation*
[04:41:50] <mfiano> Everything is a trade-off, even trade-offs. There is no right answer. The flexibility of the language doesn't hold your hand and guide you down a correct path, unlike say Clojure or Python.
[04:42:05] <mfiano> Anyway, this channel is about ANSI Common Lisp. I will stand by for any questions about the standard, but dogmatic discussions are not for me, nor the topic of this channel.
[04:42:17] <CptKirk> I'm not dogmatic in the slightest
[04:42:23] <CptKirk> I even lead with the caveat of my biases
[04:42:47] <CptKirk> And I did so to clue in anyone willing to comment into the perspective I'm coming from
[04:43:00] <CptKirk> to communicate more clearly and avoid any misunderstandings
[04:43:25] <CptKirk> so literally all of that was intended to be inverted into the form of a question with regard to "effective CL" 
[04:43:49] <CptKirk> as in "this is where I'm coming from.... what do 'effective CL programs/authors' have to say"
[04:43:57] <CptKirk> I'm here to learn Cl obviously
[04:44:04] <CptKirk> not to dismiss it outright 
[04:45:36] <CptKirk> I said "I loathe" and "I am averse to..." both blatant declarations of opinion, and not "iteration bad" or "abstraction bad", so I feel as though I was begging the question "... so what does 'effective use of CL' have to say on the subject"
[04:46:14] <mfiano> Very few CL programmers "have come from" where you have. CL is so vastly different than even mainstream languages, that the most often given advice is to forget everything you know, learn CL, and then either continue using CL or go back to the language you came from as a better programmer.
[04:47:21] <CptKirk> Is it not possible to speak to a lisp programmer comming from other lisps with the understanding that they're pretty similar, and share much of the same history, and oh by the way here are the differences, and things you should avoid?
[04:48:05] <CptKirk> I have plenty of clojure and scheme practice, I just don't understand the peculiarities of CL in particular
[04:48:18] <CptKirk> like I'm learning asdf and quicklisp, both not things you find in scheme-land
[04:48:24] <CptKirk> the package system, and also mutation everywhere
[04:48:42] <mfiano> Clojure is much more simialr to Scheme than Common Lisp is to either of them. They share parentheses and have a common ancestor, but besides that, there is not much to say.
[04:48:43] <CptKirk> recursion is not guaranteed to be optimized, it seems iteration is the word of the day in CL
[04:49:02] <CptKirk> these seem to be adequate comparisons
[04:49:28] <CptKirk> I'm not coming to CL blind either, I've used it for solving toy problems in the past using nothing but recursion over lists apparently
[04:49:53] * lotuseater forges his parentheses-sword more everyday to make it a powerful weapon for the future
[04:49:53] <CptKirk> I'm past the point of "i'm a neanderthal user" to, hey I've got some pretty broken expectations, help me out here
[04:51:17] <White_Flame> I will say that higher level treatises of accepted styles and such tend to be around more popular languages; not really one I'd expect for more niche ones
[04:51:41] <CptKirk> why is that?
[04:51:50] <CptKirk> it would seem that the discussion is all the more needed in niche languages
[04:52:00] <White_Flame> so there's no real reference to point to, except those style guides that say to use the most appropriate tools for the job, which would be the various constructs applicable for traversing/converting/iterating stuff
[04:52:19] <White_Flame> because when you get big factions yelling at each other on the job for how things should be done, then people step in to write books
[04:52:46] <White_Flame> regarding something in broader industry, not just literally in one place
[04:53:08] <CptKirk> without some kind of debate, there won't be a march to improvement, but a stagnation of style that just accepts what is rather than improving things over time, no?
[04:53:35] <White_Flame> recursion is not an improvement if tail calls are not guaranteed
[04:53:57] <White_Flame> yes, an improvement would be for the CL standard to be updated to declare/force tail recursion
[04:54:08] <CptKirk> ↑
[04:54:26] <CptKirk> I'm also not suggesting it is an improvement
[04:54:29] <White_Flame> but nobody wants to accept changes to it that aren't full ANSI processes
[04:54:40] <CptKirk> I'm saying the lack of conversation in niche communities would ultimately lead to stagnation I would have thought
[04:54:56] <White_Flame> however, lisp has very powerful iteration constructs that are appropriate for use in such problems
[04:55:31] <White_Flame> nothing wrong per se with using iteration if it's not of stack-blowing size, but it will simply be unfamiliar to many, more verbose, and less self-descriptive than specific constructs
[04:55:36] <White_Flame> *with using recursion
[04:55:55] <White_Flame> there isn't much of a conversation to be had
[04:56:19] <White_Flame> scheme optimizes for recursion.  CL optimizes for iteration, and in particular per-implementation cases, can be used for deep recursion
[04:57:24] <White_Flame> there's also very easy ways to foil tail calls in CL, regarding leaving LET scopes and such
[04:57:28] <mfiano> For the vast majority of people, recursion is harder to reason about, and considering it is more code and not as linearly readable, it is often a poor choice for clean code in the majority of solution.
[04:57:57] <White_Flame> however, for cases that are very complex to specify in iteration, recursion is fine.  It's just not really the default for the majority of CL developers
[04:59:41] <mfiano> There are in-depth courses and books on recursion. It is just a harder concept to reason about.
[04:59:59] <mfiano> and if you read one of those books while driving, you might end up rear-ending yourself ;)
[05:00:04] <White_Flame> heh
[05:00:59] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[05:01:15] <CptKirk> I disagree that recursion is harder to reason about, but then again I'm coming from APL where iteration is implicit, and is rank agnostic
[05:01:30] <CptKirk> and recursion is just specifying the inductive case
[05:01:42] <mfiano> I did say for the majority of people, and code is read much more than it is written.
[05:02:07] <White_Flame> https://pbfcomics.com/comics/freaking-vortex/
[05:02:17] <mfiano> and given the norm that CL readers of code expect, that is all the more reason against it.
[05:02:19] <CptKirk> Even when I first came to CL 3 or 4 years ago now, I found the Y combinator easier to reason about than keeping all the forms of LOOP in my head at once
[05:02:54] <White_Flame> I"ve never understood the Y combinator, and I've been doing a ton of recursion, logic & inference systems, etc for decades
[05:03:53] <CptKirk> well, apply it out by hand once, and you'll never forget it
[05:03:59] <CptKirk> it's really incredible
[05:04:10] <CptKirk> function application all the way down
[05:05:02] <lotuseater> all down to lambdas in the end :)
[05:05:10] <White_Flame> I have worked through it in the past, it's basically passing a function to call itself.  I don't "get" the significance of it, didn't recall anything memorable
[05:05:37] <CptKirk> It isn't significant necessarily, but clever and interesting that it works
[05:05:52] <White_Flame> it's no more clever than difference lists in prolog, afaik
[05:06:22] <CptKirk> I'm just saying that recursion is easier to reason about than remembering the myriad of forms loop can take all at the same time all the time 
[05:06:32] <White_Flame> for you
[05:06:36] <CptKirk> there are very few recursive forms you have to bother with
[05:06:44] <mfiano> for you
[05:06:44] <White_Flame> certainly not a shared experience for people learning programming in formal education
[05:06:46] <lotuseater> White_Flame: the thing is seeing that you don't need a name to recall something
[05:06:48] <CptKirk> and how many, 10s of thousands of combinations of loop?
[05:07:01] <CptKirk> like, I guess you could keep the spec open at all times
[05:07:15] <CptKirk> but I don't have to reference anything outside my code to write a recursive function
[05:07:31] <White_Flame> it is very academic to try to have a "NAND gate" equivalent, and leave it up to the user to construct everything on top of that
[05:07:44] <White_Flame> it is much more practical to have a vocabulary of toplevel task appropriatenesses
[05:08:00] <White_Flame> and use them directly, instead of always constructing deeply from first principles
[05:08:09] <CptKirk> right, which would be to compose data transformations/algorithms easily, but then that's what APL does well
[05:08:11] <White_Flame> and have them compose
[05:08:18] *** Joins: cyberbanjo (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[05:09:02] <White_Flame> I still do wish better description on your objections to abstractions, and that the selected concrete datastructures should be required knowledge for all levels of writing code against them
[05:09:31] <CptKirk> "required knowledge" you can just print it out in the slime repl
[05:09:44] <CptKirk> and then write the inductive case for 1, and problem solved
[05:09:50] <White_Flame> sure, and they're 100 layers deep, spanning a thousand elements per layer
[05:10:13] <White_Flame> and crash emacs when you try to print htem
[05:10:19] <CptKirk> well, you process intermediate representations, whittling down to only what is necessary for whatever process you're using
[05:10:23] <White_Flame> I mean, for programming in the small, that sort of stuff can certain work.  But it doesn't scale
[05:10:49] <CptKirk> in APL instead of printing everything you just do something like 10↑thing to look at the first 10 elements of the thing
[05:10:54] <White_Flame> there are tons of processes that need to act on a single dataset in real world programming
[05:11:09] <CptKirk> of course
[05:11:38] <CptKirk> but having 20 different representations of various subtypes of things within that data set isn't any good either
[05:11:49] <White_Flame> right, that's why there are abstractions
[05:11:50] <CptKirk> because then you not only need to understand the intention behind the representation, but also the interface for each
[05:11:55] <CptKirk> no
[05:12:05] <CptKirk> I'm saying the 20 different representations of various subtypes are the abstractions
[05:12:10] <CptKirk> OOP etc
[05:12:22] <White_Flame> which sorts of representations are you meaning?
[05:12:27] <CptKirk> objects
[05:12:29] <CptKirk> classes
[05:13:03] <CptKirk> sure you can have a list of "resourceTypes" and then have a "cisco" and a "ciena" or a "juniper" class for each manufacturer of that type of resource
[05:13:09] <CptKirk> or you could just have a list of resource types
[05:13:14] <CptKirk> and a function that operates over resource types
[05:13:36] <CptKirk> in the raw representation necessary to your application
[05:13:43] <White_Flame> as long as those resource types all obey a single abstraction, then you have ... an abstraction
[05:14:09] <White_Flame> (which has nothign to do with OO in particular)
[05:14:16] <CptKirk> which I argue is more difficult to reaosn about than simply selecting the data you need, and defining a single function or set of functions over that data
[05:14:24] <mfiano> A good abstraction emphasizes details to the reader that are important and de-emphasizes details that are not.
[05:14:37] <CptKirk> rather than instantiating an object based on the particular class of resource
[05:14:47] <CptKirk> @mfiano so does a function
[05:15:01] <White_Flame> that doesn't make much real world sense
[05:15:02] <CptKirk> and I don't mean functional abstraction
[05:15:11] <mfiano> That is at another level of abstraction. I am talking about problem domain abstractions.
[05:15:27] <White_Flame> we program in part to wrangle complexity.  saying that concreteness should be exposed and handled directly means exposing all inherent complexity
[05:15:34] <CptKirk> and I think we're getting bogged down in the PLETHORA of definitions attributed to the same word "ABSTRACTION"
[05:15:44] <CptKirk> I'm talking specifically about the kind of abstractiong that is hand-wavy, and hiding implementation details
[05:16:07] <CptKirk> Not necessarily white_flame
[05:16:19] <CptKirk> you can do a lot to eliminate complexity before doing real work with your data
[05:16:21] <White_Flame> any time we achieve "the machine should figure it out", we have advanced as people
[05:16:29] <CptKirk> yes
[05:16:30] <CptKirk> like iteration
[05:16:45] <mfiano> This conversation doesn't have a termination case
[05:16:49] <CptKirk> here's a function, here's an array, the machine should figure out the iteration
[05:16:53] <mfiano> I'm going back to code :)
[05:17:03] <White_Flame> right.  recursion means the user has to figure out how to take a single hammer and bang many types of screws, bolts, latches, etc
[05:17:16] <White_Flame> as opposed to grabbing the proper construct to directly specify the current case
[05:17:35] <White_Flame> and yes, MAP figures out hte iteration, you only specify what is to be done with each element
[05:17:46] <White_Flame> no recursion required from the user
[05:17:49] <lotuseater> mfiano: maybe it's corecursive :)
[05:17:52] <CptKirk> well with recursion I only have to figure out 1 case, and it also guarantees that the entire data structure is homogenously formatted, with iteration, that is absolutely not necessary, and you can wind up with many edge cases and errors that you don't expect unless you MENTALLY iterate through all potential cases
[05:18:02] <lotuseater> and i should sleep
[05:18:07] <White_Flame> at the very least you have to figure out 2 cases:  termination and recursive step
[05:18:09] <CptKirk> I'm not talking about map
[05:18:17] <CptKirk> map is implicit iteration in a sense
[05:18:23] <CptKirk> I'm tlaking about loop and do and dotimes etc
[05:18:40] <White_Flame> but you are tasked with manually incrementing, doing exit checks, passing data forward, etc etc.  These are all things that the machine can figure out for you if you tell it to iterate
[05:18:52] <CptKirk> white_flame well I guess I forget that you have to do that in non-array languages because in array languages you don't need to specify the base case
[05:19:09] <White_Flame> recursion = base case + recursive case
[05:19:13] <White_Flame> regardless of the task, array or not
[05:19:19] <CptKirk> in APL, recursion is application over data
[05:19:40] <CptKirk> data flow knows not of what branching is
[05:19:46] <White_Flame> so in APL speak, is "recursion" more akin to "reduce" then in other languages?
[05:19:50] <CptKirk> no
[05:20:15] <White_Flame> because in most languages, recursion is orthogonal to any sort of data
[05:20:29] <CptKirk> it is a way to say apply this function (n) times where (n) is your condition, but when the condition is false or negative, it executes the function 0 or negatives times, which is a no op
[05:20:33] <CptKirk> there is no branching necessary
[05:20:35] <White_Flame> eg, babby's first fibonacci has no "data" set it's iterating over
[05:20:40] <White_Flame> at least in a concrete sense
[05:21:18] <CptKirk> you can of course branch 
[05:22:20] <White_Flame> that kind of does sound like reduce, if the function's return value is reuse in further iterations
[05:22:22] <CptKirk> {bool : true case ⋄ false case}, but f⍣n is to execute f n times, so to say {leftArg ∇⍣(×bool)⊢rightArg } is to say apply the recursive function 0 or 1 times
[05:22:27] <CptKirk> it isn't reduce
[05:22:45] <CptKirk> +/1 2 3, f/ is reduce f over the right argument
[05:22:52] <CptKirk> completely different constructs
[05:23:01] <CptKirk> ∇ is the same as `recur` in clojure
[05:23:15] <White_Flame> what are the parameters to f in your "execute f n time" case?
[05:23:46] <White_Flame> and what happens with the intermediate return values?
[05:24:24] <CptKirk> for example, repeat until negative, ×n gives you the sign of n, so either positive n or negative n
[05:24:38] <CptKirk> but it doesn't specify your base case, like "when n is less than 0"
[05:24:42] <CptKirk> or anything of the sort
[05:24:51] <CptKirk> it says "execute the function 1 or -1 times"
[05:24:55] <White_Flame> right, it's externalized that, just like LOOP etc does
[05:25:06] <White_Flame> and it's silly to say that loop is hard to learn when you've learned all these situational APL operators ;)
[05:25:17] <CptKirk> APL operators are not situational
[05:25:40] <CptKirk> and there is also no syntax in single expressions
[05:25:48] <White_Flame> but still, it doesn't sound like "standard" function application as in other languages like lisp
[05:25:56] <White_Flame> because there's no mention of parameters or return values
[05:26:00] *** Quits: lotuseater (~user@p200300e7871bd300c158d62dc7544d08.dip0.t-ipconnect.de) (Quit: ERC (IRC client for Emacs 27.2))
[05:26:10] <CptKirk> parameters are implicit, but can be specified if desired
[05:26:24] <White_Flame> right, the model seems significantly different
[05:26:29] <CptKirk> in k for instance {[a;b;c] a + b + c}[1;2;3]
[05:26:37] <CptKirk> or its the same thing as {x + y + z}[1;2;3]
[05:26:40] <White_Flame> you'd be having these sorts of impedance mismatches in most other languages, not just lisp
[05:26:55] <CptKirk> just like in clojure #(+ %1 %2 %3)
[05:27:18] <White_Flame> especially as most languages don't even consider tail recursion
[05:27:30] <CptKirk> true enough
[05:27:50] <CptKirk> though, I guess coming from the public perception of LISP, I sort of expected it to be recursively oriented
[05:27:54] <White_Flame> so really, "Language $X is not APL" :-P
[05:28:00] <White_Flame> no
[05:28:05] <White_Flame> lisp is a metaprogramming language
[05:28:09] <CptKirk> and it also seems to be the most cognitively simple
[05:28:17] <White_Flame> it can create & transform source code as easily as any other data
[05:28:34] <White_Flame> and there's nothing special about compile-time; it's all just lisp doing lispy things
[05:28:39] <CptKirk> then why don't they call CL `Meta` or something, and not `LISt Processing`
[05:29:01] <CptKirk> lists being its fundamental data type, and a recursive data type at that?
[05:29:06] <White_Flame> because list processing in lisp is also compilation/interpretation ;)
[05:29:21] <White_Flame> recursive data type != recursive functions required
[05:29:37] <White_Flame> iteration constructs came very early on in lisp's history
[05:29:58] <CptKirk> so then the form of LISP code bearing resemblance to its fundamental data type in "modern CL" is of no consequence, and lists are not widely used for solving large problems
[05:30:12] <White_Flame> I mean, REPL = LOOP at the end, not REPR recuring :-P
[05:30:21] <White_Flame> *recursing
[05:30:47] <White_Flame> lists are used for solving large problems, non-lists are used for solving performance-sensitive problems
[05:31:04] <mfiano> I would also argue that MOP is just as "meta" as macros.
[05:31:09] <White_Flame> the non-schema notion of lists are great for just mudballing together data
[05:31:30] <White_Flame> whereas structs, arrays, etc require more organizational work
[05:31:40] <White_Flame> but in turn give you performance
[05:31:54] <CptKirk> So then would you say CL is not quite geared for data-oriented programs, and is more abstraction-oritented?
[05:31:56] <White_Flame> mfiano: yeah, I'll let others speak on that; I'm not a big OO guy
[05:32:18] <White_Flame> it's absolutely data-oriented as well
[05:32:50] <White_Flame> in terms of creating specifications, pseudo-code, data elements to process, etc, and have those easily execute because of the transformational & iterative qualities it has in traversing them
[05:33:07] <CptKirk> Ok, then let me back up, I'm talking about a particular definition of abstraction, and I think we can all agree that abstraction is a HEAVILY overloaded word
[05:33:31] <White_Flame> I can jot down all sorts of crap, creating any level of simplicity or complexity, and treat it as the canonical data to define the program
[05:33:45] <White_Flame> without having to mung the data to support some singular style
[05:33:59] <mfiano> Well with everything being a class, and CLOS/MOP so embedded into the language, you can't get away from OO, but it's not what beach describes as class-centric OO.
[05:34:26] <White_Flame> right, I almost never end up using defclass
[05:34:34] <mfiano> What do you use?
[05:34:41] <White_Flame> mostly structs, arrays, lists
[05:34:54] <White_Flame> and sometimes generic functions
[05:35:01] <mfiano> a struct is just a different metaclass
[05:35:05] <White_Flame> I probably should use GFs more
[05:35:22] <White_Flame> I do a lot of performance-oriented stuff, and structs are friendly to that
[05:35:23] <mfiano> It is still a derivative of a class
[05:36:10] <White_Flame> or more correctly, I do a lot of performance-sensitive stuff.  Don't like waiting half an hour for something to process
[05:36:48] <mfiano> You can make regular defclass classes as performant as structs using the MOP, if you ever need to
[05:37:11] <White_Flame> they really can compile down to single instruction ptr+offset accesses nowadays?
[05:37:42] <mfiano> Sure. There's a MOP function for controlling how slots are accessed; standard-instance-access.
[05:38:11] <White_Flame> ah, right.  Although I bet there's a library for that sort of thing instead of wrangling it manually
[05:38:29] <White_Flame> if you do that, isn't that neutering a lot of CLOS flexibility anyway back to structs though?
[05:40:05] <White_Flame> and also, does defining that MOP function allow that access to be fully inline at the call site?
[05:40:26] <mfiano> Yes, of course; static code conflicts with interactive code. But the fact that you can incrementally control which parts are static with tools like the MOP, allows you to fine-tune your problem to a balance between the two.
[05:40:56] <mfiano> Let me pull up an example
[05:43:12] <mfiano> Hmm, I lost the commented code explaining the expansion and everything
[05:43:14] <mfiano> https://github.com/mfiano/zed/blob/master/src/util-ordered-class.lisp
[05:44:05] <White_Flame> ah, so it generates defuns for the accessors, and can declare them inline
[05:44:06] <mfiano> That defines a macro for defining a new type of class, a class with regular inlined function accessors for slots that basically inline an aref call to the backing storage
[05:44:52] <mfiano> With :inline being a new slot option.
[05:44:54] <mfiano> Yes
[05:46:43] <mfiano> I do this because I want to use classes for their ability to be mixins. structs only have single-inheritance and are not runtime programmable. With a class I can modify the superclass list and use change-class at runtime to allow for some interesting compositional effects for the problem i'm trying to solve.
[05:47:08] <mfiano> But at the same time, I can make them as fast as structs...there is no difference on SBCL.
[05:49:03] <mfiano> The AMOP book makes the bold claim that the MOP makes it so you don't have to choose between performance over flexibility. I agree with that somewhat, but of course it's not entirely true :)
[05:49:14] <CptKirk> I don't understand the purpose of classes at all anymore. Relational lists have the same effect and are much simpler to understand, and much faster in practice
[05:50:00] <CptKirk> https://github.com/carkat/APLProjects/blob/b82b48c09f3bdb111bae2a3319a65bab20516e9f/APLP5/attraction.apl#L40
[05:50:16] <CptKirk> This is an example of treating relational lists as "objects" 
[05:50:35] <White_Flame> it's kind of hard for a non-APL programmer to read APL code
[05:51:02] <CptKirk> the point is that each "mass object" is just a single entry into a set of relational lists
[05:51:15] <White_Flame> what's a relational list?
[05:52:03] <CptKirk> so instead of a list of [mass1,mass2,...] where masses are instances of objects specified by the Mass class with properties like mass.locaiton, mass.velocity, mass.acceleration
[05:52:14] <CptKirk> you instead of a list of locations, velocities, accelerations
[05:52:29] <White_Flame> ah right.  yeah, I did a lot of that sort of datastructure unrolling in my commodore 64 days
[05:52:33] <CptKirk> and you simply map over the entire set of lists at once
[05:52:39] <White_Flame> it's pretty inflexible
[05:52:52] <CptKirk> its also pretty performant
[05:52:55] <White_Flame> if you need to change the length of the list, you have to touch a lot of stuff
[05:52:57] <mfiano> Yes, that type of thing is _one_ of the choices for buffer layout in OpenGL
[05:53:05] <CptKirk> and it isn't inflexible, to add a new property, just define a new array of the length of "instances"
[05:53:06] <mfiano> and it is by far the most inflexible/performant
[05:53:17] <CptKirk> I don't think it is inflexible in the slightest
[05:53:27] <mfiano> unperformant?*
[05:53:34] <White_Flame> and you have to manually manage dynamically assigning/freeing indexes into those lists
[05:53:49] <CptKirk> White_Flame do "destroy" an object, you just omit an index
[05:53:50] <CptKirk> ?
[05:53:53] <CptKirk> how is that difficult
[05:54:14] <White_Flame> you need to track the open index to support "allocating" a free one then
[05:54:16] <mfiano> There goes performance
[05:54:26] <White_Flame> and traversal needs special cases for those tombstones
[05:54:30] <CptKirk> like I'm going through to update all of the current locations, so I do `(⍳≢locations)~destroyed`
[05:54:35] <White_Flame> and if it's sparse, your performance can be worse than a linked list
[05:54:40] <CptKirk> that's range without the destroyed indices
[05:54:49] <CptKirk> you dont have sparse elements in your list?
[05:54:49] <White_Flame> right, and that's overhead
[05:54:53] <CptKirk> you don't have nulls in your list?
[05:54:57] <White_Flame> it's syntactically simple & supported, but not performant
[05:54:59] <CptKirk> there's literally no overhead
[05:55:08] *** Quits: sts-q (~sts-q@212.53.219.184) (Ping timeout: 252 seconds)
[05:55:12] <CptKirk> sorry, range of indices is not performant?
[05:55:18] <CptKirk> finding the length is not performant?
[05:55:19] <White_Flame> only if they're packed
[05:55:21] <CptKirk> right
[05:55:23] <CptKirk> they're never not packed
[05:55:29] <CptKirk> and it takes literally 0 management
[05:55:31] <White_Flame> hold on
[05:55:35] <White_Flame> how are they never not packed?
[05:55:39] <CptKirk> you just don't include indices that are destryed for the update
[05:55:45] <White_Flame> do you always move one to fill the hole when you remove an element?
[05:55:59] <CptKirk> White_Flame no, you just omit the specific index
[05:56:02] <White_Flame> if so, then you can't rely on retaining the index from teh outside (eg, item #100 in the lists)
[05:56:06] <mfiano> Then it becomes sparse
[05:56:09] <White_Flame> right
[05:56:19] <White_Flame> it's no longer packed if there are omissions
[05:56:21] <mfiano> cache coherency goes out the window
[05:56:28] <CptKirk> if my_list = map(f).filter((x,i) i !== destroyed)
[05:56:37] <CptKirk> then you just omit the destroyed index
[05:56:39] <CptKirk> accross all of them
[05:56:41] <White_Flame> ...
[05:56:43] <CptKirk> cache choerancy?
[05:56:47] <mfiano> right, omission = sparseness
[05:56:50] <CptKirk> you literally know nothing of data oriented design
[05:56:52] <CptKirk> no
[05:56:55] <mfiano> Yes
[05:56:56] <CptKirk> it isn't sparse at all
[05:57:01] <White_Flame> it has holes, it's sparse
[05:57:06] <CptKirk> i'm not saying create holes
[05:57:08] <CptKirk> wtf
[05:57:13] <White_Flame> it's not a specifcially sparse datastructure with disparate spans, the data simply has holes
[05:57:20] <White_Flame> "omit" = "a hole"
[05:57:28] <CptKirk> I'm saying, the array is the array without that index included, which is a dense array with length -1
[05:57:30] <CptKirk> wtf?
[05:57:31] <CptKirk> no
[05:57:33] <CptKirk> not delete
[05:57:35] <White_Flame> you are scanning through data, performing tests, and working over indexes that are not ultimately processed
[05:57:36] <White_Flame> that's overhead
[05:57:37] <CptKirk> if you filter
[05:57:42] <CptKirk> there are no holes left
[05:57:42] <mfiano> So then how do you destroy an object in the middle?
[05:57:45] <White_Flame> filtering = overhead
[05:57:46] <CptKirk> what are you even talking about
[05:57:47] <White_Flame> thsi is not performant
[05:58:17] <CptKirk> so
[05:58:37] <CptKirk> omit(int_destroyed, range(0, length)) 
[05:58:41] <CptKirk> this is not a filter
[05:58:46] <White_Flame> I'm sure APL makes this stuff syntactically easy.  I'm sure this is faster than other options in the language, as it's matrix-oriented (afaik).  But it's still suboptimal
[05:58:49] <CptKirk> but it is the range of indices without the integer you're looking for
[05:58:53] <CptKirk> right?
[05:59:01] <CptKirk> can you understand that? 
[05:59:03] <mfiano> White_Flame: Yes, I think so.
[05:59:07] <CptKirk> so then you select the indices that remain
[05:59:12] <CptKirk> there is no filtering
[05:59:16] <CptKirk> i'm using filter as an analog
[05:59:40] <White_Flame> yo don't think that that omission, int_destroyed test, and full range traversal is overhead?
[05:59:48] <CptKirk> except that isn't happening
[06:00:05] <White_Flame> that more work is being done on a list of 10000 elements than a 10 element list, if only 3 are non-omitted?
[06:00:23] <mfiano> You are not conveying your thoughts clearly enough then, and please refrain from attacking me (or others).
[06:00:30] <CptKirk> I'm not attacking anyone
[06:00:31] <mfiano> I do a lot of DOD in my line of work.
[06:00:36] <CptKirk> I felt like I was being attacked though
[06:00:38] <mfiano> So I would think I know a bit about it
[06:01:00] <CptKirk> well then you know that this is a very optimal approach to storage and iteration over data
[06:01:03] <White_Flame> CptKirk: you keep describing extra steps in order to achieve supposed packed performance, but those extra steps are work/time too
[06:01:21] <CptKirk> yes but I'm not destroying on every time passing through
[06:01:48] <mfiano> That wasn't what we were saying
[06:02:04] <White_Flame> yeah, if you cache your calculated iteration and can reuse it over read-only datasets, that's an extenuated case that can amortize the reorganized indeices
[06:02:12] <CptKirk> sorry but if you think destructors are "performant" compared with omitting and index from a list
[06:02:31] <White_Flame> do you think malloc/free is faster than GC?
[06:02:45] <CptKirk> like the amount of jumps through non-contiguous memory is enough to make prefer this approach to "deletion" of "instances" of "objects"
[06:04:28] <CptKirk> I can't speak to much of the time complexity of operations in various APL implementations because the idioms are recognized under the hood and optimized away
[06:04:34] <CptKirk> but I can't tell you which ones in which implementations
[06:05:17] <CptKirk> and that's also mainly because I really only pay attention when something is proving to need optimization
[06:05:52] *** Joins: sts-q (~sts-q@212.53.219.240)
[06:06:06] <White_Flame> there's really no difference between pointer following between object instances, and grabbing the next index from your calculated iteration indices, assuming a large enough space
[06:06:39] <White_Flame> it trends towards a custom memory heap implementation
[06:06:52] <White_Flame> except with more size limitations & such
[06:06:52] <CptKirk> except that you have to keep all of your object in memory in order to chase those pointeres, but I can fit a whole lot more instances of an object in memory when its contiguous, meaning fewer cache misses
[06:06:55] <mfiano> Can we get back to the topic of ANSI Common Lisp now? I think such discussions belong in #lispcafe or another off-topic channel.
[06:07:08] <CptKirk> sorry, idk what all the channels are
[06:07:28] <White_Flame> moving GCs place objects next to each other,t oo
[06:07:38] <mfiano> I am against the idea of filling this channel with off-topicness, as it dissuades a newbie from asking legitimate questions, and gives the regulars a long of scanning to looking for legitimate questions to answer when they wake up.
[06:07:51] <mfiano> long time*
[06:08:03] <White_Flame> but the basic fact of the matter is that you're bringing a lot of APL here with its particular defenses, which may or may not be applicable to CL, or to non-APL computing in general
[06:08:20] <mfiano> #lispcafe would be a better place for this discussion.
[06:10:08] <CptKirk> I still feel like this is a discussion about Common Lisp. I asked about effective common lisp, and it seems as though the discussion is around what kinds of patterns are useful in CL. Is abstraciton really the first approach to solving a problem, and not simply direct functional solutions, and the CLOS vs functional abstraction, and I'm beginning
[06:10:09] <CptKirk> to wonder what the distinction between the 2 really is
[06:10:15] <CptKirk> But then there's the question of Meta abstractions
[06:10:28] <White_Flame> premature abstraction is a root of many evils
[06:10:43] <White_Flame> lisp supports prototyping very well, and easy transition into more production-oriented code
[06:11:06] <CptKirk> sorry to deviate down the tangent, but structs of lists is a pattern I would recognize and reach for in CL, so I see that as relevant as well. Is that a meaningful pattern in CL or not?
[06:11:28] <White_Flame> depends on what you're doing :shrug:
[06:11:29] <CptKirk> how would a language NOT support prototyping?
[06:11:52] <White_Flame> java, being an object-obsessed language, for instance, demands creating classes before methods/functions
[06:12:18] <White_Flame> sql databases require creating a schema before just dumping in data, as other storage forms allow
[06:12:19] <White_Flame> etc
[06:12:22] <CptKirk> How could you define a method without a class?
[06:12:31] <mfiano> Oh boy
[06:12:40] <mfiano> methods are not associated with classes at all in CL
[06:12:47] <White_Flame> CptKirk: lack of semantics, hence "methods/functions"
[06:12:54] <White_Flame> for the java case
[06:13:09] <White_Flame> the interactivity of Lisp is also a huge boon in prototyping
[06:13:09] <CptKirk> but they say things like (defmethod method-name ((instance class-name)) ...) no?
[06:13:25] <mfiano> They don't have to. EQL specialization or custom rules are possible
[06:13:32] <CptKirk> that's odd
[06:13:33] <White_Flame> creating new functionality on the fly while your existing code is running, and your last-run datastructures & application state are still all fully intact in the image
[06:13:38] <CptKirk> how do you specify what it applies to then?
[06:13:48] <CptKirk> oh that is nifty
[06:13:53] <mfiano> and you can do things like (defmethod foo ((a a) (b b)) ...). Which class does foo belong inside?
[06:13:54] <CptKirk> didn't know about that
[06:14:04] <CptKirk> b and a, or a + b?
[06:14:13] <CptKirk> sorry b or a, or a + b?
[06:14:15] <mfiano> so you duplicate it everywhere?
[06:14:22] <CptKirk> idk?
[06:14:29] <mfiano> Now you do :)
[06:14:37] <CptKirk> I've read the CLOS book like... 3 years ago
[06:15:01] <CptKirk> don't remember much, but when experimenting with it I found it not to different in usage to regular OOP
[06:15:03] <mfiano> (defmethod foo ((a a) (b (eql :some-symbol))) ...)
[06:15:07] <CptKirk> maybe not in developing things
[06:15:16] <CptKirk> but in usage of instances of objects
[06:15:34] <mfiano> Then you didn't understand much, or aren't remembering much.
[06:15:37] <White_Flame> :before/:around/:after methods for one are quite different
[06:15:43] <White_Flame> as a very basic differentiator
[06:15:45] <CptKirk> or I stuck to methodology that I understood
[06:15:59] <CptKirk> and coerced it into forms that I recognized
[06:16:18] <mfiano> Also what is "the CLOS book"? I have like 5 of those things, none by that title.
[06:16:29] <CptKirk> are there any examples you'd point to of production CL that has good OO practices for CL?
[06:16:31] <White_Flame> and multiple-dispatch in general is significantly different than all popular "OO" languages
[06:16:59] <White_Flame> most production CL isn't opensource
[06:17:02] <CptKirk> "object oriented programming in common lisp" or some such
[06:17:18] <mfiano> THink that is the Keene one. I haven't read it
[06:17:41] <CptKirk> idk, but it was a pretty dense read whatever it was, very meticulous and dreary
[06:17:49] <mfiano> Yes, most production software is not open-source.
[06:17:52] <CptKirk> i remember I was reading it while my wife was shopping at the mall at one point
[06:18:03] <White_Flame> especially as Lisp's heyday was government contracting
[06:18:05] <CptKirk> any open source examples that use CL OO "correctly"?
[06:18:07] <mfiano> I don't know of any that meet your criteria that is freely available to view
[06:18:32] <CptKirk> I did look at some library a few weeks back that did OO, and the north library uses OO
[06:18:33] <mfiano> Not without gaining an in-depth understanding of the problem domain (most CL code is macroized to meet the developers thought processes)
[06:18:43] <CptKirk> and honestly I just swtiched to drakma, because I'm not really using oauth atm
[06:18:59] <White_Flame> the only "incorrectly" is not using the best tool for the job.  There's tons of ways to do things, and some will be more applicable than others in terms of directness of expression
[06:19:08] <White_Flame> don't worry about trying to achieve some sort of semantic perfection when you're literally first learning
[06:19:09] <CptKirk> that's the problem
[06:19:17] <CptKirk> there are so many tools, idk what the right ones are for which jobs
[06:19:19] <mfiano> THat's the nice thing about CL. Very difficult for outsiders, even other CL developers, but very easy to mould to be better understood by an individual and more suited to a problem domain.
[06:19:22] <White_Flame> it's a toolkit to learn
[06:19:29] <White_Flame> just learn what things do
[06:19:34] <mfiano> It's the "lisp curse"
[06:19:35] <CptKirk> right but I can't seem to figure out how to learn things one tool at a time
[06:19:45] <White_Flame> write code
[06:19:51] <CptKirk> but what do I write lol
[06:19:59] <CptKirk> most "toy" problems can be solved with recursion and lists
[06:20:04] <CptKirk> no dependencies or packages required
[06:20:13] <CptKirk> so that clearly didn't teach me much over these years
[06:20:19] <White_Flame> sure, so make toys that use other features simply for the sake of getting into those other features
[06:20:34] <CptKirk> but then I'd be using the wrong tool for the job
[06:20:43] <White_Flame> there is no "job" but learning in such a case
[06:21:17] <White_Flame> I mean, figuring out how to integrate into asdf/quicklisp for a single file project is worthwhile, even if not strictly necessary, for instance
[06:21:19] <CptKirk> I suppose, but it doesn't help me understand the application of things like the CLOS when nothing I'm solving fits its purpose
[06:21:28] <CptKirk> I'm getting better with asdf
[06:21:32] <mfiano> Might I suggest reading AMOP then?
[06:21:34] <CptKirk> because now I depend on april, drakma etc
[06:21:40] <mfiano> You implement CLOS with CLOS
[06:21:50] <mfiano> That will give you a much better understanding of how to use it
[06:22:31] <CptKirk> ok, I'll have a gande
[06:22:34] <CptKirk> gander
[06:22:48] <CptKirk> do you have a source for pdf?
[06:23:11] <mfiano> But I would really start with PCL, even if you already read it years ago, as from some of your questions, it can definitely still fill in some gaps.
[06:23:23] <mfiano> Most people start with PCL, as it is very digestible
[06:23:31] <mfiano> AMOP is not free
[06:23:32] <CptKirk> I flipped through PCL the other day, I feel like most of it is still fresh
[06:23:35] <mfiano> PCL is
[06:23:45] <CptKirk> haven't ever finished LOL
[06:23:51] <mfiano> Which LOL?
[06:23:55] <mfiano> There are 2
[06:23:59] <CptKirk> let over lambda
[06:24:07] <mfiano> That should probably be last on your list
[06:24:15] <mfiano> It is too advanced for you right now for sure
[06:24:32] <CptKirk> I didn't feel like it was beyond me in terms of language features
[06:24:55] <CptKirk> I was just mentally tired from all the formal rigor 
[06:25:00] <CptKirk> took a break from it
[06:25:15] <CptKirk> and some of the use-cases are pretty advanced as well
[06:25:28] <mfiano> That book isn't really about language features. It is a whole paradigm of thinking, and on top of that, the book is very opinionated and filled with bad code you don't want to be exposed to or pick up any bad habits from
[06:25:44] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-19-70-31-33-162.dsl.bell.ca) (Remote host closed the connection)
[06:25:56] <White_Flame> specifically, it does manual dispatch and creates objects in closures that can't be inspected or recompiled
[06:26:05] <White_Flame> just at the basic construct he builds
[06:26:12] <CptKirk> ah
[06:26:18] <mfiano> And favors anaphors, and refuses to earmuff specials, etc
[06:26:19] <CptKirk> now that you mention it, that is a benefit of clos
[06:26:41] <CptKirk> for production code especially
[06:26:49] <mfiano> It is more like "hey look what macros can do" moreso than "this is what you should do"
[06:26:54] <CptKirk> updating an object without recompiling or reinitilizing your state
[06:27:01] <White_Flame> closures are really the 1 way to achieve fully "private" data in CL, and "let over lambda" obviously is one
[06:27:22] <CptKirk> ok, that's kinda neat
[06:27:35] <CptKirk> and structs don't support extension without full recompilation?
[06:27:36] <White_Flame> which means all interactive development can't see it once it's instantiated
[06:27:45] <mfiano> fully private, except for pandoric macros :)
[06:28:08] <White_Flame> you can redefine struct definitions, but you can't update instances to match the new one.  standard-objects can be updated to match the new class
[06:28:09] <mfiano> which open up the closure, so to speak, albeit hackily
[06:28:23] <CptKirk> wait, you can define methods without recompiling, but can you add "slots" and extend instances of a class without reinitializing instances of those classes?
[06:28:30] <mfiano> Yes
[06:28:35] <CptKirk> that's slick
[06:28:56] <CptKirk> that's a huge boon, although... so would relational lists ;)
[06:29:17] <CptKirk> you would simply populate a list the lenght of the other lists with an initial value
[06:29:45] <mfiano> You can also change the class of an instance to be a completely different class, without changing the instance's identity (it is still a pointer to the same area in memory)
[06:29:49] <White_Flame> 1960s lisp did vaguely similar things, by placing key/values onto global symbols
[06:29:55] <White_Flame> but, we've grown past that :-P
[06:51:46] <beach> Wow!  
[06:52:28] * beach does not plan to enter into this discussion.
[06:52:54] <CptKirk> i found it ultimately answered some of my questions
[06:53:05] <CptKirk> so thanks to those that did :)
[06:53:17] <beach> At great cost to the participants, and I don't have such time at my disposal.
[06:53:25] <CptKirk> :/
[06:54:41] <CptKirk> well I don't have simple questions. And I tend to learn concepts in whole rather than in pieces, so I have a hard time getting to a single kernel of a question because my question is in the form of an "approach" or a "philosophy"
[06:56:20] <CptKirk> what I could reify from our conversation is "in common lisp we use meta-syntactic programming and abstractions in order to enable extension of applications at runtime in production"
[06:57:17] <CptKirk> That is a powerful idea, much moreso than "CLOS is OO in CL" or what someone said earlier "just learn to use the clos and iteration" that is advice, but it doesn't convey purpose. Now that I have a nugget of purpose I can direct my intention much more effectively
[06:57:24] <CptKirk> and so I am grateful to those htat stuck it out with me
[08:27:49] *** Joins: lisp123 (~lisp123@5.30.23.247)
[08:50:14] *** Quits: lisp123 (~lisp123@5.30.23.247) (Remote host closed the connection)
[08:50:47] *** Joins: lisp123 (~lisp123@5.30.23.247)
[08:55:29] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[09:20:08] *** Joins: lisp123 (~lisp123@5.30.23.247)
[09:21:54] *** Quits: CptKirk (~CptKirk@70-57-27-195.hlrn.qwest.net) (Ping timeout: 256 seconds)
[09:51:33] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[09:53:54] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[10:27:14] *** Quits: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de) (Quit: Leaving)
[10:28:13] *** Joins: shka (~herr@109.231.6.176)
[11:35:28] *** Joins: hendursa1 (~weechat@user/hendursaga)
[11:38:48] *** Quits: hendursaga (~weechat@user/hendursaga) (Ping timeout: 276 seconds)
[11:49:24] *** Joins: CookE[] (~thedawn@user/thedawn)
[11:49:24] *** Joins: fef (~thedawn@user/thedawn)
[11:51:00] *** Quits: fef (~thedawn@user/thedawn) (Client Quit)
[12:54:40] *** Quits: CookE[] (~thedawn@user/thedawn) (Remote host closed the connection)
[13:17:36] *** Quits: hendursa1 (~weechat@user/hendursaga) (Ping timeout: 276 seconds)
[13:19:34] *** Joins: hendursa1 (~weechat@user/hendursaga)
[13:25:14] *** Quits: lisp123 (~lisp123@5.30.23.247) (Remote host closed the connection)
[13:25:28] *** Joins: lisp123 (~lisp123@5.30.23.247)
[13:52:58] *** Joins: random-nick (~random-ni@87.116.183.117)
[14:41:09] *** Joins: macaw (~macaw@176.221.120.196)
[14:53:16] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-19-70-31-33-162.dsl.bell.ca)
[15:04:14] *** Quits: lisp123 (~lisp123@5.30.23.247) (Remote host closed the connection)
[15:11:06] *** Joins: lisp123 (~lisp123@5.30.23.247)
[15:15:38] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 246 seconds)
[15:45:12] *** Joins: jeffrey (~jeffrey@2001:1c00:b11:8800:399c:16c5:8a3c:727e)
[15:51:27] *** Joins: lisp123 (~lisp123@5.30.23.247)
[15:56:47] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[15:58:27] *** Joins: selwyn (~selwyn@user/selwyn)
[16:05:35] *** Quits: random-nick (~random-ni@87.116.183.117) (Ping timeout: 252 seconds)
[16:54:14] *** Joins: lisp123 (~lisp123@5.30.23.247)
[17:00:25] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-19-70-31-33-162.dsl.bell.ca) (Remote host closed the connection)
[17:12:02] *** Quits: makomo (~makomo@user/makomo) (Quit: WeeChat 3.2)
[17:12:29] *** Joins: makomo (~makomo@user/makomo)
[17:14:56] *** Quits: lottaquestions (~nick@2607:fa49:503e:3000:4dca:d3cb:8926:bf89) (Ping timeout: 252 seconds)
[17:19:07] *** Quits: makomo (~makomo@user/makomo) (Quit: WeeChat 3.2)
[17:19:34] *** Joins: makomo (~makomo@user/makomo)
[17:32:03] *** Joins: tyson2 (~user@cpe44d9e795a64f-cm688f2e2dfaa0.sdns.net.rogers.com)
[17:32:04] *** Joins: random-nick (~random-ni@87.116.165.220)
[17:59:32] *** Joins: thrig (~thrig@70.97.65.251)
[18:03:31] *** Quits: mns (~mns@c-73-119-178-157.hsd1.ma.comcast.net) (Quit: Quit)
[18:07:38] *** Joins: mns (~mns@c-73-119-178-157.hsd1.ma.comcast.net)
[18:09:06] *** Quits: cyberbanjo (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[18:21:12] *** Quits: mns (~mns@c-73-119-178-157.hsd1.ma.comcast.net) (Quit: Quit)
[18:21:12] *** Joins: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de)
[18:27:26] *** Quits: tyson2 (~user@cpe44d9e795a64f-cm688f2e2dfaa0.sdns.net.rogers.com) (Quit: ERC (IRC client for Emacs 27.2))
[18:29:23] *** Joins: CptKirk (~CptKirk@70-57-27-195.hlrn.qwest.net)
[18:31:53] *** Quits: lisp123 (~lisp123@5.30.23.247) (Remote host closed the connection)
[18:38:50] *** Quits: selwyn (~selwyn@user/selwyn) (Read error: Connection reset by peer)
[18:40:04] *** Quits: CptKirk (~CptKirk@70-57-27-195.hlrn.qwest.net) (Ping timeout: 256 seconds)
[18:42:45] *** Joins: selwyn (~selwyn@user/selwyn)
[18:57:50] *** Quits: selwyn (~selwyn@user/selwyn) (Read error: Connection reset by peer)
[19:11:32] *** Quits: jeffrey (~jeffrey@2001:1c00:b11:8800:399c:16c5:8a3c:727e) (Remote host closed the connection)
[19:12:12] *** Joins: lisp123 (~lisp123@5.30.23.247)
[19:23:14] *** Quits: thrig (~thrig@70.97.65.251) (Remote host closed the connection)
[19:29:31] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[19:34:11] *** Joins: thrig (~thrig@65.113.153.50)
[20:28:25] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:28:28] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:30:16] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:30:17] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:31:44] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:31:52] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:33:15] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:33:15] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:33:44] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:33:59] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:37:35] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:38:48] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:39:03] *** Joins: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23)
[20:39:37] *** Quits: malik (~user@2607:fb90:4251:52c1:bd1:ab41:5705:7c23) (Remote host closed the connection)
[20:47:31] *** Joins: pedro-delfino (sid507296@id-507296.helmsley.irccloud.com)
[20:54:47] *** Joins: lisp123 (~lisp123@5.30.23.247)
[20:59:17] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[21:21:27] *** Joins: CrashTestDummy2 (~CrashTest@ool-ad02813b.dyn.optonline.net)
[21:24:20] *** Quits: hendursa1 (~weechat@user/hendursaga) (Quit: hendursa1)
[21:24:59] *** Joins: hendursaga (~weechat@user/hendursaga)
[21:25:01] *** Quits: CrashTestDummy3 (~CrashTest@ool-ad02813b.dyn.optonline.net) (Ping timeout: 265 seconds)
[22:05:46] *** Joins: lisp123 (~lisp123@5.30.23.247)
[22:14:05] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 252 seconds)
[22:15:04] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[22:43:29] *** Quits: Josh_2 (~user@37.25.47.130) (Quit: ERC (IRC client for Emacs 27.1))
[22:47:02] *** Quits: thrig (~thrig@65.113.153.50) (Remote host closed the connection)
[23:11:31] *** Joins: tyson2 (~user@bras-base-toroon0628w-grc-46-142-112-141-177.dsl.bell.ca)
[23:15:20] *** Joins: lotuseater (~user@p200300e7871bd300c158d62dc7544d08.dip0.t-ipconnect.de)
