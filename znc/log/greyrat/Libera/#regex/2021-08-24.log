[00:00:59] *** Joins: Lope (~lope@user/lope)
[00:01:59] *** Joins: d1cor (~diego@179.63.242.114)
[00:24:07] *** Quits: d1cor (~diego@179.63.242.114) (Quit: WeeChat 3.2)
[00:26:08] *** Joins: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net)
[00:30:16] *** Joins: re101-cow-11 (~re101-cow@183.82.179.194)
[00:30:36] <re101-cow-11> hi
[00:30:55] <JohnDoe2> moooo
[00:31:36] <re101-cow-11> I need to place a 100+ redirects from an old URL to new URL
[00:32:01] <re101-cow-11> Can we achieve this adding regex redirect?
[00:32:17] <JohnDoe2> apache?
[00:32:52] *** re101-cow-11 is now known as Karthikeyan
[00:33:28] <Karthikeyan> What do you mean by apache? Sever?
[00:33:58] <JohnDoe2> yup which web server are you trying this in? or is it in a script?
[00:35:06] <Karthikeyan> Sorry, I'm not aware of the servers.
[00:35:25] <Karthikeyan> Can you tell the ways to this? I can try and let you know if this works.
[00:35:55] <Karthikeyan> The source and destination URLs almost some expect an account id.
[00:36:32] <Karthikeyan> Source: https://www.sothebysrealty.com/eng/sales/detail/180-l-2543-22TE5B
[00:36:51] <Karthikeyan> Destination: https://www.sothebysrealty.com/eng/sales/detail/180-l-86559-22TE5B
[00:39:34] <JohnDoe2> Karthikeyan sorry I'm a bit confused here - do you own the site?
[00:42:28] <Karthikeyan> No, this is for my own knowledge.
[00:43:28] <maroon> how is the regex supposed to know it should change 2543 into 86559?
[00:44:27] <Karthikeyan> I'm not sure that's why I'm asking in this chat.
[00:45:04] <JohnDoe2> ok, well, for your knowledge sites are served by HTTP servers of which arguably the 2 most popular are apache and nginx. They both support rewrite rules using regex. But then there's also the possibility to redirect using scripting languages like php or whatever else is served by those HTTP/web servers
[00:45:21] <JohnDoe2> and ultimately you can do it in HTML/js too which runs on the client's machine
[00:46:09] <JohnDoe2> but this is really just a regex channel so getting help with all of the above is outside its scope
[00:46:47] *** Joins: re101-cow-11 (~re101-cow@183.82.24.30)
[00:48:22] <re101-cow-11> Can you help me with this?
[00:48:35] *** Parts: re101-cow-11 (~re101-cow@183.82.24.30) ()
[00:49:10] *** Quits: Karthikeyan (~re101-cow@183.82.179.194) (Ping timeout: 246 seconds)
[00:49:16] *** Joins: re101-cow-54 (~re101-cow@183.82.24.30)
[00:49:22] *** re101-cow-54 is now known as Karthikeyan
[00:49:28] <Karthikeyan> hi
[00:49:53] <JohnDoe2> This isn't live customer support where you get random people every time, you're leaving and joining the same room :)
[00:50:34] <Karthikeyan> My connection was lost and not able to connect in the same chat window.
[00:51:03] <Karthikeyan> Sorry about that.
[00:51:15] <Karthikeyan> Can you help me with this redirect?
[00:52:00] <JohnDoe2> you just want a regex to swap the two numbers?
[00:53:07] <maroon> you have a list of from/to number pairs that need a search/replace within the url?
[00:54:15] <Karthikeyan> Yes
[00:54:52] <Karthikeyan> from 2543 to 86559
[00:56:24] <Karthikeyan> I think it can be done by rewrite rule.
[00:58:32] <JohnDoe2> yes it can be but if you don't know what apache is, that's probably going to be a bit of a challenge. The regex we give you won't necessarily be a copy paste over to a rewrite rule
[00:59:13] <maroon> ah, so this is a search-and-replace that applies to all url's where -2543- is found?
[01:00:25] <Karthikeyan> yes
[01:00:27] *** Joins: txtsd (~txtsd@user/txtsd)
[01:06:36] <JohnDoe2> Karthikeyan RewriteRule "-2543-" "-86559-" [R=301] ( for apache )
[01:09:05] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[01:12:18] *** Quits: Karthikeyan (~re101-cow@183.82.24.30) (Quit: Client closed)
[01:21:51] *** Quits: sQVe (~sQVe@user/sqve) (Quit: Bye!)
[01:22:49] *** Quits: Lope (~lope@user/lope) (Ping timeout: 250 seconds)
[01:42:34] *** Quits: farn (~farn@2a03:4000:7:3cd:d4ab:85ff:feeb:f505) (Ping timeout: 240 seconds)
[01:42:54] *** Quits: genius3000 (g3k@user/genius3000) (Ping timeout: 272 seconds)
[01:43:05] *** Joins: genius3000 (g3k@user/genius3000)
[01:43:45] *** Joins: farn (~farn@2a03:4000:7:3cd:d4ab:85ff:feeb:f505)
[01:45:57] *** Quits: bluesmonk (uid318026@id-318026.brockwell.irccloud.com) (Quit: Connection closed for inactivity)
[02:19:07] *** Quits: Bayes (~Bayes@user/bayes) (Quit: Connection closed)
[02:23:53] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[02:28:26] *** Parts: velix (~velix@user/velix) (Leaving)
[02:32:07] *** Quits: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net) (Ping timeout: 240 seconds)
[02:33:40] *** Quits: WildMan (~WildMan@user/wildman) (Ping timeout: 240 seconds)
[02:34:53] *** Joins: WildMan (~WildMan@user/wildman)
[02:36:55] *** Quits: karakedi (~eAC53C340@user/karakedi) (Remote host closed the connection)
[03:08:51] *** Quits: adherzog (uid387168@id-387168.tooting.irccloud.com) (Quit: Connection closed for inactivity)
[03:51:50] *** Joins: re101-ant-54 (~re101-ant@148.64.69.21)
[03:54:36] *** Joins: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net)
[04:01:51] *** Quits: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net) (Ping timeout: 250 seconds)
[04:04:08] *** Joins: mutandis (~mut@c-73-129-211-144.hsd1.md.comcast.net)
[04:04:45] *** Quits: mutandis (~mut@c-73-129-211-144.hsd1.md.comcast.net) (Client Quit)
[04:06:30] *** Quits: Gurkenglas (~Gurkengla@dslb-088-064-053-140.088.064.pools.vodafone-ip.de) (Ping timeout: 250 seconds)
[04:07:37] *** Quits: re101-ant-54 (~re101-ant@148.64.69.21) (Ping timeout: 246 seconds)
[04:42:27] *** Quits: cthulchu (~Cthulchu@193.194.107.250) (Ping timeout: 240 seconds)
[04:59:28] *** Joins: ttree (~ttree0@c-73-239-62-159.hsd1.wa.comcast.net)
[05:10:01] *** Quits: shailangsa (~shailangs@host86-186-136-25.range86-186.btcentralplus.com) (Ping timeout: 248 seconds)
[05:30:31] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:31:04] *** Joins: shailangsa (~shailangs@host86-185-102-120.range86-185.btcentralplus.com)
[05:32:42] *** Quits: maetthew (~maetthew@user/maetthew) (Quit: ZNC 1.8.2 - https://znc.in)
[05:34:29] *** Joins: vlm (~vlm@user/vlm)
[05:38:35] *** Joins: maetthew (~maetthew@c188-150-100-85.bredband.tele2.se)
[05:38:35] *** Quits: maetthew (~maetthew@c188-150-100-85.bredband.tele2.se) (Changing host)
[05:38:35] *** Joins: maetthew (~maetthew@user/maetthew)
[05:47:04] *** Quits: ttree (~ttree0@c-73-239-62-159.hsd1.wa.comcast.net) (Quit: Leaving)
[05:47:20] *** Joins: ttree (~ttree0@c-73-239-62-159.hsd1.wa.comcast.net)
[05:49:36] *** Quits: ttree (~ttree0@c-73-239-62-159.hsd1.wa.comcast.net) (Client Quit)
[08:15:23] *** Joins: ttree (~ttree0@c-73-239-62-159.hsd1.wa.comcast.net)
[08:15:50] *** Joins: d1cor (~diego@179.63.242.114)
[08:33:07] *** Quits: d1cor (~diego@179.63.242.114) (Ping timeout: 240 seconds)
[08:34:11] *** Joins: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net)
[08:38:27] *** Quits: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net) (Ping timeout: 240 seconds)
[08:52:29] *** Joins: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net)
[08:56:47] *** Quits: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net) (Ping timeout: 240 seconds)
[09:43:05] *** Joins: Lope (~lope@user/lope)
[09:48:57] *** Quits: Lope (~lope@user/lope) (Ping timeout: 250 seconds)
[10:16:07] *** Quits: txtsd (~txtsd@user/txtsd) (Ping timeout: 240 seconds)
[10:48:51] *** Joins: Gurkenglas (~Gurkengla@dslb-088-064-053-140.088.064.pools.vodafone-ip.de)
[10:51:28] *** Joins: cthulchu (~Cthulchu@193.194.107.250)
[11:06:32] *** Joins: I-M (~id@78.183.101.176)
[11:13:34] *** Joins: palasso (~palasso@user/palasso)
[11:21:34] *** Quits: ttree (~ttree0@c-73-239-62-159.hsd1.wa.comcast.net) (Ping timeout: 250 seconds)
[11:25:14] *** Joins: Lope (~lope@user/lope)
[11:25:40] *** Joins: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net)
[11:26:53] *** Joins: karakedi (~eAC53C340@user/karakedi)
[11:34:51] *** Quits: unluckyshrubbery (~unluckysh@45-19-33-188.lightspeed.livnmi.sbcglobal.net) (Quit: ZNC 1.8.2 - https://znc.in)
[11:53:30] *** Quits: I-M (~id@78.183.101.176) (Read error: Connection reset by peer)
[12:00:00] *** Joins: lavaball (felix@31.204.155.215)
[12:08:39] *** Quits: re101-macaw-17 (~re101-mac@51.124.143.196) (Quit: Ping timeout (120 seconds))
[12:15:33] *** Quits: To_Aru_Shiroi_Ne (~eva@d5152df72.static.telenet.be) (Remote host closed the connection)
[12:16:50] *** Quits: davido (~daobrien@2402:a040:26b:f600:b5c4:b735:5621:65d9) (Read error: Connection reset by peer)
[12:17:16] *** Joins: ToAruShiroiNeko (~eva@user/toarushiroineko)
[12:28:50] *** Quits: re101-canaan-86 (~re101-can@51.124.143.196) (Quit: Client closed)
[12:46:07] *** Joins: re101-numbat-44 (~re101-num@222.94.37.178)
[12:46:33] <re101-numbat-44> !rehelp
[12:46:33] <perlbot> Please share a https://regex101.com/ link containing your regex and sample data, stay as long as possible, and we'll do our best to assist you ASAP.
[13:09:04] *** Quits: koollman (samson_t@sp1.kooll.org) (Changing host)
[13:09:04] *** Joins: koollman (samson_t@user/koollman)
[13:36:41] *** Joins: unluckyshrubbery (~unluckysh@45-19-33-188.lightspeed.livnmi.sbcglobal.net)
[13:44:59] *** Joins: re101-bombay-54 (~re101-bom@103.121.16.73)
[13:46:19] *** Quits: re101-bombay-54 (~re101-bom@103.121.16.73) (Client Quit)
[13:57:56] *** Quits: re101-numbat-44 (~re101-num@222.94.37.178) (Quit: Client closed)
[14:10:49] *** Quits: mannibis (~mannibis@162.211.65.25) (Ping timeout: 248 seconds)
[14:11:43] *** Quits: shailangsa (~shailangs@host86-185-102-120.range86-185.btcentralplus.com) (Ping timeout: 252 seconds)
[14:13:04] *** Joins: mannibis (~mannibis@162.211.65.25)
[14:28:32] *** Joins: shailangsa_ (~shailangs@host86-185-102-120.range86-185.btcentralplus.com)
[14:53:26] *** Joins: re101-gerbil-53 (~re101-ger@197.98.201.65)
[14:54:07] <re101-gerbil-53> Hi,would like to create a java regex expression that matches only the body of a json and ignores anything else 
[14:54:30] <re101-gerbil-53> !rehelp
[14:54:30] <perlbot> Please share a https://regex101.com/ link containing your regex and sample data, stay as long as possible, and we'll do our best to assist you ASAP.
[14:54:51] <re101-gerbil-53> Hi,would like to create a java regex expression that matches only the body of a json and ignores anything else 
[14:57:19] *** Quits: re101-gerbil-53 (~re101-ger@197.98.201.65) (Client Quit)
[15:01:23] *** Joins: re101-deer-68 (~re101-dee@116.72.145.229)
[15:01:30] <re101-deer-68> !rehelp
[15:01:30] <perlbot> Please share a https://regex101.com/ link containing your regex and sample data, stay as long as possible, and we'll do our best to assist you ASAP.
[15:01:34] <re101-deer-68> https://regex101.com/r/41BgXm/1
[15:05:52] *** Joins: re101-deer-6841 (~re101-dee@42.105.125.75)
[15:06:36] <re101-deer-6841> Sorry, i got disconnected for a moment
[15:06:43] <re101-deer-6841> I wanna replace lines 38, 39 and 40 with an `<ol>` tag but it should not replace the number, `1.`, at the same time, it should replace lines 44 and 45 starting from </span> onwards with an `</ol>` tag
[15:08:04] *** Quits: re101-deer-68 (~re101-dee@116.72.145.229) (Ping timeout: 246 seconds)
[15:08:25] <re101-deer-6841> https://regex101.com/r/41BgXm/1
[15:11:21] <digitok> :/
[15:12:15] <re101-deer-6841> O:3 
[15:12:48] <digitok> lol
[15:14:15] <digitok> ok i'll take a look
[15:14:19] <digitok> can't say no to that face
[15:14:34] <re101-deer-6841> Thanks
[15:15:27] <digitok> what's the relevance of [CONFIRMATORY SYMPTOMS]
[15:15:32] <re101-deer-6841> There is another paragraph after lines 45, 46 and 47 but I skipped putting it in my RegEx for brevity
[15:15:39] <digitok> that's on line 33
[15:16:15] <re101-deer-6841> There are othere paragraphs, but I want only the para with CONFIRMATOTY SYMPTOMS to be changed
[15:17:23] <digitok> so just whatever paragraph comes after that?
[15:18:49] <re101-deer-6841> There is a block of text b4 the CONFIRMATORY SYMPTOMS block and one after but I want only the block of text with CONFIRMATORY SYMTOMS to have this replacement
[15:19:12] <digitok> yea i know
[15:19:23] <digitok> so is that just the first <p we find after that text?
[15:19:31] <digitok> and will there be more than 1?
[15:19:34] <re101-deer-6841> I wanna replace lines 38, 39 and 40 with an `<ol>` tag but it should not replace the number, `1.` and at the same time, it should replace lines 44 and 45 starting from </span> onwards with an `</ol>` tag
[15:19:38] <digitok> :|
[15:19:42] <digitok> i got all that
[15:21:59] <digitok> i have a solution, just waiting on your answers
[15:21:59] <re101-deer-6841> The first <p............<span...................1. after CONFIRMATORY SYMPTOMS and the last </span.................</p> needs to be replaced but not the next para (I have not put it in the RegEx0
[15:22:14] <digitok> yes i know
[15:22:42] <digitok> i'll just assume the answers are yes and no respectively
[15:22:45] <re101-deer-6841> I hope you got what I'm trying to convey
[15:23:04] <digitok> https://regex101.com/r/41BgXm/2
[15:23:17] <digitok> i mean, i got all of that before i asked those questions ;)
[15:25:15] <re101-deer-6841> Terrific
[15:25:22] <re101-deer-6841> U R the best
[15:25:29] <re101-deer-6841> <3 
[15:25:51] <re101-deer-6841> Thanks a lot
[15:26:30] <digitok> yw
[15:26:35] *** Quits: re101-deer-6841 (~re101-dee@42.105.125.75) (Quit: Client closed)
[15:46:39] *** Quits: unluckyshrubbery (~unluckysh@45-19-33-188.lightspeed.livnmi.sbcglobal.net) (Quit: ZNC 1.8.2 - https://znc.in)
[15:46:54] *** Joins: unluckyshrubbery (~unluckysh@45-19-33-188.lightspeed.livnmi.sbcglobal.net)
[16:13:52] *** Joins: rtjure (~rtjure@bras-79-132-26-254.comnet.bg)
[16:24:55] *** Joins: d1cor (~diego@179.63.242.114)
[16:44:36] *** Joins: txtsd (~txtsd@user/txtsd)
[16:57:55] *** Joins: maroloccio (~marolocci@37.100.40.252)
[17:03:53] *** Joins: re101-skunk-38 (~re101-sku@pool-74-105-162-249.nwrknj.fios.verizon.net)
[17:04:12] <re101-skunk-38> !rehelp
[17:04:13] <perlbot> Please share a https://regex101.com/ link containing your regex and sample data, stay as long as possible, and we'll do our best to assist you ASAP.
[17:07:45] <re101-skunk-38> https://regex101.com/r/hWelnI/1 I'm curious how to get this expression to say "don't include data that contains X"
[17:08:44] <digitok> you'd need to be more specific
[17:09:04] <re101-skunk-38> for my example I don't want to include anything that says admin or assistant
[17:10:42] *** Quits: maroloccio (~marolocci@37.100.40.252) (Quit: WeeChat 3.0)
[17:10:51] <re101-skunk-38> Updated the expression to include those examples: https://regex101.com/r/inNSmk/1
[17:11:33] *** Joins: maroloccio (~marolocci@37.100.40.252)
[17:12:32] <digitok> fyi you can click "update" to preserve the link id
[17:12:45] <digitok> then you'll get versions
[17:13:10] <digitok> ok, so is your input always an entire line?
[17:14:00] <re101-skunk-38> Sorry could you rephrase that.
[17:14:06] <re101-skunk-38> And thanks for the tip!
[17:15:26] <re101-skunk-38> Inputs are job titles, if that is the answer you are looking for.
[17:15:33] *** Quits: shailangsa_ (~shailangs@host86-185-102-120.range86-185.btcentralplus.com) ()
[17:15:41] <digitok> ok, and just a single job title?
[17:16:18] *** Quits: maroloccio (~marolocci@37.100.40.252) (Client Quit)
[17:16:48] *** Joins: Arauto (~Arauto@168.195.101.249)
[17:17:03] <digitok> assuming yes, https://regex101.com/r/inNSmk/3
[17:17:12] <re101-skunk-38> multiple at a time. I'm using sql to search our database for specific job titles.
[17:17:16] <digitok> this also gets rid of the empty group 2
[17:17:49] <digitok> hm, the lookahead might not work in sql
[17:17:58] *** Joins: maroloccio (~marolocci@37.100.40.252)
[17:18:07] <re101-skunk-38> Using redshift specifically
[17:18:25] <re101-skunk-38> let me give this a shot and see how redshift responds.
[17:18:41] <re101-skunk-38> one sec..
[17:18:42] <digitok> yea, it's posix
[17:18:49] <digitok> it won't work
[17:19:00] <re101-skunk-38> oh got ya
[17:19:19] *** Joins: re101-liger-73 (~re101-lig@1-169-29-184.dynamic-ip.hinet.net)
[17:19:20] <digitok> could you not do it in sql
[17:19:32] <digitok> AND NOT blah
[17:19:33] <digitok> or such
[17:19:53] <re101-liger-73> how to handle task8 
[17:19:53] <digitok> AND NOT regex_thing('Admin|Assistant')
[17:19:56] <digitok> or whatever
[17:20:01] <re101-liger-73> it's too hard
[17:20:09] <digitok> 07re101-liger-73, learn more regex
[17:20:25] <re101-liger-73> i only archieve 12/15
[17:20:33] <re101-skunk-38> Yeah I could probably do that. Thank you.
[17:21:13] <re101-liger-73> could you give me some good advice
[17:21:32] <re101-liger-73> about regex learning 
[17:22:10] <digitok> !tutorials
[17:22:11] <perlbot> https://www.regular-expressions.info/tutorial.html, http://www.rexegg.com/, https://regexone.com/, https://youtu.be/_6QBBT9Sq1U
[17:22:15] <digitok> 07re101-skunk-38, yw :)
[17:22:38] <re101-liger-73> thx 
[17:22:47] <digitok> yw
[17:26:46] *** Joins: Bayes (~Bayes@ics177-97.icsincorporated.com)
[17:26:59] *** Quits: Bayes (~Bayes@ics177-97.icsincorporated.com) (Changing host)
[17:26:59] *** Joins: Bayes (~Bayes@user/bayes)
[17:27:25] *** Parts: re101-liger-73 (~re101-lig@1-169-29-184.dynamic-ip.hinet.net) ()
[17:33:19] *** Joins: shailangsa (~shailangs@host86-185-102-120.range86-185.btcentralplus.com)
[17:34:05] *** Quits: re101-skunk-38 (~re101-sku@pool-74-105-162-249.nwrknj.fios.verizon.net) (Quit: Client closed)
[17:54:21] *** Quits: Muzer (~muzer@tim32.org) (*.net *.split)
[17:54:21] *** Quits: phenom (~primus@user/phenom) (*.net *.split)
[17:54:21] *** Quits: VectorX (~VectorX@user/vectorx) (*.net *.split)
[17:54:21] *** Quits: Koopz (~Koopz@koopz.rocks) (*.net *.split)
[17:54:21] *** Quits: byanka (~byanka@78.137.43.40) (*.net *.split)
[17:54:21] *** Quits: Timvde (~tim@towely.vdeynde.com) (*.net *.split)
[17:54:21] *** Quits: BUSY (~BUSY@user/busy) (*.net *.split)
[17:54:21] *** Quits: jelly (jelly@user/jelly) (*.net *.split)
[17:54:21] *** Quits: asynkron (sid433195@charlton.irccloud.com) (*.net *.split)
[17:54:21] *** Quits: celphi (uid97751@user/celphi) (*.net *.split)
[17:54:21] *** Quits: SirScott (~SirScott@c-67-176-100-163.hsd1.co.comcast.net) (*.net *.split)
[17:58:37] *** Joins: Muzer (~muzer@tim32.org)
[17:58:37] *** Joins: VectorX (~VectorX@user/vectorx)
[17:58:37] *** Joins: phenom (~primus@user/phenom)
[17:58:37] *** Joins: Koopz (~Koopz@koopz.rocks)
[17:58:37] *** Joins: byanka (~byanka@78.137.43.40)
[17:58:37] *** Joins: Timvde (~tim@towely.vdeynde.com)
[17:58:37] *** Joins: BUSY (~BUSY@user/busy)
[17:58:37] *** Joins: jelly (jelly@user/jelly)
[17:58:37] *** Joins: asynkron (sid433195@charlton.irccloud.com)
[17:58:37] *** Joins: celphi (uid97751@user/celphi)
[17:58:37] *** Joins: SirScott (~SirScott@c-67-176-100-163.hsd1.co.comcast.net)
[17:58:37] *** iridium.libera.chat sets mode: +vv VectorX Timvde
[18:06:31] *** Joins: adherzog (uid387168@id-387168.tooting.irccloud.com)
[18:15:03] *** Joins: hellothere (~hellother@165.225.63.59)
[18:15:10] <hellothere> hello 
[18:16:11] <hellothere> Need help, anyone available?
[18:16:20] *** Joins: proc (uid412603@wikipedia/procrastinatingreader)
[18:16:40] *** Joins: re101-uguisu-50 (~re101-ugu@93.55.83.12)
[18:16:58] *** Quits: re101-uguisu-50 (~re101-ugu@93.55.83.12) (Client Quit)
[18:18:30] <digitok> no
[18:18:31] *** Joins: re101-fousek-62 (~re101-fou@87.236.1.162)
[18:20:38] *** Quits: re101-fousek-62 (~re101-fou@87.236.1.162) (Client Quit)
[18:22:38] <hellothere> :D
[18:22:49] *** Quits: hellothere (~hellother@165.225.63.59) (Quit: Client closed)
[18:23:21] <testuser[m]> !testusee
[18:23:24] <testuser[m]> !testuser
[18:23:24] <perlbot> bruh
[18:23:27] <testuser[m]> !bruh
[18:23:28] <perlbot> testuser
[18:23:49] <proc> Is there a regex way to detect repeated strings (whatever the form may be)? Specifically I'm thinking of https://en.wikipedia.org/w/index.php?title=Bhumi_Pednekar&diff=prev&oldid=1040334745&diffmode=source & https://en.wikipedia.org/w/index.php?title=Bhumi_Pednekar&diff=prev&oldid=1040335022&diffmode=source etc, where the same BS is copied and pasted in mass
[18:24:57] <digitok> "whatever the form may be" is very vague
[18:25:12] <digitok> that could be interpreted as a single letter
[18:25:34] <digitok> but yes, that's possible
[18:25:52] <proc> right. that's the difficulty I was having. what the person usually does is write a short sentence of romanised Hindi and then copy+paste it a lot of times
[18:26:16] <digitok> the example you pasted are different links though
[18:26:22] <proc> I guess the question is if there's an approach to detect this generically using regex?
[18:26:23] <digitok> they wouldn't be considered repeated?
[18:26:40] <proc> the repeated phrase in the first is "Tereko Naangi Karke kaatunga pednekar"
[18:26:47] <digitok> oh, duh
[18:26:49] <proc> and in the second it's "Motherfucker"
[18:26:55] <digitok> i thought you meant the links literally
[18:26:57] <digitok> :)
[18:27:14] <Me-me> What digitok is avoiding telling you for good reason is that there is a very generic way to do it: (.+)\1
[18:27:21] <Me-me> But that's so monumentally inefficient as to be a Bad Idea.
[18:27:41] <digitok> was not
[18:27:44] <digitok> :<
[18:27:44] <Me-me> Especially on longer strings.
[18:27:49] * Me-me shrugs
[18:27:52] <Me-me> My apologies for assuming, then.
[18:28:04] <digitok> apology accepted
[18:28:35] <digitok> 07proc, so what's the goal
[18:28:49] <proc> well, the end goal is to block the edits
[18:29:03] <digitok> what about "the thing that that guy did"
[18:29:24] <proc> what do you mean?
[18:29:31] <digitok> well, "that" is repeated
[18:29:50] <Me-me> "I wish you well" has the l repeated at the end.
[18:29:54] <digitok> basically we need some kinda rules
[18:30:13] *** Joins: rtjure__ (~rtjure@bras-79-132-26-254.comnet.bg)
[18:30:38] <proc> ah, you mean the false positive issues? yeah, i was thinking if this approach were possible I could narrow it down further by checking if the change also contains certain common words (like "tereko" etc), but even then there are so many romanised hindi words that I'm not sure this approach would be too effective tbh
[18:32:01] <digitok> for example, we could detect a sequence of non-space characters that is repeated at least N times
[18:32:19] <digitok> for example, we could detect a sequence of non-space characters (or a sequence of multiple non-space sequences) that is repeated at least N times
[18:32:20] <digitok> rather
[18:32:50] <digitok> e.g. https://regex101.com/r/WuZE8N/1
[18:33:07] <digitok> this uses 3 as N
[18:33:09] <proc> the 11ms is an issue though however
[18:33:17] *** Quits: rtjure (~rtjure@bras-79-132-26-254.comnet.bg) (Ping timeout: 250 seconds)
[18:33:34] <digitok> the efficiency you mean?
[18:33:36] <proc> yeah
[18:33:49] <digitok> well, it also depends how it's implemented
[18:33:55] <digitok> you certainly wouldn't use /g for example
[18:34:01] <digitok> since you only need one match
[18:35:18] <digitok> https://regex101.com/r/WuZE8N/2
[18:35:24] <digitok> this makes it significantly more efficient
[18:35:40] <proc> hmm, yeah, that improves it a fair bit. this could work
[18:36:12] <digitok> \b might work better than the (?<!\S) and (?!\S)
[18:36:18] <digitok> we'd enable unicode mode
[18:37:03] <NiLon> are you going to scan whole wikipedia or why is the speed important here
[18:37:04] <Me-me> Are we doing work for actual factual wikipedia right now?
[18:37:10] <Me-me> Yeah.
[18:37:27] <digitok> https://regex101.com/r/WuZE8N/3
[18:37:33] <digitok> \b/unicode version
[18:37:59] <Me-me> \b with \S seems wrong.
[18:38:07] <digitok> not to me
[18:38:17] <Me-me> I mean why not just use \W
[18:38:24] <Me-me> \w rather
[18:38:31] <digitok> because then a-b won't match
[18:38:43] <Me-me> https://regex101.com/r/WuZE8N/4 Seems to be.
[18:38:56] <digitok> seems to be what
[18:39:00] <Me-me> Matching.
[18:39:01] <digitok> i don't see a-b there
[18:39:09] <Me-me> It matches all the same things.
[18:39:14] <digitok> <digitok> because then a-b won't match
[18:39:38] <digitok> https://regex101.com/r/WuZE8N/5
[18:40:00] <digitok> in other words, \w is far too limiting
[18:40:01] <digitok> imo
[18:40:19] <Me-me> Then don't use \b! What if it's -ab- -ab-
[18:40:39] <digitok> lol
[18:40:45] <digitok> fair enough
[18:41:12] <Me-me> As I'm understanding it we're trying to foil a spammer, aye?
[18:41:17] <proc> NiLon: the checks run before any edit are saved
[18:41:18] <digitok> the idea was based on the example where the first word was preceded by |
[18:41:25] <digitok> but subsequent words were not
[18:41:39] <Me-me> So we basically want as few edge cases as possible, so that the guy can't learn that he can wrap the spam in punctuation to get it past the filters.
[18:41:41] <digitok> but if it's repeated enough it won't matter
[18:41:45] <proc> Me-me: yeah it's some guy in odisha, india that likes to spend about an hour a day replacing pages of indian actresses with romanised indian abuse
[18:42:04] <proc> and apparently he has a ton of IP addresses to use
[18:42:15] <Me-me> Alright. (?<!\S) might be less efficient, but I think it's the way to go.
[18:42:20] <digitok> yep
[18:43:03] <digitok> (tl;dr version 2)
[18:43:06] <digitok> :)
[18:43:13] <Me-me> Minus /g
[18:43:17] <digitok> yep
[18:43:37] <digitok> unless the text contains a LOT of non-repeated stuff before the repeated stuff
[18:43:41] <digitok> it should be pretty fast
[18:44:11] <digitok> hmm
[18:44:25] <Me-me> If this is PCRE2 you could possibly optimise it with (?:\s|^)\K
[18:44:35] <digitok> making the group lazy might be better
[18:44:36] <Me-me> Iiiif I'm remembering the optimisations correctly
[18:44:46] <Me-me> which let's be honest I may just be.
[18:44:57] <digitok> that's less efficient in the example
[18:44:59] <digitok> :p
[18:45:07] <Me-me> Fair enough, suggestion withdrawn.
[18:45:10] <digitok> updated, https://regex101.com/r/WuZE8N/6
[18:45:27] <proc> it can filter by changed lines only, which should speed it up a fair bit. not sure if PCRE or PCRE2 though
[18:45:30] <digitok> now it searches for the fewest rather than the most
[18:46:04] <Me-me> Okay I'm seeing the next way through for the spammer.
[18:46:15] <Me-me> https://regex101.com/r/WuZE8N/7
[18:46:20] <Me-me> Pasting without adding spaces in between.
[18:46:29] <digitok> :>
[18:47:07] <Me-me> Look I have my orange and green morality that I stick to, okay? I don't like spammers.
[18:47:22] <digitok> https://regex101.com/r/WuZE8N/8
[18:47:36] <digitok> wait
[18:49:32] <Me-me> I have an idea but you're not going to like it.
[18:49:43] <digitok> correct
[18:49:53] <Me-me> (.{6,}?)\1
[18:49:58] <digitok> :<
[18:50:16] <Me-me> It's... better than ... .*? :(
[18:50:22] <digitok> that was actually my initial idea
[18:50:27] <Me-me> .+? rather
[18:50:34] *** Quits: BlueShark (sid10311@user/blueshark) ()
[18:50:35] <digitok> it is that, yes
[18:50:52] <Me-me> https://regex101.com/r/WuZE8N/9
[18:50:55] *** Joins: BlueShark (sid10311@user/blueshark)
[18:51:06] <digitok> hehe
[18:51:36] <digitok> i mean, it is better
[18:51:48] <Me-me> But is it good enough, is the question.
[18:51:54] *** Riviera_ is now known as Riviera
[18:52:13] <Me-me> 8000 steps is a lot of steps on a relatively small string.
[18:52:35] <Me-me> Forget it, I guess unspaced profanity will just have to get through.
[18:53:33] <digitok> it's difficult indeed
[18:54:01] <digitok> even using ., he could just generate random separators
[18:54:03] <digitok> :D
[18:54:18] <Me-me> Removing spaces is one thing - I don't want to give him too much credit.
[18:54:19] <Timvde> Me-me: I don't think it can be a lot more efficient, the problem is inherently hard
[18:54:23] <Me-me> proc: I assume there's already an actual profanity filter that he's avoiding?
[18:54:31] <proc> there are three designed just for him lol
[18:54:35] <digitok> lmao
[18:54:41] <Me-me> Hmm.
[18:54:41] <proc> i think i asked for help on an earlier version a couple months ago here
[18:55:44] <digitok> it'll be extremely difficult to come up with something that can't be broken
[18:55:53] <Me-me> Yeah, I think barring extreme inefficiency or edge cases, your best bet is some sort of learning algorithm designed to weight the likelihood an edit is made with this sort of intent in mind.
[18:56:01] <digitok> haha
[18:56:06] <Me-me> Not joking.
[18:56:09] <digitok> 07Timvde, can do that
[18:56:11] <digitok> 07Timvde, can do that
[18:56:13] <digitok> 07Timvde, can do that
[18:56:14] <digitok> wtf
[18:56:18] <digitok> sorry, ignore me
[18:56:23] <Me-me> /ignore digitok
[18:56:26] <digitok> :(
[18:57:19] <proc> one is a disallow filter on first hit, another is throttling (3+ hits in 24 hrs), and the third is logging. third has too many false positives, but it's just to help find where they are
[18:57:19] <proc> issue with the disallow one is that obviously he knows more hindi abuse than i do, so he comes up with new words or ways of phrasing. throttling has been helpful to slow him down though, because there's rarely a legitimate reason to use these words more than twice in 24hrs
[18:57:58] <Me-me> If he's targeting specific pages, maybe even just lock them down until he gets bored and masturbates himself into a coma or something.
[18:58:05] <digitok> haha
[18:58:30] <Me-me> But of course you didn't come here for moderation advice.
[18:58:40] <digitok> just enable manual moderation of all posts :p
[18:58:40] <proc> issue is there are thousands of indian actors/actresses/etc
[18:58:47] <proc> ^ they should tbh
[18:58:51] <proc> if it were up to me...
[18:59:04] <Me-me> See, this is why I hate spammers.
[18:59:11] <digitok> 07Me-me, would allow you to pay him to do it
[18:59:13] <Me-me> I don't want Wikipedia to be account-only mod-only.
[18:59:25] <Me-me> But spammers nearly necessitate it.
[18:59:48] <Me-me> proc: They're all in categories though right? You could modlock all the ones in the categories he's after, surely?
[19:01:02] <digitok> i'd imagine it would be a lot of work to moderate all posts on wikipedia
[19:01:32] <Me-me> Indeed. Which means stagnation, nothing gets done. It becomes insular and useless. I don't hate what spammers do, I hate what they prevent.
[19:01:48] <proc> it's not technically possible to lock categories, although the filter could look for text resembling the [[Category:%NAME%]] code, but two problems:
[19:01:48] <proc> 1. the category structure is such a mess that the %NAME% across indian people by occupation categories follow no logical structure to filter
[19:01:48] <proc> 2. consensus would never be happy with locking a whole category from editing
[19:02:11] <proc> people would much rather spend time reverting him around the clock than disable editing to thousands of pages
[19:02:33] <proc> which is fair enough; a lot of legitimate indian editors edit via IPs
[19:02:34] <Me-me> Sheesh.
[19:02:52] <Me-me> Not sheesh to the moderators
[19:02:55] <Me-me> sheesh to this spammer.
[19:03:40] <proc> is https://regex101.com/r/WuZE8N/6 (without /g) is the best variety of 'repeated phrase' filtering possible?
[19:03:59] <Me-me> I believe so.
[19:05:31] *** Joins: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net)
[19:06:33] <Me-me> Maybe see if you can find a hindi linguist. Maybe there's a pattern to profanity (even words he hasn't used yet) that we don't know - if there is, we can make a better regex for it.
[19:06:55] <Me-me> I don't know why I'm talking like you have a huge budget to spend :P best of luck fighting the forces of darkness!
[19:07:47] *** Quits: ahmedelg1 (~ahmedelga@2a02-a446-d88a-1-f469-689b-e9f7-9e94.fixed6.kpn.net) (Ping timeout: 240 seconds)
[19:08:21] <proc> heh, I'm just a volunteer too, so my budget is exactly £0 :D -- just hate spammers tbh, so this is my contribution
[19:08:29] <Me-me> Fight on!
[19:08:37] <Me-me> Wish I could help more.
[19:10:49] <proc> ty both of you! (& digitok). i'll track the results and see what hits. i think a possible problem might be that the pattern might match the lines with changes, but the repeated text could have already been in the page potentially (hence a false positive). not sure if it'll be a problem in practice, but if it is then I *think* the only way around it is to run in /g and check if there's more matches, but that might slow it down
[19:11:14] <Me-me> I mean all it's doing is flagging for moderation, right?
[19:11:42] <Me-me> We can also set a minimum number of words to be repeating before it flags, if that helps.
[19:11:55] <proc> this one will just log, if there are phrases that can be combined with it to narrow it down without false positives then perhaps it can be set to throttle
[19:12:03] <proc> really depends on what kinda hits it throws out
[19:12:13] <Me-me> Let us know if it needs any tweaks.
[19:12:57] <digitok> yea it's still pretty easy to get around
[19:13:09] <digitok> but as mentioned it's a difficult thing to solve
[19:13:20] <Me-me> So you know... don't tell the spammer what the workarounds are :P
[19:13:29] <proc> well, hopefully they're not in this channel :D
[19:13:35] <digitok> :D
[19:13:39] <Me-me> I'll keep an eye out for indian incels.
[19:14:31] <digitok> maybe the solution is to revert to dial-up internet with static ips and ban vpn companies
[19:14:37] <digitok> yea, we'll do that
[19:17:11] <proc> english wikipedia has really good VPN banning. it started banning a lot of residential proxies now too.
[19:17:11] <proc> i'm not familiar with how indian networks work but i'm told IP allocation in india is pretty unstable (like just browse around for 30 mins and your IP changes), so it's possible he's not even trying *that* hard to change his IPs
[19:17:54] <digitok> yea
[19:18:02] <proc> he's often on different ISPs though, and i doubt he's buying a few sim cards per day, so i'm not definitively sure what's going on tbh
[19:18:43] <digitok> he could be the crown prince of india
[19:19:10] <proc> ah, speak of the devil: https://en.wikipedia.org/w/index.php?title=Nushrratt_Bharuccha&diff=1040435600&oldid=1039596490&diffmode=source
[19:19:13] <proc> the filter works :D
[19:19:17] <proc> (as in it tagged it)
[19:19:52] <Me-me> Active fellow, huh.
[19:20:42] <Me-me> Remember we can adjust tolerances in either direction. And let's hope it takes him a while before trying a non-spaced spam.
[19:21:42] <digitok> i wonder if google's working on an "are you a spammer" captcha
[19:21:47] <digitok> they got the robots
[19:22:15] <Me-me> I'm sure they're working on it. Doesn't mean they've gotten anywhere that wasn't fully functional as of ten years ago.
[19:23:19] *** Quits: celphi (uid97751@user/celphi) ()
[19:23:29] <proc> well, they're quite persistent; to bypass you can use https://2captcha.com. basically you send a bunch of recaptcha tokens to this service, humans solve the captcha for like $0.00001, and send the challenge answer back
[19:23:36] *** Joins: celphi (sid97751@user/celphi)
[19:23:38] <proc> and you can use the challenge answer for like 10-15 mins i think?
[19:24:13] <digitok> haha
[19:24:49] <digitok> there you go Me-me, you like solving captchas
[19:25:08] <Me-me> Just because I spent a weekend at Solving Captchas Camp.
[19:25:20] <digitok> :D
[19:27:31] <Me-me> I only solve captchas as a hobby, I don't want to turn it into a career.
[19:27:42] <Me-me> Alright bit's over.
[19:30:19] *** Quits: Bayes (~Bayes@user/bayes) (Quit: Connection closed)
[20:05:34] *** Joins: mutandis (~mut@c-73-129-211-144.hsd1.va.comcast.net)
[20:13:35] *** Joins: ircuser-1 (~Johnny@71.63.241.168)
[20:15:40] *** Quits: subie (~subie@2601:4c0:4080:bc0:21e1:ab1b:5c16:8966) (Ping timeout: 240 seconds)
[20:15:47] *** Quits: farn (~farn@2a03:4000:7:3cd:d4ab:85ff:feeb:f505) (Ping timeout: 240 seconds)
[20:17:05] *** Joins: farn (~farn@2a03:4000:7:3cd:d4ab:85ff:feeb:f505)
[20:18:37] *** Joins: subie (~subie@2601:4c0:4080:bc0:8d2a:aff3:3c16:df7)
[20:22:51] *** Joins: re101-duck-63 (~re101-duc@72-21-196-65.amazon.com)
[20:24:01] <re101-duck-63> I am not familiar with regex strings and need help creating what is probably a pretty simple one: I need to make sure there is always a space before a particular string. The easiest way would probably be to add a space before all instances of the string.
[20:25:00] <re101-duck-63> !rehelp
[20:25:00] <perlbot> Please share a https://regex101.com/ link containing your regex and sample data, stay as long as possible, and we'll do our best to assist you ASAP.
[20:25:17] *** Quits: re101-duck-63 (~re101-duc@72-21-196-65.amazon.com) (Client Quit)
[20:25:27] *** Quits: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net) (Ping timeout: 240 seconds)
[20:28:33] <VectorX> too much work
[20:36:21] *** Quits: Lope (~lope@user/lope) (Ping timeout: 250 seconds)
[20:42:25] *** Quits: d1cor (~diego@179.63.242.114) (Ping timeout: 250 seconds)
[20:51:25] *** Joins: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net)
[20:55:47] *** Quits: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net) (Ping timeout: 240 seconds)
[21:01:57] *** Joins: travisghansen (~travisgha@192.74.130.86)
[21:12:39] *** Quits: JohnDoe2 (~johndoe2@2001:470:1f07:89::dead:bead) (Quit: bye)
[21:16:13] *** Quits: adherzog (uid387168@id-387168.tooting.irccloud.com) (Quit: Connection closed for inactivity)
[21:23:28] *** Quits: shailangsa (~shailangs@host86-185-102-120.range86-185.btcentralplus.com) (Ping timeout: 252 seconds)
[21:34:13] *** Joins: Lope (~lope@user/lope)
[21:44:49] *** Quits: Lope (~lope@user/lope) (Ping timeout: 250 seconds)
[21:48:08] *** Joins: JohnDoe2 (~johndoe2@2001:470:1f07:89::dead:bead)
[21:48:08] *** ChanServ sets mode: +v JohnDoe2
[21:55:24] *** Joins: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net)
[21:59:40] *** Quits: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net) (Ping timeout: 240 seconds)
[21:59:46] *** Quits: phenom (~primus@user/phenom) (Ping timeout: 268 seconds)
[22:00:42] <digitok> v
[22:46:38] *** Joins: re101-shrimp-33 (~re101-shr@2601:204:cc00:51:2083:f409:c206:d497)
[22:46:39] *** Quits: re101-shrimp-33 (~re101-shr@2601:204:cc00:51:2083:f409:c206:d497) (Client Quit)
[22:47:22] <JohnDoe2> b
[22:56:55] *** Quits: maroloccio (~marolocci@37.100.40.252) (Quit: WeeChat 3.0)
[23:03:36] *** Joins: include_ (~include_@45.131.193.42)
[23:03:50] *** Quits: include_ (~include_@45.131.193.42) (Client Quit)
[23:04:59] *** Joins: insilications (~insilicat@45.131.193.42)
[23:07:47] *** Quits: insilications (~insilicat@45.131.193.42) (Client Quit)
[23:08:21] *** Joins: insilications (~insilicat@45.131.193.42)
[23:10:29] <insilications> what does the mangenta I-beam at the end of the syntax highlighting of a certain match/group in regex101.com means?
[23:11:52] <VectorX> insilications can you provide a screenshot
[23:13:52] <insilications> VectorX https://i.imgur.com/dkvxT8A.png  https://regex101.com/r/QuYaI8/1
[23:14:35] *** Joins: re101-coati-20 (~re101-coa@dc2soezppxy001-c.vanguard.com)
[23:14:41] <re101-coati-20> !rehelp
[23:14:42] <perlbot> Please share a https://regex101.com/ link containing your regex and sample data, stay as long as possible, and we'll do our best to assist you ASAP.
[23:14:44] <re101-coati-20> https://regex101.com/r/m2SKVZ/1
[23:19:58] <insilications> re101-coati-20 try this https://regex101.com/r/TTtt8b/1
[23:20:28] <VectorX> insilications might be better if you read this, https://www.regular-expressions.info/zerolength.html
[23:20:49] <insilications> re101-coati-20 if you want to match only when there are exactly last 6 digits: (\d{6,6})$
[23:21:02] <insilications> VectorX thanks
[23:21:16] <VectorX> insilications so instead of (.*)$ you can use (.+)$  if that is desirable
[23:24:52] <VectorX> maybe make it optional at that point (.+)?$   ,though I didnt actually go thru your regex, there could be other issues
[23:25:37] <re101-coati-20> VectorX insilications instead of a digit, if I want to check for digit or charecter?
[23:26:26] *** Joins: ahmedelgabri (~ahmedelga@2a02-a446-d88a-1-6060-ed82-7bdd-40f9.fixed6.kpn.net)
[23:26:32] <insilications> VectorX nice one. I just came up with exactly that solution: (.+)?$
[23:26:38] <insilications> Perfect
[23:27:22] <re101-coati-20> could you help me with full expression
[23:27:49] <VectorX> re101-coati-20 what exactly are you trying to do, what is the problem you are trying to solve?
[23:31:35] <insilications> re101-coati-20 try this: (\d{1,6}|[a-zA-Z]{1,6})$
[23:34:49] <insilications> VectorX thanks for that link. backtracking and zero length matches related problems do show up on more complex regexes
[23:46:22] *** Joins: Lope (~lope@user/lope)
[23:59:41] *** Joins: maroloccio (~marolocci@37.100.40.252)
