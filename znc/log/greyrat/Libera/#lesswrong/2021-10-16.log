[00:01:30] <feepbot> <gwern> 'Of course, reality catches up with us all. In recent years, Brackenbury has come around to realizing that his Wizard persona isn’t enough to ward off parking tickets, old age, and the end of his contract with the city that’s employed him for the past 23 years. A Christchurch council spokesperson told the Guardian that it wasn’t anything personal—it was just that,
[00:01:30] <feepbot> well, wizards weren’t that cool anymore, and weren’t a part of the “vibrant, diverse, modern city” image that Christchurch wanted to promote to tourists and residents. Brackenbury told the Guardian that he’d still be keeping up his usual wizardry over in the Christchurch Arts Centre for anyone that came by, even if he wasn’t on the city’s payroll anymore. Canceling
[00:01:30] <feepbot> the contract, he said, “implies that I am boring and old, but there is nobody else anything like me in Christchurch.”' https://gizmodo.com/new-zealand-lays-off-its-official-city-wizard-after-20-1847871468
[00:01:35] <feepbot> New Zealand Fires Its Official City Wizard After 23 Years (A council spokesperson said it wasn’t personal—it was just that wizards aren’t that cool anymore.)
[00:06:22] <gwern> https://twitter.com/TheStalwart/status/1449047210251989001
[00:06:23] <|dbotdan> Joe Weisenthal (@TheStalwart, 2021-10-15 16:19): ‘When you see the price of tungsten hitting new highs like this, it means large holders are cashing out—ahead of the crash, which they all know is coming.’
[00:07:20] <Betawolf> wasn't everyone buying nice tungsten balls?
[00:07:46] <gwern> yes, taking their profits for tungsten balls
[00:08:05] <gwern> then they'll have us by the tungsten balls when we need to dispose of waste from the crash programs to avoid freezing this winter
[00:08:14] <gwern> the perfect short(hair) squeeze
[00:08:26] <kuudes> is this a plot by the snail?
[00:13:27] <feepbot> <gwern> https://www.barrons.com/articles/the-workers-wont-be-coming-back-covid-or-not-here-are-theories-on-where-they-went-51634290204
[00:13:28] <feepbot> The Workers Won’t Be Coming Back, Covid or Not. Here Are Theories on Where They Went. | Barron's (The pandemic has changed attitudes and priorities around work, and there are signs that many have moved on to an alternate economy, writes Lisa Beilfuss. )
[00:18:28] <feepbot> <gwern> https://cims.nyu.edu/~sbowman/bowman2021hype.pdf
[00:21:35] <Obormot\Arcturus> This "alternate economy" stuff is making our time sound more and more cyberpunk
[00:22:38] <kuudes> is it to economy what alternate medicine and alternate news are to medicine and news?
[00:25:49] <kiboneu> good m0rning
[00:30:50] <feepbot> <gwern> 'That no reporter noticed his absence during a supply chain crisis. Is not a good look for either reporters or the Secretary' https://twitter.com/KaminskiMK/status/1448802549528776707
[00:30:51] <|dbotdan> Matthew Kaminski (@KaminskiMK, 2021-10-15 00:06): ‘They didn’t previously announce it, but Buttigieg’s office told West Wing Playbook that the secretary has actually been on paid leave since mid-August to spend time with his husband, Chasten, and their two newborn babies. |  https://politi.co/3DIzq5W ’
[00:31:25] <saturn2> "There are good reasons to believe many workers aren’t coming back. In addition to lasting Covid concerns, economists and strategists point to early retirements and a reassessment of “work” by millions of Americans. A record number of businesses have been launched since the pandemic started, and Luke Tilley and Tony Roth, chief economist and chief investment officer, respectively, at Wilmington
[00:31:27] <saturn2> Trust, note that a recent Harris Poll showed 55% of respondents said they know someone who has quit a job because “you only live once.”" to save you a click
[00:31:33] <saturn2> yolo
[00:33:16] <kiboneu> i mean unemployment can be a temporary state of existence
[00:33:43] <adiabatic> I have more than a few friends who've made it into a lifestyle
[00:34:44] <adiabatic> see "resurgence in 2021": https://knowyourmeme.com/memes/wage-cage
[00:34:45] <Robomot> Wage Cage | Know Your Meme (Wage Cage, also known as Wagecage and Wagie Cagie, is a slang term used to describe an office or cubicle, though it is sometimes more broadly defined to encompass an occupation or the act of working itself. Often, memes represent wage cages with artistic representations such as the famous "Amazon wage cage" and reimaginations of the design, like the "Wage Cage 9000." …)
[00:35:35] *** Joins: galambo (galambo@user/galambo)
[00:35:40] <kiboneu> we live in a society
[00:35:44] <kiboneu> is all i have to say
[00:36:09] <kiboneu> without falling into a pit / rabbit hole of dark thinking
[00:37:40] <adiabatic> I have no idea how they're gonna be OK when they're 60 and their parents are long retired
[00:38:11] <gwern> vote Dem?
[00:38:11] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 265 seconds)
[00:38:28] <adiabatic> well, the guy I'm thinking of does that anyway
[00:38:32] <kiboneu> people tend to take their comforts and life dependent infrastructure for granted
[00:38:39] <kiboneu> people will forget how to do anything
[00:38:52] <kiboneu> how to catch errors let alone communicate and understand them
[00:39:06] <kiboneu> and we'll be run over by our own bulldosers
[00:39:07] <gwern> adiabatic: the fool! then the democratic party has less incentive to actually implement anything!
[00:39:21] <kiboneu> bulldozers
[00:39:51] <adiabatic> he used to be sensible, but some dark-triad types got to him in the past couple of years
[00:40:13] <adiabatic> well, sensible except for the long-term underemployed thing
[00:40:15] <kiboneu> people will just not do any organizational thing because they've lost trust in the whole system, because they haven't read up on the people they've voted and got all of their info from tv ads
[00:40:53] <kiboneu> it will be like idiocracy but not funny
[00:41:10] <kiboneu> not that the movie was that funny to begin with
[00:42:21] <gwern> it wasn't, but the opening sure hit hard
[00:42:38] <gwern> the 'brawndo' bits were genuinely good
[00:46:26] <rsaarelm> I kept having no idea at my day job whether it's normal to be miserable with the job all the time, despite changing workplaces, or if there's something wrong with how I relate to work, then covid and remote hit and my ability to do anything for the day job at home basically dropped to zero while as far as I could tell most other people I know kept chugging on somehow. Then I quit my job.
[00:47:35] <rsaarelm> So I dunno, basically long-term dysfunction but just plodding along because inertia, and then there's a shock and it just crashes down and good riddance.
[00:47:47] <kuudes> oh
[00:48:07] <kuudes> yeah, that sounds like depression
[00:48:18] <kuudes> have you managed to get to a doctor? it is useful for that
[00:48:33] <rsaarelm> If it was depression I'd expect to stay unhappy after I quit the job.
[00:48:44] <kuudes> are you now happy?
[00:48:48] <rsaarelm> Yeah, pretty much.
[00:48:50] <kuudes> ah, nice
[00:48:53] <kuudes> ok, yeah
[00:49:00] <kuudes> money issues are ok?
[00:49:15] <rsaarelm> Was a bit zoned out for a month or two after the work stuff ended, have been fine since.
[00:49:39] <kuudes> if you have no hard money issues, go for it! there is nothing special in work
[00:49:43] <rsaarelm> Trying to do a PovertyFIRE with my savings.
[00:49:49] <saturn2> congrats on being happy
[00:50:31] <kuudes> indeed!
[00:53:41] <rsaarelm> There seems to be some mess of ideas about people in professional jobs being supposed to find some degree of value and self-actualization in the job and not just do it for the paycheck, but I never really got a good handle of that.
[00:54:03] <rsaarelm> And obviously there's a lot of just doing it for the paycheck mixed in.
[00:55:51] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[00:56:08] <galambo> I agree it is dangerous to define your self worth with your job
[00:57:02] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 265 seconds)
[00:57:11] *** Lord_of_Life_ is now known as Lord_of_Life
[00:58:10] <saturn2> it seems odd to get satisfaction out of spending all day doing things you don't want to be doing. but if you don't, you're "depressed"
[00:59:02] <gwern> retirement wrecks a lot of people
[00:59:40] <gwern> the lack of any work, isolation, substituion of junk entertainment...
[01:00:06] <gwern> people doing FIRE foolishly may find they're like the old man who retires, and then can't think of anything better to do than sit down and turn on fox
[01:00:40] <galambo> gwern, I kind of agree. I remember reading research that people who retire early tend to have faster cognitive decline. I am trying to shift to working part time
[01:01:01] <gwern> certainly seemed to happen to my grandad. put on weight, etc. whole spiral downwards
[01:01:14] <rsaarelm> I guess I've kept defecting from whatever the proposal the day job thing was from the start and treating my own coding stuff as the actual thing I'm doing.
[01:02:13] <rsaarelm> Like if it was something like "act as if this was the only acceptable option for you and then you'll end up happy with this thing"
[01:03:48] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 265 seconds)
[01:06:39] <rsaarelm> Nobody seems to be very happy working with programming and then at some point the cynical jokes stopped being jokes. I don't know what it's like in other professional fields.
[01:07:44] <rsaarelm> Also programming has the thing where your career path doesn't really have a legible second half.
[01:12:45] <feepbot> <gwern> https://maximumtruth.substack.com/p/deep-dive-does-covid-cause-significant?r=u0rd
[01:12:46] <feepbot> DEEP DIVE: Does Covid Cause Significant Brain Harm? - by Maxim Lott - Maximum Truth ("Covid and brain tissue loss confirmed,” I read on the excellent blog Marginal Revolution. The link goes to this fascinating UK study, which scanned tens of thousands of brains before Covid, and then scanned many [snip])
[01:14:44] <rsaarelm> Rao's "people stopped solving for money" stuck with me. https://threader.app/thread/1435843468014747652
[01:14:49] <Robomot> A Thread from @vgr: "Never learning to solve for money is one kind of tragedy. Never being able to stop solving for money is a [...]" (Never learning to solve for money is one kind of tragedy. Never being able to stop solving for money is a different kind of tragedy. It’s not about when you have enough. It’s about when you’ve had enough.)
[01:19:49] <feepbot> <gwern> https://www.cato.org/policy-analysis/simon-abundance-index-new-way-measure-availability-resources# https://www.humanprogress.org/the-simon-abundance-index-2020/
[01:24:49] <feepbot> <gwern> https://www.economist.com/united-states/2021/09/11/being-demonised-has-not-stopped-american-muslims-impressive-rise
[01:24:50] <feepbot> Being demonised has not stopped American Muslims’ impressive rise | The Economist (Anti-Muslim sentiment has become entrenched among Republicans)
[01:29:17] <pie__> gwern: is groq a significant company?
[01:29:19] <Obormot\Arcturus> https://www.greaterwrong.com/posts/XPwEptSSFRCnfHqFk/zoe-curzi-s-experience-with-leverage-research#comment-6BAiH7qDvg8LtPEmx
[01:29:22] <Robomot> Zoe Curzi's Experience with Leverage Research - LessWrong 2.0 viewer [mingyuan 15 Oct 2021 18:44 UTC 39 pointsParentMy contact with Leverage over the years was fairly insignificant, which is part of why I don’t feel like it’s right for me to participate in this discussion …]
[01:30:02] <Obormot\Arcturus> Apparently these people were absolutely, paranoically obsessed with managing their reputation
[01:30:19] <Obormot\Arcturus> To the point where that's what caused many people to think poorly of them (unsurprisingly)
[01:30:37] <gwern> pie__: yes, you can reject the null of their non-existence (p<0.05)
[01:30:37] <pie__> heh https://finance.yahoo.com/news/groq-fuels-talent-growth-beyond-100000597.html In-cute-el
[01:30:39] <Robomot> Groq Fuels Talent Growth Beyond Expectations (Groq Inc., a leading innovator in compute accelerators for artificial intelligence (AI), machine learning, and high-performance computing, today announced almost 300% team growth in the last year across North America, supporting rapidly expanding customer demand for their industry-leading architecture.)
[01:30:50] <catern> is there a form of representative democracy where representatives have the power to control exactly the amount of votes that were cast for them/delegated to them? possibly with a minimum number of votes for a representative to enter the parliament/deliberative body
[01:31:31] <pie__> gwern: more specifically I'm looking at a hiring event list and they may be present and im wondering how tryhard i should be
[01:31:42] <catern> (rather than something region-based I guess)
[01:31:43] <gwern> .note shawwwn '"It is harder to get into Groq than it is to get into Harvard University. We are seeking and finding talent across the United States and all over the world. While big companies are seeing employees leave as part of the great resignation, we're hiring talent with a geo-agnostic approach that is proving to work extremely well" said Jonathan Ross, CEO of Groq.'
[01:31:48] <pie__> or if i should discount as not interesting
[01:31:57] <gwern> pie__: you should ask shawwn
[01:32:08] <pie__> ...great resignation? that sounds great
[01:32:12] <Obormot\Arcturus> What I don't understand is comments like this one https://www.greaterwrong.com/posts/XPwEptSSFRCnfHqFk/zoe-curzi-s-experience-with-leverage-research#comment-FPmrQaPmbqGSQJsHb
[01:32:16] <Robomot> Zoe Curzi's Experience with Leverage Research - LessWrong 2.0 viewer [Ruby 15 Oct 2021 15:51 UTC 16 pointsParentIMO, is that we should tolerate some impropriety for the greater good …]
[01:32:44] <Obormot\Arcturus> How is it not blatantly, 100% obvious to everyone reading any of this stuff that this Geoff Anders guy cannot be trusted anywhere near the leadership of any organization ever again for any reason
[01:33:02] <Obormot\Arcturus> "Reminder that Leverage 1.0 is defunct and it seems very unlikely that the same things are going on with Leverage 2.0 (remote team, focus on science history rather than psychology, 4 people)." ... NO!!! Wrong!!
[01:33:40] <Obormot\Arcturus> The correct attitude is "Leverage 2.0, you say, and is Geoff Anders still involved in running this 'Leverage 2.0' in any capacity? He is?? SHUNNED"
[01:33:46] <pie__> gwern: youre the most in-the-loop person i know WRT AI stuff so I figured I'd ask here for pointers
[01:33:56] <gwern> pie__: and shawwn actually works for them, hence
[01:34:08] <pie__> hm shawwn doesnt seem to be in here? (anymore?)
[01:34:15] <pie__> gwern: oh huh
[01:34:17] <gwern> he's mobile so he bounces in and out
[01:34:21] <pie__> ah i see thanks
[01:34:34] <pie__> well hey, this is certainly a start :)
[01:34:40] <pie__> im very out of the AI loop
[01:35:00] <pie__> what about your personal opinion, if you have one? :P
[01:35:16] <pie__> (pm is fine if you want)
[01:35:20] <pie__> guess i can get a bit of both sides
[01:36:55] <saturn2> did shawwn get into harvard?
[01:38:05] <saturn2> Obormot\Arcturus: i don't know how it wasn't obvious since the very beginning that leverage was extremely sketchy
[01:38:53] <saturn2> but i guess that's why i'm not invited to the cuddle puddles
[01:42:06] <gwern> pie__: they have a weird chip and they seem to be selling a lot and have a lot of money, but (like Cerebras) their chips never surface in my part of the AI world so I have no idea.
[01:45:02] <pie__> noted, thanks
[01:46:08] <gwern> I'm not sure I've *ever* read a paper where they say "btw we trained our model on a groq"
[01:46:29] <gwern> (whereas I've seen like 2 non-cerebras papers about doing stuff on cerebras chips)
[01:46:41] <gwern> yet, clearly someone is using them somewhere
[01:47:53] <pie__> probably the NSA
[01:48:19] <kuudes> sounds reasonable guess
[01:48:37] <pie__> i mean yahoo literally mentioned in-q-tel so idk lol
[01:49:01] <pie__> this makes me think of another high throughput hardware accelerator every time
[01:49:28] <pie__> imagine all the intertubes pussycat pictures you could filter with high power edge compute
[01:50:41] <Obormot\Arcturus> saturn2: Yeah, it's weird. These Bay Aryans seem to *extremely consistently* err on the side of stupidity^W ludicrous levels of quokka-esque trust
[01:51:28] <galambo> https://www.cold-takes.com/olden-the-imaginary-billion-year-old-version-of-me/
[01:51:29] <Robomot> If I were a billion years old (This blog is largely about the topics I'd be most interested in if I were a billion years old.)
[01:52:20] <gwern> the person you criticize today may be the rent-controlled apartment you need to crash at tomorrow?
[01:56:16] <pie__> 300% team growth in a year sounds like a disaster in the making tbhj
[01:57:09] <quanticle> Obormot\Arcturus, gwern: https://voxeu.org/article/enemies-people
[01:57:13] <Robomot> Enemies of the people | VOX, CEPR Policy Portal (‘Enemies of the people’ were the millions of artists, engineers, managers, or professors who were thought to be a threat to the Soviet regime solely for being the educated elite. Along with millions of non-political prisoners, they were forcedly resettled to the Gulag, the system of labour camps across the Soviet Union. …)
[01:57:37] <quanticle> So this paper looks at the long-term economic impacts of the forced resettlement of the Russian intelligentsia by Stalin
[01:58:16] <quanticle> And it finds that there are significant, long-term economic improvements to cities that were situated around gulags that had a higher proportion of "enemies of the people"
[01:58:36] <gwern> must be all the kulturniy they brought with them
[01:58:45] <quanticle> That is literally the argument, yes
[01:59:10] <gwern> but yeah, the paper was making the rounds of twitter a while ago
[01:59:32] <Obormot\Arcturus> Yes, that makes sense
[01:59:45] <Obormot\Arcturus> This happened in czarist times too, famously
[02:00:24] <quanticle> Now, I'm not suggesting that we do this, BUT if some hypothetical dictator would take all the programmers from San Francisco and Seattle and forcibly resettle them into labor camps in North Dakota, Wyoming, Kansas, etc, it would 1) solve the economic collapse of the Heartland, 2) reduce West Coast housing prices and 3) cause a pause in the further development of web standards
[02:00:32] <quanticle> I'm not seeing a lot of downsides
[02:01:22] <Obormot\Arcturus> I like it
[02:01:30] <kuudes> lets do that?
[02:01:38] <quanticle> Maybe we really do need fifty Stalins
[02:01:44] <kuudes> someone call biden?
[02:02:40] <namespace> quanticle: "I know that after my death a pile of rubbish will be heaped on my grave, but the wind of History will sooner or later sweep it away without mercy." - Stalin
[02:04:30] <quanticle> More seriously, the one big critique I have of this paper is that it jumps straight from observing that towns situated next to the sites of camps with a higher proportion of "enemies of the people" have higher wages and profits per employee straight to concluding, "Yes, this must be because of all the valuable human capital formed by the greater educational achievements of the intelligentsia."
[02:04:32] <quanticle> Meanwhile, I'm over here thinking, "Yep, one more entry in the 'everything is heritable' archive."
[02:06:33] <quanticle> namespace: Indeed
[02:06:53] <namespace> Based, tbh.
[02:07:05] <kuudes> https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2784918
[02:07:07] <Robomot> Short-term and Long-term Rates of Postacute Sequelae of SARS-CoV-2 Infection: A Systematic Review | Infectious Diseases | JAMA Network Open | JAMA Network (This systematic review estimates organ system–specific frequency and evolution of postacute sequelae of COVID-19 infection.)
[02:08:38] <gwern> quanticle: indeed, but that's true of a lot of intergenerational transmission or persistency papers. they are fundamentally 'unidentified' as far as nature vs nurture goes. like that paper about the american slaveholders' offsprings doing well post-civil-war & expropriation of all slaves - the paper author (and I argued with her on twitter too) interprets this as just showing the power of...
[02:08:44] <gwern> ...'credit' and families
[02:09:58] <gwern> or you see attempts to interpret old elites re-rising in communist china as merely showing the sheer power of family connections. sure, many of these ex-elites were so expropriated that they were literally sitting on a bare floor because every last stick of furniture had been taken away to be given to the cadres, but the success of their offspring merely *proves* how powerful culture is!
[02:10:58] <quanticle> Right. I'm just wondering whether these people actually didn't consider heritability at all, or whether they did consider it, and then thought, "No, we can't say that"
[02:12:27] <Obormot\Arcturus> Didn't consider would be my guess
[02:13:01] <quanticle> I'm still struck by the fact that companies which were situated around former labor camps where the share of "enemies of the people" was 47% had 65% higher profits per employee as compared to firms which were situated around the sites of labor camps where the share of "enemies of the people" was 19% (1 SD less). 65%! That's not a small difference!
[02:13:28] <gwern> it's all of them combined. many are ideologically devoted to blankslatism. others just take the polluted evidence at face-value and think heritability has been debunked. others are too cowed to want to bring up the topic at all. and many will just shrug and say that the available data just doesn't tell you and they are merely analyzing as best as they can
[02:13:43] <quanticle> Sad
[02:14:15] <gwern> like in this case. how *would* you distinguish? for a genetically-informative design, you need like, adoptions or IVF or twins, or extensive pedigrees, or genotypes
[02:15:01] <quanticle> At the very least, you'd need marriage records to see what the level if intermarriage was between the labor camp population and the townie population.
[02:15:05] <gwern> tends to be fairly unusual to have the right kind of data. (in large part, a chicken and egg proble. because genetics is seen as unimportant, collecting such data is then not worth the cost)
[02:15:25] <gwern> yeah, but can you imagine how hard getting large sets of marriage records for many gulag townsfrom the 1950s would be?
[02:15:31] <gwern> and that's still shit data
[02:16:15] <quanticle> Yeah, well, the managed to scrape the data on the crimes these Gulag prisoners were accused of from the state archives.
[02:16:18] <quanticle> *they
[02:16:32] <quanticle> I bet the marriage data is in there too.
[02:16:33] <gwern> that's probably a lot easier. that's their death sentence
[02:16:42] <gwern> who cares what happens to them after?
[02:16:51] <quanticle> Okay, fair enough.
[02:16:56] <gwern> the mountains are tall, and the czar far away
[02:17:12] <quanticle> After they've been sentenced, they're non-persons, and the state doesn't keep track of them any more.
[02:17:14] <gwern> it's always a lot easier to get formal criminal records, than to figure out what happens to someone afterwards
[02:17:40] <gwern> you see this even in places like america. a journalist wants to look up someone who was prosecuted, a few decades later. it is... not easy, often
[02:18:17] <gwern> soviet russia, in the middle of the purges, out in the actual gulag?
[02:23:18] <feepbot> <gwern> 'A painting that British street artist Banksy purposely shredded during a previous auction sold Thursday to an anonymous Asian collector for $25.4 million at Sotheby’s in London, setting a new record for the artist at auction. ... Now, the anonymous buyer of that $1.4 million work has had the last laugh—by reselling the ribboned work on Thursday for 18 times as much.
[02:23:18] <feepbot> Sotheby’s only expected it to sell for as much as $8 million, but at least nine bidders in the sale pushed its price even higher, with the director of Sotheby’s private sales in Asia, Nick Wood, fielding the winning telephone bid. “I can’t tell you how nervous I am to drop the gavel on this one,” said auctioneer Oliver Barker in the moment, glancing at the work hanging
[02:23:18] <feepbot> behind him. Nothing followed but applause.' https://www.wsj.com/articles/banksys-shredded-artwork-sells-for-25-4-million-11634234269
[02:23:19] <feepbot> Banksy’s Shredded Artwork Sells for $25.4 Million - WSJ (A painting that British street artist Banksy purposely shredded during a previous auction sold Thursday to an anonymous Asian collector for $25.4 million at Sotheby’s in London, setting a new record for the artist at auction. )
[02:28:18] <feepbot> <gwern> https://www.bloomberg.com/news/articles/2021-10-15/crypto-traders-to-blame-for-surging-sales-of-small-tungsten-cubes if you were wondering about the tungsten jokes
[02:28:19] <feepbot> Crypto Traders to Blame for Surging Sales of Small Tungsten Cubes - Bloomberg (They just like the pleasing feeling of holding a cube)
[02:29:10] <quanticle> >they just like the pleasing feeling of holding a cube
[02:29:12] <quanticle> Literally
[02:29:19] <quanticle> This is the companion cube from Portal, isn't it?
[02:29:46] <quanticle> It also reaffirms my suspicion that they're all autists
[02:32:09] <Obormot\Arcturus> "The tungsten cube will never threaten to crush you, and, in fact, cannot speak."
[02:33:13] <kuudes> unlike tungsten ball?
[02:33:21] <gwern> nevertheless, do not taunt the happy fun tungsten cube. do not feed it after midnight. do not overeducate it beyond its station.
[02:33:37] <gwern> do not allow it to know the taste of human blood.
[02:33:54] <gwern> warranty void if not followed.
[02:35:05] <kuudes> ah, juggernaut was steel, not tungsten https://www.wired.com/1995/07/the-helsinki-killer-ball/
[02:35:07] <Robomot> The Helsinki Killer Ball | WIRED (When Finnish sculptor Markus Copper was a child, he enjoyed playing videogames and watching movies like Blade Runner and Alien. Now, at 26, he’s making his own monsters. Copper’s most terrifying kinetic sculpture is Juggernaut, an enormous steel ball that weighs as much as two cars. It has a motor, motion sensors, a juicy battery, […])
[02:36:12] <gwern> it would have to be. how do you work or afford that much tungsten?
[02:36:40] <quanticle> 90% tungsten alloyed with 10% steel is workable
[02:37:13] <quanticle> gwern: https://twitter.com/paraschopra/status/1290185071605899264 GPT-3 explains memes
[02:37:16] <|dbotdan> Paras Chopra (@paraschopra, 2020-08-03 07:17): ‘Tried GPT-3 to explain some memes. | Used old idioms and their meaning as a prompt’ Images: https://birdsite.xanny.family/pic/media%2FEeeoeaHU8AAvlZB.png%3Fname%3Dorig (description: text; confidence: 0.64)
[02:42:16] <feepbot> <gwern> https://www.espn.com/nfl/story/_/id/19769575/what-do-athletes-do-to-pee-games ...I thought they just went to the bathroom
[02:42:18] <feepbot> What do athletes do when they have to pee during games? (No one can resist nature's call, but for athletes, knowing when to let it flow can be the difference between victory and defeat.)
[02:44:40] <quanticle> I know tennis players take bathroom breaks
[02:44:59] <quanticle> Because I remember one time Novak Djokovic complained that his opponent's bathroom break was taking too long
[02:50:00] <feepbot> <gwern> '"Guys are peeing all over the sideline in every game, into cups, on the ground, in towels, behind the bench, in their pants, everywhere," says Panthers center Ryan Kalil, who covered this topic and others in The Rookie Handbook, co-authored by Gross and Geoff Hangartner. "You'd be surprised, honestly, how many players on the sidelines just go. I guess as athletes we are
[02:50:00] <feepbot> all desensitized by the whole peeing-everywhere thing."'
[02:52:53] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[02:53:24] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[02:53:28] <gwern> Obormot\Arcturus: https://www.gwern.net/docs/www/misc/xwd-16343401602764736.png what's up with the ToC there?
[02:53:32] <Robomot> image/png (2160x3839; 768 KB)
[02:57:37] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[02:58:18] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[02:58:33] <feepbot> <gwern> 'So many runners in the New York City Marathon pee off the sides of the Verrazano-Narrows Bridge at Mile 1 that race veterans can only giggle when they hear first-timers below them on the lower deck talk about the sudden "refreshing" rainstorm they experienced. World-class cyclists still speak in awe of the balletic way former Tour de France racer Dave Zabriskie was able to
[02:58:33] <feepbot> straighten his right leg, stand tall in the saddle and urinate off the side of his bike while whizzing through the French countryside at 30 mph. In 2005, when Zabriskie became just the third American to wear the appropriately named yellow jersey, it earned him the privilege -- according to the Tour's unwritten rules -- to decide when, where and for how long the peloton was allowed
[02:58:34] <feepbot> to pee.'
[02:59:26] <ivan> gwern: your ::before content is messing it up maybe
[03:00:09] <gwern> ivan: yeah, but it's only at some specific widths, and it looks like the 'columns' wrapper gone wrong... so CSS subtlety beyond my ken
[03:00:52] <ivan> gwern: can you ::before without a width on it?
[03:00:57] <ivan> the 111px
[03:02:21] <ivan> yeah that's some pretty strange stuff
[03:02:47] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[03:03:19] <gwern> uh, I'm not sure what you mean by before. if I select that <li> in the inspector when it's weird, the ff devtools says it has one pseudo-element on it, with a content:none; if I toggle that, it just hides/unhides the popup underlining, but doesn't affect the stretching
[03:04:07] <gwern> (or hm, that's just the <a> I think it might be)
[03:04:17] <ivan> oh the column-count: 2 is doing it
[03:04:28] <ivan> chrome decides to put your text into two columns at that width
[03:05:06] <ivan> @media only screen and (max-width: 900px)
[03:05:11] <gwern> hm, oh wait it is the column: 2
[03:05:24] <gwern> it's firefox as well
[03:06:39] * Obormot\Gaia looks
[03:07:30] <Obormot\Arcturus> gwern: You're referring to the invisible text in 2.1, or what
[03:07:44] <gwern> Obormot\Arcturus: how it's stret      ched out
[03:07:49] * ivan reads https://www.gwern.net/Startup-ideas 
[03:07:50] <Robomot> Startup Ideas · Gwern.net (Proposals for new technologies, businesses, startups, satirical or serious.)
[03:07:52] <ivan> > account/​​name reservation: registers your favorite username on the top 10,000 websites so no one can steal it from you.
[03:07:52] <ivan> that exists
[03:07:54] <gwern> https://www.gwern.net/docs/www/misc/xwd-16343410342765842.png I think this is how it's supposed to look
[03:07:55] <Robomot> image/png (1130x1102; 165 KB)
[03:08:08] <Obormot\Arcturus> Oh huh
[03:08:25] <gwern> ivan: I think you've said that but it actually only registeres on like a few dozen/hundred because they aren't allowed to automate it and need humans manually creating it
[03:09:15] <gwern> so on /Changelog with a lot of small section headers, it looks fine, and better than 1 column. but on /Screwfly a long section header and generally few sections screws it up, and it'd be better to be 1-column...
[03:09:17] <Obormot\Arcturus> Yeah it has nothing to do with ::before
[03:09:24] <Obormot\Arcturus> It's just because of columns
[03:09:45] *** Joins: topdownjimmy (~topdownji@user/topdownjimmy)
[03:10:04] <Obormot\Arcturus> There's a missing break-inside property somewhere but I'm about to head out so I can't fix it right now
[03:10:07] <Obormot\Arcturus> When I come back I will
[03:10:15] <gwern> ok
[03:15:16] <feepbot> <gwern> 'Boxing's golden rule is clear: Never put the gloves on early before a big fight. Once they're secure and the tape is initialed by a boxing commission official, they can't come off. After that, if a fighter is overcome by the combination of prefight hydration and jitters, his entourage has to play a high-stakes game of "not it." Moments before he was supposed to be in the
[03:15:16] <feepbot> ring, Toney turned to Roach with a look on his face every trainer dreads...Roach figured the incident was mercifully over. Heading to the ring, though, Toney blurted out, "Oh, Fred, that was so good; you were so gentle."'
[03:19:04] <quanticle> Yeah, I read that and I lol'd
[03:22:05] <gwern> where are the slashficcers
[03:27:05] <feepbot> <gwern> https://danluu.com/productivity-velocity/
[03:27:05] <feepbot> Some reasons to work on productivity and velocity
[03:32:05] <feepbot> <gwern> https://deadspin.com/ultrarunner-courtney-dauwalter-takes-on-the-worlds-most-1830136537
[03:32:06] <feepbot> Courtney Dauwalter Takes On Big's Backyard Ultra (Gary Cantrell clanged a bell at 6:40 a.m. on Saturday, Oct. 20, signaling 70 runners to jog off into the woods on his farm in Tennessee. They had an hour to complete a 4.1667-mile loop trail. Easy. Most of the group finished with 15 minutes to spare [snip])
[03:37:06] <feepbot> <gwern> 'Then I would scan the website for the most breaking news, and check my email and Slack for any notifications from editors and reporters who were filing important stories. For the next four hours I’d scan incoming headlines and make split-second decisions about how quickly or aggressively to promote an article based on how breaking the story was and how likely it was to
[03:37:06] <feepbot> attract readers. This was the summer of 2015, and Donald Trump was beginning to make news more frequently for his racist and inflammatory comments as an unlikely Presidential candidate. And the paper was starting to take his political ambitions more seriously. If he said something egregious, a reporter would write up a quick summary and I would tweet it right out and watch
[03:37:06] <feepbot> concurrent views on the website spike...However, there was another dynamic at play I didn’t understand at the time: we saw ourselves as journalists, but that didn’t mean the rest of the newsroom did. While we recognized ourselves as innovating creative ways to make the paper’s journalism more accessible, many of the old-school print reporters and editors saw us as a bunch of
[03:37:11] <feepbot> kids playing with our phones. A former colleague, a young woman of color, once told me about how an editor told her she wasn’t a “real journalist” despite the fact that she was traveling with reporting teams, interviewing sources, and writing articles for the paper in addition to her social media duties...This presumption that social editors don’t do real work was
[03:37:11] <feepbot> heightened by the lack of visibility around the work we actually did. There are no bylines on tweets,' https://studyhall.xyz/ghostwriting/
[03:37:12] <feepbot> Ghostwriting – Study Hall (Until late this summer, I worked as a senior producer at a company that made podcasts for clients and media partners. I quit, in part, because I saw how far my ideas could go without my name attached)
[03:39:41] <quanticle> gwern: Endurance racing is absolutely insane
[03:39:58] <gwern> quite literally, once the hallucinations kick in
[03:40:17] <quanticle> I'm pretty sure they're insane even before they line up at the start line
[03:40:28] <gwern> they're just on a spectrum up until then
[03:40:46] <gwern> (an autism-correlated spectrum, it has been widely speculated)
[03:43:03] <quanticle> "Typically, Dauwalter’s takeaway from the race had nothing to do with how much she had suffered and endured, nor about winning or losing or strides made for women, but about learning: 'I feel pretty good about how it played out now that I’ve had night of sleep and a shower. Yeah, my legs hurt really bad and that’s probably going to get worse over the next couple days, but already I’m
[03:43:05] <quanticle> thinking about next year’s race, what we can do differently so we’re out there even longer. I want to come back and go into the 300s. Kevin and I have never done anything close to this. We learned so much—all the ways we can work more efficiently, gear and food that would have been helpful. To have this cool experience—I was lucky to be a part of this.'"
[03:43:07] <quanticle> Sheer insanity
[03:44:59] <gwern> you'll never know what it's like to really *live*, quanticle
[03:49:21] * gwern squints at his next item. 'Zvi Mowshowitz'... Mow... 'Zvi Meowshowitz'... no stop that
[03:54:13] <nullcone> good evening
[03:54:16] <nullcone> wagmi 
[03:54:25] <nullcone> even gwern 
[03:59:26] <feepbot> <gwern> https://www.bloomberg.com/news/articles/2021-10-15/wework-goes-public-again-no-adam-neumann-no-drama-plenty-to-prove
[03:59:26] <feepbot> WeWork Goes Public, Again: No Adam Neumann, No Drama, Plenty to Prove - Bloomberg (Infamous founder Adam Neumann is gone, and demand for the company’s office space is rising as it prepares to go public via SPAC in late October.)
[04:01:58] *** Quits: bildramer (~bildramer@2a02:587:6214:fd00:da38:7596:8413:13e7) (Ping timeout: 252 seconds)
[04:04:26] <feepbot> <gwern> https://www.aeaweb.org/articles?id=10.1257/aeri.20180633 so much valuable human capital formation
[04:04:27] <feepbot> Measuring Success in Education: The Role of Effort on the Test Itself by Uri Gneezy, John A. List, Jeffrey A. Livingston, Xiangdong Qin, Sally Sadoff and Yang Xu. Published in volume 1, issue 3, pages 291-308 of American Economic Review: Insights, December 2019, Abstract: US students often rank poo[snip] ((December 2019) - US students often rank poorly [snip])
[04:09:26] <feepbot> <gwern> https://neo.life/2021/10/the-promise-of-pills-that-do-nothing/
[04:09:28] <feepbot> The Promise of Pills that Do Nothing - NEO.LIFE (Open-label placebos may defy logic, but scientists explore promising new treatment possibilities.)
[04:12:58] <ivan> https://techcrunch.com/2021/10/13/reddit-adds-a-new-way-to-post-with-launch-of-predictions-feature/ this seems against their MO of making their audience as dumb as possible
[04:12:59] <Robomot> Reddit adds a new way to post with launch of ‘Predictions’ feature – TechCrunch (Reddit today is introducing a new way to post to its communities with the launch of the on-platform feature called “Predictions.” Spun off of the popular Reddit Polls, Predictions allow users to guess the answers to timely questions like “who will win the game tomorrow?” or …)
[04:13:24] <ivan> predicting might get them to start thinking
[04:13:42] <gwern> ...that was not anything I'd've predicted as the next reddit feature. if only they had had a Predictions I could've updated based on
[04:14:10] <gwern> 'Reddit has already been testing the feature ahead of today’s official launch and saw more than 1 million participants involve themselves in Prediction Tournaments. Popular tournaments included the Oscar Prediction Tournament on r/movies, which saw 100,000 participants; the Azerbaijan Grand Prix Prediction Tournament on r/formula1, which saw 200,000 participants; and the 2020 Eurocup...
[04:14:16] <gwern> ...Prediction Tournament on r/soccer, which saw over 300,000 participants.'
[04:15:03] *** Joins: bildramer (~bildramer@2a02:587:620a:e300:f1c:1361:9a68:d66e)
[04:19:17] <feepbot> <gwern> https://ai.googleblog.com/2021/10/simvlm-simple-visual-language-model-pre.html more token prediction
[04:19:18] <feepbot> Google AI Blog: SimVLM: Simple Visual Language Model Pre-training with Weak Supervision
[04:24:17] <feepbot> <gwern> https://twitter.com/robkhenderson/status/1449018692038242310/photo/2
[04:24:30] <|dbotdan> Rob Henderson (@robkhenderson, 2021-10-15 14:25): ‘How mass killings begin | "The first measures often simply restrict the civil rights and benefits of the victim group, perhaps as a way of punishing or getting revenge against them...when the perpetrators are surprised at how little protest there is, they...grow more violent"’ Images:
[04:24:30] <|dbotdan> https://nitter.fdn.fr/pic/media%2FFBvy0MEXIAU5iIb.jpg%3Fname%3Dorig (description: text; confidence: 0.86) | https://nitter.fdn.fr/pic/media%2FFBvy0MGXEBQurVi.jpg%3Fname%3Dorig
[04:25:12] <quanticle> I wonder how many people's predictions on the Azerbaijan Grand Prix got totally fucked when Max Verstappen crashed out from the lead on lap 46 with a freak no-warning tire failure
[04:25:58] <galambo> https://www.youtube.com/c/RationalAnimations
[04:25:59] <Robomot> Rational Animations - YouTube (Truth-seeking, science, technology, the future, and more. With animations!🟠 Patreon: https://www.patreon.com/rationalanimations)
[04:29:16] *** Quits: bildramer (~bildramer@2a02:587:620a:e300:f1c:1361:9a68:d66e) (Ping timeout: 245 seconds)
[04:30:59] <feepbot> <gwern> 'Recent supply chain breakdowns and the dramatic increase in the price of beef have made forward planning difficult for The Carnivore Bar. We are trying to scale up our business in order to make the carnivore bar as affordable and accessible as possible, while keeping quality high and increasing the volume of production to meet demand. ... I will continue to strive to
[04:30:59] <feepbot> provide them at the most affordable price possible, but that means that if we are to survive as a company, I can no longer afford to subsidize the cost of production. If beef prices and supply chains continue to snarl and lag behind, then the bars will cost more. This decision has been a living nightmare for months now for our team, but now as we’ve completely sold out for 2
[04:30:59] <feepbot> weeks straight, the decision is suddenly a lot easier. We have been bouncing off the bottom of our inventory for 2 months on top of this, and I now realize that I am not doing anyone any favors by risking the sustainability of the business to keep the sticker price down. I will do my absolute best to provide this product to anyone who needs it far into the future despite the state
[04:31:04] <feepbot> we find ourselves in as a society. To do less is to fail my duty, and I will never quit. Starting today, October 15, 2021, the following price changes have taken place: Grass-finished box: $150 + shipping Subscription Grass-finished box: $120 (20% discount) + FREE shipping Grain-finished box: $130 + shipping Subscription Grain-finished box: $104 (20% discount) + FREE shipping
[04:31:04] <feepbot> Grass-finished Ammo Box: $550 Grain-finished Ammo Box: $500 Sample Pack: $50 + shipping' <-- wow, I think that's like +$30?
[04:31:39] <quanticle> https://hard-drive.net/windows-11-review-where-the-fuck-is-space-cadet-3d-pinball
[04:31:40] <Robomot> Windows 11 Review: Where the Fuck Is Space Cadet 3D Pinball? (Microsoft has released its newest operating system, an update to its pioneering software simply called Windows 11, and it features one glaring omission. …)
[04:31:40] <quanticle> So, about that: https://news.ycombinator.com/item?id=28859610
[04:31:41] <Robomot> SpaceCadetPinball – Decompilation of 3D Pinball for Windows | Hacker News
[04:33:09] <gwern> 'Guy Stuck in ‘Groundhog Day’ Style Time Loop Finally Has Time to Watch All Those ‘Groundhog Day’ Style Time Loop Movies'  'Opinion: If Everyone Has a Death Note, Everyone Is Safe' 
[04:35:50] <quanticle> Is that last one wrong?
[04:37:11] <gwern> 'And the big issue with banning all Death Notes, of course, is that it means only criminals will have access to them. Is that what you want? You want 100% of Death Notes to be owned by criminals, who at any moment can write your name in their book, banishing you to Hell? Do you want to live in a world where the only people who own Death Notes are basically Kyosuke Higuchi?! You think the...
[04:37:17] <gwern> ...police can take him down? I sure don’t. At the end of the day, the only way we can ensure that we are all safe is if we all own Death Notes. That way, if a villain is out there writing a bunch of people’s names into Death Notes all willy nilly, a good guy with a Death Note can come along and write his name in it to stop him. If some mad man walks into a mall with a Death Note, I know...
[04:37:23] <gwern> ...we won’t be safe unless every other person in that mall is equipped with a Death Note of their own, scrambling to get the killer’s name so they can stop him. And if an angry student comes to class with a Death Note, who better to stop him than his own teacher, who has a Death Note of her own stashed in her desk? Not to mention, if we ever have to face off against a tyrannical...
[04:37:29] <gwern> ...government, we need to ensure that all American citizens have access to Death Notes so we can write the leaders’ names in them to stop them from taking away our rights. And lastly, if we want to go hunting, we should be able to name the animals we want to hunt and write their names in our Death Notes.' https://hard-drive.net/opinion-if-everyone-has-a-death-note-everyone-is-safe/ I think...
[04:37:35] <gwern> ...he is, because I'm pretty sure one of the Death Note Rules specifies it only works on humans
[04:37:43] <Robomot> Opinion: If Everyone Has a Death Note, Everyone Is Safe (You want 100% of  Death Notes to be owned by criminals, who at any moment can write your name in their book, banishing you to Hell?)
[04:38:20] <Obormot\Arcturus> Hmm
[04:40:28] <gwern> so sorry, no naming Bambi "Bambi" and then writing down Bambi in the Desu Note
[04:41:25] <quanticle> Yeah, obviously the creature being named has to know their name
[04:41:30] <Obormot\Arcturus> Of course `break-inside` doesn't actually *work* in this case, why would I think otherwise -_-
[04:42:20] <Obormot\Arcturus> I guess it's time for a close reading of the columns spec, again...
[04:43:06] *** Joins: bildramer (~bildramer@2a02:587:620e:cd00:dde9:b19f:23dc:225a)
[04:47:21] <feepbot> <gwern> https://twitter.com/anderssandberg/status/1449151410575130627 :)
[04:47:25] <|dbotdan> Anders Sandberg (@anderssandberg, 2021-10-15 23:13): ‘#FridayPhysicsFun – I got a question from the ever awesome @Gwern: shaking off water from spoons and dishes, does it actually dry them faster than just letting it drip in constant gravity? What about dropping them?’ Images: https://nitter.eu/pic/media%2FFBxqbVcXsAEbfnV.jpg%3Fname%3Dorig (description: a close-up of a drop of water; confidence:
[04:47:25] <|dbotdan> 0.47)
[04:52:28] <feepbot> <gwern> https://www.theonion.com/white-house-warns-supply-chain-shortages-could-lead-ame-1847855509 https://twitter.com/tylercowen/status/1449110198304522251
[04:52:29] <feepbot> White House Warns Supply Chain Shortages Could Lead Americans To Discover True Meaning Of Christmas (WASHINGTON—As reports of worldwide shipping issues continued to mount, the White House warned Wednesday that supply chain shortages could lead Americans to discover the true meaning of Christmas.  [snip])
[04:52:29] <|dbotdan> tylercowen (@tylercowen, 2021-10-15 20:29): ‘Just as Covid has (partly) put the kibosh on handshakes, might we hope that supply chain problems limit the deadweight loss of Xmas gifts?’
[04:53:28] <quanticle> My prediction: the gifts will be even more valuable
[04:53:35] <quanticle> After all, the signal just got that much costlier
[04:58:36] <feepbot> <gwern> https://twitter.com/PreetumNakkiran/status/1449060288234328064
[04:58:37] <|dbotdan> Preetum Nakkiran (@PreetumNakkiran, 2021-10-15 17:11): ‘Worth remembering that even interpolating kernels have adversarial examples (eg RBF on MNIST). And thus advex is not strictly a "deep learning" phenomena.’
[04:58:48] <PlanckWalk> If everyone had a Death Note, there sure as hell wouldn't be public records of births, deaths, and marriages.
[04:59:15] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[04:59:47] <PlanckWalk> "Our anonymous prime minister made an announcement today, ..."
[05:00:20] <wilrnh> good news guys: im now in the matrix @willrnh:matrix.org
[05:03:59] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[05:04:37] <catern> which one is more normal: to react instantly always when someone asks you a question while you're using your phone, or to 100% not hear others while you're using your phone
[05:04:51] <quanticle> From experience? The latter.
[05:05:26] <Obormot\Arcturus> The latter, and that is correct behavior
[05:05:44] <PlanckWalk> "Using your phone" to talk with someone, or to use some app?
[05:05:48] <catern> some app
[05:05:54] <quanticle> Speaking as someone both ignored questions while looking something up on their phone and also as someone who's had to repeat a question to other people who have been distracted by their phones.
[05:06:11] <Obormot\Arcturus> Oh, in that case I reverse my answer: never use apps on phones
[05:06:19] <PlanckWalk> Either way the latter seems more common.
[05:06:47] <PlanckWalk> Though I don't think I've seen anyone who does 100% of either.
[05:07:36] <PlanckWalk> More like maybe 30-90% of not responding at all, versus maybe 0-30% of responding instantly.
[05:08:33] <PlanckWalk> A pretty broad range of responding after some seconds.
[05:09:05] <quanticle> I don't think I've ever had anyone respond *instantly* when I've asked them a question while they were on their phone
[05:09:15] <catern> yeah so I know responding at a delay is the most normal
[05:09:18] <quanticle> It's always at least 2-3 seconds of buffering
[05:09:25] <catern> but I deliberately didn't provide that as an option :)
[05:09:37] <PlanckWalk> I've had a fair few cases of responding verbally without looking up or stopping what they were doing
[05:09:55] <quanticle> Yeah, fair enough, and I still stand by my answer: 100% not hearing the question is far more common than responding instantly
[05:10:02] <PlanckWalk> Yeah
[05:10:33] <catern> cool thanks for participating in my IRC survey
[05:10:40] <quanticle> Do I get a prize?
[05:10:43] <PlanckWalk> Now you can write an n=3 paper!
[05:10:44] <catern> the results will be published in 6-8 weeks
[05:11:25] <catern> I'm tempted to ask the followup question: what about mid-conversation becoming distracted by your phone and just flat out stopping responding
[05:11:29] <catern> that's rude right
[05:11:43] <PlanckWalk> I'd say 
[05:12:13] * PlanckWalk looks up social norm websites and never finishes the sentence.
[05:12:35] <catern> (oh, I thought "I'd say!" was the entire sentence)
[05:12:43] <quanticle> Yeah, that's rude, but sadly common
[05:12:49] <PlanckWalk> Darn.  I should have sto
[05:13:07] * quanticle slaps the phone out of PlanckWalk's hand
[05:13:12] <PlanckWalk> Ow!
[05:13:18] <catern> PlanckWalk: Have you heard of truncatism? it's a plot element in this one story that I re
[05:17:36] *** Joins: WilliamReniNoelH (~willrnhma@2001:470:69fc:105::1:1ab2)
[05:18:05] *** Parts: WilliamReniNoelH (~willrnhma@2001:470:69fc:105::1:1ab2) ()
[05:18:19] <feepbot> <gwern> https://twitter.com/swyx/status/1448858023724609541 wait... https://www.marketwatch.com/story/gitlab-stock-surges-more-than-20-on-first-day-of-trading-11634228760 'Late Wednesday, GitLab priced its stock at $77 a share, well above its already elevated range. On Tuesday, GitLab hiked its expected pricing range to between $66 and $69 a share, up from a forecast last week of
[05:18:19] <feepbot> $55 to $60 a share. Wednesday’s pricing values the company at $11 billion, based on 143 million shares expected to be outstanding after the offering. ... Regarding its most direct competitor, GitHub, which was acquired by Microsoft Corp. MSFT, +0.48% in 2018 for $7.5 billion, Robins said the potential market is big enough for both of them for now. “From a Microsoft perspective,
[05:18:20] <feepbot> we don’t see Microsoft in that many deals,” Robins told MarketWatch. “It’s not the majority of deals. And when Microsoft is in a deal, our win rate is the same with them in it, as when they’re not in it. If you took our revenue and Microsoft’s GitHub revenue combined, we are a fraction of the $40 billion market out there.”' <-- wow. I never fail to be surprised by
[05:18:20] <|dbotdan> shawn swyx wang (@swyx, 2021-10-15 03:47): ‘America’s digital divide is never more apparent than today. | On the one hand, GitLab, an open source, massively distributed company just IPOed at 2x the valuation of GitHub. | On the other, the governor of Missouri just ruled that viewing HTML is criminal hacking.’
[05:18:25] <feepbot> how... just not being acquired means that sometimes you can make tens of billions more. if you go back a few years ago, gitlab looked like a tiny lame also-ran that would collapse soon for lack of any use or value
[05:18:34] *** Joins: WilliamReniNoelH (~willrnhma@2001:470:69fc:105::1:1ab2)
[05:18:35] *** WilliamReniNoelH is now known as wilrnh[m]
[05:18:55] *** Quits: wilrnh (~wilrnh@pool-100-37-246-140.nycmny.fios.verizon.net) (Quit: leaving)
[05:19:28] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Ping timeout: 252 seconds)
[05:20:40] <catern> unrelatedly... is there a form of representative democracy where representatives have the power to control exactly and only the amount of votes that were cast for them/delegated to them?
[05:21:07] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[05:22:20] <PlanckWalk> Not that I know of.  It seems like it could become unwieldy if there are many candidates.
[05:23:10] <catern> yeah just maybe have a minimum number of votes for a representative to enter the parliament/congress/deliberative body/whatever
[05:25:54] <PlanckWalk> Seems plausible, but haven't taken 5 minutes to start thinking of flaws/improvement yet :)
[05:26:49] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[05:27:01] <PlanckWalk> At least it would get rid of "A got 3.13 million votes, B got 3.14 million votes, B gets all the power!"
[05:27:34] <PlanckWalk> (and all the people who voted for B throw a fit and call rigged election etc)
[05:27:40] <PlanckWalk> Err, for A
[05:32:41] <feepbot> <gwern> 'Alix Spiegel And it happens in all kinds of areas. Research has shown that a teacher's expectations can raise or lower a student's IQ score, that a mother's expectations influences the drinking behavior of her middle schooler, that military trainers' expectations can literally make a soldier run faster or slower. So my question was-you know, how far does this go?'
[05:32:41] <feepbot> https://www.thisamericanlife.org/544/transcript GODDAMNIT ROSENTHAL
[05:32:42] <feepbot> 544: Batman - This American Life
[05:36:34] *** Quits: Mithaldu_ (sid27181@id-27181.hampstead.irccloud.com) (Ping timeout: 252 seconds)
[05:36:34] *** Quits: flgr (sid200704@id-200704.tinside.irccloud.com) (Ping timeout: 252 seconds)
[05:36:40] *** Quits: Pent (sid313808@id-313808.lymington.irccloud.com) (Ping timeout: 252 seconds)
[05:36:55] *** Quits: pdg (sid395042@id-395042.lymington.irccloud.com) (Ping timeout: 268 seconds)
[05:36:55] *** Quits: vorpalhex (sid421573@id-421573.lymington.irccloud.com) (Ping timeout: 268 seconds)
[05:36:55] *** Quits: potatope (sid139423@id-139423.lymington.irccloud.com) (Ping timeout: 268 seconds)
[05:37:07] *** Quits: Baughn (sid153359@id-153359.tinside.irccloud.com) (Ping timeout: 252 seconds)
[05:37:23] *** Quits: chromis (sid150893@id-150893.tinside.irccloud.com) (Ping timeout: 250 seconds)
[05:37:23] *** Quits: ainoue (uid521280@id-521280.tinside.irccloud.com) (Ping timeout: 250 seconds)
[05:37:42] <feepbot> <gwern> https://github.com/readme/featured/why-the-lucky-stiff
[05:37:43] <feepbot> What we can learn from "_why" the long lost open source developer · GitHub (Code might not last forever, but _why proves you can have an impact that outlives your work.)
[05:37:49] *** Quits: cpopell (sid506802@id-506802.tinside.irccloud.com) (Ping timeout: 250 seconds)
[05:38:02] *** Joins: cpopell (sid506802@tinside.irccloud.com)
[05:38:09] *** Quits: foamy (sid25727@id-25727.lymington.irccloud.com) (Ping timeout: 268 seconds)
[05:38:13] *** Quits: mstevens (sid285816@id-285816.tinside.irccloud.com) (Ping timeout: 252 seconds)
[05:38:13] *** Quits: kaizen_ (sid60510@id-60510.tinside.irccloud.com) (Ping timeout: 252 seconds)
[05:38:37] *** Joins: ainoue (sid521280@tinside.irccloud.com)
[05:38:45] *** Joins: nullcone_ (uid11626@helmsley.irccloud.com)
[05:38:46] *** Joins: foamy (sid25727@lymington.irccloud.com)
[05:39:07] *** Joins: chromis (sid150893@tinside.irccloud.com)
[05:39:10] *** Quits: nullcone (uid11626@id-11626.helmsley.irccloud.com) (Ping timeout: 268 seconds)
[05:39:10] *** nullcone_ is now known as nullcone
[05:40:22] *** Joins: Baughn (sid153359@tinside.irccloud.com)
[05:40:35] *** Joins: Pent (sid313808@lymington.irccloud.com)
[05:41:04] *** Joins: kaizen_ (sid60510@tinside.irccloud.com)
[05:41:06] *** Joins: mstevens (sid285816@tinside.irccloud.com)
[05:42:42] <feepbot> <gwern> https://www.atlasobscura.com/articles/museums-radioactive-artifacts
[05:42:43] <feepbot> The Canadian Team on the Hunt for Radioactive Artifacts - Atlas Obscura (Historic objects made with dangerous elements are lurking in museum collections.)
[05:47:43] <feepbot> <gwern> https://www.nytimes.com/2009/09/20/world/africa/20cairo.html
[05:47:44] <feepbot> Belatedly, Egypt Spots Flaws in Wiping Out Pigs - The New York Times (When the government killed the pigs in Egypt in an attempt to combat swine flu, it was warned that Cairo would be overwhelmed with trash. Now, it is.)
[05:52:21] *** Joins: flgr (sid200704@tinside.irccloud.com)
[05:52:24] *** Joins: Mithaldu_ (sid27181@hampstead.irccloud.com)
[05:52:44] <feepbot> <gwern> https://www.ediblegeography.com/pig-futures/
[05:52:45] <feepbot> Pig Futures
[05:53:02] *** Joins: pdg (sid395042@lymington.irccloud.com)
[05:53:09] *** Joins: vorpalhex (sid421573@lymington.irccloud.com)
[05:54:25] *** Joins: potatope (sid139423@lymington.irccloud.com)
[05:57:45] <feepbot> <gwern> https://blog.8faces.com/post/95834995096/weve-seen-a-lot-of-different-approaches-to creepy
[05:57:46] <feepbot> Creepy Type 2 This ‘oral alphabet’ must surely be... | Type Worship: Inspirational Typography & Lettering; (Creepy Type 2 This ‘oral alphabet’ must surely be a counterpart to the fleshy type I posted about a few months ago. The toothy type has been created by Japanese designer Takayuki Oga [snip])
[06:02:24] *** Joins: shawwwn (uid6132@helmsley.irccloud.com)
[06:02:45] <feepbot> <gwern> https://ohnotype.co/blog/spacing
[06:02:47] <feepbot> Spacing ☠️ OH no Type Company (OH no Type Co. Retail and custom typefaces. Life’s a thrill, fonts are chill!)
[06:07:46] <feepbot> <gwern> https://typographica.org/on-typography/copyright-protection-of-typefaces/
[06:07:47] <Obormot\Arcturus> gwern: What's with those left sidebars or w/e on that site
[06:07:48] <feepbot> The Last Time the US Considered Copyright Protection for Typefaces – Typographica (The United States has the dubious distinction of offering no copyright protection for the design of typefaces&thinsp;—&thinsp;at least not in their visual form.1 With the advent of digital fonts, type manufacture [snip])
[06:07:50] <Obormot\Arcturus> Why are they cut off
[06:08:15] <gwern> you're supposed to hover
[06:08:25] <gwern> they slide open to save space
[06:08:30] <Obormot\Arcturus> ... that's bad and terrible
[06:08:46] <gwern> isn't it? but it is the explanation
[06:10:34] <shawwwn> oh no, gwern's talking to himself again. someone help him find his way home
[06:10:35] <feepbot> shawwwn: gwern left a note 4 hours, 38 minutes ago: '"It is harder to get into Groq than it is to get into Harvard University. We are seeking and finding talent across the United States and all over the world. While big companies are seeing employees leave as part of the great resignation, we're hiring talent with a geo-agnostic approach that is proving to work extremely well" said
[06:10:35] <feepbot> Jonathan Ross, CEO of Groq.'
[06:14:15] <shawwwn> was this near the beginning of the pandemic?
[06:15:01] <gwern> no, I think it's quite recent? pie__ was just interested in groq hiring
[06:16:42] <shawwwn> the only "great resignation" I'm aware of is when I decided it was time to get a job(s)
[06:17:07] <shawwwn> so I was wondering if there was something near the beginning of the pandemic happening, or ... something.
[06:18:27] <gwern> https://groq.com/groq-fuels-talent-growth-beyond-expectations/ 2021-10-07
[06:18:27] <Robomot> Groq Fuels Talent Growth Beyond Expectations : Groq (Simplify Compute, Everywhere.)
[06:18:44] <shawwwn> oh! that actually is in line with facebook's return-to-office mandate
[06:18:57] <shawwwn> they told everyone they needed to be back in the office by january
[06:19:06] <shawwwn> so it's possible that there are lots of resignations happening right now
[06:20:23] <gwern> are they picking up a lot of FBers? FB doesn't do *that* much in terms of weird exotic hardware compared to apple or google etc... I don't think FB even makes a neural accelerator ASIC of its own
[06:22:03] <shawwwn> hm.. there's a quote from the video https://youtu.be/jWpFTcAZlxM?t=71 "We're seeing acceptance rates of over 92%"
[06:22:14] <feepbot> Customer Demand Fueling Groq Geo-Agnostic Team Growth - Announcement by Jonathan Ross, CEO - YouTube (In this announcement, Jonathan Ross, CEO of Groq Inc, shares the decision to be a geo-agnostic company, a talent strategy supporting 3x growth driven by incr...)
[06:22:24] <shawwwn> I wonder what that refers to
[06:23:23] <shawwwn> maybe he didn't say "acceptance". or maybe "acceptance" refers to employees accepting that they'll stay at groq (i.e. not resigning)
[06:23:47] <shawwwn> since I'm not sure anyone would want to advertise 92% hiring acceptance rate
[06:24:55] <shawwwn> Hats off to him for taking groq remote and embracing it from the beginning of the pandemic though. That wasn't easy for any large company, let alone a new one
[06:25:16] <shawwwn> OH REALLY
[06:25:25] <shawwwn> "Additionally, Groq has received strategic investments and program sponsorship from partners such as In-Q-Tel."
[06:25:32] <shawwwn> OHO.
[06:25:49] <shawwwn> https://en.wikipedia.org/wiki/In-Q-Tel
[06:26:01] <feepbot> In-Q-Tel (IQT) is an American not-for-profit venture capital firm which invests in high-tech start-up companies focused on supporting United States intelligence capabilities. It was founded in 1999 as Peleus and is currently based in Arlington, Virginia.
[06:26:06] <shawwwn> it's essentially the VC arm of the USG intelligence sector
[06:27:08] <shawwwn> > In-Q-Tel sold 5,636 shares of Google, worth over $2.2 million, on November 15, 2005.
[06:27:10] <shawwwn> lol get rekt
[06:28:19] <shawwwn> https://news.ycombinator.com/item?id=28362279 uh
[06:28:31] <feepbot> In-Q-Tel, folks. Look it up. It funded all this "social media" BS early on for w... | Hacker News
[06:28:58] <shawwwn> hm, interesting thread, sort of https://twitter.com/twitandrewking/status/1301340210672726016
[06:28:59] <|dbotdan> Andrew King (@twitandrewking, 2020-09-03 02:04): ‘In-Q-Tel sold 5,636 shares of Google, worth over $2.2 million, on November 15, 2005. The shares were a result of Google's acquisition of Keyhole, Inc, the CIA-funded satellite mapping software now known as... Google Earth.’
[06:30:54] <gwern> shawwwn: I dunno, for super-specialized NN hardware skills, 92% sounds pretty good to me. such people are fending off multiple offers, if they're at all sensible. plus many techies interview without being too serious about it. some talk about just keeping in interview practice
[06:31:11] <gwern> (I remember a story about one guy who used interviews to try to market stuff to the interviewers)
[06:31:33] <shawwwn> lol I saw that one too
[06:32:01] <gwern> I think 92% would be pretty good for an american college too? and students are a lot less competitive than NN experts today
[06:32:50] <shawwwn> it depends what "acceptance" refers to. Usually it refers to passing a filter, i.e. it's directly at odds with the quote that groq is "harder than harvard to get into"
[06:33:13] <shawwwn> but if it refers to acceptance rates after groq makes an offer *after deciding to hire someone*, then yes, it's very good
[06:34:30] <shawwwn> lol. these 2005 quotes are hilarious
[06:34:31] <shawwwn> https://venturebeat.com/2005/11/15/pissed-at-google/
[06:34:43] <feepbot> Pissed at Google | VentureBeat (Updated We seem to be hearing from more people that Google doesn’t do that great a job outside of its core focus, search. So again, when Google decided to make its Web analytics software free yesterday, some people weren’t happy with how the company handled it. T [snip])
[06:34:44] <shawwwn> > when Google decided to make its Web analytics software free yesterday, some people weren’t happy with how the company handled it. They were pissed, says Ethan Stock, chief executive of valley events start-up Zvents.
[06:34:54] <shawwwn> ah yes, Zvents, that influential start-up
[06:35:17] <shawwwn> imagine how terrible of an idea it would've been to try to charge for google analytics
[06:37:26] <shawwwn> Let's see, google's stock in Jan 2005 was $98.33	. Let's be generous and say it was Dec 2005 (price $203.84) that they sold their stock. At the time, that was $203.84 * 5,636 = $1.14M
[06:38:58] <shawwwn> mm, I guess it's more or less a rounding error. 5.6k shares would've been worth somewhere between $15M and $32M today
[06:40:01] <shawwwn> still, losing out on a 10x opportunity is always "fun"
[06:42:58] <shawwwn> https://books.google.com/books?id=65WYDgAAQBAJ&pg=PT331&lpg=PT331&dq=5636+shares+of+google+in+2005&source=bl&ots=eTbnZhTFg5&sig=ACfU3U0surC1V8ytA53cQ1XEylSxapZVIw&hl=en&sa=X&ved=2ahUKEwin-LrI983zAhVMGs0KHTPFBIEQ6AF6BAgvEAM#v=onepage&q=5636%20shares%20of%20google%20in%202005&f=false
[06:43:00] <gwern> I mean, harvard obviously doesn't make offers to 92% of applicants. not even within 2 OOMs of that. it's like <1%
[06:43:10] <feepbot> Surveillance Valley: The Secret Military History of the Internet - Yasha Levine - Google Books (The internet is the most effective weapon the government has ever built. In this fascinating book, investigative reporter Yasha Levine uncovers the secret origins of the internet, tracing it back to a Pe [snip])
[06:44:14] <gwern> shawwwn: but 1.14m would also have done pretty well if it had just been indexed, so that's worth considering. it's hard to know if google was going to do well. look at how every year since 2005 someone was sure to forecast that google was going to pop as people discovered the true rates of online ad fraud, or that tech was a bubble &etc
[06:44:39] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[06:44:55] <shawwwn> https://www.fool.com/investing/2019/11/25/if-you-invested-10000-in-googles-ipo-this-is-how-m.aspx compares indexed vs google
[06:45:06] <feepbot> If You Invested $10,000 in Google's IPO, This Is How Much Money You've Have Now | The Motley Fool (And here's also how much $100, $500, $1,000, and other sums invested in shares of the company that's now called Alphabet would be worth now.)
[06:45:27] <shawwwn> $85 in GOOG would've become $2,589, whereas $85 would become $332 in S&P (291% growth)
[06:46:23] <shawwwn> inb4 I lose all my savings investing in saturn2's new startup
[06:47:41] <gwern> ($3.3m is nothing to sneeze at. and if you really loved risk, well, cryptocurrencies came along)
[06:49:12] <shawwwn> oh yeah, I heard about those
[06:49:25] <shawwwn> emily's dad mentioned it the other day
[06:50:19] <gwern> yeah, they're all scams, but you can make a quick buck
[06:50:20] <shawwwn> he grabbed a bag and said "8 bitcoin" and walked out the front door. so I googled it and it's this weird new thing
[06:50:30] <shawwwn> some kind of monopoly money or something I guess
[06:51:00] <adiabatic> for a while there you could make a large medium-speed buck. ask kiba
[06:51:15] <shawwwn> it's hard to escape the conclusion that snowden's work was essentially useless https://www.youtube.com/watch?v=Ve0TXM0VBiE&ab_channel=InnerVision
[06:51:26] <feepbot> \ - YouTube
[06:51:33] <shawwwn> all of his points are like ... "well, yeah"
[06:51:36] <shawwwn> gj feepbot
[06:56:37] <feepbot> <gwern> https://shadycharacters.co.uk/2018/10/emoji-part-3-go-west/
[06:56:42] <feepbot> Emoji, part 3: go west – Shady Characters
[07:01:37] <feepbot> <gwern> https://www.floodfonts.com/kontiki/ /eyeroll
[07:01:37] <feepbot> Kontiki - Typeface (Microsite of the typeface Kontiki aka Pulpo Rust by Felix Braden.)
[07:01:55] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[07:01:57] <shawwwn> Gurkenglas will be here soon
[07:01:58] <shawwwn> omfg
[07:02:01] <shawwwn> no fucking way
[07:02:13] <shawwwn> uh, hi Gurkenglas
[07:02:26] <Gurkenglas> who summoned me
[07:02:41] <shawwwn> apparently my thoughts control reality now
[07:02:53] <shawwwn> what will I do with my new powers? tune in next time...
[07:03:18] <gwern> '23:31:55 Â» Gurkenglas is "realname" on #lesswrong 23:31:57 < shawwwn> Gurkenglas will be here soon' lame
[07:03:21] * shawwwn clones oolong a few dozen times
[07:03:33] <adiabatic> gwern: what's eye-rolly about it
[07:03:54] <Gurkenglas> yeah that came after the join, but i expected he said that about something related to my interests ^^
[07:04:00] <shawwwn> nope
[07:04:05] <shawwwn> I was literally just thinking about you
[07:04:28] <shawwwn> I pressed Gurk<tab> and saw you weren't here, then finished the message and pressed enter
[07:05:12] <gwern> adiabatic: it's a kinda silly thing to do as a font instead of just a photoshop filter or something, but then the whole 'About' section is just incredible puffery
[07:05:45] <shawwwn> someone got paid to make this https://twitter.com/GroqInc/status/1433446220073091073
[07:05:45] <|dbotdan> Groq Inc (@GroqInc, 2021-09-02 15:06): ‘#tbt to National Dog Day, when @GroqInc team members shared photos of their cute pooches. | #WhyGroq #doglover #hiringtoptalent #nationaldogday’ Watch video: https://nitter.net/GroqInc/status/1433446220073091073
[07:06:14] <adiabatic> …I ate a lot today and I'm hungry anyway
[07:06:23] <shawwwn> barketing manager..
[07:06:42] <shawwwn> toy durability analyst
[07:08:11] <Gurkenglas> since i decided to turn on the computer before your thought, i submit that reality controls your thoughts
[07:09:15] <shawwwn> maybe you control my thoughts
[07:09:25] <gwern> shawwwn: I'm sure they had fun in the slack coming up with captions
[07:09:37] <gwern> are you telling me there's no #dogs in the groq slack?
[07:09:59] * gwern would replace 'head of mess development' with 'head of mess production' fwiw
[07:10:19] <shawwwn> I only got a brief glimpse before they remembered I was a contractor and thus relegated me to a slack guest account with access to two channels total
[07:10:22] <gwern> (and 'chief hairing officer')
[07:10:33] <gwern> sad! you're beingdiscriminated against
[07:10:37] <shawwwn> one of which is #contractors
[07:10:55] <shawwwn> yes. I'm trying to convince everyone in #contractors to form a club that FTEs aren't invited to
[07:11:46] <shawwwn> it doesn't end there though. yesterday a coworker tried to share some code with me. they pasted /net/home/$them/workspace/$code.py
[07:11:55] <shawwwn> so i try to access it, since it's a shared VM
[07:12:12] <shawwwn> (apparently the entire company does all of their development on this VM. we're literally not allowed to clone anything anywhere else)
[07:12:22] <shawwwn> I get access denied
[07:12:25] <shawwwn> coworker is confused
[07:12:36] <shawwwn> I ask in #infra-help. "oh it's because you're a contractor"
[07:12:46] <shawwwn> ...ok? so how do I see the code?
[07:13:00] <shawwwn> "I recommend they chgrp things to share them with you"
[07:13:11] <shawwwn> unix folders of course can only have one group
[07:13:41] <shawwwn> why not paste the code in slack? well, turns out they used to, but aren't supposed to do that anymore
[07:13:52] <saturn2> have them take a picture with their phone and post it on instagram
[07:14:12] <gwern> hm. unix directories can only have 1 group? but I could swear that files could have many groups
[07:14:34] <saturn2> wrong!
[07:14:46] <Gurkenglas> maybe in a nested folder you can have different groups per level?
[07:14:52] <gwern> oh dear
[07:14:57] <shawwwn> yeah I tried using setacl or whatever the heck it's called. but apparently it's not a first class citizen or something
[07:15:01] <saturn2> they can have posix access lists
[07:15:03] <shawwwn> they got operation denied when they tried
[07:15:16] <shawwwn> presumably because it's a network mount or something
[07:15:26] <saturn2> and users can have many groups
[07:15:49] <saturn2> but not too many, up to 64 iirc
[07:16:01] <shawwwn> but yes, everyone keeps being like "I'm surprised you went the contractor route" and "why'd you become a contractor instead of FTE?"
[07:16:05] <gwern> so... you'd make a new group, grant everyone plus the contractor access to it, and put the directory under the new group?
[07:16:14] <gwern> this does not sound scalable
[07:16:21] <shawwwn> correct! it's not1
[07:16:24] <shawwwn> that's what the IT guy said
[07:16:31] <shawwwn> "I really don't want to do this if this is just a one-off"
[07:16:44] <shawwwn> "just share the code via their manager"
[07:16:57] <saturn2> the sysadmin should have made a group for ftes+contractors
[07:16:58] <shawwwn> presumably the mental model was something like, code gets emailed to manager, and manager emails it to me
[07:17:16] <gwern> (I didn't realize groups were so profoundly restricted. no wonder you don't see much use of it outside basic sysadmin roles like 'printer')
[07:17:51] <shawwwn> yes. I'm always surprised whenever unix groups come up just how restrictive they are
[07:18:11] <shawwwn> they get the job done, I guess, but it's hard to imagine someone consciously deciding to design them this way nowadays
[07:18:19] <shawwwn> not that modern designs would be much better 
[07:18:54] <shawwwn> but, ultimately, I finally got access to a prod environment with a TSP
[07:19:03] <saturn2> it's so all the unix permissions can fit into 6 bytes
[07:19:05] <shawwwn> it's surprisingly not terrible 
[07:19:34] <shawwwn> yeah, if folders could have multiple groups then the inode entries wouldn't be constant size, or something like that
[07:19:46] <saturn2> yes
[07:20:23] <shawwwn> still should've let people specify an altgroup for +2 bytes
[07:20:37] <shawwwn> then each inode would be 64 bit, which is the only proper alignment
[07:20:53] <shawwwn> and it'd cover like 90% of real world cases people care about
[07:21:15] <shawwwn> like "gee I wish I could let this other group also have access to this area"
[07:25:04] <gwern> I dunno, even multics has better security. heck, wasn't the burroughs capability machine pre-unix even?
[07:25:41] * shawwwn realizes gwern wasn't using multics as the butt of a joke
[07:25:50] <shawwwn> don't you even know how to multics bro
[07:26:06] <gwern> multics was a very good OS
[07:26:50] <shawwwn> yep, just like this is a very good program https://twitter.com/leinweber/status/989267343002951680?lang=en
[07:26:51] <|dbotdan> will leinweber (@leinweber, 2018-04-25 22:18): ‘I made a VGP (very good program) that makes it so it looks like I’m typing on slack whenever anyone else is typing, and stops when they stop. | Everyone loves it so far and doesn’t find it annoying at all! | https://github.com/will/slacktyping ’ Watch video: https://nitter.1d4.us/leinweber/status/989267343002951680
[07:30:42] <shawwwn> surprisingly hard question https://twitter.com/RichardMCNgo/status/1449123107424276480
[07:30:43] <|dbotdan> Richard Ngo (@RichardMCNgo, 2021-10-15 21:20): ‘One explanation for why many leaders throughout history have done evil things is that power corrupts. Another is that immoral people seek out power - i.e. it's caused by selection bias. Which effect has a bigger impact, and by how much?’
[07:30:54] <shawwwn> I'm honestly not sure what to vote
[07:31:26] <shawwwn> I think "selection, more than 5x". But just barely
[07:32:15] <shawwwn> if I were given unlimited power, it would be very hard to imagine me putting anyone to death
[07:32:34] <shawwwn> (why deprive myself of watching gwern's natural demise?)
[07:32:42] <saturn2> selection, more than 5x
[07:32:47] <shawwwn> yeah
[07:33:01] <saturn2> easy question imo
[07:33:38] <linear> i feel selection a bit, but also selection that happens *after* power is gained; in order to stop other (potentially even evil) parties from stealing the power
[07:33:57] <shawwwn> I think a lot of people would be evil if given the opportunity
[07:34:12] <gwern> I think it depends on what we're thinking of by 'evil'. when you look at stalin, mao, pol pot, hitler, etc - these were clearly bad people long before they got a lick of power.  but those are, thank god, exceptional people, who make up only a small fraction of politician-years. someone like jong un who seems to have been OK enough but then actually corrupted by power is unusual. if we look at...
[07:34:15] <shawwwn> which is why the question seems not cut and dry
[07:34:18] <gwern> ...all harms and evils done by politicians, probably a lot of it is just diffuse general bad government policies, which are heavily incentivized by corruption
[07:34:50] <shawwwn> jong un was ok?
[07:35:01] <saturn2> incentivization is selection too
[07:35:04] <shawwwn> I actually don't know anything about jong
[07:35:37] <shawwwn> only to the extent that you have to design incentives perfectly, or else people will exploit the difference between intent vs reality
[07:35:38] <gwern> yeah, as a kid and into his early teens, he apparently was pretty normal. no saint, but not a vicious narcissist you'd believe could feed his uncle to the dogs while weeping to his harem about how unjustly he is persecuted
[07:35:40] <saturn2> you're free to not respond to incentives, but then you get outcompeted
[07:36:00] <shawwwn> ... did he really feed his uncle to dogs?
[07:36:14] <gwern> no. he was actually blown up by AA or shot by a firing squad, iirc
[07:36:21] <nshepperd2> corruption powers
[07:36:23] <gwern> but you could totally believe it, and many did
[07:36:53] <shawwwn> I could not believe that dogs are used in modern day torture
[07:36:58] <shawwwn> only movies
[07:37:27] <nshepperd2> nah i'd believe it
[07:37:33] <gwern> what happened with jong un is basically that he was the only male kim with no fatal flaws and he *seemed* corruptible enough to jong-il, and so they set to work giving him power, encouraging him to abuse it, surrounding him with flattery, building up a personality cult etc, and here we are 15 years later, and he's thoroughly corrupted
[07:37:39] <saturn2> being eaten by cats would be more painful
[07:37:48] <shawwwn> shooting one's uncle via firing squad is far less evil. that's just standard walmart grade evil
[07:37:57] <shawwwn> buy that level of evil off the shelf and put it under a christmas tree
[07:38:07] <gwern> un also does execution by, like, mortar
[07:38:34] <gwern> (I kinda wonder how that works. do they do a few mortar shots before hand to make sure it's perfectly dialed in and then bring in the witnesses)
[07:39:43] <shawwwn> I would execute gwern by putting him in a situation where he's only fed if he compliments someone
[07:39:44] <saturn2> maybe the mortar shell is just buried under the ground and they fake it
[07:39:52] <gwern> anyway, if you're in a place where the milk is watered down and the bridges occasionally collapse due to too much sand in the concrete and the cops pull you over for a bribe... that certainly looks a lot like corruption. but on the other hand, that's all petty evil compared to the world-historic harms caused by a mao
[07:40:00] <shawwwn> death by starvation within two weeks
[07:40:28] <shawwwn> (someone that exists in his personal life, not celebrities)
[07:40:28] <gwern> when I became delirious with hunger, I'd start seeing people as cats and complimenting them on their long fluffy tails
[07:40:38] <gwern> check and mate
[07:40:42] <saturn2> i thought we were talking about political leaders, not corrupt cops
[07:40:54] <gwern> saturn2: that comes from the top
[07:42:06] <shawwwn> in that case, s/compliment/apologize to/
[07:42:08] <shawwwn> boom ded
[07:42:49] <gwern> I would have to be crazy to think I'd done anything wrong, so the hunger hallucinations solve that one too
[07:47:50] <feepbot> <gwern> https://www.mdpi.com/2411-5150/3/1/1/htm
[07:47:50] <feepbot> Vision  | Free Full-Text | A Thickness Illusion: Horizontal Is Perceived as Thicker than Vertical | HTML (We report two psychophysical experiments that investigate a visual illusion that is considered common knowledge among type designers, but has never been studied scientifically. Specifically, th [snip])
[07:52:50] <feepbot> <gwern> https://www.bldgblog.com/2009/09/body-baroque/ body horror, although making things and buildings out of bodies is kinda easy mode body horror
[07:52:53] <feepbot> Body Baroque – BLDGBLOG ([Image: Yousef Al-Mehdari].A few weeks ago I mentioned some 3D-printed work by Yousef Al-Mehdari, a student at the Bartlett School of Architecture. That work is now pictured here, in a proposal for…)
[07:56:18] * shawwwn sighs
[07:56:38] <shawwwn> I guess 33 is the point at which "just don't worry about it and your weight reverts" stops working
[07:56:47] <shawwwn> 245lbs at the dr's office today. too high for comfort
[07:57:02] <shawwwn> guess it's back to pineapple and apples + peanut butter forever
[07:57:31] <shawwwn> I was like, nah, I just won't worry about it and it'll go back to 235 like it always does
[07:57:46] <shawwwn> but then I considered "what if it goes to 250?" and 250 is officially way too fucking high
[07:58:17] <shawwwn> luckily at 6ft such things aren't terrible, but
[07:58:30] <shawwwn> it's also mentally taxing to be fat
[07:58:50] <shawwwn> I was going to joke like "name one fattie that's changed the world"
[07:58:55] <shawwwn> but now I can't think of one
[07:59:27] <linear> depends on how large you mean, I can think of a lot of people like rms or woz or gaben that are a bit bigger
[07:59:43] <shawwwn> ah yes, I guess steve ballmer sort of counts https://www.ranker.com/list/most-successful-obese-americans/ready-to-startup
[07:59:49] <gwern> shawwwn: Mao? John Un? Jong-Il? stalin seems kinda paunchy in his photos
[07:59:54] <shawwwn> look at that face https://imgix.ranker.com/node_img/105/2096413/original/steve-ballmer-all-people-photo-1?auto=format&q=60&fit=crop&fm=pjpg&dpr=2&w=650 
[07:59:59] <feepbot> Successful Fat People | List of Obese Celebrities (The most successful obese Americans include men and women who despite being overweight, have found mainstream success. These actors, actresses, musicians, ...)
[08:00:01] <gwern> (hitler was thin, but he was cheating with amphetamines)
[08:00:04] <shawwwn> that's the face of someone who appreciates good cocaine
[08:00:21] <linear> ^ also though if you are thinking 'historically', historically bmis were much lower, so example are def harder to find. you more so want someone who *is* or *will* change the world, than someone that did in the past
[08:00:26] <shawwwn> dick cheney was *not* fat lmao
[08:00:50] <PapuaHardyNet> why were BMIs historically lower? lower QOL? lower slack?
[08:01:21] <linear> that is a very long discussion to answer but the short answer would be fewer calories, more exercise, and different environment
[08:01:36] <PlanckWalk> Henry VIII?
[08:01:38] <gwern> https://www.usatoday.com/picture-gallery/news/nation/2013/10/20/at-home-with-dick-cheney/3106173/ heart attack in his 30s
[08:01:39] <Robomot> At home with Dick Cheney
[08:02:34] <gwern> yeah, loads of people are fatter than him. but I still rather doubt he was not in any obese or overweight categories
[08:03:20] <gwern> https://www.independent.co.uk/arts-entertainment/films/news/christian-bale-weight-gain-fat-dick-cheney-diet-role-film-adam-mckay-a7941776.html
[08:03:21] <Robomot> Christian Bale explains weight gain for Dick Cheney role: 'I've just been eating a lot of pies' | The Independent | The Independent (A time-honoured method)
[08:03:53] <gwern> and of course, then he had to get rid of his cheney paunch: 'On the upcoming “CBS Sunday Morning” spotlight, Christian Bale’s “Ford v Ferrari” co-star Matt Damon seems nonplussed about Bale’s addictions to onscreen transformation. “I had a great time watching him,” Damon said of his collaborator. “He’s got an incredible monk-like discipline…he went from Dick Cheney to...
[08:03:54] <linear> being 'overweight' is usually imo surprisingly easy, e.g. at 6ft it seems to be around 185lbs
[08:03:59] <gwern> ...this guy. So he had to lose 70 pounds.”' https://www.indiewire.com/2019/11/christian-bale-weight-gain-not-getting-fat-again-1202188459/
[08:04:00] <Robomot> Christian Bale Says He’s Not Getting Fat for Roles Again | IndieWire (From "The Machinist" to "Vice," the English actor is no stranger to weight gained and lost. But, he says, those days are done.)
[08:04:35] <gwern> so if you think calling cheney fat is ludicrous...
[08:05:25] <gwern> (I mean, just look at cheney's face for the past 30 years. that is not the face of a thin or even healthy weight face)
[08:06:50] <shawwwn> it probably doesn't help that I've been eating out of boredom
[08:07:13] <shawwwn> "can't think of anything else to do. may as well go eat something"
[08:07:24] <shawwwn> speaking of...
[08:07:29] <shawwwn> pineapple yum
[08:08:18] <saturn2> i'd say donald trump changed the world
[08:09:34] <gwern> or boris
[08:09:59] <adiabatic> shawwwn: I was 6' and 245. it's not fun. lose weight, fatty
[08:10:13] <saturn2> boris johnson and boris yeltsin
[08:10:59] <linear> i find 'boredom' or similar things like procrastination as the maybe single worst variable
[08:11:13] <linear> since if i'm extremely busy eating less is very easy
[08:11:18] <saturn2> newt gingrich?
[08:11:34] <saturn2> you're in GREAT company shawwwn
[08:11:59] <shawwwn> BEST company america has ever seen
[08:12:00] <adiabatic> shawwwn: will it help if I call you fatty mc fat fat 
[08:12:22] <shawwwn> not like those other people. SAD
[08:12:32] <shawwwn> man I'm really bad at bringing trump energy to the table
[08:12:35] <shawwwn> guess that's a good thing
[08:12:55] <adiabatic> best is to have the option of trump energy whenever you want
[08:14:08] <shawwwn> I loved trump supporter energy tbh
[08:14:18] <shawwwn> I'd never partake, but they were fucking hilarious
[08:14:39] <shawwwn> the "it's fucking WEDNESDAY" quote was instantly legendary
[08:14:58] <adiabatic> The_Donald was great. It and /r/WSB were the only places on reddit where anyone was having FUN
[08:15:21] <shawwwn> https://old.reddit.com/r/SubredditDrama/comments/5ektpc/rthe_donald_accuses_the_admins_of_editing_t_ds/dadefei/
[08:15:26] <shawwwn> yeah
[08:15:33] <feepbot> notathrowaway75 comments on /r/The_Donald accuses the admins of editing T_D's comments, spez *himself* shows up in the thread and openly admits to it, gets downvoted hard instantly (#LOW ENERGY OK that was funny.)
[08:16:24] <shawwwn> GET THIS MAN A COAT
[08:16:27] <shawwwn> I miss coatbot
[08:16:31] <shawwwn> all it did was hand out coats to everyone
[08:16:40] <CoJaBo_> Why didn't he just set upvotes to MAX_INT?
[08:17:28] <saturn2> that would be crossing a line
[08:19:27] <CoJaBo_> Not if nobody graphs it =D
[08:20:44] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 265 seconds)
[08:21:56] <saturn2> what i got when i searched bing for "boris johnson body" (nsfl) https://media.zenfs.com/en/homerun/feed_manager_auto_publish_494/8a373d9958d9b7d5ff07b3b6252754f0
[08:21:56] <Robomot> image/png (1157x621; 1.1 MB)
[08:22:19] *** Joins: two2thehead (~user@124.195.202.105)
[08:23:03] <CoJaBo_> what is it
[08:23:17] <PapuaHardyNet> shawwwn: amphetamines, caffeine, nicotine, gogogo
[08:23:32] <saturn2> CoJaBo_: boris johnson next to a mummy
[08:23:51] <CoJaBo_> saturn2: wait, how would he be next to himself
[08:24:08] <saturn2> photoshop
[08:24:24] <shawwwn> PapuaHardyNet: https://www.youtube.com/watch?v=NrU-YDi8QX4&list=RDAMVMNrU-YDi8QX4&ab_channel=FemmeFatality-Topic 
[08:24:32] <nshepperd2> he is beside himself in glee
[08:24:35] <feepbot> Dr. K - YouTube
[08:25:33] <shawwwn> this song aged "ok." it didn't age badly, but not as well as I would've liked
[08:25:39] <quanticle> adiabatic: Maybe towards the end
[08:25:45] <quanticle> But in the before times, there were lots of places
[08:25:52] <quanticle> /r/watchpeopledie
[08:26:01] <quanticle> /r/darknetmarkets
[08:26:46] <PapuaHardyNet> it is sad that voat.co failed
[08:26:47] <CoJaBo_> /r/watchpeopledieinside
[08:27:21] <CoJaBo_> PapuaHardyNet: Did it ever even attempt to be anything other than a nazi version of Reddit lol
[08:27:27] <shawwwn> I was just thinking that.
[08:27:51] <shawwwn> randomly went to thedonald.win to try to remember the other site they migrated to
[08:27:53] <PapuaHardyNet> yeah hahahah not really
[08:27:54] <shawwwn> to go see some memes
[08:28:08] <shawwwn> but it's just ass-covering everywhere now
[08:28:28] <shawwwn> although there was that new subreddit which is basically WPD
[08:28:29] <CoJaBo_> Even TDW wasn't as openly-racist as voat was
[08:28:43] <shawwwn> yeah, you'll need to go back to /pol/
[08:29:00] <saturn2> /pol/ is also dead
[08:29:11] <saturn2> nothing is fun anymore
[08:29:20] <adiabatic> if it's dead, why does it leak into /fit/?
[08:29:48] <PapuaHardyNet> honestly, most places I liked are now unrecognizable. 4chan is garbage, 8ch.net is dead 8kun is crippled, uhh lainchan is okay but with low PPD, voat is dead
[08:29:52] <CoJaBo_> Also, WPD wasn't banned, just moved. We blacklist 3 of them as "terrorist propaganda and animal abuse" because, inexplicably, they aren't even quarantined
[08:30:28] <PapuaHardyNet> "Why do you like edgy places?" counter-culture is attractive
[08:31:09] <saturn2> kiwifarms is still hanging on
[08:32:47] <shawwwn> pol is indeed apparently dead https://boards.4chan.org/pol/thread/343592500
[08:32:59] <feepbot> /pol/ - /pol/, the timeline just shifted and I don't know what to do - "/pol/ - Politically Incorrect" is 4chan's board for discussing and debating politics and current events.
[08:33:37] <adiabatic> "it's the Jesuits"
[08:33:38] <shawwwn> though it's hard to blame people for larping as a timeline shifter
[08:34:45] <shawwwn> the most fun I've had recently is watching JCS videos. which is admittedly kind of sad, but whatever
[08:34:52] <shawwwn> JCS videos are like
[08:34:55] <shawwwn> fascinating
[08:35:08] <shawwwn> imagine being in a situation where all you have to do is stop talking
[08:35:20] <shawwwn> if you stop talking, you walk away with your life
[08:35:24] <shawwwn> if you keep talking, you go to prison
[08:35:29] <shawwwn> and yet everyone continues talking
[08:35:45] <shawwwn> I end up just watching the videos like "BUT WHY"
[08:36:06] <saturn2> yeah those are good videos
[08:36:13] <PapuaHardyNet> what is JCS? judicial criminal sentencing?
[08:36:23] <saturn2> jim can't swim iirc
[08:36:32] <PapuaHardyNet> oh
[08:37:12] <shawwwn> honestly they're kind of hit or miss. currently watching https://www.youtube.com/watch?v=1J2YOLQM2Yc&ab_channel=JCS-CriminalPsychology but no idea if it'll be interesting
[08:37:23] <feepbot> The Case of Michael Rafferty - YouTube
[08:37:26] <shawwwn> https://www.youtube.com/watch?v=HkRjIq8Cp2A&ab_channel=JCS-CriminalPsychology is also on the queue
[08:37:37] <feepbot> The Bizarre Case of Stephen McDaniel - YouTube
[08:37:50] <shawwwn> ah yes
[08:37:52] <shawwwn> I remember now
[08:37:56] <shawwwn> *this* was why I started watching https://www.youtube.com/watch?v=Mwt35SEeR9w&ab_channel=JCS-CriminalPsychology
[08:38:06] <feepbot> What pretending to be crazy looks like - YouTube
[08:38:31] <shawwwn> just watch from the 4min mark https://youtu.be/Mwt35SEeR9w?t=241 
[08:38:37] *** Quits: two2thehead (~user@124.195.202.105) (Quit: Leaving)
[08:38:42] <feepbot> What pretending to be crazy looks like - YouTube (Does the demon have an attorney? TCL - https://www.youtube.com/c/TRUECRIMELoserNarrator - https://www.youtube.com/user/kizzume)
[08:41:13] <saturn2> my favorite one is jeff https://www.youtube.com/watch?v=9x2NaGkl6BI
[08:41:14] <Robomot> The Legend of "Jeff" - YouTube ("How about that butterfinger you promised?"The legend continues - https://www.youtube.com/channel/UCTb9wGVamkUbf88OOmEGS0Q/Jeff's Patreon - https://www.patre...)
[08:43:42] <kiboneu> gwern: w.r.t. idiocracy yeah the humor has electrolytes at least
[08:44:03] <shawwwn> saturn2:  YES
[08:44:11] <shawwwn> omg I forgot all about jeff
[08:45:34] <kiboneu> oh these criminal psych videos are fun
[08:50:27] <Gurkenglas> > you have the right to remain silent. do you understand?
[08:50:29] <Gurkenglas> > silence
[08:50:40] <adiabatic> I'd silently nod. I'd hope
[08:53:45] <PapuaHardyNet> once I parked my car on the side of the road and laid my head on the steering wheel bitching to myself in my head about my life
[08:54:00] <quanticle> Did it help?
[08:54:23] <adiabatic> beats driving while preoccupied and crashing into something
[08:54:24] <PapuaHardyNet> the police told me to get out of the car, I was stuttering and super anxious, they thought I was on drugs, I had to call my dad to explain and bail me out because they didn't believe a word I said
[08:55:21] <PapuaHardyNet> (he had to physically walk to us, I had parked the car a few meters away from home)
[09:00:23] <feepbot> <gwern> https://www.bldgblog.com/2009/09/maunsell-towers/
[09:00:25] <feepbot> Maunsell Towers – BLDGBLOG ([Image: The Maunsell Sea Forts, photographed by Pete Speller, courtesy of Nick Sowers].I missed an amazing opportunity the other week to visit the Maunsell Towers – aka the Maunsell Sea Forts – wit…)
[09:05:23] <feepbot> <gwern> https://typographica.org/typeface-reviews/bc-brief/ totally unreadable
[09:05:25] <feepbot> BC Brief – Typographica (The most efficient way to get from one point to another is typically via a straight line. The quickest route is not necessarily the most interesting one, though. Luckily, pragmatism and speed are not everyone’s main aspirations. Case in point: BC Brief by Czech designer [snip])
[09:07:44] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Remote host closed the connection)
[09:10:24] <feepbot> <gwern> https://typographica.org/typeface-reviews/minerale/ ok that one's cool
[09:10:25] <feepbot> Minérale – Typographica (What originally caught my eye with Minérale was the way exterior outlines transform into interior outlines, particularly in the round characters. This concept is most intriguing in the M and N, not only because of the play between spaces, but also because it flies in th [snip])
[09:15:24] <feepbot> <gwern> https://typographica.org/typeface-reviews/calcula/ ooh, an interlock
[09:15:25] <feepbot> Calcula – Typographica (If typography is writing with preformed and reusable letters (or, to put it more conceptually, with the instructions for making those letters) that can be combined and recombined into arbitrary texts, then there is no aspect of typography that hasn’t been challenged, und [snip])
[09:18:28] * shawwwn wonders what a quanticle would represent if it were a unit of measurement
[09:22:14] <Obormot\Arcturus> I don't like Minerale
[09:22:31] <Obormot\Arcturus> I don't like Calcula either
[09:22:49] <adiabatic> Minerale is strongly flavored and strong flavors are good but I don't like it
[09:23:24] <adiabatic> Calcula is _interesting_
[09:28:25] <feepbot> <gwern> https://typographica.org/typeface-reviews/digestive/ more body [text] horror
[09:28:27] <feepbot> Digestive – Typographica ("Something can be good, or it can be original; it can rarely be both.” That’s a saying I’ve heard attributed to Matthew Carter, without being able to pinpoint the source. In any event, Digestive distinctly qualifies as both. It joins a tiny club of original display [snip])
[09:29:48] <PapuaHardyNet> "A typeface full of circumvolutions that evokes both bodily fluids and Dark Ages. The drippingly sexual vibe is the cherry on top."
[09:30:00] <PlanckWalk> Holy fuck that is a bad typeface.
[09:30:05] <PapuaHardyNet> what? Digestive just looks trippy. People read anything they want to in fonts these days
[09:31:16] <PlanckWalk> On a scale from 0 to 100 for legibility it rates what, a 3?
[09:33:47] <PlanckWalk> I mean sure, there are artistic uses for something that barely qualifies as text, but really?
[09:34:52] <PlanckWalk> I've seen replacements of English with fictional alphabets that were easier to read.
[09:39:54] <feepbot> <gwern> https://typographica.org/typeface-reviews/bitcount/
[09:39:55] <feepbot> Bitcount – Typographica (In an era of ever-higher screen resolutions, Petr van Blokland has released a hymn to pixel-shaped letters on coarse grids&thinsp;—&thinsp;a programmatic system for a playful design approach. A little over a year ago, I purchased a copy of Letters in studie, a booklet a [snip])
[09:42:11] <Obormot\Arcturus> Lame and lame
[09:42:29] <shawwwn> mind asplode https://news.ycombinator.com/item?id=28885442
[09:42:40] <feepbot> Andreessen Horowitz (known as "a16z"). I guess they don’t count the space? That ... | Hacker News
[09:44:53] <PapuaHardyNet> open source finance is cryptocurrency
[09:49:54] <feepbot> <gwern> https://typographica.org/typeface-reviews/brutal/
[09:49:55] <feepbot> Brutal – Typographica (Quite simply, I like Brutal because it is different. It is a refreshing change from the plethora of sans serifs and scripts that have dominated type design for over a decade. It is a refreshing change from the endless attempts to dig into the past to find undiscovered typef [snip])
[09:54:54] <feepbot> <gwern> https://typographica.org/typeface-reviews/respira-black/
[09:54:55] <feepbot> Respira Black – Typographica ("Respira” means "breathe” in Spanish. And Respira Black is a dashing, modern-looking blackletter released by Sharp Type on Earth Day (April 22), 2017. Whether designer Lucas Sharp named it this way for its bold, uncluttered glyph design or because all proceeds ar [snip])
[09:55:50] <quanticle> Should have called it Brvtal
[09:56:03] <quanticle> Retvrn to Brvtal
[09:57:26] <Obormot\Arcturus> "I like Brutal because it is different. It is a refreshing change" ... no! Fuck you! This novelty fetish is the death of good design
[09:59:11] <nshepperd2> a refreshing change from being able to read, perhaps
[09:59:51] <quanticle> Reading is overrated
[09:59:57] <quanticle> DESIGN IS LAW
[10:01:40] <Obormot\Arcturus> https://www.greaterwrong.com/posts/XPwEptSSFRCnfHqFk/zoe-curzi-s-experience-with-leverage-research#comment-7qARYThqnP7sCCMh2 
[10:01:43] <nshepperd2> ah i see, innovation in typeface design is actually a secret plan to retvrn to illiteracy
[10:01:43] <Robomot> Zoe Curzi's Experience with Leverage Research - LessWrong 2.0 viewer [Ruby 16 Oct 2021 5:21 UTC 15 pointsParentI interacted with Leverage some over the years …]
[10:02:03] <Obormot\Arcturus> I guess it's not hard to intimidate people when they're so weak and cowardly
[10:04:47] <quanticle> nshepperd2: Related: https://www.datasecretslox.com/index.php/topic,4724.msg166771.html#msg166771
[10:04:49] <Robomot> Legal Speak (Legal Speak)
[10:06:51] <nshepperd2> quanticle: lmao
[10:09:13] <quanticle> Abandon civilization. Adopt illegible typefaces. Retvrn to monke
[10:13:55] <nshepperd2> Obormot\Arcturus: this whole thing is so weird
[10:14:12] <nshepperd2> how was it not immediately obvious to everyone that leverage is dumb and stupid
[10:14:49] <nshepperd2> what dimension were all these supposed lesswrongers living in
[10:15:10] <saturn2> ruby is now the head of lesswrong? he seemed like one of the worst mods :(
[10:16:10] <quanticle> nshepperd2: Here's the thing: there are a lot of people who really really want to be rationalists, but are *terrible* at math
[10:16:41] <quanticle> And Leverage is like, "Don't worry, you don't need to do math, we're going to do *research* and build better *social institutions*. No math required!"
[10:16:52] <Obormot\Arcturus> saturn2: Agreed but it could be worse... they could've hired Valentine
[10:16:58] <quanticle> And these people sign up, because lol, what else are they going to do?
[10:17:04] <adiabatic> quanticle: what are the different levels of rationality you can get to that are gated by math amounts and what are the math amounts
[10:17:34] <adiabatic> I would updoot that post on GW, fwiw
[10:17:50] <Obormot\Arcturus> Gate 1: assignment
[10:17:52] <saturn2> nshepperd2: i guess if you went to the in-person parties you probably got a different impression than reading what was posted on LW
[10:17:53] <Obormot\Arcturus> Gate 2: recursion
[10:18:00] <quanticle> adiabatic: It's not so much the levels of rationality as the fact that people really want to feel like they're contributing, but unfortunately the only actual tangible "rationality" projects are 1) AI and 2) AI safety and both of those require math.
[10:18:01] <Obormot\Arcturus> Gate 3... wait, that's for programming
[10:18:31] <quanticle> So Leverage hijacks that impulse
[10:18:42] <quanticle> And then it's the usual cult-grooming tactics
[10:19:23] <quanticle> Secret knowledge, incredibly hierarchical structure, only the founder is capable of accessing the truth, we'll take over the world, all very very standard
[10:19:26] <saturn2> you can do kevin simler type stuff but that's even harder than math
[10:20:12] <Obormot\Arcturus> But yeah quanticle is basically right. I mean, take that Zoe person who posted the thing recently, right
[10:20:54] <quanticle> saturn2: Is Kevin Simler the Melting Asphalt guy?
[10:21:00] <saturn2> yes
[10:21:01] <Obormot\Arcturus> And like I said before, I don't mean to diss her, really, she does not seem like a bad person at all, but she's a great example
[10:21:03] <Obormot\Arcturus> She's like
[10:21:08] <Obormot\Arcturus> An actor? Or something?
[10:21:25] <quanticle> Yeah, she's a failed stage actress
[10:21:30] <quanticle> Living in New York, as one does
[10:22:06] <Obormot\Arcturus> Right, and, like... obviously she's *almost certainly* gonna have nothing to contribute to this sort of thing.
[10:24:46] <quanticle> HPMoR and its consequences have been a disaster for the rationalist race
[10:25:10] <PapuaHardyNet> 14 words, but replace "white" with "rationalist"
[10:25:18] <saturn2> man, ruby is such a huge coward. the contempt i feel for him has increased massively
[10:25:43] <PapuaHardyNet> https://palladiummag.com/2020/06/24/singapore-is-failing-at-digital-sovereignty/
[10:25:44] <Robomot> Singapore Is Failing at Digital Sovereignty – Palladium (Singapore has been held up as a model of governance. But with American political culture threatening its institutions, China’s digital sovereignty may be the strategy that endures.)
[10:26:00] <quanticle> PapuaHardyNet: What? No, I'm quoting the Unabomber, not white supremacists
[10:26:44] <PapuaHardyNet> huh? oh!
[10:26:56] <adiabatic> reminds me that there's a Robin DiAngelo quote that's also race-themed and 14 words
[10:27:14] <quanticle> "The industrial revolution and its consequences have been a disaster for the human race" <-- original
[10:27:33] <adiabatic> there's got to be lots of underfamous sets of 14 words from different authors that are interesting in similar ways
[10:27:58] <PapuaHardyNet> funny, that's also 14 words
[10:28:09] <quanticle> Yeah, I didn't realize until I counted
[10:28:19] <quanticle> It's 14 words, but it's not *the* 14 words
[10:28:56] <PapuaHardyNet> yeah
[10:29:21] <nshepperd2> adiabatic: "it is crucial for white people to recognise and acknowledge our collective racial experience"
[10:29:30] <adiabatic> nshepperd2: tytytytyty
[10:29:57] <Obormot\Arcturus> Wait what? That's not the 14 words
[10:30:05] <adiabatic> Obormot\Arcturus: these are Robin DiAngelo's
[10:30:16] <Obormot\Gaia> oh.
[10:30:33] <saturn2> new 14 words just dropped
[10:30:46] <Obormot\Gaia> These patch notes are getting wilder with each version
[10:30:58] <quanticle> Anyway, my original point is that by writing HPMoR, Eliezer attracted a bunch of people who really had no skills. And while there were some people in there, I'm sure, who were capable of developing the necessary mathematical background to meaningfully contribute to AI research, the vast majority either fell into postrat woo or, worse, got sucked into Leverage.
[10:31:07] <nshepperd2> i feel diangelo's really keep to the spirit of the original though
[10:32:02] <quanticle> saturn2: Re: ruby, I know hardly anything about them. What do you mean when you refer to their cowardice?
[10:32:12] <ivan> you have to be pretty enlightened to understand postrat woo
[10:32:19] <Obormot\Gaia> saturn2: Anyway, yeah, this is what I meant. If this is who they're dealing with, what wonder that Leverage has been able to intimidate everyone into silence?
[10:32:30] <saturn2> quanticle: the comment obormot linked above re leverage
[10:33:14] <PapuaHardyNet> comment: https://www.greaterwrong.com/posts/XPwEptSSFRCnfHqFk/zoe-curzi-s-experience-with-leverage-research#comment-7qARYThqnP7sCCMh2
[10:33:16] <Robomot> Zoe Curzi's Experience with Leverage Research - LessWrong 2.0 viewer [Ruby 16 Oct 2021 5:21 UTC 20 pointsParentI interacted with Leverage some over the years …]
[10:34:17] <quanticle> >>IMO is that we should tolerate some impropriety for the greater good
[10:34:19] <quanticle> > I agree
[10:34:20] <PapuaHardyNet> "I predict that if I do so, I’ll be placed on the list of adversaries."
[10:34:21] <quanticle> Lmao did they really just go, "Yep, that sounds reasonable," when someone threw a comic book villain line at them?
[10:34:27] <PapuaHardyNet> who writes like this in public
[10:34:42] <quanticle> People whose entire lives have been a LARP
[10:35:47] <nshepperd2> the greater good! [the greater good]
[10:36:20] <quanticle> God, just reading that just makes me want to burn all of LessWrong down
[10:37:19] <quanticle> Like, if Eliezer's posts on the futility of "rational irrationality" didn't convince them, and Scott's posts on how truth is the one principle that must not be compromised didn't convince them, there's really no hope, is there?
[10:38:09] <quanticle> The only good thing is that, unlike the wokists rationalists are hilariously ineffective
[10:38:14] <PapuaHardyNet> "Former rationalists clearing their homes of bad energy using crystals." -- zoe's post
[10:38:36] <PapuaHardyNet> "I personally prayed for hours most nights for months to rid myself of specific “demons” I felt I’d picked up from other members of Leverage."
[10:38:48] <quanticle> But... isn't that what we said about wokists twenty years ago? Ah, intersectional oppression theory is an obscure academic mode of analysis. It'll never survive in the "real world"
[10:38:51] <quanticle> And here we are
[10:40:39] <PapuaHardyNet> how is Geoff so much better at culting than Yudkowsky?
[10:41:59] <PapuaHardyNet> I see - it isn't that Geoff is better - it is that Yud didn't optimize for culting, unlike Geoff
[10:42:11] <PapuaHardyNet> Geoff specifically targetted people vulnerable to culting
[10:43:10] <quanticle> Yes. Yudkowsky didn't try to build a cult, it just sort of happened, because he wrote a bunch of stuff that had happenstance appeal to the sort of people who are susceptible to beliefs in secret knowledge.
[10:43:36] <quanticle> I think namespace talked about this a while ago
[10:44:18] <quanticle> The fundamental flaw isn't the fact that these people are overly trusting or weak willed or whatever. The fundamental flaw is that they believe you can get something for nothing, if only you can figure out the "one weird trick"
[10:44:33] <kiboneu> larping rationality
[10:44:47] <shawwwn> lol at rationality larping
[10:45:03] <shawwwn> that's the best description for AGI believers
[10:45:20] <shawwwn> it may as well be a ren faire 
[10:45:36] <saturn2> yud only ever wanted to raise enough donations that he could sit in a basement doing math all day
[10:45:43] <quanticle> ^
[10:45:45] <kiboneu> yeah 
[10:45:57] <kiboneu> can't blame him
[10:46:36] <quanticle> And in retrospect, he might have been better off going to work on Wall Street for a few years, retiring as a millionaire at the age of like 40 and then spending the rest of his life doing math.
[10:46:55] <nshepperd2> sigh, i forgot to change my name in the hidden option that gmail uses for that instead of the global google account name
[10:47:10] <nshepperd2> glad i don't send many emails
[10:47:18] <quanticle> So your e-mails are going out with your deadname or what?
[10:47:22] <nshepperd2> yeah
[10:47:45] <PapuaHardyNet> nshepperd2: did you legally change your name yet? how hard was it?
[10:47:47] <adiabatic> do you think of it as your deadname or your old name
[10:47:54] <quanticle> It's okay, the only people who still use e-mail are the kind of old people who would have insisted on calling you by your deadname regardless.
[10:47:56] <kiboneu> shawwwn: i mean, the way i mean to draw the analogy is related to people adopting an identity in the way quanticle / namespace describe; i don't really understand where you see AGI believers coming into this
[10:48:11] <shawwwn> oh, it's the same thing
[10:48:17] <nshepperd2> PapuaHardyNet: haven't yet. probably gonna look into it soon
[10:48:23] <shawwwn> AGI is central to an AGI believer's identity, by definition
[10:48:45] <shawwwn> and of course, rationality as at the center of their reasons for maintaining that it isn't just a religious belief
[10:49:08] <nshepperd2> adiabatic: dunno, i never really saw it as my name i guess
[10:49:30] <nshepperd2> quanticle: lol :S
[10:49:34] <shawwwn> yet at the end of the day, nothing changes. we go about our jobs and Wait For AGI To Come
[10:49:36] <adiabatic> nshepperd2: like, just _a_ name that people use, that isn't particularly _you_?
[10:49:39] <shawwwn> just like larping.
[10:49:44] <shawwwn> it affects nothing in the real world
[10:50:00] <nshepperd2> adiabatic: yeah basically
[10:50:09] <adiabatic> sounds like me and mine
[10:50:31] <PapuaHardyNet> shawwwn: what? are you saying that because black swan events are rare, they don't affect reality or belief in their possibility doesn't affect reality?
[10:50:32] * quanticle identifies more with quanticle than he does with his real name
[10:50:32] <kiboneu> shawwwn: it sounds like an identity you've applied to someone with certain traits and beliefs rather than strictly an identity someone ascribes to themselves
[10:50:50] <quanticle> Kind of like a Batman/Bruce Wayne thing, I suppose
[10:51:23] <Obormot\Arcturus> Wait what's this dissing of email
[10:51:28] <Obormot\Arcturus> I disapprove
[10:51:32] <PapuaHardyNet> quanticle: wouldn't you rather be a rich billionaire than a LARPing bat?
[10:51:32] <Obormot\Arcturus> Lots of people use email!
[10:51:35] <adiabatic> Obormot\Arcturus: it's the dissing of people who use e-mail
[10:51:40] <Obormot\Arcturus> I use email! >:|
[10:51:47] <adiabatic> I use email
[10:51:51] <shawwwn> PapuaHardyNet: the Rapture is also a black swan event. Would you say that believing in it -- being totally convinced it's just a matter of time -- isn't a religious belief?
[10:52:10] <shawwwn> because when you s/Rapture/AGI, it's nearly identical
[10:52:11] <quanticle> PapuaHardyNet: I mean, sure, but it's stated repeatedly in multiple iterations of the Batman franchise that Batman refers to himself as Batman, not "Bruce"
[10:52:37] <PapuaHardyNet> shawwwn: I see, you equate AGI with singularity
[10:52:38] <quanticle> So who am I to argue with that?
[10:52:38] <nshepperd2> PapuaHardyNet: lmao i just checked and there's an online form for it, which is broken
[10:53:00] <shawwwn> PapuaHardyNet: nah, just "AI companions" in general.
[10:53:15] <kiboneu> i'm still trying to understand what group of people you're referring to
[10:53:17] <shawwwn> "generalized SAT solvers" / "amazon mechanical turk solvers", etc.
[10:53:24] <PapuaHardyNet> nshep: ikr, you get some dumb name your parents assign you and you are stuck with it for life. the legal system sucks.
[10:53:46] <adiabatic> PapuaHardyNet: if you don't like yours, change it. I assume Australia isn't _that_ foreign of a country
[10:53:51] <shawwwn> kiboneu: I'm referring to any group of people that may feel offended at the idea that AGI is fundamentally impossible. If it bothers them, that's who I'm referring to, because AGI is a part of their identity.
[10:53:54] <kiboneu> PapuaHardyNet: yeah my name sucked until university
[10:53:57] <adiabatic> it's just a PITA to change
[10:54:19] <nshepperd2> the server isn't responding to pings
[10:54:30] <PapuaHardyNet> shawwwn: we'll hit AI companions within 10 years
[10:54:35] <nshepperd2> i bet this is one of those things where they *shut it down* outside of business hours
[10:54:39] <adiabatic> in general what you'd be doing has been done before by hundreds of thousands of freshly-married women
[10:54:44] <quanticle> I've told this story before, but one of the reasons my brother has the name that he has is because I vociferously argued against my parents' first choice
[10:54:44] <nshepperd2> bc government is government
[10:54:47] <adiabatic> so it's not all _that_ odd
[10:54:47] <shawwwn> No one feels upset at the idea that teleporters (in the star trek sense) are impossible, and that it'd be a waste of time to work on it. But s/teleporters/AGI/, and people lose their minds
[10:55:03] <quanticle> On the grounds that it would be difficult for Americans to pronounce
[10:55:13] <adiabatic> smart!
[10:55:48] <PapuaHardyNet> quanticle: good call man
[10:56:00] <kiboneu> shawwwn: i see. i guess the way you feel about them is the way i feel about anyone who's attached to their beliefs. when someone introduces the kind of specificity that you do, i question why it's there. and so out of the blue, you know
[10:56:18] <quanticle> Yeah, having a 9 year age gap means that your big bro is looking out for you from the very beginning lol
[10:56:33] <shawwwn> PapuaHardyNet: would you care to wager? https://twitter.com/theshawwn/status/1446752796641042434
[10:56:35] <|dbotdan> Shawn Presser (@theshawwn, 2021-10-09 08:22): ‘I've been formulating a 15-year AGI wager (AGI won't exist): if I lose, I transfer my SWE life savings. If I win, the counterparty doubles it. | But how do you decide who won? You'd need a precise definition of AGI. | Answer: Mechanical Turk won't need humans.’
[10:57:07] <shawwwn> kiboneu: hm, that's interesting. why is specificity a negative thing?
[10:58:02] <PapuaHardyNet> shawwwn: what is your definition of AGI?
[10:58:19] <nshepperd2> idk why you keep asking people to make that wager, it's objectively bad
[10:58:23] <shawwwn> PapuaHardyNet: that's precisely why the bet has been so difficult to propose. :)
[10:59:02] <shawwwn> I've spent many weeks thinking about it. "Humans are no longer needed for most Amazon Mechanical Turk problems" is the most precise thing that doesn't collapse, so far
[10:59:19] <shawwwn> because other answers are either fuzzy and unmeasurable, or they're not tied to economic activity and hence speculative in nature
[10:59:21] <PapuaHardyNet> shawwwn: think about this: a crowdsourced reinforcement learning AI that is basically the Oracle of Delphi but for modern times
[10:59:23] <rsaarelm> shawwwn: Your bet is very hyperbolic, why not offer to bet something on the order of $1000?
[10:59:37] <kiboneu> shawwwn: it's not a negative thing. what someone says and how they say it tell me about how they think. I imagine you do this too? and one of the ways to infer how someone sees the world is through the kinds of specific details someone chooses to express and fixate on
[11:00:01] <shawwwn> it's not hyperbolic if I'm willing to wager that much. The point of the bet is to show that no one is so convinced that AGI is going to happen that they'll take up the other side of the bet
[11:00:10] <PapuaHardyNet> (the oracle of delphi is an idea that popped into my head, that is completely unrelated to our current discussion)
[11:00:28] <rsaarelm> No, I mean it's socially bad that you propose to bet all your wealth and basically a signal not to engage with you on it.
[11:00:45] <quanticle> Not completely unrelated. GPT-3 and the Oracle of Delphi share many similarities
[11:01:06] <shawwwn> ah yes, merely being willing to wager one's wealth on an idea is a social signal not to engage with that person
[11:01:23] <shawwwn> the european view is quite popular in europe
[11:01:29] <rsaarelm> If you want to do scientific betting and get people engage you on it, you don't want to frame it in a way that sounds like you might blow your brains out when you lose.
[11:01:33] <nshepperd2> well you'd have to be extremely convinced to take up a bet where 1. you commit yourself to basically unlimited risk depending how much shawwwn's life savings end up being 2. you have no guarantee of actually receiving anything of value whatsoever in the instance where you win and the world is rewritten by AI
[11:02:30] <shawwwn> nshepperd2: so far, the best counterargument I've thought of to that is "you'll help make AGI happen, the more people you convince to make AGI happen." Placing this wager is evidence of your convictions
[11:02:36] <kiboneu> shawwwn: and I address this, to be clear, because people don't often mean what they say so i end doing a lot of fill-in-the-boxes for them. so when it strikes me as out-of-the-blue when someone mentions a specific detail or a sub-group, i wonder what they are actually trying to express
[11:02:43] <kiboneu> but i don't wonder anymore
[11:02:47] <nshepperd2> that's not a counterargument
[11:03:03] <shawwwn> I've also considered making it a fixed sum wager for the other side (e.g. $10k over 15 years), and that if I lose, I'll still transfer everything.
[11:03:03] <rsaarelm> In general, the scientific bets people actually do are for token sums, not something that will actually significantly affect the finances of the people participating.
[11:03:17] <quanticle> Also, beyond a certain point, the counterparty risk makes odds of winning irrelevant. If I have a 95% chance of winning a bet for a million dollars, but only a 0.1% chance of the my counterparty actually giving the million after I've won, it's a bad bet.
[11:03:20] <PapuaHardyNet> when the robot uprising occurs, shawn will be the first to go
[11:03:31] <shawwwn> ^
[11:03:34] <PapuaHardyNet> well, second, after roko
[11:03:44] <shawwwn> I'll be laughing like the joker as I go too
[11:03:57] <nshepperd2> you're not paying any attention to the fact that taking this bet is irrational
[11:04:22] <nshepperd2> it wouldn't be evidence of convictions so much as evidence of being clueless and innumerate
[11:04:53] <shawwwn> hmm, I don't think I've ever seen you so heated about something. You're cute when you're passionate
[11:05:08] <shawwwn> there's an easy way to counter that: would you take the bet if you only had to risk $100?
[11:05:23] <shawwwn> I think most people would take the chance at me being wrong and them getting my life savings.
[11:05:25] <nshepperd2> no
[11:05:30] <shawwwn> you're not most people
[11:05:42] <kiboneu> you're just not making a lot of sense
[11:06:01] <nshepperd2> bc there's still no reason to expect that i'd receive anything of value if i win
[11:06:18] <shawwwn> the fact that people aren't willing to lose anything is a strong signal that they don't really believe it's going to happen.
[11:06:49] <shawwwn> if you really believed it, you'd be willing to risk it. Risk is a facet of every other aspect of life
[11:06:51] <nshepperd2> AGI will, for all intents and purposes, instantly rewrite the fabric of the universe
[11:07:01] <nshepperd2> as far as humans are concerned
[11:07:11] <shawwwn> we're in agreement.
[11:07:13] <nshepperd2> your life savings are likely to be entirely meaningless
[11:07:14] <quanticle> Only if it's a fast takeoff
[11:07:38] <PapuaHardyNet> nshepperd2: will AGI break cryptocurrency? if not, shawwwn should make a smart contract
[11:07:45] <shawwwn> the point is to illustrate that these ideas are equal to all the ideas in the bible. The Rapture would also make my life savings meaningless
[11:07:49] <nshepperd2> PapuaHardyNet: yes
[11:08:01] <PapuaHardyNet> huh? how can AGI break math
[11:08:10] <PapuaHardyNet> ohhh, P != NP isn't proven yet
[11:08:23] <PlanckWalk> Cryptocurrency is not just math
[11:08:26] <nshepperd2> no crypto is proven secure in any solid sense
[11:08:38] <kiboneu> ugh
[11:08:41] <nshepperd2> and also it won't be worth anything if everyone's dead
[11:08:52] <nshepperd2> or a bunch of other possible scenarios
[11:09:03] <PlanckWalk> There's whole piles of external social and technological apparatus around it *even if* it were proven secure, which it isn't.
[11:09:17] <quanticle> nshepperd2: Exponential growth doesn't necessarily mean the knee in the graph is imminent. Human energy usage has been rising exponentially for literally tens of thousands of years, but for the majority of that time it was indistiguishable from linear growth.
[11:09:20] <PapuaHardyNet> yeah, I keep forgetting that money is simply a proxy for social value
[11:09:26] <quanticle> What if AGI is like that?
[11:09:52] <quanticle> We get AGI, but it's kind of meh for a few centuries, and then in the space of a decade superintelligence happens?
[11:10:02] <PlanckWalk> There are pretty darn good reasons to expect it not to be, but I hope you're right.
[11:10:15] <PlanckWalk> I'm not even talking about superintelligence
[11:10:25] <nshepperd2> quanticle: eh
[11:10:27] <PlanckWalk> Just human-equivalent or maybe very slightly better AGI
[11:10:56] <quanticle> Right, I was talking about nshepperd2's assertion that an AGI will "instantly rewrite the fabric of the universe"
[11:11:04] <PlanckWalk> Ah okay
[11:11:18] <nshepperd2> shawwwn: no your point was to demonstrate that people 'don't really believe that AGI is going to happen'. you're not engaging with what they actually believe if you ignore the consequences of AGI
[11:11:21] <PlanckWalk> I do think it will pretty darn rapidly rewrite the fabric of our economy and society
[11:11:41] <PlanckWalk> (If it arisies)
[11:11:46] <quanticle> It's quite possible that we'll have an AGI. It'll take up a datacenter or five. It'll be uneconomical as compared with human beings for a long time.
[11:11:49] <quanticle> And then one day it won't
[11:11:56] <kiboneu> capitalism is the womb of agi
[11:12:00] <shawwwn> nshepperd2: it was pretty surprising that the anger manifests itself as people saying that I'm not serious or that I'm not engaging with the ideas
[11:12:15] <shawwwn> showing that it's equal to religious belief is the whole point
[11:12:18] <quanticle> But that day may not come for some time
[11:12:23] <PlanckWalk> shawwwn: I'm not at all angry, and don't even think AGI is inevitable, but I do agree that you're not engaging.
[11:12:31] <shawwwn> quanticle: yep. Just like the Rapture.
[11:12:38] <nshepperd2> ok whatever
[11:13:04] <PlanckWalk> It's unfortunate that you can't make money off it, but really, tough.
[11:13:20] <kiboneu> how can you tell anger on irc if it's not in all caps
[11:13:27] <shawwwn> the money is irrelevant. the goal is to show that people aren't willing to make any kind of personal sacrifice for their beliefs
[11:13:38] <shawwwn> and that therefore those beliefs should be weighed accordingly
[11:13:49] <nshepperd2> you failed at their goal
[11:13:49] <adiabatic> kiboneu: I can call you gamer words without even touching any modifier keys and tell you to kill yourself
[11:13:56] <nshepperd2> *that goal
[11:14:17] <nshepperd2> bc people would only accept that bet if they had different beliefs
[11:14:29] <saturn2> quanticle: i see no reason to think it's likely to take centuries
[11:14:34] <nshepperd2> like that AGI will happen, and *additionally* that it won't matter
[11:14:51] <shawwwn> nshepperd2: I think you're the one who isn't engaging with the thesis that it's equal to a religious belief, because you know you'd lose that argument if you made a serious attempt at analyzing the differences and realizing there were none.
[11:15:02] <nshepperd2> that doesn't even mean anything
[11:15:03] <kiboneu> adiabatic: yeah sure
[11:15:24] <quanticle> saturn2: Yeah, maybe "centuries" is a bit of a stretch, but I don't agree with some of the assertions that it'll take hours or minutes either
[11:15:30] <nshepperd2> you're purporting to show that people won't make a sacrifice for their beliefs, by asking them to make a sacrifice for a different unrelated beliefe
[11:15:40] <quanticle> i.e. to go from AGI to superintelligence
[11:15:41] <nshepperd2> that they don't actually hold, nor profess
[11:15:45] <saturn2> shawwwn: what if your belief that it's equal to a religious belief is also equal to a religious belief
[11:15:46] <shawwwn> nshepperd2: for you, I'm only trying to get you to focus on the religious belief aspect. Nothing more.
[11:15:51] <kiboneu> adiabatic: but i haven't sensed that happen here
[11:16:07] <shawwwn> saturn2: it is! But I'm willing to lose everything if I'm wrong about it. :)
[11:16:09] <adiabatic> kiboneu: I'm just giving a falsification by counterexample, nothing more
[11:16:09] <rsaarelm> shawwwn: I'm sort of confused whether you have an argument that AGI is impossible and you're trying to verify it or whether you're trying to show other people act inconsistent or irrational around AGI.
[11:16:20] <adiabatic> I'm going to bed
[11:16:29] <kiboneu> adiabatic: yeh. good night
[11:16:31] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[11:16:31] <PlanckWalk> shawwwn: I thikn you're conflating an enourmous range of expectations into one "superintelligent AGI is imminent" model of belief.
[11:16:49] <PapuaHardyNet> shawwwn is laughing as he has baited the entire channel to respond
[11:17:01] <nshepperd2> atheism is a religion
[11:17:01] <PapuaHardyNet> with one line
[11:17:05] <kiboneu> yeah honestly can we return from this tangent
[11:17:16] <kiboneu> i prefer the larping convo
[11:17:16] <quanticle> I think there will be sufficient time to settle bets re: AGI before the AGI eats the world or whatever
[11:17:48] <shawwwn> yeah, so, as you can see, this is a topic that simply pisses off all the rationalists, because AGI is so central to their identity that they won't even stop to question whether it's identical to believing that Jesus might descend from heaven one day
[11:17:58] <shawwwn> yes, there would be
[11:18:00] <nshepperd2> tbh i also think making sacrifices for beliefs is dumb
[11:18:22] <nshepperd2> beliefs are for making beneficial decisions, not for flag-waving
[11:18:28] <shawwwn> then why should I pay any attention to your belief, if you believe in it so little that you're not willing to risk anything if you're wrong?
[11:18:43] <nshepperd2> i don't need to believe in my beliefs
[11:18:49] <nshepperd2> i just need to maximise expected utility
[11:18:54] <shawwwn> it would be a beneficial decision to believe in Jesus in case the rapture happens, otherwise you'll go to hell.
[11:19:05] <shawwwn> I don't understand why people feel like that's "bait" or "not engaging"
[11:19:10] <shawwwn> it seems completely identical from where I'm sitting.
[11:19:11] <kiboneu> shawwwn i just don't care, you're already applying all sorts of beliefs to your beliefs about other peoples' beliefs and how they are responding to what you think addresses their beliefs
[11:19:24] <kiboneu> it's not a game that's fun to play
[11:19:32] <shawwwn> exactly! it's larping
[11:19:38] <shawwwn> the moment someone steps out of character, it becomes un-fu 
[11:19:42] <shawwwn> un-fuuuuuuuuuu
[11:19:44] <shawwwn> n.
[11:19:51] <shawwwn> and it's all about the fun
[11:20:09] <saturn2> (string= "AGI" "jesus") => NIL ;myth busted
[11:20:17] <kiboneu> i mean, you can make all sorts of verbal associations that have nothing to do with meaning
[11:20:25] <kiboneu> it's good for convincing dumb people that you are right
[11:20:44] <quanticle> I think the real question is
[11:20:46] <kiboneu> and i suppose that's a strategy that might be good enough to survive
[11:20:51] <quanticle> How is this conversation increasing our vitality?
[11:20:56] <kiboneu> lol
[11:21:02] <shawwwn> you could also form a counterargument to the core ideas. But I suppose smarminess is a lot easier
[11:21:03] <nshepperd2> hmm
[11:21:44] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[11:21:47] <kiboneu> you can't address core arguments without addressing the measuring equipment
[11:21:49] <shawwwn> adiabatic: goodnight!
[11:22:07] <PapuaHardyNet> vitality may not be increased, but our testosterone levels sure have
[11:22:12] <nshepperd2> shawwwn: winning your life savings during the apocalypse wouldn't be a beneficial decision though
[11:22:18] <nshepperd2> so why bother
[11:22:24] <saturn2> it's not a question you can settle with a few lines on IRC
[11:22:58] <shawwwn> forget the life savings. That was a means to an end. The real argument is "why go through life with this specific religious belief?" -- and step one is to even get people to admit to themselves that it *is* a religious belief at all
[11:23:18] <PlanckWalk> shawwwn: Exactly *which* belief are you talking about?
[11:23:20] <PlanckWalk> Be specific.
[11:23:22] <nshepperd2> i don't wanna
[11:23:28] <enterprisey> this channel reeeally gets into it sometimes
[11:23:49] <PapuaHardyNet> we got you to post though - so we win enterprisey
[11:24:03] <enterprisey> touché!
[11:24:09] <shawwwn> PlanckWalk: that's precisely what I tried to do: https://twitter.com/theshawwn/status/1446736109141102598 But no amount of exactness will feel satisfying 
[11:24:09] <kiboneu> man i really want to talk about lesswrong cults
[11:24:10] <|dbotdan> Shawn Presser (@theshawwn, 2021-10-09 07:15): ‘Yes: https://twitter.com/theshawwn/status/1446734765902680066 | If less than N% of Turk problems are solved by humans in 15 years, I will agree that AGI has been invented, and declare you the victor. | What N would you agree to, though? That's a troublesome question. But perhaps we can come up with a number.’
[11:24:19] <quanticle> saturn2: Would it be out of line if I replied to that Ruby post with, "So, Ruby, what *leverage* do they have over you?"
[11:24:37] <nshepperd2> quanticle: lmao
[11:24:51] <saturn2> quanticle: i mean, he already answered that
[11:25:08] <PlanckWalk> shawwwn: I don't think anyone here has a religious belief that essentially all mechanical turk problems will be solved by computers within 15 years
[11:25:48] <kiboneu> it's just
[11:25:49] <shawwwn> the 15 is a variable.
[11:25:53] <shawwwn> feel free to substitute with "200"
[11:26:01] <kiboneu> it's kind of easy to think everyone is pissed off on irc if you're pissed off
[11:26:06] <quanticle> Well, sort of. He says that the person who was pressuring him stopped, but that he's still not going to share further details because he doesn't want to get put on an enemies list
[11:26:07] <PlanckWalk> Especially since "mechanical turk" problems are by definition those that cannot yet be economically solved by computers.
[11:26:11] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[11:26:11] <kiboneu> and vice versa
[11:26:24] <enterprisey> Heh, I also happen to think AGI isn't any time soon, but unfortunately that's just a gut feeling based on intuition for how software projects go
[11:26:24] <quanticle> So my question is, what's the big deal with being on Leverage's "enemies list"
[11:26:28] <PapuaHardyNet> imagine being the "head of LessWrong" and being so weak
[11:26:30] <quanticle> Like, what can they actually do to you?
[11:26:38] <enterprisey> I like the idea of using the percentage of MTurk problems, though
[11:26:40] <quanticle> Can they cancel you out of a job?
[11:26:43] <shawwwn> PlanckWalk: at a certain point, Amazon would shut down the API because it's no longer economically viable to keep humans in the loop.
[11:26:50] <quanticle> Can they make mean posts about you on social media?
[11:26:59] <PlanckWalk> Yeah, trouble it they might shut it down for other reasons too
[11:27:06] <PlanckWalk> trouble is*
[11:27:19] <shawwwn> sure. It was the closest approximate solution I've thought of so far. I'd love a better one
[11:27:24] <shawwwn> the others were like
[11:27:39] <shawwwn> "parents can't stop their teenagers from falling in love with AGI, and they keep demanding to marry them"
[11:27:47] <PapuaHardyNet> probably the social media thing. so CFAR called the police on sinceriously.fyi and their friend when they tried to go to CFAR to talk 
[11:27:51] <shawwwn> at that point, I'd also agree that AGI has been invented. But people already *do* do that.
[11:27:55] <PapuaHardyNet> about how they discriminate against mtfs
[11:28:01] <shawwwn> so it's really hard to get precision in this domain
[11:28:20] <quanticle> Well, that's not the same situation at all, though
[11:28:20] <Obormot\Arcturus> lol
[11:28:23] <PapuaHardyNet> perhaps something like that? lawfare is pretty powerful, especially in the hands of someone influential
[11:28:24] <quanticle> Ziz was legit crazy
[11:28:32] <saturn2> quanticle: i think it's literally just a fear of uncomfortable interactions at rationalist get-togethers
[11:28:47] <shawwwn> rationalists have the best orgies
[11:28:55] <quanticle> Ziz and co like... made actual threats and tried to blockade the entrance to the meetup
[11:29:13] <PapuaHardyNet> huh, okay, I didn't know that
[11:30:31] <shawwwn> for the record, my thoughts on AGI are "You need to literally simulate evolution, and simulating evolution is computationally intractable." I can see why it might sound like I was just sitting here shitting on beliefs with no basis
[11:30:52] <quanticle> saturn2: Goddamn, I just want to be like, "For the love of god, stop being such a goddamn pussy and say what you have to say instead of vagueposting about it"
[11:31:01] <shawwwn> it would just take energy output on the scale of an entire planet
[11:31:12] <shawwwn> and human civilization is nowhere close to that level of coordination
[11:31:13] <PapuaHardyNet> quanticle: do it (except in a more diplomatic way)
[11:31:16] <saturn2> quanticle: same
[11:31:16] <quanticle> "Or shut the fuck up"
[11:31:22] <shawwwn> so "impossible for humans" is more precise
[11:31:53] <saturn2> quanticle: it would need to be carefully worded to have any effect though
[11:32:19] <quanticle> Well, that's the thing. I don't think it'll have an effect coming from me no matter how I word it
[11:32:28] <quanticle> I'm not part of their incestuous Bay Area clique
[11:32:49] <saturn2> yet, growth mindset
[11:33:35] <quanticle> Ganesha help me
[11:33:56] <kiboneu> fishy things go on in the bay area
[11:34:01] <PapuaHardyNet> you are actually doing it? Obormot will be posting replies to your comments in an hour
[11:34:02] <kiboneu> not my circus either
[11:35:39] <quanticle> No, I'm not doing it
[11:35:40] <saturn2> shawwwn: how do you rule out other possibilities though?
[11:36:01] <quanticle> I'm dumb, but I'm not that dumb
[11:38:36] <quanticle> This whole situation reminds me of the time I asked s0ph1a about Ork supply lines in Warhammer 40k, and they said, that Orks don't need supply lines because their machines run on pure belief. You assemble a collection of junk into the shape of a tank, get a enough orks to believe that it's a tank, and boom, it's a fully working tank. You get enough rationalists to believe that Leverage has the
[11:38:38] <quanticle> power to retaliate and boom, Leverage has the power to retaliate.
[11:39:45] <PapuaHardyNet> so if you want to destroy Leverage, you need to do it outside the rationalist community
[11:39:51] <PapuaHardyNet> someone leak the drama to Vice
[11:40:05] <quanticle> Or uh... maybe Wired?
[11:40:18] <quanticle> Wait, who did the hit piece on the Damore memo?
[11:40:55] <kiboneu> i don't think attracting media attention is a good idea
[11:41:04] <kiboneu> they'll just weaponize it to sell more ads
[11:41:11] <kiboneu> whatever squeezes the most dopamine
[11:41:18] <kiboneu> and that'll usually be controversy
[11:41:23] <kiboneu> but
[11:41:30] <kiboneu> who knows how threy'll paint the drawing board
[11:41:43] <quanticle> Yeah, it's not, but it's a fun fantasy, just like burning down your house to get rid of some spiders is a fun fantasy
[11:41:48] <kiboneu> ah
[11:41:54] <s0ph1a> could only end that way
[11:41:54] <s0ph1a> srsly, that thing where Geoff was "employing" his groupies? couldn't have set it up *better* if he *wanted* to get #cancelled
[11:42:12] <kiboneu> see i keep my pests around
[11:42:39] <kiboneu> i saved a wasp from starvation in my staircase, which had a wasp nest right on the porch where it leads to
[11:42:57] <quanticle> ... why
[11:43:01] <kiboneu> truce
[11:43:09] <kiboneu> i was teaching it tit-for-tat
[11:43:12] <kiboneu> with forgiveness
[11:43:16] <quanticle> But the wasps don't honor truces
[11:43:24] <kiboneu> idk, didn't get bit!
[11:43:28] <kiboneu> :P
[11:43:32] <kiboneu> ok sure
[11:43:37] <quanticle> Stung, you mean
[11:43:40] <kiboneu> yeah
[11:43:54] <enterprisey> My apartment's accumulated a couple of spiders. I like them much more than the houseplants because they're entirely self-sufficient.
[11:43:55] <quanticle> I guess, but maybe that's just because they don't even see you as a threat
[11:44:12] <kiboneu> i'm sure their collective behavior isn't that different to begin with, yes
[11:44:15] <quanticle> enterprisey: You and Obormot will get along just splendidly
[11:44:26] <enterprisey> oh ho ho ho
[11:45:45] <PlanckWalk> shawwwn: Sorry, had to go AFK a bit.  Right, I've read that argument, but I didn't know that anyone would have evidence that leads them to bet life savings to $100 on it being *actually true*.
[11:45:47] <enterprisey> Spiders are cool, though. Pivoting slightly, I know someone who used the username "lepidoptera" (the taxonomic order of butterflies and moths), and I think it's a lovely username, together with "coleoptera" (beetles)
[11:46:22] <PlanckWalk> (Do you actually have such evidence?)
[11:46:53] <shawwwn> PlanckWalk: we exist. we were products of evolution.
[11:47:02] <PlanckWalk> Err ... yeah?
[11:47:02] <kiboneu> quanticle: i just like experimenting with animals and getting a close up to how they respond. torture is out of the question but there are more interesting things to observe in friendly / neutral environments anyway
[11:47:02] <quanticle> I think the only insects that don't creep me out are ants and bumblebees. Not the fire ants or bullet ants or whatever craziness they have in the South, but normal black ants.
[11:47:05] <PlanckWalk> And?
[11:47:17] <shawwwn> and no one is building evolution simulators. 
[11:47:25] <shawwwn> they're convinced that it's possible to bypass evolution.
[11:47:35] <PlanckWalk> I'm not asking if they've convinced.
[11:47:37] <quanticle> kiboneu: Oh, that's understandable. I observe bunnies and other wildlife in my backyard
[11:47:39] <PlanckWalk> they're*
[11:47:44] <quanticle> I saw turkeys the other day
[11:47:54] <shawwwn> PlanckWalk: sorry, what are you asking?
[11:47:55] <kiboneu> nice
[11:47:56] <quanticle> They were way more vicious looking than I thought they'd be
[11:47:56] <PlanckWalk> I"m asking why you think that's convincing evidence that it's the *only way possible*
[11:48:08] <quanticle> Turkeys have *talons*
[11:48:10] <PlanckWalk> Like, 10,000:1 convincing.
[11:48:38] <shawwwn> throughout human history, it's been exceedingly rare for inventions to happen without following some sort of model. Inventions almost never occur out of thin air. There's always prior work to build off of
[11:48:41] <enterprisey> quanticle: interesting, I've never met a turkey up-close. I knew someone who kept chickens, though. (And I've met turkey vultures up close)
[11:48:49] <shawwwn> in the case of aircraft, it was gliders, and even paper planes
[11:48:53] <quanticle> It forced me to reassess; now if it comes down to a fight, I'd much rather take on a goose than a turkey
[11:49:00] <PlanckWalk> shawwwn: But we do have a model ... us
[11:49:10] <shawwwn> yes. And we were produced by evolution. That is the model
[11:49:16] <enterprisey> quanticle: that reminds me of the survey that made the rounds about animals we could beat in a fight
[11:49:24] <shawwwn> it's the only known process by which general intelligence has been created, ever.
[11:49:29] <shawwwn> there is no other known process.
[11:49:35] <quanticle> I could probably beat the turkey in a fight, but it'd definitely score blood
[11:49:51] <enterprisey> Having worked with raptors, if I could have a pair of good ANSI safety glasses, I'm sure I could do some damage
[11:50:12] <enterprisey> people think eagles are scary but they really don't have too much control authority
[11:50:21] <kiboneu> i encountered a duck recently, very used to humans; it was in my way and i tried to quack at it and do all sorts of vocalizations. didn't quite work but then i decided to make a "beak" shape with my hand -- i certainly fixate on faces, so if i can recreate shapes that a duck would be familiar with (also, a duck not having hands will use a beak as such)
[11:50:35] <PlanckWalk> shawwwn: That seems pretty weak evidence.
[11:50:40] <kiboneu> it rapidly approached me an pecked my "beak"
[11:50:54] <PlanckWalk> But good luck with it, I hope you win your bet.
[11:50:56] <kiboneu> my companion on the walk thought it was trying to attack but
[11:51:05] <kiboneu> maybe it was trying to shake my hand?
[11:51:06] <shawwwn> PlanckWalk: it may be. But it happens to have the merit of being the strongest evidence possible, since everything else is unknown speculation
[11:51:13] <enterprisey> kiboneu: that it pecked your "beak" is pretty cute
[11:51:14] <kiboneu> or kiss me in the "beak"?
[11:51:16] <kiboneu> yeh
[11:51:26] <quanticle> Maybe! Or maybe you discovered the duck equivalent of the middle finger
[11:51:34] <quanticle> And it was like u wot m8
[11:51:37] <saturn2> kiboneu: it probably thought you were holding a piece of bread
[11:51:46] <PlanckWalk> shawwwn: Which is to say, it's still weak and not worthy of 10k:1 bets.
[11:51:54] <kiboneu> saturn2: yeah maybe desparately so
[11:51:54] <PlanckWalk> Even if it is the srongest possible so far.
[11:52:03] <kiboneu> i notice that with animals, results happen when you emulate some body-part of theirs with your hand you get interesting results
[11:52:05] <kiboneu> fiddler crabs
[11:52:16] <kiboneu> they sync with the movement of what they are observing
[11:52:31] <kiboneu> moving above them doesn't quite get them to move, but if you make a "crab" with your hands
[11:52:32] <PapuaHardyNet> it seems like I slept through a neighborhood drunken brawl
[11:52:33] <kiboneu> well
[11:52:41] <kiboneu> that's something they know how to dance with
[11:52:46] <kiboneu> that's their pattern language or whatever
[11:52:49] <PapuaHardyNet> my parents who live 10 minutes away knew about it and I didn't until they told me
[11:53:19] <quanticle> That's okay. I slept through an earthquake once
[11:53:19] <shawwwn> PlanckWalk: from my perspective, it feels identical to betting someone whether the rapture will happen, so I'm not worried. I'm mostly surprised anyone seems genuinely concerned for my well being
[11:53:19] <kiboneu> and moving one finger around doesn't quite do it either
[11:53:34] <shawwwn> I'm pretty sure lots of people here would be gleefully happy if I were destitute
[11:53:36] <kiboneu> quanticle: yeah i probably insulted the duck in all sorts of ways
[11:53:47] <kiboneu> absolutely defacated on this duck's culture
[11:53:50] <enterprisey> I wonder what duck profanity looks like
[11:53:58] <kiboneu> and i wound't even know it
[11:54:03] <kiboneu> being a big dumb human
[11:54:18] <kiboneu> thinking the the world revolves around humans or whatever
[11:54:20] <PapuaHardyNet> shawwwn: I highly doubt that last line of yours
[11:54:21] <kiboneu> thinking about parking
[11:54:34] <shawwwn> PapuaHardyNet: lol, obormot would be over the moon
[11:54:49] <kiboneu> like, imagine how much a duck would have to catch up with, just to imagine the trivial minutae of every day life
[11:54:58] <kiboneu> "parking"? "taxes"? wtf
[11:54:59] <quanticle> Yeah, like that video where the human meows back at the cat and the cat looks like you insulted its family in the most horrible way
[11:55:09] <kiboneu> lol
[11:55:18] <kiboneu> i mean like
[11:55:20] <shawwwn> gwern would be like "I told you so" and all of his followers like catern and feep would be thumbing their noses
[11:55:31] <kiboneu> we step on ant colonies without even noticing
[11:55:53] <kiboneu> i could just be thinking about lunch and i've just killed generations of queen ants or w/e
[11:55:59] <quanticle> Eh, we step on the entrances of ant colonies
[11:56:04] <kiboneu> killed 100s destroyed their home
[11:56:04] <enterprisey> I don't observe the ant colonies as much as I'd like because I'm worried about being judged in public :/
[11:56:07] <quanticle> Queen ants are usually pretty safe underground
[11:56:13] <kiboneu> ok yeah
[11:56:15] <kiboneu> good point
[11:56:24] <kiboneu> but what about when we decide to build a dam
[11:56:27] <quanticle> I'm not sure our feet do more damage to ant colonies than wind or rain 
[11:56:28] <enterprisey> now, beekeepers who can instantly ID queen bees... the hardest where's waldo game ever
[11:56:29] <kiboneu> or put a sign somewhere
[11:56:44] <enterprisey> speaking of building dams, I've been reading this book about beavers and it's quite something
[11:56:51] <kiboneu> you know, that's how the unabomber came to be, after the government put a bunch of lsd in him and tortured hium
[11:57:01] <kiboneu> he saw a sign in the mniddle of a forest
[11:57:07] <kiboneu> it was utterly pointless
[11:57:17] <kiboneu> so the rest is history
[11:57:30] <kiboneu> enterprisey: ooh
[11:58:11] <enterprisey> imagine a stream. are you imagining a clear, smoothly-running stream? according to this book, that's a human-created unnatural disaster
[11:58:37] <enterprisey> streams ought to be slow-moving swamps, which fill the water table and are many times less hostile to wildlife
[11:59:12] <enterprisey> there used to be a lot of beavers. like, a lot of beavers. on some rivers, one every 20-50 meters
[11:59:18] <enterprisey> (one dam, that is)
[11:59:38] <kiboneu> that sounds like fun
[12:00:05] <enterprisey> they do tend to mess with human creations, though, being engineers themselves
[12:00:16] <shawwwn> https://web.archive.org/web/20180719170411/https://www.gamasutra.com/view/feature/131503/1500_archers_on_a_288_network_.php?print=1
[12:00:24] <kiboneu> enterprisey: ah so we out-engineered them
[12:00:29] <feepbot> Gamasutra - 1500 Archers on a 28.8: Network Programming in Age of Empires and Beyond
[12:00:32] <enterprisey> with shotguns, yeah
[12:00:52] <quanticle> I don't think that clear smoothly running streams are human created unnatural disasters. It really depends on topography.
[12:00:57] <shawwwn> https://www.youtube.com/watch?v=Y8HhfT7QoRQ&ab_channel=TheDodo
[12:01:04] <kiboneu> "out-engineering" ... "with shotguns"
[12:01:06] <kiboneu> fucking lol
[12:01:08] <feepbot> Picky Kitten Refuses To Give Up His Bottle | The Dodo Cat Crazy - YouTube
[12:01:29] <kiboneu> not that it's a funny image
[12:01:36] <kiboneu> just a funny way to put it
[12:01:46] <PlanckWalk> Where I live, slow moving swamps can't even really exist (unless someone rearranged the landscape a lot)
[12:01:54] <kiboneu> hmm
[12:02:00] <kiboneu> i take the zhuanxi view of life
[12:02:45] <PlanckWalk> I suppose some of the hills could have small flattish areas that collect water.
[12:02:46] <kiboneu> life emerges at the crevices of spaces where the differences are capitalized by lifeforms selected to do so
[12:02:49] <kiboneu> or something like that
[12:02:56] <PapuaHardyNet> you cultivate, get stronger, and then fight people for their cultivation powers?
[12:04:03] <kiboneu> PapuaHardyNet: if that was a response to me, then nah
[12:04:14] <enterprisey> quanticle: yes, it was an exaggeration, but it does apply to most of former beaver habitat
[12:04:16] <enterprisey> which is a lot of land
[12:04:19] <PapuaHardyNet> oh, zuanxi is daoism
[12:04:20] <PapuaHardyNet> https://plato.stanford.edu/entries/zhuangzi/
[12:04:21] <Robomot> Zhuangzi (Stanford Encyclopedia of Philosophy)
[12:04:25] <kiboneu> just that life is and extension of space
[12:04:59] <kiboneu> PapuaHardyNet: eh, yeah, but i don't take the whole cake, only the good parts
[12:05:14] <PapuaHardyNet> seems interesting
[12:05:36] <kiboneu> kind of the trick to living i guess because everything is full of shit and 5% gemstones. that's why being dumb sucks
[12:06:09] <shawwwn> awe... https://www.youtube.com/watch?v=5jTOrCg-zXw&ab_channel=CultOfFlop
[12:06:20] <feepbot> The Claw - YouTube
[12:07:06] <kiboneu> PapuaHardyNet: yeah, it's... basically he explores a lot of stuff that science fiction authors have explored a bunch. spaces and consciousness, absurdities and impossibilities of communication between large and small lifeforms
[12:07:08] <kiboneu> stuff like that
[12:07:38] <kiboneu> honestly
[12:07:46] <kiboneu> it's just fucking poetic and beautiful
[12:08:12] <kiboneu> look up the butterfly dream
[12:08:37] <kiboneu> it's like the matrix but on acid
[12:08:39] *** Joins: src (~src@user/src)
[12:08:56] <kiboneu> and from 300 bc
[12:09:16] <PapuaHardyNet> I had no idea that the butterfly dream parable originated in zhuangzi philosophy
[12:09:24] <kiboneu> and shorter
[12:09:26] <kiboneu> yeah
[12:10:11] <kiboneu> a lot of people were sort of trying to spout their government backed ideologies at the time
[12:10:12] <shawwwn> any dota fans? semifinal game is starting now https://www.twitch.tv/dota2ti
[12:10:23] <feepbot> Twitch ([EN] Invictus Gaming - Vici Gaming - Dota 2 The International 2021 - Main Event  Day 5																)
[12:10:25] <kiboneu> zhuang was kind of pissed about it
[12:10:38] <kiboneu> shits on... what's his name
[12:10:58] <kiboneu> famous chinese philosopher it boggles me that i forget
[12:11:22] <kiboneu> eh anyway all this stuff needs plenty of salt
[12:12:11] <kiboneu> it's so mystical and serotonergic / dopaminergic that it's like
[12:12:27] <kiboneu> ugh
[12:12:40] <kiboneu> just shit on it once in a while and you'll be ok
[12:12:49] <kiboneu> but it's beautiful
[12:14:06] <kiboneu> i think nietsche had the right idea to diss everyone
[12:14:55] <kiboneu> he went crazy though
[12:14:58] <kiboneu> so idk
[12:19:58] <feepbot> <gwern> 'Full disclosure: I studied Blackletter calligraphy for years under the strict tutelage of the inimitable Ward Dunham, a hefty ex Special Forces Marine with a penchant for sharp knives and the occasional healthy splash of homemade Slivovitz in his morning coffee. Everything about Dunham is big, bold, and loud. He drummed into us that blackletter, specifically Textura, was a
[12:19:58] <feepbot> raging battle being fought between black and white on the page. Dunham, fist pounding on his writing desk for emphasis, railed: “We must never allow the white to win, goddamnit.” NEVER.' https://typographica.org/typeface-reviews/sachsenwald/
[12:20:00] <feepbot> Sachsenwald – Typographica (As 21st-century America hurtles towards fascism, when the current reality has become so absurd as to render parody obsolete, using a Schaftstiefelgrotesk1 may feel uncomfortably close to the real thing. So when you need a strong, imposing blackletter, but want to avoid [snip])
[12:21:36] <PapuaHardyNet> kiboneu: reading nietzsche's stuff is hard; it is much easier to read interpretations and second / third party guides
[12:21:41] <PapuaHardyNet> Kaufmann is one I highly recommend
[12:22:07] <kiboneu> yeah
[12:23:05] <kiboneu> when i've read him, i'd treat it like water
[12:23:11] <kiboneu> coming out of a faucet
[12:28:12] <feepbot> <gwern> "It's been a week since I heard the phrase "high-capacity assault unicorn" and I still grin every time I think about rhinos"
[12:33:38] <enterprisey> does the bot just randomly post quotes?
[12:34:05] <PapuaHardyNet> no, they are highly curated by gwern
[12:34:06] <Gurkenglas> i'm guessing it crossposts from somewhere
[12:34:12] <rmmh> https://pbs.twimg.com/media/FBxB08TXIAILD0p?format=jpg&name=large
[12:34:12] <Robomot> image/jpeg (1512x2016; 333 KB)
[12:35:22] <shawwwn> xxxxxxxxxxx`
[12:35:24] <shawwwn> uh
[12:35:30] <shawwwn> oops
[12:41:55] <Betawolf> through your efforts, you can give these old socks an education
[12:42:42] *** Quits: galambo (galambo@user/galambo) (Ping timeout: 265 seconds)
[12:43:15] <saturn2> Gurkenglas: no, they're just for us
[12:44:22] <saturn2> enterprisey: gwern decided to make a queue of links and quotes that auto-posts when the channel is idle for 5 minutes
[12:44:34] <enterprisey> I see. I like that idea
[12:44:44] <enterprisey> if I ran a channel I'd make it do bash.org quotes, probably
[12:44:56] <enterprisey> oh gee, the possibilities are endless
[12:45:01] <enterprisey> I could waste hours just curating quotes
[12:45:45] <enterprisey> not just bash.org quotes. like this one that I just put on my wikipedia userpage: "To the extent that we make it easy to get into trouble, we fail." originally about API design, but I think it applies to design in general
[12:54:45] <Obormot\Arcturus> We have bots posting lots of stuff
[12:54:51] <Obormot\Arcturus> !feeds
[12:54:51] <Robomot> Available feeds in this channel: Less Wrong [frontpage] (LW), Astral Codex Ten (ACX), The Digital Antiquarian (filfre), Overcoming Bias (OB), Slate Star Codex (SSC), Gwern’s Link Archive (gwernlinks), The Last Rationalist (TLR), TheZvi (Zvi), MIRI Blog (MIRI)
[12:54:55] <Obormot\Arcturus> !latest lw
[12:54:55] <Robomot> [Less Wrong [frontpage]] NLP Position Paper: When Combatting Hype, Proceed with Caution by sbowman - https://www.greaterwrong.com/posts/RLHkSBQ7zmTzAjsio/nlp-position-paper-when-combatting-hype-proceed-with-caution
[12:55:19] <Obormot\Arcturus> !latest acx
[12:55:19] <Robomot> [Astral Codex Ten] Correction: London Meetup Location - https://astralcodexten.substack.com/p/correction-london-meetup-location
[12:56:14] <Obormot\Arcturus> I should remove the gwernlinks one, I guess
[12:56:20] <Obormot\Arcturus> Since that's private now
[12:56:47] <Obormot\Arcturus> And that stuff is probably replicated by gwernqueue anyway
[12:58:20] <ivan> https://gist.github.com/ivan/73f2e2b52e22d0e6117b7306698b0487#gistcomment-3929122 I fixed Discord
[12:58:21] <Robomot> Userscript to fix some Discord styles and replace server icons with text labels · GitHub [] (Userscript to fix some Discord styles and replace server icons with text labels - discord_styles.js)
[12:59:07] <kiboneu> Obormot\Arcturus: that's sad for me to hear w.r.t. gwernlinks
[12:59:16] <kiboneu> why is this?
[12:59:43] <kiboneu> /why was public access removed
[13:00:10] <Obormot\Gaia> kiboneu: gwern took his subreddit private, same reason as his twitter
[13:00:16] <Obormot\Gaia> To ward off the Eye of Sauron
[13:00:27] <kiboneu> oh
[13:00:46] <kiboneu> i thought you were referring to the /docs/ directory
[13:00:53] <Obormot\Gaia> nnno
[13:00:56] <kiboneu> i don't care about subreddit bs that makes more sense
[13:01:07] <Obormot\Gaia> gwernlinks was the rss feed for the subreddit
[13:01:12] <kiboneu> gotcha gotcha
[13:01:13] <kiboneu> thanks
[13:01:40] <kiboneu> i didn't even know there was a gwern subreddit but it wouldn't be surprising either
[13:02:25] <ivan> https://twitter.com/search?q=from%3Abigtechalert%20gwern&src=typed_query&f=live
[13:02:32] *** Quits: Robomot (~Robomot@user/robomot) (Quit: Bye)
[13:02:46] *** Joins: Robomot (~Robomot@user/robomot)
[13:02:46] *** ChanServ sets mode: +v Robomot
[13:02:57] <kiboneu> i like this niche of cyberspace
[13:02:57] <Obormot\Arcturus> !feeds
[13:02:58] <Robomot> Available feeds in this channel: Astral Codex Ten (ACX), TheZvi (Zvi), Slate Star Codex (SSC), The Digital Antiquarian (filfre), MIRI Blog (MIRI), Less Wrong [frontpage] (LW), Overcoming Bias (OB), The Last Rationalist (TLR)
[13:03:14] <Obormot\Arcturus> Come to think of it I should remove SSC too, lol
[13:03:23] <Obormot\Arcturus> Oh well, later
[13:03:51] <kiboneu> it's a nice list to refer to
[13:04:09] <kiboneu> maybe you can have a historical / archived section so that people can refer to it for history / old posts
[13:04:28] <saturn2> it's still technically possible for new posts to appear on SSC
[13:05:03] <saturn2> and if that happened, we'd want to know!
[13:05:09] <kiboneu> mm
[13:05:13] <kiboneu> and i like it when tools teach a bit about what's available
[13:05:30] <kiboneu> in the environment, it's own, or the world -- books, lectures, papers, whatnot
[13:05:49] <kiboneu> im a pattern language guy i suppose
[13:06:10] <kiboneu> sorry i'll jump off my horse
[13:06:51] <saturn2> maybe add a feed for this https://medium.com/@anonleverage
[13:06:53] <Robomot> Leverage Accounts Anon – Medium (Read writing from Leverage Accounts Anon on Medium.  Every day, Leverage Accounts Anon and thousands of other voices read, write, and share important stories on Medium.)
[13:07:16] <Obormot\Gaia> Does Medium provide RSS?
[13:07:47] <Obormot\Gaia> Or would I have to jury-rig it myself
[13:07:56] <kiboneu> what's a good place to catch up on the leverage drama
[13:08:01] <kiboneu> other than my irc backlog?
[13:08:03] <mst> kiboneu: /dev/null
[13:08:08] <Obormot\Gaia> Anyway, bedtime now
[13:08:11] <kiboneu> you mean
[13:08:14] <kiboneu> /dev/zero
[13:08:22] <ivan> https://astralcodexten.substack.com/p/links-for-october I smell corruption on that terrible Twinder app getting in there, it didn't even show names and now the app is dead like two days later
[13:08:23] <Robomot> Links For October - Astral Codex Ten (...)
[13:08:27] <mst> no, I do not.
[13:08:32] <saturn2> Obormot\Gaia: https://medium.com/feed/@anonleverage
[13:08:33] <Robomot> text/xml; charset=UTF-8 (3 KB)
[13:08:56] <kiboneu> i mean, you usually pipe things to dev null and stdin is always blocked
[13:09:00] <kiboneu> nothing comes out
[13:09:18] <kiboneu> or is that the joke
[13:09:46] <saturn2> kiboneu: here i guess? https://medium.com/@zoecurzi/my-experience-with-leverage-research-17e96a8e540b
[13:09:46] <Robomot> My Experience with Leverage Research | by Zoe Curzi | Oct, 2021 | Medium (Many folks have reached out to me privately w/ their own stories about Leverage, Geoff, or other leadership members. Some comments on facebook, twitter, Medium, and LessWrong have shared or implied…)
[13:09:56] <kiboneu> i just have little to no context
[13:10:03] <kiboneu> i';ve been under a rock for too long
[13:10:10] <kiboneu> and i plan to stay under it
[13:10:26] <kiboneu> i just want to place a picture to what people are fricking talking about
[13:11:32] <mst> kiboneu: precisely, the fact that it immediately returns EOF is what makes it superior
[13:11:52] <kiboneu> ah right it doesn't block then
[13:11:58] <kiboneu> but yeah
[13:12:10] <kiboneu> eof isn't helpful for talking about lesswrong cults when it happens here
[13:12:56] <mst> "a rationalist group went culty" doesn't seem new or interesting to me
[13:13:04] <mst> feels like dragon army but with more woo
[13:13:53] <kiboneu> i'm not familiar with that either
[13:14:11] <kiboneu> and im generally interested in how humans, groups and organizations fail
[13:15:21] <saturn2> kiboneu: here's some background context (also the comments) https://ea.greaterwrong.com/posts/qYbqX3jX4JnTtHA5f/leverage-research-reviewing-the-basic-facts
[13:15:24] <Robomot> Leverage Research: reviewing the basic facts - Effective Altruism forum viewer (Some of the larger outputs of Leverage Research include: Its website also has seven blog posts.4 Readers are encouraged to add additional facts known about Leverage Research in the comments section, especially where these can be supported by citation, or direct conversational evidence. …)
[13:15:47] <mst> fair enough, I concluded that this one wasn't particularly enlightening
[13:16:01] <kiboneu> aye
[13:16:15] <mst> but it sounds like you'll find the novelty to facepalms-per-minute ratio better than I did
[13:19:08] <kiboneu> yeah. i'm trying a new approach to frustrating things
[13:19:29] <kiboneu> s/frustrating things/things that are frustrating (high in FPPM)
[13:20:02] <kiboneu> it involves a lot of depressants
[13:20:26] <kiboneu> good night
[13:20:56] <kiboneu> thanks saturn2 for linnks
[13:21:27] <saturn2> np
[13:22:35] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[13:23:36] <saturn2> kiboneu: another bit of background context is that Connection Theory is obvious nonsense
[13:25:28] <PapuaHardyNet> if it is obvious nonsense why do leverage people suck off Geoff so much
[13:25:47] <saturn2> it reads like a scientology auditing manual, but somehow even dumber
[13:27:23] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[13:28:18] <kiboneu> yeah just reading this with one eye open.. it anthropomorphises mind
[13:29:05] <kiboneu> like it's one thing with intent and operates on the abstraction level of that intent
[13:30:21] <saturn2> PapuaHardyNet: they're either gullible or huge cowards and he takes full advantage of either character flaw
[13:31:17] <mst> high openness to experience plus ego flattering can manufacture gullability in smart people
[13:31:48] <kiboneu> yep
[13:32:26] <kiboneu> it's a big thing with hackers
[13:32:30] <kiboneu> like security hackers
[13:32:40] <kiboneu> super high in openness, kind of a creative sport
[13:33:40] <kiboneu> well i don't find them culty or w/e but there are memes that work especially well against hacker types
[13:34:26] <kiboneu> perhaps that's true with any field or specialization, though
[13:35:11] <kiboneu> your worldview sortof forms around what you do so you perceive certain patterns moreso than others and that'd be correlated with your job or whatever, let alone the traits that led you to it in the first place
[13:35:54] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf)
[13:36:24] <kiboneu> good night for real. it's 6 am
[13:36:32] <Filipepe> hi all
[13:36:55] <PapuaHardyNet> kiboneu: don't leave us, it's just 6 am!
[13:37:22] <kiboneu> ive tried irc while lucid dreaming
[13:37:31] <kiboneu> it doesnt work very well
[13:38:33] <kiboneu> but i suppose i have other means of tapping into the jungian techno-amplified shared unconsciousness
[13:39:39] <PapuaHardyNet> Connection theory ;)
[13:39:41] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf) (Client Quit)
[13:40:09] <PapuaHardyNet> or you could be like Lain and plug yourself into the internet
[13:40:15] <kiboneu> more like watching .... dude exactly
[13:40:47] <kiboneu> fucking love john c lilly
[13:40:53] <kiboneu> dude was a real k head but
[13:41:05] <kiboneu> talking and communicating with dolphins
[13:41:29] <kiboneu> what a fun project
[13:43:07] <kiboneu> i still need to figure out why the government gave him any money
[13:43:24] <kiboneu> in my sleep perhaps. gnight
[13:45:41] <PapuaHardyNet> kiboneu: gn!
[13:45:56] <PapuaHardyNet> "Research conducted by Ariana F. Young, Shira Gabriel, and Jordan L. Hollar in 2013 showed that men who did not form a parasocial
[13:46:02] <PapuaHardyNet> relationship with a muscular superhero had poor self-perception and felt negative about their bodies after exposure to the muscular character.
[13:46:09] <PapuaHardyNet> However, if the men had a PSR with the superhero, the negative effects on body satisfaction were eliminated."
[13:46:12] <PapuaHardyNet> -- https://en.wikipedia.org/wiki/Parasocial_interaction#Negative_consequences
[13:46:13] <Robomot> Parasocial interaction - Wikipedia [Negative consequences] (Parasocial interaction (PSI) refers to a kind of psychological relationship experienced by an audience in their mediated encounters with performers in the mass media, particularly on television and on online platforms.[1][2][3][4] Viewers or listeners come to consider media personalities as friends, despite having no or limited interactions with them. …)
[13:52:12] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[13:56:12] *** Joins: src_ (~src@user/src)
[13:56:16] *** Quits: src_ (~src@user/src) (Remote host closed the connection)
[13:59:47] *** Quits: src (~src@user/src) (Ping timeout: 264 seconds)
[14:03:30] <PlanckWalk> If muscular superheroes existed, I don't think using them to conduct parasocial studies would be the most beneficial use of their abilities.
[14:04:28] <PlanckWalk> But I guess if that's what they want to do, who's going to stop them?
[14:18:39] <Gurkenglas> Neutral Evil: CDT; LE: UDT; LN: UDT with only positive-sum updates; TN: tool AI; NG: satisfy human values; LG: across the multiverse; CN: neuromorphic AI; CE: be vulnerable to infohazards, go mad and kill everyone; CG: make everyone immortal and eat all gpus and don't even finish fooming
[14:20:48] <PlanckWalk> Heh
[14:25:26] <Gurkenglas> questions, improvements?
[14:29:11] <Gurkenglas> these all seem on the same order of magnitude of subjective probability, in fact
[14:29:30] <Gurkenglas> s/seem/are/
[14:32:37] <PapuaHardyNet> what is cdt and udt
[14:34:46] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[14:35:29] *** Joins: srhm (~srhm@user/srhm)
[14:35:51] *** Joins: src (~src@user/src)
[14:35:56] <Gurkenglas> CDT: maximize *something* UDT: across the multiverse. CDT turns out badly for us for almost all values of something, so NG almost obligates us to get off easy by value learning
[14:37:30] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Quit: Laa shay'a waqi'un moutlaq bale kouloun moumkine)
[14:40:27] <Gurkenglas> would be *just like* us to just develop better and better tool AI as nobody ever actually gets around to making it agentic, just like we haven't actually accidentallied the biosphere yet
[14:40:57] <Gurkenglas> and didnt nuke ourselves in the cold war
[14:41:30] <PapuaHardyNet> tool AIs become agent AIs easily
[14:41:40] <PapuaHardyNet> I'm not even going to refer to gwern's essay on it
[14:41:51] *** Joins: Lord_of_Life (~Lord@user/lord-of-life/x-2819915)
[14:42:05] <PapuaHardyNet> imagine if you have an AI whose job is to analyze people and recommend a bank whether to give them a loan or not
[14:42:16] <Gurkenglas> yeah you can barely say tool ai around these parts without that essay coming up, i did skim the abstract again before my two-lines-ago
[14:43:03] <PapuaHardyNet> well, I haven't read the essay, but the idea makes sense
[14:43:16] <PapuaHardyNet> agentiness comes from the ability to change reality
[14:43:51] <PapuaHardyNet> an AI whose decisions mean life or death for humans - well, if that isn't an agent, then what is it?
[14:44:35] <Gurkenglas> no, tool ai becomes agentic when you ask the tool "what should i do in order to maximize f?"
[14:44:58] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[14:45:07] <Gurkenglas> (and then take the human out of the loop, i suppose)
[14:46:21] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 245 seconds)
[14:46:22] *** Lord_of_Life_ is now known as Lord_of_Life
[14:47:00] <PapuaHardyNet> Gurkenglas: are ranking algorithms used by social networking services agentic?
[14:47:09] *** Joins: Urchin[emacs] (~user@user/urchin)
[14:47:43] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf)
[14:48:16] <Gurkenglas> close enough. so i suppose the just-so story must be not "nobody ever actually gets around to" but "people stop doing it" :P
[14:48:44] <Gurkenglas> (or rather, people do it less as the tier goes up)
[14:50:09] <PapuaHardyNet> what is "it", Gurkenglas? I'm sorry, you've lost me
[14:50:11] <Gurkenglas> much of the weight on the bad outcomes is from someone turning a tool ai into an agent; but the hypothesis that doubts this is bolstered by its track record on us not all being dead
[14:52:30] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[14:53:11] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 264 seconds)
[14:54:38] <Gurkenglas> PapuaHardyNet, "it" being "wiring the tool AI up into an agent"
[14:55:20] *** Lord_of_Life_ is now known as Lord_of_Life
[14:56:00] <PapuaHardyNet> I see
[14:57:18] <Gurkenglas> like, i can think of simple what-i-would-expect-to-be-capability-gains that i don't see implemented, and also when i try implementing something simple it takes a long time, so i can project that the simple way to wire tool AIs into agent AIs isn't *necessarily* going to keep happening ^^
[14:58:04] *** Joins: galambo (galambo@user/galambo)
[15:00:50] <PlanckWalk> I expect that tool AIs get more useful the more agenty they are in the long run.
[15:01:18] <Gurkenglas> yeah, but custom proteins would also be pretty useful and as you see we're still alive
[15:01:31] <PlanckWalk> Err, relevance?
[15:01:39] <PlanckWalk> Virtually all proteins don't kill us
[15:02:18] <PlanckWalk> I'm not sure sure that's true for capable agent AIs
[15:02:50] <Filipepe> PlanckWalk: are you familiar with gwern's essay?
[15:03:13] <PlanckWalk> Not at the moment, though it rings a bell as something I may have read in the past
[15:03:33] <Filipepe> https://www.gwern.net/Tool-AI
[15:03:34] <Robomot> Why Tool AIs Want to Be Agent AIs · Gwern.net (AIs limited to pure computation (Tool AIs) supporting humans, will be less intelligent, efficient, and economically valuable than more autonomous reinforcement-learning AIs (Agent AIs) who act on their own and meta-learn, because all problems are reinforcement-learning problems.)
[15:04:11] <Gurkenglas> we appear to have the biotech to introduce novel proteins, mirror life could plausibly kill everyone, we aren't dead
[15:04:22] <PlanckWalk> Ah yep, I have read that one
[15:05:08] <PlanckWalk> We already create tons of novel proteins, including mirror ones
[15:05:11] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 264 seconds)
[15:05:26] <PlanckWalk> Mirror *life* is very much harder to synthesize than mirror proteins
[15:05:35] <kuudes> hmm, have Gurkenglas and shawwwn debated on AGI? what was the result?
[15:05:46] <PlanckWalk> (I think a few people are working on it)
[15:05:55] <kuudes> I sense adversarial collaboration possibility
[15:05:56] <Filipepe> https://sci-hub.se/10.3109/09637486.2016.1144719 <-- gwern: this has an utterly fascinating result, shame it's n=18. Totally worth a bigger study
[15:05:56] <Robomot> Sci-Hub | A randomized, double blind, placebo controlled study of spirulina supplementation on indices of mental and physical fatigue in men. International Journal of Food Sciences and Nutrition, 67(2), 203–206 | 10.3109/09637486.2016.1144719
[15:06:02] <Filipepe> hi kuudes!
[15:06:03] <kuudes> hi Filipepe :)
[15:06:28] <PlanckWalk> Synthetic mirror life is also much less useful than proteins
[15:06:41] <PlanckWalk> And really, woudl probably just die.
[15:06:47] <PapuaHardyNet> oh yes, I was actually waiting for Gurkenglas to comment on shawwwn's bet and discussion
[15:07:04] <PapuaHardyNet> but the really heated discussion - well, either I missed it, or it never materialized
[15:07:21] <PlanckWalk> Unless we specifically engineered it to be able to digest and reformulate normal proteins into its mirror analogues.
[15:07:25] <Gurkenglas> yeah we should have discussion but im uhh late right now, lets do it later
[15:07:32] <PapuaHardyNet> my new goal for the next few months: get up to date on Schmidhuber's research work (https://arxiv.org/search/cs?searchtype=author&query=Schmidhuber%2C+J)
[15:07:33] <Robomot> Search | arXiv e-print repository
[15:07:51] <kuudes> PlanckWalk, hopefully it would die. otherwise we would die.
[15:08:02] <Gurkenglas> PlanckWalk, mirror algae that eat the same sunlight but have no natural predators and then the biosphere falls over?
[15:08:23] <Filipepe> gwern: incredible result on maths, page 205 https://imgur.com/a/SVJXxfu
[15:08:25] <PlanckWalk> Of course it has natural predators
[15:08:35] <feepbot> Imgur: The magic of the Internet (Discover the magic of the internet at Imgur, a community powered entertainment destination. Lift your spirits with funny jokes, trending memes, entertaining gifs, inspiring stories, viral videos, and so much more.)
[15:08:46] <Filipepe> check this out, kuudes
[15:08:53] <PlanckWalk> The existing stuff that eats algae is still going to kill it, just not be able to digest some of it.
[15:09:45] <PlanckWalk> Maybe over millions of years of selection existing predators will stop trying to eat it
[15:09:55] <Gurkenglas> sounds like those predators will go someplace else or die out and that's an evolutionary advantage on the order of becoming venomous, without any of the costs
[15:10:16] <Gurkenglas> *poisonous, dammit
[15:10:20] <PlanckWalk> They can still digest some of it, so there's not a net loss to them
[15:10:39] <PlanckWalk> Most mirror compounds aren't *poisonous*, just harder to digest.
[15:10:56] <PlanckWalk> (But some bacteria can break them down too)
[15:11:22] <PlanckWalk> I remember there was a huge hypefest about this sort of thing a couple decades ago
[15:12:29] <Gurkenglas> *weeks, on twitter. bbl
[15:12:31] <Gurkenglas> :(
[15:13:06] <PlanckWalk> Eh, it wouldn't surprise me if some twits dragged it all up again
[15:14:02] <PlanckWalk> In short yeah, some mirror life might find an exploit a new niche.
[15:15:42] <PlanckWalk> It can still die, get eaten, won't be much good at eating anything else, still has to compete with other things in that niche, etc
[15:16:01] *** Joins: _inky (~inky_@46.36.117.129)
[15:16:49] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 252 seconds)
[15:17:29] *** Quits: Mateon1 (~Thunderbi@user/mateon1) (Quit: Mateon1)
[15:21:37] <feep> I awake
[15:21:42] <feep> - owwww headache :(
[15:21:47] <Filipepe> fip <3
[15:21:50] * feep drops an aspirin
[15:21:56] <feep> hihi
[15:23:26] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[15:27:59] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[15:29:20] *** Joins: voltage_ (voltage@user/voltage)
[15:30:53] <kuudes> mirror life is an existential threat
[15:31:12] <kuudes> if it outcompetes plant algae on ocean, we will die, very likely
[15:31:45] <kuudes> it is not as dangerous thing to study as potential vacuum collapse, but it is dangerous
[15:31:57] <feep> hm
[15:32:05] <feep> does higher blood pressure usually make headaches worse or better
[15:33:18] <Filipepe> "From 1995 to 2020, data shows that contemporary art prices out-gained S&P 500 returns by 174% according to Citi." TIL
[15:34:01] <feep> hot take: we need to tax the rich, because the rich objectively don't know what to do with their money. I present NFTs as evidence.
[15:35:02] <Filipepe> or, maybe, taking the quote above, they do
[15:35:15] <Filipepe> since art seems to be lucrative
[15:35:17] <feep> to be clear, I'm not saying "because they have, in some moral sense, too much money", I'm saying "investment opportunities are oversaturated to such an extent that they seem *no better than nfts.*"
[15:36:15] <feep> we are at a point where the median new business proposal has lower expected value than a token saying "this is valuable."
[15:36:32] <mst> part of that may simply be paper wealth locked in crypto ecosystems
[15:37:28] <PapuaHardyNet> withdrawing all that paper wealth would dilute the wealth
[15:37:46] <feep> also I kinda need an urgent answer on the blood pressure question
[15:37:57] <PapuaHardyNet> feep: it will make it better
[15:38:01] <feep> since I am currently self-medicating my headache with techno, and this is either a great idea or terrible
[15:38:16] <feep> the aspirin is probably also doing its thing
[15:38:17] <PapuaHardyNet> feep: try hentai
[15:38:24] <feep> maybe later
[15:39:08] <Filipepe> 'since I am currently self-medicating my headache with techno' germans...
[15:39:35] <feep> Filipepe: I self-medicate most things in my life with techno <3
[15:39:42] <feep> it's actually amazing for add
[15:39:48] <Filipepe> haha
[15:39:54] <feep> I am *not kidding*.
[15:40:09] <feep> it's basically a stimulant.
[15:40:09] <Filipepe> I believe you're not kidding, but I'm skeptical! :p
[15:41:19] <feep> https://soundcloud.com/doesitbangus/thebaddest in practice this means I just repeat this track on loop mostly
[15:41:20] <Robomot> Stream Lucy Stoner B2B Garridge - We Are The Baddest by DoesitBANG? | Listen online for free on SoundCloud (Stream Lucy Stoner B2B Garridge - We Are The Baddest by DoesitBANG? on desktop and mobile. Play over 265 million tracks for free on SoundCloud.)
[15:42:00] <Filipepe> I believe it may motivate you, but I doubt it'll increase your attention :p
[15:42:10] <Filipepe> but maybe you just need the motivation
[15:42:17] <feep> I mean, why do stimulants increase focus in general?
[15:42:51] <feep> my standing theory is it makes every part of  my brain more active, including the part that handles executive function and task switching
[15:42:57] <mst> feep: stoner rock for creative design, fast metal for cranking out code
[15:43:12] <PapuaHardyNet> mst: stoner rock recommendations?
[15:43:16] <feep> so I still do random bullshit but I also switch back *to* productive work more reliably.
[15:43:24] <feep> mst: yeah I can dig it
[15:43:52] <Filipepe> I only know Queens of the Stone Age
[15:43:58] <mst> PapuaHardyNet: Kyuss, Queens of the Stone Age, Fu Manchu, Karma To Burn, Goatsnake, Desert Sessions
[15:47:14] <mst> Orange Goblin are kinda stoner-adjacent I guess, or at least more 'stoner metal' than 'stoner rock'
[15:47:44] <Filipepe> does stoner metal sound better when you're stoned, or it's just the aesthetics?
[15:50:03] <mst> it's called that as much as anything else because it came out of the mohave desert generator party scene, where a band would load up their gear plus portable generators onto a truck, drive out into the desert, and then get high and jam for an audience of whoever turned up
[15:50:31] <feep> that sounds amazing
[15:50:32] <Filipepe> ah
[15:50:43] <mst> so it's "fueled by weed" first and foremost, with the aesthics and what state you prefer listening to it downstream of that
[15:51:09] <Filipepe> QOTSA turned out to be very mainstream, for such a scene
[15:51:18] <Filipepe> shame the frontman is nuts
[15:51:22] <mst> the very first QoTSA album was much more classic stoner rock
[15:51:45] <mst> Josh Homme is definitely, uh, intense
[15:52:06] <Filipepe> didn't he kick a pregnant woman, or something?
[15:53:13] <mst> I don't honestly track non-music-related stuff about artists
[15:53:22] <Filipepe> https://www.bbc.com/news/world-us-canada-42304607
[15:53:23] <Robomot> Josh Homme: Queens of the Stone Age frontman kicks female photographer - BBC News (The rock star says he is sorry for kicking the female photographer, who says he did it on purpose.)
[15:54:08] <PapuaHardyNet> never apologize
[15:54:30] <Filipepe> but it seems he really did it
[15:55:35] <mst> I can believe it, he's always hated all the ancillary stuff - publicity, merch, the whole shebang
[15:55:55] <mst> took friends of his a couple years of harassing him to get kyuss to actually play a gig in a bar rather than just doing generator parties
[15:56:26] <mst> so it would be a pretty on-brand way of being a massive dickhead
[15:57:53] <mst> oh, fuck, I forgot Unida, which was the Kyuss vocalist's next band
[15:58:17] <feep> OKAY
[15:58:19] <feep> project for the day
[15:58:24] <feep> strip out 0 size structs from the C backend
[15:58:31] <feep> so it can stop printing these stupid-ass warnings about {0}
[15:58:55] <mst> zero size structs?
[15:59:07] <feep> yeah, there's some data types in neat that have a size of 0
[15:59:14] <feep> and rn the backend just does them as struct Foo {};
[15:59:28] <feep> for instance, tag types
[15:59:48] <feep> ie. :foo is an expression of type :foo, of which it is the only value
[16:00:08] <feep> so :foo :foo = :foo is valid neat
[16:00:16] <PapuaHardyNet> https://litter.catbox.moe/k887bi.png
[16:00:18] <Robomot> image/png (758x552; 60 KB)
[16:00:34] <PapuaHardyNet> top prediction of gpt2 for "The women wept because she was": "pregnant"
[16:00:40] <feep> why tho
[16:00:49] <Filipepe> antinatalist
[16:00:51] <feep> LOL
[16:01:46] <feep> mst: this is mostly used to disambiguate entries in sumtypes
[16:02:01] <feep> ie. ((:add, Register, Register) | (:sub, Register, Register)) instr;
[16:02:42] <feep> but rn in the C backend this becomes union { struct { struct{}, Register, Register}, struct { struct{} etc
[16:03:04] <feep> which C doesn't like because it doesn't really ... *have* zero size types, the only reason this works is cause gcc is being nice to us
[16:04:27] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf) (Quit: Client closed)
[16:04:47] <feep> anyway upon looking at the code this should actually be super easy, barely an inconvenience.
[16:04:54] <feep> hm - no, hm.
[16:05:06] <feep> okay, it
[16:05:13] <feep> okay, it's not TOTALLY easy, but it should work
[16:05:36] <feep> I need a backend state for "a reg has been defined with size 0, we don't really emit it but we still need to track it"
[16:09:21] <feep> it's mostly just like, sprinkling if (size > 0) all over the code.
[16:09:38] <mst> feep: aaaah right
[16:29:02] *** Joins: two2thehead (~user@124.195.202.105)
[16:29:48] <feep> not sure if it was the speedcore or the aspirin, probably the aspirin, but my headache seems to have cleared up :)
[16:37:17] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[17:07:42] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf)
[17:13:16] *** Joins: LeoTal (~LeoTal@1.170.86.79.rev.sfr.net)
[17:14:03] <LeoTal> Friends, Romans, countrymen, lend me your machines: Could someone who runs anything other than macOS test if right-click works in Chromium/Chrome in kiosk mode?
[17:15:27] <Filipepe> how do I start kiosk mode
[17:17:06] <LeoTal> Add the "--kiosk" argument. On Windows, if you have Chrome in the usual place, try running C:\Program Files\Google\Application\chrome.exe --kiosk
[17:18:44] <PapuaHardyNet> no it doesn't for me: Arch Linux, X230, kernel 5.13.8, chromium, GNU/Linux, started from the console, using dwm and no desktop environment
[17:18:50] *** Quits: src (~src@user/src) (Quit: Leaving)
[17:19:09] *** Joins: src (~src@user/src)
[17:19:46] <PapuaHardyNet> also using colemak as my keyboard layout
[17:19:52] <LeoTal> PapuaHardyNet: I'm not entirely sure if you're being helpful or sassy, given "and no desktop environment". Right click *does* work in non-kiosk mode, right?
[17:20:08] <PapuaHardyNet> yep, it obviously works
[17:20:24] <LeoTal> Thank you very much for testing!
[17:20:28] <milanandreew> dwm and plasmashell user here, can confirm it doesn't work in kiosk mode
[17:20:36] <LeoTal> Excellent
[17:20:46] <PapuaHardyNet> dwm users, you have my utmost respect
[17:21:20] <LeoTal> I deduce that you have your own utmost respect
[17:21:54] <feep> I don't have dwm :( or chrome
[17:22:59] <feep> >Y    C backend: treat all zero-size types as void.
[17:23:02] <feep> alright! there we go
[17:23:23] <PapuaHardyNet> feep: good call, never feed the chrome monopoly!
[17:23:42] <PapuaHardyNet> btw feep, have you thought of trying postmarketOS?
[17:23:51] <LeoTal> I have three Chromiums (Chromia?) on my machine that I know off, and I don't know where 2 of them are
[17:24:17] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[17:24:36] <feep> PapuaHardyNet: I use a bunch of android stuff daily
[17:25:00] <feep> sleep tracking, maps, the bluetooth controller app for my scooter
[17:25:25] <feep> I don't think those are available on desktop/desktopesque linux
[17:26:10] <feep> and they're about half my phone use.
[17:26:29] <feep> if it was just a matter of browsing and photos, I'd probably switch, yeah
[17:29:10] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 268 seconds)
[17:31:20] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[17:35:05] <mst> heh: https://twitter.com/moyix/status/1448871687936696335
[17:35:07] <|dbotdan> Brendan Dolan-Gavitt (@moyix, 2021-10-15 04:41): ‘Does my GAN's loss go down every day? No. But does it try its hardest to make its image quality go up over time? Also no’
[17:41:24] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 265 seconds)
[17:43:17] *** Joins: two2thehead (~user@124.195.202.105)
[17:43:18] <nshepperd2> GANs and their consequences have been a disaster for the grad student race
[17:57:24] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[17:57:51] <gwern> Filipepe: yes, it is incredible how the groups differed at baseline despite supposedly being randomized
[17:57:52] *** Joins: srhm (~srhm@user/srhm)
[17:58:28] <Filipepe> gwern: do you think this is worth further study, or you place high likelihood of it being noise?
[17:58:34] <Filipepe> because it's a damn big effect
[17:58:38] <gwern> latter
[17:58:50] <Filipepe> ;_;
[17:59:18] <gwern> there is no good reason for spirulina to have much of an effect, the effect is well into 'too good to be true' range for such tiny _n_, and being imbalanced at baseline is a pretty damning fact for this study
[18:07:16] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 252 seconds)
[18:08:25] *** Quits: bildramer (~bildramer@2a02:587:620e:cd00:dde9:b19f:23dc:225a) (Ping timeout: 252 seconds)
[18:09:15] <feepbot> <gwern> https://twitter.com/UrbanFoxxxx/status/1449306584958517248
[18:09:17] *** Joins: two2thehead (~user@124.195.202.105)
[18:09:18] <|dbotdan> Irène DB (@UrbanFoxxxx, 2021-10-16 09:29): ‘Fell down a pylons rabbit hole again—currently obsessed with 'gate type' transmission towers and in particular with these incredible examples, built by TEPCO over the Seibu Tamagawa railway Line in Western Tokyo in 1967 | [Sankei/TEPCO]’ Images: https://birdsite.xanny.family/pic/media%2FFBz2eEPX0AAg7Zg.jpg%3Fname%3Dorig (description: a train going
[18:09:18] <|dbotdan> through a bridge; confidence: 0.34) | https://birdsite.xanny.family/pic/media%2FFBz3oRIWQAAHnnz.jpg%3Fname%3Dorig
[18:14:19] <feepbot> <gwern> https://store.steampowered.com/app/251110/INFRA/ what a premise
[18:14:20] <feepbot> INFRA on Steam (INFRA puts you into the boots of a structural analyst on a routine mission. Quickly though, your task turns into a fight for survival, all caused by deep-rooted schemes of the past. Your tools are simple: your camera and the wits to navigate a labyrinth of debris.)
[18:18:35] *** Joins: thoros (~thoros@80-121-136-207.adsl.highway.telekom.at)
[18:20:44] *** Joins: bildramer (~bildramer@2a02:587:620f:a200:d372:2b3c:10e1:ae1a)
[18:23:56] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 265 seconds)
[18:25:05] <feep> https://www.reddit.com/r/HPMOR/comments/q93s1w/in_defence_of_goblet_of_fire_ending_portkey_scene/ holy shit the portkey thing in hp book 4 actually makes sense
[18:25:07] <Robomot> In defence of "Goblet of Fire" ending portkey scene : HPMOR (Warning: canon book 4 spoilers ahead. I have seen people being confused about HP canon on numerous occasions, and even calling it dumb and plain …)
[18:25:35] <feep> the portkey teleports harry back because that's its *normal* function, teleporting harry to the graveyard is an *additional* enchantment.
[18:25:48] *** Joins: two2thehead (~user@124.195.202.105)
[18:36:06] <PapuaHardyNet> that was obvious
[18:36:28] <PapuaHardyNet> like a stacked enchantment. do people even play video games
[18:36:41] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf) (Quit: Client closed)
[18:40:26] <gwern> huh? people didn't understand the portkey thing? really?
[18:46:34] <gwern> I knew rowling wrote for children, but I didn't realize so many adults were mentally children too and can't understand a simple trick spelled out for them in the book
[18:48:21] <[itchyjunk]> Hmm, the pomodoro technique requires some dozen + minutes of sitting and reading/learning. How do people with lower attention span manage that? there is probably some x contagious minutes you would want to sit right? 2 minutes study break 30 second break probably doesn't make sense for example
[18:50:00] *** Quits: thoros (~thoros@80-121-136-207.adsl.highway.telekom.at) (Quit: WeeChat 3.3)
[18:53:23] <feepbot> <gwern> https://www.biorxiv.org/content/10.1101/2021.10.13.464294v1 hm
[18:53:25] <feepbot> Rilmenidine mimics caloric restriction via the nischarin I1-imidazoline receptor to extend lifespan in C. elegans | bioRxiv (Caloric restriction increases lifespan across species and has health benefits in humans. Because complying with a low-calorie diet is challenging, here we investigated pharma [snip])
[19:01:18] <feep> gwern, PapuaHardyNet: to be fair, it contradicts the text.
[19:01:59] <feep> "I offered to carry the Triwizard Cup into the maze before dinner," whispered Barty Crouch. "Turned it into a Portkey." --Goblet of Fire, 691
[19:03:07] *** Joins: Mateon1 (~Thunderbi@user/mateon1)
[19:06:01] <shawwwn> oh no, stylegan3 is so boring that nshepperd has entered her surrealist phase https://twitter.com/nshepperd1/status/1449397241534246916
[19:06:07] <|dbotdan> nshepperd (@nshepperd1, 2021-10-16 15:30): ‘"a surreal and organic stone monument to water" #stylegan3’ Watch video: https://nitter.eu/nshepperd1/status/1449397241534246916
[19:06:29] *** Joins: voltage (voltage@user/voltage)
[19:07:05] <shawwwn> (also congrats on the 1k followers.)
[19:07:47] *** Quits: voltage_ (voltage@user/voltage) (Killed (NickServ (GHOST command used by voltage)))
[19:07:53] *** voltage is now known as voltage_
[19:07:55] <nshepperd> ty :)
[19:08:18] <nshepperd> yeah, faces are kind of boring tbh
[19:08:50] <nshepperd> All the fun of stylegan3 is pushing it out of distribution to at least face-adjacent things
[19:09:13] <shawwwn> just excited for more 8-bit pokemon CLIP
[19:09:36] <gwern> should finetune CLIP on iNaturalist or something like that
[19:10:21] *** Quits: voltage_ (voltage@user/voltage) (Client Quit)
[19:10:32] <nshepperd> i am training a new pixel art model now
[19:10:34] <gwern> for best results, I think you'd want something like, 'all possible pokemon-related art and sprites; all non-human fantasy and anime art; all possible animal/insect-related art and photos'
[19:10:40] <nshepperd> with a slightly more general dataset
[19:10:44] <shawwwn> pixel art HYPE
[19:11:00] <nshepperd2> https://media.discordapp.net/attachments/730484623028519072/898952969700122694/demo_00100.png 100 epochs
[19:11:00] <Robomot> image/png (530x530; 312 KB)
[19:11:19] <gwern> so extracting pokemon keywords from danbooru/e621 and google images, download inaturalist and sources like WMF, run animal/insect/human detectors over YFCC and wikiart and BAM and artstation etc...
[19:11:31] <PapuaHardyNet> it would be cool if we had a pix2pix that converted normal booru image to a pixel art
[19:12:06] *** Joins: voltage_ (voltage@user/voltage)
[19:12:42] <gwern> PapuaHardyNet: I'd expect you could do that already with the CLIP approaches. do something like downscale the image normally, feed the danbooru tags into the clip text encoder, feed the danbooru image into the clip image encoder, and then gradient ascent the pixelated seed based on distance to both text & image embedding
[19:13:01] <gwern> that should get you the most semantically & visually similar pixelart to the original
[19:14:16] <PapuaHardyNet> gradient ascent, as in we have the ideal CLIP output, and now we are simply reducing its fidelity?
[19:14:26] <feep> gradient escape
[19:14:38] <feep> gradient flight
[19:14:40] <PapuaHardyNet> or gradient ascent is how you reduce loss for CLIP?
[19:14:54] <feep> Tagline: "The mode is collapsing. Run."
[19:15:07] <gwern> PapuaHardyNet: I mean, the downscaled version, run through a bilinear downscaler or watever, is not going to be very good. so you want to optimize it to increase similarity of its embedding to the clip embedding of the fullscale original image
[19:15:43] * gwern shuts down his old hetzner server for the last time. bandwidth use says no remaining rsync users, so should finally be safe to do so. sayonara old friend
[19:15:49] <PapuaHardyNet> ohh! so you do mean reducing loss. I'll seriously evaluate this: I'd like to be known as the most popular 8bit hentai artist
[19:16:22] <two2thehead> kuudes, s0ph1a feep : TIL that pet groomers have a dual-leash collar setup. One leash vertically to stop up-down movement, and one leash horizontally to connect the pet to the wall while the groomer trims the fur off their bum. Mildly interesting
[19:16:30] <gwern> whether you see it as maximizing similarity/reward or minimizing loss/cost tends to be a fairly arbitrary decision, yeah
[19:18:42] <PapuaHardyNet> you know what would be cool? A lesswrong adjacent channel where we only post papers and quotes from papers
[19:18:55] <PapuaHardyNet> (and discuss the papers of course)
[19:19:04] <kuudes> why can't you post them here?
[19:19:16] <PapuaHardyNet> yeah, I just realized, it is meaningless fragmentation
[19:19:28] <PapuaHardyNet> https://arxiv.org/abs/2106.06295
[19:19:28] <Robomot> [2106.06295] Going Beyond Linear Transformers with Recurrent Fast Weight Programmers (Transformers with linearised attention ("linear Transformers") have)
[19:19:55] <PapuaHardyNet> I'm curious as to whether we can take this architecture, scale it up, and then compare its performance with, say, GPT-2 small.
[19:20:26] <PapuaHardyNet> afaik the codebase that Schmidhuber and co. released has custom CUDA code. Converting this to JAX will be a pain - one will have to read the paper
[19:20:32] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf)
[19:21:29] <PapuaHardyNet> (why JAX? because JAX is interesting, and doesn't require CUDA. I'd like a codebase that can run only on a CPU)
[19:21:51] <gwern> unfortunately the history of efficient attention so far is that they all underperform in some way compared to just old fashioned attention
[19:22:17] <Gurkenglas> shawwwn debate time! Let's recap the positions. You uhh don't care about AI safety because Shawwwn(global civilizational collapse)=75%. I care about AI safety because Gurk(AI safety research will make the difference between FAI&paperclips)=50%.
[19:22:21] <PapuaHardyNet> tbh I'm missing some core skills when it comes to evaluating papers.
[19:22:50] <shawwwn> Okay
[19:22:58] <shawwwn> PapuaHardyNet: not true
[19:23:04] <shawwwn> the best way to evaluate a paper is to have no idea what you're doing
[19:23:11] <shawwwn> (it always seemed to work for me anyway...)
[19:23:31] <PapuaHardyNet> well, I'd like to hit at least 0.5 of gwern's ability. One way is to have a huge knowledge base
[19:23:47] <shawwwn> one cannot simply hit 0.5 of infinity
[19:23:53] <shawwwn> you have to be born with it
[19:24:00] <shawwwn> gwern was doing ML papers in vitro
[19:24:09] <Gurkenglas> What x did you say again, for which you're torn on whether to press a button with x% paperclips and (1-x)% fai?
[19:24:31] <shawwwn> Gurkenglas: I said y, not x
[19:24:37] <two2thehead> PapuaHardyNet, you can post papers and quotes from them here
[19:25:00] <Gurkenglas> shawwwn, wut? you mean, you gave a number of the fai % that the button must have?
[19:25:02] <two2thehead> Gwern used to do it more, and I do it when I see an interesting study or good writing from a study
[19:25:05] <PapuaHardyNet> two2thehead: that's the plan, yeah
[19:25:07] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[19:25:21] <shawwwn> Gurkenglas: nah, just literally y instead of x. x bothers me
[19:25:26] <shawwwn> it's used too frequently
[19:25:32] <Gurkenglas> that's silly, you're silly
[19:25:48] <shawwwn> it's the weekend :(
[19:26:05] <Gurkenglas> anyway, what was the fai %?
[19:26:21] <shawwwn> can I be honest? you're on a galaxy brain plane far beyond me 
[19:26:31] <shawwwn> I have no idea what you're even talking about, let alone what you're asking
[19:26:40] <shawwwn> fai to me is FastAI
[19:27:06] <Gurkenglas> <kuudes> hmm, have Gurkenglas and shawwwn debated on AGI? what was the result? <PapuaHardyNet> oh yes, I was actually waiting for Gurkenglas to comment on shawwwn's bet and discussion
[19:27:16] <shawwwn> yeah I saw that
[19:28:13] <shawwwn> the bet is simple. if AGI is invented, I will transfer my life savings to the next winner in line. Otherwise I become the winner, and they transfer whatever amount they wagered.
[19:28:34] <shawwwn> I anticipate winning from now until 200 years from now.
[19:28:57] <shawwwn> I'll commit my descendants to the bet, so that they can continue winning
[19:29:03] <shawwwn> MAGA
[19:29:07] <shawwwn> (make AI great again)
[19:29:14] <Gurkenglas> How much do they have to wager against your savings?
[19:29:47] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 264 seconds)
[19:29:52] <shawwwn> I've been thinking it over, and I think around $1k is a decent filter. Otherwise everyone will treat it like a lottery.
[19:30:11] <Gurkenglas> 1k against your, uh something like 150k
[19:30:57] <PapuaHardyNet> shawn is planning to murder anyone who has a valid theory for AGI
[19:31:07] <Gurkenglas> worth funding with 1k
[19:31:24] <PapuaHardyNet> good point
[19:32:05] <Gurkenglas> your bet doesn't *quite* imply Shawwwn(AGI)<1%, because presumably AGI reduces expected value of money. But not by a factor of 10.
[19:32:41] <shawwwn> nshepperd would disagree
[19:32:50] <shawwwn> that was one of the more surprising aspects of the bet
[19:33:05] <shawwwn> people literally refuse to believe that it can possibly mean anything, because "money won't matter at all" if AGI is invented
[19:33:15] <Gurkenglas> There's a good chance that money won't matter at all.
[19:33:29] <shawwwn> I agree, but the time frame isn't instant
[19:33:45] <shawwwn> you can take my millions and fuck a lot of hookers and do a lot of cocaine
[19:33:47] <PapuaHardyNet> money is a proxy for value, and with AGI, you have created an almost infinite supply of value
[19:33:58] <Gurkenglas> But there's a non-negligible chance that money continues mattering for at least a little while, so the expected value doesn't go down by more than like a factor of 10
[19:34:04] <shawwwn> yes
[19:34:45] <shawwwn> if my life savings after 15 years is $150k, I think I've totally failed as a jew btw
[19:34:50] <Gurkenglas> PapuaHardyNet, an AGI might well allocate voting power proportional to money held, because that's resilient to a bunch of dutch booking
[19:34:54] <shawwwn> let alone as a SWE
[19:35:26] <PapuaHardyNet> so on 20th there's a Zoom event by Mercury CEO on "how to ace your YC interview"
[19:35:35] <PapuaHardyNet> in case anyone was interested
[19:35:58] <Gurkenglas> shawwwn, describe the abilities of an example AGI for which you'd pay out
[19:36:17] <feep> And the LORD spoke to them from a whirlwind, saying: "Fornicate with female dogs, children of Israel, and acquire currency!"
[19:36:21] <shawwwn> N% of mechanical turk problems no longer require humans to solve
[19:36:26] <feep> (This line was struck from later transcriptions.)
[19:36:30] <shawwwn> pinning down the exact N is difficult
[19:37:10] <Gurkenglas> shawwwn, describe an example task you wouldn't expect automated without task-custom code
[19:37:12] <shawwwn> a less formal payout would be if e.g. most teens end up falling in love with their AI companions, and some large portion of them start a movement to attain legal rights to marry AGI
[19:37:35] <shawwwn> I don't understand the question
[19:37:58] <Gurkenglas> you could make the love&rights happen without novel software :D
[19:38:02] <Gurkenglas> *thing
[19:38:30] <mst> feep: Large Offset Religion Director
[19:39:05] <Gurkenglas> shawwwn, describe a mechanical turk problem that you'd expect solved without humans iff AGI
[19:40:02] <shawwwn> I think the percentage matters more than any particular MT problem. The key is that MT is currently a requirement by definition, and that AGI makes it obsolete by definition. That's after all the whole goal of AGI
[19:40:23] <shawwwn> the devil is in the details, of course. AGI might be too expensive to deploy against menial ML problems
[19:40:34] <shawwwn> so one shouldn't necessarily expect MT to become obsolete just because AGI exists
[19:40:43] <kiboneu> good morninng
[19:40:54] <shawwwn> however, I do expect someone to deploy AGI against MT as conclusive proof at *some* point
[19:40:57] <Gurkenglas> yeah but given that we don't make the problem you name a target, whether *that* problem is automated can correlate a lot with whether AGI, and the answer lets me guess at your innards.
[19:41:02] <shawwwn> if only to show that humans are no longer required
[19:41:44] <Gurkenglas> last line as a response to "matters more than any particular MT problem"
[19:41:56] <shawwwn> well, the MT idea actually came from carmack, not me. Or at least it arose during our discussions ~8 months ago. What I discovered was
[19:42:14] <shawwwn> when you go to MT and look at actual MT problems, you can start thinking of ways to solve with with standard ML
[19:42:28] <shawwwn> any particular problem isn't "hard"
[19:42:32] <shawwwn> it's just unsolved.
[19:42:37] <gwern> I would point out that there would be decent MT demand no matter how superhuman AGI gets, because users may be studying *humans*
[19:42:44] <PapuaHardyNet> https://archive.is/iHBvt
[19:42:46] <Robomot> How to make a chatbot that isn’t racist or sexist | MIT Technology Review
[19:42:49] <PapuaHardyNet> GPT-3 is based
[19:42:51] <shawwwn> you can imagine yourself collecting the training data and solving the problem
[19:43:03] <shawwwn> so I don't think that a specific MT problem is hard, is my point
[19:43:09] <shawwwn> the hard part is doing it *in general*
[19:43:24] <Gurkenglas> shawwwn, what if ML can be used to take in the task description and input and produce the output
[19:43:34] <Gurkenglas> does that count as AGI from ML?
[19:44:04] <ggreer> https://twitter.com/mmpaquette/status/1449219245192134656 O_O
[19:44:05] <|dbotdan> Michelle M. Paquette (@mmpaquette, 2021-10-16 03:42): ‘Giving birth (no epidural) was feral. I had no control over what my body was doing. It was actually unexpected, because even though I was prepared for it to be crazy, I didn't expect it to be so involuntary. Kind of like vomiting... but more violent and with a baby.’
[19:44:06] <shawwwn> remarkably difficult question. I think I am forced to say yes
[19:44:45] <Gurkenglas> okay, so my 1k$ against your savings. If someone else wants to wager 10k$ a month from now what do you do
[19:46:11] <pompolic> is MT "mechanical turk"?
[19:46:15] <Gurkenglas> yep
[19:46:20] <pompolic> ty
[19:46:35] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 260 seconds)
[19:46:47] <pompolic> ofc i notice it in scrollback as soon as i ask that
[19:47:01] <Gurkenglas> ctrl-f :)
[19:48:04] <pompolic> also: mild envy @ shawwn having a line to john carmack :D (if it's indeed that carmack)
[19:49:14] <Gurkenglas> shawwwn, or did i misunderstand and a 1k$ payin gets me a 2k$ payout?
[19:50:29] <Gurkenglas> guys he isn't answering i think i win the debate in 30 seconds
[19:50:54] *** Joins: Lord_of_Life (~Lord@user/lord-of-life/x-2819915)
[19:51:05] <rsaarelm> Gurkenglas: I thought the bet was shawwwn's savings vs 2x shawwwn's savings from you if AGI doesn't materialize as expected.
[19:52:10] <Gurkenglas> oh. obvious in hindsight that that would be the order of operations, i failed my braincache lookup
[19:56:24] <Gurkenglas> shawwwn, i don't have six digits. maybe i could acquire them if i was desperate but we don't know and doing it in advance seems silly given that going up that order of magnitude costs fractions of my soul and then winning the bet doesn't make that much logarithmic difference
[19:56:58] <Gurkenglas> also if the payoff is merely one money doubling, i agree with the people you talked with that the expected value of that money is too small
[19:57:16] <kiboneu> dude
[19:57:18] <kiboneu> ugh
[19:57:24] <kiboneu> not again
[19:58:07] <kiboneu> we need better anti-nerd-sniping antibodies
[19:58:58] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf) (Quit: Client closed)
[20:00:51] <kiboneu> anyway, i find it amazing that the government tried to pump heroic doses of lsd only to make a couple of dysfunctional (and ultrafunction bomb mailers) considering that tiktok girls are developing tics from watching meme videos
[20:01:07] <Gurkenglas> shawwwn, if post-foom we find that we can do an acausal trade with someone but also they are bad at predicting us and so we could trick them. would you vote that we trick them or that we don't?
[20:01:10] <kiboneu> it's like using a jackhammer to screw in some nails
[20:04:11] <PapuaHardyNet> is gurkenglas nerd-sniped
[20:04:21] <PapuaHardyNet> well, I think he is always nerd-sniped tbh
[20:04:34] <kiboneu> i mean this appened last night too
[20:05:13] <kiboneu> but that's just my opinion, it doesn't mean much, people have their own preferences w.r.t. conversation i guess
[20:05:24] <Gurkenglas> kiboneu, i don't follow your longest line there. what does ti mean to pump lsd? to make a couple what?
[20:05:28] <PapuaHardyNet> it's fun to talk to Gurkenglas though - he clearly has a ridiculously high fluid intelligence
[20:05:53] <PapuaHardyNet> simply keeping up with him is an achievement
[20:05:54] <kiboneu> Gurkenglas: i was referring to mkultra / psyops tech
[20:06:09] <Gurkenglas> it's also fun to have a ridiculously high fluid intelligence!
[20:06:19] <kiboneu> it is
[20:06:29] <kiboneu> Gurkenglas: kaczynski went through mkultra
[20:06:31] <kiboneu> er
[20:06:36] <kiboneu> the harvard experiments
[20:06:45] <Gurkenglas> fiiiiiine ill google it
[20:06:51] <kiboneu> got kinda pissed at humans for being stupid
[20:06:56] <kiboneu> and overdid it
[20:07:53] <kiboneu> imagine living in a forest and getting familiar with the seasonal cycles there
[20:08:18] <kiboneu> you come back after a trip and there's a block of cut tries and a road sign just in the middle
[20:08:37] <kiboneu> i'd be kind of pissed too. but it's really something to then, you know
[20:09:25] <Gurkenglas> are you high or something, it's like you're GPT
[20:09:49] <kiboneu> I guess you don't have context
[20:09:53] <kiboneu> one sec
[20:10:09] <PapuaHardyNet> kiboneu is describing Kaczynski's experience
[20:10:21] <PapuaHardyNet> everything he said is in that context
[20:10:23] <kiboneu> yeah, sorry to leave it unclarified
[20:11:19] <Gurkenglas> there's a famous bomber called kaczynski, who also went through what this google result says was vigorous interrogation, which you claim involved lsd
[20:12:01] <kiboneu> yeah when he worked with Henry Murray
[20:12:49] <kiboneu> this guy was at it for 17 years
[20:13:40] <kiboneu> https://orionmagazine.org/article/dark-ecology/
[20:13:41] <Robomot> Orion Magazine - Dark Ecology (Take the only tree that’s left, Stuff it up the hole in your culture. —Leonard Cohen Retreat to the desert, and fight. —D. H. Lawrence THE HANDLE, which)
[20:13:54] <Gurkenglas> and he's not the only "madman" from that study, and the government should have expected such given that tiktok causes tics?
[20:13:57] <kiboneu> "he best place, to me, was the largest remnant of this plateau that dates from the Tertiary age. It’s kind of rolling country, not flat, and when you get to the edge of it you find these ravines that cut very steeply in to cliff-like drop-offs and there was even a waterfall there. . . . That summer there were too many people around my cabin so I decided I needed some peace. I went back to the
[20:13:59] <kiboneu> plateau and when I got there I found they had put a road right through the middle of it. . . . You just can’t imagine how upset I was. It was from that point on I decided that, rather than trying to acquire further wilderness skills, I would work on getting back at the system. Revenge."
[20:14:55] <kiboneu> Gurkenglas: there was plenty of research on memetics too, just not as popular until the internet became more commonplace
[20:15:29] <kiboneu> Gurkenglas: oh, I see what you mean. Yes, pretty much
[20:15:53] <kiboneu> given the volatility / lack of control in psyops with drugs
[20:16:35] <Gurkenglas> seems sensible enough for a government to do the kind of research that might for all they know have unlocked telekinesis or IQ increase or being functional on 2 hours of sleep
[20:16:51] <Gurkenglas> though maybe they shouldn't have used harvard students, that's asking for protagonists
[20:17:12] <kiboneu> lsd does not make you functional, but yeah it does disrupt your ability to sleep while you are one it
[20:17:20] <kiboneu> and the increase of iq needs to be useful
[20:17:56] <kiboneu> it was kind of a nutty time though
[20:18:00] <pompolic> developing tics from watching meme videos?
[20:18:03] <kiboneu> with the soviets and stuff
[20:18:21] <kiboneu> i have to catch a train
[20:18:49] <Gurkenglas> if they find that lsd gives people stuck on a research problem for 2 years breakthroughs, say, seems like a good ace to have for the next manhattan project.
[20:19:34] <kiboneu> pompolic: yeah there's some article about some gov entity blaming tictoc for teens developing ticks. but more-so, it has all these gamified challenges that obviously promote anti-social behavior
[20:19:49] <kiboneu> Gurkenglas: yeah, fair enough
[20:20:00] <kiboneu> i don't think being tortured while on acid helps with this though
[20:20:41] <kiboneu> fwiw i think lsd can be useful
[20:20:50] <kiboneu> time to stop procrastinating my train ride
[20:22:01] <feep> how do you procrastinate a train ride
[20:22:27] <feep> * kiboneu surreptitiously presses the button on his phone that unblocks the track segment ahead of his intercity
[20:22:50] <gwern> 'The Green Revolution is trumpeted by progressives as having supposedly “fed a billion people” who would otherwise have starved. And maybe it did; but then we had to keep feeding them—or should I say us?—and our children. In the meantime it had been discovered that the pesticides and herbicides were killing off vast swaths of wildlife, and the high-yield monoculture crops were...
[20:22:56] <gwern> ...wrecking both the health of the soil and the crop diversity, which in previous centuries had helped prevent the spread of disease and reduced the likelihood of crop failure. It is in this context that we now have to listen to lectures from the neo-environmentalists and others insisting that GM crops are a moral obligation if we want to feed the world and save the planet: precisely the...
[20:23:02] <gwern> ...arguments that were made last time around. GM crops are an attempt to solve the problems caused by the last progress trap; they are also the next one.' <-- nice to see one be honest that they see humans as bad things and increases in population as intrinsically bad and 'progress traps'
[20:23:09] <gwern> 'he said the quiet part out loud'
[20:23:12] <feep> gwern: yeah I was gonna say "that sounds pretty antinatalist"
[20:25:15] <kuudes> I guess they would be happier if we nuked everything to glass to remove suffering?
[20:26:34] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf)
[20:26:40] <gwern> no, that would take Nature with it! an engineered pandemic would be much better
[20:27:21] <Gurkenglas> .note shawwwn FAI finds stupider AGI in the cosmos, they reveal source code to each other to prove mutual cooperation, FAI finds that it can exploit an obscure bug in the other's proof engine to defect while the other cooperates, it consults the humans, do you vote that it cooperate or defect?
[20:28:06] <kiboneu> gwern: yeah i've met people who were outwardly anti-human
[20:28:09] <kiboneu> it's kind of weird
[20:28:10] <feep> this starts as a slice of life anime and immediately edges into horror
[20:28:24] <mst> kuudes: I mean, in the case of half of the middle east it's sometimes tempting
[20:28:49] <kiboneu> feep: that _experience_ of a train ride, i suppose
[20:29:13] * kiboneu sighs as he looks at his own predicament and the cosmic humor of it all
[20:29:45] <Gurkenglas> i was quite surprised when i went from the STEM campus to the humanities campus of my university and the people there were almost unanimously of the opinion that it'd be better if humans went extinct over the coming centuries
[20:30:27] <Gurkenglas> bubbles, yo.
[20:31:19] <Gurkenglas> therefore, fai might ship us all to space just so earth can heal or something.
[20:31:42] <PapuaHardyNet> Gurkenglas: how are things wrt your main project?
[20:31:54] <PapuaHardyNet> the uh, the math thing - interpretability
[20:32:32] <Gurkenglas> uhhhh no recent tool progress, too little reading as well
[20:33:18] <Gurkenglas> anyone know anyone into statistics? such as probabilistic graphical models
[20:33:47] <Robomot> [Less Wrong [frontpage]] Write Surprisingly About Reality by lsusr - https://www.greaterwrong.com/posts/v75CrxDPniB9dzvE9/write-surprisingly-about-reality
[20:34:20] <pompolic> adopting misanthropic beliefs to signal to my fellow college-educated humans
[20:36:28] <superz_> would rob henderson's concept of luxury beliefs fit there?
[20:39:43] <Gurkenglas> might well be that one or two had that opinion and then the others copied it because they perceived their status or something, but those seem convenient excuses
[20:40:21] <pompolic> i tend to think of them as luxury beliefs yes
[20:40:29] <pompolic> also: >Reversed conformity is orthogonal to independent thought. Independent thought equals ignoring others’ opinions.
[20:40:32] <pompolic> i like this
[20:40:44] <pompolic> (from the the frontpage post)
[20:41:32] <pompolic> anyway
[20:41:35] <pompolic> my thinking
[20:41:57] <pompolic> i know what at least a deep mistrust of humans is like from the inside
[20:42:21] <pompolic> people emitting statements like "humans bad" don't seem to be consistent with it
[20:43:36] <pompolic> for example: they would not trust or seek approval of their friends
[20:43:39] <PapuaHardyNet> gwern: does NovelAI use this method called "prompt tuning"? https://arxiv.org/pdf/2104.08691.pdf
[20:43:41] <Robomot> PDF (15 pages; 535 KB) - The Power of Scale for Parameter-Efficient Prompt Tuning …
[20:44:50] <Gurkenglas> ah, humanities campus. i went to debate club once and the judge said i woulda won the debate had i not brought up that by the way the other side is silently assuming that nazis are bad
[20:45:54] <gwern> PapuaHardyNet: I think they may, actually, them or holo
[20:46:03] <rmmh> https://twitter.com/jayadan/status/1448828625273475074
[20:46:06] <pompolic> not that that's a bad assumption to make
[20:46:07] <|dbotdan> Jay Adán 🔀 (@jayadan, 2021-10-15 01:50): ‘I'm not sure what I expected a puffer fish skeleton to look like but I don't think this was it.’ Images: https://nitter.skrep.in/pic/media%2FFBtF3v2XMAEPiTG.jpg%3Fname%3Dorig (description: a hand holding a small turtle; confidence: 0.34)
[20:46:07] <PapuaHardyNet> holo?
[20:46:13] <gwern> the other one
[20:46:13] <pompolic> but there are rules, reeeeee
[20:46:28] <PapuaHardyNet> oh, holoai is another similar offering: https://writeholo.com/
[20:46:28] <Robomot> Holo AI (AI Generated Stories and Games)
[20:47:52] <PapuaHardyNet> NovelAI discord rules you need to agree to get access:
[20:48:21] <PapuaHardyNet> "If you see something against the rules or something that makes you feel unsafe, let staff know. We want this server to be a welcoming space!"
[20:49:31] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 252 seconds)
[20:50:43] <Gurkenglas> did you let them know about the rule
[20:51:16] *** Joins: two2thehead (~user@124.195.202.105)
[20:52:16] <Filipepe> as I listen to these binaural beats, the possiblity that I might just be acting as a complete idiot, listening to noise for nothing doesn't leave my head
[20:52:34] <PapuaHardyNet> Gurkenglas: yeah and get banned immediately
[20:52:41] <Gurkenglas> Filipepe, see, it is making you smarter!
[20:52:48] <PapuaHardyNet> of course I wouldn't do anything like that
[20:53:19] <PapuaHardyNet> anyway, it seems NovelAI does use prompt tuning, and that is probably what they call "AI module training"
[20:53:28] <PapuaHardyNet> based on discord chat history at least
[20:56:42] <gwern> they talked about it on reddit in a reply to me but I dunno where
[20:57:22] <PapuaHardyNet> "'prompt tuning', or 'prefix tuning' is slapping a custom, final layer onto the model that gives actual bias differences outside of the batch of tokens that make the context. This is done with modules on NAI.
[20:57:26] <PapuaHardyNet> "
[20:57:33] <Obormot\Arcturus> https://www.greaterwrong.com/posts/XPwEptSSFRCnfHqFk/zoe-curzi-s-experience-with-leverage-research#comment-ddKJigGS6ytiwtPJW ... can't help but notice that neither of these people bothered to really answer wtf these terms mean...
[20:57:36] <Robomot> Zoe Curzi's Experience with Leverage Research - LessWrong 2.0 viewer [Said Achmiz 16 Oct 2021 8:54 UTC 2 pointsParentWhat are “intense” and/or “moral” communities …]
[20:59:28] *** Quits: LeoTal (~LeoTal@1.170.86.79.rev.sfr.net) (Quit: Leaving.)
[21:02:36] <feepbot> <gwern> https://www.ctrl.blog/entry/text-wrap-balance.html
[21:02:36] <feepbot> Improving the New York Times’ line wrap balancer (Web browsers don’t yet support (text-wrap: balance). Adobe and the NYTimes have offer free JavaScript alternatives. I improved the latter to suit my needs.)
[21:04:01] <mst> feep: this might be your sort of fun: https://bugbyte.fi/spacehaven/
[21:04:02] <Robomot> Space Haven – Spaceship colony sim inspired by Rimworld, Dwarf Fortress, Spacebase DF-9 and Oxygen Not Included.
[21:05:06] <feep> mst: noted thank you!
[21:05:14] *** Joins: LeoTal (~LeoTal@1.170.86.79.rev.sfr.net)
[21:10:06] <feepbot> <gwern> 'You can find sets of rollerblade-style wheels for about 25 USD on Amazon. These wheels are sometimes marketed as “gaming wheels”. Brands also apply the “gaming” label to chewing gum and plain bottled water, so it really doesn’t mean anything anymore.' https://www.ctrl.blog/entry/rollerblade-wheels-chair.html lol
[21:10:07] <feepbot> Rollerblade wheels are a great upgrade for your office chair (Rollerblade-style wheels don’t resist movement and help you stay slightly less inactive while spending hours in your office chair.)
[21:12:08] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[21:15:07] <feepbot> <gwern> uploads https://www.gwern.net/docs/silk-road/2020-sennewald.pdf
[21:20:07] <feepbot> <gwern> uploads https://www.gwern.net/docs/psychology/2021-vohs.pdf I've been checking in on this one for like a year and a half now, *finally* -_-
[21:21:33] <mst> feep: also references 'Starbase DF-9' which is apparently a double fine game
[21:26:34] <feepbot> <gwern> https://twitter.com/AlecStapp/status/1449407570381246466/photo/1 yeah, bezos is just so far behind it's pretty ridiculous to compare them at all
[21:26:37] <|dbotdan> Alec Stapp (@AlecStapp, 2021-10-16 16:11): ‘SpaceX is in a league of its own’ Images: https://nitter.pussthecat.org/pic/media%2FFB1UgLuXsAMpPZ-.jpg%3Fname%3Dorig (description: text; confidence: 0.70)
[21:31:38] <feepbot> <gwern> https://www.nytimes.com/2021/10/14/style/finding-love-autism-spectrum.html
[21:31:38] <feepbot> The Highs and Lows of Finding Love on the Spectrum - The New York Times (Not surprisingly, the romantic lives of autistic adults are just like those of neurotypical adults: never easy.)
[21:32:11] <adiabatic> does anyone here have any strong opinions on blue origin
[21:32:16] <adiabatic> I figure more space companies is better
[21:35:23] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 246 seconds)
[21:37:17] <feepbot> <gwern> https://interestingengineering.com/ex-spacex-engineers-are-building-a-cheap-portable-nuclear-reactor
[21:37:17] <feepbot> Ex-SpaceX Engineers Are Building a Cheap, Portable Nuclear Reactor (A team of former SpaceX engineers is developing the "world's first portable, zero-emissions power source" on Earth. )
[21:37:25] *** Joins: two2thehead (~user@124.195.202.105)
[21:37:43] <mst> spacex mafia
[21:42:44] <feepbot> <gwern> https://www.smbc-comics.com/comic/fun-fact-2
[21:42:45] <feepbot> Saturday Morning Breakfast Cereal - Fun Fact
[21:46:40] *** Quits: Robomot (~Robomot@user/robomot) (Quit: Bye)
[21:46:53] *** Joins: Robomot (~Robomot@user/robomot)
[21:46:53] *** ChanServ sets mode: +v Robomot
[21:50:32] <Obormot\Arcturus> https://www.smbc-comics.com/comic/october-13
[21:50:33] <Robomot> Saturday Morning Breakfast Cereal - October 13 (Saturday Morning Breakfast Cereal - October 13)
[21:50:53] <Robomot> [Leverage Accounts Anon] Leverage Accounts - https://medium.com/@anonleverage/leverage-accounts-1cd1b6335303?source=rss-d3bef065feca------2
[21:51:18] <saturn2> Obormot\Arcturus: i guess it means groups that think the status quo is intensely immoral
[21:51:31] <Obormot\Arcturus> Heh
[21:51:37] <Obormot\Arcturus> Anyway I added the leverage thing
[21:51:39] <Obormot\Arcturus> !feeds
[21:51:39] <Robomot> Available feeds in this channel: Overcoming Bias (OB), Less Wrong [frontpage] (LW), TheZvi (Zvi), Astral Codex Ten (ACX), The Last Rationalist (TLR), The Digital Antiquarian (filfre), Leverage Accounts Anon, Slate Star Codex (SSC), MIRI Blog (MIRI)
[21:51:49] <saturn2> cool
[21:51:52] <Obormot\Arcturus> Hm why isn't the shortname working...
[21:52:20] <Obormot\Arcturus> Oh because it's shortName. lol.
[21:52:31] <Obormot\Arcturus> Well, w/e, it'll get fixed at next restart
[21:52:38] <Obormot\Arcturus> The feed works, anyhow
[21:54:23] <Obormot\Arcturus> Now. What's up with baking powder? There are *at least* three different formulations. But why?
[21:54:42] <Obormot\Arcturus> Are some better? Cheaper? What motivates the differences?
[21:56:00] <[itchyjunk]> If you store a piece of cake in fridge, do you reheat it when you eat it later?
[21:56:03] <[itchyjunk]> or eat it cold?
[21:56:10] <PapuaHardyNet> you uh, you eat it cold
[21:56:17] <Obormot\Arcturus> [itchyjunk]: Neither
[21:56:23] <adiabatic> [itchyjunk]: consider letting it that at room temperature while you eat your dinner
[21:56:27] <[itchyjunk]> I tried it both and i can't make up my mind
[21:56:27] <Obormot\Arcturus> You let it come up to room temperature
[21:56:28] <adiabatic> thaw*
[21:56:41] <[itchyjunk]> adiabatic, ah i've done that in the past but didn't try that currently
[21:57:08] <PapuaHardyNet> thawing huh, that's smart. 
[21:57:31] <[itchyjunk]> i microwaved it a tiny bit and it was pretty decent minus the icing starting to melt
[21:58:07] <Obormot\Arcturus> It depends on the kind of cake, also...
[21:58:14] <[itchyjunk]> hmm
[21:58:52] <[itchyjunk]> oh this reminds me, do you heat your icecream a tiny bit or eat it cold? i found that some people prefer microwaving it and other eat it as cold as possible
[21:59:09] <[itchyjunk]> but i can't tell if it's a texture thing or taste thing
[21:59:30] <feep> microwaving icecream?!
[21:59:37] <[itchyjunk]> would a 'starting to melt' icecream taste different than cold?
[21:59:43] <adiabatic> I like eating it straight from the store before it cools down to my-freezer temperature
[21:59:45] <[itchyjunk]> yes they nuke it for a little so it's super soft
[21:59:49] <feep> ´wth
[21:59:53] <Obormot\Arcturus> I don't microwave anything because I don't own a microwave oven
[21:59:55] <feep> cold, definitely cold
[21:59:56] <[itchyjunk]> oh is this not common?
[22:00:07] <Obormot\Arcturus> And of course ice cream is best eaten cold
[22:00:15] <Obormot\Arcturus> The correct approach is to have warm chocolate sauce
[22:00:22] <Obormot\Arcturus> Pour it on the ice-cold ice cream
[22:00:27] <Obormot\Arcturus> Eat the mixture as it's melting
[22:00:35] <adiabatic> [itchyjunk]: microwaving ice cream is…fiddly. the waves won't penetrate far
[22:00:46] <[itchyjunk]> hmmmm
[22:01:14] <Obormot\Arcturus> So, let's see. Sodium aluminum phosphate, that's a "slow acting" acid (reacts with sodium bicarbonate at high temperatures, so useful for making "double acting" bk. pwd.), but... aluminum and thus maybe Alzheimer's? bad
[22:01:30] <Obormot\Arcturus> (Ditto the phosphate version)
[22:02:23] <Obormot\Arcturus> Then there's https://en.wikipedia.org/wiki/Disodium_pyrophosphate ... and I guess the problem there is the bitter taste?
[22:02:24] <Robomot> Disodium pyrophosphate - Wikipedia (Disodium pyrophosphate or sodium acid pyrophosphate (SAPP)[1] is an inorganic compound consisting of sodium cations and pyrophosphate anion. It is a white, water-soluble solid that serves as a buffering and chelating agent, with many applications in the food industry. When crystallized from water, it forms a hexahydrate, but it dehydrates above room temperature. …)
[22:03:48] <Obormot\Arcturus> And there's also https://en.wikipedia.org/wiki/Potassium_bitartrate ... which... is not as soluble in water?
[22:03:48] <Robomot> Potassium bitartrate - Wikipedia (Potassium bitartrate, also known as potassium hydrogen tartrate, with formula KC4H5O6, is a byproduct of winemaking. In cooking, it is known as cream of tartar. It is processed from the potassium acid salt of tartaric acid (a carboxylic acid). …)
[22:08:10] <Obormot\Arcturus> So I guess the challenges in baking powder formulation are: (a) is it water-soluble? (b) Is it double-acting (does it have a component that'll react only at baking temps and not prematurely at room temp)? (c) Is it flavor-neutral? (d) Is it devoid of stuff that'll give you horrible brain diseases?
[22:08:24] <Obormot\Arcturus> Looks like you can't get all 4 criteria satisfied at once
[22:11:32] <rmmh> I don't buy the aluminum risk anyways
[22:11:41] * Obormot\Arcturus shrug
[22:12:25] <gwern> [itchyjunk]: softserve is pretty different from out of the freezer hardserve
[22:12:43] <mst> horrible ... brain diseases?
[22:13:19] <mst> Obormot\Arcturus: "don't use that baking powder, it'll give you a nasty case of DiBlasio" ?
[22:13:22] <gwern> 'Over Memorial Day weekend of 1934, Tom Carvel, the founder of the Carvel brand and franchise, suffered a flat tire in his ice cream truck in Hartsdale, New York. He pulled into a parking lot and began selling his melting ice cream to vacationers driving by. Within two days he had sold his entire supply of ice cream and concluded that both a fixed location and soft (as opposed to hard) frozen...
[22:13:28] <gwern> ...desserts were potentially good business ideas.[2] In 1936, Carvel opened his first store on the original broken down truck site and developed a secret soft serve ice cream formula as well as patented super low-temperature ice cream machines.[3]' https://en.wikipedia.org/wiki/Soft_serve
[22:13:29] <Robomot> Soft serve - Wikipedia (Soft serve, also known as soft ice, is a frozen dairy dessert, similar to ice cream but softer and less dense as a result of air being introduced during freezing. Soft serve has been sold commercially since the late 1930s in the US.[1] …)
[22:13:51] <gwern> 'produced at a temperature of about −4 °C (25 °F) compared to ice cream, which is stored at −15 °C (5 °F).'
[22:14:35] * gwern didn't know carvel arguably invented softserve *or* that it was such a wacky origin story
[22:16:15] <rmmh> mst: correlations between aluminum and alzheimer's make people suspicious of aluminum in foods 
[22:16:31] <gwern> bjorksten was super-negative on aluminum too
[22:17:23] <mst> rmmh: <shitpost>it's damaged you already, you can't even spell aluminium anymore!</shitpost>
[22:17:33] * gwern squints as he decides on the subject for this paper. still hard to believe 'sexology' is a real word and actually the name of the field
[22:19:39] <Obormot\Arcturus> mst: lol
[22:23:17] <mst> gwern: clearly would've sounded more serious if they called it fornicatonomics
[22:24:28] <mst> or 'detumescence studies'
[22:24:42] <[itchyjunk]> gwern, ah interesting
[22:25:28] <[itchyjunk]> but i think the question about it being the texture or flavor is still unclear right? maybe people like the texture of something cold but starting to melt?
[22:25:58] <[itchyjunk]> can't think of evolutionary reasons to prefer certain textures like frozen vs thawed
[22:26:25] <[itchyjunk]> i imagine smell or taste or rotting food would give better signal than texture of it..
[22:26:56] <rmmh> the secret reason people love ice cream is it's 1/3 sugar
[22:27:40] <[itchyjunk]> yes but if sweetness explained it all, shouldn't people be eating 100% sugar in some form?
[22:27:49] <rmmh> yes, it's called hard candy
[22:27:55] <[itchyjunk]> i guess candies fit that bill but people don't substitute meal for it
[22:28:23] <[itchyjunk]> hmm but that might be because only sugar is not filling..
[22:28:38] <[itchyjunk]> welp i give up, the problem seem complex 
[22:28:51] <gwern> it's the fat too
[22:30:30] <[itchyjunk]> hmm, do people crave fat liek they do sweet stuff?
[22:30:43] <rmmh> ...are you a robot?
[22:30:48] <[itchyjunk]> "i have a sweet tooth" type thing
[22:30:51] <[itchyjunk]> i could be, why?
[22:30:56] <rmmh> people love fried food
[22:31:04] <rmmh> and fatty meats
[22:31:07] <linear> i think so, i definitely have fat and salt cravings but not sweet
[22:31:08] <rmmh> it's not the same as a carb craving, but
[22:31:43] <[itchyjunk]> I seem to know a lot less about people..
[22:33:22] <gwern> 'rabbit starvation'
[22:38:23] <feepbot> <gwern> uploads https://www.gwern.net/docs/psychology/2021-bondu.pdf
[22:42:41] <rmmh> https://twitter.com/ExcelPope/status/1449363985464184836
[22:42:41] <|dbotdan> Andrew R (@ExcelPope, 2021-10-16 13:17): ‘Person 1: The glass is 1/2 full | Person 2: The glass is 1/2 empty | Excel: The glass is the 1st of February’
[22:43:11] <mst> "Why doesn’t the ETF just store the Bitcoins itself? [...] physical custody of Bitcoins does seem to be an issue that the SEC worries about, and if an SEC-approved physical Bitcoin ETF forgot its passwords and lost all of its customers’ Bitcoins that would be really, really, really, really … let’s not kid ourselves, it would be hilarious, but it would be really upsetting for the SEC." 
[22:48:12] <feepbot> <gwern> https://twitter.com/AlecStapp/status/1449407570381246466/photo/1 yeah, bezos is just so far behind it's pretty ridiculous to compare them at all
[22:48:17] <|dbotdan> Alec Stapp (@AlecStapp, 2021-10-16 16:11): ‘SpaceX is in a league of its own’ Images: https://nitter.net/pic/media%2FFB1UgLuXsAMpPZ-.jpg%3Fname%3Dorig (description: text; confidence: 0.70)
[22:48:31] <superz_> deja vu
[22:48:41] <galambo> does tether cause inflation of the usd? does a bitcoin etf cause inflation of bitcoin?
[22:49:11] <gwern> some sort of irssi screwup. occasionally I get stuck in C-r and can't break out easily, and if I screw up the escape, it may resend what seems like a random message from history
[22:49:31] <Filipepe> galambo: hello, good doctor
[22:49:42] <galambo> hi :D
[22:49:46] <galambo> long time no see
[22:49:58] <Filipepe> indeed
[22:51:04] <Obormot\Arcturus> [itchyjunk]: Fat, sugar, and salt are what make food delicious
[22:52:47] <[itchyjunk]> Speaking of salt, i saw a video where mountain goats climbed up a dam to lick some salt.
[22:53:04] <[itchyjunk]> How did humans manage to get their salt before they started drying sea water and such?
[22:53:23] <[itchyjunk]> humans lived all over the place, just got just enough from the food they ate?
[22:53:43] <[itchyjunk]> i supposed you could eat the mountain goat that liked some salt and hope it's enough
[22:54:44] <gwern> you trade for it, eat animals, find natural sources, hope you get enough from regular sources... being low salt won't kill you too effectively, so you may just be sicker and weaker and unhealthier than you could be, like being iodine-deficient
[22:55:07] <gwern> note that salt is one of the paradigmatic long-distance trades, along with metals
[22:55:26] *** Quits: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net) (Quit: Going offline, see ya!)
[22:55:36] * gwern recalls in _dead birds_ about papua new guineans, one of the only times the tribesmen leave their little niche is to travel to a salt spring, iirc
[22:55:38] *** Joins: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net)
[22:57:49] <[itchyjunk]> ah, didn't realize salt was a big ticket trading item back in the day. but now what i think of it, does makes sense
[23:01:29] <feep> yeah cause you need salt to conserve meat
[23:06:29] <feepbot> <gwern> 'I'll admit that I was wrong about GitLab. I had the chance to invest in them way back in the day, and passed. My thought at the time was that no open source company had ever been super successful except RedHat, which was more of an outlier than a pattern. And my other thought was that they are competing against GitHub, which was extremely popular and well funded. I
[23:06:29] <feepbot> honestly didn't think they stood a chance. I'm happy to have been proven wrong. Congrats to the whole team on their successful exit!' https://news.ycombinator.com/item?id=28863993 yep
[23:06:30] <feepbot> Gitlab from YC to IPO | Hacker News
[23:08:31] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf) (Quit: Client closed)
[23:12:31] *** Quits: martin02 (~silas@141.84.69.76) (Ping timeout: 252 seconds)
[23:15:03] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf)
[23:19:44] <gwern> feepbot: that's nice, yes, but you can dry meat for free. you really need it nutritionally
[23:24:52] <shawwwn> Gurkenglas: sorry, I fell asleep mid debate.
[23:24:53] <feepbot> shawwwn: Gurkenglas left a note 2 hours, 57 minutes ago: FAI finds stupider AGI in the cosmos, they reveal source code to each other to prove mutual cooperation, FAI finds that it can exploit an obscure bug in the other's proof engine to defect while the other cooperates, it consults the humans, do you vote that it cooperate or defect?
[23:25:20] * shawwwn still has no idea what FAI means
[23:25:26] <shawwwn> fastai
[23:25:31] <Gurkenglas> friendly ai
[23:25:33] <shawwwn> oh
[23:26:21] <[itchyjunk]> full ai?
[23:26:38] <kuudes> friendly ai
[23:26:44] <kuudes> ie aligned to human values
[23:26:45] <shawwwn> it's a tough question
[23:27:02] <kuudes> unfriendly ai is unaligned to human values, ie a paperclipper or whatever
[23:27:03] <shawwwn> I'm honestly not sure.
[23:27:28] <shawwwn> I was going to vote defect, but that would turn out badly if things go wrong
[23:27:43] <shawwwn> the other AI might have the capability of turning our FAI against us
[23:28:01] <Gurkenglas> your FAI is certain that's not going on.
[23:28:19] <shawwwn> but it's impossible for it t know for certain that things won't go badly
[23:28:20] <feep> my FAI has a bug, in that it's asking us
[23:28:43] <Gurkenglas> feep, it was deliberately constructed to consult the humans because some humans like their agency
[23:29:01] <feep> that sucks, humans are not safe :(
[23:29:05] *** Joins: martin02 (~silas@141.84.69.76)
[23:30:04] <Gurkenglas> humans are all there is. where else do you learn values
[23:30:29] <shawwwn> animals?
[23:30:48] <Gurkenglas> i mean, you can learn the values of some humans and then not consult those humans; it did that for those who were fine with that
[23:31:15] <adiabatic> broke: having your AI learn its values from 4channers on twitter. woke: having your AI learn its values from ichneumon wasps
[23:35:49] <shawwwn> I think I'll try heroin
[23:35:54] <shawwwn> how bad can it be?
[23:36:07] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:884e:35fa:1a96:7ebf) (Quit: Client closed)
[23:36:10] <adiabatic> probably not as bad as meth
[23:40:55] <Gurkenglas> shawwwn, rephrasing: FAI finds that in the past, a human sacrificed much of their life to alignment research, figuring that if he succeeds he gets compensated after foom. Do you prefer that he be compensated, through disproportional ressource allocation/voting power?
[23:41:22] <PapuaHardyNet> shouldn't you be asleep Gurkenglas
[23:41:46] <Gurkenglas> PapuaHardyNet, why do you think so? it's only 22:11
[23:42:12] <PapuaHardyNet> based on our werewolf call, I thought you had an enforced bedtime
[23:42:51] <Gurkenglas> nah i was just called to eat and then was p&p time
[23:44:21] <PapuaHardyNet> what is... p&p?
[23:44:54] <Gurkenglas> pen and paper. i did mention that near the start of the call iirc
[23:45:18] <PapuaHardyNet> what is that? special time to do math?
[23:45:24] <Gurkenglas> pengeons and papergons
[23:45:38] <PapuaHardyNet> huh, dnd, i see
[23:45:59] *** Quits: martin02 (~silas@141.84.69.76) (Ping timeout: 264 seconds)
[23:49:05] *** Joins: martin02 (~silas@141.84.69.76)
[23:50:39] <feepbot> <gwern> https://psyarxiv.com/jtwk7/ ah, another one of those "we threw in a PGS, that means we controlled for all possible genetics and can interpret everything as a causal effect of environment, right? because we'd really like to interpret it that way"
[23:52:04] *** Quits: src (~src@user/src) (Quit: Leaving)
[23:53:45] <Urchin[emacs]> https://i.redd.it/79yi0hg41tt71.png there's even a diamond on it
[23:53:45] <Robomot> image/png (794x567; 317 KB)
[23:57:20] <shawwwn> Gurkenglas: I don't know what foom is
[23:58:16] <shawwwn> I tried to google for it and google had some helpful suggestions
[23:58:18] <shawwwn> https://i.imgur.com/DdcNeKv.png
[23:58:34] <feep> haha
[23:58:37] <feep> shawwwn: "AI go foom"
[23:59:02] <feep> basically, if you go to sleep at slightly above human intelligence and are woken up at 3am by being eaten by a nanoswarm, you've been foomed
[23:59:28] <feep> it's an onomatopoeia for an explosion
