[00:01:31] <extern> rofl
[00:01:43] <extern> yeti: 
[00:01:54] <extern> you forgot to tell me about files-from= in rsync
[00:03:04] <yeti> what about directly git'ing it?
[00:03:15] <yeti> check the --separate-git-dir= option of git init
[00:04:19] <yeti> 1st ignoring all in .gitignore and then manualla   git add  the files you want to backup
[00:04:57] <yeti> I bet someone has written over such a way in the all knowing trash heap
[00:06:43] <yeti> https://www.anand-iyer.com/blog/2018/a-simpler-way-to-manage-your-dotfiles.html
[00:36:05] <extern> why it's not ignoring the first field ?
[00:36:09] <extern> echo ./this/is/a/test | awk -F / '{for(i=3;i<=NF;i++) printf $s, $i}'
[00:36:22] <extern> it prints all the fields
[00:37:13] <emanuele6> $s?
[00:38:21] <emanuele6> s is default initialised to 0
[00:38:25] <emanuele6> $s is $0
[00:38:50] <emanuele6> $0 ("./this/is/a/test") has no format codes, $i is ignored
[00:39:02] <emanuele6> $0 is used as the format for printf
[00:39:17] <emanuele6> you probably meant
[00:39:21] <emanuele6> echo ./this/is/a/test | awk -F / '{for(i=3;i<=NF;i++) printf "%s", $i}'
[00:39:27] <emanuele6> # echo ./this/is/a/test | awk -F / '{for(i=3;i<=NF;i++) printf "%s", $i}'
[00:39:28] <shbot> emanuele6: isatest
[00:39:37] <emanuele6> but what's the point of this script?
[00:40:38] <extern> acctually what i meant is to omit the first ../ and print the rest as usual
[00:41:24] <emanuele6> i don't see any "../" and i have explained to you why printf $s, $i prints the whole line
[00:41:36] *** Joins: Nintendo (~smb3@user/great)
[00:41:55] <extern> yes
[00:43:05] <extern> ./this/is/a/test
[00:43:21] <extern> i want this/is/a/test
[00:43:51] <emanuele6> you don't even need awk for that
[00:44:03] <emanuele6> # echo ./this/is/a/test | cut -d/ -f2- 
[00:44:05] <shbot> emanuele6: this/is/a/test
[00:44:11] <emanuele6> but it's unclear why you want that
[00:44:56] <extern> emanuele6: i found a better solution to my rsync problem
[00:45:10] <extern> instead of recursively adding complicated dir paths i jsut use --files-from
[00:45:16] <extern> and include the files directly
[00:45:42] <extern> but that option is relative to the corrent location so i need to omit the first ./ or blabla/ in find
[00:45:54] <extern> i knew about cut -d just interested knowing how to do that in awk
[00:46:39] *** Joins: seninha (~seninha@user/seninha)
[00:53:55] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 252 seconds)
[00:59:50] *** Quits: seninha (~seninha@user/seninha) (Quit: Leaving)
[01:00:38] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[01:10:41] <extern> echo ./this/is/a/test | awk -F / 'BEGIN {OFS = "/"} { for(i=2;i<=NF;i++) printf $i; printf "\n"}'
[01:10:48] <extern> i was under the impression that this would work
[01:11:44] <geirha> surely ./ is not problematic ./foo/bar and foo/bar is the same path
[01:12:04] <geirha> printf("%s", $i);
[01:12:39] <geirha> as for removing blabla/ just cd into blabla before running find
[01:12:49] <extern> geirha: rsync --files-from expect relative paths and im using find which includes ./ or whatever /src/ is
[01:13:08] <geirha> ./foo/bar and foo/bar are both relative paths
[01:19:04] <extern> it wont work with --files-from
[01:19:53] <geirha> I just tested it. Worked for me
[01:20:18] *** Quits: nvmd (~nvmd@user/nvmd) (Quit: Later, nerds.)
[01:20:49] <extern> in
[01:21:30] <extern> if you add ${HOME} to the file it will throw an error that there is not a file ${HOME}${HOME}....
[01:21:41] <extern> so i thought what's the difference with ./
[01:21:50] <extern> to one of the file paths
[01:22:14] <extern> i was under the impression that it always add ${HOME}
[01:23:29] <geirha> ~/ is what gets expanded to "$HOME". ./ is just the current directory
[01:23:32] <extern> it adds the full path to the place you run rsync from
[01:23:41] <extern> so why that 
[01:23:45] <extern> "./" is not an error ...
[01:26:04] <emanuele6> # echo '~:' ~; echo '~/afile:' ~/afile; echo './afile:' ./afile
[01:26:06] <shbot> emanuele6: ~: /root
[01:26:06] <shbot> emanuele6: ~/afile: /root/afile
[01:26:06] <shbot> emanuele6: ./afile: ./afile
[01:26:25] <emanuele6> ~ is a shell expansion that expands "$HOME"
[01:26:50] <emanuele6> . is not an expansion and doesn't expand because "foo" and "./foo" are equivalent relative paths at the os level
[01:26:57] <geirha> http://ix.io/3AgD
[01:27:12] <geirha> copied the two files I passed to --files-from, with ./ in front
[01:32:14] <extern> geirha it worked i just didn't understand why given rsync is added the current directory to each of the files 
[01:32:22] <extern> s/added/adding
[01:32:40] <roarde> pardon me if i didn't understand the question
[01:32:48] <roarde> # printf '%s\n' '/home/roarde/.config' './.config' '.config' | awk '{sub(/^(\.\/)|(\/home\/roarde)\//, "", $0); print}'
[01:32:49] <shbot> roarde: .config
[01:32:50] <shbot> roarde: .config
[01:32:50] <shbot> roarde: .config
[02:07:07] *** Joins: jess (~jess@libera/staff/jess)
[02:09:14] *** Joins: nmz (~nmz@adsl-72-50-6-136.prtc.net)
[02:19:29] *** Joins: seninha (~seninha@user/seninha)
[02:38:34] *** Quits: extern (~archer@80.246.138.111) (Remote host closed the connection)
[03:45:23] *** Quits: nmz (~nmz@adsl-72-50-6-136.prtc.net) (Ping timeout: 246 seconds)
[03:55:31] *** Quits: Nintendo (~smb3@user/great) (Ping timeout: 245 seconds)
[03:57:43] *** Joins: Nintendo (~smb3@user/great)
[04:02:11] *** Quits: earnestly (~earnest@user/earnestly) (Ping timeout: 245 seconds)
[04:18:58] *** Quits: seninha (~seninha@user/seninha) (Quit: Leaving)
[04:30:26] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[04:35:01] *** Joins: vlm (~vlm@user/vlm)
[04:41:28] *** Joins: seninha (~seninha@user/seninha)
[05:08:48] *** Quits: Torr (~Torr@user/torr) ()
[05:09:00] *** Joins: Torr (~Torr@user/torr)
[05:10:50] *** Joins: nmz (~nmz@adsl-72-50-5-53.prtc.net)
[05:41:46] *** Joins: defjam (~eb0t@90.196.142.47)
[05:49:43] *** Quits: seninha (~seninha@user/seninha) (Quit: Leaving)
[06:18:31] *** Quits: tirnanog (~tirnanog@user/tirnanog) (Quit: = "")
[06:48:26] *** Quits: nmz (~nmz@adsl-72-50-5-53.prtc.net) (Ping timeout: 246 seconds)
[07:32:43] *** Joins: waldo323__ (~waldo323@d14-69-96-170.try.wideopenwest.com)
[07:35:29] *** Quits: waldo323_ (~waldo323@d14-69-96-170.try.wideopenwest.com) (Ping timeout: 264 seconds)
[07:39:22] *** Quits: lgc (~lgc@user/lgc) (Quit: WeeChat 3.2-dev)
[07:39:55] *** Joins: nmz (~nmz@adsl-72-50-5-184.prtc.net)
[08:16:59] *** Quits: defjam (~eb0t@90.196.142.47) (Ping timeout: 246 seconds)
[08:19:02] *** Joins: defjam (~eb0t@90.202.255.249)
[08:28:40] *** Quits: Torr (~Torr@user/torr) ()
[08:28:51] *** Joins: Torr (~Torr@user/torr)
[08:45:31] *** Quits: Torr (~Torr@user/torr) (Ping timeout: 245 seconds)
[08:53:01] *** Joins: Andrew_ (~andrew@user/andrewyu)
[08:53:35] *** Quits: AndrewYu (~andrew@user/andrewyu) (Ping timeout: 252 seconds)
[09:07:00] *** Quits: jetchisel (jetchisel@user/jetchisel) (Quit: Unfortunately time is always against us -- [Morpheus])
[09:17:55] *** Joins: jetchisel (jetchisel@user/jetchisel)
[10:08:26] *** Quits: defjam (~eb0t@90.202.255.249) (Ping timeout: 245 seconds)
[10:10:18] *** Joins: defjam (~eb0t@90.209.55.200)
[10:29:02] *** Joins: lavaball (felix@31.204.155.215)
[10:44:10] *** Quits: roarde (~roarde@user/roarde) (Quit: Leaving)
[11:04:07] *** Quits: defjam (~eb0t@90.209.55.200) (Read error: Connection reset by peer)
[11:09:34] *** Joins: defjam (~eb0t@90.199.243.11)
[11:42:41] *** Joins: earnestly (~earnest@user/earnestly)
[11:52:17] *** Quits: siraben (~siraben@user/siraben) (Quit: Bridge terminating on SIGTERM)
[11:52:18] *** Quits: psydroid (~psydroid@user/psydroid) (Quit: Bridge terminating on SIGTERM)
[11:52:34] *** Quits: jmcantrell (~jmcantrel@user/jmcantrell) (Quit: Bridge terminating on SIGTERM)
[11:55:09] *** Joins: psydroid (~psydroid@user/psydroid)
[11:58:17] *** Quits: Nintendo (~smb3@user/great) (Ping timeout: 264 seconds)
[11:58:59] *** Joins: Nintendo (~smb3@user/great)
[12:01:15] *** Joins: jmcantrell (~jmcantrel@user/jmcantrell)
[12:01:15] *** Joins: siraben (~siraben@user/siraben)
[12:07:48] *** Quits: jle (~jle@aftr-88-152-185-251.unity-media.net) (Changing host)
[12:07:48] *** Joins: jle (~jle@user/jle)
[12:29:35] *** Joins: extern (~archer@141.226.60.187)
[12:29:41] <extern> good afernoon
[12:29:54] *** Quits: extern (~archer@141.226.60.187) (Client Quit)
[12:36:42] *** Joins: extern (~archer@141.226.60.187)
[12:45:05] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 264 seconds)
[13:10:53] *** Quits: earnestly (~earnest@user/earnestly) (Ping timeout: 264 seconds)
[13:11:19] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[13:25:15] *** Joins: mknod (~mknod@user/mknod)
[13:27:45] *** Quits: wuseman (~wuseman@user/wuseman) (Quit: ZNC 1.8.2+deb2build1 - https://znc.in)
[13:27:58] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 252 seconds)
[13:28:24] <mknod> # awk -F '\t'  '{ printf("FS is \"%s\"\n$1 is \"%s\"\n", FS, $1) }' <<< $'foo bar\tbaz qux'
[13:28:25] <shbot> mknod: FS is " "
[13:28:25] <shbot> mknod: $1 is "foo bar"
[13:28:32] <mknod> # awk -F '\\t' '{ printf("FS is \"%s\"\n$1 is \"%s\"\n", FS, $1) }' <<< $'foo bar\tbaz qux'
[13:28:33] <shbot> mknod: FS is "\t"
[13:28:33] <shbot> mknod: $1 is "foo bar"
[13:28:36] <extern> sure ..
[13:31:03] *** Joins: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com)
[13:31:03] *** Quits: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com) (Changing host)
[13:31:03] *** Joins: wuseman (~wuseman@user/wuseman)
[13:34:27] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[13:44:55] *** Quits: wuseman (~wuseman@user/wuseman) (Quit: ZNC 1.8.2+deb2build1 - https://znc.in)
[13:48:34] *** Joins: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com)
[13:48:34] *** Quits: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com) (Changing host)
[13:48:34] *** Joins: wuseman (~wuseman@user/wuseman)
[13:51:57] <extern> i want to lilst all files in current directory and get awk to filter only those filename that have a substring of 14 digits in them
[13:54:01] *** Quits: wuseman (~wuseman@user/wuseman) (Quit: ZNC 1.8.2+deb2build1 - https://znc.in)
[13:54:25] <mknod> standard awk cannot process file lists safely, that's not a job for awk.
[13:56:07] <mknod> of course that may work for a quick and dirty one-off job...
[13:59:27] *** Quits: wwallace (~afernande@63.240.73.102) (Changing host)
[13:59:27] *** Joins: wwallace (~afernande@user/wwilliam)
[13:59:27] *** wwallace is now known as wwilliam
[14:00:12] *** Joins: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com)
[14:00:12] *** Quits: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com) (Changing host)
[14:00:12] *** Joins: wuseman (~wuseman@user/wuseman)
[14:11:29] <wwilliam> and if we compare the numbers on the IRrecon and IM files?
[14:11:53] <wwilliam> like compare field 4 and if it equal move to a dir?
[14:13:02] <wwilliam> Hello I have 2 files   IMGSOAA_PPD_20210928123430_C_0039.zip IR_ASOA_ZIPReconciliation_20210928123430.zip  
[14:13:43] <wwilliam> How do i compare if field -F_ $4 are equals and if they are move them to anoter dir?
[14:13:57] <jetchisel> a loop
[14:14:17] <geirha> C != 20210928123430.zip  so not a match
[14:14:18] <wwilliam> can you write it please i have no idea.
[14:15:06] <wwilliam> ughhh
[14:15:11] <wwilliam> yes geirha
[14:15:48] <wwilliam> hmm in the IMGSOAAs the field is 3
[14:16:05] <wwilliam> in the IR_ASOA_ZIPReconciliation the field is 4
[14:16:12] <wwilliam> can i compare those 2?
[14:19:07] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 252 seconds)
[14:25:35] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[14:34:39] *** Quits: wuseman (~wuseman@user/wuseman) (Quit: ZNC 1.8.2+deb2build1 - https://znc.in)
[14:37:58] *** Joins: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com)
[14:37:58] *** Quits: wuseman (~wuseman@90-227-27-97-no68.tbcn.telia.com) (Changing host)
[14:37:58] *** Joins: wuseman (~wuseman@user/wuseman)
[14:39:16] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 245 seconds)
[14:56:24] <Patsie> sure, why couldn't you?
[14:56:54] <Patsie> # awk -F_ '$3".zip" == $8 { print $3 ".zip is equal to " $8 }' <<<"IMGSOAA_PPD_20210928123430_C_0039.zip IR_ASOA_ZIPReconciliation_20210928123430.zip"
[14:56:55] <shbot> Patsie: 20210928123430.zip is equal to 20210928123430.zip
[14:57:09] <Patsie> # awk -F_ '$3".zip" == $8 { print $3 ".zip is equal to " $8 }' <<<"IMGSOAA_PPD_20210999999999_C_0039.zip IR_ASOA_ZIPReconciliation_20210928123430.zip"
[14:57:10] <shbot> Patsie: no output
[15:09:00] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[15:51:27] *** Joins: ravan (~ravan@user/ravan)
[15:55:59] *** Quits: ravan (~ravan@user/ravan) (Ping timeout: 252 seconds)
[15:57:12] *** Quits: extern (~archer@141.226.60.187) (Quit: WeeChat 3.2.1)
[16:28:01] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 245 seconds)
[16:30:45] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[16:41:52] <Nintendo> Put on your programmer hat, wwilliam.  Is the field you want to compare always the only 14-digit-long string prefixed by an underscore, for example?  If so, use that criteria instead of a field number that only exists inside your head.
[16:46:39] *** Joins: nvmd (~nvmd@user/nvmd)
[16:50:15] *** Joins: seninha (~seninha@user/seninha)
[16:59:55] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[17:02:00] <wwilliam> Thank you Patsie Thank you Nintendo
[17:04:57] *** Quits: wuseman (~wuseman@user/wuseman) (Quit: ZNC 1.8.2+deb2build1 - https://znc.in)
[17:08:02] <Nintendo> Were you able to accomplish the task?
[17:08:04] *** Joins: wuseman (wuseman@90-227-27-97-no68.tbcn.telia.com)
[17:08:04] *** Quits: wuseman (wuseman@90-227-27-97-no68.tbcn.telia.com) (Changing host)
[17:08:05] *** Joins: wuseman (wuseman@user/wuseman)
[17:26:43] *** Quits: unmanbearpig (~unmanbear@user/unmanbearpig) (Quit: unmanbearpig)
[17:27:12] *** Joins: unmanbearpig (~unmanbear@45.76.95.141)
[17:55:06] *** Quits: seninha (~seninha@user/seninha) (Ping timeout: 245 seconds)
[19:30:19] *** Joins: tully (~mastodon@user/tully)
[19:31:31] <tully> If I set FS to , then go through a file and change a field if the field matches a pattern, then print; the records with changed fields print without the FS but the unchanged records print with the FS
[19:31:35] <tully> Why?
[19:32:42] *** Joins: waldo323_ (~waldo323@d14-69-96-170.try.wideopenwest.com)
[19:33:12] <tully> BEGIN { FS="," }; { if ( $3 = /pattern/ ) $3 = "new pattern" }; { print }
[19:33:49] <emanuele6> $3 ~ /pattern/
[19:34:07] <tully> right
[19:34:10] <tully> my bad that was a typo
[19:34:16] <tully> I am using ~ in the code
[19:34:56] *** Quits: waldo323__ (~waldo323@d14-69-96-170.try.wideopenwest.com) (Ping timeout: 246 seconds)
[19:35:13] <nmz> you also need to change OFS to ,
[19:35:27] <tully> Ok. That is annoying..
[19:35:38] <nmz> what is?
[19:35:46] <emanuele6> BEGIN { FS=OFS="," }; { if ( $3 ~ /pattern/ ) $3 = "new pattern" }; { print }
[19:36:03] <tully> It worked. I didn't even know about OFS. Huh
[19:36:05] <nmz> tully: if you're dealing with csv, make sure the csv is simple
[19:36:24] <tully> Thanks
[19:36:48] <nmz> if your csv contains "", then theres a parser around
[19:37:30] <tully> It does... I just escaped the quotes
[19:39:51] <nmz> does it deal with {,",",} correctly?
[19:40:32] <emanuele6> it splits fields with FS (,), it doesn't parse csv, so no
[19:41:08] <nmz> what's better to parse? '' or \' ?
[19:45:52] <tully> og I found 4 fields with commas in the string. Damn it.
[19:50:40] <nmz> tully: put this in your $AWKPATH https://github.com/Nomarian/Awk-Batteries/blob/master/Units/csv/split.awk   call as awk -f split.awk -e '{your script here}'
[19:51:03] <nmz> that's gawk
[19:51:23] <nmz> if awk then -f split.awk -f <(your script here)
[19:52:25] <emanuele6> or use perl
[19:54:13] <nmz> how do you print the 5th field in perl?
[19:54:23] <nmz> I wanna benchmark
[19:54:52] <emanuele6> $F[5] iirc
[19:56:08] *** Joins: lavaball (felix@31.204.155.215)
[19:56:17] <nmz> it auto parses the csv?
[19:56:27] <emanuele6> no, it requires packages like awk
[19:56:48] *** Joins: BSaboia (~bsaboia@45.179.224.249)
[19:56:50] <nmz> cpan?
[19:56:55] <emanuele6> but since you said split.awk is gawk only i proposed perl
[19:57:30] <tully> nmz that looks complicated XD
[19:59:25] <nmz> emanuele6: its portable awk
[19:59:58] <emanuele6> oh
[20:00:09] <nmz> but awk doesn't have a package/module manager, so you gotta do that
[20:00:36] <nmz> tully: what does?
[20:00:56] <tully> Your split.awk script
[20:01:42] <nmz> tully: https://github.com/e36freak/awk-libs/blob/master/csv.awk does this look better?
[20:02:16] <nmz> mine is faster because it uses a regex to split() everything, but it basically does the same thing
[20:03:00] <tully> I'm not saying it's bad. I just manually checked my data with grep and fixed it with sed so... it works for my purpose
[20:04:51] <nmz> but I put more faith in e36's parser than mine, I wrote it and don't know how it works XD
[20:05:07] <nmz> ah, good
[20:06:35] *** Joins: earnestly (~earnest@user/earnestly)
[20:21:21] <emanuele6> python can parse csv with its standard library
[20:21:56] <emanuele6> hi,hello :),new,old,hello
[20:22:01] <emanuele6> oops
[20:22:35] <emanuele6> python -c 'import csv,sys; csv.writer(sys.stdout).writerows(map(lambda e: ["new" if i == 2 and e[i] == "old" else e[i] for i in range(len(e))],csv.reader(sys.stdin)))' <<< 'hi,"hello :)","old","old",hello'
[20:22:45] <emanuele6> and the output is: hi,hello :),new,old,hello
[20:23:59] <emanuele6> with <<<$'hi,"hello,:)","old","old",hello\na,b,c,d\na,a,old,old', the output is: hi,"hello,:)",new,old,hello newline a,b,c,d newline a,a,new,old
[20:24:25] <emanuele6> i == 2 because python lists start from 0, unlike awk
[20:36:47] <emanuele6> ["new" if i == 2 and e[i] == "old" else e[i] for i in range(len(e))] can be rewritten as
[20:37:17] <emanuele6> ["new" if f is e[2] and f == "old" else f for f in e]
[20:37:51] <emanuele6> ah, no actually
[20:38:06] <emanuele6> because if there are <=2 fields, this will fail
[20:41:02] *** Joins: seninha (~seninha@user/seninha)
[20:55:31] <Nintendo> Convert CSV to tab-separated values and save yourself some headache.
[20:59:30] <Nintendo> The aforementioned Python module even has the excel-tab dialect for just that.
[21:24:13] *** Quits: yeti (~username@p5de7774c.dip0.t-ipconnect.de) (Changing host)
[21:24:14] *** Joins: yeti (~username@user/yeti)
[21:29:10] *** Joins: extern (~archer@80.246.140.42)
[21:29:42] *** Joins: kensanata (~user@user/kensanata)
[21:33:31] *** Quits: wuseman (wuseman@user/wuseman) (Quit: ZNC 1.8.2+deb2build1 - https://znc.in)
[21:37:03] *** Joins: wuseman (wuseman@90-227-27-97-no68.tbcn.telia.com)
[21:37:03] *** Quits: wuseman (wuseman@90-227-27-97-no68.tbcn.telia.com) (Changing host)
[21:37:03] *** Joins: wuseman (wuseman@user/wuseman)
[21:38:34] *** Joins: lgc (~lgc@user/lgc)
[21:43:58] <nmz> tsv is bulky, if no newlines are in a field, tsv is much better
[21:44:01] <nmz> csv*
[21:49:43] <nmz> because you can just do FS="\t" and be done
[21:50:07] *** Joins: X-Scale` (~ARM@46.50.4.194)
[21:50:44] *** Quits: X-Scale (~ARM@50.77.166.178.rev.vodafone.pt) (Ping timeout: 252 seconds)
[21:52:20] *** X-Scale` is now known as X-Scale
[22:11:09] *** Quits: kensanata (~user@user/kensanata) (Ping timeout: 250 seconds)
[23:06:19] *** Joins: roarde (~roarde@user/roarde)
[23:31:17] *** Quits: mcfrdy (~mcfrdy@user/mcfrdy) (Quit: quit)
[23:32:07] *** Joins: mcfrdy (~mcfrdy@user/mcfrdy)
[23:41:57] *** Quits: tully (~mastodon@user/tully) (Quit: leaving)
[23:44:44] *** Quits: shbot (~shbot@37.139.2.101) (Remote host closed the connection)
[23:47:06] *** Joins: shbot (~shbot@37.139.2.101)
