[00:14:45] <lizmat> El_Che: that explains why I needed to wait so long when loading Cro::HTTP::Client for the first time after the update :-)
[00:15:21] <lizmat> El_Che: I think the advantage of arm64 packages is that one wouldn't need to compile Rakudo on those architectures
[00:15:46] <lizmat> and compiling Rakudo on those *is* a barrier when you have less than let's say 1.2G of RAM available
[00:16:02] <lizmat> let alone how long it takes  :-)
[00:17:31] <japhb> It is indeed slow as heck.  I'm curious what target audience you're thinking of, though.  RPi 3 users?
[00:18:41] <japhb> (It compiles just fine -- if slowly -- on a 4 GB RPi 4.  I don't think you can buy an RPi 4 smaller than 2 GB these days, but maybe it was possible in the past.)
[00:19:50] <japhb> Wikipedia says there was a 1 GB RPi 4 at one point
[00:36:14] *** Quits: seednode (~seednode@user/seednode) (Read error: Connection reset by peer)
[00:38:32] *** Joins: seednode (~seednode@user/seednode)
[00:48:26] *** Joins: monkey_ (~user@190.104.116.153)
[00:48:53] <Skarsnik> my chromebook is an arm64 platform, could be nice to have a raku on it x)
[00:57:50] *** Quits: monkey_ (~user@190.104.116.153) (Remote host closed the connection)
[01:11:40] *** Joins: monkey_ (~user@190.104.116.153)
[01:14:16] <El_Che> japhb: cloud providers are starting to offer arm64 servers and VMs (aws, oracle) + roi users
[01:14:49] <El_Che> rpi
[01:15:47] <El_Che> 4
[01:18:49] <japhb> El_Che: Ah, and the cost (and time) of compiles before actively running a node could get prohibitive.
[01:22:49] <El_Che> how l9ng does it take on a rpi4?
[01:24:00] *** Quits: monkey_ (~user@190.104.116.153) (Remote host closed the connection)
[01:24:10] <japhb> El_Che: I don't have a time for just the bare MoarVM/NQP/Rakudo build -- my build script includes a fair number of big modules that I always want installed.
[01:24:30] <japhb> That said, we're talking hours for the full thing, but way less than a day.
[01:25:09] <El_Che> wow
[01:25:28] *** Quits: linkable6 (lin-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[01:25:34] <lizmat> El_Che: yeah, so on those grounds already would a binary build be nice  :-)
[01:25:36] <El_Che> and I would run 20+ in parallel
[01:26:32] *** Joins: monkey_ (~user@190.104.116.153)
[01:26:41] <El_Che> it would tequire a different approach than amd64
[01:27:14] *** Joins: linkable6 (lin-able@2001:41d0:2:5eb5::)
[01:28:55] <El_Che> does adding cpus make the buikd faster?
[01:33:36] <japhb> El_Che: I suspect the answer to that is "yes", but I normally don't widen my builds because on x64 the zef installs are the overall time limiter, and on arm64 I have heat disappation issues
[01:34:33] <El_Che> last wurstion: do rpi usets mainly run raspian or just regular distros? eg on oracle cloud you'd run arm64 ubuntu or oracle linux
[01:35:19] <japhb> Raspbian (32-bit) and Raspberry Pi OS (64-bit) are both desktop distros.
[01:35:33] <japhb> They're not very heavy, obviously, but they're certainly not intended for servers.
[01:35:55] <japhb> (Hmmm, unless Raspberry Pi OS has a server install option now, I haven't looked.)
[01:35:58] <El_Che> thx!
[01:36:10] <japhb> np
[01:46:38] *** Quits: MoC (~moc@user/moc) (Ping timeout: 260 seconds)
[01:48:02] <japhb> El_Che: BTW, as I was setting up for a 2021.12 build on the RPi 4, I remembered -- RPi 4 build performance is *STRONGLY* related to how fast the SD card is.  Early on I had to upgrade to a much faster SD card because the default cards shipped with most RPi kits is S-L-O-W.
[01:48:34] *** Quits: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429) (Quit: My MacBook Air has gone to sleep. ZZZzzzâ€¦)
[01:49:12] <japhb> I would *hope* that the data center RPi's are set up to do something like network mount their RW partition, but if you're just testing it locally, be aware.
[01:49:15] <japhb> :-)
[01:58:10] <El_Che> the idea would be running containers on arm64 servers
[01:58:29] <El_Che> or maybe a ci service
[01:59:00] <El_Che> to be investigated, because reaching timeouts is likely
[02:00:32] <japhb> Oh god yes
[02:23:00] *** Quits: tejr (~tejr@user/tejr) (Quit: leaving)
[02:33:28] *** Quits: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com) (Quit: guifa)
[02:33:51] <japhb> El_Che: Looks like about 35-40 minutes to build up through zef itself.
[02:50:25] <lizmat> yeah, we really need to look at that, and cut out at least one occurence of precompilation
[02:51:57] *** Quits: Skarsnik (~Skarsnik@91-170-31-218.subs.proxad.net) (Ping timeout: 268 seconds)
[03:06:58] *** Joins: Sgeo (~Sgeo@user/sgeo)
[03:08:19] *** Quits: Sgeo_ (~Sgeo@user/sgeo) (Ping timeout: 250 seconds)
[03:09:06] <japhb> zef authors: trying to figure out how to deal with intermittent network connectivity when building a huge mess of Raku modules -- at some point the network flakes out just as zef is trying to pull a tarball, and it blows up.
[03:09:31] <japhb> Is there a way to separate the phases and download the tarballs separately from trying to extract/test/install them?
[03:09:51] <japhb> And in particular, to be able to tell (via e.g. exit code) whether the tarball was retrieved successfully?
[03:10:21] <japhb> Because then I can wrap that download in a retry loop ... or batch download when I've got good connectivity, and build later when I'm offline.
[03:17:01] <lizmat> well, there's the --serial option, that tests / installs each module at a time ?
[03:35:08] <japhb> Nah, I really need to *completely* separate download from build.  I'm effectively serializing now, but I think zef runs a download/unpack, assumes it succeeds, and then proceeds with testing, only to have it fail, because there was never a working/complete tarball to unpack.
[03:36:55] *** Quits: reportable6 (rep-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[03:40:17] *** Joins: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com)
[03:51:45] *** Joins: jgaz (~jgaz@2600:8805:d980:7620::9e0)
[04:00:20] <El_Che> crosscompiling moarvm/rakudo ia less that obvious due the non-static nature of the setup?
[04:22:53] *** Joins: morte_ (~user@190.104.116.153)
[04:39:34] *** Joins: reportable6 (rep-able@2001:41d0:2:5eb5::)
[05:22:55] *** Quits: jgaz (~jgaz@2600:8805:d980:7620::9e0) (Quit: Leaving)
[05:48:17] *** Quits: morte_ (~user@190.104.116.153) (Ping timeout: 240 seconds)
[05:58:37] *** Joins: frost (~frost@user/frost)
[06:07:59] *** Quits: monkey_ (~user@190.104.116.153) (Remote host closed the connection)
[06:33:54] *** Quits: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com) (Quit: guifa)
[06:36:16] *** Joins: morte_ (~user@190.104.116.153)
[07:11:09] *** Joins: lockywolf (~lockywolf@vultr-seoul-openbsd.lockywolf.net)
[08:11:10] *** Quits: squashable6 (squ-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:10] *** Quits: notable6 (not-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:10] *** Quits: linkable6 (lin-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:10] *** Quits: sourceable6 (sou-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: benchable6 (ben-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:10] *** Quits: quotable6 (quo-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: coverable6 (cov-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: releasable6 (rel-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: shareable6 (sha-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: tellable6 (tel-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: bisectable6 (bis-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: bloatable6 (blo-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: nativecallable6 (nat-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: unicodable6 (uni-able@2001:41d0:2:5eb5::) (Read error: Connection reset by peer)
[08:11:10] *** Quits: statisfiable6 (sta-able@2001:41d0:2:5eb5::) (Write error: Connection reset by peer)
[08:11:10] *** Quits: committable6 (com-able@2001:41d0:2:5eb5::) (Write error: Connection reset by peer)
[08:11:10] *** Quits: evalable6 (eva-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:10] *** Quits: reportable6 (rep-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:10] *** Quits: greppable6 (gre-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[08:11:26] *** Joins: sourceable6 (sou-able@2001:41d0:2:5eb5::)
[08:11:27] *** Joins: benchable6 (ben-able@2001:41d0:2:5eb5::)
[08:12:08] *** Joins: bloatable6 (blo-able@2001:41d0:2:5eb5::)
[08:12:24] *** Joins: quotable6 (quo-able@2001:41d0:2:5eb5::)
[08:12:43] *** Joins: evalable6 (eva-able@2001:41d0:2:5eb5::)
[08:12:54] *** Joins: reportable6 (rep-able@2001:41d0:2:5eb5::)
[08:13:12] *** Joins: releasable6 (rel-able@2001:41d0:2:5eb5::)
[08:22:41] *** Quits: morte_ (~user@190.104.116.153) (Remote host closed the connection)
[09:11:46] *** Joins: notable6 (not-able@2001:41d0:2:5eb5::)
[09:12:38] *** Joins: committable6 (com-able@2001:41d0:2:5eb5::)
[09:13:25] *** Joins: coverable6 (cov-able@2001:41d0:2:5eb5::)
[09:13:26] *** Joins: greppable6 (gre-able@2001:41d0:2:5eb5::)
[09:13:37] *** Joins: linkable6 (lin-able@2001:41d0:2:5eb5::)
[09:14:07] *** Joins: nativecallable6 (nat-able@2001:41d0:2:5eb5::)
[09:14:08] *** Joins: statisfiable6 (sta-able@2001:41d0:2:5eb5::)
[09:14:09] *** Joins: tellable6 (tel-able@2001:41d0:2:5eb5::)
[09:28:05] *** Joins: mexen (uid495612@user/mexen)
[09:38:34] *** Quits: reportable6 (rep-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[09:57:39] <Woodi> do using classic modules versioning (like in Perl5), without that guix-like hashes mess, would speed things up ?
[10:38:34] *** Quits: linkable6 (lin-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[10:38:34] *** Quits: evalable6 (eva-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[10:39:52] *** Joins: evalable6 (eva-able@2001:41d0:2:5eb5::)
[10:40:13] *** Joins: reportable6 (rep-able@2001:41d0:2:5eb5::)
[10:54:35] *** Joins: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com)
[10:58:26] *** Quits: seednode (~seednode@user/seednode) (Quit: Nihil supernum.)
[10:59:14] *** Joins: seednode (~seednode@user/seednode)
[11:15:05] *** Quits: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com) (Quit: guifa)
[12:02:37] *** Quits: Sgeo (~Sgeo@user/sgeo) (Read error: Connection reset by peer)
[12:12:56] *** Joins: bisectable6 (bis-able@2001:41d0:2:5eb5::)
[12:13:16] *** Joins: unicodable6 (uni-able@2001:41d0:2:5eb5::)
[12:13:19] *** Joins: shareable6 (sha-able@2001:41d0:2:5eb5::)
[12:15:59] *** Quits: epony (epony@user/epony) (Quit: QUIT)
[12:18:21] *** Joins: epony (epony@user/epony)
[12:31:48] *** Joins: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429)
[12:40:31] *** Joins: linkable6 (lin-able@2001:41d0:2:5eb5::)
[13:14:40] * lizmat is not sure what Woodi means
[13:16:04] *** Joins: Skarsnik (~Skarsnik@91-170-31-218.subs.proxad.net)
[13:26:51] *** Joins: MoC (~moc@user/moc)
[14:18:44] *** Quits: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429) (Quit: My MacBook Air has gone to sleep. ZZZzzzâ€¦)
[14:44:10] *** Joins: sena_kun (~sena_kun_@static-84-42-198-52.net.upcbroadband.cz)
[14:47:39] *** Joins: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429)
[15:37:17] *** Quits: reportable6 (rep-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[15:37:54] *** Joins: reportable6 (rep-able@2001:41d0:2:5eb5::)
[15:49:56] *** Quits: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429) (Quit: My MacBook Air has gone to sleep. ZZZzzzâ€¦)
[16:04:38] *** Joins: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429)
[16:11:20] <ugexe> do you feel hashing is slow? if so, why?
[16:11:46] *** Joins: squashable6 (squ-able@2001:41d0:2:5eb5::)
[16:12:26] <ugexe> computers don't really care if a string is human readable. a computer can look up a seemingly random string as quickly as it can a human readable one, even if its encoded into a file path
[16:55:47] *** Quits: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429) (Quit: My MacBook Air has gone to sleep. ZZZzzzâ€¦)
[17:10:20] *** Joins: monkey_ (~user@190.104.116.153)
[17:25:33] *** Quits: monkey_ (~user@190.104.116.153) (Remote host closed the connection)
[17:30:11] *** Joins: monkey_ (~user@190.104.116.153)
[18:10:49] *** Joins: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com)
[18:32:59] *** Joins: Kaiepi (~Kaiepi@216.208.243.198)
[18:36:04] *** Quits: monkey_ (~user@190.104.116.153) (Remote host closed the connection)
[18:43:03] *** Joins: Sgeo (~Sgeo@user/sgeo)
[18:50:53] *** Joins: jjido (~Denis@2a02:c7f:5c91:e700:6cc4:96c6:a3a5:e429)
[18:56:52] *** Quits: squashable6 (squ-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[19:14:27] *** Quits: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com) (Quit: guifa)
[19:39:41] *** Quits: seednode (~seednode@user/seednode) (Quit: Nihil supernum.)
[19:40:38] *** Joins: guifa (~guifa@host-23-251-65-252.VALOLT4.epbfi.com)
[19:53:46] *** Joins: seednode (~seednode@user/seednode)
[19:59:28] *** Joins: squashable6 (squ-able@2001:41d0:2:5eb5::)
[20:23:59] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:5d5c:8c41:79c4:9b80) (Ping timeout: 250 seconds)
[20:27:16] *** Joins: euandreh (~euandreh@191.181.59.160)
[20:45:20] *** Joins: lucasb (uid333435@id-333435.hampstead.irccloud.com)
[21:26:58] *** Quits: sena_kun (~sena_kun_@static-84-42-198-52.net.upcbroadband.cz) (Quit: Leaving)
[21:37:05] *** Quits: reportable6 (rep-able@2001:41d0:2:5eb5::) (Remote host closed the connection)
[21:39:18] *** Joins: reportable6 (rep-able@2001:41d0:2:5eb5::)
[21:41:02] <moon-child> maybe longer pathnames?  But I wouldn't expect that to be a bottleneck anyway
[22:11:57] *** Quits: qorg11 (~lain@2605:6400:c022:fa04:1312:1337:0:beef) (Ping timeout: 240 seconds)
[22:38:03] *** Joins: jgaz (~jgaz@2600:8805:d980:7620::9e0)
[22:40:32] <Woodi> moustly I mean total mess on filesystem. classic way you have source file and compiled, per version, simple. and no need for links or lookups. also I'm asking: do simpler structure could gain something in speed or unmess ?
[22:43:16] <Woodi> that modern hash repos are implemented via some intermediate and generalized api's ? would be nice to have classic repositories implementation. or maybe it is one ?
[22:45:10] <ugexe> I have implemented such a repository. if anything its slower
[22:45:23] <ugexe> https://github.com/ugexe/Perl6-CompUnit--Repository--Lib
[22:48:05] <lizmat> https://www.reddit.com/r/rakulang/comments/rrcp4c/steal_these_ideas_for_raku_fosdem_talks/
[22:56:02] *** Joins: qorg11 (~lain@2605:6400:c022:fa04:1312:1337:0:beef)
[23:03:27] *** Quits: qorg11 (~lain@2605:6400:c022:fa04:1312:1337:0:beef) (Ping timeout: 250 seconds)
[23:03:49] *** Joins: qorg11 (~lain@2605:6400:c022:fa04:1312:1337:0:beef)
[23:03:57] <Woodi> ugexe: too bad it's slower. still, hours for base distro installation is not good. any idea which part is slow ?
[23:05:01] *** Quits: lucasb (uid333435@id-333435.hampstead.irccloud.com) (Quit: Connection closed for inactivity)
[23:22:19] <leont> If it was an IRL conference I'd submit my 'raku syntax I miss in other languages', but doing it online twice feels a bit weird
[23:36:24] <lizmat> maybe you started missing more?  :-)
[23:51:25] <qorg11> Is there an emacs completion framework (like company) for raku?
[23:57:21] <jdv> Woodi: parsing is still painfully slow.  maybe thats most of what youre seeing?
[23:58:14] <Woodi> ...actually no. if problem is: initial installation of compilers distro *with modules* is slow  then in classic lib/Foo/Bar.pm type of repos module installation is solved during unpacking. no need for parsing, hashing, coping, linking or running anything. just configure repo path. and, for cheating purposes, precompilation is done during first run, if I remember corectly :)  but can be done just after 
[23:58:20] <Woodi> unpacking...
[23:59:32] <jdv> by installation do you count running zef?
[23:59:40] <Woodi> jdv: actually all that *hours* thing can be considered not so slow :)  if raku is ~20x slower then Perl5 then 2 hours is not so bad ;)
[23:59:51] <MasterDuke> nine has some suggestions about making module installation faster by not duplicating some work
