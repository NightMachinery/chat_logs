[00:14:22] *** Quits: Haudegen (~quassel@178.115.237.87.static.drei.at) (Quit: Bin weg.)
[00:30:54] <sadiq> ooh ooh
[00:31:25] <sadiq> we should do an eventring integration once it's merged
[00:32:21] <sadiq> (I was going to knock up a prometheus reporter as a proof of concept)
[01:08:20] <d_bot_> <undu> @companion_cube on a hackathon at citrix edwin started a similar project to get opentelemetry working ,I don't whink he posted any code though
[01:12:15] *** Quits: wyrd (~wyrd@gateway/tor-sasl/wyrd) (Ping timeout: 240 seconds)
[01:19:25] *** Joins: wyrd (~wyrd@gateway/tor-sasl/wyrd)
[01:24:25] *** Joins: rgrinberg (~textual@177.241.245.222)
[02:14:51] <companion_cube> well this is starting to work for metrics and traces
[02:14:57] <companion_cube> conntributions welcome, etc.
[02:15:12] <companion_cube> (esp. for alternative collector backends! right now it's just a crappy http/ocurl thing)
[02:18:08] <companion_cube> sadiq: what would that look like? eventring would feed events into opentelemetry?
[02:54:49] *** Quits: kaph (~kaph@net-109-116-124-149.cust.vodafonedsl.it) (Read error: Connection reset by peer)
[02:56:08] *** Joins: kaph (~kaph@net-109-116-124-149.cust.vodafonedsl.it)
[03:04:05] *** Quits: kurfen_ (~kurfen@176.119.195.9) (Quit: ZNC 1.8.2 - https://znc.in)
[03:05:31] *** Joins: szkl (uid110435@id-110435.uxbridge.irccloud.com)
[03:06:58] *** Joins: kurfen (~kurfen@176.119.195.9)
[03:37:07] <d_bot_> <anmonteiro> oh siiiiiit
[03:37:47] <d_bot_> <anmonteiro> watching ðŸ™‚
[03:38:05] <d_bot_> <anmonteiro> oh I guess IRC doesn't see that I replied to the open telemetry link ðŸ˜›
[03:38:13] <companion_cube> no worries :)
[03:38:46] <companion_cube> I'm wondering if it should be functorized over IO or something
[03:39:06] <companion_cube> (which, thinking of it, might even be useful with effects)
[03:48:20] <d_bot_> <anmonteiro> not sure how it's structured, but I've come to prefer a runtime agnostic library where possible and I/O runtimes on top of it
[03:48:25] <d_bot_> <anmonteiro> e.g. the http/af and h2 state machines
[03:49:02] <d_bot_> <anmonteiro> I don't think all protocols can necessarily fit that model though
[03:49:41] <companion_cube> ah well, here it's an IO consumer, in a way
[03:49:55] <companion_cube> I mean it's like a `logs` reporter, so I should draw inspiration from there
[03:50:03] <companion_cube> (btw integration with `logs` might be a super useful feature)
[03:56:39] <d_bot_> <anmonteiro> very good point
[03:59:41] <companion_cube> many things to adjust (e.g. batching of traces, I think, would help a lot)
[04:06:52] <d_bot_> <Anurag> For high traffic scenarios youâ€™d most likely also want to implement some form of sampling of traces.
[04:07:42] <companion_cube> yeah there's a flag for that, not sure what the API would look like
[04:07:51] <companion_cube> (maybe the tracing probe would be probabilistic?)
[04:11:43] *** Quits: Tuplanolla (~Tuplanoll@91-159-69-98.elisa-laajakaista.fi) (Quit: Leaving.)
[04:21:15] *** Quits: kaph (~kaph@net-109-116-124-149.cust.vodafonedsl.it) (Read error: Connection reset by peer)
[04:21:33] *** Joins: kaph (~kaph@net-109-116-124-149.cust.vodafonedsl.it)
[04:48:26] *** Quits: qwr (~qwr@6-44-46-176.dyn.estpak.ee) (Quit: â†‘)
[04:55:13] *** Joins: qwr (~qwr@6-44-46-176.dyn.estpak.ee)
[05:53:48] *** Quits: xgqt (~xgqt@gentoo/developer/xgqt) (Ping timeout: 252 seconds)
[05:54:55] *** Joins: xgqt (~xgqt@gentoo/developer/xgqt)
[06:11:22] *** Joins: gravicappa (~gravicapp@145.255.0.191)
[06:46:48] *** Quits: rgrinberg (~textual@177.241.245.222) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[07:17:49] *** Joins: mbuf (~Shakthi@136.185.68.186)
[07:19:26] *** Quits: chiastre (~chiastre@user/chiastre) (Ping timeout: 250 seconds)
[07:27:49] *** Joins: chiastre (~chiastre@user/chiastre)
[07:45:59] *** Quits: waleee (~waleee@h-98-128-228-119.NA.cust.bahnhof.se) (Ping timeout: 252 seconds)
[07:50:16] <d_bot_> <darrenldl> whats the usual package for a sexp type?
[07:50:40] <d_bot_> <darrenldl> (and well parsing/printing
[08:00:41] <companion_cube> sexplib?
[08:00:52] <companion_cube> (if you use containers there's one in there too)
[08:03:04] *** Joins: rgrinberg (~textual@177.241.245.222)
[08:12:04] <sleepydog> Fmt.parens :p
[08:12:29] <sleepydog> for printing, that is
[08:14:03] *** Quits: zebrag (~chris@user/zebrag) (Ping timeout: 252 seconds)
[08:14:57] <d_bot_> <darrenldl> companion_cube: yeah was using ccsexp, but now moving sexp stuff into a separate package
[08:15:37] <d_bot_> <darrenldl> and seems a bit of an overkill to install containers just to do exactly only sexp in that sub package
[08:15:58] <d_bot_> <darrenldl> (trying to slim down deps of timedesc
[08:17:46] <d_bot_> <darrenldl> hm everything uses sexplib basically huh, seems like perfect choice, cheers
[08:18:44] <companion_cube> @darrenldl funny, ccsexp is there to not have to pull something just for sexprs :D
[08:18:51] <companion_cube> (â€¦ if you already have containers)
[08:35:12] <d_bot_> <darrenldl> companion_cube: can ccsexp be a standalone package : v
[09:25:32] *** Quits: gravicappa (~gravicapp@145.255.0.191) (Ping timeout: 250 seconds)
[09:43:39] *** Quits: rgrinberg (~textual@177.241.245.222) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[10:09:14] *** Quits: tizoc (~user@li296-221.members.linode.com) (*.net *.split)
[10:09:14] *** Quits: Absalom (~Absalom@envs.net) (*.net *.split)
[10:09:14] *** Quits: cross (~cross@spitfire.i.gajendra.net) (*.net *.split)
[10:14:34] *** Joins: tizoc (~user@li296-221.members.linode.com)
[10:14:34] *** Joins: Absalom (~Absalom@envs.net)
[10:14:34] *** Joins: cross (~cross@spitfire.i.gajendra.net)
[10:52:23] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[10:52:36] *** Quits: kurfen (~kurfen@176.119.195.9) (Ping timeout: 240 seconds)
[11:17:01] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[11:17:29] *** Joins: spip (~bobo@37.166.203.191)
[11:17:47] *** Quits: bobo (~bobo@37.167.51.28) (Ping timeout: 256 seconds)
[11:18:18] <sadiq> companion_cube, yes. So you could see GC and runtime trace events.
[11:18:22] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[12:00:46] *** Quits: kaph (~kaph@net-109-116-124-149.cust.vodafonedsl.it) (Read error: Connection reset by peer)
[12:01:45] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[12:02:52] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[12:09:15] *** Joins: kaph (~kaph@net-109-116-124-149.cust.vodafonedsl.it)
[12:10:58] *** Quits: Absalom (~Absalom@envs.net) (Quit: the lounge - https://webirc.envs.net)
[12:11:23] *** Joins: Absalom (kax@envs.net)
[12:11:25] *** Joins: bartholin (~bartholin@158.110.71.61)
[12:15:18] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[12:16:34] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[12:18:00] *** Quits: Everything (~Everythin@37.115.210.35) (Quit: leaving)
[12:26:44] *** Joins: olle (~olle@212-181-59-82.customer.telia.com)
[12:30:11] *** Quits: OCamlPro[m] (~ocamlprom@2001:470:69fc:105::1:70d1) (Quit: You have been kicked for being idle)
[12:43:32] *** Quits: bartholin (~bartholin@158.110.71.61) (Ping timeout: 240 seconds)
[12:43:50] *** Joins: bartholin (~bartholin@158.110.71.61)
[13:11:01] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[13:33:49] <d_bot_> <wokalski> companion_cube: regarding lwt+tracing; what were your thoughts about the integration? We talked about this exact topic a couple of weeks ago with my team and we thought about creating a wrapper (`type 'a t = (ctx * 'a) Lwt.t`) that will carry the context around behind the scenes but maybe there's a smarter way.
[13:46:08] *** Quits: gentauro (~gentauro@user/gentauro) (Read error: Connection reset by peer)
[13:46:21] *** Joins: gentauro (~gentauro@user/gentauro)
[13:58:49] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[14:03:17] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Ping timeout: 252 seconds)
[14:19:33] *** Joins: gravicappa (~gravicapp@46.191.232.8)
[14:22:50] *** Quits: bartholin (~bartholin@158.110.71.61) (Ping timeout: 268 seconds)
[14:24:58] *** Joins: bartholin (~bartholin@158.110.71.61)
[14:37:39] *** Joins: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340)
[15:03:02] *** Joins: kurfen (~kurfen@176.119.195.8)
[16:44:38] <companion_cube> @darrendl tough ask :D
[16:45:50] <d_bot_> <darrenldl> (:
[16:46:48] <companion_cube> @wokalski: @antron has some cool tricks in Dream, maybe Lwt.key might be a good fit?
[16:51:06] <d_bot_> <Anurag> @companion_cube Lwt.key is something I looked at for similar needs in the APM library I worked on. But I see it marked as deprecated <https://github.com/ocsigen/lwt/blob/master/src/core/lwt.mli#L1691-L1700> so I didn't push forward with that approach. I instead ended up using `with_` style functions and manually forwarding the trace context everywhere I needed to (including forwarding it to logs for adding the trace context as a 
[16:52:38] <companion_cube> yeah I guess
[16:53:42] *** Quits: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340) (Quit: WeeChat 3.4)
[17:04:27] *** Quits: szkl (uid110435@id-110435.uxbridge.irccloud.com) (Quit: Connection closed for inactivity)
[17:09:32] *** Quits: bartholin (~bartholin@158.110.71.61) (Ping timeout: 240 seconds)
[17:12:37] *** Joins: Haudegen (~quassel@91.114.49.10)
[17:22:51] *** Joins: bartholin (~bartholin@158.110.71.61)
[17:23:31] <companion_cube> you need some manual work anyway, if you're forwarding trace_id/span_id to remote hosts
[17:38:04] <d_bot_> <Anurag> That is true. So far my approach has been to create http clients from a given trace context. Then all calls made using that client will automatically add a trace context http header when making outgoing calls.
[17:38:51] <companion_cube> so I'm looking at Logs, and the reporter interface seems very promising
[17:39:00] <companion_cube> one interface can serve both sync and async needs
[17:55:46] *** Quits: d_bot_ (~d_bot@2001:4802:7800:1:be76:4eff:fe20:3027) (Remote host closed the connection)
[17:56:24] *** Joins: d_bot (~d_bot@2001:4802:7800:1:be76:4eff:fe20:3027)
[18:06:40] *** Joins: olle_ (~olle@212-181-59-82.customer.telia.com)
[18:08:11] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[18:26:04] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[18:39:57] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[18:40:40] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[18:45:05] *** Joins: dextaa_ (~dextaa@user/dextaa)
[18:45:12] <d_bot> <mbacarella> I kinda wish libraries that provided independent I/O endpoints just implemented a synchronous interface so that you can wrap them in `In_thread.run (fun () -> ...)` if you want an Async version
[18:45:56] <d_bot> <mbacarella> dealing with functorized promise modes in every single library in the world is kind of a drag
[18:46:10] <companion_cube> the Logs thing should work, actually, in this case
[18:46:19] <companion_cube> with a small Lwt wrapper
[18:46:24] <companion_cube> I just need an async reporter now :D
[18:47:22] *** Quits: Serpent7776 (~Serpent77@90-156-31-193.internetia.net.pl) (Read error: Connection reset by peer)
[18:49:10] <d_bot> <mbacarella> `Lwt_preemptive.detach`
[18:49:14] <d_bot> <mbacarella> Lwt wrapper: done
[18:49:31] <companion_cube> nah, not even
[18:49:52] <companion_cube> https://github.com/AestheticIntegration/ocaml-opentelemetry/blob/master/src/lwt/opentelemetry_lwt.ml#L13-L20 :)
[18:50:03] <companion_cube> again, imitating Logs.reporter
[18:50:09] <companion_cube> it's quite a nice API really
[18:50:29] <companion_cube> a callback to return a value (here, a promise); and a callback to signal the job is done (here, to wakeup the promise)
[18:50:36] <d_bot> <orbitz> I think that would be a subpar experience.  My preference is for people to offer an API that takes bytes and gives back decoded frames, and then you can implement a sync or async API on top of that.
[18:51:49] <companion_cube> depends for what
[18:52:01] <companion_cube> for a protocol, I agree, I guess? not sure it's easier than the functor though
[18:52:26] <d_bot> <orbitz> I haven't seen it done very successful as a functor.  Cohttp, for example, is a pain to implement, IMO
[18:52:50] *** Joins: Serpent7776 (~Serpent77@90-156-31-193.internetia.net.pl)
[18:53:22] <companion_cube> well if you want to see an incredibly large scale and robust system (lolol), see: irc-client
[18:53:34] <companion_cube> (warning: a smidge sarcastic here :D)
[18:54:01] <d_bot> <orbitz> It was hard to tell over the lol's ðŸ™‚
[18:54:13] <companion_cube> you never know!
[18:55:31] <d_bot> <mbacarella> the reason dealing with functorized promise monads is kind of a drag is because probably the author only implements either lwt or async
[18:56:05] <d_bot> <mbacarella> but also if you're trying to release a library you feel a little guilty because you've implemented only async or lwt bindings
[18:57:36] <d_bot> <mbacarella> that is, there's pressure to do the functorized promise monads. the concept alone creates some angst
[18:58:26] <d_bot> <orbitz> To support companion_cube and not support my claim: dns-client does something not terrible in that its API surface is fairly small so you do implement a functor with monad + their API and then it takes care of calling the right things.  I think it works ok there, but it's delicate work and, for example, I had to request (and was thankfully obliged) to change the API in a way that made handling cancellation correctly possible
[19:01:43] *** Quits: unyu (~pyon@user/pyon) (Quit: brb)
[19:06:58] <companion_cube> @mbacarella it does mean you can relatively easily add the other one, whereas if you don't functorize (or do the stateless IO-less version) you have to rewrite everything
[19:07:28] <d_bot> <mbacarella> sorry, rephrase?
[19:07:59] <companion_cube> you might functorize and do only lwt
[19:08:12] <companion_cube> but adding async is then easier than if you had no functor to start with
[19:08:42] <d_bot> <mbacarella> what i'm saying is there's no shame in your wrapper being `In_thread.run (fun () -> let h = Sync_io.create () in Sync_io.send_request h request; let reply = Sync_io.read_response h; Sync_io.close h; reply)`
[19:08:57] <companion_cube> for a stub, sure
[19:09:01] <companion_cube> for actual use, meh :D
[19:09:27] <d_bot> <mbacarella> i mean, the functorized monad version will be doing something close to that behind the scenes anyway
[19:10:18] <d_bot> <mbacarella> i will reiterate i meant for independent I/O endpoints. if you have to share handles between many calls yeah that has obvious issues
[19:12:59] <companion_cube> hmm, In_thread means using a thread pool? might actually scale decently, I guess
[19:15:48] <d_bot> <mbacarella> IIRC all I/O in Async is dispatched to a thread-pool
[19:16:26] <d_bot> <orbitz> No
[19:16:28] <d_bot> <orbitz> FIle I/O probably is
[19:17:26] <companion_cube> on linux, probably
[19:17:37] *** Quits: olle (~olle@212-181-59-82.customer.telia.com) (Quit: Lost terminal)
[19:17:37] *** Quits: olle_ (~olle@212-181-59-82.customer.telia.com) (Remote host closed the connection)
[19:19:20] *** Joins: rgrinberg (~textual@177.241.245.222)
[19:20:07] *** Quits: rgrinberg (~textual@177.241.245.222) (Client Quit)
[19:21:08] <d_bot> <mbacarella> hmm, indeed, async_unix src/unix_syscalls.ml is heavy on the In_thread. stuff except for socket stuff
[19:21:17] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[19:26:27] <d_bot> <mbacarella> I wonder why the break-out for network stuff. Guessing the payloads are tinier and more latency sensitive.
[19:26:49] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[19:26:55] <d_bot> <orbitz> @pilothole No, it's because most OS's have functioning non-blocking network APIs, but not for file systems
[19:27:54] <d_bot> <mbacarella> ah, that sounds more plausible
[19:28:00] <companion_cube> io_uring is supposed to change this for linux
[19:28:08] <companion_cube> with some exciting new vulnerabilities, too
[19:28:43] <d_bot> <orbitz> It's not progress without a security hole or two
[19:29:40] <d_bot> <mbacarella> you would still probably rather use the threaded interface instead of managing a non-blocking state machine if you could get away with it? I imagine it doesn't perform as awesome
[19:30:28] <d_bot> <orbitz> Threads do not performa wesome
[19:32:03] <d_bot> <mbacarella> actually, why not? you have context switches whether you use threads or non-blocking I/O
[19:32:55] <d_bot> <mbacarella> in fact, i could imagine one argument where it's better to have the kernel operate the state machine for you and let you have concurrency through threading because the kernel knows more about what's going on and is heavily optimized
[19:33:31] <d_bot> <orbitz> @pilothole  The information around why is more efficient to use the non-blocking APIs is pretty detailed on the internet.  You can start with C10k problem, which is quite old
[19:33:42] <companion_cube> @orbitz depends for what, i guess
[19:33:48] <companion_cube> doesn't scale as well, for sure
[19:33:52] <companion_cube> (although c10k is doable)
[19:34:07] <d_bot> <orbitz> Sure, c10k is not large these days, but the principles still apply
[19:34:23] <d_bot> <orbitz> My point is: this isn't some whacky decision made by Ocaml developers, there is a pretty robust discussion that's gone on over the decades
[19:34:43] <d_bot> <mbacarella> i didn't say it was a wacky decision, just trying to remember from first principles
[19:34:50] <d_bot> <mbacarella> for the sake of argument
[19:37:27] <sim642> Uhoh, this is confusing: Error: This expression should not be a function, the expected type is Ppx_deriving_ord_helper.t -> Ppx_deriving_runtime.int
[19:38:27] *** Joins: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340)
[19:41:55] <d_bot> <Anurag> @pilothole async uses `In_thread` when performing file io since that doesn't support nonblocking operations. For socket io (If Fd.t supports nonblocking mode) it doesn't go through In_thread (unless you are performing a writev call with a large number of iovecs)
[19:42:39] <d_bot> <Anurag> Ah, nvm, you just said that a little while ago (I should have scrolled further ðŸ˜„ )
[19:44:29] <companion_cube> sim642: weird indeed
[19:44:34] <d_bot> <Anurag> async (and lwt) does make working with nonblocking IO pretty straightforward  so as a user of Lwt_io/Reader/Writer (or any other wrapper over some lwt/async primitives), one doesn't really have to think about managing IO threads, or orchestrating non blocking state machines.
[19:46:29] <d_bot> <mbacarella> anyway, haven't threads traditionally sucked for c10k level concurrency because the OS doesn't make smart decisions about what to schedule next?
[19:46:30] <d_bot> <mbacarella>
[19:46:31] <d_bot> <mbacarella> i recall an old observation that if you had N processes waiting on accept the kernel would wake all of them only to put N-1 of them back to sleep, because only one can get the next client
[19:46:46] <d_bot> <mbacarella> (the kernel here being linux)
[19:47:44] <d_bot> <mbacarella> or, stated another way, you could blow my argument up where when i say "it's better to have the kernel operate the state machine for you and let you have concurrency through threading because the kernel knows more about what's going on and is heavily optimized" i'm being hopelessly naive
[19:48:06] <d_bot> <orbitz> The general issue is threads are heavy and and if you have lots of connections, you use up a lot of RAM + context switches
[19:51:22] <d_bot> <mbacarella> right. but assuming you had a perfectly executed concept, why should 1000 threads waiting on 1000 different descriptors be heavier than one thread waiting to find out about an event in 1 of 1000 descriptors? why does one model require more context switches than the other?
[19:52:18] <d_bot> <mbacarella> (true 1000 different threads means 1000 different stacks)
[19:53:00] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[19:54:18] <d_bot> <orbitz> It depends on the specifics.  But let's say you wrap "read" in an In_thread.run, you need to (possibly) spawn a thread, wait for its response, context switch over to it, read (syscall), notify that the result is ready, context switch back, handle the notification is ready, and continue, and maybe kill a thread.  The first and last are alleviated by a thread pool to some degree
[19:54:28] <d_bot> <orbitz> if you batch more operations, then context switching becomes less dominating
[19:55:30] <d_bot> <orbitz> But per thread you have 4 context switches in that scenario: into and out of the thread, and the syscall
[19:55:36] <d_bot> <orbitz> at least 4
[19:56:02] <companion_cube> otoh if you read gigantic files in a few threads, I don't think lwt would help
[19:56:09] <companion_cube> performance isn't 1 dimensionnal
[19:56:39] <d_bot> <orbitz> Excuse me, I'm referring specfically to network here.  I should have been more explicit
[19:56:40] <d_bot> <mbacarella> ah, fair, in the ocaml model dispatching things to thread pools is 4x as many context switches as needed
[19:56:58] <d_bot> <orbitz> @pilothole what I just described has nothing to do with ocaml
[19:57:09] <d_bot> <mbacarella> sorry, i meant the ocaml models we have been talking about
[19:57:26] <d_bot> <orbitz> What I described is inherent to any unixy thread model
[19:58:11] <d_bot> <orbitz> Go and Erlang handle pushing I/O to an event loop for you for example.  High performance networking APIs like Java's Jetty use an even tloop as well
[19:59:00] <d_bot> <orbitz> Netty, maybe I menat
[19:59:12] <d_bot> <rudy> Does anyone have a nice resource on what OCaml is good for? I'm looking for something in-depth, and perhaps with comparisons to other famous languages like Java or C.
[19:59:35] <d_bot> <orbitz> @rudy It's a general purpose programming language, so it's good for all the things!
[19:59:38] <Corbin> rudy: Yes. Additionally, it can.
[19:59:49] *** Quits: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340) (Ping timeout: 240 seconds)
[20:00:00] <d_bot> <mbacarella> kind of? the reason for the 4x context switches in this approach is because you're throwing away the possibility of sequencing by dispatching everything to an I/O threadpool
[20:00:27] <d_bot> <orbitz> @pilothole  I don't undertand what you mean.  The scenario I described was pretty specific.
[20:01:15] <d_bot> <orbitz> As I said, context switches become less dominating the more amount of work you do in the thread, but if you are running a specific syscall in a thread, you have a bunch of context switches
[20:01:53] *** Joins: waleee (~waleee@2001:9b0:213:7200:cc36:a556:b1e8:b340)
[20:04:16] <d_bot> <Et7f3 (@me on reply)> https://www.ssi.gouv.fr/uploads/IMG/pdf/Mind_Your_Languages_-_version_longue.pdf
[20:05:41] <d_bot> <Et7f3 (@me on reply)> it is not one vs one but it show arguments that help you choose
[20:07:19] <d_bot> <Et7f3 (@me on reply)> The conclusion I took from this: when a langage is static and include many warnings it become safer by design.
[20:07:52] <companion_cube> @orbitz yeah yeah, for networking it's quite clear
[20:08:46] <d_bot> <mbacarella> what i'm saying is you could probably eliminate a context switch if you don't have to enter and exit a threadpool if you do two system calls in a row if they depend on each other (e.g. a thread dedicated to reading a request and then sending a reply), but i now agree with you/remember threads suck because you wrap each system call context switch in a thread entry/exit context switch
[20:09:35] <d_bot> <orbitz> @pilothole That would be "doing more stuff in the thread" as I mentioned which will reduce your context switches.
[20:09:48] <d_bot> <mbacarella> right
[20:10:19] <d_bot> <orbitz> But even still, depending on your scale, you're using more resources than are necessary
[20:10:35] <d_bot> <Et7f3 (@me on reply)> log4j come from a hyper dynamic language where deserialization can run arbitrary code. It is not the first time https://opensource.googleblog.com/2017/03/operation-rosehub.html @rudy The time you earn by developing quickly is the time you will lose later in worse. JS was coded in 7 day and now many webdev spend time on creating tool to fix it.
[20:11:02] <d_bot> <mbacarella> yes, i agree. i will withdraw the contention. threads sux non-blocking I/O roolz
[20:12:17] <d_bot> <orbitz> @pilothole  Consider you have 100 connections and they all have something to read at the same time: you can do 1 kqueue call + 100 reads (202 context switches) or you can do 100 * 4, at least, context switches
[20:12:52] <d_bot> <mbacarella> yes right clearly worse
[20:13:30] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Remote host closed the connection)
[20:19:52] *** Quits: mbuf (~Shakthi@136.185.68.186) (Quit: Leaving)
[20:24:03] <d_bot> <Et7f3 (@me on reply)> @Bluddy description of #dÃ©butants is not clickable you can write <# 913078886345085008> without espace. And why we have notifications in #rules did you modified something ?
[20:30:11] *** Joins: zebrag (~chris@user/zebrag)
[20:34:21] *** Quits: Haudegen (~quassel@91.114.49.10) (Quit: Bin weg.)
[20:36:39] <d_bot> <mbacarella> neat article
[20:52:05] <d_bot> <Et7f3 (@me on reply)> reposted in #share
[21:23:00] *** Joins: rgrinberg (~textual@177.241.245.222)
[21:24:12] *** Joins: oriba (~oriba@dynamic-078-054-218-125.78.54.pool.telefonica.de)
[21:25:39] *** Quits: kakadu (~kakadu@195.19.236.234) (Remote host closed the connection)
[21:40:14] *** Quits: Techcable (~Techcable@168.235.93.147) (Remote host closed the connection)
[21:40:22] *** Joins: Techcable (~Techcable@168.235.93.147)
[21:50:48] *** Quits: chrisz (ala2kkckq2@d5360fd8.access.ecotel.net) (Ping timeout: 252 seconds)
[21:51:36] *** Joins: chrisz (gwnhy69h35@d53678d6.access.ecotel.net)
[21:52:07] *** Joins: Haudegen (~quassel@178.115.237.87.static.drei.at)
[22:08:41] *** Quits: dextaa_ (~dextaa@user/dextaa) (Remote host closed the connection)
[22:10:45] *** Quits: bartholin (~bartholin@158.110.71.61) (Quit: Leaving)
[22:18:44] <d_bot> <mbacarella> so you have a `type foo = Foo | Bar | Baz` exposed in a library. you want to get free sexp conversions for it without copy/pasting it into your library. sadly `type foo = Library.foo [@@deriving sexp]` doesn't work
[22:20:37] <d_bot> <EduardoRFS> ppx_import
[22:28:24] <d_bot> <mbacarella> that's awesome
[22:32:19] *** Joins: olle (~olle@c-8a89e455.034-536-6d6c6d4.bbcust.telenor.se)
[23:02:30] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[23:06:32] *** Quits: mro (~mro@port-92-195-141-219.dynamic.as20676.net) (Ping timeout: 240 seconds)
[23:12:30] *** Joins: bobo (~bobo@37.166.219.142)
[23:12:45] *** Quits: spip (~bobo@37.166.203.191) (Ping timeout: 252 seconds)
[23:21:01] *** Quits: t-j-r (~tjr@233.ip-144-217-92.net) (Quit: quitting)
[23:24:51] *** Quits: infinity0 (~infinity0@occupy.ecodis.net) (Remote host closed the connection)
[23:34:59] *** Joins: infinity0 (~infinity0@occupy.ecodis.net)
[23:41:18] *** Joins: mro (~mro@port-92-195-141-219.dynamic.as20676.net)
[23:41:46] *** Quits: rgrinberg (~textual@177.241.245.222) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[23:47:32] *** Quits: gravicappa (~gravicapp@46.191.232.8) (Ping timeout: 240 seconds)
