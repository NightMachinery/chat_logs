[00:05:40] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[00:17:40] *** Quits: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20) (Remote host closed the connection)
[00:17:53] *** Joins: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20)
[00:24:24] *** Joins: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
[00:29:38] *** Joins: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net)
[00:44:09] <hayley> Someone suggested that if I do two writes and two reads, and want the reads to be in order, then I have to acquire on the first read, and release on the last write. Unfortunately that's the opposite of what I have now.
[00:50:23] <hayley> https://www.youtube.com/watch?v=nETXyCYR01M
[00:50:23] -ixelp- Down in the Park (Piano Version) - YouTube
[00:50:47] <gilberth> Good morning #lispcafe!
[00:50:55] <hayley> Good morning gilberth!
[00:53:29] <hayley> Funny, either Smalltalk and Zetalisp were used for the best operating systems ever written, or the Smalltalk way is that operating systems should not exist. I think I just pick the most provocative one at any given time.
[00:59:03] <gilberth> Is the Steam cloud working? I see "Cannot connect" sort of errors with Windows 7.
[01:07:19] <hayley> https://www.youtube.com/watch?v=zgjo36-jaFY
[01:07:20] -ixelp- What Wire Connector is the Best? Settling a Debate! Wire Nut VS Wago - YouTube
[01:07:28] <hayley> EE clickbait!!
[01:09:41] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca)
[01:13:10] <clothespin> hello
[01:33:13] * hayley reads someone's informal definition of acquire/release orderings
[01:33:25] *** Joins: scymtym (~user@ip-094-114-248-079.um31.pools.vodafone-ip.de)
[01:33:53] <hayley> "Release semantics prevent memory reordering of the write-release with any read or write operation that precedes it in program order." Damn, I need to prevent reordering with operations after it though. I think.
[01:34:25] *** Joins: Brucio-61 (~Brucio-68@ip-094-114-248-079.um31.pools.vodafone-ip.de)
[01:41:03] <Aurora_v_kosmose> pl: That's interesting.
[01:45:00] *** Quits: shka (~herr@109.231.0.226) (Ping timeout: 252 seconds)
[01:49:24] *** Quits: Brucio-61 (~Brucio-68@ip-094-114-248-079.um31.pools.vodafone-ip.de) (Ping timeout: 252 seconds)
[01:54:04] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[01:56:48] <White_Flame> happened to follow a r/antiwork link.  Their pinned post is about supporting a petsmart union against corporate closing their store.  Um, why is r/antiwork trying to keep people working?
[01:57:04] *** Quits: aeth (~aeth@user/aeth) (Ping timeout: 272 seconds)
[01:57:18] <Aurora_v_kosmose> White_Flame: It's probably about the store closing to counter union stuff 
[01:57:35] <White_Flame> right, but still, this is antiwork not pro-work
[01:57:38] *** Joins: aeth (~aeth@user/aeth)
[01:57:52] <Aurora_v_kosmose> r/antiwork, despite its name, also has pro-worker stuff and anticapitalist stuff.
[01:58:13] <White_Flame> I know, it's silly, as their main desription si about a "work-free life"
[01:58:30] <Aurora_v_kosmose> The name might not be best suited, but atomizing the community for the sake of correctness would probably be counterproductive.
[01:58:33] <aeth> antiwork used to be "we shouldn't have to work to survive" but ever since it started regularly hitting r/all for the past few months/years, it has basically just become a mainstream sub
[01:58:49] <White_Flame> aeth: yeah, it looks like it
[01:59:12] <aeth> idk about mobile and new reddit, which most redditors use for some reason, but if you go to old reddit, you can still see its roots
[01:59:15] <Aurora_v_kosmose> I fully stand by the "work shouldn't be mandatory" thing.
[01:59:36] <Aurora_v_kosmose> Particulary when practically half of all software jobs are for scams, cashgrabs or actively harmful things.
[01:59:45] <hayley> "Nearly a half century ago, while Social-Democratic and Communist theoreticians babbled about a society with ‚Äúwork for all,‚Äù the Dadaists, those magnificent madmen, demanded unemployment for everybody"
[02:00:12] <Aurora_v_kosmose> I'd like that.
[02:01:09] <aeth> Aurora_v_kosmose: half?
[02:01:20] <Aurora_v_kosmose> aeth: I didn't feel like looking it up to be sure.
[02:01:39] <aeth> I mean, advertisements and social media are actively harmful things, as are widespread surveillance
[02:01:41] <Aurora_v_kosmose> It is likely significantly more than half.
[02:01:57] <aeth> And VCs love to fund scams these days
[02:02:22] <aeth> And capitalism is basically a "cashgrab", especially large, profitable companies that do capitalism well
[02:02:23] <Aurora_v_kosmose> For every useful engineering position there are numerous VC scams, spyware apps, adware and outright spyware positions
[02:03:12] <hayley> .oO( Anything that isn't funding my work on parallel SBCL GC is grifting )
[02:03:32] <hayley> .oO( but granted, you should fund someone that isn't me, idk how to write C )
[02:03:38] <Aurora_v_kosmose> .oO?
[02:04:01] <Aurora_v_kosmose> And yes plz, dowant parallel GC
[02:04:10] <hayley> Thinking bubble
[02:04:15] <aeth> object Oriented
[02:04:27] <moon-child> object disoriented
[02:04:30] <aeth> OOP is when you use .foo(...) syntax
[02:04:37] <Aurora_v_kosmose> hayley: Ah i see.
[02:04:38] <aeth> such as .oO(foobar)
[02:04:44] <aeth> or I guess .oO( foobar )
[02:04:49] <Aurora_v_kosmose> aeth: You mean it isn't (foo bar)?
[02:04:51] <Aurora_v_kosmose> :p
[02:05:00] <aeth> whatever that is, that's definitely not OOP
[02:05:21] * Aurora_v_kosmose rolls very multimethods
[02:05:47] <hayley> It'd be (foo: bar) for messaging OO.
[02:06:07] <aeth> The point of OOP is to make it look like English, e.g. aeth.runs(home)
[02:06:13] <aeth> why would you want (runs aeth home) instead?
[02:06:21] <hayley> (runs: aeth home)
[02:06:38] <Aurora_v_kosmose> Isn't that amusingly a large part of what makes COBOL so obnoxious to use?
[02:06:56] <hayley> Because there was a paper on Actors with Lisp syntax, and (aeth runs home) looks weird, as aeth is an actor, and (runs home) is the message. 
[02:06:58] <aeth> (if the point is for it to look like English, shouldn't it be subject oriented programming, not object oriented programming? because you put the . after the grammatical subject?)
[02:08:21] <Aurora_v_kosmose> some-reader-macro(aeth runs home) => (act aeth runs home) seems like it'd work... sort of.
[02:09:17] <hayley> In the language/VM combination I am specifying, bla == (bla) == (bla: self), (foo bar) == (foo: self bar) and (foo: bar) is a send of FOO to BAR.  
[02:16:18] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[02:24:37] *** Quits: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20) (Remote host closed the connection)
[02:26:29] *** Joins: vms14 (~user@29.red-79-153-202.dynamicip.rima-tde.net)
[02:26:40] <vms14> what do lispers think about forth?
[02:26:52] <skeemer> what do you people think about the little schemers series of books ?
[02:27:12] <vms14> skeemer: didn't like the format since they're questions all the way
[02:27:28] <vms14> but is one of the most recomended books by schemers
[02:27:48] <vms14> the 3 books
[02:28:35] <vms14> I'm thinking in learning forth
[02:28:50] <vms14> what I love from lisp is metaprogramming
[02:29:38] <vms14> forth seems it can make me happy and is like the easiest (usable) language to implement so I can roll my own
[02:30:48] *** Quits: clothespin (~awolven@c-73-209-95-92.hsd1.il.comcast.net) (Remote host closed the connection)
[02:31:30] <vms14> also I always do things in a revers way, so at least forth will understand me
[02:32:12] <White_Flame> forth is neat, but usually stays pretty low level and builds single-person cathedrals for "real" software development
[02:32:52] <White_Flame> it's also not really that fast of a language, but has small source code, hence stack machines being mostly relegated to intermediate formats nowadays
[02:33:09] <White_Flame> but it's an important software model to learn
[02:35:27] <skeemer> vms14, what is forth? 
[02:35:28] <vms14> White_Flame: Do you think it will give me the freedom and power I feel in Common Lisp?
[02:35:57] <White_Flame> depends on what you mean by that
[02:36:07] <White_Flame> forth has like zero abstractions at all, and you're dealing with memory pointers
[02:36:12] <White_Flame> that's fun for a certain mindedness
[02:36:31] <vms14> skeemer: depends on who responds, forth is a programming language, operating system, a religion or a way to solve computer problems
[02:36:38] <White_Flame> and you can do compile-time code generation as well, though it's not as easy as lisp
[02:36:39] <skeemer> vms14, what? XD
[02:36:51] <skeemer> vms14, wait it just seems a programming language from wikipedia
[02:37:08] <White_Flame> in forth, `1 1 +` equals 2
[02:37:16] <White_Flame> and it has a dictionary stack of named allocations
[02:37:20] <vms14> White_Flame: but I could implement it nicely or badly in some random programming language and provide easy ffi
[02:37:37] <White_Flame> and an operand stack that pushes & pops operands
[02:37:51] <vms14> so I could steal a lot of libraries, the thing is idk if I will love it like I do with lisp or more
[02:37:54] <skeemer> vms14, ohh but it does not use a lisp-y syntax :(
[02:37:58] <White_Flame> vms14: absolutely.  you're correct in that it's the easiest "real" programming language to implement
[02:38:07] <skeemer> i don't like programming languages not using list syntax
[02:38:33] <vms14> skeemer: no, I also dislike non-paren syntax, but forth is kind of an exception
[02:38:48] <White_Flame> so if you're using it, for instance, as an embedded scripting language (though not sure why you'd need to in lisp ;) ) it's super easy to bootstrap in
[02:39:00] <vms14> I consider non lisp languages like languages for mortals, but forth isn't one of them
[02:39:00] <White_Flame> forth is a zero-syntax language
[02:39:08] <White_Flame> spacing is basically the only syntax
[02:39:59] <White_Flame> and the actual definition of "polish notation" languages (whether forward or reverse) is that the number of parameters are always implicit in the operation, so you don't have to have grouping syntax
[02:40:01] <vms14> White_Flame: I mean not using it in lisp at all, but I wonder if I will be able to take forth (or a hand made one) as a replacement for common lisp
[02:40:17] <White_Flame> CL has waaaaay more abstrarctions and flexibility than forth
[02:40:28] <vms14> the plus is easy to implement in any language I can transpile or interpret and provide ffi
[02:40:30] <skeemer> i am relatively new to lisp-y... started to understand macros in common lisp then in people using scheme is telling me that using macros is a bad practice
[02:40:35] <skeemer> -.-
[02:40:41] <vms14> skeemer: hah xD
[02:40:42] <White_Flame> forth was invented to be a ham radio controller on small chips, or something like that
[02:40:51] <skeemer> how cool
[02:40:57] <vms14> skeemer: macros are the best thing lisp has and the reason I love it
[02:41:27] <vms14> White_Flame: yes, I try to focus on the zero syntax fact and metaprogramming abilities
[02:41:39] <White_Flame> I was doing tons of code generation in other languages before lisp, and it always sucked. there's a reason it's black magic to most.  Then in CL, it's so simple it's easy to pull in for very simple purposes instead of being this massive ordeal
[02:42:03] <vms14> cause knowing is easy to implement I can use any language/library I need
[02:42:22] <skeemer> White_Flame, i was foreign to the concept of code generation actually
[02:42:26] <vms14> doing something like a vm or just transpile
[02:42:37] <vms14> skeemer: it's super nice stuff
[02:42:40] <skeemer> then i started reading practical common lisp
[02:42:54] <vms14> also scheme has continuations which I never learned but everyone says they are cool xD
[02:43:14] <White_Flame> skeemer: most are
[02:43:14] <skeemer> vms14, i don't think continuations have the same amount of applications of macros
[02:43:14] <vms14> skeemer: the easiest macro you can make is a with- macro
[02:43:26] <vms14> start by this
[02:43:26] <White_Flame> skeemer: us doing codegen was way out of the model of most languages, and we had to build up things ourself
[02:44:02] <vms14> for example if you know about the try with resources in java, you can mimic that with a with- macro
[02:44:04] <White_Flame> continuations are a reduction of flow control into a singular "nand gate", and you have to reconstruct flow control from that
[02:44:26] <White_Flame> since Scheme was an attempt at making a minimalist language
[02:44:33] <skeemer> vms14, that's a good example!!! Thanks
[02:44:37] <White_Flame> (which pushes all the complexity to the user & the libraries)
[02:44:49] *** Joins: clothespin (~awolven@c-73-209-95-92.hsd1.il.comcast.net)
[02:45:12] <vms14> for example (defmacro with-db (db &body code) (let ((db (connect ...))) ,@code (close db)))
[02:45:13] <skeemer> so something like with file open do ...., so the macro should take care of the whole opening and closing of the file right? 
[02:45:24] <vms14> bad example, but hope it serves to understand what I mean
[02:45:30] <vms14> yes
[02:45:39] <skeemer> vms14, yeah sure... welll but this can be done also with a function right?
[02:45:50] <White_Flame> no
[02:45:54] <vms14> it's just for you to start understand macros
[02:46:02] <vms14> it's the easiest macro I can think of
[02:46:04] <skeemer> White_Flame, why no? 
[02:46:07] <White_Flame> well, you can do it (turing complete) but it's way more clunky
[02:46:11] <skeemer> vms14, yes it's a good one... 
[02:46:15] <skeemer> i will experiment...
[02:46:19] <vms14> a nice application is when you have to define similar functions
[02:46:26] <skeemer> do you have other kinds of task i can use to practice macros?
[02:46:35] <vms14> hmm
[02:46:52] <vms14> I have two macros and people from here helped me
[02:47:00] <skeemer> vms14, "a nice application is when you have to define similar functions" yeahh i noticed that... 
[02:47:00] <White_Flame> it'd have to be (with-db2 (lambda (db-connection) ...)), where the "with" scope then calls your function with the parameter, and closes after your function exits
[02:47:07] <vms14> it's not nice code and not even commented
[02:47:36] <vms14> https://gitlab.com/vms14/all/-/blob/master/lisp/html.lisp
[02:47:36] -ixelp- lisp/html.lisp ¬∑ master ¬∑ vms / all ¬∑ GitLab
[02:47:39] <White_Flame> and things like IF would have to be (if value (lambda () ..then-body..) (lambda () ..else-body)), if they weren't macros/special forms
[02:48:00] <vms14> this is html generator, it creates tags as functions so you can (html (head)...)
[02:48:31] <White_Flame> with a macro, it can receive blocks of code directly and decide what to construct around them
[02:48:32] <vms14> not a good example, but I used a lot this file even if i don't like how I implemented
[02:48:43] <vms14> I mean, there is even a function named recursion xD
[02:48:52] <vms14> and another example idk if is there
[02:49:08] <skeemer> thanks White_Flame 
[02:49:10] <skeemer> thanks vms14 
[02:49:40] <vms14> oh it's not there
[02:49:45] *** Quits: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net) (Ping timeout: 256 seconds)
[02:49:48] <vms14> there is only shit code in that repo
[02:50:01] <vms14> but another example was faking async code
[02:50:39] <skeemer> faking async code?
[02:50:46] <skeemer> don't understand wha tyou mean here
[02:50:55] <vms14> made a macro which expected code and returned a lambda that would execute only one statement every time is called
[02:51:02] <skeemer> anyway people i bought the three little schemers books (little,seasoned,reasoned)
[02:51:06] <skeemer> i hope it will be a good book 
[02:52:06] <vms14> the macro created a lambda with a switch case and a counter
[02:52:41] <vms14> every statement had its corresponding case and the lambda just incremented the counter and entered the switch case
[02:53:07] <vms14> so everytime you call that lambda would execute the next instruction
[02:53:19] <vms14> you cannot do that without metaprogramming
[02:53:55] <vms14> my first implementation was using eval and converted the code to a list
[02:54:04] <vms14> so I just eval
[02:54:14] <vms14> eval'ed one item of the list
[02:54:39] <vms14> nodefun helped me to get rid of the eval by making a loop that created the switch case
[02:55:39] <vms14> btw about the use case of a macro
[02:55:58] <vms14> whenever you see a pattern use a function, if the function cannot do, use a macro
[02:56:46] <skeemer> vms14, why are schemers so aganist macros
[02:56:47] <skeemer> ?
[02:56:54] <vms14> you'll start noticing when you repeat code and will make a function or a macro
[02:57:28] <White_Flame> scheme does have macros, they're just more limited.  They think those limitations make them safer
[02:57:36] <vms14> skeemer: cause two things, one is a macro can clobber a symbol name and it's a bug hard to figure
[02:57:38] <White_Flame> and they call them syntax-rules or something
[02:58:02] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[02:58:03] <White_Flame> CL macros are just functions that can return any source code they want
[02:58:13] <vms14> and the other is scheme has only one namespace for functions and variables which makes the first problem wors
[02:58:33] <vms14> but, the bug is avoided by using gensym
[02:58:49] <skeemer> vms14, what is gensym? 
[02:58:56] <vms14> when you start looking at some lisp code it's likely you'll see gensym in macros
[02:59:08] <skeemer> White_Flame, i would like something like common lisp in terms of macros but minimalistic like scheme
[02:59:26] <White_Flame> minimalism is academically interesting, but always harder to use
[02:59:33] <White_Flame> (unless you're literally doing toy programs)
[02:59:44] <vms14> gensym generates a symbol, you create a symbol to use this one in a macro so you now no one will have a symbol like this one as gensym ensures to generate a unique symbol 
[02:59:55] <White_Flame> also, CL's macro system is more minimalist than scheme's
[02:59:55] <vms14> know*
[03:00:06] <skeemer> White_Flame, just the macro system
[03:00:20] <vms14> skeemer: I tried to like scheme
[03:00:28] <vms14> it's hard
[03:00:41] <vms14> I like a lot s7 scheme, but it's scheme
[03:00:56] <White_Flame> I still need to look in to Racket and glean features into CL, in terms of muti-langauge support, and evaluate some of the graphical stuff they've done
[03:00:58] <vms14> (car ()) crashes the program in scheme
[03:01:04] <vms14> () is true
[03:01:11] <vms14> no format function
[03:01:29] <vms14> and more stuff that makes me cry
[03:01:39] <vms14> specially no defmacro
[03:01:43] <White_Flame> also, SICL might interest you.  It's a common lisp implemented in common lisp, so it all can use its own abstractions
[03:01:51] <vms14> and (define (function)) i don't like it
[03:01:55] <White_Flame> everything is built on simpler lisp
[03:02:07] <skeemer> vms14, ok you bought me... i am convinced
[03:02:12] <skeemer> CL is indeed the best
[03:02:18] <hayley> SICL is implemented in full CL
[03:02:21] <vms14> depends skeemer 
[03:02:30] <vms14> scheme has a lot of implementations
[03:02:35] <skeemer> vms14, hold on, how is (car ()) crashes the program???
[03:02:39] <vms14> racket is nice for example
[03:02:47] <White_Flame> scheme doesn't just have a lot of implementations, it has a lot of basically language forks
[03:02:53] <vms14> skeemer: in scheme you can't (car ())
[03:02:54] <skeemer> vms14, most of the ones i tried were lacking bindings for interesting/useful libraries
[03:03:04] <vms14> and () is not nil
[03:03:05] <skeemer> vms14, well but i hope it's a compile error
[03:03:43] <White_Flame> vms14: IMO that one thing is correct ;)  I wholly disagree with the (eq 'nil '())-ness of CL
[03:03:59] <vms14> and for example s7 scheme is written in ansi c as two files and you can put it wherever you want
[03:04:06] <White_Flame> and think the symbol NIL should evaluate to ()
[03:04:14] <vms14> I've put it in android and made a textview from scheme using jni
[03:04:17] <White_Flame> and thus (symbolp '()) should be false
[03:04:23] <skeemer> vms14, where is this two C files? can you link them?
[03:04:43] <vms14> White_Flame: I like () being nil when recursing
[03:05:02] <White_Flame> vms14: that's horrible.  if you're scanning fro symbols while recursing
[03:05:03] <vms14> so I can (car ()) and see if the end or get the item
[03:05:18] <vms14> White_Flame: my code is usually horrible xD
[03:05:18] <White_Flame> that part is fine
[03:05:43] <White_Flame> I do like that end-of-list still has a car & cdr that are end-of-list.  and () being the end-of-list is fine
[03:05:44] <White_Flame> however
[03:05:46] <gilberth> On that note, it's interesting how this changed with LISP. When you read the old papers, you recognize that there is T and F like in Scheme for booleans and a separate NIL with CAR and CDR only defined for conses. This later then changed. IIRC even EQ was initially defined for atoms only.
[03:05:51] <White_Flame> () being a symbol is horrible
[03:06:41] <vms14> gilberth: hi
[03:06:50] <White_Flame> and I will call it horrible as long as it is one :)
[03:06:52] <vms14> what do you think about forth
[03:06:52] <gilberth> Heh, with LISP the empty list always was the NIL atom.
[03:07:15] <vms14> also what about nodefun? is she there lately?
[03:07:37] <White_Flame> now known as hayley
[03:07:47] <vms14> oh, now I understand
[03:08:02] <gilberth> And she lives at our cafe.
[03:08:17] <vms14> :0
[03:09:08] <gilberth> Must be homeless or something. But then I am too for some definition of homeless.
[03:09:21] <hayley> With the number of times I have to leave home...
[03:10:09] <vms14> hayley: aren't you in some random course you started like some years ago?
[03:10:43] <hayley> In university? Sure, but I transferred to another in 2021.
[03:11:01] <vms14> I remember you started or were going to start and disliking the schedule
[03:11:23] <hayley> I had a database class, where the first week was basically an Oracle SQL ad. That was the straw that broke the camel's back after the university staff and infrastructure showed they were very incompetent.
[03:12:06] <vms14> idk about university but in general is hard to find a teacher with vocation
[03:12:22] <vms14> I suppose in university is easier 
[03:13:19] <vms14> but I think there was some complicated stuff you liked 
[03:13:23] <hayley> Nowadays I find it ironic that the PhD advisor for the supervisor of that course is quite helpful when I have some GC questions.
[03:13:28] <vms14> as you only like complicated stuff
[03:14:13] * vms14 likes hello worlds
[03:14:24] <hayley> I always liked the maths classes, and the electives I chose (physics and electrical engineering) were run quite well. The only bad thing there was that I'd have to attend into the evening for EE, and the maths teachers didn't have any pointers on handling submatching in REs.
[03:16:12] <vms14> hayley: being you a "math person" more than a "words person" do you notice a difference in how a "math person" writes code compared with a "words one"?
[03:16:46] <hayley> I'm not sure if I'm a "math person". e.g. I'm not a type weenie.
[03:17:06] <hayley> But I got my best marks on the maths exam at high school.
[03:17:15] <vms14> I think the ones who like math enjoy doing algorithms while the others enjoy doing another kind of abstractions
[03:17:53] <vms14> more like syntax sugar? I cannot really see if there is really a difference in the way they code
[03:17:54] *** Quits: Inline (~Inline@2a02:908:1252:7a80::1aa) (Read error: Connection reset by peer)
[03:18:19] <vms14> but I'm a "words person" and I love metaprogramming and stuff like that
[03:19:06] <vms14> I like when I make stuff like html generators and dirty transpilers
[03:30:58] <vms14> also a thing that caught my attention is bottom up programming, and I always wanted to learn more and improve my "bottom up skills"
[03:32:00] <vms14> this is in part of why I think I could get to like forth, as supposedly bottom up and forth seem to be even more related than with lisp + macros
[03:32:09] <White_Flame> I do not recomment bottoms up programming, though ;)
[03:32:15] <White_Flame> *recommend
[03:32:28] <vms14> White_Flame: I don't really have learned fully what it means
[03:32:43] <White_Flame> usually pouring a glass of alcohol down your maw
[03:32:45] <vms14> just have a vague understanding but never found explicit info about
[03:34:26] <vms14> as I understand is basically work with layers, and kind of corresponds with lisp and forth as What I think bottom up is to extend the language until it understands the problem and you end having a little program and extensions of the language
[03:35:25] <gilberth> Ok. When I say that (draw-design stream (region-union (make-line* ...) (make-line* ...)) should not draw two lines on top of each other, but fill the defined area using the line style with the foreground ink, we already have the PS model. [But for Bezier curves, but that is a minor issue.]
[03:35:34] <vms14> at least this is what I think it is, and for me it sounds to be a nice way to do stuff, I don't understand what's wrong White_Flame but I cannot appreciate becase I almost have no skills about bottom up 
[03:35:51] <White_Flame> bottom up = write simple functions, then write functions that use those
[03:35:59] <vms14> xd
[03:36:07] <White_Flame> top down = write the toplevel functions you wish to call, then write the functions that that toplevel function uses
[03:36:08] * hayley timetabling
[03:36:14] * hayley uploaded an image: (32KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/LXmWVkWdlvvrMJfFosfDZVoW/Screenshot%20from%202022-02-15%2010-40-08.png >
[03:36:25] <hayley> I have literally half the classes to schedule, but I'm still struggling to make myself happy.
[03:36:30] <White_Flame> bottom up defines technology/componentry first, top down defines abstractions/protocols/usage first
[03:36:35] <gilberth> There also is a COMPOSE-OVER operator in CLIM, which is said to draw one on top the other and thus having overlap. It also is said, that for regions compose-over would be the same as region-union, which in my model wouldn't be true anymore.
[03:37:01] <moon-child> clim3 time?
[03:37:04] <White_Flame> but you can write functions in any order you choose, and there's going to be some literal combination of top-down and bottom-up going on
[03:37:29] <vms14> White_Flame: usually what I hear from other programmers is they use a mix of both
[03:37:31] <gilberth> Hence, I could easily have the PS imaging model. Path construction API with move-to/line-to etc would just be an alternative API.
[03:37:37] <vms14> and that depends on what are they doing
[03:37:45] <White_Flame> yep
[03:37:52] <vms14> White_Flame: but I don't get why you don't recommend it
[03:38:03] <White_Flame> why I don't recommend what?
[03:38:05] <vms14> as I don't know what drawbacks has
[03:38:10] <gilberth> moon-child: More like CLIM 2.5. I would need to fix way more for a CLIM3 as untangling output recording and layout.
[03:38:12] <vms14> bottom up
[03:38:22] <White_Flame> I have no preference
[03:38:31] <White_Flame> again, the ordering really doesn't matter
[03:38:50] <White_Flame> and all that it is is which order you happen to type in or finalize the design of your functions & classes
[03:38:56] <White_Flame> s/classes/datastructures/
[03:38:56] <vms14> <White_Flame> I do not recomment bottoms up programming, though ;)            
[03:39:02] *** Quits: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se) (Ping timeout: 272 seconds)
[03:39:13] <White_Flame> "bottoms up" = alcohol reference.  "bottom up" = implementation style
[03:39:18] <vms14> lol
[03:39:25] <vms14> thought it was a typo
[03:40:04] <gilberth> Somehow I wind up to develop locally top-down, globally bottom-up and often functions appear in the source code top-down, while actually have been written bottom-up initially. my two cents.
[03:40:26] <vms14> I don't know exactly when I'm doing top or bottom
[03:40:33] * moon-child usually opts for sideways development
[03:40:39] <vms14> I understand for example if I make a predicate, this is bottom
[03:40:43] *** Joins: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
[03:40:49] <White_Flame> vms14: are you writing a function that will be called by something?  then you're doing bottom up
[03:40:56] <vms14> but for me seems like the way to do stuff
[03:40:58] <White_Flame> are you writing a function that calls things that don't exist yet?  then you're doing top down
[03:41:06] * hayley uploaded an image: (201KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/POFdhQlWyeZOKgRILmZhRdVa/banned.png >
[03:41:07] <vms14> you make your language able to understand yor problem
[03:41:14] <White_Flame> it's literally just those 2 orderings
[03:41:39] <vms14> White_Flame: do you mean the wishful thinking is top down?
[03:41:57] <White_Flame> both are wishful thinking
[03:42:38] <vms14> I've tried wishful thinking as it seemed to help you at design
[03:42:40] <White_Flame> when doing bottom-up, sometimes you realize that the lower level you wrote is much clunkier than anticipated, and after writing the higher stuff you have a better idea for how to tackle it
[03:42:57] <vms14> you try to use what you have to create
[03:43:14] <gilberth> moon-child: Ok. I'll need to write up my idea how the imaging model ought to be. And I love writing. Not.
[03:43:45] <kakuhen> <hayley> "I'm not sure if I'm a "math..." <- i'm not a type weenie either but i also consider myself bad at math
[03:43:46] <White_Flame> vms14: it's a pretty useless dichotomy, IMO
[03:43:52] <White_Flame> not really worth considering frankly
[03:44:05] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[03:44:11] <kakuhen> one of my hot takes on type theory is that it wouldnt need to exist if russell already had what we have today with category theory
[03:44:56] <vms14> but reading a book interviewing some programmers they made me realize the best way to make something grow and being defined is to start using it as soon as possible
[03:45:27] <vms14> as no one anticipates the future and using it makes you see if it is what you wanted or not
[03:45:41] <White_Flame> and others say that you should develop an architecture before you start writing code and defining what the lower things will be
[03:45:47] <vms14> so wishful thinking in this case would be useless
[03:45:57] <moon-child> gilberth: hey, if you ever get bored, there is more to write about REs
[03:46:03] <moon-child> :)
[03:46:12] <White_Flame> all of these are true simultaneously.  your train of thought is spinning on tryign to divide things that aren't really meaningful
[03:46:44] <White_Flame> coding is going to be far better for you than trrying to read all these varying opinions and attempting to pre-qualify yourself or whatever
[03:47:01] <gilberth> moon-child: Yes, I could write all day. It's only that I don't like writing and I am not too good at it.
[03:48:01] <hayley> <https://applied-langua.ge/posts/> is mostly myself writing, while being bad at it and disliking writing. So?
[03:48:02] -ixelp- Published texts
[03:48:15] <vms14> White_Flame: yes, but writing it everything before getting a feedback would force you to rewrite it from scratch if it ends not being what you wanted
[03:48:28] <White_Flame> same thing as writing all your low level before using it
[03:48:34] <White_Flame> the direction literally does not matter
[03:48:37] <vms14> this is why agile is popular today
[03:48:42] <White_Flame> it's also a lie
[03:48:53] <White_Flame> "popular" != useful, beneficial, or successful
[03:49:07] <hayley> "Billions of flies ____"
[03:49:12] <vms14> no, but what it tries is to make something minimal and get feedback
[03:49:17] <White_Flame> (successful as in the software project, not the sale of hte notion of agile itself)
[03:49:31] <White_Flame> vms14: and taht doesn't work at all for hard or research problems
[03:49:46] <White_Flame> agile was invented for small teams to work on already-solved problems for common implementations
[03:49:47] <vms14> I suppose, I'm not really into agile
[03:49:58] <vms14> also in stuff like lisp you get instant feedback
[03:50:10] <hayley> 1. are raiding your pantry while you sleep 2. are eaten by the average human while they sleep 3. eat shit 4. shit
[03:50:11] <hayley> 5. all of the above
[03:50:12] <vms14> for every function you write at the moment you write it
[03:50:34] <White_Flame> hayley: you eat flies?
[03:50:50] <hayley> That, or it's eating spiders while you sleep.
[03:50:54] <White_Flame> oh or you mean the sleep thing
[03:50:55] <White_Flame> yeah
[03:51:03] <hayley> Since the latter is wrong, the former must obviously be true.
[03:51:06] <gilberth> API design is somehow a different issue. You want to consider how a nice, well-defined interface should look like. I do that right now, and while pondering the imaging model of CLIM, I do so without much regard to how to implement it, being confident that I'll find good (that is fast yet correct in my case) implementation.
[03:51:07] <White_Flame> (also, it's very likely not true :) )
[03:54:29] <gilberth> And it's full of trade-off. I want to keep the general design of the CLIM graphics API, yet at the end of day also want to offer a move-to/line-to PSish API as the latter is so common these days. Makes my head hurt.
[03:57:10] <kakuhen> off-topic, but does anyone here know how "good" allegro CL's tree shaker is?
[03:57:19] <White_Flame> gilberth: I'm seriously considering rewriting cl-vectors
[03:57:25] <White_Flame> not sure if that overlaps with your work
[03:57:46] <kakuhen> in short, i have added "magic wormhole implementation" to my backlog of lisp vaporware and it'd be cool to ship a lisp image but with only the things i actually use
[03:57:53] <White_Flame> (or exactly what your overall project is, now that I think about it)
[03:57:54] <kakuhen> you can only go so far with sbcl's core compression
[03:59:01] <White_Flame> kakuhen: I would presume a tree shaker's primary option would be if you don't include the compiler, and if you can list thinkgs you want to keep for runtime.  beyond that, I'm not sure how much variability between them tehre would be
[03:59:15] <White_Flame> I guess just the percentage size of the various runtime components would change per implementation
[03:59:34] <gilberth> White_Flame: It perhaps does, as my secret agenda is to establish the CLIM graphics model as the de facto standard API. Hence my pondering on a familiar orthogonal API. BTW, when you dig the general designs of CLIM, you recognize that they at times could do more than PS or PDF. I really would need to write sth up to have a proposal.
[04:00:33] <White_Flame> re vectors, I think mcclim only uses cl-vectors for font rendering, and does its own thing for lines and such?
[04:01:07] <gilberth> CLIM or Silica rather is fine in general. Yet, there are hidden places at which AA wasn't really considered although CLIM has an alpha channel. I need to clarify, fix, and define those pieces in the spec.
[04:02:15] <gilberth> White_Flame: I don't know. My mcclim used FreeType, RENDER and Cairo. In general, these days, I am not a firm believer in that you should do everything in Lisp.
[04:03:44] *** Quits: lagash (lagash@lagash.shelltalk.net) (Ping timeout: 250 seconds)
[04:04:20] <gilberth> I mean, although I was dragged to rendering, I don't want to waste too much time on just that, when different people already did the work. I believe for CLIM (not the Silica graphics substrate) we have way more issues that need a serious reconsideration. I don't want to waste my time with digging font rendering.
[04:04:52] <White_Flame> I have lots of nitpicks with renderers, so in my opinion they haven't already "done the work" ;)
[04:05:21] <White_Flame> but also, non-native stuff especially in lisp is a nightmare for deployment
[04:07:24] <gilberth> Indeed, it is. Where is in the file system is your keyboard mapping today? Or the font files? Or the config? I want to pursue a different route and just using the APIs aka C libraries everybody uses fixes all this for me.
[04:11:17] <gilberth> But I said the same in the 90s as there once was a very active mailing list discussing a possible Lisp-OS. I don't want to write device drivers all days and said: "Hey, let us start by replacing init and work from there." Also I proposed a head-less system for the very same reasons.
[04:13:37] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Quit: ec)
[04:21:04] <gilberth> White_Flame: I am open to a fixed rasterizer. I would just prefer that libraries like these or like CL-PDF e.g. would stick to a common API. It's depressing that each and every graphics-related lib I come across is using its own. Unfortunately I am bad at marketing and writing. You really can untangle the underlying graphics API of CLIM from all the rest, even from window system concepts.
[04:26:58] <vms14> hayley: do humans convert to carnivorous plants while they sleep?
[04:27:07] <hayley> Maybe?
[04:27:15] <vms14> why a spider of a fly would get in a human mouth
[04:27:25] *** Joins: lagash (lagash@lagash.shelltalk.net)
[04:27:34] <vms14> and once it does, the human closes the mouth and eats it like it was a trap?
[04:27:51] <vms14> or*
[04:28:30] <vms14> maybe they just wanted to kiss the human
[04:33:11] <drakonis> phoe: what's a clr2?
[04:33:25] <phoe> drakonis: common lisp recipes 2nd ed
[04:33:31] <drakonis> oh!
[04:33:33] <drakonis> neat.
[04:34:08] *** Quits: random-nick (~random-ni@87.116.181.150) (Ping timeout: 272 seconds)
[04:35:20] <hayley> Are there any studies of effects of compressed pointers in the JVM? It seems <http://blog.leneghan.com/2012/03/reducing-java-memory-usage-and-garbage.html> shows a reduction in heap size and number of GCs.
[04:35:21] -ixelp- Hacking Away: Reducing Java Memory Usage and Garbage Collections with the UseCompressedOops VM Option
[04:35:59] <hayley> Theoretically, as you have a lower allocation rate, you run out of memory less frequently and thus can GC less often, leading to better amortized performance. But OTOH it's more instructions to compress and decompress pointers.
[04:36:34] <hayley> ...though on x86 the compiler will happily emit MOV RAX, [RBX * 4 + RCX] or smth for the same effect.
[04:38:49] <moon-child> you lose array indexing, though
[04:38:55] <moon-child> can't [rbx * 4 + rcx * 4]
[04:39:26] <hayley> Right.
[04:40:35] <drakonis> mps in sbcl when
[04:40:57] <hayley> Doug Katzman is working on it. But I want a parallel GC, and MPS is not that.
[04:41:33] <hayley> MPS is incremental, but not concurrent nor parallel, so the GC does not run faster, nor does it actually run in parallel with the mutator.
[04:41:59] <drakonis> i see
[04:42:00] *** Quits: eugercek (~user@user/eugercek) (Remote host closed the connection)
[04:47:17] <hayley> This is a big deal when you have e.g. 12 threads happily allocating along. And I guess moon-child and aeth get it worse, would they want to use all their cores.
[04:49:14] *** Quits: vms14 (~user@29.red-79-153-202.dynamicip.rima-tde.net) (Remote host closed the connection)
[04:51:23] <hayley> https://www.youtube.com/watch?v=r5tQk4BNrZ8
[04:51:23] -ixelp- 2kliksphilip's S.H.I.T Advice #2 - YouTube
[05:03:54] <drakonis> hayley: https://sci-hub.se/10.1145/1379022.1375586
[05:03:59] <drakonis> have you seen immix?
[05:04:06] <hayley> Yes.
[05:04:18] <drakonis> cool
[05:04:34] <hayley> One of the creators was the PhD advisor for the course supervisor for the course that I left in 2020.
[05:04:43] <drakonis> huh, cool.
[05:09:53] *** Quits: drakonis (drakonis@user/drakonis) (Quit: WeeChat 3.1)
[05:10:55] *** Joins: drakonis (~drakonis@user/drakonis)
[05:12:04] <hayley> I guess non-moving would be better on caches, but my main issue is how to safely parallelise SBCL's "page table" abstraction without locking all the damn time.
[05:13:40] <hayley> Cliff Click also mentioned prefetching when talking about Pauseless in 2009, but I can't find anything on prefetching for algorithms that aren't mark-sweep.
[05:15:16] <hayley> (Henry Baker wrote on cache-conscious copying, but it mostly just said "avoid reading forwarding pointers by copying immutable objects" and "use my damn stack allocation".)
[05:21:20] <hayley> ...well, Pauseless is a mark-copy collector like Immix, where it marks everything, then copies the most empty pages.
[05:24:01] <White_Flame> I don't think the cache effect of moving vs non-moving affects much, given the quantity of mutator cache misses vs the much smaller number of moving GC events
[05:25:51] <moon-child> mutator is expected to have fairly good locality though
[05:28:13] <White_Flame> how often does the GC move things in comparison to all those locality accesses?
[05:28:23] <White_Flame> it's just a pretty singular disruption per GC event
[05:28:34] <White_Flame> compared to bajillions of cache hit accesses inbetween
[05:28:49] <hayley> https://twitter.com/stevemblackburn/status/1493403260241465344 Speaking of the devil.
[05:28:56] <hayley> "AFAIK, we've never found a win, probably because the copy cost dominates."
[05:29:44] *** Joins: Rue (~rue@2001-b011-1000-17d9-d616-1cce-b758-6ab8.dynamic-ip6.hinet.net)
[05:31:11] <hayley> He also mentions <https://v8.dev/blog/pointer-compression> on the topic of compressed OOPs, with real numbers.
[05:31:11] -ixelp- Pointer Compression in V8 ¬∑ V8
[05:32:53] <White_Flame> it would be nice if a system could smoothly transition at runtime between 32-bit and 64-bit pointers as the heap grows
[05:33:12] <hayley> But it seems I can't win; either I make intrusive changes to gencgc and hurt my head trying to make locking work, since it was never designed to run in parallel, or I just redo the whole GC to make it mostly-not-moving or something.
[05:33:28] <hayley> The JVM apparently can transition, but it is sure as hell not smooth.
[05:33:45] <White_Flame> or even intermediate sizes.  40-bit is a terabyte
[05:34:21] <hayley> I have an idea on how to transition for a more CLOS-y object layout, with the necessary indirection for CHANGE-CLASS, but it is notably not thread safe, but then you can compress pretty damn small if you like (8-bit deltas, anyone?)
[05:34:56] <moon-child> I don't think it would be terrible to stop the world and transition everything to 64-bit once the heap grows large enough
[05:35:07] <White_Flame> sure, as a 1-time thing
[05:35:11] <hayley> That's what JVMs do now.
[05:35:12] <moon-child> but also, you could have 32- and 64-bit pointers coexist.  Have a tag to say 'the next 4-byte sequence is a continuation of this one'
[05:35:23] <moon-child> would be a pain.  Maybe not worth it.  But
[05:35:32] <hayley> Maybe I should bring up using MMtk with Steve, but idk how to make that work.
[05:35:57] <hayley> The SBCL build process involves Lisp spitting out C code for object layouts and tables, and Lisp has its own allocation buffers and such.
[05:37:01] *** Joins: christophergray (~christoph@186.151.40.100)
[05:47:55] <hayley> A pointer prefetch insertion pass for SBCL would also be interesting, but we already have list linearisation, and also immediate data to deal with. But a (probably easily predictable) test is supposed to be faster than a cache miss.
[05:49:14] <hayley> Another another strategy would be to see if Ravenbrook would be interested in parallelizing the MPS. But that would probably break things, as layout-wrangling code written by the user now has to involve atomics.
[06:41:53] *** Quits: minion (~minion@common-lisp.net) (Remote host closed the connection)
[06:42:39] *** Joins: minion (~minion@common-lisp.net)
[06:43:30] <robin> hayley, you might know this already but apparently some sbcl hackers are working on sbcl+mps including parallel gc; doug katzman gave a talk on sbcl+mps last year (as drakonis just mentioned in another channel: https://boston-lisp.common-lisp.dev/)
[06:44:38] <robin> (no recordings though afaict and i haven't found much other than the talk announcement yet)
[06:48:02] <robin> oh, you mentioned that already, lol
[06:51:42] <hayley> robin: I do, I attended that talk. But thanks.
[06:56:06] <drakonis> ha, crossover.
[06:56:19] <robin> hayley, oh, neat. i'm assuming from the last screenful of messages there was no exciting news about parallel gc?
[06:56:51] <hayley> Nope. And drmeister was warning everyone about allocation locks in MPS kicking his backside, near the end.
[06:56:59] * robin trying to determine whether it'd be worth using mps or mmtk or something for guile, instead of the status quo of relying on bdwgc for everything
[06:57:07] <robin> :/
[07:05:35] *** Quits: drakonis (~drakonis@user/drakonis) (Quit: WeeChat 3.4)
[07:06:06] *** Joins: drakonis (drakonis@user/drakonis)
[07:06:47] *** Quits: drakonis (drakonis@user/drakonis) (Client Quit)
[07:06:57] *** Joins: drakonis (drakonis@user/drakonis)
[07:16:19] <kakuhen> <White_Flame> "it would be nice if a system..." <- the smoothest i can think of is to start thunking 32-bit <--> 64-bit but this will suddenly add too much overhead to be considered smooth, i think
[07:16:41] <kakuhen> also what i am guessing is likely wrong anyway since it sounds too simple to be true
[07:17:56] *** Quits: drakonis (drakonis@user/drakonis) (Quit: WeeChat 3.4)
[07:18:06] *** Joins: drakonis (drakonis@user/drakonis)
[07:18:34] *** Quits: drakonis (drakonis@user/drakonis) (Client Quit)
[07:18:43] *** Joins: drakonis (drakonis@user/drakonis)
[07:19:36] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[07:23:11] <moon-child> wine does something like that
[07:24:57] <Alfr> Not sure 32-bit pointers are worth the hassle any more. Assuming byte addressing and that all data are pointers, then 32-bit pointer can only have any advantage when the space you have is less than 2*4GiB ...
[07:25:24] *** Quits: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se) (Ping timeout: 240 seconds)
[07:26:57] <moon-child> 'byte addressing' and 'all data are pointers' seem a bit inconsistent
[07:29:40] <dave0> Alfr: in the old days there was a low memory page that you could use smaller absolute addresses to acess
[07:29:42] <Alfr> moon-child, byte addressing, as that's what most (all?) cpus take nowadays, and all data are pointers would behave worst when switching from 32- to 64-bit pointers, as that would double your memory requirement.
[07:30:00] <gilberth> It's kind of funny, with word addressing you could address 16GB with 32-bit pointers. When you take into account that objects smaller than 2 words don't make sense, you could address even 32GB. And since you use just 4 bytes for a pointer this would be worth like 64GB with 64-bit pointers.
[07:30:22] <dave0> Alfr: you might be able to think of a 32 bit pointer as accessing a "low page" of the lowest 2gig addresses
[07:30:33] <moon-child> Alfr: I mean, if all data are pointers, then all data are word-aligned, so you don't need byte addressing
[07:30:54] <gilberth> And: You usually address octets within an object. The object pointer could be word-oriented, while the offset is octet-oriented.
[07:31:16] <dave0> 6502 has the first page of 256 bytes where you could use 1 byte to address it
[07:31:47] <gilberth> dave0: Nah, from what I got, this is your registers.
[07:32:34] <dave0> gilberth: ah okay i never really used 6502 .. i had a 6809 but again it had a "direct page" of 256 bytes that you could adress with a byte
[07:32:50] <gilberth> And with B 'char' was not a datatype, but a function to extract a 6-bit character from a vector of 18-bit words.
[07:33:18] <Alfr> moon-child, I understand that, using it to have an upper bound for the cost. Obviously most programs have other data than pointers as well.
[07:33:21] <gilberth> dave0: I never did either, but this is the impression I got from reading about it.
[07:34:18] <dave0> gilberth: we need B 'char' to extract a 21 bit unicode point from a 64 bit word
[07:34:20] <gilberth> Alfr: For some reason SBCL's image file is twice the size with 64-bit than with 32-bit.
[07:34:45] <Alfr> dave0, only if we could have relative addressing wrt some base ...
[07:34:49] <gilberth> dave0: Yep, but you solder the 64-bit ALU!
[07:35:19] <gilberth> And the barrel shifter.
[07:35:51] <hayley> "When you take into account that objects smaller than 2 words don't make sense, you could address even 32GB." Java compressed OOPs do this.
[07:35:59] <Alfr> gilberth, interesting.
[07:37:03] <gilberth> Alfr: You don't need that. int char (int *s, int i) { return (s[i/3] >> (i%3)*21) & 0x1FFFFF; }
[07:37:20] <gilberth> Assuming 'int' is 64-bit.
[07:37:37] * hayley still wonders what to do.
[07:38:11] <hayley> gilberth: What would you do here? Hack on gencgc some more, make some other GC library parallel, or stomach a Rust dependency and integrate that?
[07:38:43] <gilberth> hayley: I am fine with the GC that I have.
[07:39:17] <Alfr> gilberth, not sure that is cheaper, that'd be something like load + slice and dice you'd have to encode in the instruction stream.
[07:40:12] <hayley> Well, that's great.
[07:41:08] <gilberth> Alfr: I am not advocating to pack 3 chars into a word. It's just that B used to do that. And this was an example that you could address entities smaller than a word. I mean bit vectors in CL exists, although our machines have not pointers addressing a bit.
[07:42:14] <Alfr> gilberth, oh, I somehow was still thinking about general addressing; missed that you're talking about storing unicode, sorry.
[07:42:39] <gilberth> hayley: I can't tell you what to do. I don't know the merits of the algorithms in question and I don't know why SBCL's GC at times expose like 100ms pauses.
[07:43:13] <hayley> Cause it often copies mostly full generations, and they can be pretty large.
[07:44:03] <gilberth> Alfr: Well, pointer arithmetic like in C is not god given. You don't need pointers to an individual element of some vector or structure. What you need is an instruction to load some-sized chunk from some object from some offset in that object.
[07:44:14] <hayley> But generally: continue hacking on my own with the old GC, try to modify another library that someone is already porting, or make SBCL work with a library no one has ported, but is perfect short of having another language dependency?
[07:44:26] <gilberth> * You don't need ...
[07:45:17] <moon-child> I wonder, do cl implementations optimize multidimensional bit vectors?
[07:45:30] <moon-child> NB. http://www.jsoftware.com/pipermail/programming/2021-August/058464.html
[07:45:30] -ixelp- [Jprogramming] Two implementation questions
[07:47:01] <gilberth> And on that note, load and store instructions usually do just that. They all take a base pointer and an offset. x86 even allows to scale the offset by 2, 4, 8. In a word oriented architecture nothing would stop you from interpreting the offset as an octet offset, while the base is word-addressing.
[07:47:24] <moon-child> riscv only permits a constant offset iirc
[07:48:56] <gilberth> moon-child: Still, you get the idea. It's only C that has the notion to forge a byte pointer into the middle of some object. Something which happened, because the PDP-11 had byte-addressing pointers, which were not all to common at that time.
[07:49:51] <moon-child> you don't think it's useful to say  struct { int x; char y; } x; char *y = &x.y  ?
[07:50:14] <gilberth> I don't.
[07:50:40] <gilberth> CL can do without just fine.
[07:51:35] <Alfr> gilberth, what would you propose for the size of the base address part and how many bits for the offset?
[07:51:37] <moon-child> if displaced arrays didn't suck, they might work like that
[07:51:44] <moon-child> weren't you complaining about that a while ago?
[07:52:11] <hayley> gilberth: So I guess you don't spin up a lot of threads which allocate a lot, or you just have a large enough heap to stomach it?
[07:52:19] <gilberth> moon-child: How would displaced arrays change a thing?
[07:52:44] <gilberth> Alfr: Both should be the natural word size, what ever that is.
[07:52:55] <Alfr> gilberth, how does x86 interpret the base address? Words, bytes?
[07:52:56] <moon-child> gilberth: displaced arrays give you:  char a[10]; char b = &a[5]
[07:53:31] <gilberth> moon-child: Nope. Where is the header? That is, the element type and the dimensions?
[07:53:54] <Alfr> gilberth, what would "the natural word size" for x86 and x86-64 be?
[07:54:06] <gilberth> Alfr: The x86 has byte addressing pointers, just like the PDP-11. So the base address is a byte-address.
[07:54:24] <moon-child> sure.  struct { Type t; size_t l; union { char *chars; ... }; } x = {.type = ..., .l = ..., .chars = malloc(10)}, .y = {..., .chars = &x.chars[5]};
[07:54:39] <gilberth> Alfr: 16-bit for real mode, 32-bit for protected mode, or 64-bit for long mode.
[07:55:38] <gilberth> moon-child: If you go this route, add an offset slot.
[07:56:09] <moon-child> now if I want to say (aref a i) I need a.base + a.offset + i.  Vs just a.base + i
[07:57:10] <gilberth> A sufficiently smart compiler(tm) could pull the a.offset summand out of the loop. ;-)
[07:57:25] <moon-child> and if the array is aliased?
[07:57:37] <Alfr> gilberth, so if you want some datum from an object, then you'll have to know the base address of the object and the compiler arranges for the offset? So you'll need two words to address your data?
[07:57:48] <moon-child> indexing is the common operation.  Displacing is the uncommon operation.  So
[07:57:52] <moon-child> make the latter slow, and the former fast
[07:57:55] <gilberth> moon-child: That won't change things? Would it?
[07:58:20] <moon-child> if it is aliased, somebody else could change it, so you have to reload the base/offset
[07:58:22] <Alfr> gilberth, two words, because that's what the cpu needs to know to actually get the data as per your proposal.
[07:58:46] <gilberth> moon-child: Your displaced array hack already would need a compiler allocating the displaced array header into registers.
[08:00:04] <gilberth> moon-child: How would you update your forged pointer in that case? There is no difference it needing to update a "cache" of (base + offset), or base and offset.
[08:01:29] <gilberth> Alfr: Yes, I do. And compilers like gcc actually often turn a loop like while (*s++ = *t++); into for (i = 0; s[i] = t[i]; i++). It's faster.
[08:03:05] <gilberth> And I said, is that an ISA with word-addressing pointers is feasible and would also allow for finer granularity load/store instructions.
[08:03:48] <gilberth> * All I said,
[08:06:44] <Alfr> gilberth, I didn't say it's impossible. Only questioned whether it has an advantage to addressing only bytes (a fixed number of bits).
[08:06:48] <gilberth> And wrt to CL arrays, what I would which for is a kind of TLB for the array header and an AREF instruction.
[08:07:43] <gilberth> Alfr: You could address more RAM with the same word-width. And it would somewhat simplify the HW design.
[08:10:56] *** Joins: semz_ (~semz@user/semz)
[08:11:51] <gilberth> But I am dreaming here. Suppose all a CPU could do in user mode would be to load and store from some object at certain offset and it would know the object's size, you would need to say good bye to buffer overflows.
[08:12:58] <gilberth> Then tag everything to tell pointers from integers apart, and you should be relatively safe.
[08:13:20] *** Quits: semz (~semz@user/semz) (Ping timeout: 250 seconds)
[08:13:27] <ck_> tag, you're it!
[08:14:38] <Alfr> gilberth, not sure we'll run into the out of address space problem with 64-bit pointers in our lifetime ...
[08:14:59] <moon-child> I dunno, nsa records a _lot_ of internet traffic....
[08:15:47] <White_Flame> Alfr: I was considering the various brain simulation projects out there, and just mapping the connections between neurons in the brain would likely blow a 64-bit pointer
[08:16:19] <Alfr> gilberth, what I'm uncomfortable with is that in this model you'll need 2 words and size/destination you actually get your data, instead of 1 word and size/destination.
[08:16:43] <White_Flame> 16 exabytes of storage is quite possible in .gov-scale computer deployments
[08:17:25] <White_Flame> and the whole aggregate of google's storage is certainly larger than that (although not addressed in a single linear space)
[08:18:36] <White_Flame> but yeah, any form of unique handle can't be just a 64-bit number anymore in such things
[08:19:47] <gilberth> Alfr: It doesn't happen often in practice that you keep just a pointer to one object's slot/element.
[08:21:38] <gilberth> Either you address a slot at some fixed position, like with CAR or CDR, then a constant offset in the load instruction will do, or you do sth like SLOT-VALUE, where you compute the offset, but usually gain nothing by remembering a pointer to that slot, as you want to keep the object pointer and/or address other slots too.
[08:24:37] <Alfr> White_Flame, I don't think we even have cpus supporting that much memory at all.
[08:26:08] * gilberth wants a 72-bit machine for tags and immediate double floats.
[08:26:20] <moon-child> only 8 bits of tag?
[08:26:26] <moon-child> dream big!
[08:26:36] <moon-child> 96-bit machine; full type pointer right there
[08:26:48] <Alfr> White_Flame, unless you can build a system with this much ram, you won't care. And handles only have to be unique on that particular system.
[08:27:38] <gilberth> moon-child: How many types do you need?
[08:28:02] <Alfr> gilberth, also want 72-bit arithmetic?
[08:28:29] <Alfr> gilberth, as you want to use some bits for tags, I'm not sure you'll need that.
[08:28:43] <gilberth> Alfr: No. I would be satisfied with 65-bit arithmetic.
[08:28:59] <moon-child> why 65, not 64?
[08:29:28] <gilberth> moon-child: So I could have both signed and unsigned 64-bit fixnums.
[08:29:55] <gilberth> Or rather fixnum = int64_t U uint64_t
[08:29:58] <Alfr> moon-child, you'll only let me define 2^32 different types. :'(
[08:30:25] <gilberth> Alfr: You want word addressing pointers?
[08:32:06] <Alfr> gilberth, no. I still think addressing smaller chunks of memory than a whole word is more useful, be it just to save memory bandwidth.
[08:32:41] <gilberth> How would that save bandwidth?
[08:33:35] <moon-child> could, if you are unaligned
[08:34:35] <gilberth> You mean a packed structure? Like using 5 bytes for an 32-bit int and an 8-bit int?
[08:34:37] <Alfr> gilberth, in case you need smaller chunks than a whole word. Essentially gather and a cooperating memory controller.
[08:35:07] <moon-child> but memory is measured in cache lines
[08:35:11] <gilberth> The memory controller does not care about my ISA.
[08:35:19] <moon-child> which are a good deal bigger than a word
[08:35:40] <gilberth> ^
[08:36:14] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca) (Remote host closed the connection)
[08:36:35] <robin> hayley, what's the rust library you're referring to? (i think wingo mentioned rust in the context of immix, maybe the same thing...)
[08:37:18] <dave0> there's already 512 bit datatypes with AVX-2
[08:37:22] <Alfr> moon-child, that's what we do now. I somehow have the feeling that with the many core processors some workloads will simply be bound by memory throughput.
[08:37:53] <hayley> robin: MMTk, which does indeed implement Immix in Rust.
[08:37:59] <White_Flame> the next epyc is going from 8-channel memory to 12-channel memory, probably because of the increasing core couns
[08:38:12] <gilberth> bandwidth /= latency.
[08:38:29] <White_Flame> but to the point above, 64-bit counters/identifiers/indexes are running out
[08:38:42] <White_Flame> gilberth: latency still hasn't improved all that much anyway
[08:38:42] <moon-child> frequently, single-core bandwidth ‚â† multi-core bandwidth
[08:39:02] <gilberth> White_Flame: yep, what I tried to say.
[08:39:06] <moon-child> more interesting is the potential to eliminate false sharing
[08:39:21] <robin> hayley, ah, ty, didn't know mmtk was rust (having just learned of the 'modern' version today)
[08:39:33] <White_Flame> however, are memory channels locked to run in parallel?  how independent can different areas of RAM be accessed across allt he channels?
[08:39:45] <moon-child> White_Flame: 64-bit probably suffices for a single machine, though.  Then dedicate a tag to a 128-bit uuid sufficient for inter-machine storage
[08:40:10] <Alfr> gilberth, wrt latency you're restricted to 2 d / c_{copper}.
[08:40:52] <White_Flame> moon-child: and yeah, IBM standardized on 128-bit a very long time ago
[08:41:22] <gilberth> Alfr: A transistor still needs 1.25 meters to switch. I believe that is more of an issue.
[08:41:27] <Alfr> gilberth, that's something that I think compilers need to solve by appropriately prefetching things.
[08:41:35] <moon-child> Alfr: what is d?  Some function of diameter?
[08:41:48] <Alfr> moon-child, distance to your memory.
[08:42:25] <moon-child> ah, ok
[08:43:00] *** Quits: lagash (lagash@lagash.shelltalk.net) (Ping timeout: 252 seconds)
[08:43:02] <moon-child> generally memory is organised into semi-uniform banks.  So really it's a function of the distance to the furthest cell in a given bank
[08:43:04] <robin> personally i'd try to determine how hard modernizing mps would be, but i'm biased against having major rust dependencies (at least until there are multiple implementations, and mrustc doesn't count)
[08:43:09] <moon-child> (hence memory hierarchy)
[08:43:26] <gilberth> Alfr: As with the failed VLIW approach, I don't believe that compilers could improve scheduling of what could be done in parallel too much.
[08:43:58] <moon-child> I think they can do much better than they do now
[08:44:27] <moon-child> I think of it like out-of-order ISAs: the work is done in parallel, transparently, not like vliw; but instruction scheduling is still something you need to be aware of and can take advantage of at will
[08:44:42] <gilberth> I still don't believe in that approach. Speculative execution won the race.
[08:44:47] <moon-child> I think there is potential for a similar situation, where compilers automatically parallelise code, but if you are aware of how they do it, you can get much better results
[08:45:19] <moon-child> mind, these are things happening at different levels.  Instruction reordering happens at the uarch level, and compilers (or assembly-writers) are aware of it.  What I propose happens at the compiler level, and users are aware of it
[08:45:45] <Alfr> gilberth, speculative execution also needs the data/instructions to be available.
[08:45:57] *** Joins: lagash (lagash@lagash.shelltalk.net)
[08:46:31] <moon-child> counterpoint: speculative execution will automatically prefetch the data/instructions that you needed anyway
[08:46:56] <White_Flame> the problem with the compiler approach is that it's extremely individual cpu model specific, and we don't compile on the end platform, in terms of the OS model of processes
[08:47:31] <White_Flame> the stupid binary blob model requires us to ship the lowest common denominator compatible blocs
[08:47:58] <gilberth> Another problem is, unless you use PGO, the compiler cannot measure the code, but only guess. The CPU measures what happens, e.g. with branch prediction.
[08:48:09] <White_Flame> different CPUs will have differently sized windows fo parallelism they can support, and you can't tune for them all
[08:48:46] <White_Flame> however, for an individual CPU model, recompiling on site, I certainly think it can work.  the mill cpu is all based on this concept
[08:48:53] <Alfr> moon-child, I was more thinking about, pull data into L1/2 by sacrificing a register or two and using those to issue loads.
[08:48:54] <White_Flame> and their stuff is working in sim
[08:49:17] <moon-child> Alfr: I don't think explicit cache control makes sense
[08:49:18] <Alfr> moon-child, there certainly are cases where it won't work well.
[08:49:31] <gilberth> Which gets me to the "cloud" PGO approach, where different binaries are shipped to different users and the application send profile data back to the vendor.
[08:50:00] <White_Flame> or the distribution is locally compilable and not machine code binaries at all
[08:50:06] <gilberth> And milliions of users, you could invoke a genetic approach.
[08:50:10] <White_Flame> need to escape that ridiculous lock-in of though
[08:50:12] <White_Flame> t
[08:50:33] <White_Flame> machine code should never leave the execution environment, and be generated locally
[08:50:42] <White_Flame> only evil comes from distributing machine code binaries :)
[08:50:45] <moon-child> gilberth: that is what azul does
[08:51:07] <moon-child> I agree with White_Flame though.  And I think local JIT works rather well, at least for now
[08:51:09] <gilberth> moon-child: I should have patented it. :(
[08:51:19] <moon-child> maybe once superoptimization is more viable...
[08:55:42] *** semz_ is now known as semz
[08:56:32] <hayley> robin: My fear is that MPS is no easier than gencgc (but the former was a commercial product, and is very well documented, so they might be saner). And, yes, adding in Rust to the build process will be painful.
[09:30:35] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[09:31:05] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[09:47:20] <hayley> Hm. If I am very lucky, I can keep SBCL Rust-free, and reuse enough of the original C code for parsing object layouts.
[09:50:52] * hayley gets a very, very large number of "can't find blabla in this scope" errors, seemingly all in the regex library...while building a garbage collector. Shit.
[09:52:14] <hayley> Seems all the libraries are incredibly broken.
[09:53:08] <hayley> "can't find crate for `std`" So cargo doesn't actually know how to install standard libraries, but it can install the nightly compiler (which we need for some god-awful reason).
[09:53:49] <hayley> ...this demo creates 32-bit code. But why?
[09:55:07] <moon-child> smaller pointers!
[09:57:28] <hayley> Seems this bench.sh also can't make its mind up on which directory I should run it from.
[09:58:06] *** Joins: shka (~herr@109.231.0.226)
[10:03:32] <hayley> https://github.com/mmtk/mmtk-v8/blob/master/v8/third_party/heap/mmtk/mmtkUpcalls.cc Seems there is a way to get C to do MMTk's biddings w.r.t object layout and threads still.
[10:03:33] -ixelp- mmtk-v8/mmtkUpcalls.cc at master ¬∑ mmtk/mmtk-v8 ¬∑ GitHub
[10:23:47] <hayley> But it appears I at least need a shim of sorts, which will call C functions from Rust. Ouch.
[10:24:13] <shka> hayley: you doing Rust now?
[10:24:26] <shka> why do you hate yourself hayley?
[10:24:29] <hayley> shka: As little as possible to make SBCL use MMTk (maybe).
[10:24:29] <shka> :(
[10:24:56] <shka> what is MMTk?
[10:26:56] * moon-child wishes there was an interactive environment for assembly like lisp
[10:26:57] <hayley> A GC library.
[10:27:03] <moon-child> that would let you swap out, add, and remove individual instructions
[10:27:45] <dave0> oh i saw an assembly-REPL on hackernews
[10:28:13] <dave0> https://news.ycombinator.com/item?id=29385006
[10:28:14] -ixelp- Asmrepl: REPL for x86 Assembly Language | Hacker News
[10:28:23] <dave0> oh i assumed x86
[10:28:50] <moon-child> is it suitable for actually developing stuff though?
[10:29:23] <moon-child> looks like just a curiosity where you can type things in one at a time
[10:29:28] <dave0> sorry don't know, i never tried it
[10:32:38] <shka> yay, still no war on the Ukraine
[10:35:43] <epony> moon-child, we call that a debugger/monitor step through breakpoints https://en.wikipedia.org/wiki/Breakpoint#Implementations
[10:36:13] <ck_> shka: wasn't the last 'leaked' deadline the 16th?
[10:38:37] <shka> ck_: spoilers
[10:39:06] <epony> https://en.wikipedia.org/wiki/Program_animation#Techniques_for_program_animation
[10:42:11] <epony> https://en.wikipedia.org/wiki/In-circuit_emulator#Function
[10:44:13] <epony> https://en.wikipedia.org/wiki/Debugger#Memory_protection
[10:44:58] <epony> you should seek that tooling for programs running in VMs too, if you dare
[10:45:29] * epony predicts epic loss of hope on your end
[10:55:03] <hayley> moon-child: There was a story of someone (Minsky? idk) using a debugger and hacking up a PDP-something program from nothing.
[10:55:53] <hayley> .oO(Great, MMTk support uses Zulip. Now I need n + 1 accounts for everything.)
[11:04:51] <hayley> There also is no conservative stack scanning in MMTk, so neither Clasp nor SBCL (on x86-64 at least) can actually use it. Hooray!
[11:05:50] <moon-child> hmm, it seems my idea of using simd for gcd was a bust
[11:06:06] <moon-child> or at least, it is without avx512 and on random inputs
[11:06:50] <hayley> Well, so much for MMTk (at the moment). Thus, I need to get on Doug Katzman's good side, and figure out what's up with MPS on SBCL. Then get on Ravenbrook's good side, and make MPS parallel.
[11:12:17] <hayley> Are there any GC libraries with decent performance other than Boehm, MPS and MMTk?
[11:12:30] *** Quits: rogersm (~rogersm@90.166.180.250) (Ping timeout: 272 seconds)
[11:20:51] <moon-child> seems I'm dying on gathers
[11:20:53] <moon-child> makes sense
[11:21:01] <moon-child> I need a real tzcnt
[11:21:06] <moon-child> or a scatter to compensate
[11:25:38] <hayley> Well, I cannot prefetch in copying GC, I can't seem to parallelize, can I at least vectorise it?
[11:37:20] <White_Flame> huh, so that link actually is a repl, not a monitor/debugger.  Can't actually assemble a function without issuing literal MOV statements to place the opcodes in memory :)
[11:37:48] <White_Flame> that's pretty funny
[11:38:53] <hayley> Why not DEBUG?
[11:39:05] <White_Flame> it's not a rep
[11:39:06] <White_Flame> l
[11:39:38] <White_Flame> eg, you can't go mov eax,1 and have eax be 1
[11:39:58] <White_Flame> (or whatever teh syntax is, I can only read it, not write it anymore :) )
[11:42:41] <ck_> you could probably do that in TempleOS
[11:43:06] <White_Flame> heh, wouldn't surprise me
[11:43:09] <White_Flame> unless asm is an abomination to HolyC
[11:52:05] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[12:00:24] *** Quits: malaclyps (~mala@user/malaclyps) (Ping timeout: 250 seconds)
[12:02:52] *** Joins: rogersm (~rogersm@90.166.180.250)
[12:04:06] <epony> you're incapable of debugging your own interpreter ;-)
[12:05:52] <mfiano> I've been mulling about a very frustrating problem with my code for 3 days now. Today I took the time to write out the problem in a gist, and a hypothetical solution came to me instantly (also in the gist), which I didn't test until after I finished writing down all my thoughts so I wouldn't forget, and it turned out to be correct!
[12:07:05] <robin> hayley, i'm not aware of any other gc libs, except mmtk wasn't originally in rust (but it was for jikes rvm i think so it might be java??)
[12:08:03] <hayley> Right, Java.
[12:09:40] * robin needs to order jones et al.'s gc handbook
[12:11:34] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[12:12:06] <hayley> I've borrowed the university copy since July.
[12:12:48] <hayley> Found a bug in it last December. But I still can't write a parallel GC. Oh well.
[12:12:51] <robin> fwiw i'm personally interested in modernizing mps, but i have no idea of the difficulty level of adding parallel gc etc. beyond "probably pretty damn difficult"
[12:13:25] <robin> (and will probably have a contract soon that might have that in scope)
[12:14:58] <robin> i think the initial experimentation can be done with non-parallel gc, but parallel gc probably has to be feasible to justify it
[12:15:00] *** Quits: aeth (~aeth@user/aeth) (Ping timeout: 240 seconds)
[12:17:13] *** Joins: aeth (~aeth@user/aeth)
[12:17:20] <robin> (...initial experimentation for ditching bdwgc in guile)
[12:18:51] <hayley> I'm looking for a parallel GC so that I can let 10 threads allocate a lot, without having to use such a huge heap to cut down on GC wall time.
[12:19:45] <mfiano> Good luck. Parallel GC's take many years to get down right.
[12:19:56] <mfiano> where "right" is relative
[12:20:27] <hayley> How encouraging.
[12:20:46] <hayley> Not sure where you got such a figure though.
[12:30:28] <mfiano> It wasn't my intention. Computers are just garbage, ya know? Large teams tuning GC's in the JVM etc over many long attempts for starters. I am assuming you are not a large team.
[12:31:53] <hayley> Making a parallel GC that is fast enough to justify its existence is easier than making a GC that performs the best.
[12:32:00] <hayley> So far, I have failed at the former.
[12:33:06] <mfiano> If you have learned something you have not failed.
[12:35:12] <mfiano> Wasn't there a big thing about parallel GC's being memory hungry and having noticable pause times on the JVM upsetting lots of users? I remember reading about that a couple years ago when some new GC was introduced to try to solve that. Maybe I'm thinking of another platform...
[12:36:28] <hayley> If you have damn big heaps with big live sets, then yes, a stop the world GC will suck. That is how the SBCL GC is treating me.
[12:36:43] <mfiano> Ah yes, ZGC
[12:36:53] <hayley> A parallel GC should not take noticeably much more memory, but a concurrent GC may, because it has to sustain allocation while collecting.
[12:37:04] <mfiano> https://blogs.oracle.com/content/published/api/v1.1/assets/CONT20D9F4DF773B4E13B2445223DD1B7C5C/native?cb=_cache_e505&channelToken=4d6a6a00a153413e9a7a992032379dbf
[12:37:35] <hayley> Meaningless without knowing what they loaded it with, but I guess I can find the article it came from.
[12:37:57] <hayley> https://blogs.oracle.com/javamagazine/post/understanding-the-jdks-new-superfast-garbage-collectors I figure.
[12:37:59] *** Joins: mala (~mala@user/malaclyps)
[12:38:02] <mfiano> Yes
[12:38:49] <hayley> Nice, they don't mention what the workload was at all!
[12:41:58] <kakuhen> how did i find package maintenance enjoyable back then
[12:42:04] <kakuhen> i feel very bored right now
[12:42:35] <kakuhen> but the light at the end of the tunnel is MacPorts' ffmpeg builds supporting japanese subtitles
[13:04:24] <kakuhen> i hate libtool so much
[13:07:28] *** Joins: lisp123 (~lisp123@5.30.23.247)
[13:10:46] *** Quits: scymtym (~user@ip-094-114-248-079.um31.pools.vodafone-ip.de) (Remote host closed the connection)
[13:11:01] *** Joins: scymtym (~user@ip-094-114-248-079.um31.pools.vodafone-ip.de)
[13:12:04] <hayley> Hm, should my response to https://yorickpeterse.com/articles/friendship-ended-with-the-garbage-collector/ be "Friendships Should Not Befriend Their Arguments" or "Friendship is an implementation issue, not a language issue"
[13:12:04] -ixelp- Friendship ended with the garbage collector
[13:12:12] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 240 seconds)
[13:14:04] *** Joins: eugercek (~user@user/eugercek)
[13:16:00] *** Quits: scymtym (~user@ip-094-114-248-079.um31.pools.vodafone-ip.de) (Ping timeout: 272 seconds)
[13:27:58] <shka> meanwhile, in azure https://i.imgflip.com/65a4bx.jpg
[13:28:11] <shka> $5 for database, $250 for the app service
[13:28:16] <shka> wtf is wrong with people xD
[13:32:59] <hayley> https://github.com/mmtk/mmtk-core/tree/rust-g1/src/plan/g1 MMTk also has G1.
[13:33:00] -ixelp- mmtk-core/src/plan/g1 at rust-g1 ¬∑ mmtk/mmtk-core ¬∑ GitHub
[13:34:31] <moon-child> is that the real G1?
[13:34:43] <moon-child> I would think not, but I see 'Move barrier fast path to Java'
[13:36:22] *** Joins: cosimone (~user@93-44-187-99.ip98.fastwebnet.it)
[13:38:56] <hayley> It's the not real G1 from https://users.cecs.anu.edu.au/~steveb/pubs/papers/g1-vee-2020.pdf to my knowledge.
[13:42:26] *** Joins: scymtym (~user@2001:638:504:20e6:6ac3:87e0:e782:f3fc)
[13:57:37] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 240 seconds)
[14:02:57] <kakuhen> ok im finally done, now i just wait for ppl to nitpick my PR and hopefully by this friday it's in
[14:03:35] <kakuhen> once libaribb24 is in macports, I can modify ffmpeg's +gpl3 variant to throw this in, and I can finally rip japanese subtitles without having to use a custom ffmpeg build i stuck in ~/Downloads/ffmpeg
[14:04:18] <kakuhen> all of this sprang out of a really amusing issue with MPV's subtitle handlers
[14:05:03] <kakuhen> in short, VLC is able to call into this library, but MPV doesn't ever attempt to do this, and not a single MPV frontend seems to use an ffmpeg built with this library, so most ppl using MPV will be unable to see ARIB subtitles
[14:05:20] <kakuhen> basically, MPV will recognize that an MPEG-2 TS has a subtitle track, it just won't be able to decode them
[14:05:45] <kakuhen> and trying to convert arib subtitles to text subtitles (i.e. srt) led me down this rabbithole
[14:09:33] <kakuhen> ok my port explicitly depends on autoconf and the macports test thingy is claiming "./bootstrap: line 3: autoreconf: command not found"
[14:09:46] <kakuhen> i'll let someone else figure out what went wrong... too tired for this
[14:14:31] <hayley> https://www.youtube.com/watch?v=5-C88mPG82A
[14:14:31] -ixelp- The Three Fates (i) Clotho ii) Lachesis iii) Atropos) (2012 - Remaster) - YouTube
[14:48:39] *** Joins: random-nick (~random-ni@87.116.167.125)
[14:57:05] <luis> hayley: how did you come across my tweet from mid 2009 about gencgc.c? :D
[14:57:50] <hayley> 1. Magic 2. Bored, searched gencgc and that came up
[14:59:03] <hayley> While you're here, would you guess that parallelising the Memory Pool System would be easier than gencgc, or that plugging in a parallel GC library like MMTk would be easier than parallelising?
[14:59:18] <luis> This was before I had a smartphone, or a kindle, or a tablet. :)
[15:00:43] <luis> I have no experience with either MPS or MMTk, sadly.
[15:02:03] <luis> I probably didn't have a working laptop at that point even.
[15:03:41] <hayley> Fair enough then.
[15:04:20] <hayley> At that time I only had an iBook, one of the clamshell design ones. My mum would use it to basically play Flash games in slow motion, and thus cheese competitions on some online forums.
[15:07:46] <hayley> Steve Blackburn is continuing to be nice, so I am starting to err for the MMTk option. But that means I will probably never get SWCL merged into SBCL again. Oh well.
[15:09:37] *** Joins: lisp123 (~lisp123@5.30.23.247)
[15:14:03] *** Quits: lisp123 (~lisp123@5.30.23.247) (Ping timeout: 252 seconds)
[15:20:30] <selwyn> whats app service
[15:20:55] <shka> selwyn: serverless env on azure
[15:21:12] *** Quits: cosimone (~user@93-44-187-99.ip98.fastwebnet.it) (Ping timeout: 252 seconds)
[15:22:23] *** Joins: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20)
[15:29:33] <ck_> always thought whats app was owned by someone else
[15:48:42] <selwyn> hayley: i used to think i was good at flash games for that reason
[16:01:54] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 252 seconds)
[16:03:56] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[16:04:33] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca)
[16:17:35] *** Joins: Brucio-61 (~Brucio-67@2001:638:504:20e6:6ac3:87e0:e782:f3fc)
[16:21:23] *** Quits: clos-encounters (user@2600:3c00::f03c:92ff:fe19:3350) (Remote host closed the connection)
[16:29:27] *** Joins: notzmv (~zmv@user/notzmv)
[16:42:06] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[17:53:33] *** Quits: random-nick (~random-ni@87.116.167.125) (Ping timeout: 252 seconds)
[18:01:15] *** Quits: Brucio-61 (~Brucio-67@2001:638:504:20e6:6ac3:87e0:e782:f3fc) (Ping timeout: 252 seconds)
[18:05:43] *** Joins: random-nick (~random-ni@87.116.181.150)
[18:09:52] *** Joins: treflip (~user@user/treflip)
[18:11:43] *** Joins: pjb (~pjb@user/pjb)
[18:23:53] *** Quits: scymtym (~user@2001:638:504:20e6:6ac3:87e0:e782:f3fc) (Ping timeout: 250 seconds)
[18:24:12] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 240 seconds)
[18:26:29] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[18:44:38] <selwyn> the scientists use c++ in black mesa
[18:44:47] <selwyn> operator overloading no less
[18:50:31] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca) (Ping timeout: 256 seconds)
[18:51:26] <aeth> this is why we need a gofundme to buy Valve for like idk whatever it's worth 20 bil or so?
[18:51:27] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca)
[18:51:32] <aeth> unite the two lambdas
[18:51:53] <selwyn> well this is from the fan made black mesa game
[18:51:54] <selwyn> but yes
[18:52:40] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca) (Remote host closed the connection)
[18:53:33] <aeth> Black Mesa's nice and I definitely admit that the Xen part is way better than in HL1 (but HL1 Xen is also delightfully retro... nobody would ever dare to make something like that... it plays like experimental Quake 1 levels)
[18:53:55] <aeth> but I don't like how they took the staff (guards, scientists) and made them serious
[18:54:16] <aeth> It's a very big change in tone from the cheesy deaths in HL1
[18:54:41] <selwyn> i think they were motivated by trying to actually be a prequel to hl2
[18:54:50] <selwyn> which is understandable
[18:55:00] <aeth> HL1 was full of very B movie deaths... and, yeah, very different tone from the cinematic HL2
[18:57:05] *** Joins: scymtym (~user@ip-094-114-248-079.um31.pools.vodafone-ip.de)
[18:58:51] *** Joins: kevingal (~quassel@37.228.202.92)
[19:16:36] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 240 seconds)
[19:18:50] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[19:33:18] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca)
[19:36:19] *** Quits: christophergray (~christoph@186.151.40.100) (Quit: WeeChat 3.4)
[20:16:46] <selwyn> gnuxie: prince andrew settles
[20:26:03] <gilberth> Good morning #lispacafe!
[20:26:29] <gilberth> Good start, I lost an "a". :(
[20:27:26] <White_Flame> or gained an italian accent :)
[20:27:44] <gilberth> Terrifico!
[20:35:36] <ck_> you touch-a my lispa and you die
[20:35:55] <ck_> the alternative save-lisp-and-die command
[20:40:30] <selwyn> did the eastern bloc computers have lisp?
[20:41:06] <ck_> selwyn: I attended a talk of a guy who worked on (or towards) a lisp machine in the gdr
[20:41:18] <ck_> they didn't quite make it before it all went away in 89
[20:41:24] <selwyn> i see
[20:46:54] <tyson2> not quite the eastern bloc, but we had four lisp machines at my office in the 80's in Montreal
[20:54:41] *** Joins: serbest (~ike@user/serbest)
[20:57:15] *** Quits: eugercek (~user@user/eugercek) (Ping timeout: 252 seconds)
[20:58:27] <gilberth> It's funny to see how the PS model of specifying regions by pathes is incomplete. While with non-zero winding rule, you can specify the union of regions, you can't specify intersections. When you factor in the clip path, you can have intersections of unions though, but not unions of intersections.
[20:59:30] <gilberth> And you have very limited support for differences depending on the wining rule.
[21:00:30] <gilberth> * winding rule :)
[21:01:01] <Gnuxie> selwyn: settles with public royal family money 
[21:01:45] <ck_> I thought he sold of that military degree
[21:01:56] <ck_> (it's a joke relax)
[21:01:56] <selwyn> north sea oil and gas revenues put to good use
[21:02:14] <selwyn> to any americans here: how likely are we to find out what the settlement is
[21:02:31] <selwyn> how often do they make the amounts public
[21:03:14] <ck_> from my understanding that happens close to never
[21:03:19] <White_Flame> almost never
[21:03:34] <White_Flame> that's not part of the court proceedings, therefore not public record
[21:03:48] <selwyn> ok
[21:03:55] <White_Flame> the only public record thing is dropping a case
[21:03:57] <ck_> isn't it even part of some settlement agreements to keep the details private?
[21:04:04] <White_Flame> yep
[21:29:44] *** Quits: Catie (~user@user/catie) (Remote host closed the connection)
[21:31:51] *** Quits: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20) (Remote host closed the connection)
[21:32:05] *** Joins: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20)
[21:52:01] *** Quits: serbest (~ike@user/serbest) (Quit: Konversation terminated!)
[21:53:20] *** Quits: mzan (~quassel@mail.asterisell.com) (Quit: No Ping reply in 180 seconds.)
[21:54:46] *** Joins: mzan (~quassel@mail.asterisell.com)
[22:03:00] *** Quits: treflip (~user@user/treflip) (Quit: good night)
[22:13:42] *** Joins: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
[22:13:44] <shka> good evening https://www.youtube.com/watch?v=LVhJy-CR64Q
[22:13:45] -ixelp- Peace Sells (Remastered) - YouTube
[22:15:48] <ck_> by the pea shore?
[22:20:35] <selwyn> do tex labels have genuine namespaces?
[22:23:51] <ck_> first time I'm hearing of something like that
[22:24:14] <ck_> I mean the concept of a namespace in tex or latex
[22:28:12] <selwyn> i have many labels like \label{ch1:Wansatz}
[22:28:15] *** Quits: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca) (Remote host closed the connection)
[22:28:42] <selwyn> i don't know whether the : denotes a separation into 'symbol' and 'namespace' or not
[22:29:34] *** Joins: Catie (~user@user/catie)
[22:29:36] <gilberth> You misspelled Wahnsatz?
[22:30:45] <gilberth> [Wahn means mania or delusion.]
[22:34:58] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[22:35:00] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 240 seconds)
[22:35:19] <ck_> selwyn: there is no semantics to any of those characters as far as I'm aware
[22:35:34] <selwyn> gilberth: i am not that good at german lol
[22:35:37] <selwyn> an ansatz for w
[22:35:39] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[22:36:51] <gilberth> selwyn: I found it somewhat funny. A Wahnsatz would be some manic or outright crazy statement or thesis. :)
[22:37:06] <selwyn> i see lol
[22:37:10] <selwyn> well, it currently is that
[22:37:37] <gilberth> But, neither TeX nor LaTeX have any notion of namespaces as far as I know.
[22:37:55] <ck_> is my microphone broken? hello hello breaker breaker
[22:38:11] <selwyn> i can't decide whether tex is great or terrible
[22:38:38] <gilberth> ck_: I can't read you, please repeat.
[22:39:25] <ck_> DAS PFERD FRISST KEINEN GURKENSALAT STOP
[22:41:03] <gilberth> Well, TeX macros work on token sequences and this what you get.
[22:46:19] <ck_> so you're saying there is a singular namespace of what you call "token sequences". a TeX-1 so to speak.
[22:54:26] <epony> lispdecougheid (lisp on jvm, covid19-free o'zone): "~5GC Fph" (abort file garfield correct foracks peer house, no-more than 15 GC-fucks hourly)
[23:09:33] <shka> gilberth: what is the quickest way to check if ray crosses bounding box in 3D space?
[23:12:06] <ck_> ther's a chapter in numerical recipes on this topic
[23:12:11] <ck_> if you're interested
[23:12:20] <shka> i am in a hurry
[23:12:33] <ck_> then test against the boundary planes
[23:12:59] *** Joins: iamFIREcracker (~iamFIREcr@user/iamfirecracker)
[23:13:08] <shka> hmmm
[23:14:45] *** Quits: iamFIREc1 (~iamFIREcr@user/iamfirecracker) (Ping timeout: 252 seconds)
[23:21:54] <ck_> or, if you want a quick way to discard rays, compute distance to the center of the box and compare against half the largest diagonal, for example
[23:22:18] <shka> ck_: hey, that's actually a nice idea, thanks
[23:24:10] *** Joins: tyson2 (~user@bras-base-toroon0624w-grc-17-50-101-91-98.dsl.bell.ca)
[23:29:26] <clothespin> i have an algorithm "ray-intersects-box"
[23:29:45] <mfiano> https://github.com/mfiano/common-lisp/blob/master/math/origin/src/geometry/intersection.lisp
[23:29:46] -ixelp- common-lisp/intersection.lisp at master ¬∑ mfiano/common-lisp ¬∑ GitHub
[23:33:01] <mfiano> or if it's axis aligned and you need the point of intersection: 
[23:33:04] <mfiano> https://github.com/mfiano/common-lisp/blob/master/math/origin/src/geometry/raycast.lisp
[23:33:05] -ixelp- common-lisp/raycast.lisp at master ¬∑ mfiano/common-lisp ¬∑ GitHub
[23:33:23] <mfiano> night!
[23:41:47] *** Quits: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se) (Ping timeout: 256 seconds)
[23:42:25] <shka> mfiano: awesome, thanks
[23:44:42] *** Quits: minion (~minion@common-lisp.net) (Read error: Connection reset by peer)
[23:46:06] *** Joins: minion (~minion@common-lisp.net)
[23:46:18] <selwyn> i have an algorithm that does that (no common lisp implementation though)
[23:47:33] *** Quits: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20) (Remote host closed the connection)
[23:47:46] *** Joins: cosimone (~user@2001:b07:ae5:db26:c24a:d20:4d91:1e20)
[23:49:19] <selwyn> sorry, it was for intersection of a plane with a box
[23:54:08] *** Joins: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
