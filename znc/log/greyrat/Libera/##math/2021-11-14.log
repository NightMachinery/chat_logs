[00:01:28] *** Joins: jan1 (~jan@user/jan1)
[00:02:20] <jan1> I'm currently reading a proof that the composition of inverse function is the identity function and there is a part in the proof that I don't understand.
[00:02:38] <jan1> let Z = f^-1(f(x))
[00:02:52] <jan1> by definition of inverse function:
[00:02:56] <jan1> f(z) = f(x)
[00:03:03] <jan1> why is this true?
[00:03:28] <laurus> Z: is f^{-1} the inverse image or the inverse of the function?
[00:04:03] <jan1> the inverse of the function f (sorry for the bad notation)
[00:04:22] *** Joins: bosspotato_ (~bosspotat@lnsm2-montreal02-142-118-210-99.internet.virginmobile.ca)
[00:04:22] *** Quits: bosspotato_ (~bosspotat@lnsm2-montreal02-142-118-210-99.internet.virginmobile.ca) (Changing host)
[00:04:22] *** Joins: bosspotato_ (~bosspotat@user/bosspotato)
[00:04:26] <tolarz> give the def. of inverse function
[00:04:33] <laurus> jan1: So if we assume that f is invertible, then the composition of the inverse of f with f itself would give back the original element x, right?
[00:04:36] <tolarz> also the proof looks needlessly complicated
[00:04:52] <tolarz> laurus: no, "... the composition ... [APPLIED TO x]"
[00:05:05] <laurus> tolarz: That's what I meant
[00:05:09] <laurus> Sorry for unclearness
[00:05:19] <jan1> laurus: yes
[00:05:31] *** Quits: Guest57 (~Guest57@8bd8-8d0c-340c-4937-4880-8a0d-07d0-2001.dyn.estpak.ee) (Quit: Client closed)
[00:05:34] <jan1> let me rephrase it
[00:05:40] <laurus> jan1: So I'm pointing out the same thing as tolarz, that this looks a bit overcomplicated, I'm not sure what the purpose of Z is here.
[00:05:46] <jan1> let g be the inverse of the function f
[00:05:48] <Decker> x=arcsin(sin(x))
[00:05:54] <jan1> let z = g(f(x))
[00:06:05] *** Quits: BlueSky_ (~BlueSky@user/bluesky) (Quit: Leaving)
[00:06:10] <jan1> then by definition of inverse function: f(z) = f(x)
[00:06:17] <laurus> jan1: But z must be x by our reasoning just now
[00:06:26] *** Quits: chomwitt (~chomwitt@2a02:587:dc12:3f00:12c3:7bff:fe6d:d374) (Read error: Connection reset by peer)
[00:06:33] <int-e> Apparently we have some definition for f^-1(y). We need to know what that is to make progress.
[00:06:38] <jan1> yeah then the book proceeds to show that z = x and therefore g(f(x)) = x
[00:06:55] <laurus> jan1: I think perhaps it is talking about the inverse image of f rather than the inverse of f
[00:07:22] <laurus> g being the inverse function and f^{-1} being the inverse image
[00:07:55] <int-e> Maybe it uses the Hilber epsilon operator: f^-1(y) = \epsilon x. f(x) = y.
[00:08:18] <tolarz> lol
[00:08:23] <int-e> Then you actually end up with a proof like the above, arguing that x exists and is unique...
[00:08:27] *** Quits: bosspotato (~bosspotat@user/bosspotato) (Ping timeout: 256 seconds)
[00:08:30] <int-e> *Hilbert
[00:08:39] <tolarz> Herbert Grönemeyer
[00:08:47] <int-e> tolarz: Isabelle/HOL actually does that if I remember correctly.
[00:09:08] <int-e> tolarz: But I'm really mostly supporting the idea that we need to know what the actual definition being used is.
[00:09:09] <W> lpapp, also, that code is terrible; once line 18 starts being executed, the while condition will always be false, and there's no reason to append to heavy only for it to be immediately popped in the next loop iteration, it only obscures the runtime analysis. See a slight refactor: https://privatebin.net/?d5058159b666eae8#3LuzjkHrStHiD18nin4ktLBkVcJQ58ggQLKwnWL6yfXp
[00:09:19] *** Parts: laurus (~laurus@user/laurus) (Part)
[00:09:40] <int-e> (or trying to support it :P)
[00:09:53] <tolarz> well, are there any other possible definitions of inverse functions?
[00:09:58] <tolarz> i.e., concrete ones?
[00:10:20] <tolarz> maybe in ZF you could simply define f⁻¹ = {(y,x) | (x,y) ∈ f}?
[00:10:41] <mycroftiv> im trying to get a bit more context on 4d topology, https://en.wikipedia.org/wiki/Intersection_form_of_a_4-manifold is really important but im a bit lost, is there a less technical concept/intuition for what this is about?
[00:11:03] <int-e> tolarz: Yeah, that's an alternative.
[00:11:06] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 260 seconds)
[00:11:57] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[00:11:57] *** Quits: texasmusicinstru (~Rheanna@218.78.99.237) (Remote host closed the connection)
[00:12:07] <Z-module> This is easy, but I find it sort of pretty:  Let f:X -> Y be any function, and let f` denote inverse image. Then:  [forall W \subset Y, (as cardinalities)   |f`(W)| >= |W| ]  iff   f is surjective; and    [ forall W \subset Y,  |f`(W)| <= |W| ]   iff   f is injective.
[00:12:35] <int-e> tolarz: there's also the tweak where instead of \epsilon x. f^-1(y) = x, you also assert uniqueness, \epsilon x. f(x) = y \land \forall x'. (f(x') = y \implies x = x')
[00:12:38] *** Quits: [-_-] (~fractal@user/---/x-1675478) (Quit: ;3)
[00:13:21] <tolarz> hmhmh
[00:13:23] <tolarz> what am i doing
[00:13:30] <int-e> which has nicer properties (it really works without choice)
[00:13:33] <tolarz> my latex plugin renders this insanely wrong
[00:13:37] *** Joins: texasmusicinstru (~Rheanna@61.171.38.68)
[00:15:33] <tolarz> Patient says: "Doctor, I am scared of being injective."
[00:15:39] <Z-module> heh
[00:15:48] * int-e stabs tolarz
[00:17:28] * tolarz bleeds
[00:18:56] <tolarz> bekomme ich nun eine wundnaht?
[00:18:58] <tolarz> ...
[00:19:16] *** Quits: bosspotato_ (~bosspotat@user/bosspotato) (Read error: Connection reset by peer)
[00:19:24] *** Quits: gxt (~gxt@gateway/tor-sasl/gxt) (Remote host closed the connection)
[00:19:34] *** Joins: bosspotato_ (~bosspotat@lnsm2-montreal02-142-118-210-99.internet.virginmobile.ca)
[00:19:34] *** Quits: bosspotato_ (~bosspotat@lnsm2-montreal02-142-118-210-99.internet.virginmobile.ca) (Changing host)
[00:19:34] *** Joins: bosspotato_ (~bosspotat@user/bosspotato)
[00:19:52] <Z-module> Does that mean a bandage?
[00:19:54] *** Joins: gxt (~gxt@gateway/tor-sasl/gxt)
[00:20:14] *** Joins: random-jellyfish (~random-je@user/random-jellyfish)
[00:20:21] <lpapp> W: thanks for sharing. I guess they tried to minimise the code.
[00:20:26] <lpapp> I have seen this often in CP.
[00:20:47] *** Joins: kmh (~kmh@2a00:6020:5004:6800:11b9:b8b:ca08:bfc9)
[00:21:06] <mycroftiv> whitney disc, casson handle, whitehead continuum, alexander horned sphere/gored ball,  bing-whitehead link, capped grope skyscraper, clifford tori obtained dual sphere factory - i want a 4d lego kit of all these objects
[00:21:14] <tolarz> Z-module: no, wound suture
[00:21:28] *** Joins: nehsou^ (~nehsou@h50.174.139.63.static.ip.windstream.net)
[00:21:44] <tolarz> fun fact: local anesthesia injected into toe is very painful.
[00:24:30] *** Joins: newpy (~newpy@206.168.231.90)
[00:25:01] *** Joins: X-Scale` (~ARM@165.201.137.78.rev.vodafone.pt)
[00:26:58] <Z-module> I guess "stitches" is the common term for that, tolarz
[00:27:26] *** Quits: X-Scale (~ARM@46.50.4.208) (Ping timeout: 260 seconds)
[00:27:48] <dauggy> Hi Folks!
[00:27:52] <Z-module> Don't forget a Warsaw Circle in there, mycroftiv
[00:28:02] <tolarz> yeah i guess stitches is the most commonly occurring special case
[00:28:17] <dauggy>  I got an M-estimator defined here http://mathb.in/67447
[00:28:38] *** X-Scale` is now known as X-Scale
[00:28:39] <dauggy> I need to show that it it location invariant, as specified in the pastebin
[00:28:50] <dauggy> I tried setting the derivative to 0, but it didn't quite worked. Could you please tell me how to do it?
[00:30:38] <dauggy> work*
[00:31:23] <tolarz> Accept the sovereignty of the derivative not wanting to zeroed!
[00:31:29] <tolarz> Accept the sovereignty of the derivative not wanting to be zeroed!
[00:31:34] <tusko> ^
[00:32:06] <tolarz> See, exp(x) grew from a zero to having a positive-only mindset.
[00:32:48] <dauggy> alright, the thing is, I only know that m is a real-valued function :(
[00:32:51] <mycroftiv> z-module: what a painful object, im glad it isnt also in the box of spaghetti pieces that have to be glued together and/or shrunk away in this Freedman disc embedding / handle homeomorphism proof
[00:33:04] <dauggy> I can't even assumeit is differantiable
[00:33:24] <dauggy> would be very thankful for any hints
[00:33:25] <tusko> dauggy's ur vibration is so low right now
[00:33:39] <W> lpapp, compare https://privatebin.net/?f6b6b52fd100d973#6GUJgH2Zn41mPf2yWywfz8NPrr3Au1XkXVrGBys9eEih - same algorithm, written for brevity, clarity, consistency of code.
[00:33:49] <dauggy> tusko: mhm?
[00:33:51] <tolarz> surely, without more assumptions on m, this won't work dauggy
[00:34:01] *** Joins: kish` (~aqua@user/aqua)
[00:34:29] <dauggy> I only know that m is real :(
[00:35:12] <Z-module> mycroftiv: well, it's neat in that it's "kinda sorta" like a circle, except that every continuous self-map on it has a fixed point.
[00:35:31] *** Quits: ysftaha (~ysftaha@d24-57-234-201.home.cgocable.net) (Quit: Lost terminal)
[00:36:22] <mycroftiv> i would totally have guessed wrong that it was impossible for anything homotopic to circle to have that property
[00:36:23] *** Quits: Panther (Lord@2601:18a:c000:5290:a0eb:f206:8e4d:9873) (Ping timeout: 264 seconds)
[00:36:28] *** Joins: HellCat (Lord@c-73-38-66-27.hsd1.ct.comcast.net)
[00:37:51] *** Quits: src (~src@user/src) (Quit: Leaving)
[00:38:00] *** Joins: dude12312414 (~test@gateway/tor-sasl/dude12312414)
[00:38:09] <joel135> today i realized that opengl fragment shaders are pretty similar to algebraic geometry
[00:39:02] <joel135> you evoke a shape by evaluating the same function in different places, independently
[00:41:27] <joel135> this completes the idea that svg images (by contrast) are like euclidean geometry
[00:42:11] *** Quits: sazawal (~sazawal@122.161.85.123) (Ping timeout: 245 seconds)
[00:42:49] *** Joins: llorllale (~llorllale@2607:9880:3a18:69:81d:9fc:80cc:9e91)
[00:42:50] *** Quits: darkapex (~darkapex@user/darkapex) (Ping timeout: 260 seconds)
[00:45:57] *** Joins: sokan (~sokan@85.73.228.233)
[00:46:12] *** Joins: emerent_ (~quassel@p200300cd57430969ba27ebfffed28a59.dip0.t-ipconnect.de)
[00:46:12] *** Quits: emerent (~quassel@p200300cd574309b6ba27ebfffed28a59.dip0.t-ipconnect.de) (Ping timeout: 268 seconds)
[00:46:13] *** emerent_ is now known as emerent
[00:46:14] <sokan> Can anyone please help me with this exercise? I have no idea where to begin... https://dpaste.com/4KA7NVSLV
[00:47:45] <int-e> well you'll need a distribution for the present values
[00:48:07] *** Quits: Pickchea (~private@user/pickchea) (Ping timeout: 256 seconds)
[00:49:18] <sokan> int-e: you refer to me?
[00:49:24] <int-e> sokan: yes.
[00:49:50] <sokan> how did you figure it out? :S
[00:50:19] <int-e> I didn't. The problem is underspecified. I mean we can make things up to fill the gaps.
[00:50:36] <int-e> Say, present values are independent uniform real values in [0,500].
[00:50:49] <int-e> But it should be *stated* as part of the problem.
[00:51:39] <int-e> It could also be integers. (Or integer amounts of pennies.)
[00:52:03] *** Quits: jan1 (~jan@user/jan1) (Quit: WeeChat 3.0.1)
[00:52:09] <int-e> And of course the assumption that the prices are uniform is ridiculous.
[00:54:10] <int-e> Anyway, with the former you can either set up some relatively simple double integrals, or draw some areas inside 500x500 squares.
[00:57:11] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 256 seconds)
[00:57:53] *** Joins: droid3 (~fffd@071-010-228-178.res.spectrum.com)
[00:58:43] <droid3> hey does anybody know if by newtons method if you can determine the number of decimal digits that the accuracy is to.
[00:59:15] <droid3> For example say you want to compute a root out to 1000 decimal places then how many iterations would you have to perform???
[00:59:46] *** Quits: sleeping_papaya (~sleeping_@2600:1006:b106:177e:c1fa:168:b44d:dcf6) (Ping timeout: 268 seconds)
[00:59:56] <droid3> I know how to proof quadratic convergence of newtons method. But this only gives you a relation to the error terms of the iteration
[01:00:32] <droid3> I dont see how one can go from knowing en , en+1 ...etc to knowing how many decimal places the exact zero would be.
[01:01:27] <droid3> Though from knowing it converges quadratically for the error term most things converge really really fast
[01:01:27] *** Quits: texasmusicinstru (~Rheanna@61.171.38.68) (Remote host closed the connection)
[01:01:37] <droid3> faster then most other iteration algorithms
[01:01:47] *** Joins: X-Scale` (~ARM@83.223.243.66)
[01:02:29] <droid3> But i still not sure how many iteration to get an exact number of decimal digits out to.
[01:03:18] *** Quits: X-Scale` (~ARM@83.223.243.66) (Excess Flood)
[01:03:22] *** Quits: X-Scale (~ARM@165.201.137.78.rev.vodafone.pt) (Ping timeout: 260 seconds)
[01:03:38] *** Joins: texasmusicinstru (~Rheanna@61.171.38.68)
[01:05:46] *** Joins: X-Scale (~ARM@83.223.243.66)
[01:06:17] <Decker> droid3 log2(10^1000) each iteration is ^2 , so your 'digit's goes by 1/2... or you get one more bit each time...
[01:06:48] <Decker> so like 3.1 something iterations per base10 digit
[01:07:24] *** Quits: Trigo (~NeedMathH@64.201.115.44) (Ping timeout: 256 seconds)
[01:08:36] *** Quits: arseniiv (~arseniiv@94.41.2.66.dynamic.ufanet.ru) (Read error: Connection reset by peer)
[01:08:41] <droid3> can you elaborate on that
[01:09:02] <Decker> hmm
[01:09:30] *** Joins: arseniiv (~arseniiv@94.41.2.66.dynamic.ufanet.ru)
[01:10:05] <Decker> hm  https://math.stackexchange.com/questions/558145/minimum-number-of-iterations-in-newtons-method-to-find-a-square-root  droid3 maybe it's faster than I think
[01:10:10] <droid3> i suppose if en+1 = |exact root - xn+1| then i just stop iterating when i get en+1 < 1/10^8 if i wanted 8 decimal places of precision
[01:11:15] <droid3> however the problem is i dont know how to compute the |exact root - xn+1| in the first place Decker
[01:11:25] <Decker> log2(b+1)−1.35    for 2^-b accuracy
[01:11:28] <Decker> I wasn't so wrong :)
[01:11:39] <droid3> because to do that you need to know the exact root to compute that difference
[01:12:22] <droid3> For example say one wanted to compute the square root of 2 how many iteration would you need to get a million decimal places of accuracy?
[01:12:43] *** Quits: wootz (~wootz@91.196.220.102) (Ping timeout: 268 seconds)
[01:12:44] <Decker> log2(1M)*3 -ish
[01:13:22] <droid3> how are you coming up with that can you elaborate how you got these result...
[01:14:03] <Decker> Looking carefully, we see that the number of accurate digits approximately doubles on each
[01:14:03] <Decker> iteration. T  https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf
[01:14:20] <droid3> and i dont need ish i need to know the exact number of iterations to get exact number of correct decimal digits to.
[01:15:10] <Decker> well it's easier without the base10 conversion :)
[01:16:09] <Decker> if each iteratoin doubles the precision... then the log(2) of the digits you want is how many iterations...
[01:16:17] <Decker> 1 2 4 8 16...
[01:16:45] <droid3> well en+1 = M * en^2 so if M can be neglected then if en= 1/10^5 say. en+1 = approximately 1/10^10 which is doubling the number of digits like you said from 5 0.00001 to 10 0.0000000001 places
[01:17:20] <droid3> The M makes it an approximate doubling not an exact doubling where M = f'' /2 f'
[01:18:34] <droid3> ok ya makes since the log 2 of the number of digits Decker but your assuming M is like = 1 or nelectable
[01:18:44] *** Quits: trbp (~trbp@user/trbp) ()
[01:18:49] <PlanckWalk> You can determine upper bounds on error, but not the exact error.
[01:19:01] <Decker> yes - the mathexchange had a coorection of ~1.35
[01:19:08] <droid3> So its not exactly a doubling unless M = 1
[01:19:10] <PlanckWalk> (If you could determine the exact error, you coudl subtract it to get the exact result)
[01:20:09] <droid3> i understand that but so log 2 of the number of digits is not going to give you the exact number of iteration to get the exact doubling of the digits
[01:20:31] <PlanckWalk> Correct, it won't always be exact
[01:21:01] <droid3> Or another words if i provide a function that allows the user to input the number of digit precision he want how do i know how many iteration to loop thru to achieve this without guessing or approximating with log ...
[01:21:10] <PlanckWalk> Sometimes you might get the desired accuracy with fewer.
[01:21:24] <PlanckWalk> You'll never need more.
[01:21:25] <Decker> well you have a reasonable max/target
[01:22:20] <droid3> Decker what is the safe amount of iterations to over approximate there precision so they get at least the number of digit precision they entered in?
[01:22:32] <Decker> so ya know like 1k is only 10 and 1M is only 20
[01:22:39] <PlanckWalk> The formula in the SE answer gives that
[01:22:53] <PlanckWalk> (I think, on a cursory glance)
[01:24:03] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[01:24:34] <PlanckWalk> It looks like the only approximation there is in the last step simplifying the log
[01:24:47] *** Joins: kk (~kk@cpeac202e0695f3-cmac202e0695f0.cpe.net.cable.rogers.com)
[01:24:52] <PlanckWalk> I'd have to check whether that approximation preserves an upper bound
[01:25:42] <Decker> you could just keep going until n-n%(1e-digits) is the same value
[01:26:39] <droid3> if we know number of accurate digits approximately doubles on each . Then if a person want 1000 digit precision i can set the iterations to log2(1000) +1 this should be enough to over approximate the amount of precision they want.
[01:27:08] *** Joins: oxum (~oxum@122.172.47.114)
[01:27:09] <PlanckWalk> It looks like no, that simplifed log formula will sometimes underestimate by 1
[01:27:14] *** Joins: Trigo (~NeedMathH@64.201.115.44)
[01:27:22] <droid3> ya thats what i was worried about
[01:27:44] <droid3> the M = f'' /2f' in the quadratic en+1 approximation
[01:28:00] <droid3> if M = 1 we be fine to use the log iteration formula
[01:28:04] *** Joins: Pickchea (~private@user/pickchea)
[01:28:26] *** Joins: sleeping_papaya (~sleeping_@193.27.12.148)
[01:28:38] <PlanckWalk> I'm referring to the exact formula there for the square root iteration, not generally to Newton-Raphson iteration
[01:28:42] <droid3> but as you said PlanckWalk it can underestimate so is there away to always overestimate the underestimate enough to guarentee that its at least there digit precision
[01:28:47] <droid3> or greater
[01:28:52] <kk> why the dimension of the solution space coincides with the geometric multiplicity of eigenvalue?
[01:29:10] <PlanckWalk> kk: That's the definition
[01:29:28] <droid3> O i was refering to the Newton-Raphson iteration
[01:29:28] *** Quits: Pickchea (~private@user/pickchea) (Remote host closed the connection)
[01:30:03] <PlanckWalk> I mean sure, you can work it out in general for N-R and get an upper bound, but it will probably be looser.
[01:30:38] <droid3> so in that case log2(1000) + 1 should give 2000 decimal digits so if they ask for 1000 there definitely a 1000 accurate
[01:30:56] <Decker> +1.35
[01:30:58] <droid3> the thing is there getting much more if they didnt truncate to 1000
[01:31:06] *** Quits: torbjornsd (~torbjorns@213.158.42.177) (Read error: No route to host)
[01:31:29] <PlanckWalk> Well, log_2(2^(b+1) + 1) <= log_2(2^(b+2)) = b+2, so that deals with the first term
[01:31:49] <droid3> but ok ya thanks for your guys help. All use that log formula doubling digits fact to determine number of iterations to the amount of precision i need.
[01:31:53] *** Quits: Vornicus (~Vornicus@2603-8000-5d07-7ef0-3810-8d9c-60b4-f506.res6.spectrum.com) (Read error: Connection reset by peer)
[01:32:11] *** Quits: oxum (~oxum@122.172.47.114) (Ping timeout: 264 seconds)
[01:32:36] <Decker> I'd assume the .35 is related the scalar from base 10 to 2; because it's not binary digits, it's decimal but digits scale linearly
[01:33:01] <PlanckWalk> log_2(log_2((sqrt(2)+1)/(sqrt(2)-1))) ~= 1.35
[01:33:09] <droid3> There is one other addition issue is the initial start value one choose but i dont think it has much significants after the first few iterations.
[01:33:11] <PlanckWalk> So no, nothing to do with decimal there.
[01:33:24] <droid3> provide your in a convergent region
[01:33:28] *** Quits: kk (~kk@cpeac202e0695f3-cmac202e0695f0.cpe.net.cable.rogers.com) (Quit: Client closed)
[01:33:30] <droid3> to that root
[01:34:01] <PlanckWalk> droid3: That formula in the answer requires that you start with the power of two closest to the true square root
[01:34:08] <Decker> you could have a minimum delta before you start counting decimals
[01:34:08] <droid3> but i could be wrong in any case it seems the initial value if its in a convergence region for the root will not affect the iteration amount all that much.
[01:34:12] <PlanckWalk> (Which is trivial to determine in binary representation)
[01:34:43] <PlanckWalk> The later formula in the answer deals with starting with some fixed starting value
[01:35:47] <droid3> so if you where doing sqrt(3) the initial value should be 2 or 4?
[01:35:55] <PlanckWalk> Oh I see now, the exact formula there has a typo
[01:36:06] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Read error: Connection reset by peer)
[01:36:07] <PlanckWalk> droid3: It should be 2
[01:37:19] <PlanckWalk> In practice you won't really get the *exact* cutoff correct, so the initial error is slightly higher than a factor of sqrt(2) but that get handled by the rounding of the constant in the formula
[01:37:33] <droid3> so its always the floor( sqrt(n) ) to start the initial guess
[01:38:22] <droid3> either way if one picks a random guess value that will converge to the root (assuming it converges to that root ...etc )
[01:38:29] <PlanckWalk> In a binary floating point representation you have the input in the form  a * 2^b  for integer b and 1 <= a < 2
[01:38:42] <droid3> then how does the random choice affect the digit precision on iterations?
[01:38:44] <PlanckWalk> N-R for square root always converges
[01:38:50] *** Quits: deltab (~deltab@user/deltab) (Ping timeout: 260 seconds)
[01:39:19] <droid3> right for that simple function x^n - c
[01:39:20] <PlanckWalk> If b is even, the the true square root is  sqrt(a) * 2^(b/2)
[01:40:00] <droid3> but my question is choosing a random initial guess how much underestimate or overestimate will it give you in the doubling of error digits
[01:40:04] <PlanckWalk> You know that  1 <= sqrt(a) < sqrt(2)
[01:40:35] <PlanckWalk> So if b is even, 1 * 2^(b/2)  will always be the closest power of 2 to the true square root
[01:40:41] <droid3> to me it seems only  a couple iterations more.
[01:40:51] *** Joins: krupp (~svarten@m37-2-104-243.cust.tele2.se)
[01:41:00] <PlanckWalk> droid3: If you choose some fixed starting point, it can take arbitrarily many more iterations
[01:42:01] <droid3> or it can not even converge at all or to the proper root even yup i get you on that one PlanckWalk
[01:42:07] <PlanckWalk> Long-range convergence is linear, only bounded short-range convergence is quadratic.
[01:42:16] <PlanckWalk> No, it *always* converges
[01:42:19] *** Quits: Maturion (~Maturion@p200300ede72bd100580e6e7af78de52b.dip0.t-ipconnect.de) (Ping timeout: 268 seconds)
[01:42:21] <droid3> so then how does one always choose the best initial guess for a given function
[01:42:32] <PlanckWalk> Oh, you're talking about general N-R now?
[01:42:39] <droid3> to get the best start off convergence for the iteration loop error approximation
[01:42:46] <PlanckWalk> In general, you do a crapload of messy math.
[01:42:50] *** Quits: econo (uid147250@user/econo) (Quit: Connection closed for inactivity)
[01:43:01] <PlanckWalk> Which will be different for every function you have.
[01:43:38] <droid3> ok so then going back to the simple nthroot approximation with newtons method aka a function x^n - c
[01:43:51] <droid3> we know it always converges
[01:44:14] <PlanckWalk> Yes, that one does
[01:44:32] <droid3> but how do we know the affects and best values to choose for the initial start off value x0 to get the fastest number of decimal digits
[01:44:41] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 245 seconds)
[01:44:46] <PlanckWalk> It's always a trade off, there's no single "best"
[01:45:01] <PlanckWalk> Well, obviously the best starting point is the correct result.
[01:45:07] <PlanckWalk> But you don't know what that is :-p
[01:45:32] <droid3> like how many iteration would i need to get to a 1000 decimal digit accuracy if i started off at x0=2 or x0=4 or x0=-100000
[01:45:34] <PlanckWalk> In practice you need to find some range in which you can get a good rate of convergence
[01:45:46] <PlanckWalk> droid3: It depends upon c
[01:45:52] <PlanckWalk> You don't start with a fixed point
[01:45:59] <PlanckWalk> Welllll, you *can*, butit's dumb
[01:46:19] <PlanckWalk> Because you give up the nice guarantees that you get from Newton's method for this function.
[01:46:43] <droid3> so then for a function like x^n -c i should always choose the integer value closes to nthroot(c)
[01:46:47] <int-e> for the squre root you can multiply by a power of 4 to get inside [1/2,2] and then fit a small degree polynomial to the square root in this range for the starting value
[01:47:28] <droid3> then if a user inputs i want 1000 digit of precision i can do log2(1000) iterations and return the result.
[01:47:51] <droid3> meant log2(1000)+1 iterations sorry
[01:48:04] <PlanckWalk> droid3: Only if you choose your starting value correctly
[01:49:01] <PlanckWalk> You can't just say "if I start with x0 = 2 then I can always do log_2(1000) iterations and get 1000 bits correct"
[01:49:01] *** Joins: Pi-sistance (~kvirc@cpc94050-newt37-2-0-cust176.19-3.cable.virginm.net)
[01:49:10] <droid3> because this doubling of decimal digits applies to any newton root approximation provide i choose my start value correct to optimize this.
[01:49:23] *** Quits: daoudr (~daoudr@xdsl-31-164-222-159.adslplus.ch) (Quit: Leaving)
[01:49:26] <PlanckWalk> Not any, just well-behaved functions
[01:49:48] <PlanckWalk> Formtunately x^n - c is well-behaved in this sense
[01:49:53] *** Quits: sleeping_papaya (~sleeping_@193.27.12.148) (Ping timeout: 256 seconds)
[01:49:55] *** Joins: deltab (~deltab@user/deltab)
[01:50:02] <int-e> except when c = 0
[01:50:26] <PlanckWalk> True.  Or c < 0 with n even :-p
[01:50:31] *** Joins: qu4nt1n (~qu4nt1n@78.198.214.34)
[01:50:55] <PlanckWalk> But those are trivial to check before doing any iterations
[01:51:23] *** Quits: texasmusicinstru (~Rheanna@61.171.38.68) (Remote host closed the connection)
[01:51:27] <droid3> ya or any function that satisfies a nice property of M = -f'' /2f' and (exact - xn)^2 is always nice
[01:51:59] <Pi-sistance> the imaginary part of (L/wc)*e^i(wt-pi/2) should equal (Li/wc)*e^(iwt) right? My book says it is the negative part of that.
[01:52:27] <PlanckWalk> e^(-pi/2 i) = -i
[01:52:47] <Pi-sistance> we have -i in the denominator, *i/i and we end up with a postive i in the numerator
[01:53:01] <Pi-sistance> yeah but the i is in the denominator
[01:53:17] <PlanckWalk> Where is it in the denominator?
[01:53:47] *** Joins: texasmusicinstru (~Rheanna@101.91.232.166)
[01:53:50] <Pi-sistance> e^(x+y) means e^x * e^y, so minus means its divided surelyy
[01:54:06] <PlanckWalk> Also, it doesn't make sense to say that "the imaginary part of (whatever) is (some general complex expression)
[01:54:19] <droid3> yup so i guess if i can always find x0 such that |exact root - x0| < 1/10 and M behaves nice like just |M| = 1 or |M| < 1 then that log2(1000) + 1 gives the number of iteration for at least a 1000 digit accuracy
[01:54:21] *** Joins: sazawal (~sazawal@122.161.93.207)
[01:54:23] <PlanckWalk> (Li/wc)*e^(iwt)  can take any complex value.
[01:54:34] <Pi-sistance> PlanckWalk:  I was very uncomfortable with it, my book just stated it that way
[01:55:04] <droid3> in the case of x^n -c other then those special case where c=0 or c<1 it will always be the case
[01:55:18] <PlanckWalk> droid3: You won't in general find |exact root - x0| < 1/10
[01:55:27] <PlanckWalk> But fortunately you don't need to
[01:56:07] <droid3> ya i know in general i wont find it. And if |M| < 1 in most case i wont need to.
[01:57:04] <PlanckWalk> x^n - c  is scale-invariant in the sense that dividing x by 2^k and c by 2^(nk) yields the same behaviour.
[01:57:10] <droid3> But having 1/10 then doubling on each iteration gives 1/100 , 1/10000 , ...etc meaning 2 , 4 ... decimal digits of accuracy.
[01:57:37] <droid3> so a means to know how many iteration to get how many decimal digits of accuracy. is what i was getting at if i had 1/10
[01:57:40] <PlanckWalk> droid3: You usually want significant digits, rather than digits after the decimal point.
[01:58:31] <Pi-sistance> doh, if the i is in the denominator then it loses the negative ffs
[01:58:40] *** kish` is now known as ayahuasca
[01:59:00] <PlanckWalk> Pi-sistance: (L/wc)*e^i(wt-pi/2) = (L/wc)*e^(iwt)*e^(-pi/2) = (L/wc)*e^(iwt)*(-i) = -(Li/wc)*e^(iwt)
[01:59:27] <PlanckWalk> Err, that was meant to be e^(-pi/2 i) in the second expression
[02:00:17] <Pi-sistance> yeah thanks I got it.
[02:01:00] *** Quits: qu4nt1n (~qu4nt1n@78.198.214.34) (Quit: KVIrc 5.0.0 Aria http://www.kvirc.net/)
[02:01:01] <Pi-sistance> I was using the negative to take it to the denominator, but forgot to remove it. (and then reapply it after multiplying by j/j)
[02:01:53] <memorye> i am convinced Varde is just an insane person
[02:01:59] <tusko> did you make sure it was plugged in first?
[02:02:01] <memorye> well not convinced
[02:02:07] <memorye> but leaning toward that probability
[02:04:02] *** Quits: zer0bitz (~zer0bitz@dsl-hkibng31-54fae3-116.dhcp.inet.fi) (Ping timeout: 260 seconds)
[02:05:08] <droid3> PlanckWalk thanks yup now i am better about know how to compute the number of iteration if a user asks i want the nthroot out to say 1000 place or a million places,...etc. And definitely using the error formula in more detail i beable to compute the error bound of iterations in more general functions.
[02:05:41] <droid3> Thus understand how to set the number of iteration i need to achieve a given number of significant figures out to so many place that the user wants.
[02:05:57] <PlanckWalk> Good! :)
[02:07:14] <droid3> Its been a little while on this stuff good refresher.
[02:07:36] <droid3> Talk later computing the millionth digit of sqrt of 2 LOL
[02:07:47] <droid3> pretty damn quick
[02:10:51] *** Quits: dauggy (~wojtek@31.12.0.178) (Ping timeout: 256 seconds)
[02:11:01] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[02:11:03] *** Quits: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com) (Read error: Connection reset by peer)
[02:12:46] *** Joins: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com)
[02:13:06] <droid3> Ok got another unrelated question more in the field of algebraic geometry or in general when you do implicit differentiation on say x^4 = (x^2-y^2)
[02:13:25] <droid3> at the point (0,0) you want to find the tangent lines
[02:13:27] *** Joins: darkapex (~darkapex@user/darkapex)
[02:14:16] <droid3> but if you implicit differentiate you get 0/0 undetermined state and if you do higher and higher derivatives you get 0/0  as well.
[02:14:45] *** Quits: sfields_ (~sfields@2605:a601:adea:7a00:876c:3f04:3987:d13a) (Quit: Leaving)
[02:14:56] <droid3> Is there no good theory / method to resolve an indeterminte state when you implicit differentiate
[02:15:32] *** Quits: plankster (~plankster@user/plankers) (Quit: No Ping reply in 180 seconds.)
[02:15:45] *** Joins: plankster (~plankster@user/plankers)
[02:16:14] <droid3> Been thinking on this i know +- inf means you got a vertical tangent line/s but still the case of indetermined 0/0 inf/inf ...etc at a point when you implicit differentiate is eluding me.
[02:16:33] *** Quits: Donitz (~Donitz@88-115-149-152.elisa-laajakaista.fi) (Read error: Connection reset by peer)
[02:16:53] <droid3> As normally in regular calculus we teach derivative test (but there on function not multivalued functions)
[02:17:16] <droid3> And you only have inflection points , max , min type critical points to deal with.
[02:17:27] *** Quits: krupp (~svarten@m37-2-104-243.cust.tele2.se) (Quit: Leaving)
[02:17:56] <droid3> When you introduce implicit differentiation your now working with multivalue functions that normally cannt be solved for interms of one variable globally
[02:18:22] <droid3> i know we have nice stuff like implicit function theorem and inverse function theorem to solve locally alot of times.
[02:19:07] <droid3> But in any case when we get indetermined stuff for implicit differentiation 0/0 , inf /inf ,...etc how can we figure out what the slope/s of the tangent lines should be for these points
[02:19:54] <droid3> for the figure eight curve its simple enough to solve for one variable or use polar coordinates ...etc to get the values for the tangent lines at zero
[02:20:03] <droid3> but again this is just a simple example
[02:20:10] *** Quits: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Quit: Leaving)
[02:20:22] *** Joins: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[02:20:23] *** Joins: jmorris (uid433911@hampstead.irccloud.com)
[02:20:41] <droid3> anybody know a general method of getting around these 0/0 , inf/inf ...etc issue when trying to find the slopes of points using implicit differentiation
[02:21:03] *** Quits: arseniiv (~arseniiv@94.41.2.66.dynamic.ufanet.ru) (Ping timeout: 256 seconds)
[02:21:32] <droid3> Normally we dont deal with this issue when teaching implicit differentiation this is more in the realm of singularity of algebraic geometry or catastrophy theory ...etc
[02:22:09] <droid3> But i am still trying to figure a good method to solve this issue when i get a board set up i think all start trying to invent a good method to do this.
[02:22:26] <droid3> Just wondering if anybody knows and wants to talk about it.
[02:23:23] <droid3> it seems 0/0 when you do implicit differentiation at a point of your multivalued function seems to mean that there are many different tangent lines
[02:23:58] <droid3> But is 0/0 always mean this hummmm ? And if so i still need a method to resolve on how to find the slopes of all these tangent lines.
[02:24:03] <Pi-sistance> PlanckWalk:  The book had it like that beacuse the initial expresion was just sin(x)*I/wc, so sin was equated to the imgainry part of a complex term
[02:24:44] <droid3> Not to mention how to generalize this to multivariable functions like algebraic surfaces , hypersurfaces , transcendental functions in many variables ...etc to classify there singularities
[02:25:58] *** Joins: plankster_ (~plankster@user/plankers)
[02:26:46] *** Quits: random-jellyfish (~random-je@user/random-jellyfish) (Ping timeout: 256 seconds)
[02:26:47] *** Joins: Panther (Lord@2601:18a:c000:5290:50fb:c1a0:bcdc:ace4)
[02:27:13] *** ayahuasca is now known as kish`
[02:27:17] *** Quits: plankster (~plankster@user/plankers) (Ping timeout: 256 seconds)
[02:28:22] *** Quits: LucaTM (~LucaTM@user/lucatm) (Quit: Textual IRC Client: www.textualapp.com)
[02:28:26] <PlanckWalk> droid3: Hmm?  The second implicit derivative gives  y' = +/- 1 at (0,0)
[02:28:55] <droid3> i get how we can write the implicit equations for the same in multivariable case. But still the 0/0 and inf/inf combinations amongst other critical points from these systems of implicit equations gives rise to many more type of stuff. (not just saddle points, max,min , inflection points  that we all know in love from calculus 1-3 /advanced/differential geo classes.
[02:29:26] <PlanckWalk> Which isn't great and not even really correct, but isn't 0=0.
[02:29:31] *** Quits: plankster_ (~plankster@user/plankers) (Client Quit)
[02:30:20] <PlanckWalk> It is correct in the sense that there's a parameterization that yields both of those derivatives there, though.
[02:30:38] *** Quits: HellCat (Lord@c-73-38-66-27.hsd1.ct.comcast.net) (Ping timeout: 260 seconds)
[02:30:50] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[02:31:22] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Client Quit)
[02:31:36] *** Joins: hesse (~TheHerman@gateway/tor-sasl/thehermann)
[02:31:52] <tusko> Did you try turning it off and then back on?
[02:31:54] <PlanckWalk> Technically there is no tangent at that point to that set of points.
[02:32:11] *** Joins: plankster (~plankster@user/plankers)
[02:32:16] <droid3> Planckwalk how did you get that d2y/dx^2 == [F2(F11+F12y')-F1(F21+F22y') ]/(F2)^2
[02:32:20] <PlanckWalk> So it's no surprise that some technique might not find one.
[02:32:32] <droid3> where F(x,y) = 0
[02:32:41] *** Joins: trbp (~trbp@user/trbp)
[02:33:01] *** Quits: nehsou^ (~nehsou@h50.174.139.63.static.ip.windstream.net) (Remote host closed the connection)
[02:33:15] <PlanckWalk> Why are you writing things in that form?
[02:33:32] <droid3> dy/dx = - F1/F2 so from that one can compute all the higher nth derivatives for the implicit differentiation
[02:33:42] <PlanckWalk> I'm using the second implicit derivative, not trying to find the second derivative of y with respect to x
[02:34:05] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 256 seconds)
[02:34:37] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[02:34:46] <droid3> as you can see d^2y/dx^2 as above is differentiating of dy/dx = - F1/F2  with care to remember that F1,F2 depend on x,y and that y itself is a function of x
[02:35:30] <PlanckWalk> I don't care what d^2y/dx^2 is
[02:35:43] <PlanckWalk> I'm solving to find dy/dx
[02:36:01] <PlanckWalk> Because that's what you said you wanted to know
[02:36:15] <droid3> ya a dy/dx gives you 0/0 at the orgin so ho did you come up with the correct two slopes
[02:36:21] *** Quits: TheHermann (~TheHerman@gateway/tor-sasl/thehermann) (Ping timeout: 276 seconds)
[02:36:35] <droid3> just from dy/dx alone
[02:36:36] *** Joins: akuma (~movfw@user/marlboro)
[02:36:44] <PlanckWalk> I don't know what you mean
[02:37:28] <droid3> x^4 = (x^2-y^2) if you implicit differentiate this and subsitute (0,0) you get 0/0
[02:37:45] <PlanckWalk> Yes, that's the first implicit derivative.
[02:37:48] <PlanckWalk> Try the second.
[02:38:07] <droid3> the second derivative is  d2y/dx^2 == [F2(F11+F12y')-F1(F21+F22y') ]/(F2)^2
[02:38:19] <PlanckWalk> What?  No.
[02:38:31] <PlanckWalk> Second *implicit* derivative.
[02:38:35] <droid3> ya it is
[02:38:35] <PlanckWalk> Not d^2y/dx^2
[02:38:46] <droid3> i guess i not sure what you mean by second implicit
[02:39:59] <droid3> ya it is for a function in the form F(x,y) = 0  that would be the second derivative
[02:40:16] <droid3> if you use implicit differentiation
[02:40:58] <droid3> PlanckWalk PasteBin your work/steps i like to see this implicit** expression your talking about.
[02:41:29] <droid3> did you solve for y interms of x ??? because you can do it that way however i am getting at not doing it that way.
[02:41:29] *** Quits: texasmusicinstru (~Rheanna@101.91.232.166) (Remote host closed the connection)
[02:41:43] <droid3> because most times you cannt solve for y interms of x...etc
[02:41:52] <PlanckWalk> You're trying to find dy/dx for some curve along which F(x,y) = 0.  There's a few ways to do this, and one is to consider that the curve is a curve is locally a function of some parameter t (and then remove the dependence upon t)
[02:42:11] *** Quits: audiobirb (~audio@user/audio) (Ping timeout: 245 seconds)
[02:42:20] <droid3> ya assuming you cannt
[02:42:24] *** Quits: trbp (~trbp@user/trbp) ()
[02:42:24] <droid3> then what
[02:42:28] <PlanckWalk> (For other F(x,y,z,...) = 0 surfaces you can have multiple parameters)
[02:42:40] <PlanckWalk> Assuming you cannt what?
[02:42:52] <droid3> solve for a variable explicitly
[02:43:01] <PlanckWalk> I'm not assuming that you can
[02:43:27] <PlanckWalk> One possible choice of parameter is either x or y itself (in some local region)
[02:43:30] *** Joins: texasmusicinstru (~Rheanna@218.78.94.61)
[02:44:19] <droid3> x^4 = (x^2-y^2) assuming you dont solve for one of the variables to get +- two explicit equations for the tangents at (0,0)
[02:44:30] <PlanckWalk> Since the curve satisfies F(x,y) = 0, then for any parameterization x(t), y(t) you must have dF(x(t), y(t))/dt = 0, d^2 F(x(t), y(t)) / dt^2 = 0, etc.
[02:44:41] <droid3> then how do you handle 0/0 when you implicit differentiate to get dy/dx = 0/0
[02:44:57] <PlanckWalk> I can start with testing to see whether x(t) = t works in the neighbourhood of this point.
[02:45:16] <droid3> the next derivative dy^2/dx^2 is going to be [F2(F11+F12y')-F1(F21+F22y') ]/(F2)^2
[02:45:26] * PlanckWalk gives up
[02:45:27] <droid3> I just wrote out the general formula for it
[02:45:45] <PlanckWalk> You're not bothering to read anything, so I'm not going to bother writing it
[02:46:56] <PlanckWalk> So just read what I already wrote, and you can probably continue from there.
[02:47:22] <droid3> ya that assuming you can parameterize to with explicit formulas for x(t) and y(t)
[02:47:39] <droid3> sure but if you cannt then your not going to beable to use that way.
[02:50:32] <droid3> PlanckWalk first this is the sqrt(2.1) out to around 100,000 decimal places for what we talked about
[02:50:33] <droid3> https://pastebin.com/crXrk1xe
[02:51:35] <droid3> And second if you only have implicit differentiation and you dont have abilities to write the x and y variables interms of a parametric equation your method is not appliciable.
[02:51:58] <droid3> I am searching for a general method for the 0/0 implicit differentiation issue
[02:52:36] <droid3> not a special case like being able to solve for one of the variables or find a parametric equation for the variables and solve by parametric differentiation
[02:53:06] <droid3> So good idea and good method to attempt to use in alot of case but not generally applicable to solve all cases PlanckWalk
[02:53:30] <droid3> And yes i read all your stuff and think i get your parametric method /idea
[02:53:48] <droid3> which is a good one but not a general one for implicit differentiation issues.
[02:54:26] *** Joins: internalsplit_of (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net)
[02:54:28] *** Quits: internalsplit_of (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net) (Excess Flood)
[02:55:03] *** Quits: KillAnimals (~anon@199-7-159-56.eng.wind.ca) (Ping timeout: 256 seconds)
[02:55:43] <droid3> And yes your parametric method/conversion works great for this example but assuming one can find a parametric equation for both y and x explicitly is a huge assumption for a general F(x,y) = 0 equation
[02:56:36] *** isekaijin is now known as isekai-kujira
[02:56:40] *** Joins: internalsplit_of (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net)
[02:56:41] *** Quits: internalsplit_of (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net) (Excess Flood)
[02:56:56] *** Quits: givemeyourpies (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net) (Ping timeout: 268 seconds)
[02:56:58] <droid3> And generalizing to F(x,y,z,w,...) we have the same similar issue just with systems of implicit equation determined by the different partial derivatives
[02:57:02] *** Joins: internalsplit_of (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net)
[02:57:03] *** internalsplit_of is now known as givemeyourpies
[02:57:04] *** Quits: givemeyourpies (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net) (Excess Flood)
[02:57:26] *** Joins: givemeyourpies (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net)
[02:57:57] <droid3> At which point any of the equations could have a 0/0 , inf/inf ...etc interdetermined case
[02:58:25] <droid3> and sure parametric equations would get around alot of this but is even hard to determine for many variables > 2
[02:58:41] <droid3> so parametric equation is not going to solve the general problem
[02:59:10] *** Joins: Maturion (~Maturion@p200300ede72bd100580e6e7af78de52b.dip0.t-ipconnect.de)
[02:59:19] <droid3> And i would be just into understanding how to do the general problem for case of 2 vars aka F(x,y) = 0 more the algebraic curves case
[02:59:50] <droid3> Before i attempt to generalize to F(x,y,z,w...) algebraic surfaces , hypersurfaces ,...etc cases.
[03:00:59] <droid3> Its a hard question to me still unless i am missing something. SUre parametric equation converting or solving for one variable interms of the others would be a solution
[03:01:11] <droid3> if you can apply it yet most times you cannt
[03:01:45] <droid3> Anyway later Planckwalk but thats the issue /question
[03:04:52] *** Joins: Bilnon (~8iIn0n@2a01:4b00:8e07:7900:904a:a590:3eb3:9890)
[03:07:39] *** Quits: Bilnon (~8iIn0n@2a01:4b00:8e07:7900:904a:a590:3eb3:9890) (Client Quit)
[03:08:08] *** Joins: msmhbvd^ (~msmhbvd@h50.174.139.63.static.ip.windstream.net)
[03:10:27] *** Joins: frelleck (~frelleck@user/frelleck)
[03:10:49] *** Quits: takuan (~takuan@178-116-218-225.access.telenet.be) (Remote host closed the connection)
[03:10:57] *** Joins: random-jellyfish (~random-je@user/random-jellyfish)
[03:11:12] <PlanckWalk> You obviously didn't bother to read "I can start with testing to see whether x(t) = t works in the neighbourhood of this point."
[03:11:48] <PlanckWalk> Or actually test it with any examples at all, like the equation you asked about.
[03:12:37] *** Quits: Trigo (~NeedMathH@64.201.115.44) (Ping timeout: 256 seconds)
[03:16:47] *** Joins: x003fgqwe (uid479614@lymington.irccloud.com)
[03:18:14] <qergle> https://www.medrxiv.org/content/10.1101/2021.06.11.21258690v3
[03:18:52] <qergle> tl;dr covid reduces gray matter in frontal and temporal lobes and decline in cognitive ability
[03:21:50] *** Joins: fructose (~fructose@user/fructose)
[03:22:06] <tolarz> Is positivity of multivariate polynomials decidable?
[03:22:37] <tolarz> Concretely, let P ∈ Z[x_1,....,x_n] be a multivariate polynomial with integer coefficients. Is `P >= 0` decidable?
[03:24:09] <PlanckWalk> I'm not sure, but I suspect not
[03:25:06] <PlanckWalk> Especially since the corresponding real polynomial might not be >= 0.
[03:25:21] <PlanckWalk> Oh wait, are the variables integer?
[03:25:41] <PlanckWalk> or are they real variables with integer coefficients?
[03:26:32] <tolarz> For P ∈ Z[x_1, ..., x_n] I consider the induced function P: Z^n -> Z. Is `∀(x_1,...,x_n)∈Z^n. P(x_1,...,x_n) >= 0` decidable?
[03:26:57] <tolarz> hm
[03:27:14] <PlanckWalk> Ah okay, so integer variables.  Yeah I think that might be harder than the real variable case.
[03:28:19] <PlanckWalk> Any diophantine equation can be put in that form, so I guess it has to be undecidable.
[03:28:20] <tolarz> Is semidefiniteness of integer matrices decidable?
[03:28:24] <tolarz> Seems like a related problem.
[03:29:09] <PlanckWalk> P(x1,...,xn) = 0 can be turned into P^2 - 1 < 0
[03:31:11] *** Quits: magla (~gelignite@55d45814.access.ecotel.net) (Quit: Stay safe!)
[03:31:22] *** Joins: stipa_ (~stipa@user/stipa)
[03:31:23] *** Quits: texasmusicinstru (~Rheanna@218.78.94.61) (Remote host closed the connection)
[03:33:33] *** Joins: texasmusicinstru (~Rheanna@101.89.150.168)
[03:33:56] *** Quits: stipa (~stipa@user/stipa) (Ping timeout: 268 seconds)
[03:33:58] *** stipa_ is now known as stipa
[03:34:19] *** Quits: zava (~zava@ip5f5bdf0f.dynamic.kabel-deutschland.de) (Quit: WeeChat 3.3)
[03:34:43] *** Quits: jellydonut (~quassel@185.213.154.170) (Quit: jellydonut)
[03:36:08] <jmorris> do the solutions to PCA and a 3-layer autoencoder without nonlinearity actually span the same space
[03:36:52] *** Joins: jellydonut (~quassel@185.213.154.170)
[03:42:58] *** Quits: Maturion (~Maturion@p200300ede72bd100580e6e7af78de52b.dip0.t-ipconnect.de) (Ping timeout: 265 seconds)
[03:45:28] *** Joins: oxum (~oxum@122.172.47.114)
[03:48:41] *** Quits: hesse (~TheHerman@gateway/tor-sasl/thehermann) (Quit: Leaving)
[03:51:12] *** Quits: oxum (~oxum@122.172.47.114) (Ping timeout: 268 seconds)
[03:52:14] <PlanckWalk> No idea
[03:55:27] <PlanckWalk> Mainly because I don't know what a 3-layer autoencoder without nonlinearity is, or what it spans.
[03:57:33] <jmorris> PlanckWalk: i just mean with a single hidden layer without an activation function
[03:57:55] <jmorris> you can use an autoencoder like this to perform a dimensionality reduction to s dimensions where s is the size of the hidden layer
[03:58:36] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[03:58:48] <jmorris> so if you perform a dimensionality reduction using the first four principle component vectors im wondering if that gives the same solution to a single size four hidden layer autoencoder with no activation functions if
[03:59:18] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 260 seconds)
[03:59:54] *** Lord_of_Life_ is now known as Lord_of_Life
[03:59:55] <Decker> principal component analysis?
[04:00:18] <jmorris> Decker: i dont understand the question
[04:00:24] <Decker> is that pca?
[04:00:32] <PlanckWalk> I expect it should with sufficient training, since PCA gives optimal truncation errors.
[04:00:55] <PlanckWalk> And it sounds like the dimensionality reduction is linear there
[04:01:08] *** Quits: msmhbvd^ (~msmhbvd@h50.174.139.63.static.ip.windstream.net) (Remote host closed the connection)
[04:01:18] <PlanckWalk> Ohh hmm, does the autoencoder allow bias?
[04:01:39] <PlanckWalk> Or is it stricly linear in inputs rather than affine?
[04:04:04] <PlanckWalk> It seems reasonable that they'd be equivalent in some sense or other.
[04:04:20] <PlanckWalk> Even if it isn't literally identical.
[04:05:12] *** Quits: PJBoy (~PJBoy@user/pjboy) (Ping timeout: 265 seconds)
[04:14:26] *** bosspotato_ is now known as bosspotato
[04:14:42] *** Joins: Carbonflux (~Carbonflu@c-66-235-54-179.sea.wa.customer.broadstripe.net)
[04:20:31] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 245 seconds)
[04:21:46] *** Quits: texasmusicinstru (~Rheanna@101.89.150.168) (Remote host closed the connection)
[04:22:24] *** Joins: texasmusicinstru (~Rheanna@61.171.69.141)
[04:22:38] *** Quits: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com) (Ping timeout: 260 seconds)
[04:26:46] *** Quits: akuma (~movfw@user/marlboro) (Read error: No route to host)
[04:26:51] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[04:27:17] *** Joins: akuma (~movfw@2001:470:8afc:cafe::1:cafe)
[04:27:17] *** Quits: akuma (~movfw@2001:470:8afc:cafe::1:cafe) (Changing host)
[04:27:17] *** Joins: akuma (~movfw@user/marlboro)
[04:29:57] <Batzy> i dont get why an SVD algorithm would usually fail to be backward stable
[04:30:00] *** Quits: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[04:38:06] *** Quits: NllPtr (~NllPtr@186-78-245-240.baf.movistar.cl) (Quit: WeeChat 2.8)
[04:38:42] *** Joins: pavonia (~user@user/siracusa)
[04:40:55] *** Joins: NllPtr (~NllPtr@186-78-245-240.baf.movistar.cl)
[04:41:10] <PlanckWalk> I'd be pretty surprised if it was
[04:41:40] *** Joins: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[04:42:35] <biberao> hi i saw once like numbers divisible by 5 or 6 between 1 and 200
[04:42:46] <biberao> something n(A U B)
[04:42:50] <biberao> what is this called?
[04:43:33] <somiaj> n(X) is sometimes used for the cardnality of a set, though |X| is more common
[04:43:43] <Z-module> I've never seen "n(X)"
[04:44:04] <biberao> ok
[04:44:16] <PlanckWalk> I've never seen it before, but I could guess what it meant.
[04:45:17] <biberao> but i saw i believe n(AUB)=something - n(A ∩ B)
[04:45:19] <biberao> or something
[04:45:30] <somiaj> I think it was some discrete textbook I've seen that used
[04:45:32] <biberao> similar
[04:45:44] <Z-module> yeah,  |A cup B| = |A| + |B| - |A cap B|
[04:45:48] <somiaj> well |A u B| = |A| + |B| - |A n B|, this is sometimes called inclusion/exculsion
[04:45:54] <biberao> ah ok
[04:45:57] <biberao> thanks
[04:46:09] <biberao> like ive seen that used for that question i made
[04:46:17] <biberao> ike numbers divisible by 5 or 6 between 1 and 200
[04:46:31] <Batzy> PlanckWalk: well why?
[04:46:42] *** Quits: Maxdamantus (~Maxdamant@user/maxdamantus) (Ping timeout: 268 seconds)
[04:46:46] <qergle> yes, if you count each separately you've counted the multiples of 30, twice
[04:46:51] <Batzy> i have some explanation ive been thinking through, but it all feels like bullshit
[04:46:53] *** Quits: akuma (~movfw@user/marlboro) (Quit: you touch my ta la la ...)
[04:46:55] *** Quits: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[04:47:19] <biberao> another question
[04:47:36] *** Joins: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[04:47:39] <biberao> is it correct to say (1,200) or (1,200]
[04:47:41] <biberao> ?
[04:47:49] <biberao> when saying numbers between 1 and 200
[04:48:23] <qergle> so...let's do this back of envelope
[04:48:27] <somiaj> between is vague, and some use it to mean inclusive and others exclusive, though usually you are consistant, so (1,200) or [1,200]
[04:48:55] <biberao> im asking because
[04:48:58] <qergle> you have 40 multiples of 5 (in 1-200), 33 multiples of 6, and 6 multiples of 30.
[04:49:01] <biberao> its been taught differently
[04:49:17] <qergle> 40+33-6=67 would be my answer
[04:49:32] *** Quits: NEYi (~NEYi@109.251.216.38) (Quit: Leaving)
[04:50:05] *** Quits: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[04:50:47] <PlanckWalk> Batzy: Mainly topological reasons, in that the space that you're mapping the original R^(mn) into aren't homeomorphic to R^(mn)
[04:50:50] *** Joins: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[04:51:59] *** Quits: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net) (Remote host closed the connection)
[04:52:10] <qergle> 67 unless 67
[04:52:15] *** Joins: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net)
[04:52:31] <PlanckWalk> So the mapping has to be "degenerate" at some points.
[04:52:58] <biberao> qergle: thanks though i wasnt planning for you to give me answer ;)
[04:53:07] <biberao> i was just trying to understand ways to get there
[04:53:31] <qergle> there's no magic, you can ignore the answer and solve yourself, this wasn't a big spoiler.
[04:53:35] <Batzy> PlanckWalk: so the complaint is that the unitary matrices produced etc are just a much higher dimensional space
[04:53:39] <qergle> or invent new numbers
[04:53:51] <Batzy> maybe you can add some bounding conditions so that the the dimensions marry up better
[04:53:57] <PlanckWalk> Batzy: Are they?  That's not obvious to me
[04:53:57] <qergle> multiples of 4 and 17 in numbers from 1 to 666
[04:54:25] <biberao> ok
[04:54:34] <Batzy> PlanckWalk: well you're producing 3 matrices
[04:54:42] <PlanckWalk> I mean as a codomain of "all matrices of this shape" they are, but you don't get "all matrices of this shape"
[04:54:45] <Batzy> from an m x n you have now an mxm and nxn
[04:55:03] <PlanckWalk> They're always two unitary matrices and a diagonalish matrix
[04:55:09] <Batzy> yes..
[04:55:34] <PlanckWalk> So I think the spaces have similar dimensions
[04:55:56] <biberao> qergle: you deserve a scooby snack
[04:56:07] *** Quits: harveypwca (~harveypwc@2601:246:c180:a570:3828:d8:e523:3f67) (Quit: Leaving)
[04:56:15] <Batzy> then i still dont get the problem
[04:56:19] <qergle> you deserve our sympathy
[04:56:21] <PlanckWalk> (In the sense of dimension of a manifold)
[04:56:24] <biberao> thanks a lot
[04:56:50] <PlanckWalk> But their manifold of dimension mn is *not* globally homeomorphic to E^(mn)
[04:57:01] <PlanckWalk> R^(mn) rather
[04:57:19] <PlanckWalk> Just locally
[04:57:23] <Batzy> still feels like bullshit
[04:57:38] <Batzy> i've had this vague sense about it sure
[04:58:26] <PlanckWalk> Or C^(mn) really
[04:58:30] <Batzy> but backward stability is a pretty specific statement, if i have an algorithm acting on the input X it's equal to the actual answer of some perturbed input that's close to X
[04:58:57] <PlanckWalk> Yes, that's a continuity property
[04:59:17] <Batzy> I'm just thinking whatever the algorithm does, accumulates some roundoff error
[04:59:33] <Batzy> and a slightly perturbed matrix from unitary matrix is probably not going to be unitary itself
[05:00:19] <PlanckWalk> Hmm wait, does your model assume exact real arithmetic?
[05:00:38] <Batzy> no
[05:00:42] <Batzy> floating point arithmetic
[05:00:57] <PlanckWalk> Oh, in that case then no it's definitely not backward stable.
[05:01:07] *** Quits: jero98772 (~jero98772@2800:484:1d80:d8ce:3490:26c5:1782:da8c) (Quit: leaving)
[05:01:08] <Batzy> is it for the reason i just said
[05:01:24] <PlanckWalk> Even without considering theoretical stability with perfect real arithmetic
[05:02:34] <Batzy> yes im just trying to understand the problem
[05:02:35] <PlanckWalk> Yes, the space of unitary matrices is of much lower dimension than the space its embedded in.  Which isn't itself automatically fatal
[05:02:54] <Batzy> ok
[05:02:57] <Batzy> lower dimension?
[05:03:28] <Batzy> i wouldnt see why it would be automatically fatal, but this is like the only thing to cause the problem no?
[05:04:06] <PlanckWalk> Like, the diagonal matrices are also lower dimension than the space of matrices in general
[05:04:19] <Batzy> oh, sure
[05:04:24] *** Joins: Donitz (~Donitz@88-115-149-152.elisa-laajakaista.fi)
[05:04:44] <PlanckWalk> But in the space of all the correct diagonal matrices, there is always a representable diagonal matrix nearby.
[05:05:10] <Batzy> ah, and for unitaries there might not be
[05:05:15] <PlanckWalk> (Rounding the diaongal matrix off to the nearest floating points in every entry gives you that)
[05:05:27] <Batzy> yes and you still get something diagonal
[05:05:28] <Batzy> when you do that
[05:05:36] <PlanckWalk> And yeah, unitary matrices will often have nothing representable nearby
[05:05:38] <Batzy> but if you do the same thing for unitaries, you get something that could be non-unitary
[05:05:40] <Batzy> ok
[05:05:50] <Batzy> that makes sense
[05:06:10] <Batzy> so it would still be stable though then, because you can get things that are "nearly unitary" maybe?
[05:06:12] <PlanckWalk> There will only be very a few special points that are both floatign point representable and unitary
[05:06:27] <Batzy> and by stable there i mixed like "mixed stable" not backward stable
[05:07:54] <PlanckWalk> As in, small changes to the input yield small changes in the output?
[05:08:16] <PlanckWalk> (In terms of some particular norm of differences)
[05:08:25] <Batzy> yes
[05:08:33] <PlanckWalk> Then no, SVD can't be made stable
[05:08:36] <Batzy> you can actually talk about it
[05:08:43] <Batzy> regardless of norm you choose
[05:08:50] <Batzy> SVD ye it can
[05:09:01] <Batzy> well, multiple places online say it can be
[05:09:07] <PlanckWalk> You can isolate the unstable points, but there will always be some
[05:10:28] <Batzy> PlanckWalk: there are stable svd algorithms
[05:11:00] <PlanckWalk> Not in the sense of "small changes to inputs yield small changes to outputs"
[05:11:39] *** Quits: texasmusicinstru (~Rheanna@61.171.69.141) (Remote host closed the connection)
[05:11:45] <PlanckWalk> Err, small changes to inputs *always* yield small changes to outputs.
[05:11:55] <Batzy> In the sense that it computes almost the right solution to almost the right problem
[05:12:05] *** Quits: givemeyourpies (~givemeyou@c-66-235-2-202.sea.wa.customer.broadstripe.net) (Remote host closed the connection)
[05:12:14] <PlanckWalk> You can arrange it so that small changes to *most* inputs yield small changes to outputs.
[05:12:39] <Batzy> so let's represent the SVD of X by f(X), and our algorithm is f' and X' is a perturbation on X
[05:12:44] *** Joins: texasmusicinstru (~Rheanna@218.78.79.129)
[05:13:19] <PlanckWalk> And yes, you can arrange it so that there exists some small e1, e2 such that SVD(A + e1) = SVD(A) + e2
[05:13:33] <Batzy> i mean ||f'(X) - f(X')||/||f(X)|| = O(machine epsilon) for some X' with ||X-X'||/||X|| = O(machine epsilon)
[05:13:35] <PlanckWalk> Ugh, that's not what I meant
[05:14:24] <PlanckWalk> And yes, you can arrange it so that there exists some small e1, e2 such that Algorithm(A) = True SVD(A + e1) + e2
[05:14:35] <PlanckWalk> There that's better
[05:14:47] <Batzy> "arrange it"?
[05:14:53] <PlanckWalk> That is, you can get close to the correct result for a nearby input.
[05:15:00] <PlanckWalk> Arrange your algorithm
[05:15:27] <Batzy> you just get it for free? you don't have to have some special condition to get that?
[05:15:41] <PlanckWalk> I don't know what you mean by "for free"
[05:15:58] <PlanckWalk> It's not like devising reasonably efficient algorithms with this property is easy!
[05:16:15] <Batzy> well, you said before you didnt think it was stable, right?
[05:16:19] <PlanckWalk> The point is that for this problem, it's *possible*
[05:16:21] <Batzy> ah not easy, sure
[05:16:48] <PlanckWalk> Yes, and clarified what you meant by stable, and you agreed, and then told me you meant something else instead.
[05:17:15] <PlanckWalk> Under the *new* meaning of stable, I agree that there are stable SVD algorithms.
[05:17:31] <Batzy> hm
[05:18:24] *** Joins: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com)
[05:22:07] <Batzy> alright
[05:26:17] *** Quits: peterhil (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[05:27:24] *** Joins: tizef (~tizef@202.153.82.149)
[05:31:37] *** Quits: droid3 (~fffd@071-010-228-178.res.spectrum.com) (Remote host closed the connection)
[05:31:55] *** Joins: droid3 (~fffd@071-010-228-178.res.spectrum.com)
[05:32:09] *** Quits: tizef (~tizef@202.153.82.149) (Remote host closed the connection)
[05:33:31] *** Quits: seninha (~seninha@user/seninha) (Quit: Leaving)
[05:38:28] *** Joins: oxum (~oxum@122.172.47.114)
[05:42:06] *** Joins: notzmv (~zmv@user/notzmv)
[05:42:16] *** Quits: random-jellyfish (~random-je@user/random-jellyfish) (Ping timeout: 256 seconds)
[05:44:14] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[05:45:03] *** Joins: Nognosis (~Nognosis@198.11.28.198)
[05:45:16] *** Joins: oxum (~oxum@122.172.47.114)
[05:47:16] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[05:48:50] *** Joins: harwiltz (~harwiltz@modemcable212.231-202-24.mc.videotron.ca)
[05:49:35] *** Quits: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de) (Ping timeout: 256 seconds)
[05:50:32] *** Joins: oxum (~oxum@122.172.47.114)
[05:51:22] <harwiltz> Hello all. I've been stuck on a proof for a while and havent really made any headway, I'd really appreciate if I can be pushed in the right direction. There's a normed vector space X and an open convex subset K. I have to prove that for every x in X\K, there exists f in X' (topological dual) such that f(y) < f(x) for each y in K.
[05:52:08] *** Quits: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net) (Quit: Leaving)
[05:52:58] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[05:53:03] <harwiltz> So intuitively this seems to make sense, since convex sets contain all points on the "line" between points in the convex set, so I can visualize this in 2D. But for some reason I haven't really gotten anywhere in the proof.
[05:54:58] <harwiltz> Right now I'm trying to work out a proof by contradiction, and hopefully show that it is impossible for the image of each linear functional over K contains points greater than f(x)
[05:55:35] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Ping timeout: 264 seconds)
[05:56:27] *** Joins: Fohsap (~Muimi@2001:19f0:5001:2bf8:5400:3ff:fe30:8554)
[05:59:15] *** Joins: XCode (~XCode@d108-173-59-218.abhsia.telus.net)
[05:59:18] <isekai-kujira> Is it possible to reduce to the case where K does not contain any whole line?
[05:59:33] <XCode> hey.
[05:59:38] <isekai-kujira> Hello.
[05:59:59] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[06:00:10] *** Quits: slidercrank (~slidercra@user/slidercrank) (Ping timeout: 260 seconds)
[06:00:35] *** Quits: pretty_dumm_guy (trottel@gateway/vpn/protonvpn/prettydummguy/x-88029655) (Quit: WeeChat 3.3)
[06:00:54] *** Quits: biberao (~m@user/biberao) (Quit: WeeChat 2.3)
[06:01:04] *** Joins: oxum (~oxum@122.172.47.114)
[06:01:30] *** Quits: texasmusicinstru (~Rheanna@218.78.79.129) (Remote host closed the connection)
[06:01:37] <frelleck> is it true there's a point in K of mimimal distance to x?
[06:02:15] <harwiltz> frelleck: No, we need K to be uniformly convex for that :(
[06:03:11] <harwiltz> isekai-kujira: I don't know if we can do that, since X is an arbitrary normed vector space, it can be infinite dimensional. Also we don't have control over K
[06:03:24] *** Joins: texasmusicinstru (~Rheanna@218.78.94.61)
[06:03:29] <frelleck> the idea I had in mind was to let y be such a point, then write each point in X as c(y - x) + m for m in K, then define the linear functional to be just c
[06:03:54] <frelleck> something along those lines anyhow
[06:04:48] <harwiltz> frelleck: Are you sure you can write each point in X as c(y - x) + m though?
[06:04:51] <frelleck> no :)
[06:04:55] <harwiltz> hahaha
[06:05:24] *** Joins: invin (~invin@2604:ca00:179:22a::60:d4bf)
[06:05:24] <harwiltz> Still, I like the idea. I hadn't come up with anything as intuitive as that, maybe that'll lead somewhere.
[06:05:52] <frelleck> say x = 0 to make things easier
[06:05:59] <frelleck> then what do we want
[06:06:09] <harwiltz> frelleck: I was thinking that, but I don't know if we can say that without loss of generality
[06:06:24] <harwiltz> If x = 0, then necessarily f(x) = 0
[06:06:25] *** Quits: invin (~invin@2604:ca00:179:22a::60:d4bf) (Client Quit)
[06:06:31] <frelleck> yeah
[06:06:54] <isekai-kujira> Maybe you mean an open convex set that is symmetric about the origin?
[06:07:07] <frelleck> basically we are looking for a separating hyperplane between M and x
[06:07:08] <harwiltz> isekai-kujira: not that I know of
[06:07:12] <frelleck> do you have a theorem like that?
[06:07:23] *** Joins: invin (~invin@2604:ca00:179:22a::60:d4bf)
[06:07:24] <harwiltz> frelleck: yes that's what we're looking for, but no I don't know of such a theorem
[06:07:26] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[06:07:27] <isekai-kujira> No, I am just throwing stuff at the wall to see what sticks.
[06:07:30] *** Quits: invin (~invin@2604:ca00:179:22a::60:d4bf) (Client Quit)
[06:07:55] *** Joins: invin (~invin@2604:ca00:179:22a::60:d4bf)
[06:08:34] <frelleck> if there is a nearest point y to x, you can take the midpoint of the segment joining y and x, and take a hyperplane "perpendicular" to y - x containing this midpoint
[06:08:36] <harwiltz> If x = 0, then we need f(y) < 0 for each y in K. At first I thought that was impossible because if f(y) <0 then f(-y) > 0, but we don't know if -y is in K
[06:08:40] <frelleck> so maybe this idea can be generalized
[06:08:53] <W> is there some pedagogical example of multiplying negative numbers to get a positive, for children? E.g. for just negative numbers (or negative times positive) one can use giving vs taking items (canonically apples, no?), but I can't think of anything natural where multiplication of two negative numbers enters the picture (without getting into physical dimensions anyway)
[06:09:06] <harwiltz> frelleck: Perpendicular sounds too Hilbert-spacy though, I'm not sure how we can say perpendicular without an inner product
[06:09:41] <W> (physical dimensions have the downside that we intuitively operate with their absolute value in daily life, making it less pedagogic than it perhaps can be)
[06:10:13] <isekai-kujira> If the origin is not in K, then K cannot simultaneously contain any y and its negative -y.
[06:10:27] <harwiltz> isekai-kujira: right. I think that's crucial
[06:10:40] <frelleck> doesn't the hahn banach theorem give you a linear functional that is one on x - y
[06:11:07] <harwiltz> frelleck: Ah, now that's a theorem I recognize. But I havent heard it in the form you're mentioning, lemme think about that.
[06:11:17] <frelleck> I think it's a corollary
[06:11:28] <frelleck> you apply it to the subspace generated by x - y
[06:12:20] <harwiltz> frelleck: I was just gonna say we need a linear subspace and a convex set isn't enough, but the subspace generated by x - y certainly is ;)
[06:12:38] <frelleck> so you get a linear functional where f(x) = f(y) + 1
[06:12:49] <frelleck> not sure how to go from there though
[06:12:50] <harwiltz> That's not linear though
[06:12:59] <frelleck> no it just satisfies that
[06:13:03] *** Quits: sander (~sander@user/sander) (Quit: So long! :))
[06:13:05] <frelleck> but is linear
[06:13:20] <frelleck> i.e. for our "nearest" y to x
[06:13:27] <frelleck> which doesn't have to exist
[06:13:31] <harwiltz> Ohhhh I thought you meant for each y
[06:13:35] *** Joins: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net)
[06:14:05] <frelleck> this isn't enough though
[06:14:06] <isekai-kujira> W: Recall that one can teach the distributive property by drawing a rectangle, whose sides have length a+b and c+d. Of course, in your first example, you set a,b,c,d > 0. Your next example could be the case where a, c > 0 and |a| < b < 0 and |c| < d < 0.
[06:14:08] <frelleck> fuck it, I'm done
[06:14:30] <harwiltz> frelleck: lol, thanks for the help anyway! I think you're on the right track
[06:15:03] <harwiltz> Also at least now I know I'm not crazy and this problem actually is pretty tough :)
[06:15:15] <frelleck> hehe
[06:15:50] <frelleck> look into 'separating hyperplane theorems'
[06:15:54] <frelleck> they give results of this type
[06:16:01] <harwiltz> Thanks!
[06:16:24] *** Joins: sander (~sander@user/sander)
[06:16:42] <W> isekai-kujira, that's a bit too advanced I think, I was more thinking for children who aren't far beyond learning the multiplication table
[06:16:47] <Batzy> PlanckWalk: how do you know you can arrange an algorithm for SVD that is stable?
[06:17:01] <munkis> is the set of perfect numbers infinitely large?
[06:17:24] *** Quits: invin (~invin@2604:ca00:179:22a::60:d4bf) (Ping timeout: 256 seconds)
[06:17:59] <isekai-kujira> W: Then delay teaching negative numbers as well.
[06:18:10] *** Joins: extern (~archer@141.226.72.6)
[06:19:45] *** Quits: dutch (~DutchIngr@user/dutch) (Quit: WeeChat 3.3)
[06:21:04] *** Joins: Trigo (~NeedMathH@64.201.115.44)
[06:21:24] *** Joins: dutch (~DutchIngr@user/dutch)
[06:23:31] *** Quits: xff0x (~xff0x@2001:1a81:526d:df00:b864:176f:3a64:2e83) (Ping timeout: 268 seconds)
[06:23:42] <isekai-kujira> W: What I had in mind was this: https://i.imgur.com/0lgNVIU.png
[06:24:25] <isekai-kujira> W: The product of two negatives arises as the orange thing. But it contributes a positive term to the sum.
[06:24:44] *** Quits: newpy (~newpy@206.168.231.90) (Quit: Leaving)
[06:24:58] *** Joins: xff0x (~xff0x@2001:1a81:52ad:7900:2980:608c:4201:500d)
[06:25:08] *** Quits: emerent (~quassel@p200300cd57430969ba27ebfffed28a59.dip0.t-ipconnect.de) (Remote host closed the connection)
[06:25:12] <W> yeah I got it, and I can see how you could teach that with e.g. blocks arranged in a grid, but I feel that bumps the age where it would "take" a few years higher than strictly necessary
[06:26:03] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[06:26:21] *** Joins: emerent (~quassel@p200300cd57430969ba27ebfffed28a59.dip0.t-ipconnect.de)
[06:26:26] *** Quits: NllPtr (~NllPtr@186-78-245-240.baf.movistar.cl) (Ping timeout: 256 seconds)
[06:27:01] *** Joins: NllPtr (~NllPtr@186-78-245-240.baf.movistar.cl)
[06:27:14] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 260 seconds)
[06:27:31] <isekai-kujira> W: If you're trying to teach negative numbers to kids who are still 7-8 years old, then just don't.
[06:28:07] *** Quits: harwiltz (~harwiltz@modemcable212.231-202-24.mc.videotron.ca) (Ping timeout: 256 seconds)
[06:28:23] *** Joins: Maxdamantus (~Maxdamant@user/maxdamantus)
[06:28:27] *** Joins: oxum (~oxum@122.172.47.114)
[06:28:29] <isekai-kujira> It is more important that they learn to manipulate nonnegative numbers confidently and correctly.
[06:35:54] *** Joins: Codaraxis (~Codaraxis@user/codaraxis)
[06:35:59] *** Joins: tizef (~tizef@202.153.82.149)
[06:36:01] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[06:38:11] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[06:38:31] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[06:39:33] *** Joins: oxum (~oxum@122.172.47.114)
[06:44:32] *** Joins: harwiltz (~harwiltz@modemcable212.231-202-24.mc.videotron.ca)
[06:44:58] *** Quits: oxum (~oxum@122.172.47.114) (Ping timeout: 260 seconds)
[06:45:32] *** Joins: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de)
[06:50:53] *** Quits: Macuser (~Macuser@216.30.159.201) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[06:52:07] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[06:52:07] *** Quits: texasmusicinstru (~Rheanna@218.78.94.61) (Remote host closed the connection)
[06:53:15] *** Joins: texasmusicinstru (~Rheanna@218.78.67.149)
[06:54:59] *** Quits: Inline (~Inline@2a02:908:1252:7a80:22ee:92f9:2a07:2e7) (Ping timeout: 264 seconds)
[06:56:46] *** Quits: tizef (~tizef@202.153.82.149) (Remote host closed the connection)
[06:57:15] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[06:59:31] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[07:01:46] *** Quits: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de) (Ping timeout: 260 seconds)
[07:03:11] *** Quits: droid3 (~fffd@071-010-228-178.res.spectrum.com) (Remote host closed the connection)
[07:03:31] *** Joins: sheepduck (~sheepduck@user/sheepduck)
[07:05:56] *** Joins: droid3 (~fffd@071-010-228-178.res.spectrum.com)
[07:08:46] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 260 seconds)
[07:11:36] <qergle> munkis: we don't know
[07:13:37] *** Quits: harwiltz (~harwiltz@modemcable212.231-202-24.mc.videotron.ca) (Quit: WeeChat 3.3)
[07:16:25] *** Joins: sleeping_papaya (~sleeping_@89.46.62.173)
[07:18:33] *** Quits: xkuru (~xkuru@user/xkuru) (Read error: Connection reset by peer)
[07:20:27] *** Quits: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com) (Quit: ZNC 1.7.5+deb4 - https://znc.in)
[07:21:19] *** Joins: Fohsap_ (~Muimi@221.201.3.188)
[07:22:06] *** Joins: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com)
[07:22:23] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[07:25:05] <Galois> w: in american football, penalties yield negative yardage. Penalties can be overturned upon video review. Overturning n penalties of m yards each results in (-n)*(-m) net yards.
[07:25:06] *** Quits: Fohsap (~Muimi@2001:19f0:5001:2bf8:5400:3ff:fe30:8554) (Ping timeout: 245 seconds)
[07:26:46] <Galois> you can do similar examples with things like reversing a pay cut, but I find kids understand football more than salary
[07:31:45] *** Quits: jmorris (uid433911@hampstead.irccloud.com) (Quit: Connection closed for inactivity)
[07:34:50] *** Joins: i0e (~is0ke3@user/is0ke3)
[07:42:24] *** Joins: pavlushka (~pavlushka@user/pavlushka)
[07:45:20] *** Joins: jmorris (uid433911@hampstead.irccloud.com)
[07:52:14] <greenbagels> for some reason the hahn-banach theorem recently popped into my mind
[07:52:21] <greenbagels> but i can't for the life of me recall where i heard this theorem before
[07:52:23] *** Joins: oxum (~oxum@122.172.47.114)
[07:56:00] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[07:57:18] *** Quits: oxum (~oxum@122.172.47.114) (Ping timeout: 260 seconds)
[08:01:35] *** Quits: Maxdamantus (~Maxdamant@user/maxdamantus) (Ping timeout: 264 seconds)
[08:02:45] *** Quits: sleeping_papaya (~sleeping_@89.46.62.173) (Ping timeout: 256 seconds)
[08:03:17] <greenbagels> also, if i have a countably infinite sequence of nested closed nonempty sets in some metric space
[08:03:53] <greenbagels> is it trivial to say this infinite intersection is nonempty?
[08:04:11] *** Joins: andai (~andai@ip26-92-214-87.adsl2.static.versatel.nl)
[08:04:35] *** Quits: i0e (~is0ke3@user/is0ke3) (Ping timeout: 264 seconds)
[08:05:03] <greenbagels> because given any of these sets, say some U_n with index n in N, any element of U_n is also an element of U_k for k < n
[08:05:14] <greenbagels> hm no
[08:05:20] *** Joins: CatCow (~wtf_over@c-73-96-109-206.hsd1.or.comcast.net)
[08:06:07] <frelleck> U_n = [n, infinity) in R^n is a counterexample
[08:06:27] <frelleck> in R^1 I mean
[08:06:40] *** Joins: i0e (~is0ke3@user/is0ke3)
[08:06:44] <greenbagels> true
[08:07:05] <greenbagels> god i hate this infinite business
[08:07:20] <bosspotato> don't we all
[08:09:10] <mycroftiv> heres a really fun infinite nested object https://en.wikipedia.org/wiki/Whitehead_manifold
[08:09:39] <mycroftiv> you can make these arbitrarily deep in our actual physical space with flexible rubber donuts
[08:10:02] *** Quits: extern (~archer@141.226.72.6) (Quit: WeeChat 3.3)
[08:10:27] <bosspotato> however greenbagels bear in mind https://en.wikipedia.org/wiki/Cantor%27s_intersection_theorem which is close enough to what you were saying
[08:11:38] <greenbagels> bosspotato: yeah my textbook is asking me to prove the "variant for complete spaces" below
[08:11:55] <greenbagels> i'm just trying to get a feel for how the assumptions affect the result
[08:12:04] <bosspotato> ah right
[08:12:21] <greenbagels> at least my intuition that completion + diameter approaching 0 aren't required to show non-emptiness
[08:12:32] <greenbagels> at least my intuition... was right*
[08:12:35] <greenbagels> so there's something, i guess
[08:14:41] <bosspotato> right
[08:15:00] <greenbagels> i think i'll try to prove that first
[08:15:14] <greenbagels> oh but you need compactness, ah
[08:16:51] <mycroftiv> mathematical paranoia : when you declare all your objects are compact closed discrete finite computable in primitive recursive arithmetic in an effort to stave off pathologies
[08:17:21] <greenbagels> mycroftiv: when you add so many constraints your sandbox becomes an empty set
[08:19:35] *** Quits: bosspotato (~bosspotat@user/bosspotato) (Ping timeout: 264 seconds)
[08:23:07] <mycroftiv> earlier tonight I was ambushed by "Bordered Heegard Floer homology" and im still groggy from it
[08:23:11] *** Quits: Trigo (~NeedMathH@64.201.115.44) (Ping timeout: 264 seconds)
[08:23:39] *** Joins: Maxdamantus (~Maxdamant@user/maxdamantus)
[08:24:10] *** Joins: Trigo (~NeedMathH@64.201.115.44)
[08:27:01] *** Joins: frost (~frost@user/frost)
[08:29:18] <mycroftiv> clinging by my mental fingertips to thin threads of vague understanding of how slice knots relate to 4d topology, i was not prepared for it.
[08:32:00] <mycroftiv> i was exploring to possibly find a connection from braid theory and laver tables https://www.lmno.cnrs.fr/archives/dehornoy/Papers/Dij.pdf which i did some work with http://wiki.9gridchan.org/incoming/mycro/agdahtml/LaverTables.html
[08:32:00] *** Quits: texasmusicinstru (~Rheanna@218.78.67.149) (Remote host closed the connection)
[08:32:25] <qergle> piccirillo proved the conway knot is slice as a grad student, so you never know when ambushes will lead to inspiration
[08:33:59] *** Joins: texasmusicinstru (~Rheanna@218.78.104.50)
[08:35:25] <mycroftiv> qergle: i am doing good on the inspiration, i just have a big gap between what i can formalize in agda and understand deeply, and the math id like to understand better
[08:37:54] *** Quits: XCode (~XCode@d108-173-59-218.abhsia.telus.net) (Ping timeout: 260 seconds)
[08:38:02] <mycroftiv> i should probably take a look at lean since it has indeed been getting a lot more formalization of sophisticated non-constructive math, agda and hott/cubical are still kind of their own thing though synthetic homotopy theory is maybe relevant/useful
[08:39:39] *** Joins: oxum (~oxum@122.172.47.114)
[08:41:47] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[08:42:19] <mycroftiv> i was looking at some topology software that isnt a proof assistant, and playing with https://regina-normal.github.io/ a little bit
[08:51:48] *** Joins: Ronnin (~Ronnin@23.83.184.132)
[08:52:49] <mycroftiv> intuitively, id like to understand if there is a physical knot (or other comprehensible structure) which corresponds to the left self distributive algebra of the laver tables beyond just the Redemeister III move
[08:55:37] <mycroftiv> https://www.ams.org/journals/proc/1995-123-04/S0002-9939-1995-1246517-X/S0002-9939-1995-1246517-X.pdf on explicit exotic casson handles references https://arxiv.org/pdf/math/9307233.pdf on iterated positive untwisted doubles of positive trefoil
[08:57:08] <mycroftiv> Król has that theorem that "A general Casson handle appearing in the handlebody of a small exotic R4 determines a nontrivial  Cohen  forcing  adding  a Cohen real in some generic model M[G] of ZFC."
[08:58:00] *** Joins: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de)
[08:58:11] <mycroftiv> so what would be really far out is if there is a real way we can map a lot of set theory of large cardinals and forcing to physically realizable (or approximatable) topological structures
[08:58:40] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[08:59:58] <mycroftiv> and it seems like the connections between knot theory and 4manifolds can actually do this systematically if the threads were all charted out, pun intentional
[09:01:40] *** Joins: rindolf (~shlomif@2a0d:6fc2:4bb1:500:6b1e:2524:3d70:36ec)
[09:05:05] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 256 seconds)
[09:05:11] *** Quits: llorllale (~llorllale@2607:9880:3a18:69:81d:9fc:80cc:9e91) (Quit: WeeChat 3.3)
[09:05:48] *** Joins: XCode (~XCode@d108-173-59-218.abhsia.telus.net)
[09:10:35] *** Quits: i0e (~is0ke3@user/is0ke3) (Ping timeout: 264 seconds)
[09:12:25] *** Joins: i0e (~is0ke3@user/is0ke3)
[09:15:17] *** Quits: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de) (Ping timeout: 256 seconds)
[09:18:34] *** Joins: Bilnon (~8iIn0n@2a01:4b00:8e07:7900:904a:a590:3eb3:9890)
[09:19:41] *** Quits: i0e (~is0ke3@user/is0ke3) (Ping timeout: 245 seconds)
[09:21:06] *** Joins: vftec (~8iIn0n@2a01:4b00:8e07:7900:904a:a590:3eb3:9890)
[09:21:53] *** Joins: i0e (~is0ke3@user/is0ke3)
[09:22:05] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Read error: No route to host)
[09:22:42] *** Quits: dude12312414 (~test@gateway/tor-sasl/dude12312414) (Remote host closed the connection)
[09:23:07] *** Joins: vicfred (~vicfred@user/vicfred)
[09:23:35] *** Joins: dude12312414 (~test@gateway/tor-sasl/dude12312414)
[09:26:37] *** Quits: XCode (~XCode@d108-173-59-218.abhsia.telus.net) (Ping timeout: 256 seconds)
[09:26:39] *** Quits: dude12312414 (~test@gateway/tor-sasl/dude12312414) (Client Quit)
[09:28:23] <isekai-kujira> Hello. Are all complex algebraic varieties orbifolds? (Let's consider manifolds as a special case of orbifolds.)
[09:31:03] *** Quits: vftec (~8iIn0n@2a01:4b00:8e07:7900:904a:a590:3eb3:9890) (Quit: Leaving)
[09:31:03] *** Quits: Bilnon (~8iIn0n@2a01:4b00:8e07:7900:904a:a590:3eb3:9890) (Quit: Leaving)
[09:33:12] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[09:33:55] <isekai-kujira> Mmm, apparently not.
[09:35:10] *** Joins: dauggy (~wojtek@31.12.0.178)
[09:40:02] *** Quits: dauggy (~wojtek@31.12.0.178) (Client Quit)
[09:44:52] *** Joins: mendel_munkis (~mendel_mu@ool-ae2cb218.dyn.optonline.net)
[09:45:34] *** Quits: munkis (~mendel_mu@ool-ae2cb218.dyn.optonline.net) (Ping timeout: 260 seconds)
[09:49:50] *** Joins: munkis (~mendel_mu@ool-ae2cb218.dyn.optonline.net)
[09:50:11] *** Quits: mendel_munkis (~mendel_mu@ool-ae2cb218.dyn.optonline.net) (Ping timeout: 264 seconds)
[09:54:23] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 256 seconds)
[09:54:42] *** Joins: xelxebar (~xelxebar@aj173254.dynamic.ppp.asahi-net.or.jp)
[10:02:05] *** Quits: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[10:03:31] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[10:08:49] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[10:10:50] *** Joins: ertiportline (~ertiportl@user/ertiportline)
[10:13:05] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 256 seconds)
[10:23:47] *** Joins: Simplar (~Simplar@188.163.92.225)
[10:24:25] <Simplar> if u and v are given integers such that u >= 1, v >= 1, which form is the solution of the following equation? (vx+uy)(u+v)=uv(x+y)
[10:27:49] <Simplar> x/y = -(u^2)/(v^2) ?
[10:30:02] <greenbagels> yes
[10:30:34] <int-e> don't forget about x=y=0
[10:30:42] <greenbagels> or y = -(v/u)^2 x
[10:30:50] <greenbagels> a line with slope -(v/u)^2
[10:31:31] *** Joins: cvmn (~caveman@gateway/tor-sasl/caveman)
[10:33:39] *** Quits: Nognosis (~Nognosis@198.11.28.198) (Read error: Connection reset by peer)
[10:33:43] *** Quits: frelleck (~frelleck@user/frelleck) (Quit: Zoinx)
[10:33:57] *** Quits: Nitrousoxide (~msdos@user/nitrousoxide) (Remote host closed the connection)
[10:35:14] *** Joins: Nitrousoxide (~msdos@user/nitrousoxide)
[10:36:47] <Simplar> int-e: I wanted to not include 0;0
[10:37:02] *** Quits: bliminse (~bliminse@host86-185-253-43.range86-185.btcentralplus.com) (Quit: leaving)
[10:37:09] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[10:37:30] <int-e> Simplar: that's fine too, but you didn't say so
[10:37:35] *** Quits: i0e (~is0ke3@user/is0ke3) (Ping timeout: 268 seconds)
[10:39:21] *** Joins: bliminse (~bliminse@host86-185-253-43.range86-185.btcentralplus.com)
[10:39:36] *** Joins: i0e (~is0ke3@user/is0ke3)
[10:42:07] *** Joins: gthm (~gthm@ip-213-127-57-210.ip.prioritytelecom.net)
[10:43:12] *** Quits: cvmn (~caveman@gateway/tor-sasl/caveman) (Ping timeout: 276 seconds)
[10:46:08] *** Quits: Nitrousoxide (~msdos@user/nitrousoxide) (Quit: No Ping reply in 180 seconds.)
[10:47:23] *** Joins: Nitrousoxide (~msdos@user/nitrousoxide)
[10:50:16] *** Joins: sleeping_papaya (~sleeping_@86.106.143.10)
[10:53:59] *** Quits: qedders63 (~qedders@bzq-84-108-229-161.cablep.bezeqint.net) (Quit: Connection closed)
[10:54:16] *** Quits: sleeping_papaya (~sleeping_@86.106.143.10) (Ping timeout: 245 seconds)
[11:02:12] *** Joins: mbuf (~Shakthi@122.178.124.57)
[11:03:29] *** Quits: Trigo (~NeedMathH@64.201.115.44) (Ping timeout: 268 seconds)
[11:09:59] *** Joins: oxum (~oxum@122.172.47.114)
[11:11:37] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[11:14:31] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[11:14:50] *** isekai-kujira is now known as isekaijin
[11:15:09] <lpapp> W: thanks for sharing.
[11:17:54] *** Joins: oxum (~oxum@122.172.47.114)
[11:19:20] <W> no problem, it just frustrated me when I looked closer. In retrospect, they probably did it that way intentionally to obfuscate the runtime and show that a little analysis could demonstrate that two nested non-constant loops can still provide a result of degree one
[11:20:08] *** Quits: oxum (~oxum@122.172.47.114) (Remote host closed the connection)
[11:22:37] *** Joins: Macuser (~Macuser@216.30.159.201)
[11:23:04] *** Joins: oxum (~oxum@136.185.170.109)
[11:23:19] *** Quits: Macuser (~Macuser@216.30.159.201) (Client Quit)
[11:25:41] <lpapp> So, what is the point of the greedy algorithm? It helps improving the runtime complexity in certain cases by making optimal choices at each step?
[11:25:48] <lpapp> as opposed to checking each variation?
[11:25:54] *** Quits: gthm (~gthm@ip-213-127-57-210.ip.prioritytelecom.net) (Ping timeout: 260 seconds)
[11:28:08] *** Joins: Inline (~Inline@2a02:908:1252:7a80:9763:cc0b:5eaf:ee4)
[11:28:09] *** Quits: oxum (~oxum@136.185.170.109) (Ping timeout: 268 seconds)
[11:28:19] <W> a greedy algorithm is often something suboptimal that you do simply because an optimal algorithm seems intractable
[11:28:40] *** Quits: Inline (~Inline@2a02:908:1252:7a80:9763:cc0b:5eaf:ee4) (Remote host closed the connection)
[11:28:41] <W> but in this, and occasional other cases, it is one of the optimal algorithms
[11:29:54] <W> the whole thing about "making optimal choice presuming optimal choices have been made so far" is about proving that the greedy algorithm is optimal (when it is)
[11:30:14] *** Joins: Inline (~Inline@2a02:908:1252:7a80:9763:cc0b:5eaf:ee4)
[11:30:31] *** Joins: daoudr (~daoudr@xdsl-31-164-222-159.adslplus.ch)
[11:31:01] <lpapp> thanks
[11:33:59] <W> other ways is knowing a lower bound, and an analysis of the greedy algorithm having a runtime matching the bound (e.g. a problem of known O(n^2) is transformable to your problem in O(nlogn) time, and the greedy algorithm turns out to be O(n^2))
[11:34:20] *** Joins: takuan (~takuan@178-116-218-225.access.telenet.be)
[11:35:13] *** Joins: oxum (~oxum@136.185.170.109)
[11:39:29] <int-e> lpapp: If this is still about the canoeist example, that algorithm is exact, not an approximation. The heaviest canoeist has to sit somewhere, and any solution can be turned into one where they're paired with the heaviest canoeist that still fits into the same canoe
[11:39:33] *** Quits: oxum (~oxum@136.185.170.109) (Remote host closed the connection)
[11:39:56] <int-e> (or noone if there is no such canoeist)
[11:44:20] *** Joins: oxum (~oxum@136.185.170.109)
[11:44:47] <lpapp> I guess with the greedy algorithm, one needs to understand first whether it results in the right solution before applying?
[11:44:51] <lpapp> I.e. proving it first?
[11:45:45] <int-e> that's kind of true for all algorithms
[11:46:21] <W> if you don't need right solutions, you can just {return 0;} :p
[11:46:34] <W> (glossing over approximations and heuristics and such)
[11:47:14] <W> trying the obvious greedy algorithm is just a low-cost thing to do first to see if it actually is sufficient
[11:47:14] *** Quits: oxum (~oxum@136.185.170.109) (Remote host closed the connection)
[11:47:34] <W> (whether to real life performance goals, or analysis of asymptotic runtime)
[11:47:49] <lpapp> sounds good, thanks
[11:50:56] <W> well, I guess I put that a bit misleading; usually the question with greedy algorithms is indeed if it solves the problem or not (i.e. if the output is meeting requirements to be "the minimal" output/structure/number etc) not the runtime
[11:51:08] <W> if it is correct, its runtime is usually optimal too
[11:51:34] *** Quits: texasmusicinstru (~Rheanna@218.78.104.50) (Remote host closed the connection)
[11:53:07] *** Joins: texasmusicinstru (~Rheanna@61.171.38.68)
[11:54:22] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Remote host closed the connection)
[11:55:05] *** Quits: specing (~specing@user/specing) (Ping timeout: 256 seconds)
[11:55:51] <lpapp> Yes, thanks.
[11:56:01] <W> Are there any equivalents of "linear algebra done right" for calculus, integrals/derivations specifically? I get the sense I learned that stuff the "wrong way" too, memorizing rules for derivatives and antiderivatives, and still not having a good grip on how you can manipulate symbols like d, dx, etc
[11:56:33] *** Quits: x003fgqwe (uid479614@lymington.irccloud.com) (Quit: Connection closed for inactivity)
[11:57:17] <W> I see physicists write up their differential equations, moving d terms around like they're their own variables without a care, and I get easily lost (probably at least in part from the actual notation and its full implication not being established in my mind)
[11:58:04] *** Joins: specing (~specing@user/specing)
[12:00:58] <W> and I notice things I am entirely unfamiliar with, like exterior products
[12:02:16] *** Joins: Maturion (~Maturion@p200300ede72bd100580e6e7af78de52b.dip0.t-ipconnect.de)
[12:03:42] *** Quits: daoudr (~daoudr@xdsl-31-164-222-159.adslplus.ch) (Ping timeout: 260 seconds)
[12:04:01] <joel135> Some people say ... the geometric derivative is fundamental
[12:04:34] <joel135> https://en.m.wikipedia.org/wiki/Geometric_calculus
[12:04:36] *** Joins: palasso (~palasso@user/palasso)
[12:04:38] *** Joins: Turingtoast (~Tino@200116b8608bf2001497fb438a790c0d.dip.versatel-1u1.de)
[12:04:48] <joel135> I haven't really grokked it myself
[12:05:08] *** Joins: LucaTM (~LucaTM@user/lucatm)
[12:05:11] *** Quits: libsys (~libsys@186.105.159.91) (Remote host closed the connection)
[12:05:21] *** Joins: libsys (~libsys@186.105.159.91)
[12:05:26] <W> sure, but the people who say that, do they have a favoured textbook?
[12:07:16] *** Quits: Me-me (~me-me@user/me-me) (Quit: Disconnecting on purpose.)
[12:08:07] *** Quits: Turingtoast (~Tino@200116b8608bf2001497fb438a790c0d.dip.versatel-1u1.de) (Client Quit)
[12:08:41] <joel135> Don't think so. It doesn't seem fully canonized yet.
[12:11:04] *** Joins: Me-me (~me-me@v.working.name)
[12:11:26] *** Joins: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de)
[12:12:03] *** Quits: Me-me (~me-me@v.working.name) (Changing host)
[12:12:03] *** Joins: Me-me (~me-me@user/me-me)
[12:14:33] *** Joins: alzgh (~alzgh@user/alzgh)
[12:16:17] <lpapp> I wonder where the name "greedy" comes from.
[12:16:27] <lpapp> Is it because it is greedy to have the optimal choices?
[12:16:53] <int-e> it's greedy to pick the biggest thing first
[12:18:44] *** Joins: oxum (~oxum@136.185.170.109)
[12:19:16] *** Joins: rain3 (~rain3___@2a02:2f09:d10a:400:9e2f:eb47:e2ae:761d)
[12:19:51] <lpapp> I mean it does not have to be the biggest, right?
[12:20:07] <lpapp> optimal could be the smallest in some tasks, I thought?
[12:20:25] <W> lpapp, let's say the canoe problem is changed so a canoe can seat any number of people (as long as they still meet the weight requirement) - now the greedy algorithm is probably not going to work (the problem looks a lot more like/is equivalent to the knapsack problem)
[12:20:38] <int-e> lpapp: sure but you asked where the term comes from
[12:21:03] <lpapp> oh, it was originally invented for an issue with picking the greatest elements?
[12:21:26] <int-e> no, it is used in real life for people who always pick the biggest piece of the pie etc.
[12:23:31] <int-e> (I mean no, it wasn't invented. It was borrowed from real life and given a more abstract meaning.)
[12:23:44] *** Quits: oxum (~oxum@136.185.170.109) (Remote host closed the connection)
[12:24:04] *** Quits: memorye (~john@ool-457a36e7.dyn.optonline.net) (Remote host closed the connection)
[12:24:25] *** Joins: memorye (~john@ool-457a36e7.dyn.optonline.net)
[12:24:30] <lpapp> I am not sure greedy makes sense
[12:24:32] <int-e> And in that abstract setting, maximizing and minimizing are mostly the same (you just reverse an order to switch between those), so the term is applied to both.
[12:24:41] <lpapp> maybe, it should have been called optimal algorithm or so
[12:24:48] <W> (it would be the bin packing problem, and indeed it is np-hard and no greedy algorithm is going to work)
[12:24:56] <int-e> No, that term already has a meaning.
[12:25:20] <int-e> And greedy approaches aren't always optimal either.
[12:26:33] <lpapp> W: I am yet to learn about knapsack
[12:26:47] <lpapp> for some reason, codility does not have a lesson for that, so maybe not so common according to codility.
[12:26:47] *** Quits: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de) (Ping timeout: 264 seconds)
[12:27:16] <lpapp> ok, I understand, but greedy does not make much sense in terms of it is not always the biggest element.
[12:27:40] <lpapp> also, what I do not like about the term greedy is that the word has a negative connotation to it.
[12:27:57] <int-e> well as I said it's a matter of abstraction
[12:28:01] <lpapp> the person inventing it was probably a bit negative rather than coming up with a positive term :)
[12:28:12] <lpapp> but it does not abstract is what I am trying to say.
[12:28:21] <lpapp> it means a specific thing, but the real application is more abstract.
[12:28:45] <int-e> ??? ...whatever, I don't care.
[12:29:00] *** Joins: oxum (~oxum@136.185.170.109)
[12:29:11] <W> lpapp, okay, but the point is, you grab the heaviest/lightest person and put them in a canoe, and this works out to produce the right result (canoe count), but if the problem is modified a bit, you need to look at what other arrangements are possible, which would be a non-greedy algorithm; the greedy algorithm is specifically the one that selects for optimization of the immediate small subproblem and that might sabotage follow-up subproblems
[12:29:45] <lpapp> yes, that sounds like a good explanation, W.
[12:30:02] <lpapp> at least, I can relate to it.
[12:32:51] <lpapp> E.g. this is also greedy, but not necessarily picking the biggest: https://app.codility.com/programmers/lessons/16-greedy_algorithms/max_nonoverlapping_segments/
[12:33:51] *** Quits: oxum (~oxum@136.185.170.109) (Ping timeout: 245 seconds)
[12:33:52] <int-e> lpapp: Yes of course that happens. But this is greediness in the abstract setting of algorithms, not the real-life term.
[12:34:08] <lpapp> sorry, I only speak real life language.
[12:34:09] *** Joins: cvmn (~caveman@gateway/tor-sasl/caveman)
[12:34:12] *** Quits: cvmn (~caveman@gateway/tor-sasl/caveman) (Remote host closed the connection)
[12:34:19] <int-e> But it's still a real-life analogy that explains why this particular word was adopted.
[12:34:44] <lpapp> it is ok to respectfully disagree on this. I would have picked a different term myself for the reasons I outlined above.
[12:34:48] <int-e> Words change meaning when they enter slang.
[12:35:10] <int-e> lpapp: Yes, it is okay to be wrong.
[12:35:32] <int-e> It's still standard terminology and you are unlikely to change that.
[12:36:09] <lpapp> I am neither saying it is not standard (albeit incorrect and needlessly negative in my opinion), nor that I want to change that.
[12:36:28] * int-e should probably stop answering etymological questions like that
[12:36:37] <int-e> It never leads anywhere good.
[12:38:44] <lpapp> W: I assume that when I make a greedy algorithm decision, I also need to prove that it does not sabotage subtasks.
[12:39:29] <W> lpapp, k=16,W={7,6,5,4,4,2,2,2} for your canoe problem where you can seat more than two people in a canoe; greedy algorithm takes 7,6,2 (or 7,2,2,2, or 2,2,2,4,4) and puts them in a canoe, then the remaining people don't fit in another canoe, and the result is 3, but the actual answer is 2 (7 and 5 together in one canoe, the rest in another)
[12:39:55] <int-e> W: btw, I'm not sure whether you oversimplified this or whether you missed it: you do not grab the heaviest and lightest person and pair them.
[12:40:02] <W> lpapp, yes, but the point is there are cases where you can't prove that, because it doesn't; then an actual correct algorithm isn't greedy
[12:40:19] <W> int-e, there are two suggested solutions, A and B, B does that
[12:40:37] <int-e> well that doesn't work
[12:41:12] <W> *7,5,4
[12:41:38] <W> int-e, the reasoning seemed sound when I looked at it, but maybe I misunderstood indeed - I focused just on the A part
[12:41:38] *** Quits: texasmusicinstru (~Rheanna@61.171.38.68) (Remote host closed the connection)
[12:42:26] <lpapp> W: how do you mean? You can always prove with a test case?
[12:42:38] <W> lpapp, you can't prove false
[12:43:35] <lpapp> ?
[12:43:42] <W> if an algorithm looks beyond the immediate subproblem and picks so as not to sabotage the next pick(s), it is not a greedy algorithm, that's just what greedy algorithm means
[12:43:44] <int-e> W: Oh, sorry. Yes, it does work; I missed the reason why.
[12:43:47] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[12:43:53] <lpapp> You can give a test case for which the greedy algorithm does not work, e.g. 3-3 for the coin example in that pdf.
[12:44:47] <lpapp> what I am trying to say is that you need to prove or disprove the greedy algorithm either way if you look for an optimal solution, I think.
[12:45:13] <W> sure
[12:45:31] <W> but that's what you need to do for all algorithms, like int-e said
[12:45:34] <lpapp> disproving might be easier if you have a counter example.
[12:46:02] <lpapp> yes, true, but some algorithms do not need much proving.
[12:46:08] <lpapp> they are so simple.
[12:46:23] <int-e> So actually you could pick *any* canoeist and pair them with the heaviest other canoeist that fits into the same canoe (if there is one) and continue until you run out of canoeists... and that'll yield an optimal solution.
[12:46:34] <W> yep
[12:46:45] *** Quits: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com) (Read error: Connection reset by peer)
[12:46:50] *** Joins: NEYi (~NEYi@109.251.216.38)
[12:47:07] <int-e> Or, you could pick the heaviest canoeist and pair them with *any* canoeist that fits into the same canoe (if there is one), and continue like that, and it'll also give an optimal solution.
[12:47:09] <W> just having one or two people in each canoe simplifies the problem by a lot
[12:47:44] <int-e> And the correctness argument for the former (which I had) doesn't work for the latter. Hence my reaction that it wouldn't work... but it does.
[12:48:31] <int-e> . o O ( Absence of proof is not proof of absence. )
[12:49:02] *** Joins: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com)
[12:50:17] <W> lpapp, sometimes a greedy algorithm defies analysis too, sometimes you need to start at how to prove that a hypothetical algorithm is correct and work your way backwards from that to the actual algorithm
[12:50:55] <lpapp> ok, thanks.
[12:51:26] <W> (see: moving sofa problem)
[12:52:54] <lpapp> I will look that up soon, thanks for mentioning.
[12:54:11] <W> it's a complex and unsolved mathematical problem, where the best answer to date is from such an approach - but it's not really about algorithms
[12:57:09] *** Quits: frost (~frost@user/frost) (Quit: Connection closed)
[12:59:21] *** Joins: zava (~zava@ip5f5bdf0f.dynamic.kabel-deutschland.de)
[13:03:50] *** Joins: texasmusicinstru (~Rheanna@218.78.53.13)
[13:06:33] *** Quits: scara (~user@user/scara) (Remote host closed the connection)
[13:06:56] *** Joins: scara (~user@user/scara)
[13:07:38] *** Quits: pavlushka (~pavlushka@user/pavlushka) (Ping timeout: 256 seconds)
[13:08:46] *** qedders is now known as qed
[13:09:01] *** Quits: qed (~qedders@132.76.61.51) (Changing host)
[13:09:01] *** Joins: qed (~qedders@user/qed)
[13:10:51] *** Joins: oxum (~oxum@136.185.170.109)
[13:11:54] *** Quits: Inline (~Inline@2a02:908:1252:7a80:9763:cc0b:5eaf:ee4) (Quit: Leaving)
[13:18:14] *** Quits: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com) (Read error: Connection reset by peer)
[13:18:36] *** Joins: slidercrank (~slidercra@user/slidercrank)
[13:18:46] *** Joins: twJizhan (~twJizhan@223-139-136-210.emome-ip.hinet.net)
[13:20:01] *** Quits: oxum (~oxum@136.185.170.109) (Remote host closed the connection)
[13:20:13] *** Joins: oxum (~oxum@136.185.170.109)
[13:23:50] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[13:24:02] *** Joins: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com)
[13:24:48] *** Joins: CryptoDavid (uid14990@uxbridge.irccloud.com)
[13:29:10] *** Quits: Nitrousoxide (~msdos@user/nitrousoxide) (Ping timeout: 256 seconds)
[13:29:22] *** Joins: qu4nt1n (~qu4nt1n@78.198.214.34)
[13:31:37] *** Quits: texasmusicinstru (~Rheanna@218.78.53.13) (Remote host closed the connection)
[13:31:48] *** Joins: Nitrousoxide (~msdos@user/nitrousoxide)
[13:33:37] *** Quits: qu4nt1n (~qu4nt1n@78.198.214.34) (Client Quit)
[13:34:49] *** Joins: texasmusicinstru (~Rheanna@61.171.21.169)
[13:35:08] *** Quits: Simplar (~Simplar@188.163.92.225) (Quit: Going offline, see ya! (www.adiirc.com))
[13:38:43] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[13:39:23] *** Quits: xff0x (~xff0x@2001:1a81:52ad:7900:2980:608c:4201:500d) (Ping timeout: 264 seconds)
[13:40:12] *** Joins: xff0x (~xff0x@2001:1a81:52ad:7900:fdd2:161e:af5e:122)
[13:40:18] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[13:41:45] *** Quits: jmorris (uid433911@hampstead.irccloud.com) (Quit: Connection closed for inactivity)
[13:43:25] *** Joins: PJBoy (~PJBoy@user/pjboy)
[13:44:37] *** Joins: pavlushka (~pavlushka@user/pavlushka)
[13:46:03] *** Joins: Inline (~Inline@2a02:908:1252:7a80:b442:91f8:4666:206e)
[13:47:18] *** Quits: Fohsap_ (~Muimi@221.201.3.188) (Ping timeout: 260 seconds)
[13:49:41] *** Quits: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com) (Read error: Connection reset by peer)
[13:53:02] *** Joins: lakitu (~lakitu@192-198-3-9.dhcp.radiolinkinternet.com)
[13:58:30] *** Joins: red_owl (~red_owl@p5b23f9cd.dip0.t-ipconnect.de)
[14:06:49] *** Joins: dsrt^ (~dsrt@h50.174.139.63.static.ip.windstream.net)
[14:08:07] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[14:08:58] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Read error: Connection reset by peer)
[14:09:49] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[14:14:30] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 256 seconds)
[14:15:06] *** Joins: random-jellyfish (~random-je@user/random-jellyfish)
[14:15:27] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[14:20:42] *** Joins: TheHermann (~TheHerman@gateway/tor-sasl/thehermann)
[14:23:54] *** Quits: xff0x (~xff0x@2001:1a81:52ad:7900:fdd2:161e:af5e:122) (Ping timeout: 268 seconds)
[14:24:24] *** Joins: xff0x (~xff0x@2001:1a81:52ad:7900:8288:e51a:352c:7fbc)
[14:29:00] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[14:29:28] *** Quits: xff0x (~xff0x@2001:1a81:52ad:7900:8288:e51a:352c:7fbc) (Ping timeout: 268 seconds)
[14:32:11] *** Joins: trace987 (~trace@91.66.153.65)
[14:32:21] *** Joins: Jordy (~jordy@user/jordy)
[14:34:48] *** Joins: xff0x (~xff0x@2001:1a81:52ad:7900:8288:e51a:352c:7fbc)
[14:35:00] *** Joins: fweht (uid404746@lymington.irccloud.com)
[14:37:20] *** Joins: [-_-] (~fractal@user/---/x-1675478)
[14:41:42] *** Quits: twJizhan (~twJizhan@223-139-136-210.emome-ip.hinet.net) (Ping timeout: 256 seconds)
[14:46:08] *** Joins: daoudr (~daoudr@xdsl-31-164-222-159.adslplus.ch)
[14:50:12] *** Quits: scara (~user@user/scara) (Ping timeout: 276 seconds)
[14:50:45] <lpapp> is CLRS a good book to read for solving algorithm tasks?
[14:51:04] *** Joins: scara (~user@user/scara)
[14:54:58] *** Quits: firewyre (~firewyre@pool-71-184-153-62.bstnma.fios.verizon.net) (Ping timeout: 260 seconds)
[14:57:06] <qed> lpapp it is good for basic understanding lpapp
[14:57:16] <qed> it will help you in general
[14:57:22] <qed> so very recommended to read
[14:57:34] <qed> I believe in strong foundations
[14:58:40] <lpapp> nice, thanks, yeah, cause the other books suggested were CtCI, programming interviews exposed, etc, which are also good, but something more systematic would be good.
[14:59:04] <lpapp> I would do it alongside practicing on leetcode to also get practical, not just read.
[14:59:22] *** Joins: sleeping_papaya (~sleeping_@86.106.143.10)
[15:01:41] <qed> lpapp we had a course or two in college based on clrs
[15:01:53] <qed> If you can do the course while reading the book it would be very good for you
[15:01:59] <qed> or read the book and then do the course
[15:02:39] <qed> I am not a great fan of self education, I lack self-discipline for that
[15:03:19] <lpapp> which course?
[15:03:48] *** Quits: sleeping_papaya (~sleeping_@86.106.143.10) (Ping timeout: 256 seconds)
[15:03:54] *** Joins: KillAnimals (~anon@199-7-159-92.eng.wind.ca)
[15:04:33] <qed> data structures and then introduction to algorithms
[15:04:46] <lpapp> how can I do it?
[15:05:07] <qed> coursera perhaps lpapp?
[15:05:12] <qed> unless people here have better suggestion
[15:05:21] <qed> have you considered doing a degree in cs lpapp?
[15:06:07] <lpapp> I thought about a degree of applied mathematics or so, but it is challenging with a full-time job. I might do MBA, but that is not relevant :)
[15:06:18] <traxex> MIT has online courses that use CLRS
[15:06:35] <qed> that should be very nice traxex
[15:06:35] <traxex> well, course materials
[15:06:40] <qed> I thought about https://www.coursera.org/learn/algorithms-part1
[15:06:50] <qed> do not know if it is very good or not
[15:07:08] *** Quits: cheater (~Username@user/cheater) (Ping timeout: 246 seconds)
[15:07:19] <qed> lpapp with a full time job it is very hard yes
[15:07:27] <qed> it was not easy for me even without a job
[15:07:34] <lpapp> oh, I see, thanks.
[15:07:51] <lpapp> qed: yes, so evenings and weekends remain for practicing until I burn out :)))
[15:08:34] <qed> lpapp good luck my friend
[15:08:37] <qed> may it go well
[15:09:02] <qed> I will start my math marathon for today
[15:09:04] <lpapp> W: is the greedy algorithm not "primitive" in some ways? Like this: https://app.codility.com/programmers/lessons/16-greedy_algorithms/tie_ropes/
[15:09:07] <qed> every day new questions sigh
[15:09:22] <lpapp> :)
[15:09:24] <lpapp> thanks.
[15:09:30] <traxex> new questions sounds much better than the same question every day at least
[15:10:28] <qed> yes it is just that there is so much to learn
[15:10:57] *** Joins: cheater (~Username@user/cheater)
[15:10:58] <cherim> Proper MIT OCW sequence is
[15:10:59] <cherim> https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/
[15:11:05] <cherim> https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-046j-design-and-analysis-of-algorithms-spring-2015/
[15:11:11] <cherim> https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-854j-advanced-algorithms-fall-2008/
[15:11:16] <cherim> https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-851-advanced-data-structures-spring-2012/
[15:11:20] *** Quits: texasmusicinstru (~Rheanna@61.171.21.169) (Remote host closed the connection)
[15:11:39] <cherim> And they have a list of about 12 other courses as suggestions at the last lecture of 6.046
[15:11:41] <qed> we did data structures before algorithms cherim, is that outdated way to learn it already?
[15:12:32] <cherim> Maybe you mean that there is a programming course before any algorithms course
[15:12:59] <cherim> Then MIT has https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-0001-introduction-to-computer-science-and-programming-in-python-fall-2016/
[15:13:26] <qed> introduction to computer science is recommended yes
[15:13:36] *** Joins: mei (~mei@user/mei)
[15:13:38] <cherim> But overall the CLRS-based algorithms sequence starts with general algorithm construction techniques, not stacks/queues/...
[15:14:53] <cherim> I see they have a 2020 version of the course and it has Demaine but no Devadas
[15:15:02] *** Joins: src (~src@user/src)
[15:15:55] <cherim> https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-spring-2020/ Give me back Srini!
[15:17:51] *** Quits: Carbonflux (~Carbonflu@c-66-235-54-179.sea.wa.customer.broadstripe.net) (Quit: When all you have are solutions, everything is a problem.)
[15:19:20] *** Quits: rex_victor (~rex@2a02:8071:2291:b520:3285:a9ff:fe3a:67fa) (Quit: Bye)
[15:19:25] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 268 seconds)
[15:19:40] <riv> I feel like doing these course
[15:19:55] <riv> I was checking the other day and if I did 1 lecture a week it would take too long
[15:20:13] *** Joins: Trieste_ (T@user/pilgrim)
[15:20:38] *** Quits: Trieste (~T@user/pilgrim) (Ping timeout: 260 seconds)
[15:20:53] *** Quits: src (~src@user/src) (Quit: Leaving)
[15:21:06] <lpapp> I also need to plan theory vs. practice.
[15:21:15] <lpapp> not easy with a full-time job and other commitments, but I shall try.
[15:22:36] *** Quits: darkapex (~darkapex@user/darkapex) (Ping timeout: 245 seconds)
[15:23:08] <riv> i signed up on codility but it doesnt have rust, so I am using C++
[15:23:25] *** Joins: darkapex (~darkapex@user/darkapex)
[15:24:06] *** Trieste_ is now known as Trieste
[15:24:14] *** Quits: menace (~someone@user/menace) (Quit: menace)
[15:26:41] <cherim> Just noted this is not an #algorithms tab
[15:26:56] <cherim> Why isn't this an #algorithms tab?
[15:27:46] *** Quits: SyntaxError (~afP@194.87.46.214) (Read error: Connection reset by peer)
[15:30:04] *** Quits: TheHermann (~TheHerman@gateway/tor-sasl/thehermann) (Remote host closed the connection)
[15:30:26] *** Quits: cheater (~Username@user/cheater) (Ping timeout: 256 seconds)
[15:30:34] *** Joins: TheHermann (~TheHerman@gateway/tor-sasl/thehermann)
[15:31:37] *** Joins: rex_victor (~rex@HSI-KBW-095-208-219-086.hsi5.kabel-badenwuerttemberg.de)
[15:33:40] *** Joins: SyntaxError (~afP@194.87.46.214)
[15:34:24] *** Quits: mikoto-chan (~mikoto-ch@esm-84-240-99-143.netplaza.fi) (Ping timeout: 256 seconds)
[15:37:31] <lpapp> riv: hmm, odd, that they do not have rust.
[15:38:17] *** Quits: rex_victor (~rex@HSI-KBW-095-208-219-086.hsi5.kabel-badenwuerttemberg.de) (Quit: Bye)
[15:40:16] *** Joins: rex_victor (~rex@HSI-KBW-095-208-219-086.hsi5.kabel-badenwuerttemberg.de)
[15:42:23] *** Quits: somiaj (~somiaj@fvwm/admin) (Ping timeout: 264 seconds)
[15:46:12] <riv> https://twitter.com/mattmacauley/status/1459659847092293642
[15:46:17] *** Joins: cheater (~Username@user/cheater)
[15:47:14] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[15:47:37] *** Joins: somiaj (~somiaj@fvwm/admin)
[15:50:24] *** Joins: src (~src@user/src)
[15:52:37] *** Joins: cadmio (~cadmio@151.25.143.75)
[15:52:42] <cadmio> Hello
[15:53:08] *** Quits: caveman (~caveman@gateway/tor-sasl/caveman) (Quit: AA TOO NEE ZUBARALHADEEEEEEEEEEEED)
[15:53:40] <riv> hi
[15:54:04] *** Quits: wwilly (~wwilly@217.140.99.251) (Quit: Leaving)
[15:54:14] <cadmio> As a consequence of Sylow's theorems this seems to hold "Every subgroup of order 20 contains a normal subgroup"
[15:54:34] <cadmio> I'm not sure why is that
[15:54:54] *** Quits: KillAnimals (~anon@199-7-159-92.eng.wind.ca) (Quit: Konversation terminated!)
[15:55:05] <riv> Use n_p = 1 (mod p)
[15:55:20] <riv> 20 = 2^2 * 5
[15:55:26] <riv> so check p=2 and p=5
[15:55:52] <riv> and use: n_p | |G|/p^r
[15:57:09] *** Quits: TheHermann (~TheHerman@gateway/tor-sasl/thehermann) (Ping timeout: 276 seconds)
[15:58:24] <Z-module> you meant every group of order 20
[15:59:48] <cadmio> my text says "subgroup"
[16:00:02] *** Joins: caveman (~caveman@gateway/tor-sasl/caveman)
[16:00:12] <Z-module> that's a typo
[16:00:33] <cherim> Still true since not claimed to be proper
[16:01:08] <Z-module> Oh yeah. So the intended assertion is: If G is a group, and |G| = 20, then G has a normal subgroup other than 1 or G.
[16:01:37] *** Joins: royaljelly (~royaljell@user/royaljelly)
[16:02:07] *** Joins: texasmusicinstru (~Rheanna@218.78.94.61)
[16:02:29] <cadmio> I'm not sure whether the syslow subgroup of a finite group is unique
[16:02:41] <Z-module> not in general
[16:04:23] <cadmio> there's a theorem that states "any p-subgroup H of G is contained in a p-Sylow subgroup." if that subgroup is a sylow subgroup then how can you have more than one?
[16:04:26] <Z-module> cadmio, use the thing about p-Sylows being mutual conjugates to check:   G has a unique p-Sylow P  =>  P is normal in G.    A p-Sylow P is normal iff P is the unique p-Sylow.
[16:05:33] <Z-module> S_6 = {(), (1 2), (1 3), (2 3), (1 2 3), (1 3 2)} has three distinct 2-Sylows: {(), (1 2)}, {(), (1 3)}, {(), (2 3)}
[16:05:53] <cadmio> suppose K to be a p-Sylow subgroup. then if H ⊆ K and H is also a Sylow subgroup then H = K, isn't it?
[16:06:03] <Z-module> yes
[16:06:05] <cadmio> 'cause they have the same cardinality
[16:06:34] <Z-module> but there can be p-Sylows besides K. None of these others are subsets of K.
[16:06:36] *** Joins: pretty_dumm_guy (trottel@gateway/vpn/protonvpn/prettydummguy/x-88029655)
[16:07:15] *** Joins: savask (~savask@Powder/Developer/savask)
[16:07:31] <cadmio> ok
[16:07:59] <Z-module> If L is some *other* p-Sylow, then it's a p-subgroup, and "every p-subgroup is contained in some p-Sylow" is still true simply from  L \subset L
[16:08:01] <cadmio> so (number of Sylows) = 1 modulo p
[16:08:11] *** Quits: [-_-] (~fractal@user/---/x-1675478) (Ping timeout: 264 seconds)
[16:09:24] <Z-module> For each fixed prime p that divides |G|, a p-Sylow P is unique iff P is normal in G.
[16:10:56] <Z-module> (use the thing about p-Sylows all being mutual conjugates to get the <== direction of taht; the ==> direction is something more general: If H is the unique subgroup of G having size |H|, then H is normal)
[16:11:11] <cadmio> so my first proposition says take a finite group G and a subgroup H such that |H| = 20 then H contains a unique p-Sylow subgroup?
[16:11:31] <Z-module> This is quite weird, to be doing it with G lying above there
[16:11:45] <Z-module> it's really about H as a group all by itself
[16:12:39] <Z-module> Every group of order 20 does have a unique p-Sylow, for some prime p dividing 20.  Which you can quickly find.
[16:12:58] <cadmio> ok so that's a typo
[16:13:05] <Z-module> and then this unique p-Sylow is normal in H
[16:13:22] <cherim> Maybe there is some context like H containing a Sylow subgroup of G (say, |G|=60 implies every H with |H|=20...)
[16:13:29] <Z-module> so use the thing riv mentioned to check which p does this
[16:13:56] <cadmio> it's just "Every subgroup of order 20 contains a normal subgroup"
[16:14:17] <cherim> What text is this?
[16:14:26] <Z-module> plus the trivial thing we mentioned that if G is any group, its subgroups G and 1 are always normal, so hopefully they meant "besides G and 1"
[16:14:40] <cadmio> cherim: it has not been translated in English
[16:14:45] <cherim> OK...
[16:16:37] <Z-module> Eventually you might get to the massive exercise: If 1 < |G| < 60 and |G| is not prime, then G has a normal subgroup other than G and {e}.  (Earlier I was using "1" to denote {e}, but I've decided it's too confusing here.)
[16:16:48] <Z-module> That exercise is almost entirely done using Sylow
[16:16:57] <Z-module> along with some counting ideas
[16:17:55] <Z-module> well, along with stuff like groups of order p^2  (p prime) are abelian, I guess. I forget all the details it actually uses.
[16:17:56] <cadmio> so the only suitable p in this case is 5, and the number of distinct 5-Sylow subgroups is congruent to 1 modulo p and divides 4
[16:18:10] <Z-module> Right
[16:18:23] <Z-module> well, how did you rule out p = 2 being suitable?
[16:18:29] <cadmio> well In any case there only one suitable :) (which is the maximum)
[16:19:35] <cadmio> so we can have only 1, 2 or 4 of these 5-Sylow subgroups
[16:19:47] <Z-module> yes and?
[16:19:53] <riv> in fact it is equal to 1
[16:19:58] <Z-module> there you you
[16:20:04] <cadmio> the only congruent to 1 is 1
[16:20:09] <riv> well done
[16:20:10] <Z-module> unique 5-Sylow, so that 5-Sylow is normal
[16:20:18] *** Joins: darkapex_ (~darkapex@user/darkapex)
[16:20:26] <riv> cadmio: https://twitter.com/mattmacauley/status/1459659847092293642
[16:20:39] <riv> some nice examples of sylow theorems, diagrammed
[16:20:50] *** Joins: seninha (~seninha@user/seninha)
[16:21:04] *** Quits: darkapex (~darkapex@user/darkapex) (Ping timeout: 268 seconds)
[16:21:07] <cadmio> it is left as exercise that if there's a unique sylow that's normal
[16:21:46] <Z-module> cadmio: how did you decide p = 2 isn't "suitable"?
[16:22:39] <cadmio> 2-1 isn't divisible by 5
[16:22:44] *** Quits: madage (~madage@user/madage) (Remote host closed the connection)
[16:23:39] <Z-module> Let n_2 be the # of distinct 2-Sylows. So n_2 = 1 (mod 2) and n_2 | 5.  But this allows n_2 = 5 as a possibility.
[16:25:10] <Z-module> The Sylow-fact   n_p = 1 (mod p)    has to use the same prime p "on both sides"
[16:25:19] <cadmio> in this case p=2 is not a maximum power
[16:25:47] <Z-module> that Sylow-fact does talk about congruence mod p, *even* though the p-Sylows involved may have size larger than p
[16:25:58] *** Quits: andai (~andai@ip26-92-214-87.adsl2.static.versatel.nl) (Ping timeout: 260 seconds)
[16:26:15] <Z-module> it's just about mod p, regardless
[16:26:26] <cherim> Hard to get a normal 2-sylow by the congruence alone
[16:26:46] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) ()
[16:28:09] <Z-module> anyway, there are groups such as D_10 (of order 20) having non-normal 2-Sylows
[16:28:10] *** Quits: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net) (Remote host closed the connection)
[16:28:25] *** Joins: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net)
[16:28:35] <Z-module> but the exercise just wanted some normal p-Sylow without saying which p does it, and 5 does do it, as you saw
[16:29:47] *** Quits: sunny93 (~sunny93@wireguard/tunneler/sunny93) (Quit: The Lounge - https://thelounge.chat)
[16:30:39] *** Joins: sunny93 (~sunny93@wireguard/tunneler/sunny93)
[16:31:12] *** Joins: madage (~madage@user/madage)
[16:31:40] <cadmio> ok thanks see you
[16:31:42] *** Quits: cadmio (~cadmio@151.25.143.75) (Quit: WeeChat 3.0)
[16:32:25] *** Quits: cpuid (~cpuid@co5.at) (Quit: ZNC 1.8.2 - https://znc.in)
[16:32:43] <Z-module> Cute factoid I just found out:   Speaking of primes, one may think of Hensel's Lemma -- this is Kurt Hensel.  Today is the birthday of Mendelssohn's sister Fanny, who married painter Wilhelm Hensel and one of their grandchildren was Kurt.
[16:33:15] *** Joins: cpuid (~cpuid@co5.at)
[16:33:52] <riv> interesting set of links
[16:38:25] *** Joins: tomtomgps (~tom@2a01:cb1c:56f:a200:25ed:a2da:a455:9ad7)
[16:38:43] *** Quits: cheater (~Username@user/cheater) (Ping timeout: 265 seconds)
[16:43:55] <Z-module> I forgot that there are three nonabelian groups of order 20. Since all their 2-Sylows are abelian, and since they all have a normal 5-Sylow, all three groups must have non-normal 2-Sylow to avoid ending up as a direct product (some 2-Sylow) x (the 5-Sylow)  which would make the whole group abelian. So in all three cases, there are 5 distinct 2-Sylows. Good fact to know for use at parties and such.
[16:44:22] <Z-module> (the last answer on  https://math.stackexchange.com/questions/577917/find-four-groups-of-order-20-not-isomorphic-to-each-other       fully lays out how to get these three groups as semidirect products)
[16:45:00] <riv> I really like the power of semidirect products to do this stuff explicitly
[16:45:15] <Z-module> absolutely
[16:46:00] <riv> > (Source: Crazyproject)
[16:46:23] <riv> crazyproject was a blog someone did posting their solutions to dummit and foote, unfortunately it got shutdown so you need to use archive to see it now
[16:46:39] *** Quits: nf (~n@monade.li) (Quit: Fairfarren.)
[16:46:45] *** Quits: CatCow (~wtf_over@c-73-96-109-206.hsd1.or.comcast.net) (Quit: Textual IRC Client: www.textualapp.com)
[16:47:30] *** Joins: nf (~n@monade.li)
[16:51:19] *** Quits: texasmusicinstru (~Rheanna@218.78.94.61) (Remote host closed the connection)
[16:51:41] <tomtomgps> Hi I'm tryting to do question 1 here https://imgur.com/hAGba2Y   can someone help ?
[16:52:15] <tomtomgps> its in french so I can translate if you need
[16:52:46] <tomtomgps> from what I understand I have to show by induction for question 1. Start with R(t1,....tn)
[16:53:27] <tomtomgps> and then suppose it woprks with any formulae A an continue but it seems like theres is a lot of cases, is there somehting simp)àler i'm ,ot seeing ?
[16:56:29] <riv> what does 'sont derivables' mean?
[16:56:49] <Z-module> are differentiable
[16:56:53] <riv> so you have a function |-| that kind of dualizes, and you want to prove that A |- |A| ?
[16:56:56] <riv> that doesn't make sense
[16:57:09] <riv> oh wait, |-| is mutually recursive with ||-||
[16:57:59] <tomtomgps> it means we can we can construct  a tree proof from that given the hypothesis A  prooves |A| . This is usign the LK system.
[16:58:22] <tomtomgps> yes |-| is mutually recursive with ||-||
[16:58:36] <tomtomgps> I will send you the LK system
[16:58:52] <riv> yes it will require many cases
[17:00:10] <riv> the proof will follow the structure of the 2 mutual functions
[17:00:27] *** Parts: rapha (~jrs@user/rapha) (WeeChat 2.3)
[17:01:18] <tomtomgps> I want to start of with R(t1,...tn). This is immeidate because |R(t1,...tn)| = R(t1,...tn)
[17:02:31] <tomtomgps> here is the LK system https://imgur.com/GOIGe0G
[17:02:49] <tomtomgps> I can use axiom rule
[17:05:49] *** Joins: Everything (~Everythin@37.115.210.35)
[17:09:38] *** Joins: twJizhan (~twJizhan@223-139-136-210.emome-ip.hinet.net)
[17:11:53] *** Joins: Simplar (~Simplar@188.163.92.225)
[17:12:55] <Simplar> Does a series a+a^2+a^3+...+a^n have a name?
[17:12:55] *** Quits: takuan (~takuan@178-116-218-225.access.telenet.be) (Read error: Connection reset by peer)
[17:13:05] *** Joins: takuan (~takuan@178-116-218-225.access.telenet.be)
[17:14:28] <riv> geometric series, if you add 1
[17:15:14] <peterhil_> Simplar: Isn't that same as a^n!
[17:15:36] <Simplar> peterhil_: why should it be?
[17:15:47] <riv> it's 1/(1-a)
[17:15:48] <Simplar> riv: which b and q are here?
[17:15:49] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[17:15:58] <riv> i mean a^n/(1-a)
[17:16:03] <Simplar> oh
[17:16:24] <riv> sorry
[17:16:27] <riv> (1-a^n)/(1-a)
[17:17:23] *** Quits: mh_le (~mads@user/mh-le/x-4465771) (Remote host closed the connection)
[17:19:04] <peterhil_> Simplar: Oh nevermind, I need to finish my morning coffee. If the exponents were multiplications, then it would be a^n!
[17:20:22] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 256 seconds)
[17:20:23] *** Quits: kish` (~aqua@user/aqua) (Quit: Leaving)
[17:20:39] *** Joins: kish` (~aqua@user/aqua)
[17:20:52] *** Joins: cheater (~Username@user/cheater)
[17:21:55] *** Joins: tomeaton17 (~tomeaton1@51.195.150.49)
[17:23:34] *** Quits: kish` (~aqua@user/aqua) (Remote host closed the connection)
[17:23:55] *** Joins: kish` (~aqua@user/aqua)
[17:24:23] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[17:26:57] *** Joins: bosspotato (~bosspotat@lnsm2-montreal02-142-118-210-99.internet.virginmobile.ca)
[17:26:57] *** Quits: bosspotato (~bosspotat@lnsm2-montreal02-142-118-210-99.internet.virginmobile.ca) (Changing host)
[17:26:57] *** Joins: bosspotato (~bosspotat@user/bosspotato)
[17:27:40] *** Quits: pavlushka (~pavlushka@user/pavlushka) (Ping timeout: 268 seconds)
[17:29:24] *** Joins: Roughy (~mdaw45ns@user/roughy)
[17:30:05] <tomtomgps> I'm trying to do    not A |- |not A|  but I'm stuck
[17:30:37] <tomtomgps> |not A| = ||A||
[17:33:12] <riv> your induction hypothesis gives you A |- |A| in this case
[17:33:12] <pavonia> What is A? What is |.|?
[17:33:47] <riv> and you need to prove not A |- ||A||
[17:34:24] <riv> if this isn't do-able, perhaps strengthen the formula that you are trying to prove by induction
[17:34:43] <riv> you could try to prove:  A |- |A|  AND  not A |- ||A||
[17:34:45] <riv> maybe
[17:34:52] <riv> something like this will give you enough to make all the cases go through
[17:34:54] <pavonia> What notation is that?
[17:34:57] <riv> it
[17:35:00] <riv> 's formal logic
[17:36:58] <pavonia> So what does |.| denote?
[17:37:45] <riv> https://imgur.com/hAGba2Y
[17:38:23] <tomtomgps> hmm well A |- |A| is my hypothesis and  not A |- ||A|| is what i'm trying to prove since  |not A| = ||A||
[17:38:49] <tomtomgps> My issue here is I don't knows what to do with ||A||
[17:39:07] <tomtomgps> *i don't know*
[17:39:14] <riv> you'e currently doing a proof of: A |- |A|  by induction
[17:39:26] <riv> maybe try to prove: A |- |A| AND A |- ||A||  by induction, instead
[17:39:33] <tomtomgps> oh
[17:39:36] <pavonia> Oh, I didn't see the earlier discussion, sorry
[17:39:39] <riv> it's stronger, so you get a stronger induction hypothesis
[17:40:07] *** Joins: bpmedley_ (~bpmedley@2600:1700:e2c:8410:bc64:f93f:dcdb:8032)
[17:40:42] *** Joins: pavlushka (~pavlushka@user/pavlushka)
[17:42:55] <tomtomgps> what if  I suppose I have  A |- |A| and  |A| |- A  and not A  |-  ||A|| and  ||A||  |-  not A
[17:43:01] *** Quits: bpmedley (~bpmedley@2600:1700:e2c:8410:b850:1b43:885f:16e1) (Ping timeout: 245 seconds)
[17:43:12] <tomtomgps> would that be doable?
[17:47:06] <riv> it's hard to know without trying it out
[17:47:28] <riv> I wouldn't try a reverse polarity one like |A| |- A, at first
[17:48:00] *** Joins: Macuser (~Macuser@216.30.159.201)
[17:49:01] *** Joins: texasmusicinstru (~Rheanna@101.91.232.166)
[17:49:05] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[17:51:34] *** Joins: TheHermann (~TheHerman@gateway/tor-sasl/thehermann)
[17:54:47] *** Joins: JimmyRustles (~Haddock@cpc119394-smal16-2-0-cust17.19-1.cable.virginm.net)
[17:56:42] *** Quits: Ronnin (~Ronnin@23.83.184.132) (Quit: AndroIRC - Android IRC Client ( http://www.androirc.com ))
[18:01:37] *** Joins: availabled (~available@gateway/tor-sasl/availabled)
[18:02:20] *** Quits: availabled (~available@gateway/tor-sasl/availabled) (Client Quit)
[18:02:30] *** Joins: availabled (~available@gateway/tor-sasl/availabled)
[18:02:41] <Simplar> What is the minimum value of log_n (sqrt(2)) (n is the base of a logarithm) if n > 1?
[18:04:11] *** Joins: sokan_ (~sokan@2a02:587:9e19:b600:bf9b:c2e4:f632:62ce)
[18:04:40] *** Quits: sokan (~sokan@85.73.228.233) (Ping timeout: 268 seconds)
[18:04:40] *** sokan_ is now known as sokan
[18:04:44] *** Quits: gxt (~gxt@gateway/tor-sasl/gxt) (Quit: WeeChat 3.3)
[18:04:44] *** Quits: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[18:06:16] *** Joins: gxt (~gxt@gateway/tor-sasl/gxt)
[18:06:30] *** Joins: receiveyou (uid527141@hampstead.irccloud.com)
[18:07:01] <availabled> write log_n(sqrt(2)) = log(sqrt(2))/log(n)
[18:07:41] <Z-module> It turns out to be sort of trick question.
[18:08:03] <availabled> it has no answer because log is increasing
[18:12:07] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[18:15:36] *** Parts: receiveyou (uid527141@hampstead.irccloud.com) ()
[18:18:36] *** Joins: magla (~gelignite@55d41163.access.ecotel.net)
[18:20:09] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[18:20:54] <Simplar> http://mathb.in/67470
[18:20:59] <Simplar> This is where it comes from
[18:21:16] <Simplar> I'm trying to solve it somehow, but simply trying to transform the equation does not work well
[18:21:35] <Simplar> So I was trying majorant method
[18:23:28] <riv> that expression looks overcomplicated
[18:23:45] <Simplar> Do I need simplifying it before analysis?
[18:24:10] <riv> im not sure if it can be
[18:25:24] *** Joins: noord (~noord@user/noord)
[18:25:43] <Simplar> It can be riv
[18:25:47] <Simplar> Want me to link my thoughts?
[18:28:05] *** Joins: Vornicus (~Vornicus@2603-8000-5d07-7ef0-7c30-d6d4-cc96-be8a.res6.spectrum.com)
[18:29:22] <Simplar> http://mathb.in/67471
[18:29:24] *** Joins: arseniiv (~arseniiv@94.41.2.66.dynamic.ufanet.ru)
[18:29:57] *** Quits: Maturion (~Maturion@p200300ede72bd100580e6e7af78de52b.dip0.t-ipconnect.de) (Ping timeout: 268 seconds)
[18:31:29] <Z-module> greenbagels: on the nested closed sets thing, even being in a complete metric space and having *bounded* closed nonempty sets K_1 \supset K_2 \supset K_3 ...  isn't enough to get nonempty intersection. Take R with the standard bounded metric d(x,y) = min{|x - y|, 1}, and K_n = [n, +infty) for each n.  So if you're avoiding the diam -> 0 condition, you need something like one of the K_m being compact. But then each later K_j is a closed
[18:31:29] <Z-module> subset of the compact space K_m, and the collection {K_m, K_(m+1), K_(m+2), ...} has the finite intersection property in the compact space K_m, so that alone gets their intersection being nonempty.
[18:31:45] *** Quits: Decker (~d3x0r@user/d3x0r) (Read error: Connection reset by peer)
[18:32:03] *** Joins: Decker (~d3x0r@ip68-96-102-241.lv.lv.cox.net)
[18:34:06] *** Quits: oxum (~oxum@136.185.170.109) (Remote host closed the connection)
[18:34:19] <Simplar> In my last link, I've made use of a+1/a >= 2 when a > 0
[18:38:37] *** Joins: oxum (~oxum@136.185.170.109)
[18:39:38] *** Quits: twJizhan (~twJizhan@223-139-136-210.emome-ip.hinet.net) (Read error: Connection reset by peer)
[18:40:00] *** Joins: twJizhan (~twJizhan@223-139-136-210.emome-ip.hinet.net)
[18:40:48] *** Joins: twJizhan2nd (~twJizhan@223-139-136-210.emome-ip.hinet.net)
[18:41:47] <cherim> Should be x=5pi/4+2pi k or such
[18:42:44] *** Quits: twJizhan (~twJizhan@223-139-136-210.emome-ip.hinet.net) (Killed (NickServ (GHOST command used by twJizhan2nd)))
[18:42:56] *** twJizhan2nd is now known as twJizhan
[18:43:10] *** Quits: oxum (~oxum@136.185.170.109) (Ping timeout: 260 seconds)
[18:44:03] *** Joins: xkuru (~xkuru@user/xkuru)
[18:45:05] *** Quits: TheHermann (~TheHerman@gateway/tor-sasl/thehermann) (Remote host closed the connection)
[18:45:40] *** Joins: TheHermann (~TheHerman@gateway/tor-sasl/thehermann)
[18:45:55] <Simplar> cherim: why?
[18:46:13] <cherim> Too many symbols to type :)
[18:47:13] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[18:47:40] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Client Quit)
[18:47:42] <cherim> -(a+1/a)/2 on one side with values in (-inf, -1] and 4^{sqrt(2)sinx}+4^{sqrt(2)cosx} estimated from blow by Cauchy to make another side take values in [-1, +inf)
[18:48:00] *** Quits: CryptoDavid (uid14990@uxbridge.irccloud.com) (Quit: Connection closed for inactivity)
[18:48:22] <cherim> Common -1 value implies sinx+cosx attains minimum = -sqrt(2)
[18:49:39] <cherim> It's the most remote from mathematics thing that is present in school math curriculum (seemingly in many contries)
[18:50:01] *** Joins: fbiagent_ (~fbiagent@user/fbiagent)
[18:50:11] *** Quits: fbiagent (~fbiagent@user/fbiagent) (Ping timeout: 264 seconds)
[18:51:41] <cherim> Any normal mathematician/physicist who gets log_{(tan^4+1)^2} in real computations must feel "I am doing something wrong, should abandon this direction, this should never happen", not utilize knowledge of how to proceed
[18:56:54] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[18:58:26] *** Quits: memorye (~john@ool-457a36e7.dyn.optonline.net) (Ping timeout: 245 seconds)
[18:58:26] <[itchyjunk]> "As an example, consider the polynomial x2 + xy and the finite field with just two elements, 0 and 1. This polynomial has value 1 when x = 1 and y = 0, but it has value 0 for the other three possible combinations of x and y"
[18:58:35] <[itchyjunk]> if x,y = 1, isn't it 2?
[18:58:41] <[itchyjunk]> its x^2 + xy
[18:58:50] <[itchyjunk]> https://www.quantamagazine.org/mathematicians-find-structure-in-biased-polynomials-20211109/
[18:59:10] <savask> [itchyjunk]: 2 = 0 in a field of order 2
[18:59:11] *** Joins: memorye (~john@ool-457a36e7.dyn.optonline.net)
[18:59:22] *** Joins: enoq (~enoq@194-208-178-35.lampert.tv)
[18:59:52] <Z-module> this field is F_2, GF(2), Z/2Z,  pick your notation
[19:00:31] <[itchyjunk]> savask, oh :<
[19:01:25] *** Joins: Turingtoast (~Tino@200116b8608bf200e12ae8befb8c6bf3.dip.versatel-1u1.de)
[19:02:52] *** Quits: magla (~gelignite@55d41163.access.ecotel.net) (Quit: Stay safe!)
[19:03:02] *** Quits: availabled (~available@gateway/tor-sasl/availabled) (Quit: leaving)
[19:03:36] <twJizhan> hi Z-module
[19:04:17] <twJizhan> Z-module: IIRC you said your favorite analysis book is Carothers' "Real Analysis"
[19:04:18] <Z-module> hi twJizhan
[19:04:36] <Z-module>  well, favorite of the ones that cover that particular material, but yes
[19:05:22] <[itchyjunk]> If elements of vector spaces are called vectors, are elements of hilbert spaces called hilberts?
[19:05:24] <twJizhan> Z-module: Could you recommend a prerequisite/corequsite book to Carothers' ?
[19:05:49] <Z-module> twJizhan: hmm, hard to think of. Maybe a basic work on metric spaces.
[19:06:01] <savask> [itchyjunk]: Some 1000IQ thinking
[19:08:11] <riv> lolol
[19:08:27] *** Quits: Decker (~d3x0r@ip68-96-102-241.lv.lv.cox.net) (Changing host)
[19:08:27] *** Joins: Decker (~d3x0r@user/d3x0r)
[19:08:48] <Z-module> twJizhan: but Carothers is quite self-contained, I would say.
[19:09:30] <[itchyjunk]> well i kinda wanted to know if they had a name. like psi(x,t) the wave function of a particle is an element of some hilbert space.
[19:09:32] <Z-module> It does help if you have some comfort with basic topology in a metric context, and with normed vector spaces. But you don't need very much.
[19:09:37] <Z-module> (that was for twJizhan )
[19:09:45] <[itchyjunk]> :s
[19:11:28] <[itchyjunk]> Guess no one bothered namthing things past vector space structure
[19:12:06] <riv> [itchyjunk]: hilbert spaces are a special kind of vector space, so they are vectors
[19:12:48] <twJizhan> Amazon.com says that "The way of analysis" and "baby Rudin" are frequently bought together https://www.amazon.com/dp/0763714976/
[19:12:49] *** Joins: beencubed (~beencubed@209.131.238.248)
[19:12:51] <[itchyjunk]> hmm fields are special kind of rings but elements of fields are scalars but not ring right?
[19:13:31] <twJizhan> this Amazon.com info probably somehow valuable
[19:13:50] <Z-module> elements of fields *in general*, on their own, aren't too often called scalars. That word is really just in the case of the field that a given vector space is over.
[19:14:04] <[itchyjunk]> oh
[19:21:34] *** Quits: texasmusicinstru (~Rheanna@101.91.232.166) (Remote host closed the connection)
[19:24:15] *** Joins: texasmusicinstru (~Rheanna@218.78.67.149)
[19:24:28] *** Joins: Trigo (~NeedMathH@64.201.115.44)
[19:27:59] *** Quits: memorye (~john@ool-457a36e7.dyn.optonline.net) (Ping timeout: 264 seconds)
[19:29:06] *** Joins: gb73d (gb73d@host-92-7-42-10.as13285.net)
[19:33:14] *** Joins: memorye (~john@ool-457a36e7.dyn.optonline.net)
[19:34:43] *** Joins: jero98772 (~jero98772@2800:484:1d80:d8ce:3490:26c5:1782:da8c)
[19:35:39] *** Joins: Julian (~tos9@python/site-packages/Julian)
[19:36:56] *** Quits: xelxebar (~xelxebar@aj173254.dynamic.ppp.asahi-net.or.jp) (Quit: WeeChat 3.3)
[19:44:41] *** Joins: audiobirb (~audio@user/audio)
[19:44:44] <JimmyRustles> hi guys
[19:45:03] <JimmyRustles> if i typed a 9129-word document in 55 minutes, does that work out to 9129 / 55 = 165.98 words per minute?
[19:45:24] *** Joins: robin__ (~robin@user/terpri)
[19:45:29] *** Joins: martingale (~martin@2601:42:0:3660::a99)
[19:46:35] *** Quits: robin (~robin@user/terpri) (Ping timeout: 264 seconds)
[19:47:32] *** Quits: enoq (~enoq@194-208-178-35.lampert.tv) (Quit: enoq)
[19:49:10] *** Quits: robin__ (~robin@user/terpri) (Client Quit)
[19:49:27] *** Joins: robin (~robin@user/terpri)
[19:50:09] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[19:52:32] *** Joins: LTCD (~LTCD@2a02:c7f:dd1c:b600:f9f7:94ca:eb42:a635)
[19:52:53] <[itchyjunk]> it works out to 9129/55 per minute, yes
[19:53:36] <[itchyjunk]> 9129/(55*60) works per second.
[19:54:17] <LTCD> Hey people. I am studying basic probability, and I understand that the probability of picking something in the sample space S is equal to one, that is P(S) = 1. However, when I follow the equation in this picture with k=1 my answer is 0.5 not 1. I assume I have done something wrong. https://ibb.co/gV5yjv2
[19:54:57] <LTCD> Like assume it goes from k=1 to just 1, and not any further. It was just a simple example to check the numbers work.
[19:55:34] <LTCD> Even if I do k=1 to 4 then my output appears to be 0.125 when it should be 1?
[19:55:57] <[itchyjunk]> for a coin flip, the sample space would have P of heads and P of tails, each 1/2 and their sum to 1
[19:56:12] <[itchyjunk]> i.e your space has to contain all possibilities
[19:56:19] <[itchyjunk]> maybe you are not considering all of them?
[19:57:22] <LTCD> [itchyjunk] Oh, so setting my sample space to 1 was stupid, because a coin 2 sides?
[19:57:43] <LTCD> [itchyjunk] Also, setting my sample space to 4 is stupid because a coin has only 2 sides?
[19:58:03] *** Quits: seninha (~seninha@user/seninha) (Remote host closed the connection)
[19:58:09] <[itchyjunk]> hmm, i am not sure. if your sample space has probability for head, tails and landing on side
[19:58:18] <[itchyjunk]> then the sum of heads and tails might not be 1
[19:58:29] <[itchyjunk]> is the prob of landing on it's side is non 0
[19:58:43] *** Joins: magla (~gelignite@55d41163.access.ecotel.net)
[19:58:53] <[itchyjunk]> 1 is the are under the entire curve
[19:58:56] <[itchyjunk]> area*
[19:59:09] *** Joins: menace (~someone@ppp-93-104-164-149.dynamic.mnet-online.de)
[19:59:10] <LTCD> Basically, in that picture I need to replace the infinity symbol with the maximum length of my sample space, so in the case of a coin that only lands on heads or tails it's 2.
[19:59:32] *** Quits: menace (~someone@ppp-93-104-164-149.dynamic.mnet-online.de) (Changing host)
[19:59:32] *** Joins: menace (~someone@user/menace)
[19:59:34] <LTCD> ?*
[19:59:49] <[itchyjunk]> Unfortunately, i am poor with probability. so i don't really understand what's happening in that picture
[20:02:25] <cherim> For the picture it coul dhelp if the definition of A_k was given
[20:02:30] *** Joins: seninha (~seninha@user/seninha)
[20:03:04] *** Quits: fbiagent_ (~fbiagent@user/fbiagent) (Ping timeout: 268 seconds)
[20:03:09] <cherim> It looks like "in a series of coin tosses, the first heads is on k-th toss" or such
[20:07:58] *** Joins: fbiagent (~fbiagent@user/fbiagent)
[20:08:37] <LTCD> cherim No, it's the formula to show that the P(S) =1.
[20:08:44] <LTCD> Formal to show probability of sample space is 1.
[20:09:11] <LTCD> I am struggling to find an example where I can plug numbers into that equation to make it equal one. Like I used a fair 6 sided die to no avail.
[20:09:15] *** Quits: fweht (uid404746@lymington.irccloud.com) (Quit: Connection closed for inactivity)
[20:09:38] <[itchyjunk]> well even if it is a formula, the terms need to be defined
[20:09:47] <cherim> What is A_k and why is P(A_k)=1/2^k?
[20:09:50] *** Quits: random-jellyfish (~random-je@user/random-jellyfish) (Ping timeout: 256 seconds)
[20:09:55] <LTCD> cheater https://www.coursera.org/learn/probability-theory-foundation-for-data-science/lecture/Y0Amk/axioms-of-probability
[20:10:00] <LTCD> cherim *
[20:11:01] <cherim> They literally say "Flip a coin until the first tail appears"
[20:11:16] <cherim> In Example 1
[20:11:24] *** Quits: texasmusicinstru (~Rheanna@218.78.67.149) (Remote host closed the connection)
[20:11:58] <LTCD> Okay?
[20:12:12] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[20:12:32] <cherim> So P(A_k)=1/2^k is OK, as well as sum_{k=1}^inf 1/2^k=1
[20:12:34] *** Joins: Hercules (~Hercules@user/hercules)
[20:13:18] *** Joins: texasmusicinstru (~Rheanna@218.78.79.129)
[20:13:24] <cherim> And A_k are mutually exclusive, and their union is almost all space of events (they omit "tail never appears", perhaps they mention it has probability 0 somewhere)
[20:13:45] <LTCD> So what does sample space S contain then?
[20:14:03] <cherim> Sequences like {T, HT, HHT, HHHT, ....}
[20:14:10] *** Quits: trace987 (~trace@91.66.153.65) (Ping timeout: 268 seconds)
[20:14:43] <cherim> Oh, they also have it in the video, just with 0/1 instead of H/T
[20:15:12] *** Joins: dude12312414 (~test@gateway/tor-sasl/dude12312414)
[20:15:29] *** Parts: savask (~savask@Powder/Developer/savask) ()
[20:17:32] <LTCD> I do not get how that equals one though in that formula.
[20:18:03] <cherim> It's a sum of a geomertic series 1/2+1/4+1/8+...
[20:18:36] <LTCD> You mean 1/6 not 1/8 right?
[20:18:44] <cherim> There is a lot of ways to see the limit is 1, but you can simply claim by induction that 1/2+1/4+...+1/2^n = 1-1/2^n
[20:19:07] <mornfall> it would not converge if it continued 1/6 (i.e. ∑1/2n)
[20:19:40] <cherim> It would also not converge if it were 1+2+4+8+..., but why does it matter
[20:19:57] <mornfall> cherim: because LTCD thought it should be 1/6
[20:21:21] *** Joins: trace987 (~trace@ip5b429941.dynamic.kabel-deutschland.de)
[20:23:06] *** Quits: tct_ (~tct@8.200.173.83.static.wline.lns.sme.cust.swisscom.ch) (Quit: ZNC 1.8.2 - https://znc.in)
[20:25:08] *** Quits: Macuser (~Macuser@216.30.159.201) (Quit: Textual IRC Client: www.textualapp.com)
[20:26:59] <[itchyjunk]> <LTCD> You mean 1/6 not 1/8 right?
[20:27:05] <[itchyjunk]> 1/2^k
[20:27:45] <LTCD> Ah, because it's 2 to the power of k it's impossible to get 6.
[20:32:43] *** Quits: dude12312414 (~test@gateway/tor-sasl/dude12312414) (Quit: THE RAM IS TOO DAMN HIGH)
[20:33:15] *** Joins: tct (~tct@8.200.173.83.static.wline.lns.sme.cust.swisscom.ch)
[20:33:20] <mycroftiv> LTCD: this is a good place to anchor your understanding to how things actually work physically, a sequence of n+1 constant flip outcomes is always half as likely as n constant flips, and the chance of infinite constant flips should 'vanish'
[20:39:19] <andi_> can somebody help me understand please: if i have a word w ∈ Σ*. a prefix of w is u ∈ Σ* so that a word w' ∈ Σ* exists with uw'=w. let also prefix(w) be the set of all prefixes of w. show that for all n ∈N: |w|= n => |prefix(w)|= n + 1
[20:40:11] *** Joins: dez (uid92154@user/dez)
[20:40:53] <[itchyjunk]> Oh, formal system stuff? interesting
[20:41:19] <andi_> i'd use induction as a proof. so for w = a i have |prefix(w)| = 2 which is true.
[20:41:37] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[20:41:44] <andi_> oh and of course i forgot w = a => |w| = 1
[20:43:21] <andi_> so now i add a letter to my word.. i changed the notation to |w^n| = n where n is the number of letteres used, so i get the equation |w^(n+1)| => n+1
[20:43:37] <andi_> but i'm pretty stuck with the set of prefixes
[20:44:24] *** Quits: LTCD (~LTCD@2a02:c7f:dd1c:b600:f9f7:94ca:eb42:a635) (Quit: Client closed)
[20:46:40] *** Joins: nick222 (~nick222@internet-178-58-211-226.narocnik.mobitel.si)
[20:47:14] <nick222> can anyone recommend a book that covers:
[20:48:28] <nick222> differential equations, 1st order diff equations, n-th order diff equations and systems of 1st order linear, qualitative analysis of dynamical systems
[20:48:59] <nick222> and calculus of variations
[20:49:11] <andi_> here would be an example of my words and prefixes https://paste.xinu.at/ugs/
[20:52:02] *** Joins: enoq (~enoq@194-208-178-35.lampert.tv)
[20:53:31] *** Quits: jess (~jess@libera/staff/jess) ()
[20:54:23] *** Quits: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Ping timeout: 264 seconds)
[20:54:58] *** Joins: gthm (~gthm@ip-213-127-57-210.ip.prioritytelecom.net)
[20:55:17] <somiaj> nick222: here are some OEM books, https://www.jirka.org/diffyqs/html/diffyqs.html and http://faculty.sfasu.edu/judsontw/ode/html-20200801/odeproject.html
[20:55:40] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[20:56:41] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[20:58:04] *** Joins: palasso (~palasso@user/palasso)
[20:58:04] *** Quits: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi) (Remote host closed the connection)
[20:58:07] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[20:58:17] *** Joins: peterhil_ (~peterhil@dsl-hkibng32-54fb56-2.dhcp.inet.fi)
[20:59:32] <nick222> somiaj: those look nice thanks
[21:01:18] *** Quits: Trigo (~NeedMathH@64.201.115.44) (Ping timeout: 260 seconds)
[21:01:19] *** Quits: texasmusicinstru (~Rheanna@218.78.79.129) (Remote host closed the connection)
[21:02:57] *** Joins: texasmusicinstru (~Rheanna@218.78.104.50)
[21:07:11] *** Quits: specing (~specing@user/specing) (Ping timeout: 245 seconds)
[21:09:01] *** Joins: chomwitt (~chomwitt@2a02:587:dc12:3f00:12c3:7bff:fe6d:d374)
[21:09:25] <twJizhan> oh
[21:09:39] <twJizhan> it's 1:39 AM in Taiwan
[21:12:07] *** Quits: Hercules (~Hercules@user/hercules) (Quit: Leaving)
[21:12:59] <twJizhan> well IIRC it used to be an antidepressive time in ##math - many interesting topics were disscussed at this time in ##math
[21:13:29] <mycroftiv> twJizhan: whats a topic that interests you in math, currently?
[21:13:35] *** Quits: i0e (~is0ke3@user/is0ke3) (Ping timeout: 264 seconds)
[21:14:16] <twJizhan> is 0.999.... = 1 ? @@
[21:15:58] *** Joins: i0e (~is0ke3@user/is0ke3)
[21:16:12] <twJizhan> I don't know why this ^ is a frequently debated topic in Mandarin Facebook math groups... @@
[21:16:48] <somiaj> Because most don't know what 0.99999.... even means, once you know what it means, you can then ask if it is equal to 1 or not
[21:16:55] <mycroftiv> im trying to understand https://en.wikipedia.org/wiki/Jones_polynomial and some other things in knot theory. people do debate that infinite-decimal equality a lot, everywhere.
[21:17:34] <tolarz> i second somiaj
[21:17:59] <tolarz> most don't even know what real numbers are.
[21:18:39] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[21:18:51] <somiaj> that is a bit more understandable, real numbers are a bit bizzar due to completness, most only experience the computable numbers anyways.
[21:19:00] <mycroftiv> that, arguing whether cantor's diagonal argument works or not, misunderstanding Gödel, throwing 'halting problem' at unrelated issues in programming - the classic pitfalls of amateur logic
[21:19:12] *** Quits: joilerv (~joilerv@host86-191-93-41.range86-191.btcentralplus.com) (Quit: Textual IRC Client: www.textualapp.com)
[21:19:32] <Franciman> thanks mycroftiv for reminding me I still do all of those
[21:19:34] <Franciman> ^^
[21:19:44] <tolarz> andi_: induction sounds fine
[21:20:00] <andi_> tolarz: i just have no idea on how to start :/
[21:20:07] <tolarz> andi_: you already provided the bases case correctly
[21:20:13] <riv> the jones polynomial is cool
[21:20:42] <andi_> tolarz: yeah. the base case was correct. but my induction step is sadly not even existing
[21:21:00] <tolarz> We prove |prefix(w)| = |w| + 1 by induction on |w|. For |w| = 0 we have w = epsilon and prefix(w) = {epsilon}, a set of size 1. Donee.
[21:21:20] <mycroftiv> riv: im just starting out in all this knot theory stuff, got dragged into it via 4manifolds, but im really just learning the vocabulary and notation and concepts at this point, big stretch relative to my logic background
[21:21:30] *** kfv_ is now known as kfv
[21:21:34] <tolarz> Now consider |w| = n + 1. Try to simplify prefix(w).
[21:21:53] <tolarz> Hint: split w into the first part of length n and the last character.
[21:22:04] *** Joins: oxum (~oxum@136.185.170.109)
[21:22:58] *** Quits: oxum (~oxum@136.185.170.109) (Client Quit)
[21:23:16] <andi_> tolarz: but how do i write that?
[21:24:10] <tolarz> Write w = uv with |u| = n, |v| = 1. Then prefix(w) ...
[21:24:14] <tolarz> Write w = uv with |u| = n, |v| = 1. Then prefix(w) = ...
[21:25:09] <mycroftiv> although i also got dragged into a bit of braid theory from laver tables in set theory, and the adjacency of knots/braids conceptually is another reason i want to *cough* tie all this together
[21:25:26] <tolarz> weren't you in cubical type theory and wanted something with ultrafilters?
[21:25:29] <tolarz> how did you get into knot theory now?
[21:25:42] <andi_> tolarz: prefix(w) = |u| = n + prefix(v)?
[21:25:43] *** Quits: FragmentedCurve (~FC@pool-100-2-232-17.nycmny.fios.verizon.net) (Quit: leaving)
[21:25:49] <tolarz> prefix(w) is a set
[21:25:52] <tolarz> |u| is a scalar
[21:25:55] <tolarz> They cannot be equal
[21:26:02] *** Joins: Trigo (~NeedMathH@64.201.115.44)
[21:26:10] <mycroftiv> tolarz: im still into all that, ultrafilters = forcing, and i read a theorem that forcing relates to casson handles, and casson handles are 4 manifold topology and it has a translation to knot theory in 3d!
[21:26:23] <andi_> you're right tolarz |prefix(w)| = |u| = n
[21:26:32] <tolarz> how do you argue that?
[21:26:40] <tolarz> in fact, if that were true, the theorem would be unprovable (because it would be wrong)
[21:27:01] <andi_> well wasn't u the prefix?
[21:27:01] <tolarz> (well only unprovable if ZF is consistent, but I digress)
[21:27:21] <tolarz> please concretize your question.
[21:27:35] *** Joins: econo (uid147250@user/econo)
[21:28:09] <mycroftiv> also laver tables = large cardinal elementary embeddings = ultrafilters, and laver tables are about the left self distributive algebra that corresponds to redemesiter III moves in braid theory
[21:28:49] <andi_> w = uv with |u| = n, |v| = 1, so if the word w has n+1 letters. |u| is the cardinality of the prefix
[21:29:17] *** Quits: kish` (~aqua@user/aqua) (Remote host closed the connection)
[21:29:21] <tolarz> yes.
[21:29:24] <tolarz> carry on.
[21:29:38] *** Joins: kish` (~aqua@user/aqua)
[21:29:41] <tolarz> mycroftiv: interesting relations
[21:30:01] *** Joins: Koen (~Koen@217.252.88.92.rev.sfr.net)
[21:30:31] *** Quits: gthm (~gthm@ip-213-127-57-210.ip.prioritytelecom.net) (Ping timeout: 245 seconds)
[21:30:32] <mycroftiv> tolarz: yes, i barely understand all this, but its all published peer reviewed papers that allow this chain of connections between ultrafilters in set theoretic logic, 4manifold topology, knot/braid theory
[21:30:35] <tolarz> andi_: anyway, i want to go afk now. I hope somebody else helps you.
[21:30:44] <andi_> tolarz: i don't know how to argue further
[21:30:59] <tolarz> tolarz | Write w = uv with |u| = n, |v| = 1. Then prefix(w) = ...
[21:31:02] <tolarz> this is the best hint so far.
[21:31:09] <tolarz> i hope somebody picks it up.
[21:31:50] <andi_> tolarz: thanks anyway and bye, see you soon.
[21:32:09] <andi_> i'll think of it a bit, and maybe somebody will guide further
[21:34:47] *** Joins: biberao (~m@user/biberao)
[21:34:49] <biberao> hi
[21:38:39] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[21:41:45] <andi_> tolarz: can i agrue that Then |prefix(w)| = |prefix(uv)| = |u| + |prefix(v)| and from my induction i know that |prefix(w)| = n + 1 with |w| = n, i know by definition that |v| = 1 => |prefix(v)| = 1 + 1 so i have |u| + 2 and |u| = n
[21:43:01] *** Quits: twoisprime (~twoisprim@user/twoisprime) (Ping timeout: 245 seconds)
[21:43:20] *** Quits: Simplar (~Simplar@188.163.92.225) (Quit: Going offline, see ya! (www.adiirc.com))
[21:45:58] *** Joins: trbp (~trbp@user/trbp)
[21:51:25] *** Quits: texasmusicinstru (~Rheanna@218.78.104.50) (Remote host closed the connection)
[21:51:36] *** Quits: trbp (~trbp@user/trbp) ()
[21:51:37] *** Quits: Julian (~tos9@python/site-packages/Julian) (Ping timeout: 268 seconds)
[21:53:07] *** Joins: texasmusicinstru (~Rheanna@218.78.53.13)
[21:53:15] *** Joins: Simplar (~quassel@188.163.92.225)
[21:55:43] *** Quits: Everything (~Everythin@37.115.210.35) (Quit: leaving)
[21:57:23] *** Parts: royaljelly (~royaljell@user/royaljelly) ()
[21:58:12] *** Joins: DrNostril (~DrNostril@84.17.59.177)
[21:59:02] *** Joins: Julian (~tos9@python/site-packages/Julian)
[21:59:24] *** Joins: twoisprime (~twoisprim@user/twoisprime)
[22:01:55] *** Joins: FragmentedCurve (~FC@pool-100-2-232-17.nycmny.fios.verizon.net)
[22:05:44] *** Quits: mbuf (~Shakthi@122.178.124.57) (Quit: Leaving)
[22:07:58] *** Quits: Pi-sistance (~kvirc@cpc94050-newt37-2-0-cust176.19-3.cable.virginm.net) (Quit: happy math or coding)
[22:10:14] *** Joins: specing (~specing@user/specing)
[22:26:54] *** Joins: sleeping_papaya (~sleeping_@89.45.224.147)
[22:30:44] <isekaijin> Consider the power series f(z) = \sum_{n=1}^\infty z^n / n^2
[22:31:01] <isekaijin> Clearly, the radius of convergence of this thing is 1.
[22:32:02] <isekaijin> But, for |z| = 1, the series is still absolutely convergent: f(1) = \sum_{n=1}^\infty 1 / n^2 = \pi^2 / 6.
[22:32:18] <isekaijin> I thought this could not possibly happen?
[22:32:29] <mornfall> why not?
[22:32:53] <riv> anything can happen on the boundary
[22:32:57] *** Quits: tomeaton17 (~tomeaton1@51.195.150.49) (Quit: Client closed)
[22:33:02] <riv> everything can diverge, everything can converge, any mix
[22:33:11] <isekaijin> I vaguely remember someone telling me that a power series had to diverge at some point on the boundary of the disc of convergence.
[22:33:14] <mornfall> what riv says
[22:33:48] <isekaijin> But maybe they were just wrong.
[22:34:36] <mornfall> i can't think of a reason why that would be true… did they give an argument, do you remember?
[22:34:43] <isekaijin> I don't remember.
[22:35:21] <isekaijin> Now, since f(z) is actually defined for every z \in S^1, the next question is whether this function f : S^1 -> C has any nice properties
[22:35:25] <greenbagels> Z-module: ah, i see; thanks for the enlightening example (re: nested intervals)
[22:35:26] <isekaijin> Is it at least continuous?
[22:35:33] <greenbagels> nested sets*
[22:37:11] *** Quits: Inline (~Inline@2a02:908:1252:7a80:b442:91f8:4666:206e) (Ping timeout: 245 seconds)
[22:39:04] <mornfall> isekaijin: i guess you could substitute exp(iφ) for z and see what falls out of an arbitrary limit φ → θ?
[22:39:43] <isekaijin> Oh, of course, you are right. My brain is turned off today.
[22:39:50] <riv> https://i.postimg.cc/K8wdpyzH/Screenshot-2021-11-14-19-09-16.png  a very exciting graph of the function
[22:40:24] <riv> https://en.wikipedia.org/wiki/Spence%27s_function
[22:41:21] *** Quits: texasmusicinstru (~Rheanna@218.78.53.13) (Remote host closed the connection)
[22:41:48] *** Joins: superdupond (~Kev@2a01cb0400149f00c866202855143f20.ipv6.abo.wanadoo.fr)
[22:42:00] <riv> so it can be analytically continued beyond the disk
[22:42:26] *** Joins: texasmusicinstru (~Rheanna@101.89.150.168)
[22:43:58] *** Quits: Trigo (~NeedMathH@64.201.115.44) (Ping timeout: 260 seconds)
[22:48:26] *** Quits: pavlushka (~pavlushka@user/pavlushka) (Remote host closed the connection)
[22:54:30] <Z-module> greenbagels: here's a fun/easy little thing for you. Find an example like the above, closed sets K_1 \supset K_2 \supset ... in a complete metric space, where  diam(K_n) does not -> 0, but the intersection  cap_n K_n   has exactly one point.
[22:54:51] *** Quits: i0e (~is0ke3@user/is0ke3) (Quit: WeeChat 3.3)
[22:55:06] <isekaijin> Interesting, so Spence's function can be continuously extended to z = 1, and yet it has a logarithmic branch point there.
[22:56:12] <Z-module> and the diameters are all finite
[22:56:51] <Z-module> hmm, actually, that might not be possible, that last requirement
[22:58:39] <Z-module> oh wait, sure it's possible
[22:58:41] <tusko> There is more math than any one person could ever master, except Euler and Galois.
[23:00:50] <Z-module> isekaijin: it's more subtle than that:  https://math.stackexchange.com/questions/119926/how-does-a-complex-power-series-behave-on-the-boundary-of-the-disc-of-convergenc
[23:01:38] <riv> ah! "However, there is at least one point along which the holomorphic function the series defines cannot be analytically continued."
[23:01:45] <Z-module> (I also thought what you had said you remembered, and I unlearned it some years ago, and my stubborn math brain then went back to thinking the original thing)
[23:01:51] <riv> so it's not that there must be a divergence
[23:02:05] <riv> it's that there must be a something that can't be continued across
[23:02:19] *** Joins: ysftaha (~ysftaha@d24-57-234-201.home.cgocable.net)
[23:02:29] <Z-module> analysis is chock full of subtle phenomena like that. Look at Fourier analysis.
[23:02:50] <riv> something had to stop the series from convergening - it makes sense that a singularity would do it, and it does. but it's not the only thing
[23:02:58] <riv> converging*
[23:03:31] <isekaijin> Z-module: It's okay, I can forgive it, because it's complex analysis, not real analysis.
[23:04:19] <isekaijin> Jokes aside, actually this is very cool.
[23:06:40] *** Quits: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net) (Remote host closed the connection)
[23:06:55] *** Joins: dogbert2 (~Bill@ip68-105-189-91.lv.lv.cox.net)
[23:07:49] <Z-module> I once saw a nice paper on some general properties of the full set of divergence points of a power series along its border circle, but I can't remember the content now.
[23:08:09] <Z-module> I think there is always at least one point of CONvergence on that circle, no?
[23:09:14] <int-e> Z-module: nah, there's things like sum[n=0..oo] n x^n
[23:09:38] *** Joins: Brainium (~brainium@user/brainium)
[23:10:01] <int-e> Eh, I should just take x^n.
[23:10:03] *** Joins: CryptoDavid (uid14990@uxbridge.irccloud.com)
[23:10:45] <mornfall> it'd seem rather counterintuitive that it'd be impossible to have a series that converges on exactly an open disc, in any case
[23:10:59] <riv> yes
[23:12:10] <int-e> Not that I understand this really... there's an easy example for which there's exactly one point of divergence on the boundary: sum[n=0..oo] x^n/n
[23:12:29] <riv> that's related to log isnt it
[23:12:45] <int-e> But can you have just one point of convergence?
[23:12:48] <riv> log(1-x)
[23:13:23] *** Joins: random-jellyfish (~random-je@user/random-jellyfish)
[23:15:42] <isekaijin> Ah, TAing calculus during the pandemic is lovely, because you can easily tell who's friends with whom.
[23:16:00] <int-e> Oh my n should start at 1.
[23:16:04] <isekaijin> (Because they copy each other's answers.)
[23:16:11] <greenbagels> people giving the same wrong answer? heh
[23:16:51] <int-e> greenbagels: maybe they're "outsourcing" the exercises to the same paid service :P
[23:17:09] <greenbagels> supposedly chegg's stock ticker went wild during the pandemic or something
[23:17:41] <greenbagels> i remember me and my roommate one night finding out that someone asked all of our analysis take home final exam questions on stackexchange
[23:17:59] <riv> i suppose you could take a series that's divergent on the radius of convergence everywhere, and add a scaled version of log(1-x) that cancels it out exactly to leave you with a single point of convergence on the radius of convergence
[23:18:48] <isekaijin> Well, their paid service sucks. Or, alternatively, they are great actors who never break character, i.e., they remember to make the same mistakes that a student would.
[23:19:16] <Z-module> Any time I see the string "chegg" in my browser, I flee with alacrity.
[23:22:47] *** Quits: rain3 (~rain3___@2a02:2f09:d10a:400:9e2f:eb47:e2ae:761d) (Ping timeout: 265 seconds)
[23:24:28] *** Quits: KevinX (~KevinX@c-71-200-222-150.hsd1.fl.comcast.net) (Quit: Textual IRC Client: www.textualapp.com)
[23:28:32] <somiaj> Yea, chegg is good in theory, but bad in practice, many students just don't care that they are cheating.
[23:28:34] *** Joins: availabled (~available@gateway/tor-sasl/availabled)
[23:28:57] <somiaj> Though I fou9nd many of my exam questions online, the person who uploaded it failed the class.
[23:29:30] *** Joins: KevinX (~KevinX@c-71-200-222-150.hsd1.fl.comcast.net)
[23:31:34] *** Quits: texasmusicinstru (~Rheanna@101.89.150.168) (Remote host closed the connection)
[23:32:07] *** Quits: Julian (~tos9@python/site-packages/Julian) (Ping timeout: 268 seconds)
[23:32:58] *** Joins: texasmusicinstru (~Rheanna@61.171.69.141)
[23:33:04] <greenbagels> somiaj: you found out who it was?
[23:33:14] *** Joins: MarcoFe (~marcofe@host-82-49-154-107.retail.telecomitalia.it)
[23:33:15] <greenbagels> oh i guess you can just compare the answers online with the answers given in class
[23:34:19] <somiaj> In this case I can't see the solutions (since I don't have a chegg account), but my problems are randomized, and the random values they upload is a finger print
[23:34:46] <somiaj> I looked through all my students problems, only one had the same random numbers as the one uploaded (no clue of others used the answer, but the person who uploaded failed the class)
[23:34:46] *** Quits: loopspace (sid488598@helmsley.irccloud.com) ()
[23:35:56] <mornfall> cheating is pox on the face of education :\
[23:37:23] <qergle> random numbers on tests, devious. you should fail for being sneaky!  :)
[23:37:46] *** Quits: munkis (~mendel_mu@ool-ae2cb218.dyn.optonline.net) (Remote host closed the connection)
[23:38:03] <somiaj> the sad part is because I grade based on write up, they ended up with a 30% on the problem even using chegg.
[23:38:13] *** Joins: munkis (~mendel_mu@ool-ae2cb218.dyn.optonline.net)
[23:38:13] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[23:38:30] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Client Quit)
[23:40:00] *** Quits: Turingtoast (~Tino@200116b8608bf200e12ae8befb8c6bf3.dip.versatel-1u1.de) (Quit: My iMac has gone to sleep. ZZZzzz…)
[23:41:26] <somiaj> qergle: I've been doing lots of randomized problems lately, and think they are a bit more authentic. Students will tell each other answers, but they won't usually do the problem for another student, so randomization forces them to talk about the process more than just saying, 'oh the answer is 23.583'
[23:41:29] <qergle> anyhow, TIL about chegg. was this service borne out of covid?
[23:41:40] *** Joins: gthm (~gthm@ip-213-127-57-210.ip.prioritytelecom.net)
[23:41:45] <isekaijin> Nah.
[23:41:45] <somiaj> no chegg is actually quite old, they use to do 'cliff notes' back in the 90s
[23:42:02] <somiaj> they went online maybe 10-15 years ago
[23:42:07] <qergle> oh, the cliff notes summaries of novels was chegg?
[23:42:23] <mornfall> the sad part is that people who are failing because they don't know shit also firmly believe that they deserve a passing grade (and since they deserve it but aren't getting it, they feel justified in cheating)
[23:44:59] <qergle> somiaj: wikipedia is contradicting, says chegg was started in 2000 as cheggpost (no link to the cliff notes company)
[23:45:14] <somiaj> qergle: ahh then I'm mistaken, I thought they were older than that
[23:46:40] <somiaj> yea I was mistaken there, for some reason I thought they were an older compnay that adapted
[23:47:03] <qergle> maybe cliff notes went online to something?
[23:47:18] <isekaijin> What motivates people to spend their money on Chegg, when Math.SE exists and can be used for free?
[23:47:25] <somiaj> anyways, chegg is just annoying, but nothing can be done about it. All of my courses (every single question) is on Chegg. So students can just look up the answers vs work through the problems. Thus they think they are learning, but come exams it shows they didn't.
[23:47:31] <qergle> ohh...
[23:47:35] <qergle> i think i know the link
[23:47:48] <qergle> both seem to now be owned by course hero
[23:47:53] <qergle> could that have been the mixup?
[23:48:05] <somiaj> maybe, or just me not fully paying attention.
[23:48:39] <somiaj> Anyways, in theory chegg is useful, in practice it is not, since there is a big gap between being shown how to solve a problem, and learning how to solve problems yourself.
[23:49:13] <mornfall> isekaijin: math.se probably won't do your homework
[23:50:01] <riv> M.SE sucks
[23:50:06] <riv> well, the mods suck
[23:50:49] *** Joins: Julian (~tos9@python/site-packages/Julian)
[23:51:39] *** Joins: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se)
[23:51:51] *** Quits: Mattiaslndstrm (~Mattiasln@c213-103-137-235.bredband.tele2.se) (Client Quit)
[23:52:24] *** Joins: trbp (~trbp@user/trbp)
[23:53:16] <mornfall> isekaijin: ‘According to our Chegg review, they are available 24/7. Take a picture (or scan) of your homework, and send it to Chegg. You’ll get a detailed answer within 30 minutes.’ ← i think this is the main thing that people pay for
[23:53:49] <jimbzy> You only get so many questions per month, too.  20 I think?
[23:54:09] <qergle> how much does chegg cost?
[23:54:26] <jimbzy> I don't even remember now.  $20-30 USD?
[23:54:36] <qergle> pretty cheap
[23:54:46] *** Quits: specing (~specing@user/specing) (Ping timeout: 256 seconds)
[23:54:47] <somiaj> Yea, and chegg provides students what they want, answers to problems, though I think most students would be better off with hints pointing them in the right direction vs here is a solution.
[23:54:50] * jimbzy shrugs
[23:55:04] <jimbzy> There were some quality helpers on there, but most were like "This is the answer."
[23:55:15] <matrixidentity[m> "Prices starting at $14.95/month"
[23:55:16] <qergle> some people on ##math provide answers all the time
[23:55:29] *** Joins: specing (~specing@user/specing)
[23:55:40] *** Quits: Simplar (~quassel@188.163.92.225) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[23:55:55] <mycroftiv> concepts, definitions, applications, theorems, calculations, proofs . math education tends to generate a lot of calculational-homework and testing which makes sense if you are looking for applied-skill development and objective measurement but repetitive problem-set homework is often boring drudgery in practice
[23:56:02] *** Joins: ania123 (~ania123@212.72.140.51)
[23:56:18] *** Quits: sleeping_papaya (~sleeping_@89.45.224.147) (Ping timeout: 260 seconds)
[23:56:41] <mornfall> somiaj: what students want vs what students need… always a problem :)
[23:56:50] <somiaj> yea, but without the repetitive style homework, many students wouldn't be sucessful on routieen problems.
[23:57:09] <qergle> seems all this is moot once classes re-open in-person and you have to take a test in person
[23:57:10] <somiaj> And if you can do well without it, then often you can do the homework fairly quickly anyways.
[23:57:11] <mycroftiv> im not claiming there is a known better way, it may just be no-free-lunch
[23:57:30] <qergle> as for HW cheating, who cares? just weight tests a lot more.
[23:57:46] <mornfall> mycroftiv: every field, math included, has a skill component… if you don't build up that skill, you are unlikely to amount to much; and building skill is generally boring work
[23:57:57] <qergle> A's in HW and F's in tests signal cheating and proper weights make overall grade closer to F than to A.
[23:57:59] <somiaj> Yea, I don't often care about HW cheating, but all of the remote exams just escilated the issue. in person exams are a lot easier to control.
[23:58:33] <jimbzy> I just can't do that, though.
[23:58:40] *** Parts: Roughy (~mdaw45ns@user/roughy) ()
[23:58:44] <somiaj> though really hw I want students working together, helping each other out. Chegg I think is a good tool for homework, provided students do enough additional problems on their own.
[23:58:44] <mycroftiv> mornfall: i agree, that is pretty much the essence of what i said. my years spent practicing piano, years spent writing and debugging code, and time spent trying to Actually Learn math all confirm
[23:58:48] <jimbzy> I know I could cheat, but what's the point?
[23:59:04] <qergle> i recall back in the prehistoric days when i was in school, some classes allowed (and some even encouraged) group work on HWs
[23:59:21] <qergle> wasn't considered cheating, was actually considered a good way to learn.
[23:59:33] <mornfall> qergle: it's good way to learn for those doing the work :-)
[23:59:34] <jimbzy> Math with friends is a lot of fun.
