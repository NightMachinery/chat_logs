[00:02:03] *** Quits: sord937 (~sord937@gateway/tor-sasl/sord937) (Quit: sord937)
[00:03:29] *** Joins: TheGuestMovie (~TheGuestM@173.231.114.74)
[00:10:32] *** Joins: kylese (~kylese@p5dd8b9b1.dip0.t-ipconnect.de)
[00:11:38] *** Joins: m_ben_ (~m_ben@user/m-ben/x-7429725)
[00:13:43] *** Joins: badone (~badone@209.132.189.136)
[00:15:15] *** Quits: m_ben (~m_ben@user/m-ben/x-7429725) (Ping timeout: 260 seconds)
[00:15:15] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[00:19:46] *** Quits: m_ben_ (~m_ben@user/m-ben/x-7429725) (Quit: WeeChat 3.3)
[00:24:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[00:29:56] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[00:29:56] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[00:31:00] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[00:37:00] *** Quits: CarloWood (~LdK13@212-127-230-18.cable.dynamic.v4.ziggo.nl) (Ping timeout: 260 seconds)
[00:38:27] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[00:40:42] *** pah_ is now known as pa
[00:41:04] *** Quits: pa (~pah@host-95-251-40-214.retail.telecomitalia.it) (Changing host)
[00:41:04] *** Joins: pa (~pah@user/pah)
[00:42:48] *** Joins: lumbermb (~lumbermb@191.114.114.152)
[00:47:45] *** Quits: great_taste (~great_tas@190.32.235.20) (Quit: Client closed)
[00:48:12] <yolo_> c++ book concurrency in action, i thought concurrency is for coroutines(no preempt OS scheduling, your code schedules it), but in that book the concurrency means threads. the difference among process/thread/coroutines are pretty clear, now 'concurrency' as a work becomes ambigiuous to me
[00:48:40] <yolo_> s/as a work/as a word/
[00:49:20] <LordKalma> concurrency means every time things are happening simultaneously
[00:49:24] <LordKalma> regardless of the method
[00:49:25] *** Quits: kylese (~kylese@p5dd8b9b1.dip0.t-ipconnect.de) (Remote host closed the connection)
[00:49:49] <yolo_> that means, coroutine on a single core can never be called concurrent?
[00:50:01] <LordKalma> sure they can
[00:50:03] <yolo_> for that matter, neither does process/thread
[00:50:08] <rpav> people like to differentiate between "concurrent" and "parallel" in what would otherwise be known as "yet another case of fucking terrible verbiage"
[00:50:15] <Raziel> doesn't the OS schedule everything anyway?
[00:50:17] <LordKalma> hahahaha indeed rpav
[00:50:51] <Raziel> and yes, I can start 1000 threads and that's also concurrent even though they won't all be running at the same time because I don't have 1000 cores
[00:51:19] <rpav> "concurrent" is basically meaninglessly broad "everything that can happen in nondeterministic order" and parallel is "some specific subset of things happening at the same time, e.g. vectorized math"
[00:51:25] <Raziel> unless I shove em on the gpu instead hyuk
[00:52:00] <LordKalma> concurrent is every time your program will crash on data races
[00:53:10] <Raziel> we're off to the races! the data races!
[00:53:12] <yolo_> it's about how to schedule them, if it's scheduled by the OS, I call it preempty parallel thread/process or whatever(i.e. with context switch), if it's scheduled by my code explicitly I can it coroutines without context switch, i thought concurrent sided with the second case, because, 'parallel' != 'concurrent'
[00:54:04] <cbreak> yolo_: no need for coroutines
[00:54:19] <yolo_> anyways, the take away is that, for c++ when I see concurrency again, i will not treat it as coroutines by default
[00:54:21] <cbreak> Mac OS 7 had cooperative multitasking without them, and without a sane OS Scheduler
[00:54:51] <cbreak> (without a preemptive multithreading scheduler)
[00:54:53] <yolo_> i'm doing some systemc work, which is c++ plus coroutines
[00:55:12] <Raziel> C+++coroutines
[00:55:31] <yolo_> they avoid parallel to make code 'simpler', even though hardware design differs from software exactly at absolutely parallelism
[00:56:16] <yolo_> so they use coroutines to simulat true parallelism, via events/shared-variable/its own scheduler
[00:57:26] <Raziel> that sounds dumb
[00:57:36] <Raziel> but surely it can't possibly be dumb and there's a good reason for it, right? RIGHT?
[00:58:59] <Alipha> rpav: ? can't be at the end of an identifier because ? is part of the ternary operator, and so that'd be ambiguous. ! could potentially be at the end of an identifier because the ! operator only precedes identifiers, I think, but I doubt the committee would go for that
[00:59:17] <rpav> Alipha: != ;/
[00:59:39] <rpav> though, if it were only allowed for functions, it would be ok in either case i think
[00:59:42] <yolo_> so, in systemc concurrent means coroutines, in the 'concurrency in acton' c++ book, concurrency means threads, which led to my original question, now I realize they invent their own terms freely
[00:59:47] <rpav> maybe not
[00:59:57] <rpav> since you can refer to function "barewords" or whatever
[01:00:57] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[01:08:32] <RandomReader> PJBoy - the new "customization point" language means that std::ranges::size() will use the customized form outside of the namespace, e.g. via ADL
[01:08:58] <PJBoy> but the section I linked wasn't the ranges stuff
[01:08:59] <RandomReader> which means user code can call std::ranges::size instead of doing the { using std::size; size(...); } dance
[01:09:23] <PJBoy> unless it's just saying it incidentally
[01:10:11] *** Joins: zen_coder (~zen_coder@2a02:8109:a280:2d8d:f56e:630b:ae2e:6e55)
[01:10:17] <RandomReader> oh, sorry, I misread what you were referring to
[01:16:41] <RandomReader> heh, [lwg3441]
[01:16:41] <npaperbot> LWG3441: Misleading note about calls to customization points (Status: Open, Submitter: Michael Park, Last modified: 2020-10-04) <https://wg21.link/lwg3441>
[01:17:20] <PJBoy> great haha
[01:19:18] <PJBoy> dude I was also thinking about 3442 when I read that
[01:19:24] <PJBoy> wow
[01:19:39] *** Quits: proller (~p@80.240.216.69) (Ping timeout: 260 seconds)
[01:20:03] <PJBoy> I'm honestly not sure what the intended wording is
[01:21:26] <PJBoy> some functions are expected to turn up in ADL for certain parts of the standard library
[01:21:30] <PJBoy> I get that much
[01:21:37] <RandomReader> I'm not either, I think they wanted to simplify existing library under currently-recommended practices, but somehow missed that it simply isn't possible without a breaking change
[01:21:43] <PJBoy> think they should just have a section for all of them
[01:22:25] <PJBoy> possibly with some backreferences e.g. size() backreferencing ranges::size and ranges::ssize
[01:25:45] <RandomReader> it's also interesting that this seems to be a surprise
[01:26:15] <RandomReader> I mean, at least some of these folks should have been involved in the discussions regarding std2 that eventually led to std::ranges duplicating so much of the library... right?
[01:26:59] <PJBoy> we can git blame it
[01:27:10] <Raziel> std2? is that a meme like PC 2 or despacito 2?
[01:27:40] <PJBoy> oh nvm it was P0551
[01:29:10] <PJBoy> I mean ranges was a huge merge
[01:29:18] <PJBoy> I can see how it slipped through the cracks
[01:30:13] <RandomReader> yeah but p0551 references ranges
[01:30:56] *** Quits: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it) (Quit: Leaving.)
[01:31:37] <RandomReader> and says "We are uncertain that all these implementation details are truly necessary to its specification of customization points." which should automatically be a hint to everyone involved that somebody needs to check their work and *get* certain
[01:32:12] <RandomReader> I'm sure you're right that this is just a symptom of the larger scale issues with the committee process
[01:32:43] *** Joins: proller (~p@2a02:6b8:b081:8831::1:29)
[01:33:05] <RandomReader> Raziel - std2 was floated as a namespace early on because of goals like Ranges changing some of the "big" concepts of the library in a way that isn't backwards-compatible with existing code
[01:33:37] <RandomReader> not fundamental changes in the model, just not API-compatible
[01:33:51] <Raziel> oh jeez
[01:34:35] <RandomReader> so it was a "what if we make a std2 namespace, and work out a migration path for those who want to" kind of thing
[01:34:51] *** Quits: Tobbi (~Tobbi@2a02:8108:1240:48ec:6ccf:bc6:7bec:d17c) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[01:35:31] *** Joins: Tobbi (~Tobbi@2a02:8108:1240:48ec:6ccf:bc6:7bec:d17c)
[01:35:51] <RandomReader> it didn't fly, so now there's std::ranges
[01:35:55] <Raziel> RandomReader, and then they realized that's a bad idea?
[01:35:56] <Raziel> right
[01:36:10] <johnny> what else can be done tho?
[01:36:37] <Raziel> honestly I wouldn't know to use most of the shit in ranges if resharper didn't just spoon-feed me all the "hey replace this old trash with this new std::ranges trash!" stuff
[01:36:58] <RandomReader> well that's kind of the point, practically speaking it's no different
[01:37:05] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[01:37:14] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[01:37:14] *** ChanServ sets mode: +v npaperbot
[01:37:32] <RandomReader> can't have the convenience and consistency benefits without using the new stuff, and the new stuff is broad, so it's not really an incremental shift no matter what
[01:37:48] <RandomReader> whether you name it std2::size or std::ranges::size, what you have to do is the same
[01:38:47] <RandomReader> (although the upside here is that Ranges really is a consistent concept on its own, so std2::size isn't that great a name since it's really about ranging things anyway, not byte sizes or anything else)
[01:39:59] <fruitypunk> I've not used ranges yes, but concepts are fun
[01:40:11] <Raziel> From what I have used of ::ranges, the API is quite polite and many of its replacements-for-old-stuff are more straightforward than the old stuff
[01:40:24] <Raziel> it's just that I wouldn't even know they exist without resharper telling me >_>
[01:40:58] *** Quits: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net) (Read error: Connection reset by peer)
[01:41:12] <johnny> https://rpav.github.io/cpp-pipedream/#C-quiz it was neat to see this
[01:41:16] <fruitypunk> :)
[01:41:17] *** Joins: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net)
[01:41:46] <johnny> auto m0 = zip("a,b,c" | split(","), from(1)) | collect<std::map>; // Take a string "a,b,c" and make a map like {{"a": 1}, {"b": 2}, ...}.
[01:42:29] <cbreak> and people hate on boost for abusing operator overloads...
[01:42:44] <cbreak> boost::spirit did nothing wrong! ... at least not too much...
[01:45:22] <johnny> i don't think it's that simple though. i can both be against so many operator overloads and for pipes.. although other languages support something more like |>
[01:45:50] *** Quits: spaceangel (~spaceange@ip-89-176-181-220.net.upcbroadband.cz) (Remote host closed the connection)
[01:48:59] <johnny> f#'s is like |> for pipe forward, >> for composition, and even one for pipe backwards
[01:51:51] *** Quits: Tobbi (~Tobbi@2a02:8108:1240:48ec:6ccf:bc6:7bec:d17c) (Ping timeout: 260 seconds)
[01:52:47] *** Quits: Munnu (~timo@81-197-107-130.elisa-laajakaista.fi) (Ping timeout: 246 seconds)
[01:53:50] *** Joins: Munnu (~timo@81-197-107-130.elisa-laajakaista.fi)
[01:54:40] <RandomReader> it is an oddly inconsistent position to have though :)
[01:54:52] <yolo_> so the trend is to evolve c++ into a script-alike language but still need a compiler to build and keep the good performance
[01:55:01] <RandomReader> e.g.: why would I bitwise-OR a zip thing with a split thing? that makes no sense
[01:55:20] <RandomReader> even if I try to translate that to non-numeric terms, it's still illogical
[01:55:52] <RandomReader> ...so it's really just a domain-specific operator choice, same as any other
[01:56:46] *** Quits: proller (~p@2a02:6b8:b081:8831::1:29) (Ping timeout: 245 seconds)
[01:57:00] <RandomReader> er, "zip thing with a collect thing", I can match parens honest...
[01:57:27] *** Quits: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca) (Ping timeout: 260 seconds)
[01:57:44] <johnny> well in ranges-v3 if there was a reasnable split it'd be closer to  out = "a,b,c" | view:split(",") | enumerate  to end up with the pairs to build a map from
[01:58:21] <johnny> can't remember if tha's what the split is called
[01:58:29] *** Joins: Tobbi (~Tobbi@2a02:8108:1240:48ec:d13c:5504:c021:3627)
[01:58:35] <johnny> i shoudln't have prefixed it with view:: i can't quite remember
[01:58:55] *** Joins: rackj (~rackj@c-73-140-240-136.hsd1.wa.comcast.net)
[01:59:00] <rackj> I have a L1 cache line size of 64 bytes and a total L1 cache size of 32K. I have a vector that takes up 128 bytes. Will the vector use up a second line of L1 cache or would it be moved to L2?
[01:59:19] <johnny> alhtough i'd be reasonably happy just to be able to do what i can do in js fo the same thing  with map!
[01:59:24] <RandomReader> rackj - in general, you can't control cache, that'll depend entirely on the access patterns and caching algorithms
[01:59:39] <rackj> RandomReader: trying to write a cache-friendly data structure
[01:59:44] <RandomReader> if the vector's entire range is accessed frequently, it's likely to end up in L1 cache
[02:01:18] <rackj> RandomReader: ok, what about this then? Let's say I vector.reserve(64 bytes), I push_back beyond 64 bytes and trigger a resize, is this still cache-friendly code if I want the data to remain in L1 cache?
[02:02:16] <RandomReader> not sure there's much to "cache-friendly", it's more likely to either be cache-aware (you care about specifics) or cache-oblivious (you don't care about specifics, just design to divide and work on smaller subsets)
[02:02:38] <RandomReader> the questions you're asking are specific without being specific enough, so they're not answerable
[02:02:51] <PJBoy> johnny, in general it's `ranges::xxx_view(range)` and `x | views::xxx`
[02:03:12] <RandomReader> if you want to know what your specific hardware will do, you just need to profile it .. e.g. on intel, vtune should be able to provide the info
[02:03:23] <PJBoy> (re: when to use the views namespace)
[02:03:55] <johnny> '1,2,3'.split(',').map((part, idx) => { return { part, idx }})
[02:04:09] <johnny> i'd be happy enough with something closer to that
[02:04:40] <rackj> Basically, I'm writing a vector.resize() algorithm. I'm wondering if I should just keep doubling until the size of L1 cache is reached, or if it would be more efficient to resize once to the L2 cache line size?
[02:05:05] <RandomReader> is this bare metal?
[02:05:11] <rackj> yes
[02:05:38] <RandomReader> then you should have access to docs that describe the cache behavior for your hardware, which would help answer this
[02:06:04] <RandomReader> e.g. does it do independent or contiguous L1 mapping, are L1 and L2 duplicated or seprate, etc
[02:06:20] <cbreak> rackj: you should keep doubling for far beyond cache size
[02:06:31] *** Quits: TheGuestMovie (~TheGuestM@173.231.114.74) (Quit: Client closed)
[02:07:04] <rackj> cbreak: I was going to just increase linearly by L1 cache line size first and then increase by L2 cache line size
[02:07:09] <RandomReader> and then weigh this against the other data flows going on, since that will also be relevant
[02:07:30] <cbreak> if you ever stop doubling (or rather, stop growing geometrically), your push-ack complexity will stop being constant on average
[02:08:11] <rackj> Hmm... that's an interesting way to look at it.
[02:08:13] <RandomReader> (e.g. it's almost never *just* the vector element storage, it's also the vector itself, any objects that aren't already in registers, etc .. all of which will influence cache availability)
[02:08:41] <cbreak> rackj: the size of your vector doesn't matter for cache contents
[02:09:26] <cbreak> caches don't actually store primary data
[02:09:29] <cbreak> they only cache it
[02:09:53] <cbreak> primary data either lives in ram, or in registers
[02:10:03] *** Quits: horribleprogram (~user@user/horribleprogram) (Read error: Connection reset by peer)
[02:10:32] <cbreak> the contents of the caches is chosen by many factors, often based on what was accessed last
[02:10:33] <RandomReader> I was assuming that your choice of resizing would be related to the usage going on
[02:10:43] *** Joins: proller (~p@80.240.216.69)
[02:10:55] <cbreak> (read access, maybe write access)
[02:11:05] <RandomReader> if this is just a generic vector implementation, and not the user-code choosing when and how big to go, then yeah what cbreak says is more important: this isn't something you care about cache for
[02:11:31] *** Joins: great_taste (~great_tas@190.32.235.20)
[02:11:33] <RandomReader> (because the actual influences on cache are so far from this, anything you do is more likely to be harmful)
[02:13:39] <rackj> Ok, at the very least, I need a default vector size that isn't zero because I know our code isn't going to have zero-sized vectors. Would the L1 cache line size be a good default size?
[02:14:19] <cbreak> rackj: how about 8 bytes? :)
[02:14:27] <RandomReader> do all the users of it expect an empty vector to waste size?
[02:14:30] <cbreak> or let's say 16 bytes
[02:14:44] <cbreak> then you can store the data in the pointers of an "empty" vector :D
[02:15:51] <RandomReader> e.g. let's say code makes an array of Foo[] where Foo just has a std::vector<whatever> member;    do they expect that the array will start off with N buffers of whatever your default vector size is?
[02:16:23] <rackj> RandomReader: not so much about wasting size as much as it is about avoiding the unnecessary resize
[02:16:31] <RandomReader> that kind of consideration would seem more important than whatever the cache size is, since at this point you don't even know when the vector storage will be used, and therefore can't judge whether it might be cached
[02:16:44] <cbreak> rackj: there's no resize from empty
[02:16:56] <RandomReader> well, for a std::vector, when a user wants to avoid unnecessary resize they call .reserve
[02:17:00] <cbreak> obviously you don't have to resize an empty array because there's no data in it
[02:17:04] <RandomReader> because the generic vector has no clue what the usage pattern would be
[02:17:07] <cbreak> you have to allocate fresh memory
[02:17:12] <cbreak> so you only pay allocation cost
[02:17:19] <RandomReader> for what you're implementing, the expected uses, do you have enough additional information to know?
[02:17:24] <cbreak> that's the same cost you would pay if you allocated in the constructor
[02:17:33] <cbreak> but you ONLY pay for it if it is actually used
[02:17:34] <rackj> RandomReader: what do you mean by "additional information"?
[02:17:48] <RandomReader> the use cases of your vector
[02:17:59] <cbreak> unless you have small-buffer-optimization, starting out non-empty is silly.
[02:18:26] <RandomReader> e.g. do the vast majority of them always need N entries right off the bat, so making a default is more useful than having that code do .reserve() or otherwise explicitly tell you?
[02:18:35] *** Joins: emerent_ (~quassel@p200300cd57485562ba27ebfffed28a59.dip0.t-ipconnect.de)
[02:18:35] *** Quits: emerent (~quassel@p200300cd574855b8ba27ebfffed28a59.dip0.t-ipconnect.de) (Killed (zirconium.libera.chat (Nickname regained by services)))
[02:18:35] *** emerent_ is now known as emerent
[02:18:44] <rackj> RandomReader: yes, for instance, declaring a vector (without reserve) and, immediately in a for loop, push_back being used
[02:18:53] <RandomReader> or are enough of them going to need vastly different Ns such that you can't reasonably predict this?
[02:19:01] <RandomReader> yes, but how many push_backs in the loop?
[02:19:06] <RandomReader> and how big is each element?
[02:19:38] *** Quits: plastico (~plastico@neomutt/plastico) (Quit: WeeChat 3.3)
[02:19:51] <rackj> generally, just 1-2 push_backs over multiple loop iterations. sizeof element varies.
[02:20:03] <RandomReader> I think you're still missing it
[02:20:42] <RandomReader> so taking std::vector's spec, in a general algorithmic sense, it's a contiguous array of storage which means every resize is expensive: create new storage, transfer all elements over to it
[02:20:56] <rackj> right
[02:21:06] <RandomReader> so in a general usage sense, the goal is to have as few resizes as possible, by getting as close to the *final* size as possible
[02:21:18] <RandomReader> which is what .reserve() provides, a way to communicate that
[02:22:00] <RandomReader> but if the number of elements are small to start with, avoiding the first few resizes isn't terribly important, since the cost of the resize is also small (small N to transfer / small buffer sizes)
[02:22:34] <RandomReader> see what I mean? this isn't a general question that has anything to do with caches, it's about expending space up front because you expect the users will need a *final* size of, say, 4 elements
[02:23:05] <RandomReader> if that's your use case, great .. if not, this seems more likely to waste resources than preserve them, since it's incorrect and incomplete information being assumed
[02:23:26] <cbreak> and as I said above: an empty vector wastes no space.
[02:23:44] <cbreak> there simply is no point blindly allocating any memory before you need it
[02:23:50] <RandomReader> (I'm also assuming this is somewhat like std::vector in usage, you may have other interesting patterns or interfaces going on that will help you make these decisions)
[02:23:54] *** Quits: sprout_ (~quassel@86-82-44-193.fixed.kpn.net) (Ping timeout: 260 seconds)
[02:24:12] <cbreak> allocations cost time and memory
[02:24:55] <cbreak> if you delay allocation until you have an estimate for how much space you need, or at least know that you need space at all, you can be more efficient
[02:24:59] *** Quits: veverak (~veverak@ip-89-102-98-161.net.upcbroadband.cz) (Ping timeout: 264 seconds)
[02:25:12] <RandomReader> if your use cases are fairly broad, then letting them communicate more closely (by e.g. implementing .reserve()) will probably give better results
[02:25:37] <RandomReader> or a constructor that reserves, actually .. one thing std::vector doesn't have
[02:27:31] *** Joins: veverak (~veverak@ip-89-102-98-161.net.upcbroadband.cz)
[02:28:04] <RandomReader> that also pushes the cache-related decisions closer to the usage site, which is helpful .. e.g. the code using the vector can choose to make it intentionally small and reuse it continuously (making it likely to spend time in cache) on chunks of the larger problem
[02:29:37] <rackj> Hmm... ok
[02:29:50] <Raziel> so, somewhat related - in my usecases, when profiling, I find that vector construction + reserve takes significantly more time than using an array
[02:29:53] <Raziel> and I don't really get why.
[02:30:04] <rackj> because vectors are dynamically allocated
[02:31:14] <cbreak> because vectors contain a dynamically allocated buffer if they are not empty
[02:31:23] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[02:31:30] <Raziel> hmm, yes, I should test it against a dynamically allocated array maybe
[02:31:37] <cbreak> if they would have small buffer optimization, like strings, or boost::small_vector, then you would only pay for going beyond that size
[02:32:05] <cbreak> (you should give boost::small_vector a try)
[02:32:30] <cbreak> https://www.boost.org/doc/libs/1_77_0/doc/html/boost/container/small_vector.html
[02:32:44] <cbreak> it's optimized for performance when only containing few elements
[02:33:48] <Raziel> cbreak, but what about reserving for a large number of elements?
[02:34:01] <Raziel> I mean, not sure what exactly "few" or "small" means in this case
[02:35:33] *** Quits: Hello71 (~Hello71@wireguard/contributor/hello71) (Remote host closed the connection)
[02:35:47] *** Quits: zen_coder (~zen_coder@2a02:8109:a280:2d8d:f56e:630b:ae2e:6e55) (Ping timeout: 264 seconds)
[02:36:00] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 260 seconds)
[02:36:08] <Raziel> but yes, for that one case it'd probably work well
[02:36:14] *** Quits: dextaa (~DV@user/dextaa) (Ping timeout: 258 seconds)
[02:36:38] <RandomReader> the differences will depend on the types involved .. e.g. dynamically creating an array will create the objects, which is something reserving a vector doesn't do
[02:36:39] *** Joins: Hello71 (~Hello71@wireguard/contributor/hello71)
[02:37:04] *** Joins: lkor (~lionkor@i577BC4BA.versanet.de)
[02:37:24] <RandomReader> so there's a potential overhead difference depending on what "create" entails
[02:37:54] <RandomReader> .reserve is essentially removing allocation pauses from the following .push_backs, but that's about it
[02:38:09] *** Quits: lionkor (~lionkor@200116b80ff518009ef0135c65608c7d.dip.versatel-1u1.de) (Ping timeout: 258 seconds)
[02:38:44] <Raziel> hmm
[02:43:04] *** Quits: irrenhaus3 (~xenon@HSI-KBW-046-005-003-214.hsi8.kabel-badenwuerttemberg.de) (Quit: Lost terminal)
[02:46:21] *** Joins: CarloWood (~LdK13@212-127-230-18.cable.dynamic.v4.ziggo.nl)
[02:46:23] *** Quits: The_Jag (~The_Jag@host-79-13-46-237.retail.telecomitalia.it) (Quit: The_Jag)
[02:50:45] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[02:52:55] <RandomReader> rackj - oh, to reinforce something earlier that may not have been clear about typical caching systems, you asked if the size of the vector would cause it to use a second L1 line or move to L2 .. the answer is "neither", because the cache knows nothing about the size of the vector
[02:53:32] <RandomReader> it doesn't even know about allocations or memory regions .. all it's doing is taking a chunk of memory that is being used, and keeping a copy closer to the thing using it
[02:54:17] <RandomReader> that chunk might have several logically-separate program things in it (e.g. multiple variables), or a piece of some logically-larger program thing (e.g. a handful of the vector elements)
[02:54:47] *** Joins: dextaa (~DV@user/dextaa)
[02:55:04] <RandomReader> what the cache system cares about is how the CPU is accessing that particular chunk of memory, how frequently, whether it's likely to access it again, or maybe a nearby chunk, etc
[02:55:06] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 245 seconds)
[02:56:00] <RandomReader> but that chunking is entirely separate from how the program is organizing memory
[02:56:15] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[02:57:22] <RandomReader> in a programming sense, making the most of caching is handled by dividing your processing/access work into small chunks that you do all the things on before moving to the next chunk
[02:57:36] <RandomReader> (vs accessing things randomly all over the place)
[02:58:00] <RandomReader> but that could also be accomplished by simply working on, say, elements 1-16 of a 45-million element array
[02:58:07] <cbreak> there are techniques to encourage true sharing, avoid false sharing
[02:58:17] *** Joins: pah (~pah@user/pah)
[03:04:05] <rackj> RandomReader: yeah, more than vectors, I guess that was my real question. If I have a line size of 64 bytes, and I have 128 bytes of contiguous data, would it be more likely to be cached in L1 or L2?
[03:11:07] <RandomReader> depends entirely on how the cache system works, but at a base level, those are two independent/unrelated units of 64 bytes each
[03:11:52] <RandomReader> it might use two L1 lines next to each other, two L1 lines separate from each other, one L1 line for one and ignore the other .. and it might duplicate both, one, or neither line in L2
[03:12:07] <rackj> I see, thanks.
[03:14:02] <RandomReader> a simpler cache system would prefer to use L1 lines next to each other, with the entire region duplicated in L2 .. but it depends on how they spent their hardware budget on use tracking, associativity, etc since they're basically implementing things like hash algorithms in hardware -- and needing it to make decisions that are faster than just accessing main memory would be
[03:15:00] *** Joins: The_Jag (~The_Jag@host-79-13-46-237.retail.telecomitalia.it)
[03:20:11] *** Quits: jkaye (~jkaye@2601:281:8300:7530:289e:28f2:97ea:9bd4) (Ping timeout: 264 seconds)
[03:21:26] *** Quits: whupdup (~whupdup@pool-173-76-128-81.bstnma.fios.verizon.net) (Quit: Going offline, see ya! (www.adiirc.com))
[03:22:48] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[03:29:05] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 260 seconds)
[03:34:14] *** Joins: vdamewood (~vdamewood@fedora/vdamewood)
[03:44:38] *** Quits: Tobbi (~Tobbi@2a02:8108:1240:48ec:d13c:5504:c021:3627) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[03:45:23] *** Joins: Tobbi (~Tobbi@2a02:8108:1240:48ec:d13c:5504:c021:3627)
[03:45:24] *** Quits: Tobbi (~Tobbi@2a02:8108:1240:48ec:d13c:5504:c021:3627) (Client Quit)
[03:51:47] *** Quits: PJBoy (~PJBoy@user/pjboy) (Ping timeout: 260 seconds)
[03:53:30] *** Quits: proller (~p@80.240.216.69) (Ping timeout: 260 seconds)
[04:01:54] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[04:03:54] *** Joins: pah (~pah@user/pah)
[04:05:36] *** Joins: proller (~p@2a02:6b8:b081:8025::1:37)
[04:08:50] *** Quits: Juliu (~Juliu@2a02:810b:c640:3ec0:98d1:6a2c:b26:f083) (Quit: Quit)
[04:10:56] *** Quits: pah (~pah@user/pah) (Ping timeout: 245 seconds)
[04:13:07] *** Joins: lh_mouse (~lh_mouse@mingw-w64/developer/lhmouse)
[04:13:11] *** Joins: pah (~pah@user/pah)
[04:18:01] *** Quits: pah (~pah@user/pah) (Ping timeout: 245 seconds)
[04:18:57] *** Quits: DSpider (DSpider@86.127.146.140) (Quit: Leaving)
[04:21:22] *** Joins: pah (~pah@user/pah)
[04:21:41] *** Joins: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca)
[04:29:39] *** Quits: AmR (~AmREiSa@156.199.244.83) (Quit: Konversation terminated!)
[04:34:31] *** Quits: ahlk (~user@2600:1700:31c0:3a10::43) (Ping timeout: 252 seconds)
[04:36:13] *** Joins: ahlk (~user@2600:1700:31c0:3a10::43)
[04:37:19] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[04:39:03] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[04:43:38] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[04:44:23] *** Joins: ferdna (~ferdna@user/ferdna)
[04:45:46] <johnny> hmm.. https://fedoraproject.org/wiki/Changes/Package_information_on_ELF_objects . adding some metadata to ELF files to describe their source (ike rpm, or deb, or whatever). it was developed with debian folks too, so it'll probably end up being used by lots of distros over time
[04:59:08] *** Joins: The_Jag_ (~The_Jag@host-87-19-40-26.retail.telecomitalia.it)
[05:01:25] *** Joins: pah_ (~pah@host-95-248-130-153.retail.telecomitalia.it)
[05:01:33] *** Quits: The_Jag (~The_Jag@host-79-13-46-237.retail.telecomitalia.it) (Ping timeout: 265 seconds)
[05:01:50] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[05:09:34] *** Quits: pah_ (~pah@host-95-248-130-153.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[05:12:01] *** Joins: pah (~pah@user/pah)
[05:13:00] *** Joins: frost (~frost@user/frost)
[05:28:21] *** Quits: chozorho (~chozorho@2601:146:300:c30::6f8c) (Ping timeout: 258 seconds)
[05:29:24] *** Joins: chozorho (~chozorho@2601:146:300:c30::6f8c)
[05:35:24] <RandomReader> interesting
[05:35:35] <RandomReader> I wonder why json though, they don't really seem to say
[05:36:43] <RandomReader> from the metadata so far I'd think something like xml would be a better fit
[05:36:45] <johnny> other than keys needing to be quoted, it seems like a fine format
[05:36:50] *** Quits: pah (~pah@user/pah) (Ping timeout: 265 seconds)
[05:36:57] <hnOsmium0001[m]> I guess so that you don't have to write a custom parser?
[05:37:05] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[05:37:11] <johnny> yeah, you can parse it with a schema, or not, easily
[05:37:12] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[05:37:12] *** ChanServ sets mode: +v npaperbot
[05:37:17] <RandomReader> it's a more complex format though .. note that in their example, all the values are quoted
[05:37:19] <hnOsmium0001[m]> xml is very much against those unix people's ideals I would imagine
[05:37:31] <RandomReader> even the numeric ones, because you can't trust arbitrary numbers in json
[05:37:57] <RandomReader> what they have right now is just text key/value, and I could see some desire for future extensibility in, say, some nesting or hierarchy representations
[05:38:10] <hnOsmium0001[m]> it's not like xml vs json is a big difference here, the only difference is which library you get
[05:38:13] <RandomReader> but not necessarily arrays, floating point values, etc that json provides
[05:38:24] *** lkor is now known as lionkor
[05:38:40] <RandomReader> why would xml be against the ideals?
[05:39:03] <johnny> i don't see what value xml would really bring if you're not actually using a schema to validate it
[05:39:11] <RandomReader> I only mention it because it's frequently used as metadata and it's a formal standard
[05:39:49] <RandomReader> there are other text-based key/value formats that might work too
[05:39:53] <johnny> also , using something like json really cuts down arguments about what should be attributes vs children and whatnot
[05:40:37] <RandomReader> hah .. nah, json just turns into "is it structured or just text" arguments
[05:40:56] <johnny> well that'd apply the same with xml and cdata
[05:41:20] <RandomReader> like I said, could pick something else entirely
[05:41:28] <hnOsmium0001[m]> politically, I would imagine using json also makes people who likes to go "Blah blah XML is bloated blah blah" much less likely to complain
[05:41:29] <johnny> i said something like json
[05:41:31] <RandomReader> I just don't see any rationale for *json*, and I would have expected some, even implied
[05:41:55] <johnny> well i'd hope for a format mot people have parsers for, so ithsould already exist
[05:42:07] <hnOsmium0001[m]> at least personally I feel like more people have XML allergy than JSON allergy
[05:42:08] <johnny> so that's rationale for some existing format
[05:42:25] <johnny> one could have not encoded text at all but went with soemthing like bson
[05:43:07] <RandomReader> by that standard I'd think xml would be a win, there should be *more* parsers for it over json
[05:43:14] <RandomReader> even simplistic ones
[05:43:22] <johnny> except json is still easier to parse
[05:43:32] <RandomReader> how so?
[05:43:52] *** Joins: pah_ (~pah@host-79-37-70-80.retail.telecomitalia.it)
[05:43:58] <johnny> one can throw it in a webbrowser.. any webbrowser and parse it
[05:44:30] <RandomReader> no, only ones that deal in javascript
[05:44:44] <RandomReader> and what does a web browser have to do with metadata on an executable?
[05:44:46] <johnny> any webbrowser used by most folks
[05:45:01] <johnny> you just say about parsers.. and i said more people hae a json parse than an obvious xml parser
[05:45:13] <RandomReader> the same browsers parse xml :P
[05:45:34] <RandomReader> are you maybe confusing xml with something else?
[05:46:01] <johnny> no.. i just haven't thrown plain xml into a browser in so long i forgot how it worked
[05:46:36] <johnny> lol.. i can't remember how to do it
[05:47:07] <johnny> but i've thrown json into a browser console and manipulated it plenty of times
[05:47:57] <RandomReader> I suppose xml gets associated with the web, but the main point was xhtml .. bare xml has more general uses
[05:48:13] <RandomReader> and pre-dates json, even informally
[05:48:14] <johnny> oh sure.. folks were doing soap on the internet and xmlrpc
[05:48:34] <RandomReader> that's as a communication format though
[05:48:38] <johnny> and then of course we got entire documents based on it like whatever the sandard for open documents is called
[05:48:44] <RandomReader> I'm talking about its native purpose: markup, structured text
[05:48:51] <RandomReader> yea, that would be a closer application
[05:49:05] <johnny> and then there's all the stuff done inside companies
[05:49:14] *** Quits: pah_ (~pah@host-79-37-70-80.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[05:49:15] <johnny> and i think the .idea base ides use it for config still
[05:49:27] <RandomReader> json got started more as a comms format than a storage format, but that was just because the endpoints had javascript handy
[05:49:34] <johnny> indeed
[05:49:53] <lru> json is nested key/value... xml is nested key/attributes/value DOM with potential validation... json is light, xml is heavy
[05:50:09] <johnny> yeah.. schema comes later
[05:50:30] <johnny> RandomReader, in my early days when we thought xhtml was goingsomwhere we had an xlstish templating language for documents
[05:50:40] *** Joins: pah (~pah@user/pah)
[05:50:46] <RandomReader> DOM is not required to use XML, that's just a specific form
[05:50:59] <johnny> mostly because using plain xlst was impossible probably
[05:51:01] <RandomReader> anyway, the original line of thought had nothing to do with any of this stuff
[05:51:02] <johnny> xslt*
[05:51:28] <RandomReader> it was more that they want to add metadata to an executable, which is a pretty strict/reliable/etc format, so something you'd want to nail down
[05:51:38] <RandomReader> and then they picked json, which is pretty sloppy: https://seriot.ch/projects/parsing_json.html
[05:51:56] <RandomReader> and didn't seem to have any real rationale for it, implied or otherwise, which just strikes me as odd
[05:52:10] <RandomReader> why wouldn't they want something more reliable in spec?
[05:52:37] <RandomReader> xml might fit, or it might get rejected for other reasons, but there's no shortage of options
[05:52:38] <lru> oh, I forgot... json is readable, xml is ... less so :-)
[05:53:31] <johnny> RandomReader, aren't most of those concerns irrelevant in practice, especially since they avoid number handling by quoting numbers
[05:53:45] *** Quits: lionkor (~lionkor@i577BC4BA.versanet.de) (Ping timeout: 260 seconds)
[05:54:23] <RandomReader> that isn't avoiding anything though, that's just having people assume that the metadata won't contain anything confusing / arbitrary to one of the many random-quality parsers that someone might use
[05:54:37] <RandomReader> which is silly, since they know what data and what forms of data they want to allow
[05:54:59] <RandomReader> put another way, this is almost like *intentionally* putting a security hole in a spec
[05:55:23] <RandomReader> (it's not that extreme, at least as long as it's only used the way they intend .. but hopefully you get the idea)
[05:56:11] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[05:56:20] *** Quits: pulse (~pulse@user/pulse) (Quit: pulse)
[05:56:59] <RandomReader> although I suppose it could technically enable someone to drop a maliciously-tagged binary into an environment that will analyze a core dump while privileged, so maybe it's not that far off...
[05:57:14] <johnny> hmm? wait what?
[05:58:00] <RandomReader> well, one of their purposes is to be able to find the original package when analyzing the core dump of a crashed executable
[05:58:13] <RandomReader> which means $tool is going to be looking at this tag, while looking at said core dump
[05:58:20] <johnny> yes.  so what's the maliciously tagged binary?
[05:58:36] <johnny> oh i read a comma in there or didn't
[05:58:44] <johnny> "into an environment that will"
[05:58:48] *** Joins: pah (~pah@user/pah)
[05:58:52] <RandomReader> oh
[05:59:14] <RandomReader> yeah, theoretical attack against $tool by someone either creating or altering an executable beforehand
[05:59:35] <johnny> i first parsed t as the maliciously tagged binary will ..  ut you're referring to an something that analyzes the executble, not the tagged executable
[05:59:51] <johnny> but that's no different than tring to break it by throwing any random garbage in there
[05:59:58] <johnny> which you can of course already do
[06:00:21] <johnny> throwing nay random garbage into similar place as this json data (oranywhere else into the malicious executable)
[06:00:37] <johnny> i'm trying to think about hwo it's any worse than what you can already do
[06:00:45] <RandomReader> yes, but right now it's just plain text, not structured data fed into $arbitrary_parser
[06:01:04] <johnny> well you' til have to trust your parser anyways.. plain text or not
[06:01:16] <RandomReader> this attack would depend on $tool using an exploitable json library and being in a different privileged context than the original executable
[06:01:35] <johnny> yes, and htat'd be the same as it were xml would it not?
[06:01:40] <RandomReader> well yes, but straight unstructured text is a hell of a lot less complex than json
[06:01:43] <johnny> or even just some csv
[06:01:59] <johnny> and csv itself has some thorns in it  :(
[06:02:04] <RandomReader> sure, it'd be the same for any format .. but some formats are a lot less complex, and therefore easier to get quality parsers for, than others
[06:02:15] <johnny> yeah you're right about that
[06:02:21] <RandomReader> which is my underlying point: they chose something complex, and don't seem to *use* any of that complexity
[06:02:28] <RandomReader> maybe they have unmentioned future ideas or something, I dunno
[06:02:39] <johnny> maybe it hsould have just been something json compatible rather than acutal json
[06:03:05] <johnny> like there's nothing wrong with a format that looks like { "key": "value", "key2": "value2" }
[06:03:59] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[06:04:42] <johnny> and that's totally valid json, but the parser doesn't need to accept anything else
[06:05:06] <RandomReader> I wouldn't expect them to like .ini due to coming from MS, but yeah, for the data they have I'd expect something that's on that level of simplistic
[06:05:23] <johnny> heh.. that ha nothing to do with it, plenty of nixy programs use ini
[06:05:31] <johnny> systemd's service files are basically ini
[06:05:40] <RandomReader> I think YAML still has more complexity than needed, I can't recall how structured it is
[06:05:50] <johnny> yaml is waaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaay worse
[06:06:03] <lumbermb> https://twitter.com/thingskatedid/status/1452709524167553024
[06:06:16] <johnny> just allowing unquoted strings causes a ridiculous amount of problems by itself
[06:06:22] <RandomReader> lol
[06:06:25] <lumbermb> tl;dr: for consistency C++ should introduce short short
[06:06:31] <lumbermb> (since long long is a thing)
[06:06:33] <johnny> i ike not having to quote keys, but values should be quoted always
[06:07:10] <johnny> give me long bool
[06:07:17] <RandomReader> if char went away and got replaced by char8_t, and then we got short short as an integer value, that might actually end up simpler
[06:07:42] <lru> solution: use the filesystem as key/value, key being filename, value being contents :-)
[06:07:42] <RandomReader> (ignoring all the existing code, of course)
[06:07:48] <RandomReader> lol
[06:07:52] <johnny> RandomReader, i often have to use yaml.. but one should never use yaml
[06:08:30] <kalven> yaml is way to complex
[06:08:40] <johnny> RandomReader, although i prfer toml over ini..  but configparser in python is ini enough
[06:08:44] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[06:09:04] <johnny> and it's always availabe, so it's hard not to use unless you definitely run into problems with it
[06:10:13] <johnny> ini at least traditionally was a bit under specified
[06:10:23] *** Joins: pah_ (~pah@host-79-37-68-19.retail.telecomitalia.it)
[06:10:45] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[06:11:01] <lumbermb> personally I've grown fond of mozilla's prefs.js-like system
[06:11:23] <lumbermb> but the classic tried and true old reliable ini is always a good choice
[06:11:46] <johnny> ini itself dosn't specify how nested groups work do they?
[06:11:57] <johnny> that's all implementation defined isn't it?
[06:11:58] <lumbermb> I don't think so, no
[06:12:11] *** Joins: jkaye (~jkaye@2601:281:8300:7530:8985:f1bc:4422:2d97)
[06:12:11] <johnny> that's why i like toml
[06:12:34] <lumbermb> that's why I like prefs-js system more: a group is simply part of the name that uses it, and as such variables in groups can be anywhere
[06:13:00] <johnny> although considering the ubiquity of python, i wish there were more implemenatinos of configparser in other languages, particularly C++ here :)
[06:13:17] <lumbermb> wait, there is not a configparser-like for C++?
[06:13:27] <johnny> not that i've found so far
[06:13:39] <lumbermb> I know there exists inih, but I'm not sure how far into "this is an .ini" it actually goes into
[06:13:39] <johnny> maybe i missed it.. if you find one that's uhmm. bug for bug compat, that'd be nice :)
[06:13:55] <johnny> config parser does more than just parse ini files into structures though iirc
[06:14:11] <johnny> it's also got interpolation
[06:14:37] <lumbermb> yeah it tries to impose a structure and typesystem and stuff. All I need is read options from a file, leave it to myself to decide what do I use them for.
[06:14:46] <lumbermb> (which is why I personally lean towards inih)
[06:17:50] <johnny> but we don't always get to work on the programs we want to
[06:18:29] <johnny> i'm trying to play around with more python + C++ stuff
[06:21:45] *** Quits: proller (~p@2a02:6b8:b081:8025::1:37) (Ping timeout: 260 seconds)
[06:25:15] *** Quits: pah_ (~pah@host-79-37-68-19.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[06:27:25] *** Joins: pah (~pah@user/pah)
[06:32:02] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[06:32:54] *** Quits: pah (~pah@user/pah) (Ping timeout: 265 seconds)
[06:37:29] *** Joins: pah (~pah@user/pah)
[06:39:37] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[06:39:44] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[06:39:59] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Remote host closed the connection)
[06:40:55] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[06:44:27] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 260 seconds)
[06:45:23] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[06:48:06] *** Joins: pah (~pah@user/pah)
[06:53:11] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[06:55:06] *** Quits: smeso (~smeso@user/smeso) (Quit: smeso)
[06:55:31] *** Quits: emerent (~quassel@p200300cd57485562ba27ebfffed28a59.dip0.t-ipconnect.de) (Read error: Connection reset by peer)
[06:56:45] *** Joins: emerent (~quassel@p200300cd57485562ba27ebfffed28a59.dip0.t-ipconnect.de)
[06:57:45] *** Joins: pah (~pah@user/pah)
[06:58:30] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[06:59:21] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[07:02:52] *** Quits: pah (~pah@user/pah) (Ping timeout: 265 seconds)
[07:03:22] *** Joins: smeso (~smeso@user/smeso)
[07:03:22] *** Joins: pah_ (~pah@host-82-51-7-114.retail.telecomitalia.it)
[07:03:52] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[07:05:25] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[07:05:39] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[07:07:28] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[07:08:43] *** Quits: pah_ (~pah@host-82-51-7-114.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[07:10:42] *** Joins: pah (~pah@user/pah)
[07:11:09] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[07:11:39] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[07:11:56] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[07:12:11] *** Quits: jkaye (~jkaye@2601:281:8300:7530:8985:f1bc:4422:2d97) (Ping timeout: 245 seconds)
[07:16:35] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 260 seconds)
[07:17:26] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[07:18:27] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[07:25:01] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:597f:2b81:7c02:7eaf)
[07:26:14] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[07:26:57] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[07:27:23] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[07:27:51] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[07:32:46] *** Quits: Hello71 (~Hello71@wireguard/contributor/hello71) (Remote host closed the connection)
[07:32:47] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 264 seconds)
[07:33:12] *** Joins: Hello71 (~Hello71@wireguard/contributor/hello71)
[07:33:27] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Ping timeout: 260 seconds)
[07:39:29] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[07:44:35] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Ping timeout: 260 seconds)
[07:45:35] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[07:49:41] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 245 seconds)
[07:54:41] *** Joins: z8z (~x@ac255238.ppp.asahi-net.or.jp)
[07:56:47] *** Quits: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca) (Ping timeout: 260 seconds)
[07:58:40] *** Quits: luizfrds (~Luiz@152.250.243.147) (Read error: Connection reset by peer)
[08:06:52] *** Joins: pah (~pah@user/pah)
[08:15:35] *** Quits: skapata (~Skapata@user/skapata) (Remote host closed the connection)
[08:26:39] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[08:27:06] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[08:31:39] *** Joins: Guest3770 (~Guest3770@h67-217-13-182.ftcmco.broadband.dynamic.tds.net)
[08:33:02] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[08:34:57] *** Quits: UmarJ (~username@user/umarj) (Ping timeout: 244 seconds)
[08:38:15] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 260 seconds)
[08:45:50] *** Quits: chozorho (~chozorho@2601:146:300:c30::6f8c) (Ping timeout: 260 seconds)
[08:47:40] *** Joins: chozorho (~chozorho@c-69-250-72-103.hsd1.md.comcast.net)
[08:51:23] *** Quits: Guest3770 (~Guest3770@h67-217-13-182.ftcmco.broadband.dynamic.tds.net) (Quit: Client closed)
[08:54:23] *** Joins: sord937 (~sord937@gateway/tor-sasl/sord937)
[08:55:14] *** Quits: ferdna (~ferdna@user/ferdna) (Quit: Leaving)
[08:57:46] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[09:05:42] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 260 seconds)
[09:12:16] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[09:12:47] *** Quits: chozorho (~chozorho@c-69-250-72-103.hsd1.md.comcast.net) (Quit: WeeChat 3.0)
[09:17:11] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Ping timeout: 264 seconds)
[09:22:02] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[09:24:57] *** Joins: pah (~pah@user/pah)
[09:27:02] *** Joins: meator (~meator@user/meator)
[09:27:22] *** Quits: Juliu (~Juliu@2a02:810b:c640:3ec0:597f:2b81:7c02:7eaf) (Quit: Quit)
[09:27:23] *** Quits: lumbermb (~lumbermb@191.114.114.152) (Ping timeout: 265 seconds)
[09:28:02] *** Joins: JohnMS_WORK (~kvirc@213.134.183.29)
[09:29:52] <ville> and your discussion already shows why there's no point standardizing a "config parser". write your self one. it takes an hour
[09:30:17] <johnny> oh, i never suggested standardizing a config prser
[09:30:59] <johnny> ville, where'd you get the idea anybody wanted to standardize config parsers?
[09:31:29] <johnny> anybody here who was talking rather*
[09:32:04] <ville> none the less writing parsers is really a skill you should poses. if i could redo the order i learned things with c++ i'd jump parsing as one of the very first things
[09:32:09] *** Quits: rackj (~rackj@c-73-140-240-136.hsd1.wa.comcast.net) (Quit: Client closed)
[09:32:19] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[09:32:19] <johnny> it probably takes more than hour to write a compatible python configparser though
[09:32:33] <johnny> a parser compatible to python configparser i mean*
[09:33:53] <johnny> we weren't even really talking about config parsers, but how json was being embedded in elf binaries to describe provenance (not authoritative provenance) and how it could have been some other format. somebody else brought up about how it could have been ini
[09:34:47] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[09:34:48] <johnny> you're right i should probably learn to write a parser at some point, but i'd never write my own since all the existing formats cover my needs
[09:35:00] <johnny> never write my own config parser*
[09:36:36] <ville> well "a parser" is a start, parsing it self is a very wide field, but luckily it's well-researched so learning is easy. you've all the research papers and books explaining those research papers you could ever want
[09:36:47] <johnny> i'm sure there is
[09:37:06] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[09:37:14] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[09:37:14] *** ChanServ sets mode: +v npaperbot
[09:38:25] <johnny> actually i know there is.. i've read enough about grammars and stuff and how one can express them, and stuff about context free grammars and whatnot
[09:38:41] <johnny> it's been awhile though
[09:40:28] *** Joins: pah (~pah@user/pah)
[09:41:47] *** Quits: kraa (~kraa@107-190-7-216.cpe.teksavvy.com) (Ping timeout: 260 seconds)
[09:42:11] <johnny> i wonder if pegtl is any good
[09:42:34] <johnny> not that i'd be doing it in C++ though in reality
[09:45:12] *** Joins: pah_ (~pah@host-79-54-72-198.retail.telecomitalia.it)
[09:45:23] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[09:46:01] <ville> pegtl is a c++ library, so not sure what you mean there
[09:46:36] <ville> peg would be the concept it's using, if that's what you meant?
[09:46:38] <johnny> isn't it a parser generator?
[09:47:08] <johnny> i'm just going off this list of libraries i saw. i didn't look at that since i was looking for something completely differet
[09:47:28] <ville> i am not sure i'd call it a generator really. it's a c++ library made up of bunch of templates. that's the TL part in the name: template library
[09:47:55] <ville> it provides you with parser combinators
[09:47:57] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[09:48:33] <johnny> yeah i see that now that i opened it up
[09:49:18] <ville> in other words it has a thing that is able to parse say literals, and it has another thing that is able to parse 0-to-n-things. so combining the two would give you a string parser
[09:50:09] <ville> or a thing that is able to parse a digit, then combining that 1-or-more times gives you integral parser
[09:50:22] *** Joins: pah (~pah@user/pah)
[09:50:47] *** Quits: pah_ (~pah@host-79-54-72-198.retail.telecomitalia.it) (Ping timeout: 264 seconds)
[09:55:45] *** Quits: badone (~badone@209.132.189.136) (Quit: ZNC 1.7.5 - https://znc.in)
[09:55:54] *** Quits: pah (~pah@user/pah) (Ping timeout: 265 seconds)
[09:56:24] *** Joins: pah_ (~pah@host-79-12-65-41.retail.telecomitalia.it)
[09:58:35] <johnny> but i probably wouldn't be playing around with any of this in C++, since i'm not even using C++ on purpose
[09:58:48] <johnny> i'd have to find the equivalent somewhere else (which shouldn't be hard)
[10:01:21] *** Quits: pah_ (~pah@host-79-12-65-41.retail.telecomitalia.it) (Ping timeout: 245 seconds)
[10:01:21] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[10:01:31] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[10:09:40] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[10:11:37] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[10:13:17] *** Quits: great_taste (~great_tas@190.32.235.20) (Quit: Client closed)
[10:14:16] *** Joins: Haohmaru (~Haohmaru@195.24.53.110)
[10:16:25] *** Joins: kraa (~kraa@107-190-7-216.cpe.teksavvy.com)
[10:17:35] *** Joins: pah (~pah@user/pah)
[10:26:35] *** Joins: andreasbuhr (~quassel@p549db179.dip0.t-ipconnect.de)
[10:26:42] *** Joins: UmarJ (~username@user/umarj)
[10:28:22] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:95fb:9cb4:fb7c:82e3)
[10:33:07] *** Quits: kraa (~kraa@107-190-7-216.cpe.teksavvy.com) (Ping timeout: 260 seconds)
[10:35:16] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[10:37:12] *** Quits: immibis (~hexchat@62.156.144.218) (Remote host closed the connection)
[10:37:35] *** Joins: immibis (~hexchat@62.156.144.218)
[10:51:16] *** Joins: Tobbi (~Tobbi@2a02:8108:1240:48ec:146e:edfd:ccd9:4c5c)
[10:54:11] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[10:54:44] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[10:59:13] *** Joins: txtsd (~txtsd@user/txtsd)
[11:00:46] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[11:07:37] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[11:08:17] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[11:11:13] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[11:14:59] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[11:15:07] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[11:16:12] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[11:16:18] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[11:17:48] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[11:18:00] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[11:26:38] <johnny> cbreak, i thought i'd give that {row, column} as key for maps a try, but what's the most efficient way to get all the values for a row in that case?
[11:26:48] <johnny> or rather.. most reasonable..
[11:28:09] <johnny> that way makes it really easy to get the max column value in any case.. since i gotta fill in max_column_size as empty strings
[11:28:31] *** Joins: zen_coder (~zen_coder@2a02:8109:a280:2d8d:f56e:630b:ae2e:6e55)
[11:41:29] <cbreak> johnny: this representation isn't meant to be used efficiently if you want to access everything
[11:41:55] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[11:41:59] <cbreak> if you want efficiency, consider a dense layout first
[11:42:22] <cbreak> if you can't afford a dense layout, a proper sparse matrix would be better
[11:42:22] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[11:43:06] <cbreak> you can still work inefficiently with this representation of course, but as you've seen, you'd have to look at every element to query all entries with a given column
[11:43:12] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[11:43:22] <johnny> ultimately i'm just fillin in th matrix to simply print it out to a file
[11:43:31] <johnny> i won't be generally accessing it
[11:45:12] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[11:45:24] <johnny> i don't now the max column value until i'm actually discovering it, so it'd end up like 6000 x 100... ahtough i don't honestly know the max value .. that 100 is just a guess
[11:45:48] *** Joins: DSpider (DSpider@86.127.146.135)
[11:45:48] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[11:46:53] <johnny> i'm really just trying to match the existing implementation such that  current_generated_xlsx -> csv == my_csv
[11:47:19] <johnny> it's possible the output format could change once 100% compat has been achieved
[11:48:35] *** Joins: plastico (~plastico@neomutt/plastico)
[11:48:46] <johnny> you confused me with my understanding of sparse vs dense when you asked that, but then i realized i had it right.. except empty strings instead of 0 of course
[11:48:49] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[11:49:09] <johnny> both on the row and column level
[11:49:47] <johnny> since empty strings are valid in many places anyways, i don't see how i could do it densely anyways
[11:50:00] <johnny> other than putting some nonsense to filter out i guess
[11:53:28] <johnny> i probably wouldn't have even considered efficiency until i realize i'd have to loop over it twice somehow, first to get the max column, and then actually print it
[11:54:40] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[11:57:05] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[11:57:13] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[11:57:38] <johnny> thanks android studio.. when you asked me to update and restart and i said yes, i expected you to retart
[11:57:42] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[11:58:23] *** Joins: spruit11 (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[12:00:22] <ville> if you're just outputting it, then why have a matrix in-memory at all?
[12:01:49] <johnny> i can't, i need to know all the data first
[12:02:43] *** Quits: spruit11 (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Client Quit)
[12:02:48] <johnny> particularly i don't know the total number of columns , plus it'd put the responsibility of printing out in a place where it doesn't belong
[12:03:41] <johnny> i can't know the total number of columns until the very very end.. at least with the way the rest of the code (that i didn't write) is designed
[12:03:41] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[12:04:41] *** Joins: lionkor (~lionkor@200116b80fb518007285c2fffea63d72.dip.versatel-1u1.de)
[12:04:42] <johnny> my goal was to simply replace qxlsx->write(row, column, data) with a csv writer .. and not really touch anything else
[12:05:29] <johnny> anything else can be dealt with when/if we decide to change the output format such that it doesn't generate such an unneeded amount of columns
[12:06:52] <johnny> are you interested in seeing the the generated xlsx file to know what i'm dealing with? probably not though
[12:06:56] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Client Quit)
[12:07:14] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[12:07:16] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[12:07:53] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[12:09:07] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[12:11:18] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Client Quit)
[12:12:30] *** Joins: egelbot (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[12:14:20] *** Quits: egelbot (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b) (Client Quit)
[12:15:12] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:e876:dcb:76b1:818b)
[12:19:38] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[12:19:47] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[12:21:36] *** Joins: PJBoy (~PJBoy@user/pjboy)
[12:28:14] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[12:28:39] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[12:28:58] *** Joins: Ivii (~Ivyy@2001:a61:1304:3a01:ff77:5d07:db8e:c40c)
[12:31:39] *** Quits: UmarJ (~username@user/umarj) (Ping timeout: 260 seconds)
[12:31:39] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[12:40:15] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[12:40:22] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[12:40:47] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[12:40:47] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[12:41:37] *** Joins: paule32 (~paule32@user/paule32)
[12:47:38] *** Quits: ethoxy (~caretaker@cx21.havox.ru) (Ping timeout: 246 seconds)
[12:59:53] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[13:05:13] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[13:06:07] *** Joins: m_ben (~m_ben@user/m-ben/x-7429725)
[13:06:54] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[13:07:20] <lpapp> is it ok to only put template<typename T> in the source file if only the method implementation works with the template, but it is not required for the signature in the header file, or is it better to stay consistent?
[13:08:09] <lpapp> in this case, perhaps the method does not even need it if it is on the class already?
[13:08:18] <lpapp> I am not very pro at template progamming.
[13:09:44] <cbreak> lpapp: if  you use a template in only one source file, then you don't have to put it into a header
[13:10:09] <cbreak> but you can't pretend that a function is a function template, or that a function template is a function, in different places
[13:12:19] <lpapp> Thanks, and if the template is the same as on the class, I do not even need it on the function or do I still need it?
[13:15:32] *** Joins: synaps3 (~void@178-221-103-129.dynamic.isp.telekom.rs)
[13:19:20] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[13:22:45] *** sprout is now known as egelbot
[13:25:01] *** egelbot is now known as sprout
[13:25:01] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:25:20] *** Joins: mike18 (~geri@217-149-167-230.nat.highway.telekom.at)
[13:25:32] <mike18> hi - how is std::hash implemented?
[13:26:06] <mike18> e.g. when be used with std::unordered_map
[13:27:32] <lionkor> mike18: are you asking how to make std::hash of your own type, for example to use your own type as a key to std::unordered_map?
[13:27:41] *** Joins: whupdup (~whupdup@pool-173-76-128-81.bstnma.fios.verizon.net)
[13:27:43] <mike18> no just wondering how its implemented
[13:27:57] <mike18> i could my my own key for std::pair
[13:28:13] *** Quits: dextaa (~DV@user/dextaa) (Quit: Ping timeout (120 seconds))
[13:28:25] <mike18> return std::hash<string>(param1) ^ std::int<int>(param2);
[13:28:33] <mike18> return std::hash<string>(param1) ^ std::hash<int>(param2);
[13:28:33] *** Joins: dextaa (~DV@user/dextaa)
[13:28:43] <lionkor> The actual hash functions used in std::hash are implementation-dependent
[13:28:59] <mike18> but underlying its using a hash function?
[13:30:00] <lionkor> it can be, yeah, but it might also just be an identity function (hash(i) => i) for integers
[13:30:16] <lionkor> its definitely not guaranteed to use a cryptographic hash function
[13:30:44] <PJBoy> one would hope that doesn't use a crypto hash
[13:32:09] *** Joins: evocatus (~evocatus@84.51.113.13)
[13:32:14] <lionkor> the only thing you can be sure about is that whatever hash function it is, it satisfies the requirements: 1. if (a == b) then (hash(a) == hash(b)), and if (a != b) then the probability of (hash(a) == hash(b)) should be *very small*, approaching zero
[13:32:20] <PJBoy> it is specified that the hash functions should have a roughly even distributio though
[13:32:29] <PJBoy> yeah that
[13:33:11] <PJBoy> approaching 1 / (max - min + 1) specifically
[13:33:20] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:35:38] <lpapp> Hmm, did not know there was std::hash. I thought the hash map in the C++ STL was named unordered_map.
[13:36:06] <PJBoy> it is
[13:36:18] <PJBoy> hash != hash map
[13:36:30] <lionkor> std::hash is a functor that is used to provide a templated hash function for std::unordered_map, so std::unordered_map is the hash-map, and std::hash is it's hash functor
[13:36:41] <lionkor> more or less
[13:36:55] <lionkor> i think std::unordered_set and some others use std::hash as well
[13:36:56] <lpapp> ah, it is the hash function underneath
[13:37:04] <lpapp> that is why i have not come across it yet as I used the default.
[13:37:06] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[13:37:13] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[13:37:13] *** ChanServ sets mode: +v npaperbot
[13:37:27] <lionkor> yeah its a struct that you can "overload" with templates, and then its invoked like std::hash<mytype>{}(mytype_instance)
[13:37:44] <lpapp> I guess rarely do you need that.
[13:38:20] <lionkor> you need to implement your own std::hash "overload" if you want your own non-primitive type as a key to a std::unordered_map
[13:38:20] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:39:04] <mike18> whats better?  unsigned int unordered_map_index = return std::hash<int>(index) ^ std::hash<int>(currSum); or unsigned int unordered_map_index = index << 16 | currSum;
[13:39:42] <lionkor> lpapp: for example, you could have a std::unordered_map of 2d-positions to some other type, and then youd implement std::hash<my2dpostype> as combining the hashes of both coordinates. So it's useful, but
[13:39:53] <mike18> second hone is hashed by default hash func of unordered_map
[13:39:54] <lionkor> in my experience usually as sign of non-optimal design
[13:40:13] <PJBoy> neither of those hashes look great
[13:40:22] <mike18> PJBoy: why not?
[13:40:34] *** Joins: rond_ (~rond_@2a02:a31a:a23c:f480:2fd7:e087:5546:a438)
[13:40:37] <PJBoy> the index ^ sum has the problem of always being zero if index == sum
[13:40:39] <mike18> index fits in 16 bits
[13:40:48] <PJBoy> oh does it?
[13:40:53] <PJBoy> well that sounds pretty optimal then
[13:40:59] <PJBoy> use the second one
[13:41:19] <mike18> the index ^ sum has the problem of always being zero if index == sum .... oh
[13:41:39] <lionkor> mike18: I believe the idiomatic way is `hash(a)^(hash(b)<<1)` or something like that?
[13:41:41] <lpapp> hmm, true class Foo { }; int main() { std::unordered_map<Foo, int> myHashMap; return 0; } would not compile (with the include of course)
[13:42:00] <mike18> why shift to left? multiply by 2?
[13:42:30] <PJBoy> to make the second hash unrelated to the first
[13:42:42] <PJBoy> prevents the a == b issue I just raised
[13:42:46] <mike18> yes
[13:42:48] <rond_> struct A{std::optional<B> maybeB; explicit A(const B& b, bool storeB) : maybeB(storeB ? b : std::nulloptr) {}};    this doesn't work because b and std::nulloptr are of different types. Is there a way to achieve this cleanly? or should I move initializing maybeB to the constructor body and that's the only valid way?
[13:43:02] <PJBoy> but it's honestly a questionable calculation
[13:43:10] <PJBoy> boost::hash_combine does something much fancier
[13:43:12] <mike18> PJBoy: in what sense?
[13:43:28] <PJBoy> hashes are a pretty deep science
[13:43:39] <PJBoy> I'm not very accepting that such a simple bitshift makes sense
[13:44:02] <mike18> PJBoy: yeah
[13:44:19] *** Joins: CaCode (~Cas@user/cacode)
[13:44:59] <PJBoy> https://www.boost.org/doc/libs/1_64_0/boost/functional/hash/hash.hpp
[13:46:06] <mike18> it it creating a 64 bit hash?
[13:46:21] <PJBoy> it uses a few different algorithms depending on integer size
[13:46:42] <PJBoy> the main calculation I believe is the size_t one
[13:46:45] <PJBoy> `seed ^= value + 0x9e3779b9 + (seed<<6) + (seed>>2);`
[13:47:14] <PJBoy> which comes from https://en.wikipedia.org/wiki/MurmurHash IIRC
[13:47:16] <mike18> there is some background here btw https://www.it-swarm.com.de/de/c%2B%2B/c-warum-ist-boost-hash-combine-der-beste-weg-hash-werte-zu-kombinieren/823707716/
[13:47:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:47:26] <mike18> mumuhash is fancy
[13:47:37] <mike18> google hash?
[13:47:38] <lionkor> rond_: you can make them both std::optional:   maybeB(storeB ? std::optional<B>(b) : std::nullopt)
[13:48:06] <PJBoy> tldr is don't write your own hash function combiner
[13:48:38] <rond_> lionkor and then move-constructor will be triggered so it's cheap, right?
[13:49:05] *** Quits: Juliu (~Juliu@2a02:810b:c640:3ec0:95fb:9cb4:fb7c:82e3) (Quit: Quit)
[13:49:32] <lionkor> rond_: Yeah. The right way would be to just have two constructors, one with `const B&` and one empty one, but there's probably a good reason you need B and not store it
[13:50:29] <rond_> I do need B in my constructor, correct.
[13:50:55] <rond_> it's just "store your origins" stuff I want to model
[13:51:43] <mike18> there is not hash combiner in std lib?
[13:51:48] <PJBoy> nope
[13:51:56] <mike18> not needed at all?
[13:52:00] *** pah is now known as pa
[13:52:02] <PJBoy> nah it would be good to have
[13:52:12] <rond_> I've got one more question that I'm not sure about: is passing to function (or returning from a function) std::optional<T> as expensive as passing the value of T?
[13:52:28] <rond_> mike18 the lack of it is awful
[13:52:39] <mike18> rond_: just use boost?
[13:52:42] <PJBoy> npaperbot search hash_combine
[13:52:42] <npaperbot> P0814R2: [Library Evolution, Library] hash_combine() Again <https://wg21.link/p0814r2> (by Nicolai Josuttis) (2018-02-12) (Related: https://wg21.link/p0814r2/github)
[13:52:42] <npaperbot> Also: P0814R0
[13:53:10] <PJBoy> making some headway
[13:53:30] <PJBoy> they want to make it constexpr, which makes sense
[13:53:45] <PJBoy> boost's is notably not constexpr
[13:53:59] <lpapp> We also use murmur3 hash in our project.
[13:54:05] <rond_> struct A{std::optional<const B> maybeB; ...std::optional<const B> getMaybeB() {return maybeB;}};      is that good? doesn't introduce any unnecessary copies?
[13:54:09] <mike18> lpapp: what for?
[13:54:22] <rond_> or would each call of `getMaybeB()` result in creating a copy of B?
[13:54:30] <lpapp> something called Cryptomatte.
[13:54:43] <lionkor> rond_: that should copy it each time, yeah, since std::optional owns B
[13:54:43] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:54:53] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:55:06] <rond_> lionkor so perhaps a better way would be .const std::optional<const B>& getMaybeB() {return maybeB;}
[13:55:18] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:6926:4bc4:cc94:817e)
[13:55:33] <rond_> this one wouldn't introduce copies, right?
[13:55:41] <rond_> (as I said, my usecase is:
[13:55:50] <rond_> "store origin if you wish" )
[13:56:00] <rond_> hence all these consts :D
[13:56:45] <lionkor> as long as you dont store the return in a new std::optional, yeah. If you do `std::optional<> b = a.getMaybeB()` then it does still copy
[13:57:16] <lionkor> you'll need to store it in const std::optional<B>& as well
[13:57:25] <lionkor> on the caller side
[13:57:40] <rond_> lionkor or "auto b = a.getMaybeB()" ? would it work without copying?
[13:58:02] <PJBoy> think you should just try these options out
[13:58:24] <PJBoy> it's pretty important to know these value semantics
[13:58:41] <rond_> they're a bit tricky to wrap your head around
[13:58:58] <PJBoy> yeah
[14:01:32] <lionkor> rond_: I'm actually not sure whether `auto` understands that you want `const&`, I can't find that part in the reference rn
[14:01:42] <PJBoy> it does not
[14:01:44] <lionkor> `const auto&` would work for sure, though
[14:01:58] <lionkor> PJBoy: Okay sweet, good to know, I wasn't sure
[14:02:37] <mike18> PJBoy: thanks for the infos!
[14:02:52] <rond_> so, summing up
[14:03:04] <urdh> { auto ptr = get_ptr(); if(!ptr) throw std::exception(); return std::shared_ptr(ptr); }  // why would people do this >:(
[14:03:04] <geordi> error: 'get_ptr' was not declared in this scope; did you mean 'getpt'? (fix known)
[14:03:29] <rond_> what's a good design for this functionality?  struct A{std::optional<const B> maybeB; ...const std::optional<const B>& getMaybeB() {return maybeB;}}    <- is it a good way ?
[14:03:52] <PJBoy> there's a part in the standard that says auto deduction works like template type deduction
[14:04:23] <PJBoy> so `auto x` works like `template<typename T> void f(T x)` if you were to make the analogous function
[14:04:39] *** Quits: The_Jag_ (~The_Jag@host-87-19-40-26.retail.telecomitalia.it) (Read error: Connection reset by peer)
[14:04:47] *** Parts: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) ()
[14:04:49] <PJBoy> and auto& works like f(T&) etc, so you get to follow those rules for auto
[14:05:11] <PJBoy> and that bit is here http://eel.is/c++draft/dcl.type.auto.deduct#3
[14:05:18] *** Joins: The_Jag (~The_Jag@host-87-19-40-26.retail.telecomitalia.it)
[14:05:27] *** Quits: zen_coder (~zen_coder@2a02:8109:a280:2d8d:f56e:630b:ae2e:6e55) (Ping timeout: 260 seconds)
[14:06:03] <PJBoy> rond_, that looks fine
[14:06:22] <PJBoy> I would go one step further and make the function const qualified
[14:06:53] <PJBoy> struct A { std::optional<const B> maybeB; const std::optional<const B>& getMaybeB() const { return maybeB; } };
[14:07:20] <PJBoy> and that would be the standard form for getters
[14:07:47] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[14:08:50] <rond_> great, thanks!
[14:09:46] *** Joins: pah (~pah@user/pah)
[14:12:28] <rond_> virtual ~AbstractClass() = default;    <- is that a standard way?
[14:12:42] <LordKalma> yes
[14:12:42] *** Quits: synaps3 (~void@178-221-103-129.dynamic.isp.telekom.rs) (Quit: Leaving)
[14:12:44] <rond_> (assuming no dynamic allocation happens)
[14:13:22] <LordKalma> assuming no dynamic allocation happens you won't have polymorphism
[14:15:00] <rond_> LordKalma I mean, no dynamic allocation in AbstractClass ctor
[14:15:42] <LiaoTao> rond_, You mean to say that "nothing needs to be done in the destructor"
[14:17:35] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[14:17:57] <PJBoy> dynamic allocation isn't needed for polymorphism >:(
[14:18:18] <PJBoy> dtors don't care about that anyway
[14:19:49] <rond_> +1 for both
[14:20:51] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Ping timeout: 260 seconds)
[14:23:28] *** Quits: frost (~frost@user/frost) (Quit: Connection closed)
[14:23:46] <PJBoy> apart from perhaps the destroying delete thing in C++20
[14:23:55] <PJBoy> I forget what it's for and how it works
[14:27:04] <rond_> C++ in its majesty
[14:28:36] <lionkor> beautiful
[14:28:36] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:31:41] *** Joins: r-g (~r-g@51.158.144.32)
[14:32:25] <PJBoy> I mean I looked it up quickly and yeah
[14:32:32] <PJBoy> it's not relevant
[14:32:40] *** Joins: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[14:33:39] *** Joins: frost (~frost@user/frost)
[14:34:41] <PJBoy> it allows you to inspect the object you're deleting before deleting it
[14:35:19] <PJBoy> which has some value for custom allocators I think
[14:35:49] *** Joins: pah (~pah@host-87-10-190-200.retail.telecomitalia.it)
[14:35:49] *** Quits: pah (~pah@host-87-10-190-200.retail.telecomitalia.it) (Changing host)
[14:35:49] *** Joins: pah (~pah@user/pah)
[14:36:28] *** Joins: night_wulfe__ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[14:36:34] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 260 seconds)
[14:37:01] *** pah is now known as pa
[14:37:27] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[14:38:00] *** Quits: whupdup (~whupdup@pool-173-76-128-81.bstnma.fios.verizon.net) (Quit: Going offline, see ya! (www.adiirc.com))
[14:40:35] *** Quits: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 264 seconds)
[14:42:52] <very_sneaky> \o/ second package merged into conan
[14:43:00] <very_sneaky> er, cci
[14:44:11] <very_sneaky> how much trouble do you guys have reading library code when it's been heavily templated and abstracted? do you find it relatively easy?
[14:44:21] *** Joins: UmarJ (~username@user/umarj)
[14:44:22] <very_sneaky> I'm struggling and not sure if it's just that my relative inexperience
[14:45:02] <rond_> depends
[14:45:06] *** Joins: gggpkm (~gggpkm@li2015-124.members.linode.com)
[14:45:11] <rond_> If I'm the author, then it's superb
[14:46:09] <LiaoTao> I think it's fine as long as it doesn't use both templates and macros
[14:46:14] <LiaoTao> *cough* ASIO *cough*
[14:47:17] <lionkor> There's readable code, which is usually idiomatic c++ with "expected" coding styles and easy-to-understand datastructures. And then there's code that is some other weird style, bad naming, macros and #ifdefs, etc. So it really depends. "heavily templated and absracted" sounds pretty hard to read, especially if it relies on template magic, auto, etc. *everywhere*. TL;DR Some libraries are just hard to read.
[14:47:38] <rond_> LiaoTao yesterday I've just created code with both templates and macros...
[14:47:55] <LiaoTao> :(
[14:47:57] <rond_> but for the good cause!
[14:48:02] <rond_> improves readability
[14:48:13] <rond_> and maintainability  :)
[14:48:19] <PJBoy> I have code that uses macros and templates
[14:48:37] <rond_> I actually think of my yesterday's code very highly
[14:48:39] <rond_> cool stuff B)
[14:48:56] <lionkor> easy-to-read is not easy-to-understand, neccessarily
[14:49:37] <very_sneaky> hmm, okay. sounds like probably a combination of things then
[14:49:37] <PJBoy> yeah the biggest challenge of macros is not making cryptic non sense
[14:49:44] <lionkor> it might be easy to read `DoAllTheThings(x); Again(y)` but you'll have zero idea what is actually happening
[14:50:18] <rond_> #define almost_all_template_arguments_ void, A, B
[14:50:29] <rond_> #define all_template_arguments almost_all_template_arguments_ C
[14:50:31] <very_sneaky> i've been trying to read a simulation engine which heavily uses abstract messaging techniques, so it's difficult to get a grasp of the execution order of the library
[14:50:35] <rond_> foo<all_template_arguments>
[14:50:46] <rond_> I'm really glad of this construct
[14:50:48] <very_sneaky> it's not well documented outside of the code either, though. so that probably doesn't help
[14:50:48] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:50:49] <lionkor> rond_: please be a joke please be a joke
[14:50:55] <rond_> why
[14:50:59] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[14:51:50] <PJBoy> man I hate codebases that use IPC
[14:51:51] <lionkor> very_sneaky: if you can, step through it with a debugger! make some breakpoints in major functions, and just continue over and over. You should quickly see what gets called when, from where, it's an easy way
[14:52:15] <PJBoy> "I'll just jump to the callers of this function"
[14:52:21] <PJBoy> > massive message processing loop
[14:52:24] <PJBoy> fuck
[14:52:56] <lionkor> rond_: you specify the template arguments either way, why not specify them right there? `all_template_arguments` is not expressive, it just hides what's going on
[14:53:03] <LiaoTao> PJBoy, I think the problem is that most people who write IPC code don't understand the concept of ownership
[14:53:17] <LiaoTao> At least most people whose code I've read
[14:53:39] <rond_> because they get used in a bunch of tests
[14:53:40] <PJBoy> there's a lot of avenues for problems
[14:53:47] <rond_> and the list is subject to grow
[14:54:02] <PJBoy> and I've been fortunate enough to not have to worry too much about them
[14:56:29] <lionkor> rond_: oh, i see, okay. still not a fan, to be honest, but I see why you did that. if it's test code its not that big of an issue anyways
[14:56:29] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:57:30] *** Joins: proller (~p@2a02:6b8:0:51e:ff06:8de1:4ad8:5bfb)
[14:58:13] *** Quits: evocatus (~evocatus@84.51.113.13) (Read error: Connection reset by peer)
[14:58:53] <very_sneaky> lionkor: yeah, I'm using a debugger. It's still a slog
[14:58:58] <very_sneaky> slowly piecing it together though
[15:05:01] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:07:01] <very_sneaky> i guess this is a skill in and of itself though. doing it is good practice
[15:18:01] <cbreak> very_sneaky: debugging is a useful skill indeed
[15:18:08] <cbreak> both with a debugger, and with alternate means
[15:18:56] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[15:18:56] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[15:20:00] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[15:24:37] *** Quits: rond_ (~rond_@2a02:a31a:a23c:f480:2fd7:e087:5546:a438) (Quit: Client closed)
[15:28:05] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:29:47] <very_sneaky> my problem isn't so much debugging, it's being able to quickly build a mental model of abstract/templated code that i haven't written
[15:30:53] *** Quits: m_ben (~m_ben@user/m-ben/x-7429725) (Quit: WeeChat 3.3)
[15:31:53] *** Joins: Deneb (~johnch@86.111.189.80.dyn.plus.net)
[15:36:07] *** Joins: whupdup (~whupdup@pool-173-76-128-81.bstnma.fios.verizon.net)
[15:42:00] *** Joins: horrible` (~user@2607:fea8:7040:830:1431:b543:c667:1c6a)
[15:42:00] *** Quits: horrible` (~user@2607:fea8:7040:830:1431:b543:c667:1c6a) (Changing host)
[15:42:00] *** Joins: horrible` (~user@user/horribleprogram)
[15:43:10] *** horrible` is now known as horribleprogram`
[15:43:19] *** horribleprogram` is now known as horribleprogram
[15:43:19] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[15:44:07] *** Quits: andreasbuhr (~quassel@p549db179.dip0.t-ipconnect.de) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[15:45:55] <DSpider> should I worry about member variable data sizes in structs/classes?
[15:46:05] <DSpider> do I still need to place larger data types first?
[15:46:21] <DSpider> or does the compiler arange them?
[15:47:56] <PJBoy> the compiler does not rearrange them
[15:48:13] <PJBoy> although I'm not sure if that's an actual language guarantee
[15:49:02] <cbreak> DSpider: you should worry
[15:49:05] <cbreak> but not too much
[15:49:10] *** Joins: pulse (~pulse@user/pulse)
[15:49:20] <PJBoy> yeah
[15:49:35] <cbreak> think about how the types fit together semantically, and if you find out you need to optimize space, reorder them yourself
[15:51:01] <DSpider> sometimes it messes with the feng-shui of the variables
[15:51:21] <DSpider> like if I have a float[4] array representing color (RGBA)
[15:51:47] <DSpider> it needs to be fist in that struct/class, even if it doesn't really make sense to place it first
[15:52:06] <DSpider> when the other member variables are just ints and floats
[15:52:38] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:53:16] <cbreak> it doesn't have to be first
[15:53:38] <cbreak> << alignof(float[4]); // it's not that bad
[15:53:39] <geordi> 4
[15:54:34] *** Joins: andreasbuhr (~quassel@p549db179.dip0.t-ipconnect.de)
[15:56:15] *** Joins: Guest82 (~Guest82@eth-west-pareq2-46-193-4-100.wb.wifirst.net)
[16:06:41] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[16:12:51] *** Joins: NovumDXW (~NovumDXW@183.12.239.113)
[16:22:16] *** Joins: zen_coder (~zen_coder@141.113.64.22)
[16:30:33] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[16:30:35] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[16:31:02] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[16:33:08] <rpav> 0.0f 0.0f 0.0f 0.0f 0.0f ... alignof float
[16:35:43] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[16:36:58] *** Joins: pah (~pah@user/pah)
[16:38:13] *** Joins: AmR (~AmREiSa@156.199.244.83)
[16:38:13] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[16:38:57] *** Joins: tm604 (~tom@perlsite.default.entitypark.uk0.bigv.io)
[16:41:15] *** Quits: meator (~meator@user/meator) (Ping timeout: 260 seconds)
[16:42:22] *** Joins: kraa (~kraa@107-190-7-216.cpe.teksavvy.com)
[16:44:34] *** Quits: NovumDXW (~NovumDXW@183.12.239.113) (Quit: Leaving)
[16:46:30] *** Joins: magla (~gelignite@55d4747b.access.ecotel.net)
[16:47:09] *** Joins: skapata (~Skapata@2804:14c:87b0:a6f9:2111:1b2c:6ebe:efdf)
[16:47:09] *** Quits: skapata (~Skapata@2804:14c:87b0:a6f9:2111:1b2c:6ebe:efdf) (Changing host)
[16:47:09] *** Joins: skapata (~Skapata@user/skapata)
[16:47:10] *** pah is now known as pa
[16:47:14] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[16:55:27] *** Joins: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca)
[16:55:45] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Remote host closed the connection)
[16:57:13] *** Joins: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[17:02:08] *** Quits: smallvil_ (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Read error: Connection reset by peer)
[17:09:38] *** Quits: artok (~azo@mobile-access-bcee2b-18.dhcp.inet.fi) (Ping timeout: 260 seconds)
[17:18:20] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[17:18:28] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[17:19:16] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[17:20:59] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[17:23:29] *** Joins: pah (~pah@user/pah)
[17:23:29] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:27:58] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[17:30:34] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[17:32:48] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[17:34:31] *** Quits: JohnMS_WORK (~kvirc@213.134.183.29) (Ping timeout: 260 seconds)
[17:35:27] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 260 seconds)
[17:37:07] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[17:37:15] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[17:37:15] *** ChanServ sets mode: +v npaperbot
[17:38:34] *** Quits: pulse (~pulse@user/pulse) (Ping timeout: 260 seconds)
[17:38:34] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:38:50] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[17:38:53] *** Joins: Ronalds_Mazitis_ (~Ronalds_M@46.109.76.104)
[17:44:10] *** Joins: pulse (~pulse@user/pulse)
[17:44:11] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:46:39] *** Joins: meator (~meator@user/meator)
[17:47:28] *** Joins: jessicara (~shirogits@user/jessicara)
[17:50:51] *** Quits: gggpkm (~gggpkm@li2015-124.members.linode.com) (Remote host closed the connection)
[17:52:52] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[17:52:55] *** Joins: lumbermb (~lumbermb@191.114.114.152)
[17:56:46] *** Quits: UmarJ (~username@user/umarj) (Ping timeout: 245 seconds)
[17:57:49] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:58:27] *** Joins: paulmcquad (~gamer@78.17.229.141)
[18:01:33] *** Quits: sord937 (~sord937@gateway/tor-sasl/sord937) (Remote host closed the connection)
[18:02:10] *** Joins: sord937 (~sord937@gateway/tor-sasl/sord937)
[18:02:39] *** Joins: h4ppy (~happy@user/h4ppy)
[18:06:54] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:07:17] *** Quits: magla (~gelignite@55d4747b.access.ecotel.net) (Quit: Stay safe!)
[18:08:36] *** Quits: Ivii (~Ivyy@2001:a61:1304:3a01:ff77:5d07:db8e:c40c) (Remote host closed the connection)
[18:10:22] *** Joins: Ivii (~Ivyy@2001:a61:1304:3a01:8462:5527:4b8e:6633)
[18:10:27] *** Quits: Ivii (~Ivyy@2001:a61:1304:3a01:8462:5527:4b8e:6633) (Remote host closed the connection)
[18:11:26] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Remote host closed the connection)
[18:13:13] *** Joins: markong (~kvirc@213.146.188.203)
[18:17:00] *** Joins: UmarJ (~username@user/umarj)
[18:20:34] *** Quits: meator (~meator@user/meator) (Quit: Leaving)
[18:27:39] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[18:27:39] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[18:27:47] *** Joins: CodeMouse92 (~CodeMouse@user/codemouse92)
[18:27:56] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:28:04] <lpapp> in a huge project where the build time can be large, even with ninja, does it make sense to spare headers when we can rely on implicit includes?
[18:28:15] <lpapp> e.g only add cmath for atan2 if it does not compile.
[18:28:44] <lpapp> I tend to always add header files that I need to be explicit and avoid compilation issues in unseen circumstances
[18:28:55] <lpapp> but could one argue that this is counter-productive for build-time?
[18:29:02] <lpapp> and only add it if it is not yet included implicitly?
[18:29:35] <lpapp> if unnecessary header otherwise, sure, do not include it, that is dumb for sure.
[18:31:41] <lpapp> I guess one argument is stray includes when method calls go.
[18:31:52] <lpapp> But some kind of auto-detection system for those could help, perhaps.
[18:41:46] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[18:45:14] *** Quits: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it) (Quit: Leaving.)
[18:45:30] <lumbermb> what do you mean included implicitly?
[18:46:28] <lumbermb> If foo.h requires <cmath>, or an include in foo.h is going to require <cmath>, it's still included explicitly in the end (unless you mean some kind of feature like the compiler auto-adding includes depending on what functions you write or what libs you liink)
[18:49:00] <imMute> lumbermb: if foo.h includes bar.h and bar.h includes cmath, but foo.h also requires cmath, then there's a potential problem if bar.h stops including cmath (maybe it never actually needed it, maybe it got refactored out)
[18:50:49] *** Joins: davidlowryduda (~davidlowr@73.61.9.42)
[18:51:00] <lumbermb> if foo.h requires cmath, it should always include it explicitly
[18:51:02] *** Quits: UmarJ (~username@user/umarj) (Quit: UmarJ)
[18:51:17] <lumbermb> (it'd be even better tho if it's foo.cpp that requires cmath instead of foo.h, but you never know)
[18:52:06] <lumbermb> of course, if you are in control of both foo.h and bar.h (they are both in your project), there's no issue and you can make lots of assumptions
[18:52:31] <lumbermb> but for any kind of 3rd party code *including stdlib*, you should not assume that any header is ever included implicitly
[18:52:59] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) ()
[18:53:25] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[18:53:37] *** davidlowryduda is now known as dld
[18:54:08] <rpav> really best not to assume an implicit include for any direct dependency with the possible exception that some `T` in `T.h` is so tied to `S.h` that it would not make sense to include T.h without having S.h
[18:54:09] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[18:54:21] <rpav> whether this happens in practice or not is a different story
[18:57:45] *** Quits: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca) (Ping timeout: 260 seconds)
[19:01:16] *** Quits: Haohmaru (~Haohmaru@195.24.53.110) ()
[19:02:02] <lpapp> lumbermb: would that slow down a big build with thousands of header files or more though?
[19:02:11] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 264 seconds)
[19:02:46] <lpapp> I do not know the overhead of pragma once or include guards with ifdefs.
[19:03:00] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:03:15] <lpapp> I see also the rationale of people who think only include what you really need
[19:03:22] <lpapp> i.e. the compiler must complain for you to include
[19:03:29] <CarloWood> { std::filesystem::path p = "/home/carlo/bin/";  /* how do I get the last component (directory)? ie "bin" */ }
[19:03:29] <geordi>  
[19:04:04] <rpav> lpapp: merely checking for a file's include-or-not is the least concern vs instantiating templates or other things
[19:04:21] <lumbermb> lpapp, I don't know if it would slow it down, but if it did, the correction would be to refactor the code that *uses* <cmath>, not try to work aroudn the fact that if the code ises it and can't find it it has to complain
[19:04:48] <lpapp> I have no idea what you mean by refactoring the code that uses cmath
[19:05:09] <lpapp> well, it is an old principle that do not touch what works :)
[19:05:26] <lpapp> what you need to remember in this context is that every little optimisation for build time matters.
[19:05:27] <lumbermb> use precompiled headers, move math code form a .h to a .cpp, profile your options for using integrated (in-header / in-file) math instead of requiring on <cmath>, etc
[19:05:47] <lpapp> so, if we can eliminate 1000 pragma once, and it gives us a few seconds back, that is a great win.
[19:06:13] <lpapp> ah, no, that would be a lot of maintenance overhead
[19:06:19] <lpapp> to do NIH
[19:06:20] <lumbermb> lpapp, how much time is your code build vs the time it is used? I'd say if your code is compiled for 36 hours and is used around the world for 1400k hours, eliminating 2 hours from the compile means not much
[19:06:42] <lpapp> I build the whole day
[19:06:45] <rpav> how much is your actual compile time and have you actually benchmarked what's taking time
[19:06:55] <lpapp> that should explain it
[19:07:06] <rpav> it explains little
[19:07:23] <rpav> are these repeated compiles? the same .exe? what file/header/step in the compilation is taking the most time?
[19:07:24] <lumbermb> IMO, trying to remove build time by changing header inclusions is an obvious sign of premature optmization when it is contrasted with the alternative that *the code would not even compile otherwise*
[19:07:30] <rpav> ^
[19:07:46] <rpav> if you _haven't even analyzed_ you're just blindly shooting and hoping something speeds something up
[19:08:04] <Guest82> how would I create a base class (say, Animal) with a virtual enum declaration (say, Predators) that derived classes can implement?
[19:08:04] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[19:08:08] <rpav> in reality it could be something like, your link step is taking 10 minutes because you're using a shitty linker, you don't have enough ram, and it's massively churning swap
[19:08:36] <CarloWood> { std::filesystem::path p = "/home/carlo/bin/";  std::filesystem::path p2 = p.parent_path(); cout << p2; }
[19:08:36] <geordi> "/home/carlo/bin"
[19:08:41] <CarloWood> :/
[19:08:46] <Guest82> I couldn't make the enum declaration static
[19:09:01] <rpav> Guest82: that's not how enums work
[19:10:14] <lumbermb> doesn't std::flilesystem have split? If it does, you can implement basedir/dirname from there
[19:10:29] <Guest82> rpav: maybe there is another way to express that "a class has a (static) property which can only have *these* values"?
[19:10:38] <lpapp> lumbermb: if the code does not compile, it is caught by CI, and then fixed, so not really an issue
[19:11:19] <rpav> Guest82: you can do that with an enum, but there is no such thing as a "virtual enum"
[19:11:32] <PJBoy> enums don't limit your values
[19:11:41] *** Quits: horribleprogram (~user@user/horribleprogram) (Read error: Connection reset by peer)
[19:11:45] <PJBoy> they just give you some useful names for hardcoded values
[19:12:52] <Guest82> rpav: but if I use an enum (class) on my derived classes, I have no way of stating the requirement in the base class because each one would be a different type ...
[19:13:27] <rpav> it wouldn't really work like you probably think even if it worked like you probably want
[19:13:40] <PJBoy> perhaps you want a `virtual bool is_valid_animal(int animal)` or some such
[19:13:52] <rpav> probably you shouldn't be using inheritance in any case
[19:15:50] *** Quits: skapata (~Skapata@user/skapata) (Ping timeout: 260 seconds)
[19:17:03] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:17:10] <Guest82> I was trying to make a base class for a "Game" and wanted to have a static member describing possibles moves, but that's a bad idea yeah
[19:17:44] <Guest82> now that I think of it, in most games, this doesn't make any sense
[19:18:34] <Guest82> the number of moves might be too big, and you would only be interested in the moves you _can_ make
[19:18:41] <rpav> adopting "configuration" of data is generally your best bet in a game (and a lot of other places really)
[19:19:32] <Guest82> as in "state of the board" in chess for eg?
[19:19:32] <PJBoy> okay "dir_path/" not acting like "dir_path" w.r.t. std::filesystem sucks
[19:20:01] <PJBoy> I thought my day of checking if the last character of a path is "/" were over
[19:21:55] *** Joins: skapata (~Skapata@2804:14c:87b0:a6f9:a08e:2845:2bb:1c33)
[19:21:55] *** Quits: skapata (~Skapata@2804:14c:87b0:a6f9:a08e:2845:2bb:1c33) (Changing host)
[19:21:55] *** Joins: skapata (~Skapata@user/skapata)
[19:23:41] <rpav> huh yeah path is apparently considerably shittier than i remember
[19:25:29] *** Joins: UmarJ (~username@user/umarj)
[19:26:00] <PJBoy> { filesystem::path p = "/home/carlo/bin/";  for (auto sub : p) cout << sub, ""; }
[19:26:01] <geordi> "/", "home", "carlo", "bin", "",
[19:26:14] <PJBoy> to its partial credit, it *is* consistent with that ^
[19:26:24] <PJBoy> { filesystem::path p = "/home/carlo/bin";  for (auto sub : p) cout << sub, ""; }
[19:26:25] <geordi> "/", "home", "carlo", "bin",
[19:27:01] <lumbermb> I mean, from a functional perspective /path/foo is different from /path/foo/
[19:27:15] <lumbermb> (eg for copies, rsync, linking, etc) so it's consistent with that too
[19:27:31] <PJBoy> oh those things care too?
[19:28:01] <lumbermb> yeah
[19:28:19] <PJBoy> what's the difference in those cases?
[19:28:45] <PJBoy> will rsync tell you you're wrong if you forget/provide the trailing slash?
[19:28:45] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[19:28:57] <lumbermb> rsync /path/foo /target/bar/ creates /target/bar/foo, whereas rsync /path/foo/ /taregt/bar create /target/bar with the contents of /bar/foo/
[19:29:21] <PJBoy> ahh
[19:29:23] <PJBoy> hm
[19:29:37] <lumbermb> I think. Haven't used it in a while. But basically there's a difference between "a folder" and "a folder and its contents"
[19:29:53] <PJBoy> okay that's something to keep in mind
[19:30:08] *** Quits: retr0taku[m] (~retr0taku@2001:470:69fc:105::f576) (Quit: You have been kicked for being idle)
[19:30:11] <PJBoy> so the best way of getting the parent directory path would be, what
[19:30:23] *** Joins: retr0taku[m] (~retr0taku@2001:470:69fc:105::f576)
[19:30:24] *** Parts: retr0taku[m] (~retr0taku@2001:470:69fc:105::f576) ()
[19:30:51] <lumbermb> get the current directory (eg.: "/path/to/foo/.") (notice the "."), then walk to "./../"
[19:30:59] <PJBoy> { filesystem::path p = "/home/carlo/bin";  cout << (p / "..").lexically_normal(); }
[19:31:00] <geordi> "/home/carlo/"
[19:31:02] <lumbermb> then resolve into an absolute path via filesystem
[19:31:03] <PJBoy> that probably?
[19:31:03] <rpav> of course the _obvious_ solution of making a reverse iterator for path is broken
[19:31:43] <PJBoy> I don't think it would work anyway
[19:31:52] <lumbermb> never use reverseiterators for building paths. Among other things, it doesn't do what you want in presence of a link anyways.
[19:32:35] <PJBoy> my attempt at using accumulate fell to the trailing slash's empty element
[19:32:41] <rpav> { filesystem::path p("/a/b/c"); auto it = std::make_reverse_iterator(p.end()); ++it; cout << *it; }
[19:32:42] <geordi> "b"
[19:33:02] *** Joins: X-Scale` (~ARM@50.77.166.178.rev.vodafone.pt)
[19:33:20] <rpav> (not why it's broken)
[19:33:22] <PJBoy> { filesystem::path p = "/home/carlo/bin/", p2 = accumulate(begin(p), prev(end(p)), filesystem::path(), divides<>()); cout << p2; } // with trailing slash
[19:33:23] <geordi> "/home/carlo/bin"
[19:33:30] <PJBoy> { filesystem::path p = "/home/carlo/bin", p2 = accumulate(begin(p), prev(end(p)), filesystem::path(), divides<>()); cout << p2; } // without
[19:33:30] <geordi> "/home/carlo"
[19:33:50] <PJBoy> i.e. the iterator behaves in exactly the unhelpful way
[19:34:20] <lumbermb> yeah it's one of the reasons why I barely touch <filesystem>
[19:34:27] *** Quits: X-Scale (~ARM@31.22.144.14) (Ping timeout: 260 seconds)
[19:34:43] <lumbermb> (the whole utf8 paths fiasco being another reason)
[19:34:51] <rpav> it's the usual case of "let's add something to the standard library" "let's make it look mildly useful" "let's ensure it's utterly useless in practice"
[19:35:05] *** X-Scale` is now known as X-Scale
[19:36:01] <PJBoy> better than nothing <_<
[19:36:10] <rpav> i'm not sure it is
[19:36:22] <rpav> if one had nothing, one would find a better library and it would become defacto
[19:36:27] <PJBoy> nah
[19:36:31] <PJBoy> definitely not
[19:36:42] <PJBoy> people would instantly resort to manual path manipulation
[19:36:50] <PJBoy> and posix / windows api calls
[19:36:56] <rpav> rather one struggles with the builtin crap and it doesn't really work and you end up with bugs and a bunch of utility code to sortof patch over it
[19:37:05] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:38:48] <lumbermb> tbf I've always used POSIX
[19:39:10] <lumbermb> when on Windows, I just try to find posix compatibility layers for what I need (eg.: punistd.h)
[19:39:14] *** Quits: lh_mouse (~lh_mouse@mingw-w64/developer/lhmouse) (Read error: Connection reset by peer)
[19:40:55] <lumbermb> and IMO everyone should use POSIX. Or at least POSIX 2008 TC1
[19:42:56] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[19:43:00] <rpav> posix isn't really a general solution
[19:43:05] *** Joins: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca)
[19:43:06] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:45:09] <lumbermb> one thing I wish was fixed in C++ is the issue of making containers depend on exceptions. Like, container.at(), IMO there should be an alternative method .at_or() that returns an element or an alternative, without potentially raising exceptions.
[19:46:56] <PJBoy> but .at returns a reference
[19:47:02] <rpav> .at_or could return a pointer
[19:47:09] <lumbermb> yeah, that's what the alternative is for
[19:47:10] <rpav> .maybe_at
[19:47:15] <rpav> heh
[19:47:15] <PJBoy> what would it point to?
[19:47:21] <rpav> lumbermb: yeah that wouldn't work
[19:47:25] <PJBoy> a new allocated element?
[19:47:31] <PJBoy> that isn't part of the container?
[19:47:36] <lumbermb> container.at(index, alternative) return container[index] if it exists, alternative otherwise
[19:47:53] <rpav> that's a crash
[19:47:54] <PJBoy> so what's the return type of .at_or?
[19:47:58] <PJBoy> a value type?
[19:48:06] <lumbermb> it's not a crash, alternative is a reference
[19:48:11] <rpav> heh
[19:48:11] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[19:48:19] <PJBoy> oh I see
[19:48:20] <rpav> _that_ is a crash
[19:48:26] <lumbermb> returning a reference to a reference parameter is a well understood idiom, in used for eg.: std::clamp
[19:48:28] <rpav> if you returned a pointer or value it would be valid
[19:48:42] <PJBoy> not sure what crash you're referring to rpav
[19:49:02] <lumbermb> it's very definitively not a crash, unless you are using dunno, a 1995 compiler
[19:49:52] <rpav> { auto&& x = std::clamp(5, 0, 1); cout << x; }
[19:49:53] <geordi> 1
[19:49:53] <lumbermb> reference at_or (size_t index, reference alternative) (ditto for const_reference const member version)
[19:50:09] <rpav> that's actually a crash / UB
[19:50:15] <rpav> can you make geordi -fsanitize=address?
[19:50:33] <PJBoy> { vector v{1, 2, 3}; int x{}; cout << at_or(v, 3, x); } auto& at_or(auto container, auto key, auto& alternative) try { return container.at(key); } catch (const out_of_range&) { return alternative; }
[19:50:34] <geordi> 0
[19:50:35] <PJBoy> there
[19:50:47] <rpav> that's a crash
[19:50:50] <PJBoy> because?
[19:51:04] <rpav> well, not _in that specific case_, but in the one everyone would actually want to use
[19:51:15] <lumbermb> rpav, you are not passing a reference in your example
[19:51:20] <rpav> i.e. `auto& x = at_or(v, 3, -1);`
[19:51:23] <PJBoy> can't pass an rvalue as the alternative argument
[19:51:25] <PJBoy> so it's safe
[19:51:32] <rpav> safe and useless
[19:51:42] <PJBoy> it's useful for lumbermb
[19:51:44] <lumbermb> why would it be useless? clamp() is not useless
[19:51:49] <PJBoy> and yeah
[19:51:50] <rpav> clamp is unsafe
[19:51:53] <PJBoy> min et al aren't useless
[19:51:56] <PJBoy> they just have a caveat
[19:52:04] <lumbermb> like everything in C++
[19:52:12] <lumbermb> so it's not like it changes anything on that end
[19:52:24] <PJBoy> it's not my favourite caveat ofc
[19:52:28] <rpav> they're unsafe and pretty useless .. also generally worse than not using values, but that's aside
[19:53:18] <rpav> err generally worse than using values directly, though in specific cases your optimizer is probably going to do fine
[19:53:28] <PJBoy> they do have a value like overload
[19:53:33] <PJBoy> via the initializer_list overload
[19:54:00] <lumbermb> oh no!
[19:54:07] <lumbermb> you have invoked initializer_list!
[19:54:15] <PJBoy> I mean yeah, that is the downside
[19:54:21] <PJBoy> no move semantics or anything like that
[19:54:27] <lumbermb> now I can't ever use your class never ever again
[19:54:40] <rpav> but in any case the "find or default" type functions suck if you try to use references .. either _using_ them is shitty (as above) or using them is unsafe (as per clamp/minmax/etc)
[19:54:45] <PJBoy> function in this case
[19:54:54] <rpav> but if you use pointers it's perfectly fine :p
[19:55:06] <PJBoy> yeah that's kiiiiiinda true
[19:55:10] <lumbermb> well, also add a pointer overload then
[19:55:20] <rpav> if(auto* v = find(map, "somekey"); v) { .. } basically gives you all the things you want
[19:55:28] <rpav> it's almost as if pointer is some kind of optional reference type :p
[19:55:32] <lumbermb> pointer at_or (size_t index, pointer alternative) (ditto for the const_pointer const member version)
[19:56:06] <rpav> that's just as terrible as reference
[19:56:06] <lumbermb> rpav, did you just mention the phrase "optional reference"? What a madman! You have no idea what you shall unleash upon us
[19:56:16] <rpav> lumbermb: that's what a pointer _is_
[19:56:16] <lumbermb> we already had enough issues with initializer_list
[19:56:20] <PJBoy> but to be fair
[19:56:28] <PJBoy> you can just make a at_or function like I di
[19:56:30] <PJBoy> d
[19:56:42] <rpav> you can, it's just terrible to use
[19:56:46] <lumbermb> I made mine too. I just think it should be added to the std
[19:57:01] <lumbermb> as well as the opt-out-of-exceptions idea
[19:57:09] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:57:14] <PJBoy> or you could have an at function that returns an optional
[19:57:24] <PJBoy> and use .value_or on the result
[19:57:35] <lumbermb> hmmm yeah, I can use an optional<T&>
[19:57:38] <rpav> you rarely want that since most of the time you want a referential return of the original
[19:57:45] <PJBoy> you cannot have an optional<T&>
[19:57:50] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[19:57:54] <lumbermb> says who? the standard? pffff
[19:58:01] <lumbermb> I already have my own optional
[19:58:03] <PJBoy> that's what pointers would be for
[19:58:05] <rpav> but it _is_ more useful than the above because a lot of the time you want a "default value" it's fine to copy .. floats, ints, whatever
[19:58:22] <rpav> yeah you don't need optional<T&>, you have T*
[19:58:36] <PJBoy> T* doesn't have a .value_or method, but hey
[19:58:45] <rpav> i do prefer ptr<T> or ref<T> over raw T*/T& but
[19:59:20] <PJBoy> I don't really vibe with any of this alternative stuff anyway
[19:59:30] <PJBoy> I do my key checking explicitly
[19:59:40] <rpav> it's sometimes useful but rarely in this context
[20:00:22] <rpav> where it's a lot more useful is if you're loading data, and then you likely want a copy _anyway_
[20:00:33] <rpav> e.g. configuration values or something
[20:00:53] *** Joins: pah_ (~pah@host-79-49-135-108.retail.telecomitalia.it)
[20:00:54] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[20:01:35] <hnOsmium0001[m]> supposedly boost::filesystem had a remove_trailing_separator that std::filesystem didn't get
[20:02:07] <PJBoy> booo
[20:02:07] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:02:12] <PJBoy> booo std::filesystem
[20:02:28] <lumbermb> considering that the entire point of std was that people don't have to create their own list, vector, etc..., I think my idea to have something like std::list<int> nothrow mylist; has some merit
[20:02:53] <lumbermb> we already can opt out of exceptions in new with new nothrow, why can't we for other library components?
[20:03:33] <PJBoy> because then you end up with an exception / error_code dual API like std::filesystem
[20:03:40] <PJBoy> and error_code sucks
[20:03:52] <PJBoy> and stdlib likes exceptions
[20:04:11] <PJBoy> also because it goes through std::allocator
[20:04:37] <LiaoTao> Nothrow new...cool
[20:05:07] <PJBoy> and in general, the allocator requirements are such that exceptions are the only way to report failure
[20:05:47] <lumbermb> that sucks, but could be fixed by refining allocators at the same time we implement opt-in nothrow
[20:06:04] <PJBoy> eh
[20:06:11] <PJBoy> isn't an allocation failing exceptional?
[20:06:34] <PJBoy> are you really going to write sequences of code to handle allocation failure via error codes?
[20:06:34] <lumbermb> technically, by the time a memory allocation fails, whether you get an exception or not you are already doomed
[20:06:43] <PJBoy> that's not remotely true
[20:07:06] <lumbermb> the general understanding I have is that exceptions in allocators are useless because the one that can be planned to be returned (bad_alloc) is the one the container code can do nothing about
[20:07:10] <PJBoy> unless you get killed by the OOM killer
[20:07:31] <LiaoTao> Plugging for James Renwick's deterministic exceptions https://github.com/jsren/llvm-detex
[20:07:33] <PJBoy> it's pretty easy to deal with out of memory exceptions
[20:07:45] <PJBoy> you just don't try to allocate that memory again like an idiot
[20:08:11] <PJBoy> options include telling the user they're low on memory, or their file you're trying to load is too big or whatever
[20:08:24] <PJBoy> deferring the operation to later
[20:08:28] <PJBoy> cutting down on block size
[20:08:39] <PJBoy> failing the operation
[20:08:45] *** Joins: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net)
[20:08:47] <lumbermb> yeah and in *immediate* code that is easy to return to the user as indication: "attempt to allocate returned nullptr"
[20:09:15] <lumbermb> (if they want to add an error_code, perhaps an exposed errc/errno like deposit that one can sign in to the allocator to read information from later, even better)
[20:09:17] <PJBoy> yeah if you wanna write allocation failure handling code on every allocation
[20:09:20] *** Quits: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net) (Client Quit)
[20:10:01] <LiaoTao> PJBoy, I've done that for a large telecom project and it sucks like you wouldn't believe
[20:10:13] <PJBoy> with exceptions you just write the exception handler at some reasonable point where you can do something
[20:10:22] <LiaoTao> And it's not like you have a decent avenue of error handling deep down in the internals. You generally do want to propagate everything all the way up somewhere.
[20:10:42] *** Quits: dld (~davidlowr@73.61.9.42) (Ping timeout: 265 seconds)
[20:10:44] *** Joins: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net)
[20:10:45] <PJBoy> yeah
[20:10:55] <PJBoy> but my main point is allocation failure is exceptional
[20:11:12] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[20:11:18] <LiaoTao> In most cases.
[20:11:29] <PJBoy> basically any function that isn't noexcept can throw due to allocation failure
[20:12:01] <LiaoTao> If you're dealing with pooled memory that's designed to run near the page limit you will be failing allocations and, say, dropping packets.
[20:12:12] <imMute> PJBoy: even functions that don't allocate memory?
[20:12:26] <PJBoy> that was covered by the use of the word "basically"
[20:12:31] <lpapp> do you typically need to put template instantiation in the source cpp file rather than the header where you implement your head-only library?
[20:12:35] *** Joins: dld (~dld@2601:197:600:1210:d10e:482c:eb89:99b9)
[20:12:40] <lpapp> in other words, does template instantiation work from a header-only library?
[20:12:56] <PJBoy> that's a confusing question
[20:13:10] <PJBoy> what do you mean by template instantiation?
[20:13:18] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[20:13:22] <lpapp> template class Vec2<int>;template class Vec2<float>;template class Vec2<double>; where I implement Vec2<T> fully in a header?
[20:13:27] <lpapp> PJBoy: ???
[20:13:48] <PJBoy> so explicit instantiations?
[20:14:05] <PJBoy> presumably they'd need to be in a source file, yeah
[20:14:31] *** Quits: cursey (~cursey@user/cursey) (Ping timeout: 244 seconds)
[20:14:36] <lpapp> that is a real shame for a library that is meant to be header-only
[20:15:03] <lpapp>  so, basically, you cannot write a header-only library with explicit instantiation? That is a bit disappointing.
[20:15:11] <imMute> why do you need to explicitly instantiate templates in a header-only library?
[20:15:18] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[20:15:42] <lpapp> to only support those types?
[20:16:12] <imMute> lpapp: the user of the library can instantiate the template with whatever types they want.
[20:16:12] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:16:18] <InPhase> lpapp: You can use static_assert
[20:16:35] <InPhase> lpapp: And is_same_v
[20:17:04] <lpapp> are you saying that explicit instantiation does not make sense ?
[20:17:36] <lpapp> InPhase: C++17, but yes, we can use std::is_same, however that is not the point, I guess.
[20:17:40] <imMute> lpapp: yes, I don't see any reason for explicit instantiation in a header-only library.   and it definitely doesn't prevent users of the library from instantiating the template with other types.
[20:17:51] *** Quits: zen_coder (~zen_coder@141.113.64.22) (Ping timeout: 260 seconds)
[20:17:55] <InPhase> It does not by itself achieve your goal, and is not necessary to achieve the goal.  But if you throw a static_assert in that trips over the type, it will give a clean error message if a user tries to use unsupported types.
[20:18:01] <lpapp> would it prevent in a header and source library?
[20:18:15] <PJBoy> explicit instantiations are just an optimisation
[20:18:24] <LiaoTao> lpapp, SFINAE is your second choice, and that works for a wide enough variety of C++ versions
[20:18:34] <PJBoy> they don't prevent or allow anything
[20:18:41] <lpapp> then, what is the point?
[20:18:46] <PJBoy> optimisation
[20:18:48] <lpapp> of having this feature?
[20:18:50] <lpapp> what optimisation?
[20:18:51] *** Joins: cursey (~cursey@user/cursey)
[20:18:59] <imMute> they allow you to put the definition of the template in a source file instead of the header.
[20:19:18] <imMute> but you have to explicitly instantiate the template with all the ways you want to use it in that source file
[20:19:20] <lpapp> I am sorry, what?
[20:19:23] *** Joins: artok (~azo@mobile-access-bcee2b-18.dhcp.inet.fi)
[20:19:25] <PJBoy> oh yeah they do provide that
[20:19:29] <PJBoy> but eh
[20:19:44] <lpapp> maybe, I need to take a step back
[20:19:45] <PJBoy> you can have N files instantiating a Vec<float>, and the compiler will have to generate that Vec<float> N times
[20:19:50] <lpapp> what is the point of explicit instantiation then?
[20:19:56] <lpapp> if it is not to specify what you want to support?
[20:20:05] <PJBoy> or you can explicitly instantiate a Vec<float>, and your N files will all use that instantiation
[20:20:10] <lpapp> Then, is there any point in them other than blocking header-only libraries? Which are largely useful?
[20:20:11] <PJBoy> so it saves compile time there
[20:20:31] <InPhase> lpapp: It's so that you don't have to make everything header-only, which is nicer but compiles slower.
[20:20:45] <imMute> lpapp: we just gave you two.
[20:20:55] <lpapp> sick
[20:21:01] <lpapp> why is it not allowed in headers?
[20:21:11] <imMute> it's allowed in headers, it just doesn't do anything useful
[20:21:13] <PJBoy> because of the one definition rule
[20:21:25] <PJBoy> explicit instantiations are definitions
[20:21:25] <lpapp> it does not make sense that you cannot optimise this in a header-only library
[20:21:35] *** Quits: pah_ (~pah@host-79-49-135-108.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[20:21:43] <InPhase> It does not optimize anything at the point that it's all in the header.
[20:21:43] <PJBoy> and there's no inline version
[20:21:46] <imMute> lpapp: the optimization comes from doing work once.  the whole point of a header-only library is to put everything in headers, which necessarily duplicate work.
[20:22:05] <PJBoy> yeah header-only libraries have the opposite goal of explicit instantiations
[20:22:15] <PJBoy> to make the compiler do as much work as possible
[20:22:30] <lpapp> so, I guess header-only libraries are not such a big fun as I thought.
[20:22:44] <PJBoy> yeah header only libraries suck
[20:22:47] <LiaoTao> They're great if you are the end user and don't mind slightly increased compile times
[20:22:53] <PJBoy> they're just a little easier to integrate into a project
[20:23:04] <lumbermb> I find them pretty useful tbh, but personally I prefer the header-only-with-single-cpp library model
[20:23:04] <imMute> the only good thing about header-only libraries is they're easy to pull in to a project.  after that they're just downsides.
[20:23:04] <lpapp> maybe a language improvement for the future to allow this for headers? Cannot see why this declaration to the compiler would be restricted to the source.
[20:23:08] <InPhase> I think header-only libraries are pretty great in terms of flexibility and ease of integration.  But they do slow compile times a bit.
[20:23:11] <PJBoy> if it weren't for the terrible library linking experience that is C++, no one would use header only libraries
[20:23:31] <imMute> lumbermb: header only with a #define you set before including to get the single-cpp part ;)
[20:23:46] <InPhase> PJBoy: Or conversely, if not for the terrible compile times, everyone would use header only libraries.  :)
[20:23:47] <lumbermb> that too ;)
[20:23:57] <PJBoy> InPhase, haha, indeed
[20:24:03] *** Joins: pah (~pah@user/pah)
[20:24:04] <lpapp> that does not make sense to me.
[20:24:07] *** Quits: Ronalds_Mazitis_ (~Ronalds_M@46.109.76.104) (Quit: Connection closed)
[20:24:12] <lpapp> That you can only optimise the compiler in a source, and not header.
[20:24:25] <PJBoy> source files are files that are compiled once
[20:24:30] <InPhase> lpapp: You're misundestanding what's being optimized.
[20:24:36] <PJBoy> headers are files that are processed by every source file that includes it
[20:24:47] <lpapp> anyway, no header-only library then, I guess!
[20:24:50] <PJBoy> hence anything in a header is more expensive to compile than anything in a source file
[20:24:51] <lumbermb> there's a diference between source files and translation units (the latter is what the compiler *actually* cares about)
[20:24:51] <InPhase> lpapp: The optimization is specifically NOT recompiling the contents that you have put into the header, when it's not in the header.
[20:25:15] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[20:25:54] <PJBoy> anyways
[20:25:57] * LiaoTao shrugs
[20:26:01] <PJBoy> you don't actually care about explicit instantiations anyway
[20:26:08] <PJBoy> so you can go about your header only business like usual
[20:26:32] <LiaoTao> Never seen anyone this upset about one of the actual non-issues of C++, especially when there's so much other stuff to complain about
[20:27:49] <InPhase> lpapp: Header-only will always win for maximum flexibility and ease of use.  Minimizing header content will compile faster.  Templates must be header only to be flexible in types, and can really only work defined outside of the header if you explicitly instantiate.  Hopefully that sums it up.
[20:28:57] <InPhase> The only way to avoid explicit instantiation with a template defined outside of the header is to define it in the same file you will use it in.
[20:29:50] <InPhase> For this reason, templates are most often done header-only, especially if it is a library targetting reuse.
[20:29:57] *** Joins: kenanmarasli (~kenanmara@user/kenanmarasli)
[20:30:56] *** Quits: pah (~pah@user/pah) (Ping timeout: 245 seconds)
[20:30:56] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:31:05] *** Quits: proller (~p@2a02:6b8:0:51e:ff06:8de1:4ad8:5bfb) (Ping timeout: 260 seconds)
[20:31:48] <lpapp> Header-only lost huge loads here
[20:31:56] <lumbermb> you can never *really* prevent anyone from instantiating your templates however they want. Not even std can do that. What people do, and listen to, is documentation: "instantiations other than Foo ro Bar are ill-defined / considered UB / unsupported"
[20:32:27] <lumbermb> (which is how basically all type traits are defined, for example)
[20:32:49] *** Joins: great_taste (~great_tas@190.32.235.20)
[20:33:10] <lpapp> Because our APIs will not work with other instances, it is not an issue
[20:33:32] <lpapp> to explicitly instantiate them, in fact, in my case, a non-reusable library, this is the right thing to do, I understand it now after this discussion
[20:33:43] <lpapp>  for me, header-only libraries are a big sucker for compilation times :)
[20:34:09] <lpapp> will try to avoid them in this project like plague
[20:34:23] <lpapp> compilation time is a big issue in our project, unfortunately, this would just make things a lot worse.
[20:34:29] <lumbermb> header-only libraries, or header-preferent libraries, are what keeps me from switching away from C++ to Python
[20:35:24] *** Joins: pah (~pah@user/pah)
[20:36:09] <lpapp> Thanks for the discussion and input, I appreciate that.
[20:36:33] <lpapp> It made me understand that header-only libraries are not rosy-cosy after all.
[20:37:22] *** Joins: luizfrds (~Luiz@152.250.243.147)
[20:38:00] <lpapp> lumbermb: I guess it makes sense in some cases, like smaller projects and reusable libraries.
[20:38:26] <lpapp> Although, conan resolves the issues with header and source libraries, too.
[20:38:45] <lpapp> conan and cmake.
[20:38:52] <InPhase> luizfrds: You can absolutely prevent it, with static_assert and SFINAE.  At least up through them actually editing the template.
[20:39:04] <lumbermb> Oh? what does conan do with stuff like header-only libraries?
[20:39:18] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[20:39:53] *** Joins: pah_ (~pah@host-80-116-237-69.pool80116.interbusiness.it)
[20:40:28] <LordKalma> ships you the headers
[20:40:31] <LordKalma> what else would it do?
[20:40:37] <luizfrds> wait what?
[20:40:43] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[20:40:51] <LordKalma> "what does conan do with stuff like header-only libraries?"
[20:40:55] <LordKalma> ship you the headers
[20:41:06] <lpapp> you specify your dependencies
[20:41:13] <LordKalma> ships that too
[20:41:20] <lpapp> from that point on, it does not matter what technology the library comes with
[20:41:21] <LordKalma> as with everything
[20:41:28] <lpapp> not interesting detail anymore :_
[20:41:31] <lpapp> :)
[20:41:38] <LordKalma> https://github.com/conan-io/conan-center-index/blob/master/recipes/miniaudio/all/conanfile.py#L68
[20:41:39] <lpapp> This was useful before you had a proper dependency management system
[20:42:04] <lpapp> so, header-only has become a bit moot with conan, cmake, etc.
[20:42:49] <lpapp> You would not copy headers around for anything non-toy caliber, I would think.
[20:47:15] *** Joins: c4017w (~c4017@209.52.68.8)
[20:59:26] *** Joins: magla (~gelignite@55d4747b.access.ecotel.net)
[20:59:26] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[21:00:53] *** Quits: lionkor (~lionkor@200116b80fb518007285c2fffea63d72.dip.versatel-1u1.de) (Remote host closed the connection)
[21:01:14] *** Quits: paulmcquad (~gamer@78.17.229.141) (Quit: Konversation terminated!)
[21:01:16] *** Joins: lionkor (~lionkor@200116b80fb518006bb1b386965aceb8.dip.versatel-1u1.de)
[21:08:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[21:11:30] <rpav> it really hasn't become moot, and a lot of things use header-only libraries
[21:12:02] <lpapp> well, if conan can pull you in both header-only and header-and-source libraries, what is the reason for slowing down your compilation time?
[21:12:12] <rpav> of course it doesn't help that a lot of things basically require being header-only anyway
[21:12:46] <rpav> i'd want to see benchmarks about how it actually impacted things and what the difference actually is
[21:12:49] <rpav> link-time is nontrivial
[21:13:19] <rpav> though really the most impactful things generally can't be worked around anyway
[21:13:19] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[21:13:26] *** Quits: UmarJ (~username@user/umarj) (Ping timeout: 245 seconds)
[21:15:22] <lumbermb> the stuff that has to be header-only has to be header-only yeah. Other times, header-only enhances adoption, in particular if otherwise the size of the library is small enough that it's not really determinant in compilation times
[21:15:46] <lumbermb> Like, if I see someone using eg.: Boost, they should not complain about adding 8 seconds more of compile time to a 45 min process.
[21:15:51] <rpav> i'm not sure i've seen too many libraries that are "header only" vs "header and library"
[21:15:57] <rpav> mostly it's "single header" vs "multiple header"
[21:16:20] <rpav> there are probably some rare things with a #define somewhere but that's not really different than header-and-library
[21:17:29] <lumbermb> single-header libraries are kinda difficult, unless they aim to solve very specific problems with a strongly specified API.
[21:17:45] <lumbermb> multiple-header libraries are kinda difficult because, well, *multiple*
[21:17:46] <rpav> not really, they're `cat *.h > single_header.h`
[21:18:20] <rpav> of course if you really want to save (full-source) compile time, you want unity builds, which is `cat *.{cpp,h} > single_file.cpp`
[21:19:05] <rpav> (or into some small selection of files so you can still take advantage of -j)
[21:19:21] *** Quits: Tobbi (~Tobbi@2a02:8108:1240:48ec:146e:edfd:ccd9:4c5c) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[21:20:51] *** Quits: emerent (~quassel@p200300cd57485562ba27ebfffed28a59.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[21:21:06] *** Joins: emerent (~quassel@p200300cd5748557eba27ebfffed28a59.dip0.t-ipconnect.de)
[21:22:25] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[21:22:34] *** Quits: pah_ (~pah@host-80-116-237-69.pool80116.interbusiness.it) (Ping timeout: 260 seconds)
[21:22:37] *** Quits: imMute (~immute@user/immute) (Quit: Reconnecting)
[21:22:45] *** Joins: imMute (~immute@user/immute)
[21:24:18] *** Joins: pah (~pah@user/pah)
[21:25:33] <lumbermb> yeah that makes sense
[21:30:41] *** Quits: Deneb (~johnch@86.111.189.80.dyn.plus.net) (Quit: Leaving)
[21:34:39] *** pah is now known as pa
[21:36:45] <manuels> is it common practice to include all header files of a  library into one single header like winapi.h?
[21:37:07] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[21:37:14] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[21:37:14] *** ChanServ sets mode: +v npaperbot
[21:37:20] <rpav> it's pretty common to have a "single entry" to include a library, depending
[21:37:43] <rpav> if your API is relatively compact and generally anything that wants it is going to want most of it
[21:38:11] <rpav> but definitely bigger libraries (obvious example, Qt) split things up more
[21:39:33] *** Parts: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) ()
[21:40:13] <manuels> how do I write a single entry in a cmake context?
[21:40:46] <rpav> make one mylib.hpp that #includes <mylib/other.hpp> etc?
[21:40:52] *** Joins: meator (~meator@user/meator)
[21:41:30] <manuels> is it simply writung a include/lib.h  containing a multiple # include "lib/xyz.h" files?
[21:41:55] <rpav> usually
[21:42:19] <rpav> if you want a single-header library you want to write it such that you can easily combine all the files into a single file
[21:43:43] *** Quits: markong (~kvirc@213.146.188.203) (Ping timeout: 260 seconds)
[21:52:55] *** Quits: skapata (~Skapata@user/skapata) (Remote host closed the connection)
[21:55:25] *** Quits: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca) (Remote host closed the connection)
[21:55:43] *** Joins: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca)
[21:59:56] *** Quits: wasd (~wasd@user/axis) (Ping timeout: 246 seconds)
[21:59:58] <great_taste> { foo(nullptr); } template <typename T> void foo(T *t) {}
[21:59:58] <geordi> error: no matching function for call to 'foo(nullptr_t)'
[22:00:25] <great_taste> how could you have an optional template parameter?
[22:01:54] *** Joins: wasd (~wasd@100.101.7.51.dyn.plus.net)
[22:02:18] *** wasd is now known as Guest3655
[22:03:23] *** Quits: meator (~meator@user/meator) (Remote host closed the connection)
[22:03:50] <imMute> great_taste: give it a default?
[22:04:56] *** Joins: Tobbi (~Tobbi@2a02:8108:1240:48ec:146e:edfd:ccd9:4c5c)
[22:08:03] <hnOsmium0001[m]> { foo(nullptr); } template <typename T = void> void foo(T *t) {}
[22:08:03] <geordi> Same error.
[22:08:43] <hnOsmium0001[m]> oh in this case it's more convenient to just add a nullptr_t overload than trying to mess with templates default parameter
[22:08:43] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:08:45] *** Joins: UmarJ (~username@user/umarj)
[22:09:00] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:09:25] <rpav> or just have a `void foo() {}` overload :P
[22:09:41] <rpav> you need to ask yourself what you're actually trying to accomplish here
[22:13:16] <great_taste> or use std::optional
[22:14:15] <rpav> i think you're confusing "default template argument" with "optional/default function argument"
[22:14:15] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:17:13] <imMute> { foo(nullptr); }  void foo(int*t){}
[22:17:14] <geordi>  
[22:17:58] <imMute> I can see why the non defaulted template argument doesn't work (what would T be?) but why can't nullptr be converted to a void* for the other one??
[22:19:16] *** Joins: pah (~pah@user/pah)
[22:19:30] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[22:20:39] <malinus> How do I implement a template with two implementations, one that is called if a specific type_trait is true, and another when it's false? It's easy peasy with concepts, but I'm on c++17. Is SFINAE what I want?
[22:20:48] <malinus> template function, that is.
[22:22:27] <great_taste> optional parameter that happens to be a template
[22:23:03] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:25:45] <malinus> great_taste: not sure I'm following? like foo(T, bool trait=type_trait<T>::value)? Problem is that I'm doing operations on T that are only possible if/if not the trait is true, so the compiler gives errors. Unless you meant something else?
[22:25:52] *** Joins: wootehfoot (~wootehfoo@user/wootehfoot)
[22:27:41] <great_taste> I think I'll need overloads because that doesn't seem practical
[22:28:05] <great_taste> or I'd have to use a variadic
[22:30:54] <rpav> what are you _actually trying to accomplish_, like what's some context
[22:33:24] <lumbermb> malinus, unless I'm missing something obvious foo(T t) { return foo_implementation_class<T, conditions<T> >(t); } should work?
[22:33:35] <lumbermb> At least, that's how eg.: iterator stuff has done it since forever
[22:33:51] <great_taste> a function that takes an optional iterator
[22:34:07] <great_taste> extra things will be done if the iterator is provided
[22:34:48] <great_taste> such as... it takes a list of vertex positions and an optional list of vertex colors
[22:34:49] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:35:05] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:35:23] <rpav> oh i missed malinus's Q but yeah
[22:36:08] <rpav> great_taste: is your function already a template? seems weird for something that takes a vector of verts or something
[22:36:11] <great_taste> oh lol yeah malinus' question got mixed in the discussion
[22:36:30] <malinus> yeah confusion is total :), let me specify again.
[22:36:39] <great_taste> rpav I am taking an iterator
[22:37:12] <rpav> really you probably ought to have like `void process(const vertvec& verts);` and `void process(const vertvec& verts, const colvec& colors);` or similar
[22:37:46] <rpav> i mean you could take an iterator too, i'm not sure if it's quite as ick as it sounds ubt
[22:38:02] <rpav> it's not hard to get an iterator from a thing i guess, but you also probably need an _end_ iterator of course, and then
[22:43:18] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[22:44:02] *** Joins: pah (~pah@user/pah)
[22:44:43] *** Quits: h4ppy (~happy@user/h4ppy) (Quit: WeeChat 2.8)
[22:45:06] *** Joins: horribleprogram (~user@2607:fea8:7040:830:1431:b543:c667:1c6a)
[22:45:17] *** Quits: horribleprogram (~user@2607:fea8:7040:830:1431:b543:c667:1c6a) (Changing host)
[22:45:17] *** Joins: horribleprogram (~user@user/horribleprogram)
[22:52:00] *** Joins: Tokamak (~Tokamak@107.117.203.34)
[22:53:52] <malinus> lumbermb: yeah that's exactly what I wanted, thanks.
[22:54:20] <malinus> lumbermb: still much less boilerplate with concepts, that's a nice concept
[22:54:25] * malinus signs off
[22:58:17] *** Quits: garo (~garo@ptr-1pln5puxqxmejxq9kws.18120a2.ip6.access.telenet.be) (Ping timeout: 264 seconds)
[22:59:09] *** Joins: garo (~garo@ptr-1pln5puxqxmejxq9kws.18120a2.ip6.access.telenet.be)
[23:00:05] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[23:01:08] *** Quits: wootehfoot (~wootehfoo@user/wootehfoot) (Read error: Connection reset by peer)
[23:08:45] *** Joins: X-Scale` (~ARM@31.22.167.71)
[23:09:16] *** Quits: X-Scale (~ARM@50.77.166.178.rev.vodafone.pt) (Ping timeout: 245 seconds)
[23:10:52] *** X-Scale` is now known as X-Scale
[23:15:50] *** Joins: spaceangel (~spaceange@ip-89-176-181-220.net.upcbroadband.cz)
[23:27:29] *** Joins: TheGuestMovie (~TheGuestM@173.231.114.74)
[23:33:51] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[23:33:58] *** Joins: proller (~p@80.240.216.69)
[23:34:23] *** Joins: pah_ (~pah@host-87-20-64-150.retail.telecomitalia.it)
[23:34:47] *** Quits: ___nick___ (~quassel@cpc68286-cdif17-2-0-cust533.5-1.cable.virginm.net) (Ping timeout: 260 seconds)
[23:36:36] *** Joins: bobb_ (~bobb_@dslb-092-074-236-095.092.074.pools.vodafone-ip.de)
[23:42:10] <LordKalma> Do you know any DB that like, I can do "polymorphic" behaviour on? What I mean is. An entry can be several things, or not. And for each thing the entry is, it gains its fields, or something like that
[23:42:25] <LordKalma> like a database with inheritance/composition
[23:42:37] <LordKalma> which is not just a flat table with all possible fields left blank
[23:43:16] *** Joins: RoKenn (~RoKenn@2001:a61:3505:d101:b4b5:1d8:302c:6e02)
[23:43:16] *** Quits: RoKenn (~RoKenn@2001:a61:3505:d101:b4b5:1d8:302c:6e02) (Changing host)
[23:43:16] *** Joins: RoKenn (~RoKenn@user/rokenn)
[23:46:06] <TinoDidriksen> PostgreSQL tables can inherit from other tables.
[23:46:54] <TinoDidriksen> https://www.postgresql.org/docs/current/tutorial-inheritance.html
[23:46:54] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[23:47:44] <TheGuestMovie> it's better to use a noSQL document store no? so the object "kalma": { "im-entity1": { "entity1field1": 123, "entity2field2", 456 } , "im-also-entity2": { "entity2field1": "whatever" } }
[23:48:49] <TheGuestMovie> and if he decides to make "kalma" be an entity3 instead of entity2, he just drops the im-also-entity2 subkey, and adds a new one "entity3"
[23:48:50] *** Quits: horribleprogram (~user@user/horribleprogram) (Remote host closed the connection)
[23:49:26] <TheGuestMovie> the names should probably be fixed entity1, entity2, entity3 across all objects, so you can do subqueries, like *.entity3
[23:55:13] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[23:55:58] <LordKalma> TinoDidriksen, looks really cool, but not exactly what I want. Basically, what I want is, using object notation names: when I create a new object (entry in the DB) that object is guaranteed to be of the basic type. But it can belong to *one or more* other types. Like, there's the basic fields, and it can gain aditional fields depending on what it is exactly, in any arbitrary combination of the optional field "groups"
[23:56:47] *** Quits: Tokamak (~Tokamak@107.117.203.34) (Ping timeout: 264 seconds)
[23:57:39] *** Joins: skapata (~Skapata@2804:14c:87b0:a6f9:1849:4f5f:1c0b:e16f)
[23:57:39] *** Quits: skapata (~Skapata@2804:14c:87b0:a6f9:1849:4f5f:1c0b:e16f) (Changing host)
[23:57:39] *** Joins: skapata (~Skapata@user/skapata)
