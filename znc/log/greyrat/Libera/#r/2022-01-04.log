[01:05:23] *** Quits: triberio13 (~triberio1@195.53.32.158) (Quit: Konversation terminated!)
[02:18:31] *** Quits: palasso (~palasso@user/palasso) (Quit: I am not a quitter!)
[02:47:12] *** Quits: Vojtaeus (~vojta@user/vojtaeus) (Quit: Odcházím...)
[02:56:17] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Ping timeout: 240 seconds)
[03:30:13] *** Quits: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl) (Ping timeout: 256 seconds)
[03:42:51] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Remote host closed the connection)
[04:11:52] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[04:41:07] *** freddy is now known as frmg
[04:47:29] *** Quits: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net) (Quit: Abandonando - Leaving)
[04:47:51] *** Joins: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net)
[04:48:51] *** Joins: freddy (~frmg@190-72-79-137.dyn.dsl.cantv.net)
[04:49:11] *** Quits: freddy (~frmg@190-72-79-137.dyn.dsl.cantv.net) (Remote host closed the connection)
[04:54:52] *** Quits: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net) (Quit: Abandonando - Leaving)
[04:55:14] *** Joins: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net)
[05:48:11] *** Quits: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net) (Quit: Abandonando - Leaving)
[06:14:34] *** Quits: Sheilong (uid293653@id-293653.ilkley.irccloud.com) ()
[06:18:31] *** Quits: twrk (~user@user/twrk) (Ping timeout: 256 seconds)
[06:48:20] *** Joins: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net)
[06:52:15] *** Parts: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net) ()
[07:01:56] *** Quits: eliocamp (~eliocamp@user/eliocamp) (Quit: The Lounge - https://thelounge.chat)
[07:07:54] *** Quits: vd (~vd@bras-base-mtrlpq2848w-grc-41-70-53-240-211.dsl.bell.ca) (Quit: Client closed)
[07:09:52] *** Joins: vd81 (~vd@bras-base-mtrlpq2848w-grc-41-70-53-240-211.dsl.bell.ca)
[07:18:00] *** Joins: twrk (~user@user/twrk)
[09:02:01] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[09:02:01] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Client Quit)
[09:02:46] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[09:14:18] *** Quits: vd81 (~vd@bras-base-mtrlpq2848w-grc-41-70-53-240-211.dsl.bell.ca) (Quit: Client closed)
[09:35:43] *** Quits: perro_ (~perro@072-191-245-069.res.spectrum.com) (Ping timeout: 256 seconds)
[09:59:48] *** Joins: perro_ (~perro@072-191-245-069.res.spectrum.com)
[11:07:52] *** Joins: Vojtaeus (~vojta@user/vojtaeus)
[11:29:13] *** Joins: palasso (~palasso@user/palasso)
[11:54:24] *** Joins: DrNostril (~DrNostril@217.138.219.164)
[12:24:30] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi)
[12:55:11] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Ping timeout: 256 seconds)
[12:56:29] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[13:05:08] *** Quits: DrNostril (~DrNostril@217.138.219.164) (Quit: Leaving)
[13:12:58] *** Joins: rickyrick_ (~rickyrick@S01069050ca454523.vf.shawcable.net)
[13:12:58] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Killed (NickServ (GHOST command used by rickyrick_)))
[13:32:43] *** Quits: rickyrick_ (~rickyrick@S01069050ca454523.vf.shawcable.net) (Ping timeout: 256 seconds)
[13:59:56] *** Quits: ph88 (~ph88@2a02:8109:9e00:71d0::7e04) (Ping timeout: 268 seconds)
[15:28:19] *** Joins: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl)
[16:10:26] *** Joins: usr725635 (~User@cpe-45-47-86-32.twcny.res.rr.com)
[16:16:44] *** CuriousErnestBro is now known as cactus
[16:18:36] *** cactus is now known as CuriousErnestBro
[16:25:49] *** Quits: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl) (Ping timeout: 240 seconds)
[16:26:16] *** Joins: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl)
[16:38:33] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi) (Read error: Connection reset by peer)
[16:39:43] *** Quits: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl) (Ping timeout: 256 seconds)
[16:42:03] *** Joins: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl)
[16:43:11] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: -now)
[16:46:59] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi)
[16:47:05] *** h_m is now known as confuzius
[17:06:21] *** Joins: ph88 (~ph88@2a02:8109:9e00:71d0::7e04)
[17:20:43] *** Joins: marcello42 (~mp@2001:1a81:12a9:b900:4ccd:c26d:723b:afc2)
[17:23:16] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[17:35:49] *** Quits: marcello42 (~mp@2001:1a81:12a9:b900:4ccd:c26d:723b:afc2) (Ping timeout: 240 seconds)
[17:44:42] *** Joins: eliocamp (~eliocamp@user/eliocamp)
[17:57:19] *** Joins: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net)
[18:04:31] *** Joins: kmh (~kmh@2a00:6020:5004:6800:a21f:ef4a:1372:da5b)
[18:11:01] *** Joins: rinzewind (~rinzewind@user/rinzewind)
[18:30:39] *** Quits: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl) (Ping timeout: 256 seconds)
[18:34:01] *** Joins: flower_ (~debian@217-123-218-6.cable.dynamic.v4.ziggo.nl)
[19:18:35] *** Joins: DrNostril (~DrNostril@217.138.197.44)
[19:39:49] <Bayes> does anyone know of a good reference for "data management"? things like definitions of raw data, transformed data, long data, wide data, etc
[19:40:40] <twrk> https://r4ds.had.co.nz/tidy-data.html ?
[19:42:47] <twrk> or just r4ds in general. I'm sure there's another reference out there using base R... just haven't looked for it
[19:44:28] <confuzius> here is another one: https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf
[19:52:48] <DrNostril> who knows a good way of visualizing/representing a multinom() model?
[19:53:14] <twrk> multinom or nom noms
[19:56:12] <DrNostril> har har
[19:59:57] *** Quits: usr725635 (~User@cpe-45-47-86-32.twcny.res.rr.com) (Ping timeout: 240 seconds)
[20:01:47] *** Quits: confuzius (~h_m@186-149-117-154.bitcointernet.co.za) (Remote host closed the connection)
[20:03:33] *** Joins: confuzius (~h_m@186-149-117-154.bitcointernet.co.za)
[20:09:37] *** Joins: debianero (~debianero@60.132.134.77.rev.sfr.net)
[20:11:54] <Bayes> confuzius that's very neat, thanks!
[20:12:24] <Bayes> twrk a bit too tidy-centric but thanks anyway
[20:13:33] <Bayes> https://www.jstatsoft.org/article/view/v059i10 that seems to be the base paper
[20:17:32] *** Quits: DrNostril (~DrNostril@217.138.197.44) (Quit: Leaving)
[20:22:15] *** Joins: usr725635 (~User@cpe-45-47-86-32.twcny.res.rr.com)
[20:23:47] *** Joins: usr725635_ (~User@cpe-45-47-86-32.twcny.res.rr.com)
[20:26:37] *** Quits: usr725635 (~User@cpe-45-47-86-32.twcny.res.rr.com) (Ping timeout: 240 seconds)
[20:31:51] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi) (Read error: Connection reset by peer)
[20:35:56] *** Joins: warrior`of`light (~micahb@68.179.154.138)
[20:36:20] *** Parts: warrior`of`light (~micahb@68.179.154.138) ()
[20:43:34] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[20:51:44] <Bayes> advanced R cheatsheet https://www.rstudio.com/wp-content/uploads/2016/02/advancedR.pdf
[20:52:07] *** Joins: _hm_ (~h_m@186-149-117-154.bitcointernet.co.za)
[20:52:08] * rickyrick slaps Bayes with the R inferno
[20:52:10] <rickyrick> :^)
[20:52:49] *** Quits: confuzius (~h_m@186-149-117-154.bitcointernet.co.za) (Read error: Connection reset by peer)
[20:54:14] *** Quits: _hm_ (~h_m@186-149-117-154.bitcointernet.co.za) (Client Quit)
[20:54:46] *** Joins: confuzius (~h_m@186-149-117-154.bitcointernet.co.za)
[21:06:17] *** Quits: Vojtaeus (~vojta@user/vojtaeus) (Quit: Odcházím...)
[21:33:50] <Bayes> Im looking at some old code I wrote
[21:34:06] <mefistofeles> Bayes: are you facepalming already?
[21:34:06] <mefistofeles> xD
[21:34:15] <Bayes> triple nested lapply, an anon function, and two nested unlists
[21:34:27] * Bayes sadface
[21:35:03] <fendur> did it get the job done?
[21:35:22] <Bayes> yeah, but now wanted to introduce a small variation and .................................................
[21:35:29] <mefistofeles> haha
[21:35:33] <rickyrick> :^)
[21:35:40] <fendur> ok then yes you should be shamed
[21:36:02] <mefistofeles> nah, it's okay
[21:36:15] <rickyrick> Should have just copy-pasted the loop contents
[21:36:23] <rickyrick> It's called loop-unrolling :^)
[21:36:36] <Bayes> cool thing is that I wrote once an xply function that works like apply but for a combination of many factors... so rewriting the triple nested lapply shouldn't be too problematic
[21:36:46] <Bayes> (we all know it will be anyway)
[21:37:00] <rickyrick> expand.grid |> apply(1,
[21:37:02] <rickyrick> :^)
[21:37:48] <fendur> loop-unrolling is best practice. so much clearer than a loop.
[21:38:10] <fendur> with loops, you have to imagine doing the same thing over and over and over, possibly millions of times.
[21:38:28] <fendur> if unrolled, it's super explicit.
[21:38:39] * rickyrick writes a loop to generate an unrolled loop
[21:38:49] <Bayes> rickyrick will the pipe pass the column as named arguments to apply?
[21:38:49] <fendur> that's innovation
[21:39:21] <rickyrick> I think you can get \(x) x["name"]
[21:39:28] <rickyrick> I don't remember exactly :^)
[21:39:39] <Bayes> yeah I think x['name'] too
[21:40:07] <Bayes> http://ix.io/3L1p this helps
[21:40:40] <Bayes> just xpply(myfun, x, y, z) and x, y, z will get outer'd and pass to myfun
[21:41:05] <rickyrick> Now come up with a way of not explicitly generating xList :^)
[21:41:28] <Bayes> for like large structures?
[21:41:33] <rickyrick> ya
[21:42:23] <Bayes> hm idk how I would Map online
[21:42:47] <Bayes> a compromise would be to generate all combinations of indices
[21:43:40] <Bayes> but yeah writing a recursive xpply seems like a pita
[21:44:13] <rickyrick> :^)
[21:44:26] * rickyrick brings out the for loops
[21:53:05] <eliocamp> If you don't want to jump off a bridge every time you read old code you wrote, when you haven't improved as a programmer. 
[21:56:01] <eliocamp> I have trend estimates + std.errors of multiple members of a climate model. How would you plot the result? 
[21:56:02] <eliocamp> Showing every single estimate is kind of a lot (multiple models, multiple variables and multiple vertical levels) so I'm thinking I could combine all into one estimate + std.error. How would you do that? I recall that Bayes had a similar problem not long ago. 
[21:56:07] *** Joins: triberio13 (~triberio1@195.53.32.158)
[22:06:16] <Bayes> eliocamp yeah I did
[22:07:32] <Bayes> so in my case, I had 5 model families using 5 different inputs and 8 data subsets, so I had one (validation) statistic per 5 x 5 x 8 comb
[22:08:20] <Bayes> I set up a hierarchical model (read, mixed effects) to compare models and inputs
[22:09:12] <Bayes> and I just ended up plotting the marginal means (ie a model averaged over all inputs and subsets)
[22:09:19] <Bayes> even tho the model had all fancy interactions and such
[22:09:45] <Bayes> and finally dumped the whole table as supplementary material
[22:10:17] <Bayes> would that make sense eliocamp?
[22:11:19] <eliocamp> I don't know. I've never really looked into hierarchical models so I don't know if it'd work for me. 
[22:12:02] <eliocamp> I don't think I need a lot of fancy stuff, since each realisation is basically independent. It's just  performing the same experiment multiple times. 
[22:12:29] <Bayes> I get that, you want the mean across replications
[22:12:37] <Bayes> and then the "marginal means"
[22:13:49] <Bayes> mean across replications for statements like: Model `modA` with Variable `var3` works best for Vertical `vert2`
[22:14:37] <Bayes> marginal means: Model `modA` produces, on average, the best results when averaged across all possible variables and vertical levels
[22:15:24] <Bayes> design of experiment is the thing I would never ever study but I'd love to know by osmosis
[22:15:27] <Bayes> ^_^
[22:16:52] <fendur> i often wish my adviser did not advise _against_ studying experimental design.
[22:17:06] <Bayes> heh
[22:17:31] <fendur> "you'll be working on observational data. you will not be running experiments." as if that's the only reason to understand experimental design.
[22:17:36] <Bayes> the real twist is that design of experiments is useful for observational analyses too
[22:17:42] <eliocamp> Yeah, although I don't need to average across vertical levels. 
[22:17:42] <Bayes> yep exactly that
[22:18:53] <fendur> right. some innovations in observational data causal inference for sure come right from what we know about experimental design
[22:18:53] <eliocamp> (I expect vertical levels to be similar, so the estimate should be smooth-varying with height, but I treat each level more or less independently) 
[22:19:11] <Bayes> eliocamp for sure we don't know the specifics of your situation to understand what you want to average across, but part of creating a reasonable visualization is to identify the main factors in the message you want to convey
[22:19:25] <Bayes> then you integrate all other variability out
[22:19:26] <fendur> Bayes: the problem was that my adviser did not really understand what "causal inference" meant at the time.
[22:19:41] <Bayes> and leave the full dump table for the appendix
[22:19:55] <eliocamp> This is a oral presentation, so no dump table :P
[22:20:29] <Bayes> yeah just try not to have as many panes as AxB and colors as C
[22:20:37] <fendur> er, from observational data, i mean. he just thought you don't get causal estimates from observational data. i.e., there's standard limitation text to add to papers
[22:21:23] <Bayes> tbh I'm totally ignorant on causal inference even tho it always sounded like a rather relevant thing to understand
[22:21:35] <eliocamp> I need to communicate the trend simulated by each model at each level (and compare it to observations). But since each model has multiple realisations, I have multiple estimated trends (plus their standard error). 
[22:22:11] <Bayes> trend = response variable over vertical levels?
[22:22:22] <eliocamp> Trend = change over time
[22:22:23] <Bayes> as in - log10 hPa ?
[22:22:58] <Bayes> oh ok
[22:23:20] <eliocamp> Ideally I would like to have a single central estimate + uncertainty for each model (and each vertical level) 
[22:23:52] <Bayes> then integrate out the input variables
[22:24:20] <eliocamp> But now I have multiple estimates + uncertainty. The question is how to pool it. I could to the mean(estimate) +- sd(estimate), but that ignores the uncertainty in the estimates :\
[22:24:26] <Bayes> for each model and vertical level, report mean + se
[22:25:15] <Bayes> do you mean sd(estimate) or se(mean) ?
[22:26:08] <Bayes> forget about the replications, just take the mean across reps
[22:26:39] <Bayes> for each model and vertical level, report mean(var1, ... ,var5) + se(var1, ..., var5)
[22:27:00] <Bayes> se(var1, ..., var5) = sd(var1, ..., var5) / sqrt(5) or smth
[22:27:23] <eliocamp> So ignore se(var1), se(var2), and so forth?=
[22:27:42] <Bayes> yep
[22:28:52] <Bayes> I mean, don't know the specifics of your data again, but I'd except the uncertainty between variables to be magnitudes larger than within variables
[22:29:58] <Bayes> you can eyeball it first, visualizing the variability between and within
[22:30:44] <Bayes> look Im gonna show you
[22:31:27] <Bayes> https://i.imgur.com/yRzV2YE.png
[22:31:44] <Bayes> each facet/pane = one model and vertical level in your case
[22:32:13] <confuzius> is that not a candidate for meta analysis? though my limited understanding of it is more like an application of mixed models (as already mentioned by Bayes).
[22:32:15] <Bayes> each color = a variable in your case
[22:32:21] <Bayes> each colored interval = variability across replications for each variable
[22:32:48] <eliocamp> Yeah, variability between each realisation is not that different from std.error of each realisation https://i.imgur.com/a2G6fCY.png
[22:33:36] <Bayes> so, by ignoring the intervals se(var1), se(var2)... and keeping only the mean mean(var1, ... ,var5) I'm not really losing much just because the between variability is larger than the within variability
[22:33:54] <Bayes> that said, for an oral presentation, you do need to make some compromises for the purpose of clarity
[22:34:15] <Bayes> so it's ok to ignore the intervals if you know deep in ur heart that it's a reasonable simplification for this oral presentation
[22:34:29] <eliocamp> You're right. i might be overthinking this
[22:35:23] <Bayes> confuzius agreed, we were discussing a similar situation a year ago (ie a few weeks ago :P) with fendur and we concluded that yep it's meta analysis
[22:35:35] <Bayes> which in my case ended up being just a mixed effect model
[22:35:56] <Bayes> or more precisely a hierarchical linear model but same shit
[22:37:48] <eliocamp> Now I'm thinkng about how to treat vertical levels, though. The estimate of each vertical level is obviously not independent because adjacent levels will be very similar. So there should be a way of using that information to reduce the uncertainty of each estimate, right?
[22:37:58] <eliocamp> (I won't do it, though, I'm just thinking)
[22:39:46] <Bayes> that's effectively where confuzius ' mixed model joins the party
[22:40:11] <Bayes> basically it's a way to create a correlation structure among groups, and subgroups, in your statistics
[22:40:42] <eliocamp> Sounds exactly like what I'd need. 
[22:41:04] <Bayes> for example, all statistics generated on one band are somewhat correlated
[22:41:12] <Bayes> so you set up a random effect for that
[22:42:14] <Bayes> if you can spell out your validation process more precisely, I'd be happy to help you set this one up
[22:42:44] <Bayes> really the key is to figure out the correlation structure, after that it's a one liner
[22:43:42] <eliocamp> Thanks. I'll look into that, but not now because I need to first finish this presentation before my advisor leaves on vacation xD
[22:43:50] <Bayes> yeah I get that
[22:44:00] <Bayes> it's the kind of thing you do for fun on your own time
[22:44:10] <Bayes> or for learning
[22:49:40] <eliocamp> Yeah, but I also think it 'd be good methodoloty. 
[22:51:23] <eliocamp> There's a lot of these sort of "treat things as independent when they  are not" thing in climatology. My biggest pet peeve is the way that most people build regression fields. You basically perform a regression on each grid-point and report a map with colour mapped to that value plus some marker of statistical significance on that pixel. 
[22:52:16] <eliocamp> Which is, IMHO, very wrong because it doesn't take spatial correlation into account and it also means essentially performing thousands of statistical tests (one for each pixel). 
[22:53:02] <eliocamp>  /rant 
[22:53:50] <fendur> you're on the right track 
[23:00:03] *** Joins: marcello42 (~mp@2001:1a81:12a9:b900:4ccd:c26d:723b:afc2)
[23:02:27] *** Joins: Sheilong (uid293653@id-293653.ilkley.irccloud.com)
[23:51:10] *** Quits: frmg (~frmg@190-72-79-137.dyn.dsl.cantv.net) (Remote host closed the connection)
[23:51:12] *** Joins: freddy (~frmg@190-72-79-137.dyn.dsl.cantv.net)
[23:53:51] *** freddy is now known as frmg
[23:58:34] <Bayes> is the right assignment something you ever see in code?
[23:59:08] <fendur> not me. maybe in some tidyverse pipe code i've seen somewhere on the internet...
[23:59:36] <Bayes> eliocamp you know what the worst thing is? that adding a basic yet reasonably powerful spatial correlation in such case might actually not be that hard
