[00:06:06] *** Joins: SiegeLord (~sl@user/siegelord)
[00:06:11] *** Quits: jlrnick (~josephler@2a01cb040a15940038db3e71ef3adc74.ipv6.abo.wanadoo.fr) (Ping timeout: 268 seconds)
[01:27:09] <xs> you can interpret linear regression with an L2 loss probabilistically, but this isn't necessary nor is it how it was originally motivated.
[01:27:24] <xs> note that the L2 loss corresponds to a decision function that picks the best choice on average
[01:28:02] <xs> the gaussian motivation for linear regression is a little strange in this setting, as, what's the variance parameter doing?
[01:28:21] <xs> it makes a bit more sense with something like gaussian process regression, but even then it's a bit of a hack imho
[01:40:25] *** Quits: `Tim (~zenguin@user/zenguin) (Remote host closed the connection)
[01:40:43] *** Joins: `Tim (~zenguin@user/zenguin)
[01:56:24] *** Joins: medium_cool (~medium_co@2605:a601:a9aa:f800:f59a:5511:89e5:f851)
[02:05:47] <Klinda> as I understand in the probabilistic setting xs, your single y was generated by h(x^i) + random noise... these random noise follow a gaussian distribution with mean 0 and some variance sigma^2  so you can write it as random noise = y^i - theta^T x^i , so from this y^i - theta^T x^i  you can plug theta^T x^i  as the mean of the distribution and you end up calculatining the probability densitiy and so the likelihood according to that mean ...
[02:05:49] <Klinda>  and it's same as minimizing the loss function (y-h(x))^2
[02:08:17] <HuntsMan> Klinda: you are confusing assumptions with the model itself
[02:09:06] <Klinda> what do you mean?
[02:09:44] <Klinda> we start by saing that our y has a random noise, so h(x) + random noise
[02:09:45] <HuntsMan> you don't compute any probability density, for example
[02:10:26] <HuntsMan> Klinda: did you learn what is the central limit theorem?
[02:10:54] <Klinda> when we have y that was sample from a  N(theta^Tx, sigma^2)
[02:11:18] <Klinda> we can calculate P(y|x;theta)
[02:11:56] <Klinda> nope, didn't have time HuntsMan
[02:13:52] <HuntsMan> Klinda: you are just parroting stuff, not really understanding it
[02:14:06] <HuntsMan> Klinda: learn the central limit theorem to find out why we use the Gaussian distribution so much
[02:14:07] <Klinda> in our case theta is fixed for all y, so we can calculate the entrie distribution for the mean theta^Tx, that's what I understand
[02:14:33] <HuntsMan> to do what?
[02:15:34] <Klinda> I just understand that if you say that you are using the same theta, you are just using one distribution in the end
[02:16:03] <Klinda> because theta have to be the mean of all distributions of our y
[02:16:19] <Klinda> what change is the x given
[02:16:31] <HuntsMan> but for what is this? training? prediction? cross-validation? etc
[02:16:38] <Klinda> training
[02:17:18] <Klinda> I mean so in the probabilistic setting, maximize the log likelihood is the same as minimzing the cost function that you see in linear regression
[02:17:41] <Klinda> so that's the cause you can see as a generalized linear model
[02:18:31] *** Quits: palasso (~palasso@user/palasso) (Quit: I am not a quitter!)
[02:19:19] <Klinda> I know I am not good in math, but from the stanford course I am understaing that
[02:20:06] <mefistofeles> Klinda: you just need to learn and practice the math, stop thinking you are not good at it
[02:20:20] <mefistofeles> sounds like an excuse not to learn it, sometimes
[02:20:30] <Klinda> I have not time, really
[02:20:37] <Klinda> a lot of exams i have to do
[02:20:41] <Klinda> not only ml course
[02:20:42] <mefistofeles> ah okay, fair enough
[02:20:49] <mefistofeles> yeah, that's modern education
[02:20:55] <mefistofeles> there is not much learning going on xD
[02:22:14] <Klinda> so the probabilitic setting that they give you is just to see... hey maxmize the log likelihood used in generalized linear models is the same as we saw early in linear regression
[02:22:55] <Klinda> and that's the reason generalized linear models is composed by logistic regression etc
[02:23:06] <Klinda> are*
[02:23:45] <Klinda> all depends on what y do you want to have
[02:24:11] <Klinda> y = real numbers? laplace and gaussian!
[02:24:22] <Klinda> that's regression
[02:24:31] <Klinda> y binary ?
[02:24:34] <Klinda> bernoulli
[02:24:41] <Klinda> classificatio!
[02:24:54] <Klinda> y = {1,....,k} ?
[02:25:02] <Klinda> categorical!
[02:25:15] <Klinda> multinomial classification (softmax regression)
[02:25:16] <HuntsMan> Klinda: why are you even studying GLMs?
[02:25:31] <Klinda> Fabio explained us
[02:26:25] <Klinda> is that bad HuntsMan?
[02:26:43] <Klinda> you have also a general learning update rule for theta
[02:26:51] <Klinda> why don't you want it?
[02:28:03] <Klinda> The only thing that I didn't understand was about the fact how can I say that a linear regression is a GLM
[02:28:07] <Klinda> now I understood it
[02:28:32] <Klinda> just pick the mean of the distributions of the y's with the same theta
[02:28:34] <Klinda> and you have it
[02:29:40] <Klinda> but also it's not a problem discussing it because the y are just given
[02:30:09] <HuntsMan> it is an advanced topic for a ML course
[02:30:30] <HuntsMan> its more statistics than ML
[02:31:17] <Klinda> true
[02:31:20] *** Quits: manti7 (~manti7@176.10.104.94) (Quit: WeeChat 3.3)
[02:31:33] <Klinda> but in the end how the y are generated we don't care very much
[02:31:44] <Klinda> they are just given
[02:31:54] <Klinda> depends on what y you have, you have different algorithms
[02:32:00] <Klinda> *models
[02:33:02] <Klinda> what makes me really not understanding anything is that every y is generated by a different same type of distribution or not
[02:33:16] <Klinda> if*
[02:33:39] <Klinda> like you have two examples: (x=1,y=10) and (x=2,y=20)
[02:34:04] <Klinda> the frist y come from a gaussian, the second one from another gaussian different from the first?
[02:36:07] <Klinda> because for example in linear regression we have only one hypothesis
[02:36:48] <Klinda> that is the mean of every gaussian distribution
[02:36:52] <Klinda> of the y
[02:37:13] <Klinda> with this you have GLM xD
[02:39:44] <Klinda> but I am a noob in math, so I will maybe later understand it
[02:41:01] *** Joins: black_13 (~jjosb@2600:1700:1100:61c0:d8ac:8983:7bdd:2b24)
[02:42:06] <Klinda> I understand the fact that the line in linear regression is given by minimzing the cost function
[02:42:29] <Klinda> so your loss is lowa
[02:42:37] <Klinda> and we are happy, we are near the true y
[02:42:50] <Klinda> low*
[02:43:07] *** Joins: black_13_ (~jjosb@104-191-0-171.lightspeed.snantx.sbcglobal.net)
[02:46:17] *** Quits: black_13 (~jjosb@2600:1700:1100:61c0:d8ac:8983:7bdd:2b24) (Ping timeout: 240 seconds)
[02:47:18] <Klinda> if we suppose maybe that every y are generated by a gaussian with same mean (theta^T * x) and some variance, we can say that is the same as linear regression, but as I understand that if you have 14 number of y, you have 14 distributions that have the same mean and some variance, so we can merge it maybe nad we have linear regression?
[02:48:32] <Klinda> each y have the same theta and different x
[02:49:00] <Klinda> a distribution*
[02:49:14] *** Quits: black_13_ (~jjosb@104-191-0-171.lightspeed.snantx.sbcglobal.net) (Remote host closed the connection)
[02:49:49] *** Joins: black_13_ (~jjosb@2600:1700:1100:61c0:6165:890f:ce9d:d00a)
[02:50:09] *** Quits: georgios (~georgios@user/georgios) (Ping timeout: 250 seconds)
[02:57:23] <Klinda> HuntsMan: we assume that the y are coming from different gaussian distribution because we assume that the y have some noise and we wanna take the signal and not the noise in the end
[02:57:39] <Klinda> (we hope)
[02:59:15] <Klinda> so we find the the best theta that does it
[02:59:47] <mefistofeles> wow, what's with the monologue? xD
[03:01:25] <Klinda> do you wanna answer mefistofeles ?
[03:01:30] <Klinda> maybe the monologue end
[03:02:25] <mefistofeles> Klinda: well, if that monologue is a question, then no, I don't want to answer xD
[03:02:31] <mefistofeles> Klinda: what's the question?
[03:03:21] <Klinda> we are talking about GLMs, are you in touch with that?
[03:03:46] <mefistofeles> Klinda: what's the question?
[03:04:16] <mefistofeles> it works better if you ask the question in a concise manner, and if someone knows the answer they will probably help
[03:04:48] <Klinda> the answer is that why linear regression is a GLM ?
[03:06:33] <Klinda> question*
[03:06:39] <Klinda> xD
[03:07:40] <Klinda> as I was saying for what I understand, if we assume that each y is sample from a gaussin distribution with mean theta^Tx and some variance
[03:07:41] <mefistofeles> haha
[03:07:57] <Klinda> we have GLM
[03:08:06] <mefistofeles> wait, so you know the answer?
[03:08:13] <Klinda> but this is done by the probabilistic interpretation
[03:08:24] <Klinda> maybe mefistofeles
[03:08:37] <Klinda> but guess not as HuntsMan said something
[03:08:48] <mefistofeles> I'm not following tbh
[03:09:12] <Klinda> so you don't know the answer too :P
[03:09:29] <mefistofeles> I mean, it's "okay" if you want to treat this public IRC channel as your public notebook, but I think we can agree it's not the best idea :P
[03:09:50] <mefistofeles> Klinda: I didn't know this was a test xD
[03:10:44] <mefistofeles> I think I know the answer, but I don't really know why you are asking a question and answering and having a conversation with yourself, it's hard to track the issue that way
[03:11:17] <Klinda> maybe someone can help understand more
[03:11:57] <mefistofeles> https://stackoverflow.com/help/how-to-ask this is a good resource on how to ask, I think it applies to IRC as well
[03:11:57] <SigmoidFroid> â‡’  How do I ask a good question? - Help Center - Stack Overflow
[03:12:11] <mefistofeles> specially that "pretend you're talking to a busy colleague" plays a role in this case
[03:12:18] <Klinda> I was discussing with HuntsMan cause we had an open question about the GLM
[03:12:30] <Klinda> now that I understand more I was saying my findings
[03:12:40] <mefistofeles> okay
[03:13:06] <Klinda> we can pass trough glm by the probabilistic interpretation
[03:16:53] <Klinda> also I mean that's a ml general channels, what should  I talk ?
[03:17:45] <Klinda> about days I spent to find a cve on imagemagick with afl?
[03:17:47] <Klinda> xD
[03:17:51] <mefistofeles> GLM is a fine topic for this channel, of course
[03:18:05] <mefistofeles> but oyu are missing the point
[03:18:08] <mefistofeles> *you
[03:18:21] <mefistofeles> and that's fine, you do you, I just wanted to comment and give my opinion
[03:18:40] <Klinda> if you want I don't ask any question, problem solved xD
[03:18:54] <mefistofeles> no need to behave that childish, i never said that xD
[03:19:29] <mefistofeles> if you can't understand what I'm trying to say, that's fine, ignore it... it's not a problem, for real
[03:19:49] <Klinda> I was putting effort on what I studied these days, maybe I can help some as me, maybe all knows all and they don't wanna help.. but what's the propouse of this channel?
[03:21:25] <mefistofeles> yeah, that's fine
[03:23:23] <Klinda> maybe you like more practice stuff
[03:23:35] <mefistofeles> I'm here because I want to have interesting conversations with people on the ML subject, learn and help with what I know. But when I'm faced with tons of messages from a single user, it just makes it harder for me. That's what I was trying to say. Again, you do what you think is best for you.
[03:24:40] <Klinda> if you don't want interactive chat and like question & answer, there is stackoverflow for example
[03:25:34] <mefistofeles> I've been here for many years, I know how this works, don't worry about it :)
[03:26:29] <Klinda> I remeber the days when I was an operator of emule in them irc channels
[03:26:38] <Klinda> I was helping all to have high id
[03:27:04] <Klinda> step by step
[03:28:21] <Klinda> every 5 seconds you had someone who ask questions, you had to be a machine to write in fact you had macro for sure
[03:30:53] <Klinda> hower nevermind I wll not write much next times so you are happy xD
[03:31:51] *** Joins: georgios (~georgios@user/georgios)
[03:39:13] *** Quits: hygl (uid16621@id-16621.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[03:40:03] *** Quits: georgios (~georgios@user/georgios) (Quit: Konversation terminated!)
[03:42:43] <dostoyevsky2> mefistofeles: I guess its an art form in itself to talk about ML problems in proper terms.  I sometimes envy channels like #python or #linux where it seems so easy to help people and understanding their problems as it often seems impossible in ML, as it would take ages to properly understand what people want to do
[03:50:17] <mefistofeles> dostoyevsky2: I agree
[04:02:44] *** Quits: medium_cool (~medium_co@2605:a601:a9aa:f800:f59a:5511:89e5:f851) (Quit: I have gone to sleep. ZZZzzzâ€¦)
[04:04:57] *** Quits: sinaowolabi (~SinaOwola@160.152.131.234) (Ping timeout: 240 seconds)
[04:05:59] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[04:12:27] <Jong> mefistofeles  do you use pytorch or tensorflow?
[04:19:20] <mefistofeles> Jong: I have used it, but not much, if you have a question with those you can just ask and if someone knows the answer they would probably help
[04:34:54] *** Quits: Malvolio (~Malvolio@user/malvolio) (Read error: Connection timed out)
[04:46:57] *** Quits: black_13_ (~jjosb@2600:1700:1100:61c0:6165:890f:ce9d:d00a) (Ping timeout: 240 seconds)
[04:51:09] *** Joins: medium_cool (~medium_co@2605:a601:a9aa:f800:7845:3197:f41c:fdaa)
[05:02:15] *** Quits: medium_cool (~medium_co@2605:a601:a9aa:f800:7845:3197:f41c:fdaa) (Quit: I have gone to sleep. ZZZzzzâ€¦)
[05:07:29] *** Quits: spinningCat (~spinningC@about/web/muscles) (Read error: Connection reset by peer)
[05:16:13] *** Joins: Malvolio (~Malvolio@user/malvolio)
[05:57:35] *** Joins: sinaowolabi_ (~SinaOwola@102.134.114.1)
[06:14:34] *** Quits: Sheilong (uid293653@id-293653.ilkley.irccloud.com) ()
[06:17:15] *** Joins: sinaowolabi (~SinaOwola@160.152.131.234)
[06:17:39] *** Joins: spinningCat (~spinningC@176.54.82.228)
[06:18:44] *** Quits: spinningCat (~spinningC@176.54.82.228) (Changing host)
[06:18:44] *** Joins: spinningCat (~spinningC@about/web/muscles)
[07:04:13] *** Joins: medium_cool (~medium_co@2605:a601:a9aa:f800:284d:37ed:d557:ead3)
[07:34:46] <ns12> Is knowledge of symbolic AI necessary for machine learning, or can one learn machine learning without knowing symbolic AI at all?
[07:38:35] <mefistofeles> I don't even know what symbolic AI is, tbh
[07:39:14] <ns12> GOFAI https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence
[07:39:15] <SigmoidFroid> â‡’  Symbolic artificial intelligence - Wikipedia
[07:39:37] <mefistofeles> does sound like an old and kinda deprecated thing
[07:39:45] <mefistofeles> I'd imagine it's not required
[07:39:46] <ns12> It was the main paradigm of AI for most of its history.
[07:40:36] <mefistofeles> but I gues that if you want to learn the foundations and have a solid understanding of those, it can't hurt
[07:41:32] <ns12> So from what I gather, symbolic AI is not very relevant in practical machine learning, but is probably useful for other AI tasks (and for a history lesson in machine learning too).
[07:51:46] *** Quits: medium_cool (~medium_co@2605:a601:a9aa:f800:284d:37ed:d557:ead3) (Quit: I have gone to sleep. ZZZzzzâ€¦)
[08:49:02] *** Joins: hygl (uid16621@id-16621.tinside.irccloud.com)
[09:16:19] *** Quits: SiegeLord (~sl@user/siegelord) (Quit: WeeChat 2.8)
[09:21:28] *** Joins: SiegeLord (~SiegeLord@user/siegelord)
[09:25:48] *** Quits: sinaowolabi_ (~SinaOwola@102.134.114.1) (Quit: Leaving)
[09:26:07] *** Joins: jinsun__ (~quassel@user/jinsun)
[09:27:13] *** Quits: jinsun (~quassel@user/jinsun) (Ping timeout: 256 seconds)
[10:01:58] *** Joins: sinaowolabi__ (~SinaOwola@102.134.114.1)
[10:18:31] *** Quits: `Tim (~zenguin@user/zenguin) (Quit: Leaving)
[10:24:26] *** Joins: jinsun (~quassel@user/jinsun)
[10:27:57] *** Quits: jinsun__ (~quassel@user/jinsun) (Ping timeout: 240 seconds)
[11:15:01] *** Joins: jlrnick (~josephler@2a01cb040a15940038db3e71ef3adc74.ipv6.abo.wanadoo.fr)
[11:20:28] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[11:28:20] *** Joins: manti7 (~manti7@176.10.104.94)
[11:29:13] *** Joins: palasso (~palasso@user/palasso)
[12:24:30] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi)
[12:43:29] *** Quits: SiegeLord (~SiegeLord@user/siegelord) (Read error: Connection reset by peer)
[12:43:41] *** Joins: Klinda (~superleag@user/klinda)
[13:10:20] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[13:51:37] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Ping timeout: 240 seconds)
[13:52:52] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[14:01:37] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Ping timeout: 256 seconds)
[14:03:41] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[14:12:23] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Ping timeout: 256 seconds)
[14:19:38] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[14:33:55] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Ping timeout: 256 seconds)
[14:34:40] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[14:42:59] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Quit: Leaving)
[14:43:21] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[14:53:35] <hodapp_> ns12: it's almost irrelevant in practical machine learning because symbolic AI aims at a completely different method and problem
[14:55:25] <hodapp_> particularly, symbolic AI is deductive - it is done with rules of deduction from symbolic representations
[14:56:22] <hodapp_> machine learning is *inductive* - it is based around refining some model from a dataset in hopes that this model can generalize properly past this dataset
[15:01:39] <lericson> and of course the key to truly unlocking ai potential is combining them
[15:02:07] <lericson> i think that's essentially what we're seeing in robotics a lot, combining a good think with some inductive priors
[15:05:01] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Ping timeout: 240 seconds)
[15:09:12] <hodapp_> I don't think there's much consensus or evidence that that's the key
[15:22:24] <lericson> it's what humans do
[15:22:59] <lericson> and ultimately to interact with humans, you have to model human reasoning
[15:23:16] <lericson> otherwise you're doomed to these very limited bandwidth applications we see today
[15:23:24] <lericson> s/doom/limit/
[15:41:29] *** Parts: Klinda (~superleag@user/klinda) (Konversation terminated!)
[16:14:19] *** Quits: jlrnick (~josephler@2a01cb040a15940038db3e71ef3adc74.ipv6.abo.wanadoo.fr) (Remote host closed the connection)
[16:33:41] *** Quits: jim (~jim@about/linux/staff/jim) (Read error: Connection reset by peer)
[16:38:33] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi) (Read error: Connection reset by peer)
[16:42:37] *** Quits: sinaowolabi (~SinaOwola@160.152.131.234) (Ping timeout: 240 seconds)
[16:46:59] *** Joins: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi)
[16:49:22] *** Joins: jim (~jim@about/linux/staff/jim)
[16:55:26] *** Joins: sinaowolabi (~SinaOwola@102.134.114.1)
[17:18:27] *** Joins: marcello42 (~mp@2001:1a81:12a9:b900:4ccd:c26d:723b:afc2)
[17:20:37] *** Quits: mambang[m] (~mambang@user/mambang) (Ping timeout: 240 seconds)
[17:22:39] *** Joins: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de)
[17:24:17] *** Quits: sinaowolabi (~SinaOwola@102.134.114.1) (Ping timeout: 240 seconds)
[17:29:01] *** Quits: trace987 (~trace@ip5b4296d8.dynamic.kabel-deutschland.de) (Ping timeout: 240 seconds)
[17:35:49] *** Quits: marcello42 (~mp@2001:1a81:12a9:b900:4ccd:c26d:723b:afc2) (Ping timeout: 240 seconds)
[17:38:23] *** Joins: mambang[m] (~mambang@user/mambang)
[17:41:04] <hodapp_> a famous essay along these lines: https://people.csail.mit.edu/brooks/papers/elephants.pdf
[17:41:05] <SigmoidFroid> â‡’  Elephants Don't Play Chess Rodney A. Brooks MIT Artificial Intelligence Laboratory, Cambridge, MA 02139, USA Robotics and Autonomous Systems 6 (1990) 3-15 Keywords: Situated activity; Mobile robots; Planning; Subsumption architecture; Artificial Intelligence. Rodney A. Brooks was born in Adelaide, Australia. He studied (138K)
[17:41:13] *** Joins: sinaowolabi (~SinaOwola@160.152.87.243)
[17:46:58] *** Quits: spinningCat (~spinningC@about/web/muscles) (Remote host closed the connection)
[18:15:55] *** Quits: sinaowolabi (~SinaOwola@160.152.87.243) (Ping timeout: 256 seconds)
[18:19:39] *** Joins: `Tim (~zenguin@user/zenguin)
[18:20:08] *** Joins: trace987 (~trace@dynamic-002-247-248-146.2.247.pool.telefonica.de)
[18:20:09] *** Quits: trace987 (~trace@dynamic-002-247-248-146.2.247.pool.telefonica.de) (Remote host closed the connection)
[18:29:38] *** Joins: sinaowolabi (~SinaOwola@169.159.126.87)
[18:46:09] *** Joins: spinningCat (~spinningC@94.54.210.37)
[18:46:09] *** Quits: spinningCat (~spinningC@94.54.210.37) (Changing host)
[18:46:09] *** Joins: spinningCat (~spinningC@about/web/muscles)
[19:19:45] *** Joins: georgios (~georgios@user/georgios)
[19:37:45] *** Joins: jlrnick (~josephler@2a01cb040a1594008c5f8b78473174f2.ipv6.abo.wanadoo.fr)
[20:07:40] *** Joins: medium_cool (~medium_co@2605:a601:a9aa:f800:4d3f:8f37:6755:e967)
[20:31:21] *** Quits: Malvolio (~Malvolio@user/malvolio) (Quit: two years to flatten the curve AND to build surge capacity. who do we blame for this failure of leadership?)
[20:31:51] *** Quits: DnzAtWrk (~DnzAtWrk@mobile-access-6df043-241.dhcp.inet.fi) (Read error: Connection reset by peer)
[20:42:49] *** Quits: Jong (~Jong@2620:10d:c090:400::5:f0a6) (Read error: Connection reset by peer)
[20:53:46] *** Joins: Malvolio (~Malvolio@user/malvolio)
[21:10:07] *** Quits: medium_cool (~medium_co@2605:a601:a9aa:f800:4d3f:8f37:6755:e967) (Quit: I have gone to sleep. ZZZzzzâ€¦)
[21:11:15] *** Joins: SiegeLord (~sl@user/siegelord)
[21:57:53] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[21:57:55] <lericson> not my cup of tea i gotta say
[21:59:29] <lericson> really starting to lose me around 3.1
[22:00:21] <mefistofeles> lericson: what exactly
[22:00:22] <mefistofeles> ?
[22:02:50] <lericson> using evolution as an argument for how to construct intelligent robotic systems is just... man
[22:03:41] <mefistofeles> I see
[22:04:17] <lericson> there are a lot of leaps of logic and non-sequent deductions prior to that too, i just don't find it convincing
[22:04:29] <lericson> going to read about the subsumption stuff now
[22:04:39] <mefistofeles> depends on what you actually mean by evolution, because clearly what we call features of intelligence in biological systems are a product of evolution
[22:04:59] <lericson> my tailbone is a product of evolution, it doesn't make it special
[22:05:00] <mefistofeles> but doing that with an algorithm is a totally different thing :)
[22:05:41] <mefistofeles> lericson: I'd argue tailbones are really special, we couldn't naturally survive without those
[22:05:44] <mefistofeles> :P
[22:05:51] <mefistofeles> but yeah, that's the issue, it really depends on what you need/mean
[22:06:02] <lericson> ha, you could survive without your lower body half
[22:06:05] <lericson> and many do
[22:06:08] <lericson> i wouldn't recommend it
[22:06:10] <mefistofeles> not naturally
[22:06:20] <mefistofeles> you need a lot of help :)
[22:06:34] <mefistofeles> and that's why I insist on the "what you mean by evolution" part
[22:06:39] <lericson> you mean if you throw a quadripelegic into the woods they die?
[22:06:42] <mefistofeles> evolution is a HUGE thing
[22:06:42] <lericson> i think this is true of most people
[22:07:29] <mefistofeles> lericson: no, I mean that quadriplegic needed a lot of help (artificial help) to heal and become somewhat functional again
[22:07:41] <mefistofeles> nature would just discard them if it weren't for modern medicine or things like that
[22:07:42] <lericson> have you met newborns
[22:08:34] <lericson> i question here the idea that something can be unnatural in the natural world
[22:08:49] <lericson> if q.p's survive in the modern world, then they do so naturally by definition
[22:08:59] <mefistofeles> you are taking it too literal, that's not what's meant when you use natural vs artificial selection in biology and evolution
[22:09:03] <mefistofeles> read up on those
[22:10:28] <mefistofeles> when we cure a commonly deadly condition it's a type of artificial selection in broad biological terms
[22:11:24] <mefistofeles> and this happens in nature, all the time... it's not unnatural, but it's not natural selection
[22:12:09] <mefistofeles> people tend to think artificial is opposed to natural, and that they are mutually exclusive, but that's not the case
[22:14:18] <lericson> uhu
[22:14:34] <lericson> maybe i'm missing background research here but the subsumption stuff really comes out of the blue
[22:20:18] <lericson> anyway to bring it all back to the start, humans clearly reason semi-symbolically (humans do play chess) so the "holy grail" as brooks puts it, must also
[22:20:55] <mefistofeles> ah I see, yes, I agree
[22:21:12] <mefistofeles> which is a fallacy, right?
[22:33:48] *** Joins: gareppa (~gareppa@user/gareppa)
[22:36:14] *** Quits: gareppa (~gareppa@user/gareppa) (Remote host closed the connection)
[22:37:38] *** Quits: hygl (uid16621@id-16621.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[22:46:43] <hodapp_> "it's what humans do" is more or less just "this is what evolution produced"
[22:47:58] <hodapp_> symbolic reasoning has a lot more to do with how humans chose to formalize reasoning than with how they *do* reasoning
[22:49:23] *** Joins: kristjansson (sid126207@id-126207.tinside.irccloud.com)
[22:49:55] <lericson> let's put it this way, do you believe the kahneman style type 1 and 2 system hypothesis?
[22:59:29] <hodapp_> I am familiar with type 1 and type 2 but was unaware of him ever proposing a hypothesis that they are fundamental, necessary, or sufficient to how human cognition arises
[22:59:54] <lericson> he never did, and i never did
[23:00:03] *** Joins: marcello42 (~mp@2001:1a81:12a9:b900:4ccd:c26d:723b:afc2)
[23:00:09] <lericson> forget about it
[23:02:27] *** Joins: Sheilong (uid293653@id-293653.ilkley.irccloud.com)
[23:03:57] <hodapp_> the view that I consider credible is that what we call "human level intelligence", or even some "general" notion of intelligence, is a mixture of a larger number of more specific intelligences, maybe 15-20 different ones, that we've likely yet to even describe in meaningful form
[23:06:12] <hodapp_> and that it will end up being a bit less naive than just "take symbolic deduction, and take machine learning, but crank it up to 11"
[23:07:38] <hodapp_> but to paraphrase Mitchell, the whole industry has this tendency to look at every time a person climbs a tree, and go "this is the first step towards reaching the moon"
[23:08:03] *** Quits: georgios (~georgios@user/georgios) (Quit: Konversation terminated!)
[23:09:21] *** Joins: georgios (~georgios@user/georgios)
[23:35:16] *** Quits: Scarecr0w (scarecr0w@user/scarecr0w) (Ping timeout: 268 seconds)
[23:36:06] *** Joins: Scarecr0w (scarecr0w@user/scarecr0w)
[23:43:26] *** Quits: georgios (~georgios@user/georgios) (Remote host closed the connection)
