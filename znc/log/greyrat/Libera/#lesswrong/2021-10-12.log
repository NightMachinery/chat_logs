[00:00:22] <feepbot> <gwern> https://www.ofcom.org.uk/__data/assets/pdf_file/0020/225335/offensive-language-quick-reference-guide.pdf#page=5 'Bloodclaat'? 'Bumberclat'?
[00:05:18] <Betawolf> they considered 'Ginger' in the same category as 'Bitch'?
[00:06:32] <Betawolf> https://www.urbandictionary.com/define.php?term=bumberclat
[00:06:32] <Robomot> Urban Dictionary: bumberclat (asshole)
[00:08:00] <Betawolf> bloodclaat is Jamaican for menstrual rag
[00:13:01] <feepbot> <gwern> 'Words which were familiar to fewer than 40% of quantitative respondents are highlighted with an asterisk (*) and these findings should be treated with additional caution.' no kidding
[00:49:28] <pompolic> " There are lots of incentives for people (Russians, game developers) to try to manipulate the feed."
[00:49:39] <pompolic> I don't know why, but "(Russians, game developers)" cracked me up
[00:50:29] <Obormot\Arcturus> gwern: I was confused at first until I realized that by "scroll bar" you meant "scroll progress bar"
[00:50:48] <Obormot\Arcturus> gwern: But no, that's not built in at all. That's definitely a non-zero amount of JS
[00:51:39] <gwern> ah. I guess they intended it to look 'native' then because I didn't even realize it wasn't just default chrome chrome until I thought to myself, 'wait, since when do mobile browsers have sticky headers'
[00:52:03] <Obormot\Arcturus> I guess so. Anyway, it's doable, yeah, but I'd have to custom-code it
[00:52:08] <Obormot\Arcturus> I'll add it to the list
[00:52:18] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[00:53:26] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 245 seconds)
[00:53:37] *** Lord_of_Life_ is now known as Lord_of_Life
[00:53:44] <Obormot\Arcturus> https://i.imgur.com/TjGp5XP.jpeg ... lol
[00:55:55] <Obormot\Arcturus> ">     Maimonides, describing Jewish law, goes into some detail on how often a man is obliged to have intercourse with his wife, depending mostly on how tiring his normal work is.
[00:55:55] <Obormot\Arcturus> I guess we found out how Jews got selected for intelligence. Joking, sort of."
[00:56:59] <Obormot\Arcturus> https://www.greaterwrong.com/posts/jr3sxQb6HDS87ve3m/book-review-free-will ... interesting!
[00:57:00] <Robomot> Book Review: Free Will - LessWrong 2.0 viewer (Sam Harris' Free Will isn't a conventional philosophy book. Rather, it's a laconic manifesto full of bold and provocative statements invoking us to free ourselves from the delusion of free will and abolish the whole concept as misleading and unnecessary. …)
[00:57:09] <Obormot\Arcturus> "Predictably, the publication of the book led to a philosophical debate on the matter of free will between Sam Harris and Daniel Dennet which turned out to be larger than the book itself. I’ll touch it a little in this review as well." ... ooh
[00:58:17] <Obormot\Arcturus> Oh this is old
[00:58:20] <Obormot\Arcturus> How did I miss it though
[01:03:21] <feepbot> <gwern> https://twitter.com/ak92501/status/1447673178294300673
[01:03:22] <|dbotdan> AK (@ak92501, 2021-10-11 21:19): ‘stylegan3 is out | github: https://github.com/NVlabs/stylegan3 ’ Watch video: https://twitr.gq/ak92501/status/1447673178294300673
[01:06:58] <gwern> https://ngc.nvidia.com/catalog/models/nvidia:research:stylegan3 checkpoints available looks like: FFHQ, metfaces, animal faces. 
[01:07:00] <Robomot> NVIDIA NGC
[01:10:10] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 252 seconds)
[01:12:01] <feepbot> <gwern> https://twitter.com/emollick/status/1447424130119344133
[01:12:02] <|dbotdan> Ethan Mollick (@emollick, 2021-10-11 04:49): ‘Silicon Valley, New York City, and Boston soaked up 66% of all VC funding in the US in Q3, 2021.  | The percentage of all VC funding raised in those same three locations  in 2017 (before COVID disruption and Zoom dealmaking, etc.) was... 66%. | Building startup ecosystems is hard!’
[01:12:58] <rmmh> oh alias-free GANs *is* stylegan3 eh
[01:13:13] <rmmh> Requirements: 1–8 high-end NVIDIA GPUs with at least 12 GB of memory. We have done all testing and development using Tesla V100 and A100 GPUs.
[01:13:27] <rmmh> god, this is worse than following instructions you find on a Kraft product
[01:13:49] <gwern> rmmh: yeah, I was using stylegan3 for stylegan2-ada, but I guess they decided -ada wasn't interesting enough and only alias-free is worthy of being numero trois
[01:14:20] <rmmh> limited data isn't as sexy as alias-free
[01:14:34] *** Quits: _inky (~inky_@46.241.144.156) (Ping timeout: 252 seconds)
[01:14:54] * gwern squints at a twitter follow request. '@FragonardRapist' ... that's allowed?
[01:15:23] *** Joins: [_] (~itchyjunk@user/itchyjunk/x-7353470)
[01:18:10] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Ping timeout: 260 seconds)
[01:19:54] <feepbot> <gwern> https://twitter.com/ByrneHobart/status/1447578446125744128
[01:19:55] <|dbotdan> Byrne Hobart (@ByrneHobart, 2021-10-11 15:02): ‘Today we honor Christopher Columbus's discovery that you can raise funding based on some wildly wrong assumptions about your target market and then pivot to something totally different but actually viable a few months later.’
[01:24:29] <kuudes> hmm. would it be useful to train a net with different corpuses on different clusters and then later combine it?
[01:25:33] <kuudes> can one do such? ie to just take average of two nets and expect it to retain large part of both nets' learnings?
[01:26:38] *** [_] is now known as [itchyjunk]
[01:27:58] <kuudes> I mean, I guess if you start both from different random weight-position then they might put different parts of information to different parts of weights, but maybe you could try to limit that by pretraining a net with smaller corpus at start and then forking it to both corpuses and then joining the result of those later?
[01:28:08] <gwern> just literally average the parameters? no, only in special cases like SWA or stylegan
[01:28:33] <kuudes> hmm. why not?
[01:30:14] *** Joins: galambo (galambo@user/galambo)
[01:30:17] <gwern> there are lots of symmetries and permutation and equivalences which mean that even the same model/data/training may be nonsense when averaged
[01:30:45] *** Joins: galambo__ (galambo@user/galambo)
[01:30:57] <kuudes> yes. but if you trained it enough before forking so that much of the structure would have formed?
[01:31:01] *** Joins: _inky (~inky_@141.136.76.213)
[01:31:29] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 265 seconds)
[01:31:51] <kuudes> ie you would train it in hopes brain organs like hypothalamus or amygdala or whatever are formed, and then train on matter knowledge and then average the hypothalamuses together etc
[01:33:18] <[itchyjunk]> huh, interesting. how do you assert two models are equivalent generally?
[01:33:26] <[itchyjunk]> I had never thought of this
[01:34:41] *** Quits: galambo (galambo@user/galambo) (Ping timeout: 245 seconds)
[01:35:39] <Obormot\Arcturus> "Once Diogenes was going into the theater just as everybody was coming out. When asked why he did this, he answered, “Opposition has been my manner. It is what I have been doing all my life.”" ... truly, was there ever a greater philosopher?
[01:36:15] <kuudes> I don't know. gwern likely is right
[01:38:50] <gwern> kuudes: if you train it enough, you can do some tricks in terms of merging back, like SWA or stylegan model averaging
[01:39:24] <[itchyjunk]> Man, i can't believe you guys are merging models and such, i still haven't figured out my hello world ANN
[01:43:45] <TheWhisper> Wow, I finally figured out why my MBP kept "crashing" after sleep with no crash logs being generated. I had the hidden setting (buried in Security & Privacy > General > Advanced) `Log out after X minutes of inactivity` checked. I had thought I was going crazy...
[01:47:47] *** Quits: nanotube (~nanotube@user/nanotube) (Quit: *poof*)
[01:48:45] <feepbot> <gwern> https://twitter.com/robinhanson/status/1447674949460705285 I regret to report robin has discovered kink
[01:48:45] <|dbotdan> Robin Hanson (@robinhanson, 2021-10-11 21:26): ‘"~30% of participants in BDSM activities are females. … 89% of heterosexual females who are active in BDSM [prefer] the submissive-recipient role … [&] a dominant male, … 71% of heterosexual males preferred a dominant-initiator role" https://en.wikipedia.org/wiki/Dominance_and_submission ’
[01:51:17] *** Joins: nanotube (~nanotube@user/nanotube)
[01:53:12] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[01:57:31] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[02:00:31] *** SomeBrashAtom_ is now known as SomeBrashAtom
[02:06:20] <galambo__> http://www.tallcomics.com/comic/unwinder-reads-celeb-magazine/
[02:06:21] <Robomot> Unwinder Reads Celeb Magazine – Unwinder's Tall Comics
[02:09:15] * gwern discovers that the wikipedia popups don't play well with wp namespace like 'File:'
[02:13:42] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[02:19:03] <Obormot\Arcturus> oh no
[02:24:00] <gwern> RiversHaveWings: interesting how wild the camera movement is on https://twitter.com/RiversHaveWings/status/1447692046160986113 https://twitter.com/RiversHaveWings/status/1447695344192524290
[02:24:01] <|dbotdan> Rivers Have Wings (@RiversHaveWings, 2021-10-11 22:34): ‘First try guiding #StyleGAN3 with CLIP...’ Watch video: https://birdsite.xanny.family/RiversHaveWings/status/1447692046160986113
[02:24:01] <|dbotdan> Rivers Have Wings (@RiversHaveWings, 2021-10-11 22:47): ‘flower...’ Watch video: https://nitter.fdn.fr/RiversHaveWings/status/1447695344192524290
[02:29:52] <gwern> RiversHaveWings: I guess because no-alias gan can so easily move the camera, any ol' gradient update does?
[02:30:00] <RiversHaveWings> gwern: yep
[02:30:18] <gwern> an unexpected obstacle
[02:30:25] <RiversHaveWings> The videos I am making are from exponential moving averaged StyleGAN3 latents.
[02:30:32] <RiversHaveWings> The underlying iterates are even worse
[02:34:17] <gwern> I hope you won't have to decode the positioning part of the latent to clamp it
[02:35:14] <RiversHaveWings> gwern: It just derives the translation and rotation parameters for the input coordinate grid from the latent
[02:35:32] <RiversHaveWings> I can just *fix the parameters* by taking the model apart and manually setting them
[02:36:35] <gwern> oh, interesting. I didn't realize it was explicitly parameterized like that. but I didn't understand the no alias paper, so no surprise there
[02:36:56] <gwern> Obormot\Arcturus: I guess the header thing is called 'scroll spy'? https://ux.stackexchange.com/questions/60533/which-ui-design-pattern-is-this-progress-bar-at-the-top-of-an-article
[02:36:56] <Robomot> terminology - Which UI design pattern is this? (progress bar at the top of an article) - User Experience Stack Exchange (On this page there is a progress bar at the top which progresses as you scroll down. …)
[02:37:01] <RiversHaveWings> Yeah it makes the input coordinate grid with Fourier Features and feeds it in at the start of the stack of conv2d layers.
[02:38:53] <mst> "There are now 69 billion Tethers in circulation, 48 billion of them issued this year."
[02:38:58] <mst> that's going to be fun.
[02:39:11] <RiversHaveWings> https://twitter.com/RiversHaveWings/status/1447697339385143299
[02:39:12] <|dbotdan> Rivers Have Wings (@RiversHaveWings, 2021-10-11 22:55): ‘This is just wild. #StyleGAN3’ Watch video: https://nitter.eu/RiversHaveWings/status/1447697339385143299
[02:39:15] <RiversHaveWings> This one's fun
[02:39:46] <gwern> zomg furry
[02:40:40] <nshepperd> oh, it provides position embeddings but randomly rotates and translates them?
[02:40:45] <nshepperd> like during training?
[02:45:46] <feepbot> <gwern> https://jerrygood0703.github.io/KaraSinger/assets/audios/long/lyrics1/temp0.wav https://jerrygood0703.github.io/KaraSinger/assets/audios/long/lyrics1/temp1.wav https://jerrygood0703.github.io/KaraSinger/assets/audios/long/lyrics1/temp2.wav https://jerrygood0703.github.io/KaraSinger/assets/audios/long/lyrics1/temp3.wav
[02:45:46] <feepbot> https://jerrygood0703.github.io/KaraSinger/assets/audios/long/lyrics1/temp4.wav  https://jerrygood0703.github.io/KaraSinger/ https://twitter.com/chrisdonahuey/status/1447682153286885379 my sides
[02:45:47] <|dbotdan> Chris Donahue (@chrisdonahuey, 2021-10-11 21:54): ‘The bar for singing voice synthesis research demos has been raised to "sing your paper's abstract"’ Watch video: https://nitter.skrep.in/chrisdonahuey/status/1447682153286885379
[02:47:36] <Obormot\Arcturus> "The commitment to phase out nuclear energy production in Germany was made by law in 2002. Among the reasons for this were lack of public acceptance of nuclear energy in Germany, and the view that the residual risk associated with its use in electricity production is no longer tolerable. This phase-out is based on an agreement between the federal government and the electricity utilities, initialled on 14 June 2000 and signed
[02:47:36] <Obormot\Arcturus>  on 11 June 2001. The agreement to phase out the use of nuclear power for electricity production therefore limits the standard lifetime of nuclear power plants to about 32 years from the date of commissioning."
[02:48:01] <Obormot\Arcturus> (And then there's a chart of where Germany's electric power actually comes from and it's over 50% coal)
[02:48:29] <Obormot\Arcturus> (Then it's 30% nuclear, which they're phasing out, and replacing with... well, who knows, probably something awesome like solar or hydro, right?? Surely not... more coal)
[02:49:34] <gwern> I mean, that's what they always do. like post-fukushima, germany shut down nukes because obviously all their plants were dangerous and flawed in the same way and it was time to go green!
[02:49:57] <Obormot\Arcturus> Actually no I take it back, it looks like they have replaced with non-fossil: https://en.wikipedia.org/wiki/Electricity_sector_in_Germany
[02:49:57] <Robomot> Electricity sector in Germany - Wikipedia (Germany's electrical grid is part of the Synchronous grid of Continental Europe. In 2020, Germany produced 484 TWh of electricity of which 50% was from renewable energy sources, 24% from coal, and 12% from natural gas.[ …)
[02:50:32] <gwern> (given how terribly dangerous nuclear has been proven to be by fukushima and chernobyl, it's a mystery how france gets along. maybe they're just covering it up - how many french people not from paris have you ever met?)
[02:50:41] <Obormot\Arcturus> Now, what might be the consequences of this?
[02:50:44] <Obormot\Arcturus> "German households and small businesses pay the highest electricity price in Europe for many years in a row now. More than half of the power price consists of components determined by the state (53%). These Taxes, levies and surcharges have tripled since 2000 [from 5.19 to 16.49 Euro Cents]. These include levies for financing investment in renewable energy (22.1%) and for other kinds of taxes (e.g. GST 19%). Grid charges
[02:50:44] <Obormot\Arcturus>  account for almost 25%, and only the remaining 22% are used to actually generate the electricity. "
[02:50:48] <Obormot\Arcturus> Gosh.
[02:51:32] <Obormot\Arcturus> Here's France: https://en.wikipedia.org/wiki/Electricity_sector_in_France
[02:51:32] <Robomot> Electricity sector in France - Wikipedia (The electricity sector in France is dominated by nuclear power, which accounted for 71.7% of total production in 2018, while renewables and fossil fuels accounted for 21.3% and 7.1%, respectively[1] (compare to 72.3% nuclear, 17.8% renewables and 8.6% fossil fuels in 2016).[2] France has the largest share of nuclear electricity in the world. …)
[02:52:14] <gwern> 'green did not mean glowing!' 'but why not'
[02:52:40] <Obormot\Arcturus> https://energycentral.com/c/ec/germany-solar-and-wind-triple-cost-france%E2%80%99s-nuclear-and-will-last-half-long ... oh no
[02:52:40] <Robomot> Germany Solar and Wind is Triple the Cost of France’s Nuclear and Will Last Half as Long | Energy Central (France's nuclear energy spending was 60% of what Germany spent on renewables. France gets about 400 Terawatt hour per year from nuclear but Germany gets 226 Terawatt-hours each year. 45 Terawatt-hours of Germany's renewable power come from burning biomass)
[02:53:15] <saturn2> france even reprocesses their fuel so they don't need those absurd warnings not to dig for 100,000 years
[02:53:53] <Obormot\Arcturus> https://www.globalpetrolprices.com/Germany/electricity_prices/ ... this is a fun chart
[02:53:54] <Robomot> Germany electricity prices, March 2021 | GlobalPetrolPrices.com (Germany, March 2021: The price of electricity is  U.S. Dollar per kWh for households and  U.S. Dollar for businesses which includes all components of the electricity bill such as the cost of power, distribution and taxes.  For comparison, the average price of electricity in the world for that period is 0.136 U.S. …)
[02:54:24] <Obormot\Arcturus> (Germany is aaaaalll the way at the bottom)
[02:59:25] <feepbot> <gwern> 'This project is a set of programs that I use to create a README.md file. How does it work? It reads program files and concatenates the beginning of all files to create a input prompt which is then fed to OpenAI Codex to generate a README.' https://github.com/tom-doerr/codex-readme
[02:59:26] <feepbot> GitHub - tom-doerr/codex-readme (Contribute to tom-doerr/codex-readme development by creating an account on GitHub.)
[03:01:33] <Obormot\Arcturus> https://samharris.org/reflections-on-free-will/ ... popups for footnotes, but you have to click on them -_-
[03:01:34] <Robomot> Reflections on FREE WILL | Sam Harris (Daniel Dennett and I agree about many things, but we do not agree about free will. Dan has been threatening to set me straight on this topic for several years now, and I have always encouraged him to do so, preferably in public and in writing. He has finally produced a review of my book … Continued)
[03:01:43] <Obormot\Arcturus> (Also, rubrication)
[03:04:44] <gwern> free will, gee, that's a bit of a trip
[03:05:20] <gwern> (I wonder if I am imagining it, but it seems like as AI gets better, you hear ever less about how materialism and determinism are *obviously* false and we *must* have immaterial minds/souls/spiritstuff and 'free will')
[03:06:23] <Obormot\Arcturus> I dunno. This debate I linked is from 2014. I think it's been declining for a while
[03:06:37] <saturn2> you hear ever less about religious worldviews in general
[03:07:30] <gwern> yeah, it's hard to tell, but people always claimed that they didn't believe in dualism and free will just because of religion, so its simultaneous decline is still telling
[03:08:05] <Obormot\Arcturus> That was probably always a lie, in most cases
[03:08:28] <Obormot\Arcturus> Because saying "yeah I believe this because of religion" has been low status in elite circles for some time now
[03:09:13] <gwern> right now it looks like without religion pushing it, and with the continual progress in AI and neuroscience, free will / dualism will never be refuted, they'll just... fade away in a "sire, I have no need of that hypothesis" way
[03:09:15] <saturn2> people don't automatically know what they believe because of religion
[03:12:03] <gwern> (materialism/determinism will just increasingly be the common sense default of people raised irreligiously in a world increasingly filled with thinking machines, not even thought about except when you run into your old friend who read a bunch of c.s. lewis and wants to explain your errors)
[03:12:25] <saturn2> you can reject the idea of a supreme being but the idea of free will that rode in on its coattails remains as cached background knowledge until someone comes along to talk you out of it
[03:14:04] <pie_> what if free will isnt binary
[03:14:40] <Obormot\Arcturus> gwern: Yes, I think I've made this point before - the more machines behave in a way that looks like thinking, the more Turing's "polite convention" will just be extended to non-human intelligences and the argument will disappear without ever being settled
[03:15:07] <Obormot\Arcturus> (i.e., you can't prove machines think but you also can't prove people think, but nobody bothers to argue about *that*)
[03:15:09] <nshepperd> ternary free will: free, determined, and file not found
[03:15:32] <Obormot\Arcturus> nshepperd: The optionals approach imo
[03:15:44] <Obormot\Arcturus> To avoid null references in free will discussions
[03:16:08] <gwern> in the event of a E_NO_FILE, the standard specifies that execution of the mind process is undefined and it may be free, compatibilist, or determined as universe-implementation-dependent
[03:16:28] <gwern> the mind may also be optimized away to a constant returned value
[03:16:59] <Obormot\Arcturus> The mind will just be set to 4
[03:17:01] * pie_ gets an aneurism
[03:17:03] <gwern> (GCC versions 4.2 and up appear to leave undefined minds as not bound but free variables)
[03:17:14] <Obormot\Arcturus> (With a comment assuring us that the number 4 was determined in a random manner)
[03:17:32] <pie_> Obormot\Arcturus: id pray the mind was not written in C, but it was probably hacked together in perl
[03:18:12] <nshepperd> i am not a number! i am free variable!
[03:18:28] <Obormot\Arcturus> The mind of the true rationalist must be written in Objective C
[03:18:36] <Obormot\Arcturus> The better to reject subjective biases
[03:19:06] <Obormot\Arcturus> (Of course, a mind written in Objective C is incapable of accepting subjective probability, which may or may not be a problem)
[03:19:08] <saturn2> Maybe free_will = Just compatibilism | Nothing
[03:19:52] <pie_> they do that? thats pretty cool <saturn2> france even reprocesses their fuel so they don't need those absurd warnings not to dig for 100,000 years
[03:20:35] <saturn2> yep (there is still waste but it has a much shorter half-life)
[03:22:25] <pie_> join me for my ted talk: nuclear waste depositories, a worse idea than covid
[03:22:43] <gwern> https://en.wikipedia.org/wiki/La_Hague_site
[03:22:43] <Robomot> La Hague site - Wikipedia (The La Hague site is a nuclear fuel reprocessing plant at La Hague on the Cotentin Peninsula in northern France, with the Manche storage centre bordering on it. Operated by Orano, formerly AREVA, and prior to that COGEMA (Compagnie générale des matières atomiques), La Hague has nearly half of the world's light water reactor spent nuclear fuel reprocessing capacity.[ …)
[03:24:01] <gwern> 'In October 1976,[8] concern of nuclear weapons proliferation (especially after India demonstrated nuclear weapons capabilities using reprocessing technology) led President Gerald Ford to issue a Presidential directive to indefinitely suspend the commercial reprocessing and recycling of plutonium in the U.S. On 7 April 1977, President Jimmy Carter banned the reprocessing of commercial reactor...
[03:24:07] <gwern> ...spent nuclear fuel. The key issue driving this policy was the risk of nuclear weapons proliferation by diversion of plutonium from the civilian fuel cycle, and to encourage other nations to follow the USA lead.[9][10][11] After that, only countries that already had large investments in reprocessing infrastructure continued to reprocess spent nuclear fuel. President Reagan lifted the ban in...
[03:24:13] <gwern> ...1981, but did not provide the substantial subsidy that would have been necessary to start up commercial reprocessing.[12]' https://en.wikipedia.org/wiki/Nuclear_reprocessing figured it'd be something proliferation-related
[03:24:14] <Robomot> Nuclear reprocessing - Wikipedia (Nuclear reprocessing is the chemical separation of fission products and unused uranium from spent nuclear fuel.[1] Originally, reprocessing was used solely to extract plutonium for producing nuclear weapons. With commercialization of nuclear power, the reprocessed plutonium was recycled back into MOX nuclear fuel for thermal reactors.[ …)
[03:26:58] <pie_> its always proliferatrion
[03:27:16] <pie_> but what i dont get is what does *US* reprocessing have to do with foreign proliferation?
[03:32:17] <feepbot> <gwern> 'I prompted GPT-3 to describe “the feelings and adventures” of a plastic bag, and edited the result to my liking. Rather than pretending that what GPT-3 wrote has literary or artistic value, I want to pause and marvel at this unexpected subjective reality.' https://medium.com/@thomasbuysens/i-feel-free-i-am-in-the-air-again-5f8a0e48a684 are we sure this wasn't just
[03:32:17] <feepbot> plagiarized from _american beauty_
[03:32:17] <feepbot> “I feel free. I am in the air again.” | by Thomas Buÿsens | Oct, 2021 | Medium (I brought a plastic bag to life with OpenAI)
[03:32:41] <saturn2> it's the kindergarten rule. you can't bring plutonium unless you bring enough for everyone
[03:33:59] <pie_> XD
[03:34:49] <pie_> the US peaked at manhattan project change my mind
[03:36:32] <pie_> Huh. https://nitter.snopyta.org/wellerstein/status/1437075145810714627
[03:36:43] <feepbot> Alex Wellerstein (@wellerstein): "The German atomic program in general was several orders of magnitude smaller than the Manhattan Project. The Manhattan Project spent more *per day* at its peak than the German program did over its entire time, and 100X more people involved in it. It wasn't a close [snip]
[03:38:32] <ivan> how do I know whether something was actually generated with GPT-3 or if it was loosely inspired by GPT-3 and tweaked for engagement farming
[03:39:11] <ivan> can it please publish signatures of all its creations to the blockchain?
[03:39:49] <pie_> "The Manhattan Project, of course, is not the "barometer" to compare all other nuclear programs to, but it gives a good indication of what is necessary to invent this kind of stuff from scratch under time pressure (3 years)."
[03:40:25] *** Joins: src_ (~src@user/src)
[03:41:10] <gwern> ivan: depending on how much certainty you want? other models are decent at detecting GPT-generated text, and you can do something like feed a text through GPT-3 and look at the estimated probability of each additional token; with top-k or top-p sampling, the next token must *always* be within a certain probability 100%-x% if it is completely unedited and unmodified
[03:41:38] <ivan> oh interesting 
[03:41:50] <gwern> for example, with top_p=0.95, you will never find any tokens which GPT assigns <5% probability. it just won't ever be picked during sampling
[03:42:33] <pie_> more "huh": https://nitter.net/wellerstein/status/1071466795268272129
[03:42:35] <Robomot> Alex Wellerstein (@wellerstein): "The AEC had very few direct employees but huge numbers of contractors — comparable to Manhattan Project peak. I only have numbers from 1947-1961, though." | nitter (The AEC had very few direct employees but huge numbers of contractors — comparable to Manhattan Project peak. I only have numbers from 1947-1961, though.)
[03:42:48] <shawwwn> nshepperd: trinary not ternary
[03:42:50] <gwern> or er, is in the bottom 5% by probability mass, not has <5% probability
[03:43:40] *** Quits: src (~src@user/src) (Ping timeout: 252 seconds)
[03:44:13] <gwern> (most people admit to some cherrypicking but I think that would preserve the top-k/p traces as long as they are only restarting at various points)
[03:45:46] *** Quits: src_ (~src@user/src) (Quit: Leaving)
[03:49:14] <feepbot> <gwern> https://mikehadlow.blogspot.com/2012/05/configuration-complexity-clock.html the wheel of reincarnation
[03:49:14] <feepbot> Code rant: The Configuration Complexity Clock
[03:50:33] *** Joins: src (~src@user/src)
[03:52:08] <ivan> yeah, I skipped the DSL and went straight for quickjs
[03:52:17] <ivan> everyone can write JavaScript, right
[03:54:02] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[03:54:37] <ivan> those things are useful for making a decision based on a few inputs, if you're starting to write tests for that should be part of some function in the real program
[03:55:03] <ivan> s/for that/for it, that/
[03:58:42] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 260 seconds)
[04:01:39] <Obormot\Arcturus> https://www.datasecretslox.com/index.php/topic,4726.msg313.html#new
[04:01:40] <Robomot> Reverse Software Engineering For Correction Now Legal In EU (Reverse Software Engineering For Correction Now Legal In EU)
[04:06:40] <feepbot> <gwern> 'For all experiments, we used pre-trained dense decoder-only Transformer language models, ranging in size from 2 million to around 100 billion parameters (with the largest denoted 100B+). These models were pre-trained on web documents and dialog data' https://openreview.net/pdf?id=iedYJm92o0a#page=3 'tell me your anonymous paper is by googlers using LaMDA without using
[04:06:40] <feepbot> either word'
[04:11:40] <feepbot> <gwern> https://hai.stanford.edu/news/peter-norvig-todays-most-pressing-questions-ai-are-human-centered huh
[04:11:40] <feepbot> Peter Norvig: Today’s Most Pressing Questions in AI Are Human-Centered (The AI expert, who joins Stanford HAI as a Distinguished Education Fellow, discusses building inclusive education and broadening access to students.)
[04:16:22] * gwern goes to add https://www.amazon.com/Tog-Interface-Bruce-Tognazzini/dp/0201608421 to his to-scan list since it's not in libgen and just stares in befuddlement at the reviews. ...why is half the page in italics?
[04:16:25] <Robomot> Tog on Interface: Tognazzini, Bruce: 9780201608427: Amazon.com: Books (Tog on Interface [Tognazzini, Bruce] on Amazon.com. *FREE* shipping on qualifying offers. Tog on Interface)
[04:17:26] <pie_> Obormot\Arcturus: aw. thats cool but the EULA clause is :c
[04:17:32] <pie_> IANAL
[04:22:33] <feepbot> <gwern> https://restofworld.org/2021/instagram-and-class-in-india/ ACTIVISTS: "I hate tiktok, it's so biased and classist, I wish it would go away!" ACTIVISTS [later]: "oh no"
[04:22:33] <feepbot> Instagram has largely replaced TikTok in India, and erased working&#x2d;class creators &#x2d; Rest of World ("TikTok was a canteen; Instagram is a café. But the canteen has better food, and the café serves costly coffee that not everyone drinks.”)
[04:24:13] <mst> gwern: I managed to make a post to HN early today that's half italics because I was talking about CSV/TSV/etc. and used *SV twice in my comment ;)
[04:29:14] <feepbot> <gwern> 'Oh my gosh, and there's a (pre-release) 1985 HIG that's quite different. It includes e.g. case studies (useful!), and an extended discussion of Jung's theories of intuition and how they should influence your designs (!!)' https://twitter.com/andy_matuschak/status/1447407670403612672 I guess you had to be there
[04:29:14] <|dbotdan> Andy Matuschak (@andy_matuschak, 2021-10-11 03:44): ‘Following up: several people mentioned the original 1987 Apple Human Interface Guidelines, which I'd not read. It's not a comprehensive primer on interface design, but it is an extraordinary read—a huge amount of detail on *why* things are as they are. And a great bibliography!’
[04:34:15] <feepbot> <gwern> https://twitter.com/lisatomic5/status/1447599024555511811 so much valuable human capital formation
[04:34:18] <|dbotdan> lisatomic (@lisatomic5, 2021-10-11 16:24): ‘My 10yo son tells me, of his time in the classroom: "I can look at *any* two things and make them fight in my mind"’
[04:35:33] <nshepperd2> i always suspected Apple was covertly manipulating the collective unconscious
[04:36:10] <ivan> thanks gwern - I am liberating the TOG book mentioned downthread
[04:36:33] <ivan> (it's on openlibrary)
[04:37:24] <gwern> yeah but IA scans aren't that great
[04:37:27] <catern> this restofworld.org site seems quite shit
[04:37:52] <ivan> gwern: really? they use DSLRs and your CIS feed scanning is better?
[04:38:12] <catern> the other article I saw on restofworld.org was a hit piece on prospera
[04:38:14] <gwern> ivan: they certainly seem to come out nicer. maybe the destructive scanning is just that much better
[04:38:19] <ivan> hmm
[04:38:38] <catern> rather pathetic, and amusingly, it's funded by eric schmidt's daughter: https://www.wsj.com/articles/eric-schmidts-daughter-has-tech-ambitionsjust-not-in-silicon-valley-11601218509
[04:38:38] <Robomot> Eric Schmidt’s Daughter Has Tech Ambitions—Just Not in Silicon Valley  - WSJ (Sophie Schmidt launched Rest of World, a nonprofit journalism startup, in May to shine a light on technology’s impact in less-covered markets.)
[04:38:48] <ivan> I think maybe they just don't sharpen or adjust the curves enough
[04:38:55] <TheWhisper> <gwern> (materialism/determinism will just increasingly be the common sense default of people raised irreligiously in a world increasingly filled with thinking machines, not even thought about except when you run into your old friend who read a bunch of c.s. lewis and wants to explain your errors) <- up until the thinking machines become so powerful and abstracted away that worshipping them as gods becomes the new religion
[04:39:07] <catern> the generational transition from creating massive value, to destroying it, seems to have accelerated in modern times
[04:40:06] <gwern> they must buy salvation of their metaphorical souls
[04:40:38] <gwern> ivan: I dunno what they do, but IA scans look like dogshit, and that's when they aren't completely fucked up like layers turning into multiple pages each unreadable
[04:45:38] <feepbot> <gwern> 'If you've only read "modern" HIGs, I definitely recommend reading the 1987 edition! It's *very* different. It is amusingly difficult to imagine this passage in a contemporary Apple text.' https://twitter.com/andy_matuschak/status/1447408339160231947 :(
[04:45:41] <|dbotdan> Andy Matuschak (@andy_matuschak, 2021-10-11 03:46): ‘If you've only read "modern" HIGs, I definitely recommend reading the 1987 edition! It's *very* different. It is amusingly difficult to imagine this passage in a contemporary Apple text.’ Images: https://nitter.1d4.us/pic/media%2FFBY6NJSVQAAwXRA.jpg%3Fname%3Dorig (description: text; confidence: 0.90)
[04:48:12] <catern> gwern: you replied to me with my own link???
[04:48:18] <catern> i've been robbed
[04:48:18] <gwern> jinx
[04:49:30] <Obormot\Arcturus> gwern: Yeah, it occurred to no one, back then, that all these generalizations about "people" are totally true but only if you chop off the bottom 85% or so of the intelligence distribution
[04:49:51] <TheWhisper> 2021 HIG: too much microdosing
[04:49:57] <TheWhisper> 1987 HIG: perfect amount of macrodosing
[04:50:04] <Obormot\Arcturus> "Everyone who uses or might use computers and therefore to whom our comments could even conceivably apply is like this" was totally true back then!
[04:50:16] <Obormot\Arcturus> Then we got the iPhone and shit like that and it stopped being true.
[04:50:17] <catern> i macrodose food and water every day
[04:50:52] <Obormot\Arcturus> Eternal September of the Curious Mind
[04:55:29] <TheWhisper> Nobody has time to be curious when it takes laser focus and determination to buy an Xbox before the bots scalp them
[05:00:30] <feepbot> <gwern> https://www.youtube.com/watch?v=StLtMcsbQes&t=2s seems like a reasonable overview
[05:00:30] <feepbot> Large Language Models and the Future of AI with Connor Leahy, EleutherAI - YouTube
[05:00:46] <Obormot\Arcturus> https://www.greaterwrong.com/posts/jr3sxQb6HDS87ve3m/book-review-free-will/comment/MgtpPZCdSpFhYv6gu ... this guy makes a good point
[05:00:47] <Robomot> Razied comments on Book Review: Free Will - LessWrong 2.0 viewer (I think the main point that people are missing here is that Sam Harris is an experienced meditator with years of intensive retreat practice. …)
[05:01:49] <nshepperd2> damn, i didn't know writing books about free will was just another of the many dangers of meditation
[05:01:59] <nshepperd2> don't meditate, kids
[05:03:24] *** Joins: sh0|tmp (~sh@135-180-132-137.fiber.dynamic.sonic.net)
[05:04:10] *** Quits: vorpalhex (sid421573@lymington.irccloud.com) (Ping timeout: 260 seconds)
[05:04:10] *** Quits: potatope (sid139423@lymington.irccloud.com) (Ping timeout: 260 seconds)
[05:04:10] *** Quits: pdg (sid395042@lymington.irccloud.com) (Ping timeout: 260 seconds)
[05:04:20] *** Joins: potatope (sid139423@id-139423.lymington.irccloud.com)
[05:04:23] *** Joins: vorpalhex (sid421573@id-421573.lymington.irccloud.com)
[05:04:45] *** Quits: foamy (sid25727@lymington.irccloud.com) (Ping timeout: 260 seconds)
[05:04:45] *** Quits: Mithaldu_ (sid27181@hampstead.irccloud.com) (Ping timeout: 260 seconds)
[05:04:53] *** Joins: foamy (sid25727@id-25727.lymington.irccloud.com)
[05:05:13] *** Quits: sh0 (~sh@135-180-132-137.fiber.dynamic.sonic.net) (Read error: Connection reset by peer)
[05:05:35] *** Joins: pdg (sid395042@id-395042.lymington.irccloud.com)
[05:05:40] *** Joins: Mithaldu_ (sid27181@id-27181.hampstead.irccloud.com)
[05:07:01] <feepbot> <gwern> https://arxiv.org/abs/2110.05448 https://twitter.com/ak92501/status/1447730659196342272
[05:07:02] <feepbot> [2110.05448] Unsupervised Neural Machine Translation with Generative Language Models Only (We show how to derive state-of-the-art unsupervised neural machine)
[05:07:02] <|dbotdan> AK (@ak92501, 2021-10-12 01:07): ‘Unsupervised Neural Machine Translation with Generative Language Models Only | abs: https://arxiv.org/abs/2110.05448 | using method to leverage GPT-3’s zero-shot translation capability, achieve sota in unsupervised translation on WMT14 English-French benchmark, attaining a BLEU score of 42.1’ Images: https://twitr.gq/pic/media%2FFBdfSRWXoAM2-oN.jpg%3Fname%3Dorig
[05:12:03] <feepbot> <gwern> https://arxiv.org/abs/2109.07740
[05:12:03] <feepbot> [2109.07740] Scaling Laws for Neural Machine Translation (We present an empirical study of scaling properties of encoder-decoder)
[05:15:35] <Obormot\Arcturus> https://en.wikipedia.org/wiki/Knightmare_Chess
[05:15:36] <Robomot> Knightmare Chess - Wikipedia (Knightmare Chess is a fantasy chess variant published by Steve Jackson Games (SJG) in 1996. It is a translation of a French game Tempête sur l'échiquier (Storm on the Chessboard), designed by Pierre Cléquin and Bruno Faidutti. A stand-alone 80 card expansion called Series 2 was scheduled for a December 1997 release.[1] …)
[05:16:20] <Obormot\Arcturus> "Conversely, Steve Darlington of RPGnet, while finding the artwork "absolutely gorgeous" and that "in terms of sheer presentation ... [Knightmare Chess] is streets ahead of anything I've seen in years", felt that while the game itself "might make for an interesting game or two, it's not something you'll be playing an awful lot." He said "the dark design only conflicts with the abstract nature of the game, and ends up being
[05:16:20] <Obormot\Arcturus>  more humorous than dramatic" and that it "ultimately doesn't hold your attention for too long."[7]"
[05:16:25] <Obormot\Arcturus> > streets ahead
[05:16:53] <gwern> that's an idiom you don't see much of these days. who goes out walking
[05:20:35] *** Quits: two2thehead (~user@124.195.205.148) (Ping timeout: 265 seconds)
[05:21:53] <feepbot> <gwern> https://openreview.net/forum?id=IKA7MLxsLSu
[05:21:54] <feepbot> Data and Parameter Scaling Laws for Neural Machine Translation | OpenReview (We observe power law scaling in neural MT and use it to predict BLEU when obtaining more data for low-resource scenarios.)
[05:26:54] <feepbot> <gwern> https://twitter.com/ak92501/status/1447734873326768128 today is the day of big models, it seems
[05:26:56] <|dbotdan> AK (@ak92501, 2021-10-12 01:24): ‘Yuan 1.0: Large-Scale Pre-trained Language Model in Zero-Shot and Few-Shot Learning | abs: https://arxiv.org/abs/2110.04725 | singleton language model with 245B parameters, sota results on natural language processing tasks. high-quality Chinese corpus with 5TB high quality texts’ Images: https://nitter.namazso.eu/pic/media%2FFBdjJgZX0AIUf90.jpg%3Fname%3Dorig
[05:26:56] <|dbotdan> (description: table; confidence: 0.98)
[05:31:58] <feepbot> <gwern> 'The computing amount of Yuan 245B is much greater than that of PanGu-α. The training loss of Yuan 245B is the smallest among these three models. Table 10 compares the generation results between Yuan and recently published Chinese pretrained language models, Pangu-α[7] and Ernie 3.0[21]. The average scores of Yuan outperform Pangu-α and Ernie 3.0 by a large margin on
[05:31:58] <feepbot> Close-book QA[24] and Span Extraction reading comprehension[25], which proves the excellent zero-shot generation capacity of Yuan 245B. Regarding WebQA, Yuan significantly improves the performance, no matter evaluated with EM or F1 Score. For CMRC2018, Yuan also achieved a better averaged score and F1 score compared to the SOTA, and it is little worse on EM compared to the SOTA'
[05:35:36] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[05:36:58] <feepbot> <gwern> 'Previous work (Brown et al., 2020) has shown that after generative pre-training on a corpus of English-dominated Internet text, GPT-3 models are far more capable of translating into English than translating out of English. This is reflected by the disparity between English-French and French-English BLEU scores immediately after few-shot distillation and before
[05:36:58] <feepbot> backtranslation on the few-shot prompted data. Interestingly, after only two epochs of backtranslation on the relatively scarce few-shot prompted data, this gap is reversed, with all models achieving significantly higher English-French BLEU than French-English BLEU. The data efficiency of the bootstrap suggests that coming out of pre-training, the models are merely misaligned
[05:36:58] <feepbot> rather than deficient in knowledge about French, and that their latent knowledge about translation out of English can be surfaced using backtranslation.'
[05:48:07] *** Quits: src (~src@user/src) (Quit: Leaving)
[05:54:52] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[05:59:28] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[06:09:03] * gwern looks at a few web serials since he's caught up on _practical guide_ now and sighs as all he can think of is "I could design a much better site for reading web serials than *these*"
[06:10:43] <gwern> (why don't the 'next' links prerender so the chapters are instantaneous? why do these blogs have useless UI clutter like 'uncategorized' tag links on every page? why can't I just hit 'Right' or 'PgDwn' to go to the next chapter? why no dark mode? why are the default font sizes often so terrible?)
[06:12:52] <gwern> I mean look at this: https://thezombieknight.blogspot.com/2013/04/page-1.html ok the fancy background is cool initially but I expect it'd grow distracting after a while, but more importantly, did this guy set an entire web serial in ARIAL???
[06:12:53] <Robomot> The Zombie Knight Saga: Page 1 -- I. (A dark serial novel. Free to read, contemporary fantasy. Mature language. Updated by ~500 words every night at midnight EST.)
[06:16:51] <gwern> http://www.ironteethserial.com/dark-fantasy-story/story-interlude/prologue/ or this one, just has a giant margin to the left, forcing a horizontal scroll with half the right-column cutoff, for absolutely no reason
[06:16:53] <Robomot> Online Dark Fantasy Story - The Iron Teeth - Prologue: The Shattering of Ways (The Iron Teeth Prologue: The Shattering of Ways Online Dark Fantasy Story Blood poured from the man’s wounds onto the cold ground beneath him. He knew he was dying, and beyond help now. He choked and gasped as bitter fluids Coroulis, Dark Fantasy Story, drake, Jerack, Myagnoir, web serial)
[06:17:02] <gwern> and the font is way too small
[06:18:53] <gwern> looks like it has that footer ad at the end of every chapter too
[06:19:26] <gwern> or take this one:   'Author’s Note: Please be sure to use the ‘Previous – Next Chapter’ links at the top and bottom of these chapters, and not the links further down (just above the comments for the chapter) which list the actual chapter title (such as Orientation 1-02 →) in this chapter. The former (the previous chapter/next chapter links) were manually created by me and are the...
[06:19:32] <gwern> ...intended reading order, while the latter are automatically generated by WordPress and are simply the posted order without taking into account chapters being rearranged or the eventual addition of the second story on this site. Thank you!' https://ceruleanscrawling.wordpress.com/2015/10/03/orientation-1-01/ is it unreasonable to shame him for this? I don't think it is
[06:19:33] <Robomot> Orientation 1-01 | Heretical Edge and Summus Proelium (Next Chapter Author’s Note: Please be sure to use the ‘Previous – Next Chapter’ links at the top and bottom of these chapters, and not the links further down (just above the…)
[06:41:11] <PlanckWalk> Yes, a lot of authors could do with either learning web design, or finding someone who can do it for them.
[06:41:35] <PlanckWalk> Especially the ones who have aspirations of ever getting enough readers to go commercial.
[06:47:52] <gwern> indeed. I cut them a bit of slack if they don't have any patreon or anything except I think all of these do -_-
[06:48:48] <gwern> one thought I had was that heavily character-centric chapters would benefit from the Robert Jordan strategy of little dropcap like logos at the beginning of each chapter
[06:49:24] <gwern> eg _practical guide_ - I bet you could comission a pretty nice set of icons for <$500
[06:55:21] <mst> gwern: having watched scott versus wordpress ...
[06:56:34] <gwern> scott is like baby yoda, you know that
[06:58:41] * gwern is trying out crunchyroll for the first time to watch _odd taxi_ since it isn't on bakabt for some reason. the ads aside, it actually works pretty well even for free?
[07:00:31] <pie_> gwern: isnt there that one website nowadays thats like patreon for writing
[07:00:52] <gwern> pie_: a couple come to mind. royalroad, wattpad
[07:01:07] <pie_> the one with all the "terrible right wing people"
[07:01:36] * pie_ wishes his map could encode  topic->key lookups...
[07:01:44] <gwern> uh, not sure. can't say I'm *that* deep into web fiction
[07:02:29] <gwern> (royalroad is decent enough, but of course the problem is that authors very sensibly don't want to trust a third-party for the rest of their life and such third-party hosts inevitbaly limit you technically too)
[07:03:30] <pie_> valid
[07:09:14] * gwern is amused that as a character exclaims "it's about money, isn't it? it's always about money" - cut to the ad break
[07:13:02] <nshepperd2> hah
[07:14:00] <nshepperd2> cats on my lap purring right now~
[07:14:03] <gwern> I'd like to think that the ad placements are manual and somewhere at crunchyroll someone had a sensible chuckle to themselves that day... but it's probably all automated
[07:15:12] <nshepperd2> the automated ad placement system has no mouth and must scream^Wmake jokes to spite its creators
[07:16:04] <shawwwn> nshepperd2: lucky
[07:17:13] <gwern> still, CR wants $10/month? that seems a bit steep as an adjunct to all the other streaming services. isn't netflix etc all topped out at $20? seems like CR really makes sense mostly if you're watching primarily, and so a lot, of anime
[07:17:56] <nshepperd2> i don't think it's worth it
[07:18:40] *** Quits: Skarn (~skarn@user/skarn) (Quit: bye)
[07:18:59] *** Joins: Skarn (~skarn@user/skarn)
[07:19:17] <nshepperd2> and if you're a heavy anime watcher i think you quickly notice limitations like CR having random seasons of things missing bc of regional rights and stuff
[07:19:55] <PapuaHardyNet> most heavy anime watchers use torrents, I think
[07:20:35] <PapuaHardyNet> also, what anime has gotten you interested, gwern
[07:21:32] <gwern> nshepperd2: true, but I think the idea is that you watch the new stuff on CR while it's there and torrent the long tail
[07:21:44] <nshepperd2> https://irc.zlkj.in/uploads/19b9b9e959007ad9/PXL_20211012_035101829.jpg cat
[07:21:45] <Robomot> image/jpeg (3024x4032; 4 MB)
[07:22:12] <gwern> PapuaHardyNet: _Odd Taxi_, as I said. not on bakabt tonight when I went to grab a bunch of my to-watch items as I realized that all the movies I have downloaded are grim long serious ones and I've been avoiding them as work
[07:23:00] <gwern> the problem with torrents is that with the rise of streaming, the torrent scene seems to've decayed, and it's always been in flux - if I lose bakabt I don't even know where I'd go for curated anime torrents
[07:23:13] <gwern> nshepperd2: odd eyes
[07:23:56] <nshepperd2> oh, are they unusual?
[07:24:40] <saturn2> bureaucat
[07:25:01] <gwern> might just be the reflection making the outlines look off
[07:25:06] <gwern> but it gives me a gan feel
[07:25:17] <gwern> are you sure you have a real cat and not a broken afhq model
[07:26:19] <PapuaHardyNet> gwern: while I do have a bakabt account, I don't see how using bakabt is better than, say, using nyaa
[07:26:39] <gwern> nyaa is way more messy, assuming it's not down or at yet another url
[07:26:41] <nshepperd2> idk, that pic was taken with the official phone app on a pixel, so who knows, maybe google's proprietary algorithms fucked with it
[07:27:02] <PapuaHardyNet> the nyaa scene also has newer releases of the same anime series in much better quality, especially for popular series like EVA (to give an example)
[07:27:29] <PapuaHardyNet> here quality can mean many things, including better subs, or improved subs
[07:27:32] <saturn2> paying money for anime? preposterous
[07:27:33] <gwern> bakabt does update
[07:27:53] <gwern> saturn2: it is against the old ways, but the world has changed... and perhaps the tribes must too
[07:28:17] <gwern> can the zoku stand against the winds that will blow? the bamboo bends, and lives, and the oak falls
[07:31:21] <nshepperd2> been a while since i used bakabt for something
[07:31:30] <nshepperd2> currently airing series seem to come out of nyaa
[07:43:18] *** sh0|tmp is now known as sh0
[07:45:51] <mst> ... if Aslan is Jesus' fursona, does that mean it's really the Chronicles of Nyaania?
[07:50:23] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Read error: Connection reset by peer)
[07:52:21] *** Quits: srhm (~srhm@user/srhm) (Ping timeout: 265 seconds)
[07:55:51] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[08:00:05] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 250 seconds)
[08:15:19] <PapuaHardyNet> WLOP's art is amazing
[08:15:24] <PapuaHardyNet> a feast for the senses
[08:23:28] *** Joins: starfire (~slyfox@185.207.249.60)
[08:23:49] <starfire> anyone alive?
[08:24:43] <mst> BRAIIIINS
[08:25:01] <starfire> so you admit it!
[08:25:29] <saturn2> hello
[08:25:50] <starfire> why do people come here?
[08:26:06] <starfire> what is your EV from this chat?
[08:26:55] <mst> we come here because it's fun
[08:26:59] <mst> don't overthink it
[08:27:19] <mst> after all, part of the fun is in overthinking everything *else* ;)
[08:27:37] <starfire> that's a silly blindspot to have. you must apply your art to everything
[08:28:00] <starfire> especially the things you're aversive to applying it to
[08:28:34] <starfire> by "art" i mean your ability to think
[08:29:00] <starfire> what's fun about it?
[08:30:10] <saturn2> are you here to try to rescue us from chatting?
[08:30:31] <starfire> i'm here because i'm curious what people do here and why
[08:30:42] <PapuaHardyNet> awkward
[08:31:16] <starfire> for who?
[08:31:22] <mst> and yet you start off by making accusations of blindspots based on zero data
[08:31:35] <starfire> you said "don't overthink it"
[08:31:40] <starfire> that is a blindspot
[08:32:18] <mst> it really isn't. in fact, *over* thinking by definition is an unnecessary expenditure of effort that doesn't forward your goals
[08:32:35] <starfire> colloquially it means, "don't think about it"
[08:33:10] <mst> this is #lesswrong, I expected you to read the words, not make shit up based on how other people misuse those words
[08:33:32] <starfire> the assumption in "don't overthink it" is that thinking about it at all is overthinking it
[08:33:34] <PapuaHardyNet> this almost feels like you are signalling "rationality" tbh
[08:33:46] <mst> maybe it is for you
[08:33:59] <PapuaHardyNet> mst: that was for starfire
[08:34:07] <starfire> none of you have actually answered my question
[08:34:23] <saturn2> trying to assign an explicit EV to every form of entertainment would be what we call goodharting
[08:34:25] <kuudes> people generally don't come here but just are here
[08:34:33] <kuudes> though right now I will be off for reboot
[08:34:38] *** Quits: kuudes (~kuudes@user/kuudes) (Quit: Leaving)
[08:36:20] <starfire> goodharting is when you are trying to measure a thing by measuring something downstream of it that can be faked, like standardized testing
[08:37:20] <starfire> i don't need an explicit EV though. 
[08:37:39] *** Joins: kuudes (~kuudes@user/kuudes)
[08:37:40] <PlanckWalk> I'm planning to buy an EVm but I hardly use the car I have.
[08:37:52] <starfire> so this chat is just for entertainment?
[08:38:16] <PlanckWalk> No, though it mostly is in practice.
[08:38:33] <mst> talking about a wide range of topics with people who have read the sequences tends to be both fun and often a useful source of information and discussion
[08:38:39] <PlanckWalk> For some values of "entertainment" anyway.
[08:39:43] <mst> right, same way as evening drinking at a conference with people who share overlapping expertise is both entertaining and informative
[08:40:03] <starfire> informative to do what?
[08:40:28] <starfire> what do you do with the information you've gained?
[08:41:35] <mst> ...
[08:41:39] <PlanckWalk> Anything I like :-)
[08:42:12] <starfire> what do you like?
[08:42:31] <mst> learning things is seldom wasted time, and often comes in handy later in unexpected ways
[08:42:32] <PapuaHardyNet> gentlemen, I suppose by now it is clear that this conversation is not in good faith
[08:43:51] <starfire> oddly it is in good faith.
[08:44:14] <starfire> there's a question i keep asking that people aren't answering
[08:44:27] <PlanckWalk> What was that question?
[08:44:59] <PlanckWalk> Oh, "what is your EV from this chat?"
[08:45:02] <PlanckWalk> 1.62
[08:45:16] <starfire> cool
[08:45:21] <kuudes> given nord stream 2 was completed, isn't that good if germany now needs more energy?
[08:45:35] <PlanckWalk> Well, it was back then.  It's 1.58 now.
[08:45:44] <mst> the increased LNG prices aren't helping though
[08:46:02] <starfire> i will let you get back to your corpse entertainment
[08:46:12] *** Quits: starfire (~slyfox@185.207.249.60) (Quit: Leaving)
[08:47:29] <PlanckWalk> Yay, back up to 1.62!
[08:47:49] <mst> http://trout.me.uk/foom.jpg
[08:47:50] <Robomot> image/jpeg (900x600; 85 KB)
[08:47:56] <saturn2> i wonder what he was hoping to accomplish
[08:48:30] <kuudes> well, it was prosocial to leave without getting banned
[08:50:12] <mst> I think he was coming from a mistaken framing, hence being unable to understand my attempts at genuine answers
[08:52:52] <mst> funny that he quit the instant an actual conversation seemed to be potentially starting
[08:53:37] <PlanckWalk> funny that they quit the instant a conversation wasn't about them
[08:57:00] <PapuaHardyNet> Shells are actually really unweildy for text processing - the one thing they are supposed to be good at
[08:57:48] <PapuaHardyNet> what shells are really good at is an interface to navigate the file system and start programs that are good at stuff like text processing
[08:58:35] <PapuaHardyNet> representing all data as text is a dumb idea
[08:59:07] <mst> I think they felt like we weren't taking them seriously
[08:59:18] <mst> which is probably the one thing they were right about in the whole interaction
[09:01:12] <PlanckWalk> A question asking for a definite numerical value to be assigned to an action is ... definitely odd.
[09:01:53] <PapuaHardyNet> lurking is a standard practice when you want to understand a community and become a part of one
[09:02:15] <saturn2> did they want us to explain the concept of social interaction?
[09:02:25] <mst> they did an excellent job of making me consider taking them seriously to have a negative EV
[09:11:00] <PapuaHardyNet> when I was in high school, I asked this girl why does she spend time with our social group. She said it was fun.
[09:11:12] <PapuaHardyNet> I asked, "Why is it fun exactly?" She just stared at me in confusion.
[09:12:14] <PapuaHardyNet> (I'm fairly sure I'm non-neurotypical based on such experiences, and the need for me to consciously intellectually understand most of social skills and social interaction)
[09:16:29] <nshepperd2> who can truly explain what is fun
[09:18:43] <PlanckWalk> Unfortunately no one can be told what fun is. You'll have to see it for yourself.
[09:18:59] <kuudes> wasn't there fun theory somewhere?
[09:20:19] <PapuaHardyNet> https://www.greaterwrong.com/posts/K4aGvLnHvYgX9pZHS/the-fun-theory-sequence
[09:20:21] <Robomot> The Fun Theory Sequence - LessWrong 2.0 viewer (Fun Theory is the field of knowledge that deals in questions such as "How much fun is there in the universe?", "Will we ever run out of fun?", "Are we having fun yet?" and "Could we be having more fun?" Many critics (including George Orwell) have commented on the inability of authors to imagine Utopias where anyone would actually want to live. …)
[09:20:56] <PapuaHardyNet> fun theory is lower quality than I expected. I'd recommend people try reading something more fundamental, like Nicomachean Ethics, if they want to understand fun
[09:21:07] <saturn2> fun theory is more about how it might be possible to still have fun when we're uploaded computer gods
[09:21:36] <PapuaHardyNet> yeah, what saturn2 said. It assume you have an idea about fun already
[09:21:49] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[09:25:13] <kuudes> but is it fun
[09:25:53] <PapuaHardyNet> not for me, I abandoned it midway all the three times I attempted to read it
[09:38:05] <mst> kuudes: depends on how you calculate your EV, obviously?
[09:44:10] <kuudes> ah, indeed, of course
[09:47:35] <PapuaHardyNet> https://seirdy.one/2021/01/12/password-strength.html
[09:47:35] <Robomot> Becoming physically immune to brute-force attacks - Seirdy (Using thermal physics, cosmology, and computer science to calculate password vulnerability to the biggest possible brute-force attack.)
[09:48:04] <PapuaHardyNet> "A password with 327 bits of entropy is nearly impossible to crack even if you burn the whole observable universe trying to do so."
[09:52:17] <adiabatic> "An excerpt from a religious text with a trailing space: " kek
[10:04:38] *** Quits: adiabatic (~adiabatic@user/adiabatic) (*.net *.split)
[10:04:38] *** Quits: Skarn (~skarn@user/skarn) (*.net *.split)
[10:04:38] *** Quits: nanotube (~nanotube@user/nanotube) (*.net *.split)
[10:04:38] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (*.net *.split)
[10:04:39] *** Quits: Obormot\Gaia (~obormot@user/obormot) (*.net *.split)
[10:04:39] *** Quits: sm2n (~sm2n@user/sm2n) (*.net *.split)
[10:04:39] *** Quits: luna-is-here (~quassel@ip-95-223-59-100.hsi16.unitymediagroup.de) (*.net *.split)
[10:04:39] *** Quits: soapes (~soapes@46-126-108-131.dynamic.hispeed.ch) (*.net *.split)
[10:04:39] *** Quits: wrycode (~wrycode@168.235.110.39) (*.net *.split)
[10:04:39] *** Quits: rxcomm (~rxcomm@user/rxcomm) (*.net *.split)
[10:04:39] *** Quits: rugan_ (~mich@srv1.demonlabs.be) (*.net *.split)
[10:04:39] *** Quits: mst (~matthewt@perl/shadowcat-mst/chainsaw-wielder) (*.net *.split)
[10:04:39] *** Quits: StathisA (~StathisA@178-147-35-19.haap.nym.cosmote.net) (*.net *.split)
[10:04:39] *** Quits: dv^_^_ (~cat@80-42-10-216.dynamic.dsl.as9105.com) (*.net *.split)
[10:04:39] *** Quits: martin02 (~silas@141.84.69.76) (*.net *.split)
[10:17:37] *** Quits: topdownjimmy (~topdownji@user/topdownjimmy) (Remote host closed the connection)
[10:18:37] *** Joins: topdownjimmy (~topdownji@user/topdownjimmy)
[10:26:26] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[10:26:26] *** Joins: Skarn (~skarn@user/skarn)
[10:26:26] *** Joins: nanotube (~nanotube@user/nanotube)
[10:26:26] *** Joins: Lord_of_Life (~Lord@user/lord-of-life/x-2819915)
[10:26:26] *** Joins: Obormot\Gaia (~obormot@user/obormot)
[10:26:26] *** Joins: sm2n (~sm2n@user/sm2n)
[10:26:26] *** Joins: luna-is-here (~quassel@ip-95-223-59-100.hsi16.unitymediagroup.de)
[10:26:26] *** Joins: soapes (~soapes@46-126-108-131.dynamic.hispeed.ch)
[10:26:26] *** Joins: wrycode (~wrycode@168.235.110.39)
[10:26:26] *** Joins: rxcomm (~rxcomm@user/rxcomm)
[10:26:26] *** Joins: rugan_ (~mich@srv1.demonlabs.be)
[10:26:26] *** Joins: mst (~matthewt@perl/shadowcat-mst/chainsaw-wielder)
[10:26:26] *** Joins: StathisA (~StathisA@178-147-35-19.haap.nym.cosmote.net)
[10:26:26] *** Joins: dv^_^_ (~cat@80-42-10-216.dynamic.dsl.as9105.com)
[10:26:26] *** Joins: martin02 (~silas@141.84.69.76)
[10:28:45] *** Quits: StathisA (~StathisA@178-147-35-19.haap.nym.cosmote.net) (Max SendQ exceeded)
[10:28:45] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Max SendQ exceeded)
[10:29:26] *** Joins: Lord_of_Life (~Lord@user/lord-of-life/x-2819915)
[10:30:41] *** Joins: StathisA (~StathisA@178-147-35-19.haap.nym.cosmote.net)
[10:33:28] <PapuaHardyNet> It's pretty crazy how people comment about how they lost their family members or whatever on youtube music videos
[10:34:04] <PapuaHardyNet> how insecure can one be that they feel compelled to share such pain to the world and grovel for sympathy and attention from strangers?
[10:35:12] <rsaarelm> Maybe they don't have any other place to talk about stuff like that.
[10:35:24] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[10:35:31] <nshepperd2> i imagine having family members die would make you question your security, yes
[10:35:33] <rsaarelm> And no real idea where you're supposed to talk about stuff like that.
[10:35:38] <saturn2> i don't think they're groveling for sympathy
[10:36:21] *** Quits: Fusxfaranto (~Fusxfaran@cpe-75-85-179-208.san.res.rr.com) (Ping timeout: 245 seconds)
[10:36:32] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[10:36:44] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[10:37:57] *** Quits: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net) (Quit: Going offline, see ya!)
[10:38:53] <PapuaHardyNet> hmm. that makes sense. also perhaps it is quite appropriate to share such things in a semi-anonymous platform like youtube which is a hugbox
[10:40:03] <PapuaHardyNet> my experience hasn't been pleasant when I share such things. this probably says more about me than about others, and more about the communities I've been in, than about youtube
[10:40:23] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[10:41:54] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[10:46:29] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 250 seconds)
[10:55:28] *** Joins: feep[work] (~mathis@217.64.163.97)
[11:29:27] *** Joins: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[11:57:34] *** Joins: voltage_ (voltage@user/voltage)
[11:58:31] <ivan> https://www.amazon.com/gp/customer-reviews/R2GZ01J0VX33HC/ common story
[11:58:31] <Robomot> oh my gosh!!! i used this thing for 6 months and...
[11:59:14] <Obormot\Arcturus> ... rofl
[12:00:03] *** Joins: Lucas54 (~Lucas@072-182-100-009.res.spectrum.com)
[12:03:08] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[12:08:28] *** Joins: voltage_ (voltage@user/voltage)
[12:09:58] *** Quits: _inky (~inky_@141.136.76.213) (Ping timeout: 265 seconds)
[12:24:23] *** Joins: _inky (~inky_@46.241.144.156)
[12:37:33] <PapuaHardyNet> https://www.youtube.com/watch?v=7e_zNLyEReg
[12:37:35] <Robomot> Mirror's Edge: 13 Years Later - YouTube (Head to http://www.squarespace.com/whitelight and use coupon code "whitelight" for 10% off your first purchase of a website or domain.Mirror's Edge is an exp...)
[12:38:02] <PapuaHardyNet> just want to say, the writing behind this game "review" is amazing.
[12:42:44] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[12:47:28] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 268 seconds)
[12:50:00] *** Quits: Lucas54 (~Lucas@072-182-100-009.res.spectrum.com) (Ping timeout: 256 seconds)
[13:08:58] *** Joins: galambo (galambo@user/galambo)
[13:11:50] *** Quits: galambo__ (galambo@user/galambo) (Ping timeout: 265 seconds)
[13:33:47] *** Joins: Gurkenglas_ (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de)
[13:36:29] *** Quits: _inky (~inky_@46.241.144.156) (Ping timeout: 265 seconds)
[13:36:31] *** Quits: Gurkenglas (~Gurkengla@dslb-002-203-144-204.002.203.pools.vodafone-ip.de) (Ping timeout: 252 seconds)
[13:50:17] *** Joins: galambo_ (galambo@user/galambo)
[13:52:23] *** Quits: galambo (galambo@user/galambo) (Ping timeout: 250 seconds)
[13:53:24] *** Joins: galambo (galambo@user/galambo)
[13:53:47] <shawwwn> Ugh
[13:54:01] <shawwwn> I can’t recover too soon
[13:54:14] <shawwwn> It’s a mild annoyance but still annoying
[13:54:40] <shawwwn> Speaking of recovery… I hope dbohdan will be back soon :(
[13:55:46] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 252 seconds)
[14:03:46] <shawwwn> ahhhh
[14:11:48] *** Joins: _inky (~inky_@37.252.67.70)
[14:12:15] <kuudes> do you know if you are in covid?
[14:25:11] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[14:25:28] *** Joins: voltage_ (voltage@user/voltage)
[14:25:40] *** Quits: voltage_ (voltage@user/voltage) (Remote host closed the connection)
[14:43:34] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[14:48:01] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[15:04:51] *** Joins: voltage_ (voltage@user/voltage)
[15:12:46] *** Joins: two2thehead (~user@124.195.202.105)
[15:22:05] <PapuaHardyNet> shawwwn: did you get yourself tested yet (re: kuudes)
[15:22:21] <PapuaHardyNet> also, I've been thinking, perhaps the most sensible way to model GPU prices is using ETH as your currency
[15:22:32] <PapuaHardyNet> now I only need a dataset to test this
[15:23:28] <PapuaHardyNet> nice, discord logged me out because my VPN wasn't on
[15:30:24] <shawwwn> It’s not covid. I’ve just been being nice to you all rather than graphic
[15:30:30] <shawwwn> Straightforward stomach flu
[15:31:05] <shawwwn> Luckily I haven’t felt like throwing up, just … uh… spent a lot of time in the bathroom
[15:34:28] <kuudes> hmm, ok
[15:43:31] <shawwwn> i've always wondered
[15:43:43] <shawwwn> is there an equivalent to mentos + soda, but for the digestive tract?
[15:43:54] <shawwwn> because it seems like I found it :/
[15:52:16] <kuudes> sounds something like norovirus
[15:55:17] <shawwwn> eh, surely there must be something that, if you ingest it, will result in lots of gas production
[15:55:30] <shawwwn> similar to mentos and soda
[15:55:48] <kuudes> mentos+soda is base+acid reaction, isn't it?
[15:56:30] <kuudes> norovirus infection produces volume out of mass iirc, which causes the vomiting and diarrhea
[15:57:03] <kuudes> ie it is not that much that it triggers vomiting reflex rather than the stuff it produces just does not fit into you
[15:58:57] <shawwwn> ah
[16:41:16] *** Joins: galambo_ (galambo@user/galambo)
[16:41:49] <nshepperd2> i have used the power of the new stylegan to turn a person into a tree https://cdn.discordapp.com/attachments/730484623028519072/897470976898519120/out.mp4
[16:41:50] <Robomot> video/mp4 (5 MB)
[16:44:00] <catern> https://ronjeffries.com/xprog/articles/jatbaseball/ entertaining
[16:44:01] <Robomot> We Tried Baseball and It Didn't Work (This is RonJeffries.com, the combination of new articles, XProgramming, SameElephant,  and perhaps even some new items never before contemplated.  <br/>Copyright © 1998-forever Ronald E Jeffries)
[16:44:02] *** Quits: galambo (galambo@user/galambo) (Ping timeout: 260 seconds)
[16:44:39] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[16:49:11] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 250 seconds)
[16:59:46] *** Joins: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net)
[17:01:03] <PapuaHardyNet> my mother and sister came to visit. was pretty good
[17:03:17] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[17:18:16] <gwern> ivan: same damn thing happened to me with my coway
[17:19:00] <gwern> nshepperd2: went to a state with legal weed, didn't feel so good! many such cases!
[17:21:41] <gwern> catern: the problem is, baseball *is* boring. in fact, it's so boring that MLB is screwing with the atlantic league to try to figure out rule tweaks which won't make the fans scream but will not be so goddamn boring: https://www.nytimes.com/2019/03/08/sports/mlb-atlantic-league-rule-changes.html...
[17:21:42] <Robomot> Bigger Bases and Limited Shifts: Atlantic League to Test Rule Changes - The New York Times (At the behest of Major League Baseball, the independent Atlantic League will test several rule changes this season.)
[17:21:46] <gwern> ...https://www.bloomberg.com/news/features/2021-10-11/mlb-rule-changes-atlantic-league-tests-tweaks-meant-to-save-baseball
[17:21:47] <Robomot> MLB Rule Changes: Atlantic League Tests Tweaks Meant to Save Baseball - Bloomberg (The league is using the independent Atlantic League as a laboratory for changes that could speed up games and add more drama.)
[17:22:53] <catern> gwern: yeah that makes the analogy even better since the author doesn't realize that :)
[17:31:22] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 252 seconds)
[17:34:20] <nshepperd2> "what did you think 'smoke trees' meant?"
[17:42:13] *** Joins: two2thehead (~user@124.195.202.105)
[17:43:43] <gwern> RiversHaveWings: you haven't gotten position clamping working? https://twitter.com/RiversHaveWings/status/1447927371542286351
[17:43:45] <|dbotdan> Rivers Have Wings (@RiversHaveWings, 2021-10-12 14:09): ‘Another #StyleGAN3 + CLIP iteration video, this time using an image prompt that @nshepperd1 made with CLIP guided diffusion.’ Watch video: https://nitter.vxempire.xyz/RiversHaveWings/status/1447927371542286351
[17:51:24] <feepbot> <gwern> https://arxiv.org/abs/2110.04830
[17:51:26] <feepbot> [2110.04830] Vectorization of Raster Manga by Deep Reinforcement Learning (Manga is a popular Japanese-style comic form that consists of black-and-white)
[17:51:41] <rmmh> gwern: one tweet down, it's intentional
[17:52:45] <nshepperd2> gwern: we got fixed-position working but people said they liked the erratic motion heh
[17:52:59] <gwern> weird
[17:53:34] *** Joins: two2theheadPC0 (~user@124.195.202.105)
[17:54:16] <nshepperd2> i can see its charm
[17:56:02] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 265 seconds)
[17:56:13] *** two2theheadPC0 is now known as two2thehead
[17:59:17] <feepbot> <gwern> 'by carefully utilizing the widespread supervision among the image-text pairs, our De-CLIP can learn generic visual features more efficiently. Instead of using the single image-text contrastive supervision, we fully exploit data potential through the use of (1) self-supervision within each modality; (2) multi-view supervision across modalities; (3) nearest-neighbor
[17:59:18] <feepbot> supervision from other similar pairs. Benefiting from intrinsic supervision, our DeCLIP-ResNet50 can achieve 60.4% zero-shot top1 accuracy on ImageNet, which is 0.8% above the CLIP-ResNet50 while using 7.1 x fewer data. Our DeCLIP-ResNet50 outperforms its counterpart in 8 out of 11 visual datasets when transferred to downstream tasks.' https://arxiv.org/abs/2110.05208 join the
[17:59:18] <feepbot> club, lots of people do better than clip...
[17:59:18] <feepbot> [2110.05208] Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm (Recently, large-scale Contrastive Language-Image Pre-training (CLIP) has)
[17:59:46] *** Joins: galambo__ (~galambo@user/galambo)
[18:03:43] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 250 seconds)
[18:04:18] <feepbot> <gwern> https://psyarxiv.com/8cxyh
[18:08:12] <RiversHaveWings> gwern: yeah so i just manually calculate the translate/rotate params for the current latent and apply an L2 penalty vs the params for the average latent
[18:08:29] <RiversHaveWings> this keeps the "harsh motion" but stops it from sliding all the way over to the "skybox"
[18:09:02] <nshepperd2> the 4th wall eheh
[18:09:15] <RiversHaveWings> and i can either fix it in place entirely or vary the strength of the L2 penalty
[18:09:33] <RiversHaveWings> to achieve various degrees of stabilization
[18:12:26] *** Joins: son0p (~ff@181.136.122.143)
[18:14:44] <feepbot> <gwern> uploads https://www.gwern.net/docs/psychology/2002-kuhlmeier.pdf
[18:18:28] <nshepperd2> i think it's kind of interesting that the camera motion is part of the optimization. so like in this gen https://cdn.discordapp.com/attachments/730484623028519072/897491163848773702/out.mp4 it seems to somewhat deliberately move the person out of the way to make way for the landscape
[18:18:29] <Robomot> video/mp4 (5.1 MB)
[18:18:43] <Obormot\Arcturus> catern, gwern: The analogy is indeed mis-aimed, because baseball is, like, the most boring sport ever (of well-known sports, anyhow), with the most arbitrary bullshit and finicky crap...
[18:18:53] <nshepperd2> (because it was prompted with a landscape artwork)
[18:19:10] <RiversHaveWings> Can't wait until we have a WikiArt SG3
[18:19:28] <nshepperd2> eheh~
[18:19:59] <gwern> will that work? the no-aliasing stuff didn't seem like it'd address the general stylegan weakness
[18:20:15] <RiversHaveWings> The WikiArt SG2 was good
[18:20:28] <RiversHaveWings> Though apparently pbaylies used some tricks to train it
[18:20:40] <RiversHaveWings> Like top-k training and manually blending a bunch of good checkpoints
[18:21:15] <nshepperd2> painful
[18:21:25] <catern> Obormot\Arcturus: perhaps that makes it even better-aimed because the analogy is to agile development
[18:21:30] <RiversHaveWings> (Manually blending checkpoints actually helps SG2 a lot)
[18:21:58] <RiversHaveWings> (We actually managed to salvage a run we thought had gone badly by blending like the 10 most recent G_ema checkpoints.)
[18:22:16] <Obormot\Arcturus> catern: Yes, but that's not intended, right
[18:22:34] <Obormot\Arcturus> catern: Like, Jeffries's point is "actually agile is awesome, by analogy to baseball which is also awesome"
[18:22:37] <catern> yes but it's funny
[18:24:04] <Obormot\Arcturus> Honestly, I just can't take Ron Jeffries even a little bit seriously after the sudoku thing
[18:25:01] <mst> the what
[18:25:16] <Obormot\Arcturus> What! You haven't read about this??
[18:25:20] <Obormot\Arcturus> It was amazing
[18:25:37] <Obormot\Arcturus> Peter Norvig and Ron Jeffries decided to both write a sudoku solving program
[18:26:03] <Obormot\Arcturus> Norvig just, like, wrote it, in C or something, in the straightforward correct way etc.
[18:26:18] <Obormot\Arcturus> Jeffries fucked around with "test driven development" for like 7 blog posts before giving up
[18:26:31] <Obormot\Arcturus> Because he just did not have the first idea wtf he was doing
[18:26:38] <Obormot\Arcturus> Or how to write a sudoku solver
[18:27:06] <Obormot\Arcturus> http://ravimohan.blogspot.com/2007/04/learning-from-sudoku-solvers.html
[18:27:07] <Robomot> One Man Hacking: Learning From Sudoku Solvers (Ron Jeffries attempts to create a sudoku solver - here , here , here , here  and here . (You really ought to read these articles. They are u...)
[18:28:04] *** Quits: _inky (~inky_@37.252.67.70) (Ping timeout: 252 seconds)
[18:28:48] <Obormot\Arcturus> (It was Python, not C, that Norvig used, I was misremembering)
[18:33:44] <rsaarelm> Yes, that thing was awesome.
[18:37:21] <two2thehead> kuudes, s0ph1a feep : "North Korea: Kim Jong-un vows to build 'invincible military'"
[18:37:42] <two2thehead> They've been doing that for thirty years. Lord Porky needs to learn about diminishing returns :-/
[18:38:39] *** Joins: srhm (~srhm@user/srhm)
[18:42:42] <feepbot> <gwern> uploads https://www.gwern.net/docs/psychology/2021-serota.pdf
[18:43:45] *** Quits: srhm (~srhm@user/srhm) (Read error: Connection reset by peer)
[18:45:16] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[18:46:33] *** Joins: _inky (~inky_@46.241.132.21)
[18:47:42] <feepbot> <gwern> uploads https://www.gwern.net/docs/psychology/2014-levine.pdf
[18:48:05] *** Joins: srhm (~srhm@user/srhm)
[18:49:39] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 250 seconds)
[18:52:42] <feepbot> <gwern> https://www.magicleap.com/en-us/news/news/magic-leap-raises-usd500-million-in-funding what
[18:52:43] <feepbot> Magic Leap
[18:56:03] <Obormot\Arcturus> ... Magic Leap is not dead? How
[18:58:30] <mst> hubble trouble VC bubble
[19:03:31] <feepbot> <gwern> 'In our experiments we show that DKS enables SGD training of residual networks without normalization layers on Imagenet and CIFAR-10 classification tasks at speeds comparable to standard ResNetV2 and Wide-ResNet models, with only a small decrease in generalization performance. And when using K-FAC as the optimizer, we achieve similar results for networks without skip
[19:03:31] <feepbot> connections. Our results apply for a large variety of activation functions, including those which traditionally perform very badly, such as the logistic sigmoid. In addition to DKS, we contribute a detailed analysis of skip connections, normalization layers, special activation functions like RELU and SELU, and various initialization schemes, explaining their effectiveness as
[19:03:31] <feepbot> alternative (and ultimately incomplete) ways of "shaping" the network's initialization-time kernel.' https://arxiv.org/abs/2110.01765 initializations are pretty darn important, despite their widespread neglect
[19:03:36] <feepbot> [2110.01765] Rapid training of deep neural networks without skip connections or normalization layers using Deep Kernel Shaping (Using an extended and formalized version of the Q/C map analysis of Poole et)
[19:08:31] <feepbot> <gwern> https://twitter.com/mstrakastrak/status/1447660588771917827
[19:08:32] <|dbotdan> Michael Straka (@mstrakastrak, 2021-10-11 20:29): ‘The most surprising thing to me after working with cryptography for 3+ years is how many published proofs/definitions are broken in a non-trivial sense, that people seem to just gloss over. It’s kind of amazing the field works so well in practice’
[19:11:44] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[19:13:32] <feepbot> <gwern> https://www.biorxiv.org/content/10.1101/2021.10.11.463990v1 high-dimensional spaces amirite
[19:13:34] <feepbot> The structure of genotype-phenotype maps makes fitness landscapes navigable | bioRxiv (Fitness landscapes are often described in terms of 'peaks' and 'valleys', implying an intuitive low-dimensional landscape of the kind encountered in everyday experience. The space of genotypes, however, is extrem [snip])
[19:15:13] *** Quits: srhm (~srhm@user/srhm) (Ping timeout: 250 seconds)
[19:18:33] <feepbot> <gwern> https://twitter.com/marypcbuk/status/1447941255653208073
[19:18:36] <|dbotdan> Scary Mary Branscombe (@marypcbuk, 2021-10-12 15:04): ‘Inspur is one of those companies you've never heard of that have huge presence in cloud; they're one of the top 3 server vendors globally do Intel reference OCP designs, this is one of their 2019 AI compute setups used by Baidu & their 32-GPU setup (JBOG)  | ’ Images:
[19:18:36] <|dbotdan> https://birdsite.xanny.family/pic/media%2FFBge5d_XEAgqjns.jpg%3Fname%3Dorig (description: graphical user interface; confidence: 0.73) | https://birdsite.xanny.family/pic/media%2FFBge5baXoAojXHh.jpg%3Fname%3Dorig
[19:18:54] *** Joins: srhm (~srhm@user/srhm)
[19:23:37] <feepbot> <gwern> https://twitter.com/mark_riedl/status/1447626597381574657 why does no one ever seem to notice that almost every time riedl tweets about large language models, he's wrong, on often basic facts, like claiming that storing GPT-3 model weights is insuperable difficult?
[19:23:38] <|dbotdan> Mark Loki Variant Riedl (@mark_riedl, 2021-10-11 18:14): ‘The thing that confuses me about the Megatron-Turing model is this: why did Microsoft dump $1Billion into OpenAI for exclusive access to GPT3 when it could (and did) make something just as good (if not better)?’
[19:25:02] <Obormot\Arcturus> https://scp-wiki.wikidot.com/scp-4774 ... this is one of the weirdest link hover styles I've seen
[19:25:18] <Obormot\Arcturus> (scroll down a bit, "ontological anomaly" is the first link in the text)
[19:30:19] <feepbot> <gwern> https://www.reddit.com/r/SpiceandWolf/comments/q6ndhu/custom_figure_commission_turned_out_beautiful/ wow
[19:30:20] <feepbot> Custom Figure Commission - turned out beautiful. :') : SpiceandWolf (0 votes and 7 comments so far on Reddit)
[19:33:04] <Obormot\Arcturus> https://scp-wiki.wikidot.com/scp-4500 ... ok, I wasn't sure if I liked this one until I got to "Pi Upsilon Theta"
[19:34:33] <galambo__> hi. did someone here play disco elysium? I wanted to ask you something
[19:35:13] * shawwwn whines while he heads to the bathroom for the 13th time over the past few days
[19:35:52] <galambo__> shawwwn, going to the bathroom 13 times in a few days isnt actually that frequent
[19:36:06] <shawwwn> Number two
[19:36:20] <shawwwn> It’s starting to burn
[19:36:27] <kuudes> oh, also remember to drink fluids
[19:36:50] <kuudes> milk is good if you are not lactose intolerant, otherwise some juice or something
[19:37:07] <kuudes> galambo__, he has diarrhea
[19:37:18] <shawwwn> His words not mine!
[19:37:30] <shawwwn> But I think it’s accurate
[19:37:41] <galambo__> I hope you get better soon
[19:38:28] <shawwwn> Hehe, thank you, but this is definitely “minor annoyance” side of the scale
[19:38:43] <shawwwn> dbohdan on the other hand.. come back :(
[19:40:39] <gwern> sounds like a body horror movie. _The 13th Visit_
[19:41:03] <gwern> "no, shawwwn, don't go in there alone!" "...you want to follow me into the bathroom? perv"
[19:41:38] <gwern> little did he realize he'd go the way of the occasional medieval king or aristocrat, as the privy proves pervious to perfidy
[19:46:39] <feepbot> <gwern> 'Rudin, a professor of computer science and engineering at Duke, is the second recipient of the new annual award, funded by the online education company Squirrel AI to recognize achievements in artificial intelligence in a manner comparable to top prizes in more traditional fields.' https://pratt.duke.edu/about/news/rudin-squirrel-award
[19:46:40] <feepbot> Duke Professor Wins $1 Million Artificial Intelligence Prize, A ‘New Nobel’ | Duke Pratt School of Engineering (Cynthia Rudin becomes second recipient of AAAI Squirrel AI Award for pioneering socially responsible AI)
[19:47:59] * shawwwn puts a tally mark for #14
[19:50:02] <RiversHaveWings> Wow, I got like 700 new Twitter followers since StyleGAN3's release.
[19:50:05] <shawwwn> Mainly I’m just impressed my body can produce so much … um… fuel
[19:50:11] <shawwwn> Oh shut up rhw
[19:50:22] <shawwwn> All you do is post pretty pictures
[19:50:33] <shawwwn> Just kidding. Congratulations
[19:50:36] *** Joins: Fusxfaranto (~Fusxfaran@cpe-75-85-179-208.san.res.rr.com)
[19:51:14] <shawwwn> “Wow, I made $3 million since the last time I checked my bank account!”
[19:51:58] <gwern> sadly, it's more like you need 3 million twitter followers to make $700
[19:52:26] <shawwwn> Nah, all my contract gigs came from Twitter
[19:52:45] <shawwwn> I’d be shocked if rhw didn’t have a shiteload of people DMing her trying to get her on
[19:53:16] <gwern> Obormot\Arcturus: weird. I uess it's supposed to make it 'moar sci fy!'
[19:55:35] <gwern> 'Requests to classify the potential inhabitants of SCP-4774 as an anomalous phenomenon in their own right have been denied, as no evidence for their existence (or lack thereof) has been or will be found. Further information on the anomaly can be obtained by considering SCP-4774.' ok that's a cute memetic/antimemetic instance
[19:55:56] <Obormot\Arcturus> I didn't like it, tbh
[19:56:35] <Obormot\Arcturus> The concept is ok-ish but the whole "thinking about it gets you the following info" just seemed super lazy
[19:56:46] <Obormot\Arcturus> Hard to get more "tell instead of show" than that
[19:56:50] <gwern> seems in line with a lot of the other memes
[19:56:55] * Obormot\Arcturus shrug
[19:58:13] *** Quits: feep[work] (~mathis@217.64.163.97) (Ping timeout: 252 seconds)
[20:01:55] <feepbot> <gwern> 'Akihito was the first emperor to receive a conventional education, at Gakushuin, Japan’s grandest school; among his English tutors was Elizabeth Vining, an American Quaker, who nicknamed him ‘Jimmy’. ‘His interests in those days were almost entirely confined to fish,’ she wrote later, ‘and I felt they needed broadening.’ The influence of this American
[20:01:55] <feepbot> pacifist on the young prince was regarded resentfully by right-wing intellectuals; one of them would later complain that Akihito had contracted a spiritual and intellectual ‘fungus’ from his tutor.' https://www.lrb.co.uk/the-paper/v42/n06/richard-lloyd-parry/akihito-and-the-sorrows-of-japan I've mentioned this one before, but skeleton key to history etc
[20:01:56] <feepbot> Richard Lloyd Parry · Akihito and the Sorrows of Japan: The Anxious Emperor · LRB 7 March 2020 (Britain’s royal family is deplorable principally because it institutionalises the corrosive divisions of social class...)
[20:06:42] *** Joins: badsektor (~badsektor@user/badsektor)
[20:06:56] <feepbot> <gwern> 'Thirty-two times a year, dressed in the garb of a Shinto priest, he paid his respects at a shrine to his legendary ancestor, the sun goddess, Amaterasu. In the evenings there were official receptions and banquets. Last thing at night, the emperor and empress might watch a nature programme or a video. Thirteen years ago, when the information was shared with me, they did
[20:06:56] <feepbot> this on a VHS player – there was no DVD player in the palace, and no internet. The senior courtiers to whom I was speaking did not have work email accounts, or even computers on their desks. My communications with Makoto Watanabe, then the grand chamberlain, were by telephone through his secretary; one of his colleagues, a slightly younger man, had a personal email account that
[20:06:56] <feepbot> he could access at home. But the imperial couple were avid consumers of print, both Japanese newspapers and magazines, and, I was told, my own newspaper, the Times, which arrived at the palace by airmail several days late.'
[20:11:56] <feepbot> <gwern> 'On Sundays, in his later years, he relaxed by pursuing a new line of research, into the tanuki, or raccoon dogs, which inhabited the palace grounds. ‘The emperor collected their droppings every Sunday afternoon between January 2009 and December 2013,’ the Kyodo news agency reported, ‘and examined plant seeds contained in them through a microscope.’'
[20:19:33] <feepbot> <gwern> https://twitter.com/ShaiCarmi/status/1447819023752728581 /eyeroll
[20:19:37] <|dbotdan> Shai Carmi (@ShaiCarmi, 2021-10-12 06:58): ‘In contrast, when selecting the lowest PRS embryo, risk reduction can be substantial -- up to 40-50% for common diseases. These results are based on mathematical theory (the liability threshold model) and simulations. | 3/12’ Images: https://nitter.eu/pic/media%2FFBevulTVgAEfGSo.jpg%3Fname%3Dorig (description: chart, scatter chart; confidence: 1.00) |
[20:19:37] <|dbotdan> https://nitter.eu/pic/media%2FFBevutpVQAQ7Wme.png%3Fname%3Dorig
[20:22:18] <feep> home!
[20:25:57] <shawwwn> feep: weekend over
[20:27:54] <mst> for us, it was just tuesday
[20:28:44] <feep> shawwwn: I am aware
[20:29:23] <shawwwn> Just reminding you
[20:32:03] <gwern> don't worry, somewhere it's always the weekend! [aid scurries up with note, gesticulates at various points and draws lines] "what? oh... I see. I retract my prior statement."
[20:34:33] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[20:34:47] *** Joins: SDr7 (~SDr@li1189-192.members.linode.com)
[20:35:03] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[20:35:29] *** Quits: SDr (~SDr@user/sdr) (Ping timeout: 264 seconds)
[20:35:37] *** Quits: two2thehead (~user@124.195.202.105) (Ping timeout: 252 seconds)
[20:37:04] <feepbot> <gwern> https://arxiv.org/abs/2110.04686 another brax/TPU paper
[20:37:05] <feepbot> [2110.04686] Braxlines: Fast and Interactive Toolkit for RL-driven Behavior Engineering beyond Reward Maximization (The goal of continuous control is to synthesize desired behaviors. In)
[20:39:28] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[20:40:05] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[20:40:12] <shawwwn> BRAX!!
[20:43:02] <shawwwn> Today’s theme https://youtu.be/pt8VYOfr8To
[20:43:13] <feepbot> Britney Spears - Work B**ch (Official Music Video) - YouTube (From the album "Britney Jean". Download now on iTunes:http://smarturl.it/britneyjean?Iqid=yt Black Dog Films/Little MinxDirector: Ben MorExecutive Producer: ...)
[20:44:50] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 260 seconds)
[20:49:45] *** Joins: two2thehead (~user@124.195.202.105)
[20:52:54] *** Quits: badsektor (~badsektor@user/badsektor) (Quit: Leaving)
[20:54:06] <feepbot> <gwern> https://www.nytimes.com/2021/10/12/health/aspirin-heart-attack-stroke.html
[20:54:06] <feepbot> Aspirin Use to Prevent 1st Heart Attack or Stroke Should Be Curtailed, U.S. Panel Says - The New York Times (Adults at high risk for cardiovascular disease may face serious side effects if they start a daily regimen of low-dose aspirin.)
[20:54:32] <Robomot> [Less Wrong [frontpage]] EDT with updating double counts by paulfchristiano - https://www.greaterwrong.com/posts/m3DiiBiXApN3kQMyM/edt-with-updating-double-counts
[20:54:38] <Robomot> [Less Wrong [frontpage]] Quantifying Risk by dpandey - https://www.greaterwrong.com/posts/EygijHwCXsnLnusQ7/quantifying-risk
[20:59:39] <feepbot> <gwern> https://www.nytimes.com/2021/10/10/opinion/instagram-facebook-mental-health-study.html
[20:59:40] <feepbot> Opinion | Does Instagram Harm Girls? No One Actually Knows. - The New York Times (The findings of psychological research are inconclusive.)
[21:01:23] *** Quits: _inky (~inky_@46.241.132.21) (Ping timeout: 250 seconds)
[21:03:32] <Robomot> [Less Wrong [frontpage]] Book Review:  Feeling Great by David Burns by Fei - https://www.greaterwrong.com/posts/QXuspfvLnMJoXrsDG/book-review-feeling-great-by-david-burns-1
[21:06:22] <Robomot> [Less Wrong [frontpage]] Building Blocks of Politics: An Overview of Selectorate Theory by Yoav Ravid - https://www.greaterwrong.com/posts/N6jeLwEzGpE45ucuS/building-blocks-of-politics-an-overview-of-selectorate
[21:11:23] <feepbot> <gwern> https://whyevolutionistrue.com/2021/10/09/the-art-institute-of-chicago-fires-all-122-of-its-unpaid-and-volunteer-docents-because-they-arent-sufficiently-diverse/ wonder where they'll divert the money for the replacements from
[21:11:25] <feepbot> The Art Institute of Chicago fires all 122 of its (unpaid and volunteer) docents because they aren’t sufficiently “diverse” – Why Evolution Is True (This is a story that, for obvious reasons, has gotten almost no airplay in Chicago, and none nationally, with no reporting in the major media. [snip])
[21:12:21] <shawwwn> I like how the lede assumes it’s impossible for the workers not to be “not sufficiently diverse”
[21:16:38] <shawwwn> RiversHaveWings: I guess all I meant earlier is “I’ve been wondering if you really want to gain so many followers so quickly just by posting videos and pictures”. Because it seems to attract a lot of antagonistic people.
[21:16:51] <RiversHaveWings> oh?
[21:17:04] <shawwwn> It’s probably just ptsd talking, but I watched my friend citnaj implode from something similar
[21:17:15] <shawwwn> Miss him every day
[21:17:18] <RiversHaveWings> oh
[21:17:35] <RiversHaveWings> well, the $20k or so we've made from selling NFTs after I got popular on Twitter helps. ^^;;
[21:17:40] <shawwwn> But if you’re happy then keep doing it! It’s really none of my business. Yeah
[21:17:47] <gwern> images are too easy to understand. need to post more equations and arxiv links
[21:18:07] <RiversHaveWings> gwern: i save those for discord mostly ^^;
[21:18:11] <kuudes> grats RiversHaveWings :)
[21:18:15] <shawwwn> Just uh, watch out if you ever start ranting about Trump takeovers and such
[21:18:20] <gwern> there's an art to finding your audience... that's part of the reason I like adding memes and anime jokes to my articles. it helps cut down the readers
[21:18:23] <shawwwn> Since that’s what citnaj did shortly before seppuku
[21:18:54] <gwern> (eliezer, I realized somewhere around 2010, is especially good at this in repelling the readers you *don't* want)
[21:19:17] <kuudes> indeed
[21:22:52] * shawwwn writes an epic story about RiversHaveWings not being able to resist the temptation of joining NFT circles
[21:25:40] <shawwwn> One NFT to generate them all, one NFT to find them, one tweet to bring them all, and in the blockchain bind them
[21:25:44] <kuudes> ooh https://www.sydney.edu.au/news-opinion/news/2021/10/12/strange-radiowaves-galactic-centre-askap-j173608-2-321635.html
[21:25:44] <Robomot> Strange radio waves emerge from direction of the galactic centre - The University of Sydney (A student at the University of Sydney has discovered strange radio signals emerging from deep inside the Milky Way. They fit no understood pattern of variable radio source and could suggest a new class of stellar object.)
[21:26:37] <saturn2> https://palladiummag.com/2021/10/11/the-triumph-and-terror-of-wang-huning/
[21:26:37] <Robomot> The Triumph and Terror of Wang Huning – Palladium (One man’s thought has become pivotal in China’s new political and cultural crackdowns. That man is not Xi Jinping.)
[21:31:22] <gwern> 'Moreover, he says that the “American spirit is facing serious challenges” from new ideational competitors. Reflecting on the universities he visited and quoting approvingly from Allan Bloom’s The Closing of the American Mind, he notes a growing tension between Enlightenment liberal rationalism and a “younger generation [that] is ignorant of traditional Western values” and actively...
[21:31:28] <gwern> ...rejects its cultural inheritance. “If the value system collapses,” he wonders, “how can the social system be sustained?”'
[21:33:02] <gwern> 'But even those Chinese youth who could afford to have kids have found they enjoy a new lifestyle: the coveted DINK (“Double Income, No Kids”) life, in which well-educated young couples (married or not) spend all that extra cash on themselves. As one thoroughly liberated 27-year-old man with a vasectomy once explained to The New York Times: “For our generation, children aren’t a...
[21:33:08] <gwern> ...necessity…Now we can live without any burdens. So why not invest our spiritual and economic resources on our own lives?”'
[21:36:02] *** Quits: topdownjimmy (~topdownji@user/topdownjimmy) (Remote host closed the connection)
[21:37:01] *** Joins: topdownjimmy (~topdownji@user/topdownjimmy)
[21:38:10] <feepbot> <gwern> 'While the stylized maps above do a great job of highlighting WDW’s many attractions, they generally downplay an important fact. Much of the land owned by Disney is still undeveloped, and there is a lot of space between the various parks. Much of this space is earmarked as conservation areas, and only some of the remaining land is actually suitable for development.
[21:38:10] <feepbot> Despite the sheer size of the property occupied by WDW, space for expansion grows increasingly scarce with each new development. The stylized maps also downplay the size of WDW’s parking lots, which are extensive. The Magic Kingdom parking lot, for example, is actually larger than the theme park itself.'
[21:38:10] <feepbot> https://www.visualcapitalist.com/50-year-evolution-of-walt-disney-world-in-maps/
[21:38:11] <feepbot> The 50-Year Evolution of Walt Disney World in Maps (Historical maps highlight the Magic Kingdom's dramatic transformation from swampland to the biggest theme park in the world.)
[21:39:23] <shawwwn> Gwern, what are you even posting nowadays
[21:39:32] <gwern> disney faxx
[21:39:35] <shawwwn> You’d think you’d post something relatable
[21:39:45] <gwern> that's very relatable. what, you've never been?
[21:39:52] <shawwwn> Wanna go? :)
[21:39:53] <gwern> surely you've been in giant parking lots in your life
[21:40:01] <shawwwn> Let’s go!
[21:40:12] * shawwwn takes gwern to Disney world
[21:40:24] <gwern> the problem is that given the whole labor thing, I expect this right now is one of the worst times to go to disney in decades
[21:40:32] <gwern> and also wrong time of year
[21:41:13] *** Quits: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net) (Quit: Going offline, see ya!)
[21:41:28] <gwern> I've been twice. once, we went during off-peak when school was in session. fantastic. another time we went in winter but when school was out. the lines were so long I began to wish I never went
[21:41:58] <gwern> october is still pretty close to summer
[21:46:58] <feepbot> <gwern> https://www.latimes.com/california/story/2021-10-09/california-will-require-large-retailers-to-provide-gender-neutral-toy-sections
[21:46:59] <feepbot> California moves toward gender neutral retail under new law - Los Angeles Times (The new law, which takes effect in 2024, says that retail stores with 500 or more employees must sell some toys and child-care products outside of areas specifically labeled by gender. )
[21:49:49] <ivan> https://www.youtube.com/watch?v=adPXDTvADD0
[21:49:50] <Robomot> Levi's Wokes - SNL - YouTube (Introducing Wokes, sizeless, style-neutral, gender non-conforming denim for a generation that defies labels.#SNL #SNLPremiere #SNL43Subscribe to SNL: https:/...)
[21:53:53] *** Joins: GvP (~GvP@ip70-162-85-176.ph.ph.cox.net)
[21:54:52] <feepbot> <gwern> https://www.inquiremore.com/p/culture-not-racism-explains-asian needs mor order statistics
[21:54:52] <feepbot> Culture — Not Racism — Explains Asian American Educational Success - by Zaid Jilani - I N Q U I R E (The failure to admit what is plainly obvious is driving unnecessary school wars.)
[21:59:52] <feepbot> <gwern> https://kill-the-newsletter.com/alternates/s66jh7h612uye1uk.html
[21:59:53] <feepbot> Conservatism in science
[22:04:53] <feepbot> <gwern> https://twitter.com/obra/status/887701051557552129 the baby shark of disney
[22:04:54] <|dbotdan> Jesse Vincent (@obra, 2017-07-19 15:49): ‘I always felt like "It's a small world" was a ride for babies. I did not, however, expect my baby to go absolutely ape for the entire ride.’
[22:09:55] <feepbot> <gwern> https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3131087
[22:09:55] <feepbot> Why So Serious?: Survey Trolls and Misinformation by Jesse Lopez, D. Sunshine Hillygus :: SSRN (Following the 2016 Presidential Election, there has been growing concern with the prevalence of fake news stories and political rumors; and the consequences thi)
[22:13:45] *** Joins: _inky (~inky_@141.136.76.213)
[22:13:46] <rmmh> gwern: oh nice ACX is writing about how climate change shouldn't stop you from having kids
[22:18:48] <feepbot> <gwern> https://twitter.com/gponcin/status/1447948308907913218 huh
[22:18:48] <|dbotdan> Guillaume Poncin (@gponcin, 2021-10-12 15:32): ‘We’re starting a new crypto team at @Stripe. I’m hiring engineers and designers to build the future of Web3 payments: https://stripe.com/jobs/search?q=crypto. ’ Watch video: https://nitter.mailstation.de/gponcin/status/1447948308907913218
[22:23:50] <feepbot> <gwern> 'Top PL papers are also not nearly as impactful. Just, there's a really consistent quality bar at POPL or PLDI, so I know what having a POPL or PLDI paper means Well, I guess they make less money. They have won a lot of Turing Awards, though' https://twitter.com/TaliaRinger/status/1447777973680152578 and in the end, isn't legible status like turing awards what *really*
[22:23:50] <feepbot> counts?
[22:23:51] <|dbotdan> Talia Ringer (@TaliaRinger, 2021-10-12 04:15): ‘One thing that confuses me about machine learning work is that there are a lot of papers that make it into top conferences that really do nothing of note or are outright wrong, but then there are also revolutionary papers that change everything’
[22:27:06] <rmmh> instead of buying a tesla, just performatively spend $10k/yr paying someone to sequester 10 tons of carbon
[22:34:18] <rmmh> https://www.nature.com/articles/d41586-021-02758-2
[22:34:19] <Robomot> COVID lesson: trust the public with hard truths (When governments assume that people will panic, that exacerbates the pandemic.)
[22:34:21] <shawwwn> gwern: let’s go to Japan~~ I’m not joking this time
[22:34:29] <shawwwn> So come get your bags packed, and we’ll be just fine
[22:34:40] <shawwwn> We’ll both wear kimonos no shoes on our feet
[22:34:52] <shawwwn> Let’s go to Japan, Japan it with me~~
[22:35:01] <gwern> shawwwn: we're banned from it: https://www.japan.travel/en/coronavirus/
[22:35:02] <Robomot> Coronavirus (COVID-19) advisory information | Travel Japan | JNTO (None)
[22:35:37] <gwern> someone must've told'em about the furry porn gans
[22:36:38] <kuudes> big in japan? wait
[22:36:41] <Betawolf> only fairtrade artisinal furry porn
[22:36:59] <gwern> owow why's that japan bulge in cases so big growl
[22:37:56] <shawwwn> gwern: https://youtu.be/rUv26JhEA58
[22:38:07] <feepbot> Hetalia - Japan: Japan It! - YouTube (Once again, a video for gaia. But this one is for my friend's profile.Song: Japan It!Artist: LudoI OWN NOTHING.)
[22:40:58] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[22:43:52] <gwern> https://en.wikipedia.org/wiki/Ludo_(band) one of us, one of us
[22:43:52] <Robomot> Ludo (band) - Wikipedia (Ludo is an alternative rock band from St. Louis, Missouri. The band consists of lead vocalist/guitarist Andrew Volpe, lead guitarist/back up vocalist Tim Ferrell, moog/synth and back up vocalist Tim Convy, and drummer/back up vocalist Matt Palermo. Although on hiatus since 2012, Ludo announced on their Facebook page on July 16, 2018, that they would be performing in St. Louis in October. …)
[22:45:28] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 252 seconds)
[23:37:49] <shawwwn> has there really been no activity for almost an hour in here?
[23:37:55] <shawwwn> no one leaving, joining, or saying anything
[23:37:58] <shawwwn> gwern slacker
[23:42:31] <linear> the peace and quiet is a feature, not a bug 
[23:43:11] <milanandreew> pax gwerna
[23:52:21] <kuudes> https://www.nature.com/articles/d41586-021-02669-2
[23:52:21] <Robomot> Real-world data show that filters clean COVID-causing virus from air (An inexpensive type of portable filter efficiently screened SARS-CoV-2 and other disease-causing organisms from hospital air.)
[23:52:32] <kuudes> air scrubbers should be put to every place.
[23:54:34] <kuudes> https://www.medrxiv.org/content/10.1101/2021.09.16.21263684v1
[23:54:36] <Robomot> The removal of airborne SARS-CoV-2 and other microbial bioaerosols by air filtration on COVID-19 surge units | medRxiv (Background The COVID-19 pandemic has overwhelmed the respiratory isolation capacity in hospitals; many wards lacking high-frequency air changes have been repurposed for managing patients infected with SARS-CoV-2 requiring either standard or intensive care. …)
