[00:11:08] *** Joins: jamiejackson (~jamiejack@131.106.140.145)
[00:21:47] *** Joins: Hokedli (~lasliedv@gateway/tor-sasl/hokedli)
[00:35:17] <last1> but doesn't the mysqldump ensure the same character set is used ?
[00:35:59] <last1> I see at the top of the mysqldump: /*!40101 SET NAMES utf8 */;
[00:42:05] <lopid> yes, it should contain all the same settings
[00:42:51] <lopid> your dump does contain the DROP TABLE statements, right?
[00:50:22] *** Quits: mav`rik (~unknown@ec2-54-171-126-99.eu-west-1.compute.amazonaws.com) (Quit: leaving)
[00:50:54] <Xgc> That's the thing.  If the character set and column definitions are the same, there must be a bug somewhere causing your problem... or someone mishandled the dump file.
[00:51:43] <Xgc> I thought I saw a difference in the character set in your description above.  But I didn't read the entire log that carefully.
[00:52:23] *** Joins: Naktibalda (~Naktibald@88.135.22.17)
[00:57:34] <Xgc> Your char_length comment above seems like a problem.
[00:58:22] *** Quits: Hokedli (~lasliedv@gateway/tor-sasl/hokedli) (Remote host closed the connection)
[00:58:38] *** Joins: Hokedli (~lasliedv@gateway/tor-sasl/hokedli)
[01:00:23] <Xgc> I wonder if there are other similar problems in that table.  SELECT COUNT(*) FROM tbl WHERE char_length(name) > 90);
[01:00:37] <Xgc> s/)//
[01:01:34] <Xgc> For those that are found, is there some special character in the string.
[01:01:41] *** Quits: shibboleth (~shibbolet@user/shibboleth) (Quit: shibboleth)
[01:05:10] *** Quits: PTNapivoski (~PTNapivos@179.189.133.33) (Quit: Leaving)
[01:13:10] <last1> yes, there are accents in that string
[01:13:15] <last1> that's from the live table
[01:14:04] <last1> for example, in this particular table, the limit for first_name is 50
[01:16:00] <last1> char_length reports 51 characters, and it contains this word: Vanđelic
[01:38:07] *** Quits: Naktibalda (~Naktibald@88.135.22.17) (Quit: If at first you don't succeed, skydiving is not for you.)
[01:43:07] *** Quits: kevr (~kevr@user/kevr) (Remote host closed the connection)
[01:43:25] *** Joins: kevr (~kevr@user/kevr)
[01:47:18] <dontyouloveshort> by accident i created a grant with @% in the username itself, trying to remove that with: revoke all privileges on mydb for 'myuser@%'@'%';     does not work
[01:47:26] <dontyouloveshort> how to remove it?
[01:53:36] *** Quits: jamiejackson (~jamiejack@131.106.140.145) (Quit: Connection closed)
[01:58:32] *** Joins: snedd (~snedd@86.14.114.137)
[02:05:01] <litheum> !t us doesn't work
[02:05:01] <ubiquity_bot> #mysql: Doesn't work is not a helpful statement. Was there an error? Unexpected results? Does it sit on the couch all day eating all your cheetos and ignoring the classifieds? Be specific!
[02:05:13] *** Quits: snedd (~snedd@86.14.114.137) (Quit: Leaving)
[02:08:53] <lopid> try %%
[02:35:37] <lopid> or \%
[02:44:46] <Xgc> dontyouloveshort: There's always the direct approach.
[02:56:52] *** Joins: ferdna (~ferdna@user/ferdna)
[03:28:04] *** Quits: Hokedli (~lasliedv@gateway/tor-sasl/hokedli) (Quit: Konversation terminated!)
[03:32:15] <passage> dontyouloveshort: this is day 2, right? select user, host from mysql.user; <-- pastebin that output
[03:33:56] <passage> dontyouloveshort: then do something like: select user, host from mysql.user where user like 'substr%';
[03:34:21] <passage> dontyouloveshort: when you find the bad user, use the DROP USER syntax
[03:34:51] <passage> dontyouloveshort: then create the user you actually want
[03:34:58] <dontyouloveshort> will do that tomorrow, thanks
[03:35:23] <passage> yw
[03:35:30] <dontyouloveshort> have to go to bad now...works is waiting
[03:36:06] *** Quits: dontyouloveshort (~dontyoulo@p200300d21f0ddb01f0fb05d462c23efc.dip0.t-ipconnect.de) (Quit: Leaving)
[04:03:55] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[05:26:52] *** Quits: Dra|n (~Shaaf@user/Dran/x-3752239) (Quit: ZNC 1.8.2 - https://znc.in)
[05:40:01] *** Quits: Terlisimo (~Terlisimo@outofband.ozna.net) (Quit: Connection reset by beer)
[05:43:45] *** Joins: Terlisimo (~Terlisimo@outofband.ozna.net)
[06:17:35] <skyfall> My client returns an error with this simple CTE query on line 4, but I couldn't figure out the issue here: https://bpa.st/SCVQ Am I doing something incorrect on line 4?
[06:19:16] <thumbs> skyfall: you can't terminate the CTE with ;
[06:19:28] <thumbs> skyfall: also, do not use GROUP BY 1, 2
[06:19:49] <thumbs> skyfall: golly, stop grouping by column positions. Use the column/alias name
[06:19:51] <skyfall> Even if I remove `;` and write `GROUP BY customerid, shipcountry` it still returns the error.'
[06:20:28] <skyfall> *that didn't solve the error though.
[06:22:02] <thumbs> skyfall: https://dbfiddle.uk/?rdbms=mysql_8.0&fiddle=f5cd29c5fa37faf44c28e6a910f0a2f1
[06:22:07] <thumbs> skyfall: works fine
[06:22:58] <thumbs> skyfall: stop using column positions in GROUP BY clauses. Everywhere.
[06:24:06] <skyfall> Hmm, seems like there was a typo when I entered column names inside CTE query. But why doesn't column positions work in CTEs?
[06:24:35] <thumbs> skyfall: you should have stopped using column positions 16 years ago
[06:25:01] <thumbs> skyfall: newer versions of MySQL will follow standards.
[06:25:45] <thumbs> skyfall: using column positions with GROUP BY was always a hack, since MySQL 3.x
[06:28:46] <thumbs> skyfall: you are likely using old bad practices like a comma in the FROM clause
[06:29:11] <skyfall> Ah, I see. My instructor was using column positions, so I used it.
[06:29:25] <thumbs> your instructor is 16 years out of date
[07:03:28] *** Joins: makoto2600 (~makoto260@94.86-180-91.adsl-dyn.isp.belgacom.be)
[07:04:49] *** Quits: makoto2600 (~makoto260@94.86-180-91.adsl-dyn.isp.belgacom.be) (Client Quit)
[08:08:55] *** Quits: Avago_Broadqual (~Avago_Bro@74-194-130-160.bcstcmtk03.res.dyn.suddenlink.net) (Quit: The Lounge - https://thelounge.chat)
[08:12:24] *** Quits: Vacuity (~Vacuity@user/vovo) (Ping timeout: 252 seconds)
[08:12:39] *** Joins: Avago_Broadqual (~Avago_Bro@74-194-130-160.bcstcmtk03.res.dyn.suddenlink.net)
[08:14:12] *** Joins: Vacuity (~Vacuity@user/vovo)
[08:31:53] *** Joins: Heartsbane (tsharpe@shell.xmission.com)
[08:58:16] *** Quits: Avago_Broadqual (~Avago_Bro@74-194-130-160.bcstcmtk03.res.dyn.suddenlink.net) (Quit: The Lounge - https://thelounge.chat)
[09:01:46] *** Joins: Avago_Broadqual (~Avago_Bro@74-194-130-160.bcstcmtk03.res.dyn.suddenlink.net)
[09:04:15] *** Joins: doug16k (~doug16k@172-97-188-4.cpe.distributel.net)
[09:04:32] <doug16k> what does "actual time=0.091..8.247" mean?
[09:05:21] <doug16k> dot dot?
[09:05:30] <doug16k> what's that?
[09:05:55] <doug16k> it's from explain analyze select
[09:07:47] <Xgc> doug16k: Time to get the first row to the time to get all rows.
[09:08:34] <Xgc> doug16k: Described here: https://dev.mysql.com/blog-archive/mysql-explain-analyze/
[09:08:50] <doug16k> thanks
[09:13:26] <doug16k> I have a table that has a unique index (a,b,c,d) and d is the id (AI PK). if I do select a,b,c,max(d) ... group by a,b,c then it scans an awful lot. shouldn't it optimize that?
[09:14:49] <Xgc> doug16k: Does it scan the index?
[09:15:25] <Xgc> doug16k: When you are reading the entire index, a scan is common.
[09:16:16] <doug16k> not sure how to interpret. does this answer that? https://gist.githubusercontent.com/doug65536/61e15a8508ff78ac4d1b1f7065326df0/raw/8558cdad0683dec0b7288f94acbd7e2c787a4091/gistfile1.txt
[09:16:54] <doug16k> it could just upper bound where (a,b,c) prefix and bump back one. is that too much to expect?
[09:17:25] <Xgc> doug16k: using index_for_group_by .... But the table scan seems odd, if what you said above is true.
[09:17:56] <Xgc> doug16k: Best to dpaste.com the actual SQL and the CREATE TABLE statements.
[09:19:12] <Xgc> Maybe t is a derived table or CTE term.  That might make sense.
[09:19:57] <doug16k> the main query does the max, then a subquery does max where the id < outer query id, to get 2nd last
[09:20:06] <doug16k> the analyze seems to say that part is awesome, though, right?
[09:20:28] <Xgc> Sorry.  That's not the detail required to answer the question.  The scan is probably on the derived table, and that is fine.
[09:20:29] <doug16k> wait, not really eh
[09:20:48] <doug16k> ok
[09:21:06] <doug16k> yeah I'll work on showing more
[09:21:12] <Xgc> Hard to provide the best answer without detail.
[09:42:19] <doug16k> it's 3.4M records and about 140 groups, I hope I can make it not scan
[09:43:38] <doug16k> 2.3M match recordType="MeterValues" from the explain
[09:47:06] <doug16k> something is telling me to "help" it by manually doing max as subquery, alter the table and reverse that index direction, order by it desc, limit 1. sounds worse right?
[09:48:25] <doug16k> in a way that's closer to asking for that upper bound trick
[09:50:11] <doug16k> it would be lower bound on a,b,c prefix then
[10:01:46] *** Joins: gulzar (~gulzar@49.206.240.149)
[10:03:05] <doug16k> oh wow I found it. I neglected to make it have criteria on the "a" part of the index when testing it. now that it has the prefix properly, it's good: https://gist.github.com/doug65536/1ad059eee4e9ce3c010d1ba49dc959ab
[10:06:19] *** Quits: ferdna (~ferdna@user/ferdna) (Quit: Leaving)
[10:30:27] *** Joins: Naktibalda (~Naktibald@88.135.22.17)
[11:28:18] <gulzar> Hi . Using mysql.connector https://dev.mysql.com/doc/connector-python/en/connector-python-api-mysqlcursor-fetchall.html . I was getting 1292 error on fetching data with row having a hash as string in one of the column (varchar). Other rows having number as string gives no issue.  After lots of debugging. I reached here. Only when I do
[11:28:18] <gulzar> cursor.fetchall() or loop over the cursor the error 1292 comes up.  cursor.fetchone() gives no error.  empty dataset with fetchall() gives no error .The query, the table, the error backtrace all are mentioned here https://paste.debian.net/1235415 .  Any ideas what can be done?  The data is being fetched from  a view.
[11:59:04] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[12:20:10] *** Joins: palasso (~palasso@user/palasso)
[12:23:34] *** Quits: wyre (~wyre@user/wyre) (Quit: ZNC 1.8.2 - https://znc.in)
[12:25:54] *** Joins: wyre (~wyre@user/wyre)
[12:33:07] <gulzar> Found these warnings in db, looks like db contains them . https://paste.debian.net/1235422/   . 1024 row in set.
[12:35:49] <gulzar> seems my insert has some problems
[13:01:46] *** Joins: BravoSlo (BravoSlo@gateway/vpn/airvpn/bravoslo)
[13:06:20] <doug16k> gulzar, do you have automatic fetch warnings enabled? it screws up for me
[13:06:36] <doug16k> can't enable it imho
[13:07:11] <doug16k> I mean in your .connect call to create the connection
[13:07:33] <doug16k> and or the call that turns on always-fetch-warnings
[13:08:13] <doug16k> it seems like it works, then blows up if you do a multi query
[13:09:04] <Naktibalda> anyway, it shouldn't be producing those warnings. they mean that he is inserting strings to FLOAT or DOUBLE field
[13:09:51] <gulzar> doug16k I found that the view has one comparisio. one of the field is int and another is varchar. So probably for entries like '3024'=3024 there is no issue but 'aisdhjfjaksdnfler4534tef' = int  might be screwing up
[13:10:01] <gulzar> Naktibalda ^
[13:10:57] <gulzar> though, fetchone() is able to get the row, but fetchall() throws the error
[13:11:15] <gulzar> select on cli also works
[13:12:43] <doug16k> these screw up fetch for me: https://overiq.com/mysql-connector-python-101/exception-handling-in-connector-python/#handling-warnings
[13:13:20] <doug16k> is either on?
[13:13:53] <gulzar> doug16k have to check.
[13:14:19] *** Quits: rvalue (~rvalue@user/rvalue) (Remote host closed the connection)
[13:14:58] *** Joins: rvalue (~rvalue@user/rvalue)
[13:15:19] <gulzar> doug16k I am using django to connect. No manual connect call
[13:26:30] <Isotopp> I just experimented with Oracle MySQL Connector/Python
[13:27:05] <Isotopp> and I found that if I configure the connection with "use_pure" (using the pure python connector), I can print c._executed to get the statement that was sent to the database, even if that statement contains an error.
[13:27:26] <Isotopp> Using the Cython connector, c._execuuted is also updated, but only after the statement ran
[13:27:37] <Isotopp> and never if the statement raises an exception. that makes debug kind of hard.
[13:28:23] <doug16k> gulzar, get_warnings is a property on the connection
[13:28:31] <Isotopp> So if I had an update statement that raised a "double truncation" warning, I'd want to use connector/python with "use_pure" as a connection option, and then print(cursor._executed) to see the actual SQL string that was sent when the error happens
[13:28:42] <gulzar> doug16k tryingto figure out how to set it in django
[13:28:43] <doug16k> gulzar, look at the example warning lol https://dev.mysql.com/doc/connector-python/en/connector-python-api-mysqlconnection-get-warnings.html
[13:29:09] <doug16k> is yours that specific like 'a' thing?
[13:29:48] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Ping timeout: 240 seconds)
[13:32:05] <gulzar> doug16k : more like .     "aslkdfjoin1234ilj" = 3456       .  there is a where in the view, which is checkign for int vs varchar .   For varchar   1200 and string "1200"  the = will work (please correct me)  but for a proper varchar , int cannot be compared
[13:32:45] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[13:33:21] <Naktibalda> even worse, 3456 may match "3456sdf" and 0 will match any string starting with non-digit
[13:33:34] <Naktibalda> correct sollution would be to make the column types match
[13:34:36] <gulzar> found this in django log              raise errors.get_mysql_exception(*self._warnings[0][1:3])       . seems the warnings are True. doug16k
[13:34:47] <gulzar> need to turn it off
[13:35:17] <gulzar> Naktibalda Ah, yes. that also.
[13:35:46] <doug16k> is it okay if "asdfjkasdfadsf" is interpreted as 0 ?
[13:36:22] <doug16k> select cast("asdfasdf" as double) gave me 0
[13:38:55] <gulzar> doug16k , this column is present in two tables. one of this is int, another is hash. These are project ids.  So in one table one pipeline is updating as a string number "4371"  but in other table hash is being added for whatever reason.. The view is bringing the filtered data, some conditions, from both tables. All columns are matching except
[13:38:56] <gulzar> these two.
[13:39:21] <gulzar> doug16k can't make it 0 , as the view needs to compare the value with other table to fetch the rows
[13:39:49] <doug16k> hex hash?
[13:40:12] <doug16k> base64
[13:40:26] <gulzar> doug16k no idea which one. :(          will check, if hex or base64, will try to convert
[13:41:19] <gulzar> doug16k atleast now I know the issue , thanks to all of you
[13:41:56] <gulzar> first I need to find how to supress that raiseerrors.get_mysql_exception   in djagno
[13:42:18] <doug16k> try just setting that property of the connection to false really early
[13:42:29] <doug16k> I think?
[13:42:35] <doug16k> if it is hard to get at connect I mean
[13:43:39] <doug16k> anytime before the query is probably close enough
[13:43:41] <gulzar> trying different methods
[13:44:51] <gulzar> doug16k something like this https://paste.debian.net/1235430/ ?  . but not working .Have to figure it out.
[13:45:10] <gulzar> doug16k Isotopp  Naktibalda  Thank You
[13:45:33] <doug16k> connections["qcstats"].get_warnings = False
[13:45:53] <gulzar> tried that also
[13:45:55] <doug16k> probably before you create the cursor too to be max safe
[13:46:25] <doug16k> don't know if it affects the creation of the cursor at all
[13:49:00] <gulzar> doug16k found it, it needs to go in settings.py
[13:49:03] <gulzar> working. :)
[13:49:09] <doug16k> nice
[13:50:28] <gulzar> such simple things
[14:24:03] <Isotopp> i wrote the debug thing down in https://blog.koehntopp.info/2022/03/24/debugging-sql-in-python.html
[14:29:42] <gulzar> noted
[14:36:40] *** Quits: montywi (~monty_@83-245-178-47.elisa-laajakaista.fi) (Remote host closed the connection)
[14:54:17] *** Quits: wyre (~wyre@user/wyre) (Quit: ZNC 1.8.2 - https://znc.in)
[14:55:09] *** Joins: makani_kai23 (~makani_ka@gateway/vpn/pia/makanikai/x-36391196)
[14:55:31] *** Joins: wyre (~wyre@user/wyre)
[14:55:51] *** Quits: makani_kai2 (~makani_ka@gateway/vpn/pia/makanikai/x-36391196) (Ping timeout: 256 seconds)
[14:57:16] *** Joins: makani_kai2 (~makani_ka@gateway/vpn/pia/makanikai/x-36391196)
[15:00:08] *** Quits: makani_kai23 (~makani_ka@gateway/vpn/pia/makanikai/x-36391196) (Ping timeout: 272 seconds)
[15:16:00] *** Joins: alexises (~lameire@51.15.136.90)
[15:17:35] <alexises> hello, I have a quite dumb question. I have a pretty old db without any foreign key constraint and I will need to perform some deletion. How can I get the affected row of one query to use on the next one
[15:18:38] <Naktibalda> you could even delete related rows with a single statement by using joins
[15:18:44] *** jkavalik_ is now known as jkavalik
[15:19:14] <jkavalik> or do a select first, to get the PKs (maybe into a temp table) and use them for deletes
[15:19:21] <Naktibalda> DELETE table1, table2 FROM table1 JOIN table2 ON table1.x = table2.y WHERE table1.status = 'old'
[15:19:34] <alexises> hum definitively better
[15:22:26] <alexises> definively the join is the way to go here :)
[15:23:31] *** Joins: mav`rik (~unknown@ec2-54-171-126-99.eu-west-1.compute.amazonaws.com)
[15:27:33] <alexises> and another small one with insert, I will need to insert some entry and get the corresponding autoincrement key to do another insert
[15:28:52] <Naktibalda> !n alexises last_insert_id
[15:28:52] <ubiquity_bot> alexises: See https://dev.mysql.com/doc/refman/5.7/en/information-functions.html#function_last-insert-id
[15:33:22] *** Quits: regedit (uid150526@id-150526.uxbridge.irccloud.com) (Quit: Connection closed for inactivity)
[15:34:12] <alexises> could i get the list of inserted id and not only the first one ?
[15:37:40] <Naktibalda> no
[16:00:33] *** Quits: dslegends_ (~dslegends@user/dslegends) (Quit: ZNC 1.8.2 - https://znc.in)
[16:04:39] <obviyus> does UUID_SHORT() (being just a 64-bit integer) perform better than UUID() stored as BINARY(16)?
[16:05:57] *** Quits: gulzar (~gulzar@49.206.240.149) (Quit: gulzar)
[16:06:23] <obviyus> but AUTO_INCREMENT should still be faster, I imagine
[16:08:31] <obviyus> https://krow.livejournal.com/497839.html
[16:08:35] <obviyus> seems not
[16:33:24] *** Quits: Norkle (~norkle@admin.nasa-g0v.com) (Ping timeout: 240 seconds)
[16:53:45] <Isotopp> obviyus: no
[16:54:09] <Isotopp> define your performance requirement to be sure, but in general, if 16 by 8 byte key length matter that is a weird boundary condition
[16:54:24] <Isotopp> also, be sure to use uuid_to_bin() with the swap parameter set to true
[16:55:44] <Isotopp> the disadvantage of uuid() over auto_increment is 16 bytes instead of 4, but the advantage of uuid() over auto_increment is that you do not need primary key exhaustion monitoring
[16:56:07] <obviyus> interesting bit about the swap parameter Isotopp
[16:56:31] <obviyus> ah fair, the auto_increment will run out eventually
[16:56:45] <Isotopp> this applies to type 1 uuid, such as generated by mysql itself
[16:57:03] <Isotopp> java and other languages may or may not generate type 1, and if they are not type 1, it may be that they are not "sortable".
[16:57:32] <Isotopp> innodb profits a lot from the actual primary key value being strongly monotonically increasing. the swap parameter applied to type 1 uuid does this
[16:57:44] <Isotopp> java generated uuid may not be type 1, and may be completely random
[16:57:53] <Isotopp> in that case the performance will be abysmally bad.
[16:57:59] <Isotopp> discussion in https://blog.koehntopp.info/2021/04/06/mysql-and-uuids.html
[17:01:57] *** Joins: Norkle (~norkle@admin.nasa-g0v.com)
[17:03:12] <obviyus> understood, thank you Isotopp
[17:43:36] *** Joins: snedd (~snedd@86.14.114.137)
[17:46:31] *** Quits: snedd (~snedd@86.14.114.137) (Client Quit)
[18:00:31] *** Quits: mickey (~user@user/mickey) (Quit: mickey)
[18:06:16] *** Joins: regedit (uid150526@id-150526.uxbridge.irccloud.com)
[18:59:46] *** Parts: youmustrust (~nobody@ec2-18-182-239-10.ap-northeast-1.compute.amazonaws.com) ()
[19:04:52] *** Joins: jamiejackson (~jamiejack@131.106.140.145)
[19:17:46] *** Joins: Slartiba1t (~user@c-4dece655.217486-0-69706f6e6c79.bbcust.telenor.se)
[19:17:54] *** Quits: Slartibart (~user@c-4dece655.217486-0-69706f6e6c79.bbcust.telenor.se) (Ping timeout: 272 seconds)
[19:48:27] *** Joins: PTNapivoski (~PTNapivos@179.189.133.33)
[19:59:28] *** Quits: ueberall (ueberall_l@user/ueberall) (Quit: ZNC)
[20:01:54] *** Joins: ueberall (ueberall_l@user/ueberall)
[20:22:17] *** Joins: rackj (~rackj@c-73-193-19-25.hsd1.wa.comcast.net)
[20:33:09] *** Quits: rackj (~rackj@c-73-193-19-25.hsd1.wa.comcast.net) (Quit: Client closed)
[20:34:11] *** Quits: lamneth (~IceChat9@modemcable213.189-81-70.mc.videotron.ca) (Quit: The early bird may get the worm, but the second mouse gets the cheese)
[20:47:49] *** Quits: gde33 (~gde33@84-106-154-98.cable.dynamic.v4.ziggo.nl) (Ping timeout: 240 seconds)
[20:54:45] *** Joins: maroloccio (~marolocci@pousada3ja.mma.com.br)
[20:58:36] *** Quits: mthall_ (~quassel@mail.thalliman.com) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[21:00:48] *** Joins: mthall (~quassel@mail.thalliman.com)
[21:12:03] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Quit: Leaving)
[21:53:17] *** Joins: gde33 (~gde33@84-106-154-98.cable.dynamic.v4.ziggo.nl)
[22:55:24] <thumbs> /2/13
[23:00:25] *** Quits: BravoSlo (BravoSlo@gateway/vpn/airvpn/bravoslo) (Quit: Leaving)
[23:12:43] <lopid> divide by 2/13 error
[23:28:41] <sharpertool> I have a very important question for the very talented folks here...
[23:28:56] *** Quits: zoraj (~zoraj@vmi794994.contaboserver.net) (Read error: Connection reset by peer)
[23:29:10] <sharpertool> I'm helping the company I work for improve systems.. we upgraded from MySQL 5.0.. to 5.7. A huge step
[23:29:20] <sharpertool> Now, we are looking at converting MyISAM to InnoDB.
[23:29:45] <sharpertool> The main reason is to avoid table level locking, but the ability to have some referential integrity is nice also..
[23:30:25] <sharpertool> I have one concern, based on some docs I've read. This is, that moving to InnoDB could have issues with existing code that is not currently issuing 'commit' at the end of an insert/update/delete
[23:30:57] <sharpertool> I do not know how big of an issue that is.. or, what some of the easier solution are. One solution is to edit all of the code and add commits()... but, editing all of the code is non-trivial.
[23:31:27] <sharpertool> It would be nice to not have to do that, but, of course, only if there is a reasonable and robust alternate solution
[23:31:55] <PTNapivoski> sharpertool, https://dev.mysql.com/doc/refman/5.7/en/innodb-autocommit-commit-rollback.html
[23:33:07] *** Joins: zoraj (~zoraj@vmi794994.contaboserver.net)
[23:35:35] <sharpertool> So, there does not seem to be too much downside to autocommit. That was my concern
[23:40:34] *** Joins: shibboleth (~shibbolet@user/shibboleth)
