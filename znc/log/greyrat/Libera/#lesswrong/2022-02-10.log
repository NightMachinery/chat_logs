[00:04:31] <feepbot> <gwern> https://www.penny-arcade.com/comic/2022/02/09 'rated Adult'
[00:04:32] <Robomot> Penny Arcade - Comic - Age Range (Videogaming-related online strip by Mike Krahulik and Jerry Holkins. Includes news and commentary.)
[00:04:53] <quanticle> Also, re: switching from D-R, apparently what swung the gubernatorial election in Virginia was the fact that Democrats alienated the Asian-American vote wrt education. There are a lot of South Asians in Northern Virginia, because of government contractors and their associated IT jobs, and Terry McAuliffe talking about how he was going to improve Black enrollment at highly selective high schools
[00:04:54] <quanticle> (apparently the high-schools in that area are top-10 in the entire nation) did not go over well with a group of people who grew up with the notion of "Scheduled Castes/Scheduled Tribes" in their home country.
[00:05:36] <Obormot\Arcturus> gg
[00:05:49] <quanticle> Of course, the Republicans don't understand this either
[00:05:54] <quanticle> Because they're stupid too
[00:06:00] <quanticle> They think it's about "critical race theory"
[00:07:29] <quanticle> Which it is, in a way, but not in the way that the Republicans think it is. It's not about people being outraged that critical race theory concepts are being taught in the classroom, it's more about people being outraged about critical race theory being taught in the teacher's lounge
[00:07:59] <Betawolf> I mean, good, that's at least closer to the root of the problem.
[00:08:06] <Obormot\Arcturus> "There were other successes. Some of the Bitcoins went into yet another exchange, ‚ÄúVCE 7,‚Äù where Lichtenstein and Morgan each opened personal accounts and where Morgan opened an account for her business, which is called SalesFolk (‚Äúthe first company to specialize in cold email copywriting‚Äù)." https://salesfolk.com/
[00:08:07] <Robomot> SalesFolk
[00:08:43] <quanticle> I can't get over the fact that a dude doing money laundering is named Lichtenstein
[00:08:50] <quanticle> Like, c'mon feds
[00:09:34] <quanticle> He couldn't have been more obvious if he'd named himself "Cayman"
[00:12:09] <Betawolf> "My name is Cayman Panama Lichenstein, you taxed my father."
[00:12:09] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Read error: Connection reset by peer)
[00:12:46] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[00:13:11] <gwern> Betawolf: 'prepare to dun.'
[00:18:13] <feepbot> <gwern> 'But the last quarter of 2021 proved painful for the top 28. Only seven generated positive returns, with the worst performer, High-Flyer Quant, losing an average of more than 11% across its funds.' https://www.wsj.com/articles/chinas-quant-hedge-funds-stumble-after-breakneck-growth-11644402602?mod=hp_lead_pos3 that name seems kinda asking for it
[00:18:14] <Robomot> China‚Äôs Quant Hedge Funds Stumble After Breakneck Growth - WSJ (Data-driven Chinese hedge funds are becoming victims of their own success, after several years of eye-catching returns and surging inflows from investors.)
[00:21:20] <saturn2> Obormot\Arcturus: have you tried grainger?
[00:21:36] <Obormot\Arcturus> saturn2: I have not
[00:21:47] * Obormot\Arcturus looks
[00:21:56] <saturn2> grainger has everything (male words only)
[00:23:02] <Obormot\Arcturus> saturn2: Nope they only have narrow sheets, 6" or less
[00:23:05] <quanticle> We tried McMaster-Carr, but Grainger is also a good idea
[00:23:24] <quanticle> And yeah, McMaster-Carr had the same problem
[00:23:26] <saturn2> oh :(
[00:23:49] <quanticle> Turns out really thin stainless steel is something you order by the ton from Alibaba
[00:24:01] <rmmh> These people are charged with money-laundering conspiracy, but their real tragedy is that they allegedly did a lot of conspiring without a whole lot of _laundering_. They were allegedly billionaires in ill-gotten Bitcoin, and they couldn‚Äôt spend it.
[00:24:41] <quanticle> My impression is that they were busted the moment they tried to launder their ill-gotten Bitcoin, because the feds were watching their wallets
[00:25:57] <gwern> not the moment. look at the alphabay stuff. ab went down eons ago
[00:27:43] <Robomot> [Astral Codex Ten] So You Want To Run A Microgrants Program - https://astralcodexten.substack.com/p/so-you-want-to-run-a-microgrants
[00:29:34] <Obormot\Arcturus> Maybe I could use aluminum instead ... https://www.grainger.com/product/GRAINGER-APPROVED-Aluminum-786CV8
[00:29:35] <Robomot> GRAINGER APPROVED Aluminum, Sheet Stock, Thickness (Decimal) 0.016 in, Width and Length 24 in x 24 in - 786CV8|21563_24_24 - Grainger (Looking for Aluminum Sheet 6061? Find it at Grainger.com¬Æ. With over 1.6M products and 24/7 customer service we have supplies and solutions for every industry.)
[00:31:53] <Obormot\Arcturus> Hm. There's a Grainger store in Brooklyn... maybe I will just drive down there and see what they have
[00:33:26] <quanticle> gwern: x-posted from #-politics, this photo cries out for a caption: https://www.reuters.com/resizer/Ay8p0xoTRT6WjcDQryZzZPDGCuI=/1200x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/3MA6FAC5KVLVTDDYEBBOCYIW64.jpg
[00:33:26] <Robomot> image/jpeg (1200x823; 97 KB)
[00:33:50] <gwern> who's that?
[00:34:13] <rmmh> https://cloudfront-us-east-2.images.arcpublishing.com/reuters/3MA6FAC5KVLVTDDYEBBOCYIW64.jpg
[00:34:14] <Robomot> image/jpeg (4118x2824; 2.4 MB) - French President Emmanuel Macron attends a meeting with Russian President Vladimir Putin in Moscow, Russia February 7, 2022. Sputnik/Kremlin via REUTERS
[00:34:30] <rmmh> wait what
[00:34:41] <quanticle> Yeah, Macron's in Russia holding talks
[00:34:45] <gwern> oh, macron. he looks... a good deal more hawkish than I recalled
[00:35:12] <gwern> quanticle: hm. how about: "Somewhere... It's Miller time. But *where*"
[00:35:33] <quanticle> Well, I was going to with, "Shit, I know I should have gone to the bathroom ahead of time."
[00:35:38] <rmmh> how did robomot get a title from that
[00:36:49] <gwern> that's a good question. both of those links are just JPGs
[00:37:37] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[00:38:11] <quanticle> Does Robomot use the Googlebot UA?
[00:40:34] <quanticle> Obormot\Arcturus IRL: https://i.imgur.com/BqTseYp.png (Look at the computer)
[00:40:35] <Robomot> image/png (1000x562; 565 KB)
[00:41:30] <gwern> this dude is so good he doesn't even need the monitor to be on. no wonder they let him dress as a clown
[00:41:56] <gwern> (for a 10-100x programmer, these days, hell, he can come dressed in full furry if he wants to)
[00:42:24] <otoburb> The JPGs have IPTC meta data embedded, which includes a caption description. 
[00:42:29] <quanticle> https://cloudfront-us-east-2.images.arcpublishing.com/reuters/6CONHWQE5RIJRC7CFZCYDH7VMM.jpg This is the full image
[00:42:30] <Robomot> image/jpeg (5328x3376; 4.9 MB) - Russian President Vladimir Putin attends a meeting with French President Emmanuel Macron in Moscow, Russia February 7, 2022. Sputnik/Kremlin via REUTERS
[00:43:11] <quanticle> Seems really awkward
[00:43:23] <Obormot\Arcturus> quanticle: no, no googlebot
[00:43:55] <gwern> otoburb: huh. I piped it into exiftool just on the off chance that it had some sort of metadata... and exiftool did not tell me that
[00:43:59] <Obormot\Arcturus> rmmh, gwern: Robomot inspects EXIF metadata
[00:44:08] <kuudes> ooo
[00:44:10] <kuudes> nice!
[00:44:21] <otoburb> gwern: Your tool is lying to you. 
[00:44:22] <gwern> although it also reported it was text so I guess I missed up the pipe or something
[00:44:33] <otoburb> NSO'd? 
[00:44:37] <rmmh> Obormot\Arcturus: I don't see any exif data
[00:44:45] <Obormot\Arcturus> Apple's image APIs are superior to your unix tools :)
[00:44:47] <gwern> ah, --head
[00:44:52] <gwern> yeah, I messed up
[00:44:54] <gwern> 'Envelope Record Version : 2 Destination : OUSTPM,OCATPM,RTRFLN,OUSWDM,RCOM_WORLD File Format : JPEG File Interchange (JFIF) File Version : 1 Service Identifier : RTRPIX Envelope Number : 51743493 Product ID : PIX Envelope Priority : 4 Date Sent : 2022:02:07 Time Sent : 17:42:39+00:00 Coded Character Set : UTF8 Application Record Version : 2 Object Name : UKRAINE-CRISIS-MACRON-PUTIN Edit...
[00:45:00] <gwern> ...Status : ORIGINAL Urgency : 4 Category : I Supplemental Categories : POL DIP Fixture Identifier : LYNXMPEI160YB Keywords : –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å Special Instructions : 3TP Date Created : 2022:02:07 Time Created : 17:42:39+00:00 Originating Program : FotostationAWS Program Version : 7.0 By-line : SPUTNIK City : MOSCOW Country-Primary Location Code : RUS Country-Primary Location Name :...
[00:45:02] <rmmh> oh it's not exif
[00:45:03] <rmmh> its
[00:45:05] <rmmh> it's xmp
[00:45:06] <gwern> ...RUSSIA Original Transmission Reference : PM004 Headline : Russian President Vladimir Putin meets with French President Emmanuel Macron in Moscow Credit : via REUTERS Source : X02440 Caption-Abstract : French President Emmanuel Macron attends a meeting with Russian President Vladimir Putin in Moscow, Russia February 7, 2022. Sputnik/Kremlin via REUTERS Writer-Editor : ANI Language...
[00:45:08] <kuudes> soon: "<Robomot> image/jpeg (1980x1200; 1 MB) Gwern Branwen with his relatives"
[00:45:12] <gwern> ...Identifier : en'
[00:45:19] <Obormot\Arcturus> EXIF, XMP, whatever. It's all the same
[00:45:23] <gwern> well, I was using 'exiftool -All -', and I think most exif is xmp anyway
[00:45:31] <gwern> at least , it never seems to make a difference to exiftool
[00:45:57] <rmmh> Iptc actually
[00:46:15] <kuudes> also putin uses a long table for physical distancing + air cleaners on both ends
[00:46:15] <Obormot\Arcturus> Also same
[00:46:33] <gwern> kuudes: I see he watched _dune_ too
[00:46:41] <kuudes> oh?
[00:46:58] * kuudes has not watched dune and misses the reference
[00:47:07] <gwern> (see, it's funny because the harkonens are based on russian invaders to the caucasus)
[00:47:17] <Obormot\Arcturus> In ObjC you just do ... `CIImage *image = [CIImage imageWithData:data];` and then `image.properties` has whatever metadata is there
[00:47:23] <gwern> (in addition to in-universe being from the USSR originally)
[00:47:34] <quanticle> Wait, really?
[00:47:37] <quanticle> Where is that explained?
[00:48:00] <gwern> quanticle: Dune LPs. herbert explains that the atreides descend from US cold war programs, and the harkonnens are their opposite New Soviet Men
[00:48:10] <quanticle> Huh
[00:48:23] <gwern> might also be in the dictionary of dune or something, but the LPs is the source I remember
[00:48:43] <Robomot> [Less Wrong [frontpage]] My investment protects you. Your investment protects me. by Nicole Dieker - https://www.greaterwrong.com/posts/aWs97cAAfato22vQ8/my-investment-protects-you-your-investment-protects-me
[00:49:16] * gwern transcribed them years and years back while visiting the SF public library which unusually had copies, even though they had nothing to play them on
[00:49:23] <quanticle> Okay, so the cold war allegory was not just a product of my own imagination
[00:49:45] <gwern> nope, quite intentional, and also a bit cynical. the atreides had little more interest in democracy than the harkonnens did, after all
[00:49:57] <quanticle> Dune really was about the US and the Soviets fighting over the Middle East
[00:50:01] <quanticle> IN SPAAAAAAAACE
[00:50:04] *** Joins: galambo__ (galambo@user/galambo)
[00:50:06] <saturn2> Obormot\Arcturus: be aware that they won't really let you just "shop" at a grainger location
[00:50:56] <Obormot\Arcturus> saturn2: oh...
[00:51:35] <kuudes> afganistan actually, quanticle
[00:51:53] <saturn2> they'll reluctantly sell stuff to individuals but only if you have all you i's dotted and know the exact part number you want
[00:52:25] <quanticle> Eh, not really. It's well established that CHOAM is an allegory for OPEC, and the concept of a precious commodity, vital for transportation, buried under a desert... does it really need to be stated?
[00:52:51] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 245 seconds)
[00:53:53] <quanticle> It's like a hybrid, I guess. The Fremen are the Afghan and Central Asian nomadic peoples
[00:53:59] <quanticle> But the location is 100% Saudi Arabia
[00:54:00] <feep> hey so remember when I talked here about transition probabilities for an hour
[00:54:07] <gwern> no
[00:54:18] <feep> well anyway https://feep.life/~feep/cache2/232087669_1920x1080_530841600.small.png new generator~
[00:54:19] <Robomot> image/png (1920x1080; 75 KB)
[00:54:40] <gwern> so which lobe is AGP?
[00:54:45] <quanticle> When feep says "transition probabilities" I literally can't tell if he's talking about chaos theory, transistors or eggs
[00:54:49] <feep> hee
[00:55:52] <kuudes> feep, so the previous matrix talk was related to those wallpapers you make?
[00:56:13] <feep> yep! the wallpapers now being generated use that random state transition approach
[00:56:28] <kuudes> are they prettier or do they have other uses?
[00:56:35] <feep> no other use :D
[00:56:41] <feep> might be prettier! I can't tell yet
[00:57:04] <quanticle> Is the tool that makes these written in Neat?
[00:57:08] <feep> going to bed tho, I just wanted to finish that
[00:57:10] <quanticle> And if not, why are you a bad programmer?
[00:57:12] <feep> quanticle: yep! hang on lemme commit
[00:57:17] <quanticle> Cool
[00:58:00] <feep> quanticle: https://github.com/Neat-Lang/neat/blob/master/demos/fflame.nt
[00:58:02] <Robomot> neat/fflame.nt at master ¬∑ Neat-Lang/neat ¬∑ GitHub
[00:58:14] <quanticle> Filipepe: Get well soon! https://www.reuters.com/world/europe/spains-king-felipe-tests-positive-covid-19-2022-02-09/ 
[00:58:15] <Robomot> Spain's King Felipe tests positive for COVID-19 | Reuters (Spain's King Felipe tested positive for COVID-19 earlier on Wednesday after displaying mild symptoms overnight and will remain in isolation for seven days, the Royal Palace said in a statement.)
[00:58:30] <feep> quanticle: the transition stuff starts at line 231
[00:58:44] <feep> quanticle: have another one! https://feep.life/~feep/cache2/985835528_1024x768_201326592.small.png
[00:58:47] <Robomot> image/png (1024x768; 424 KB)
[00:59:51] <feep> it definitely *looks* like it has more visual potential.
[01:00:11] <quanticle> Cool
[01:00:40] <kuudes> is there a mask breathing how-to? my friend has problems with mask use
[01:02:21] <feep> quanticle: https://feep.life/~feep/cache2/470962365_1024x768_201326592.small.png isn't it pretty
[01:02:24] <Robomot> image/png (1024x768; 680 KB)
[01:02:25] <feep> anyway, going to bed~
[01:03:38] <feep> aw shit, it just outright generated a svastika
[01:03:46] <quanticle> AWKWARD
[01:03:51] <feep> https://feep.life/~feep/cache2/750284870_1024x768_786432.small.png I am not sure if I'm legally allowed to host this 
[01:03:52] <Robomot> image/png (1024x768; 97 KB)
[01:04:00] <quanticle> Cancel Neat
[01:04:09] <quanticle> For being an inherently white supremacist language
[01:04:21] <Ralith> feep stop going to bed late
[01:04:30] <feep> dude this thing generates so many stars of david, I feel this is fair
[01:04:52] <feep> Ralith: sorry! had to finish up, be in bed soon
[01:04:59] <feep> well, I say "had"
[01:05:37] <quanticle> kuudes: re: breathing, tell your friend to get one of these: https://smile.amazon.com/dp/B00MVKTAHQ and git gud
[01:05:41] <quanticle> At breathing
[01:05:41] <Robomot> Amazon.com: HealthAndYoga(TM) Deep Breathing Exerciser - Breath Exercise Measurement System : Health & Household (Buy HealthAndYoga(TM) Deep Breathing Exerciser - Breath Exercise Measurement System on Amazon.com ‚úì FREE SHIPPING on qualified orders)
[01:06:27] <kuudes> well, sure. but like, there has got to be a guide somewhere on internet, and one of the guides should be not-insane, right?
[01:08:42] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:2c8a:e08a:3ded:de79) (Quit: Client closed)
[01:10:25] <quanticle> kuudes: I don't know, other than, breathe more forcefully. And that's the point of the exerciser - it's really designed for people recovering from injuries and whatnot who need to exercise their breathing muscles in order to restore lung function
[01:10:36] <quanticle> My dad has one, from when got out of surgery
[01:10:41] <quanticle> *when he
[01:12:18] <gwern> Obormot\Arcturus: synced backlinks/dark mode changes. seems to work
[01:12:40] <Obormot\Arcturus> \o/
[01:13:04] <kuudes> thanks quanticle
[01:13:39] <Obormot\Arcturus> In that case tonight/tomorrow I'll work on correcting the final couple of backlinks-popup recursion bugs
[01:15:14] <gwern> neat. in the mean time, I will be trying out this arxiv change. I've implemented it but don't know if it actually works
[01:17:49] <quanticle> Ralith: Are you feep's mom or something? feep can go to bed whenever he damn well pleases
[01:18:17] <feep> you are missing a context here
[01:18:26] <feep> which is that we usually game in the morning
[01:18:42] <Ralith> also feep consistently gets 5-6 hours of sleep a night and that's not good
[01:18:51] <feep> which is why I need to stop refreshing the fractal generator
[01:18:58] <feep> fucking lootbox
[01:19:03] <gwern> quanticle: he could be feep's mom. that sounds pretty sexy. with a big crib and diapers
[01:19:13] <Ralith> o_o
[01:19:20] <gwern> there, made you imagine it
[01:19:30] * feep boops gwern with the horny stick
[01:19:35] <Ralith> please keep your weird kinks out of the chat
[01:20:07] <gwern> in my defense, ever since a real old timer told me working a SF con about babyplay and how many hotel rooms would need cribs sent up during past SF cons, I've never been quite the same
[01:20:50] <quanticle> gwern: Given that I'm a mod of #lw-fandom, you're going to have to much better than that to overcome my defenses
[01:20:54] <feep> https://feep.life/~feep/cache2/193522986_1920x1080_530841600.small.png last link.
[01:21:03] <Robomot> image/png (1920x1080; 1.2 MB)
[01:21:04] <gwern> I'll always be reading some Chalker and suddenly the imp of the perverse will pop up and say, 'you know, Chalker went to SF cons. the oldtimer could've been talking about *him*'
[01:21:28] <quanticle> Who's Chalker?
[01:22:11] <gwern> jack l. chalker. my dad had a lot of his SF. mid-brow SF pulp
[01:22:27] <gwern> https://en.wikipedia.org/wiki/Jack_L._Chalker
[01:22:27] <Robomot> Jack L. Chalker - Wikipedia (Jack Laurence Chalker (December 17, 1944 ‚Äì February 11, 2005) was an American science fiction author. Chalker was also a Baltimore City Schools history teacher in Maryland for 12 years, retiring during 1978 to write full-time. He also was a member of the Washington Science Fiction Association and was involved in the founding of the Baltimore Science Fiction Society.)
[01:22:37] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[01:23:16] <quanticle> Ah, okay. Mid-century middlebrow SF, a.k.a. stuff that's damn near *impossible* to find in print
[01:23:17] <gwern> most famous for _Well World_ but I remember his _Rings of the Master_ well, if only because it is the most badass use of "12 Days of Christmas" in SF ever. or elsewhere, really
[01:24:04] <quanticle> Because it's not public domain, but, at the same time, there's nowhere near enough demand for it to justify additional licensed print runs
[01:24:16] <gwern> orphan, yeah. but probably a lot of it is in the baen library
[01:27:14] <gwern> (but, that's why we scan books & upload to libgen when we come across such problems)
[01:32:15] <feepbot> <gwern> https://www.bloomberg.com/news/features/2022-02-09/there-are-now-1-000-unicorn-private-company-startups-worth-1-billion-or-more?sref=1kJVNqnU I wonder if that's exactly 1000 unicorns in that image
[01:32:16] <Robomot> There Are Now 1,000 Unicorn Private Company Startups Worth $1 Billion or More - Bloomberg (Almost a decade after the term ‚Äúunicorn‚Äù was coined to describe a rare breed of private company, about two new companies are joining the herd daily.)
[01:37:17] <feepbot> <gwern> https://twitter.com/dmvaldman/status/1491289708256661505
[01:37:18] <Robomot> David Valdman (@dmvaldman): "`Dead man walking by Laurie Lipton`" (https://nitter.namazso.eu/pic/media%2FFLIfucxVEAAY0yu.png)
[01:42:20] <feepbot> <gwern> https://gimletmedia.com/shows/reply-all/n8hw3d  https://twitter.com/AlanMCole/status/1491456863803944960
[01:42:20] <Robomot> #149 30-50 Feral Hogs | Reply All (A legit question from a rural American.)
[01:42:21] <Robomot> Alan Cole (@AlanMCole): "Has anyone so thoroughly defeated the mob of people making fun of him as the "feral hogs" guy? / At this point he doesn't even actively rub it in, he just passively retweets evidence of the feral hog problem as it's pointed out to him." (http://n.hyperborea.cloud/pic/media%2FFLK33RzWQAcLCME.png)
[01:44:36] <quanticle> gwern: Oh, I was vaguely disappointed. I was hoping he'd retweet the news about the feral hog problem in California
[01:44:47] <saturn2> do people on twitter doubt the existence of feral hogs?
[01:45:10] <quanticle> They doubt that 30-50 of them will run onto your property while your children play
[01:46:13] <saturn2> oh
[01:46:27] <saturn2> well, that does sound like a funny image
[01:48:05] <quanticle> "On the day of Productboard‚Äôs internal announcement, Dune Analytics, a Norwegian crypto analytics startup, gained its horn by raising a cheeky $69,420,000."
[01:48:07] <quanticle> I'm surprised I didn't hear about this from Matt Levine.
[01:48:07] <saturn2> https://nitter.42l.fr/CultySmother/status/1491524340927668224 it me
[01:48:08] <Robomot> Culty (@CultySmother): "I'm as much of a urban bubble-dweller as anyone and I never understood why people thought he was making it up." | 42l - nitter (I'm as much of a urban bubble-dweller as anyone and I never understood why people thought he was making it up.)
[01:53:11] <feepbot> <gwern> 'So for instance, if you have a gang of feral hogs terrorizing your land, and you set up a box trap ‚Äì if one of them falls for the trap, the rest will now teach each other how to avoid it. They‚Äôve also been caught using rocks to test whether electric fences are turned on. They‚Äôre smart.'
[01:53:51] <quanticle> So what you're saying is that the only solution is realy claymore mines
[01:56:16] <saturn2> you need an automated machine gun turret that continually shoots everywhere in the yard except where the children are
[01:56:18] <nshepperd> https://www.twitter.com/ShakedDown/status/1491526545525166090 if they do they should record a video, sounds interesting
[01:56:19] <Robomot> Fake Mario (@ShakedDown): "I'm as much on team feral hogs guy as the next man, but I am curious - it's definitely a real problem afaict, but do people actually regularly deal with it by spraying the hogs with an automatic rifle (while their kids are around)?"
[01:56:49] <nshepperd> seems like mostly the ones on youtube are sniping them at night
[01:57:38] <Betawolf> the best move is to tame one pack of hogs to guard against the others
[01:57:49] <quanticle> >automatic rifle
[01:57:52] <quanticle> Already dismissed
[01:58:03] <Betawolf> https://en.wikipedia.org/wiki/Hogs_of_War
[01:58:04] <Robomot> Hogs of War - Wikipedia (Hogs of War is a turn-based tactics video game developed by Infogrames Sheffield House and published by Infogrames, released for the PlayStation in Europe on 25 August 2000, and North America on 29 September 2000,[1] and later for Microsoft Windows in Europe only on 3 November 2000. In 2003 the publishing rights were taken up by ZOO Digital, who subsequently re-released the game again ‚Ä¶)
[01:58:11] <quanticle> Dude doesn't realize that machine guns are far too rare and expensive to use for shooting hogs
[01:58:37] <saturn2> WILLIE: It was probably mid-morning. It was a spring day and my wife, she liked the kids to be outside and play, and I would too, and I‚Äôm sure she‚Äôs the one that let them out that morning to go outside. And we had a little playground set up in the backyard. And uh, she just, she just yells out, ‚ÄúThere‚Äôs pigs! All in the yard! Everywhere!‚Äù
[01:58:39] <saturn2> PJ: Did she sound scared?
[01:58:41] <saturn2> WILLIE: She did. You could hear it in her voice
[01:58:43] <saturn2> PJ: Willie told me the reason his wife was scared is these weren‚Äôt like, barnyard pigs, they were feral hogs. They‚Äôre more like wild boars ‚Äì some have big sharp tusks, they‚Äôre much bigger, with longer legs. They move really fast. And that moment, there was a bunch of them swarming around his 4 and 5 year old. It was scary.
[01:58:45] <saturn2> WILLIE: I went to my safe. I got my gun. I got my shells. Went right out on the back porch.
[01:58:47] <saturn2> PJ: And how were the hogs acting? Were they like moving quickly? Were they‚Äì
[01:58:49] <saturn2> WILLIE: Well, yeah. You know, they‚Äôre running all through the yard from the back of my yard all the way to the front. And then I pick out, of course, the ones that look the meanest. The one with the tusk. These are two or three hundred pound hogs. I‚Äôm not letting them near my family. 
[01:58:51] <saturn2> PJ: Yeah‚Äì
[01:58:53] <saturn2> WILLIE: So, just for lack of a better term, I just start laying them down. 
[01:58:55] <saturn2> PJ: Willie shoots three with his hunting rifle, and the rest of the hogs run off. Afterwards, he was just bewildered. He‚Äôd never seen anything like this before.So he started looking for answers. 
[01:59:08] <quanticle> Nice
[02:00:21] <Betawolf> America has taken the trope of the rare ancient magical sword that is the only thing that could defeat the evil and made it real.
[02:00:52] <nshepperd> quanticle: i thought the original thing was about automatic rifles
[02:01:14] <gwern> but there are machine guns all over rural hick america! I'm sure I read it in the NYT or on NPR
[02:02:26] <quanticle> nshepperd: No the original thing was about *assault* rifles
[02:02:31] <quanticle> i.e. scary-looking black guns
[02:03:32] <quanticle> Dude was asking, if you take away my AR-15 or w/e how am I going to deal with feral hogs
[02:03:33] <nshepperd> oh i see
[02:04:09] <nshepperd> and those are semi auto
[02:04:17] <quanticle> Yeah
[02:04:41] <saturn2> just wrap your AR-15 with adhesive vinyl woodgrain, then it's not an assault weapon anymore
[02:04:50] <quanticle> Which, if you're going to put down three or four hogs in quick succession, yeah, I can see the value of semi-auto and a deep magazine.
[02:05:26] <quanticle> saturn2: Yeah, but that doesn't do you much good if people decide that semi-auto in general should be banned.
[02:05:50] <Betawolf> the compromise to save america is you can buy any armaments you want but they're all only available in rainbow flag patterns 
[02:05:53] <quanticle> At that point it's like, git gud. Channel your inner Finn
[02:07:27] <gwern> as tom of finland would say, there's a little finn in many of us
[02:07:40] <quanticle> Found Betawolf's loadout: https://imgur.com/a/6bB29
[02:07:40] <Robomot> Hello Kitty - Album on Imgur (Find, rate and share the best memes and images. Discover the magic of the Internet at Imgur.)
[02:07:56] <quanticle> ggreer: ^ 
[02:09:01] <nshepperd> https://youtu.be/ANKgTjUD69U according to CNN, AR-15s are effective at stopping ruinous wild hogs
[02:09:02] <Robomot> AR-15 rifles to protect crops from hogs - YouTube (00:05:38) (Victor Blackwell introduces the owner of Hog Swat and shows what some call a practical use for the AR-15 rifle.)
[02:09:22] <gwern> 'Also, this is Chococat. I was originally under the impression Hello Kitty owned him, which seemed kind of racist. But it turns out they are friends and on equal footing. Thank god.'
[02:09:47] <gwern> I don't think it's legal for a cat to own cats. only humans.
[02:10:03] <quanticle> 1. Hello Kitty is not a cat 2. Hello Kitty owns a cat
[02:10:11] <quanticle> Charmy Kitty
[02:13:02] <quanticle> Also related: https://external-preview.redd.it/uycbvfP1ejk4pqdO49bxnLimriiAP2rfzecN9ph9-Fg.png?width=640&crop=smart&auto=webp&s=03358d5f5aba0aee0fff888029ce25dd6567e4af
[02:13:03] <Robomot> image/webp (307 KB)
[02:13:05] <Betawolf> I was also gonna suggest all rural communities maintain regimental discipline to keep up the firing rate, but then I got nerdsniped by this lephrechaun-hunt thread: https://www.greatwarforum.org/topic/105402-the-machine-guns-of-mons/
[02:13:06] <Robomot> The "machine guns" of Mons ? - The Western Front - The Great War (1914-1918) Forum (I'm looking for the original source(s) of a common legend of the battle at Mons in August 1914: that the British troops fired their rifles so rapidly that the Germans thought that they were being fired upon with many machine guns.I encountered this in Tuchman's The Guns of August. Her source appe...)
[02:18:07] <feepbot> <gwern> https://twitter.com/t_homas_mach/status/1488438867397124096 /reeeee
[02:18:08] <Robomot> Thomas Mach (@t_homas_mach): "Another example of a website that does not care about licenses. Most arXiv papers are published under the arXiv license, which does not allow for this kind of "service"."
[02:21:58] <quanticle> Lol: https://nitter.net/dginev/status/1488493998155210756#m
[02:21:58] <Robomot> Deyan Ginev (@dginev): "The seven paper ids I could find with you as co-author are now permanently removed from the ar5iv site, never to return again. / The broader licensing issues remains of course. Just showing some good will." | nitter [Deyan Ginev @dginev Feb 1 Replying to @t_homas_mach The seven paper ids I could find with you as co-author are now permanently removed from the ar5iv site, never to return ‚Ä¶]
[02:26:59] <feepbot> <gwern> 'There were only two times the network ever did anything. One of them was [‚ÄúMarge Be Not Proud‚Äù] with Lawrence Tierney where he says, ‚ÄúIf I wanted smoke blown up my ass, I‚Äôd be at home with a pack of cigarettes and a short length of hose.‚Äù We refused to remove it. So they took the master videotape and removed it for the initial broadcast. [Producer James L.]
[02:27:00] <feepbot> Brooks read them the Riot Act. The other time was in ‚ÄúSideshow Bob‚Äôs Last Gleaming‚Äù when we had [21st Century Fox founder] Rupert Murdoch in prison with Sideshow Bob. Someone at Fox worried and went to Murdoch. And he said, ‚ÄúI would be honored to be in prison on The Simpsons.‚Äù'
[02:27:00] <feepbot> https://www.hollywoodreporter.com/tv/tv-features/simpsons-itchy-scratchy-poochie-show-25-1235081217/
[02:27:00] <Robomot> The Simpsons Oral History: The Itchy & Scratchy & Poochie Show at 25 ‚Äì The Hollywood Reporter (The Simpsons episode The Itchy & Scratchy & Poochie Show turns 25 with cast and crew looking back and sharing new insight into the classic.)
[02:29:49] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[02:31:13] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[02:32:00] <feepbot> <gwern> 'Moore:  I might get in trouble for this, but the card that says ‚ÄúPoochie died on the way back to his home planet‚Äù was actually just my writing on a piece of paper that I sent overseas and had them animate. There was no design approval, but I could defend it since it was in the spirit of what the script was asking for. I guess they were happy with it.     Oakley:  Oh,
[02:32:00] <feepbot> wow. I had no idea!'
[02:37:00] <feepbot> <gwern> 'One person, in the process of explaining why he needed a grant, sort of vaguely confessed to a pretty serious crime. I don‚Äôt have enough specifics that I feel like I can alert police, and it‚Äôs in a different country where I don‚Äôt speak the language. Still, this is a deeper grantwriting failure than I imagined possible.' awkward
[02:37:35] <nshepperd> https://www.twitter.com/dginev/status/1488511551988543497 if you didn't want people to see "private" footnotes maybe don't publish them on the internet in the latex source
[02:37:37] <Robomot> Deyan Ginev (@dginev): "I'll even take the site down if it's a bigger pain than benefit. / I've already heard of problems caused by only using the first version (author lists) and reputation harm from bad conversions (private footnotes going public). / This is all my fault - and you have my apologies."
[02:38:18] <nshepperd> maybe they deserve their reputation to be harmed
[02:40:45] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[02:42:14] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[02:42:32] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:2c8a:e08a:3ded:de79)
[02:43:18] <feepbot> <gwern> '(8) You will suffer heartbreak I‚Äôd been on a couple of dates with someone a month or two before the grants program. Then in the chaos of sorting through applications, I forgot to follow up. Halfway through the grant pile, I found an application from my date. It was pretty good, but I felt like it would be too much of a conflict of interest. I sent them an email:
[02:43:18] <feepbot> ‚ÄúSorry, I don‚Äôt feel like I can evaluate this since we‚Äôre dating‚Äù. The email back: ‚ÄúI don‚Äôt consider us to still be dating‚Äù. This remains the most stone-cold rejection I have ever gotten.'
[02:44:46] <quanticle> lmao
[02:49:46] <feepbot> <gwern> 'Here's a really interesting article by Tucker Max about why he got out of venture capital. https://www.tuckermax.com/why-i-stopped-angel-investing-and-you-should-never-start/ Short version: it takes way more time than you'd think. To be a successful angel investor, you pretty much have to know your founders' businesses as well as they do themselves. "Even though angel
[02:49:46] <feepbot> investing looks like this casual, easy and fun activity, make no mistake about it, if you want to avoid losing your shirt, you spend a LOT of time on it: finding deals, vetting companies you‚Äôre interested in, and then once you invest, working with them like hell to make them succeed. Just one example: I invested in a custom dog toy company, PrideBites, and have probably spent at
[02:49:46] <feepbot> least 500 hours over two years learning about the dog toy space, the dog retail space, and the complexities of Chinese manufacturing and logistics (so I can better advise them). Not to mention, another 500+ hours I‚Äôve spent with the team helping them through all the hundreds of issues that come up. [...] That‚Äôs almost a full time job‚Äìand it‚Äôs only ONE company. " (yeah,
[02:49:47] <Robomot> Why I Stopped Angel Investing (And You Should Never Start) - Tucker Max (I started angel investing almost by accident, which sounds strange to say. Who ‚Äúaccidentally‚Äù invests tens of thousands of dollars into highly speculative ventures? Well, I did. A friend introduced me to Clayton Christopher who was raising money for his new liquor company Deep Eddy. Their first product, a sweet tea vodka, was amazing and‚Ä¶)
[02:49:51] <feepbot> that's the same Tucker Max who used to write stories about getting loaded on Everclear, fucking midget strippers, and having diarrhea in hotel lobbies. He's had some life changes.)'
[02:50:03] <feepbot> Why I Stopped Angel Investing (And You Should Never Start) - Tucker Max (I started angel investing almost by accident, which sounds strange to say. Who "accidentally‚Äù invests tens of thousands of dollars into highly speculative ventures? Well, I did.  A friend introduced me to Clayton Christopher [snip])
[02:54:47] <feepbot> <gwern> https://twitter.com/JanelleCShane/status/1491443125671571458
[02:54:48] <Robomot> Janelle Shane (@JanelleCShane): "I made holographic chocolate! / Way easier than I thought - and it‚Äôs 100% pure bittersweet, no coatings. When you catch the light at the right angle, it‚Äôs mesmerizing." (http://n.hyperborea.cloud/i/videos/1491443125671571458)
[02:59:49] <feepbot> <gwern> https://fullfrontal.moe/sakuga-expresso-gundam-unicorn-takashi-hashimoto/
[02:59:50] <Robomot> Sakuga Expresso - Gundam Unicorn, Takashi Hashimoto - Full Frontal (Sakuga analysis of Takashi Hashimoto‚Äôs scene in Gundam Unicorn)
[03:04:51] <feepbot> <gwern> https://publicdomainreview.org/essay/a-paper-archaeology
[03:04:51] <Robomot> A Paper Archaeology: Piranesi‚Äôs Ruinous Fantasias / ‚Äì The Public Domain Review (From the vast confines of his _imaginary prisons_ to the billowy scenes that comprise his _grotteschi_, the early works of Giovanni Battista Piranesi wed the exacting details of first-hand observation with the farthest reaches of artistic imagination. Susan Stewart journeys through this 18th-century engraver-architect‚Äôs paper ‚Ä¶)
[03:07:58] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[03:08:09] <quanticle> Okay, feature request: Can we get Robomot to ignore feepbot entirely?
[03:08:44] <quanticle> Like... when feepbot posts a gwern, and then Robomot interrupts it with the link title, that makes the gwern hard to read
[03:11:52] <quanticle> gwern: re: the Sakuga Moe, another example of very aesthetic explosions: https://www.youtube.com/watch?v=rs0p9Nd8WEA
[03:11:53] <Robomot> missile clip from Evangelion episode 01 - YouTube (00:00:13)
[03:16:54] <feepbot> <gwern> uploads https://www.gwern.net/docs/psychiatry/2022-gooding.pdf
[03:16:55] <Robomot> PDF (7 pages; 116 KB) - Addiction chronicity: are all addictions the same? (Nolan B. Gooding, Jennifer N. Williams, Robert J. Williams) - addiction
[03:21:56] <feepbot> <gwern> https://twitter.com/LeaksPh hah
[03:21:58] <Robomot> astro-ph-leaks (@LeaksPh) (http://nitter.fly.dev/pic/pbs.twimg.com%2Fprofile_images%2F1130379425265201152%2FVrIy0RHe_400x400.jpg)
[03:26:58] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1486386028436934661
[03:26:59] <Robomot> astro-ph-leaks (@LeaksPh): "A quick anecdote until the 1990s, when telescopes were bigger and more expensive and electronic storage had more capacity and cheaper, it was cheaper to store data on the sky I don't mean cloud storage by which I mean, if you the data, go observe the object again!"
[03:32:00] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1478052892049387526
[03:32:01] <Robomot> astro-ph-leaks (@LeaksPh): "For anyone reading this, I'm not presenting archival dataset images because they're not very interesting."
[03:37:02] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1473341689209131009 WAKE UP SHEEPLE
[03:37:03] <Robomot> astro-ph-leaks (@LeaksPh): "THERE WAS NO TIME BETWEEN THE END OF THE 19TH CENTURY AND THE BEGINNING OF THE 20TH"
[03:42:04] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1467542526957551622 deep
[03:42:05] <Robomot> astro-ph-leaks (@LeaksPh): "These violent delights have violent ends."
[03:42:33] *** Quits: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:2c8a:e08a:3ded:de79) (Quit: Client closed)
[03:47:06] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1462106500726501379
[03:47:07] <Robomot> astro-ph-leaks (@LeaksPh): "this paragraph should be edited by someone who knows what they're talking about (i.e. not me)"
[03:49:46] *** Joins: phill (uid429774@id-429774.ilkley.irccloud.com)
[03:52:08] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1485661543098290177
[03:52:09] <Robomot> astro-ph-leaks (@LeaksPh): "as Landau reportedly quipped, cosmologists are often in error but never in doubt."
[03:57:10] <feepbot> <gwern> https://twitter.com/LeaksPh/status/1482401086535311366 guess he did
[03:57:11] <Robomot> astro-ph-leaks (@LeaksPh): "Sometimes you're writing disc, sometimes disc. You should choose either the British spelling or the US one"
[04:02:12] <feepbot> <gwern> uploads https://www.gwern.net/docs/longevity/2021-lee.pdf
[04:02:13] <Robomot> PDF (8 pages; 220 KB) - Effect of Metformin and Lifestyle Interventions on Mortality in the Diabetes Prevention Program and Diabetes Prevention Program Outcomes Study (Christine G. Lee, Brandy Heckman-Stoddard, Dana Dabelea, Kishore M. Gadde, David Ehrmann, Leslie Ford, Philip Prorok, Edward J. Boyko, ‚Ä¶) - diabetes
[04:07:15] <feepbot> <gwern> https://twitter.com/BertChakovsky/status/1491267528706117633 https://developmentalsystems.org/sensorimotor-lenia/
[04:07:16] <Robomot> Bert Chan (@BertChakovsky): "In this fun project, we trained artificial life using machine learning! / Lenia creatures learn to survive obstacles using gradient descent (Neural CA) & curriculum learning (IMGEP), generalize well to unseen tasks. / Full video + blog post + interactive demo: https://developmentalsystems.org/sensorimotor-lenia/" (http://n.hyperborea.cloud/i/videos/1491267528706117633)
[04:12:16] <feepbot> <gwern> https://www.animenewsnetwork.com/watch/2022-02-09/the-orbital-children-ending-explained/.182416 that is quite a plot
[04:12:17] <Robomot> The Orbital Children Ending Explained - Anime News Network (In Mitsuo Iso's new mini-series, The Orbital Children, anime fans new and old now have the chance to discover one of the most ambitious voices in the industry and we deep dive into the wild ending.)
[04:16:03] <ggreer>  https://news.ycombinator.com/item?id=30277356 convenient for me
[04:16:04] <Robomot> OpenSCAD 3D rendering just got an order of magnitude faster | Hacker News
[04:18:00] <gwern> Obormot\Arcturus: https://www.gwern.net/docs/www/misc/xwd-16444539483621151.png so this is how it works right now: for archiving, it gets rewritten into the PDF version which gets archived normally, and returns the PDF path; then the data-originalurl attribute also gets rewritten, to turn it into the ar5iv version instead. the main title in a popup then will be the local PDF which can popup...
[04:18:00] <Robomot> image/png (1072x400; 53 KB)
[04:18:06] <gwern> ...live, but the '[LIVE]' original link will go to ar5iv. 'live' might not be the best word. I was thinking 'raw' might be better. 'original' is too long... 'origin'?
[04:23:07] <feepbot> <gwern> https://twitter.com/deKxi/status/1491409166338236416
[04:23:09] <Robomot> deKxi (@deKxi): "'Help I spilled some lovecraftian coffeethulu into my coffee!'" (https://nitter.1d4.us/pic/media%2FFLKMtZCVQAg8Z3_.jpg)
[04:24:04] <nshepperd2> cute
[04:28:53] <Betawolf> fake. That's swimming to the right, which real 'thulus never do.
[04:30:22] <gwern> Betawolf: a common misperception, but deKxi is from the Southern Hemisphere, so a cthulhu swimming 'right' is going the correct direction
[04:32:03] <gwern> Obormot\Arcturus: ...and if you actually go to the Ar5iv in that example, it doesn't work. just a big old mostly-blank error page. doesn't even redirect to arxiv! lol. I've filed a bug https://github.com/dginev/ar5iv/issues/54 we'll see if they're jerks who don't give a shit about readers
[04:32:04] <Robomot> Redirect back to Arxiv for low-quality/unavailable papers ¬∑ Issue #54 ¬∑ dginev/ar5iv ¬∑ GitHub
[04:36:05] <gwern> Obormot\Arcturus: ie. this will be a useful litmus test for whether I want to use Ar5iv at all. if they can't even get this right, then forget about filing more bugs, I'm not going to send my readers to them in the first place. might try arxiv-vanity but otherwise I'll delete them and stick with mirroring arxiv PDFs as better than the status quo
[04:41:06] <feepbot> <gwern> https://twitter.com/SteveStuWill/status/1491564374435065857 hm
[04:41:08] <Robomot> Steve Stewart-Williams (@SteveStuWill): "Why are tigers so conspicuously colored? Doesn't it give them away to prey? Well, they're conspicuous to us, with our trichromatic vision. But the species they typically hunt have dichromatic vision, and can't distinguish orange from green. To them, tigers are camouflaged!" (http://nitter.domain.glass/pic/media%2FFLMZ5DeaIAEqTjo.jpg)
[04:46:13] *** Quits: gwn (00597634f8@2604:bf00:561:2000::390) (Ping timeout: 240 seconds)
[04:46:43] *** Joins: gwn (00597634f8@2604:bf00:561:2000::390)
[04:50:38] <quanticle> Uh, even to us
[04:50:47] <quanticle> Has this person ever tried to see a tiger in a jungle?
[04:53:38] <nshepperd2> i've never been in a jungle with tigers
[04:53:38] <adiabatic> I avoid jungles. If there were a tiger in a jungle, I'd want to see it.
[05:00:51] <Obormot\Arcturus> gwern: Good test case, yeah
[05:11:26] <Obormot\Arcturus> gwern: ... so I'm looking at the twitter thread about ar5iv and... where are some of these features? Where's this dark mode toggle, for instance?
[05:13:33] <Obormot\Arcturus> nm I found it. It's all the way at the bottom... for some reason
[05:14:03] <Obormot\Arcturus> (And it's the lame two-state toggle, of course, because nobody bothers to do this right)
[05:14:37] <Obormot\Arcturus> ... their "figure zoom" feature works by zooming in *as long as you hold down the mouse on the figure*
[05:14:40] <Obormot\Arcturus> What the hell
[05:15:09] <Obormot\Arcturus> (Also it seems to zoom in by a fixed multiplier, which can easily result in zooming to a size bigger than the viewport, which is worse than useless)
[05:15:28] <Obormot\Arcturus> Well, let's hope this all gets fixed
[05:16:57] <Obormot\Arcturus> https://share.obormot.net/screenshots/Arcturus_Screen%20Shot%202022-02-09%20at%208.45.57%20PM.png ... an example of one of their popups in action. You have to click the annotated link ("2015" in the screenshot), whereupon you get the popup, which is then closable *only* by clicking on that little rectangle with the 'x' in it
[05:16:58] <Robomot> image/png (981x329; 93 KB)
[05:17:38] <Obormot\Arcturus> Also they style popup-generating local "links" (not actually links) and actual external hyperlinks identically, which is... unfortunate
[05:18:01] <Obormot\Arcturus> Hm. Is this... MathML?
[05:18:51] <Obormot\Arcturus> Heh. When you load the page in Chromium, you get several seconds of the entire page just being a giant loading spinner that says "Typesetting Equations..."
[05:19:07] <Obormot\Arcturus> Which are then typeset with...
[05:19:50] <Obormot\Arcturus> MathJax... but it's not selectable... alright
[05:20:06] <Obormot\Arcturus> Seems like a lot of this is fumblingly reinventing rudimentary parts of gwern.net
[05:36:08] <saturn2> welcome to the fumbleweb
[05:38:50] <nshepperd2> the "dark" web
[05:42:23] *** Joins: nanotube (~nanotube@user/nanotube)
[05:45:22] * gwern rates the response 3/5 stars
[05:53:55] <nshepperd2> Obormot\Arcturus: aw there was a tiny cute spider on my monitor but it ran away underneath something before i could get a picture
[05:55:41] <Obormot\Arcturus> darn
[05:56:22] <nshepperd2> need to get a proper macro lens attachment for my phone
[05:58:21] <Obormot\Arcturus> gwern: ... lol. Just read the response. It seems like the dude is trying to be helpful but ... doesn't really get it
[06:01:35] <gwern> Obormot\Arcturus: yeah, I just added a response to try to educate him a little. he's most of the way there, and maybe invoking a few phrases he knows but isn't really internalizing like "don't let the perfect be the enemy of better" will push him over the finish line
[06:08:00] <gwern> nshepperd2: "we call it the dark web because after a while using it, you start thinking dark thoughts"
[06:13:01] <feepbot> <gwern> https://twitter.com/mjtech01/status/1491180890365775872
[06:13:02] <Robomot> Chris Jones (@mjtech01): "Our children's @philips electric toothbrush contains a 32-bit ARM processor, clocked at 48MHz. I've even got the development tools for the Cypress PSoC 4, and they've nicely labelled the debug pads. It's just a toothbrush. Really." (https://birdsite.xanny.family/pic/media%2FFLG9HLOWUAE7ct3.jpg)
[06:15:05] <gwern> ( https://www.gwern.net/docs/www/misc/xwd-16444610333689758.png at least my end of things *seems* to be working with the rewrites...)
[06:15:06] <Robomot> image/png (2160x3839; 1,009 KB)
[06:16:26] <gwern> quanticle: but the research in question https://royalsocietypublishing.org/doi/10.1098/rsif.2019.0183 does looks interesting
[06:16:27] <Robomot> Optimizing colour for camouflage and visibility using deep learning: the effects of the environment and the observer's visual system | Journal of The Royal Society Interface (Avoiding detection can provide significant survival advantages for prey, predators, / or the military; conversely, maximizing visibility would be useful for signalling. / One simple determinant of detectability is an animal's colour ‚Ä¶)
[06:19:59] <nshepperd2> gwern: and also you can't find anything
[06:25:01] <feepbot> <gwern> https://www.science.org/doi/10.1126/sciadv.abl6496 neat you can just sequence animals which went extinct centuries ago
[06:25:02] <Robomot> Genomic basis for skin phenotype and cold adaptation in the extinct Steller‚Äôs sea cow (Paleogenomes from Steller‚Äôs sea cows reveal functional changes responsible for their bark-like skin and adaptation to cold.)
[06:30:01] <feepbot> <gwern> https://twitter.com/HvnsLstAngel/status/1491419594443358208 you are already a buddha
[06:30:02] <Robomot> HeavensLastAngel (@HvnsLstAngel): "loving the way these angel-rugs are coming out üßò‚Äç‚ôÇÔ∏è A or B?" (http://twitter.censors.us/pic/media%2FFLKWNzbakAYV9u4.jpg)
[06:32:25] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Quit: Leaving...)
[06:33:55] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[06:35:03] <feepbot> <gwern> https://twitter.com/RiversHaveWings/status/1491578889893658624 too bad it can't create vector art versions
[06:35:05] <Robomot> Rivers Have Wings (@RiversHaveWings): ""vibrant circles and squares, tempera" cc12m_1_cfg, 25 PLMS steps." (https://nttr.stream/pic/media%2FFLMnFi1UcAAJKYj.jpg)
[06:40:06] <feepbot> <gwern> https://arxiv.org/abs/2202.04350
[06:40:06] <Robomot> [2202.04350] pNLP-Mixer: an Efficient all-MLP Architecture for Language (Large pre-trained language models drastically changed the natural language / processing(NLP) landscape. Nowadays, they represent the go-to framework to / tackle diverse NLP tasks, even with a limited number of annotations. However, / using those models in production, either in the cloud or at the edge, remains a / challenge due to the ‚Ä¶)
[06:45:07] <feepbot> <gwern> https://www.reddit.com/r/TheMotte/comments/so3gjo/meta_the_vault_blocking_and_terror/ hm
[06:45:09] <Robomot> [META] The Vault, Blocking, And Terror : TheMotte (90 votes, 100 comments. Ahoy! A somewhat-standard preamble: Meta threads are for me to talk to you, but they're also for you to talk to me. However ‚Ä¶)
[06:51:37] <feepbot> <gwern> 'There is now a footnote on the article that links to this very post.' 'Nothing escapes this Gwern guy.' https://old.reddit.com/r/boardgames/comments/sbkous/does_this_ai_generated_idea_for_a_board_game/ heh. they noticed. *do not think you can evade the all-seeing eye* ÍôÆ
[06:51:38] <Robomot> Does this AI generated idea for a board game already exist? : boardgames (Gwern asked GPT3 to generate some ideas. One of them had > Well, this new co-op game actually has two separate sides to it and, as the game goes...)
[06:52:47] *** Joins: src (~src@user/src)
[07:07:17] <feepbot> <gwern> https://gizmodo.com/futurama-revival-hulu-new-episodes-2023-1848509517 damn, streamers will pay for any IP
[07:07:17] <Robomot> Futurama Returns: Hulu Orders More Sci-Fi Comedy Cartoon (Hulu has ordered 20 new episodes of the beloved animated series from the creator of The Simpsons.)
[07:07:30] <gwern> '‚ÄúIt‚Äôs a true honor to announce the triumphant return of Futurama one more time before we get canceled abruptly again,‚Äù commented Groening. This will, amazingly, be the fourth time that Futurama has returned after airing what the creators thought was going to be a finale. The first was at the end of the fourth season, after the show was canceled by the Fox TV channel in 2003. In 2006,...
[07:07:36] <gwern> ...Comedy Central ordered four straight-to-DVD Futurama movies, of which the fourth (Into the Wild Green Yonder) was assumed to be the end, as were the final episodes of seasons six and seven, both of which aired on Comedy Central. The last episode of Futurama to date aired in September of 2013, so it will have been 10 long years when the show returns to TV; it‚Äôs currently scheduled to air...
[07:07:42] <gwern> ...on Hulu sometime in 2023.'
[07:09:09] *** Joins: Logos01 (~Logos01@user/logos01)
[07:09:24] *** Parts: Logos01 (~Logos01@user/logos01) ()
[07:24:56] <ggreer> I dropped my car off to get some wind noise fixed and tesla didn't have any loaner cars. instead they gave me $200 of uber credit. this is egregious!
[07:25:12] <adiabatic> how long does $200 of Uber credit last?
[07:25:34] <ggreer> well the credits expire in 2 days so.... 2 days
[07:25:52] <ggreer> it's a bit of a perverse incentive. I've been using uber a lot today
[07:26:15] <ggreer> at one point I thought "I wonder where this bus goes" and I took it and then ubered back home
[07:26:17] <adiabatic> well, you're getting a taste of what it's like to not have to drive your own car
[07:26:35] <adiabatic> That's a future Tesla's trying to work towards anyway, right?
[07:26:41] <ggreer> basically
[07:27:50] <ggreer> honestly it's probably less stressful than getting a loaner car. I've only used a loaner once and it was a ridiculous model s. it was a fucking land yacht. I could barely fit it into my garage
[07:33:26] <gwern> ggreer: hold on, haven't we literally shared articles here about *exactly that*?
[07:33:29] <gwern> why are you surprised
[07:33:47] <Robomot> [Less Wrong [frontpage]] Bet on Rare Undesirable Outcomes when Seeding a Prediction Market by lsusr - https://www.greaterwrong.com/posts/LsyuX5rLsApZFdQGp/bet-on-rare-undesirable-outcomes-when-seeding-a-prediction
[07:33:48] <ggreer> about their lack of loaners?
[07:33:59] <Robomot> [Less Wrong [frontpage]] Why rationalists are not much concerned about mortality? by alex_lw - https://www.greaterwrong.com/posts/koWia2KgN6EfHn26Q/why-rationalists-are-not-much-concerned-about-mortality
[07:33:59] <gwern> yes, and getting some uber credits instead
[07:34:18] <ggreer> oh. maybe. I haven't followed all the tesla drama lately
[07:36:25] <rmmh> based on mazda: OTA updates are good, actually
[07:37:09] <quanticle> saturn2: https://www.youtube.com/watch?v=pVdAN26WFkU I don't know why, but the moment I saw this ad, I thought of you.
[07:37:10] <Robomot> 1990 Sports Illustrated Commercial (Football Phone) - YouTube (00:01:02) ((c)1990 Meredith Corporation (via acquisition of Time, Inc.)1990 Sports Illustrated commercial in which SI offers a football phone as a promotion for those w...)
[07:42:12] <feepbot> <gwern> https://twitter.com/BlancheMinerva/status/1491621024676392960 ok *now* gpt-j-20b is released
[07:42:13] <Robomot> Stella Rose Biderman (@BlancheMinerva): "A little over one year ago @CoreWeave approached #EleutherAI and asked how much compute we needed to train the largest open source language model in the world. Today, we are finally releasing the weights of a 20B parameter LM trained on the Pile."
[07:44:59] <saturn2> quanticle: lol
[07:49:08] *** Quits: UniquelyGeneric (~karma@cpe-68-173-154-253.nyc.res.rr.com) (Ping timeout: 256 seconds)
[07:49:20] *** Joins: UniquelyGeneric (~karma@cpe-68-173-154-253.nyc.res.rr.com)
[08:15:12] *** Quits: UniquelyGeneric (~karma@cpe-68-173-154-253.nyc.res.rr.com) (Ping timeout: 256 seconds)
[08:15:12] *** Joins: WisestFool (~karma@cpe-68-173-154-253.nyc.res.rr.com)
[08:34:26] <rmmh> quanticle: the fact that they even mention the swimsuit issue
[08:41:09] <PapuaHardyNet> gwern: technically it isn't gpt-j since they surely changed things up when using the neox code, in comparison to the gpt-j / mesh-transformer-jax code
[08:41:43] <PapuaHardyNet> that's why they call it "20B parameter LM", because they took a lot of liberty in modifying things as they saw appropriate (which is good, of course)
[08:42:42] <PapuaHardyNet> ggreer: did you seriously just take a bus to a random place and then uber back home? that's... yeah. perverse incentive
[08:51:17] *** Joins: feep[work] (~mathis@195.50.168.194)
[09:01:13] <nshepperd2> free stuff and its consequences
[09:11:03] <quanticle> I'm just wondering if that's where he saw the burning car
[09:13:52] <quanticle> "We show that the simplest architecture change of gating each residual connection using a single zero-initialized parameter satisfies initial dynamical isometry and outperforms more complex approaches."
[09:13:54] <quanticle> https://arxiv.org/abs/2003.04887
[09:13:54] <Robomot> [2003.04887] ReZero is All You Need: Fast Convergence at Large Depth (Deep networks often suffer from vanishing or exploding gradients due to / inefficient signal propagation, leading to long training times or convergence / difficulties. Various architecture designs, sophisticated residual-style / networks, and initialization schemes have been shown to improve deep signal / propagation. Recently, Pennington et ‚Ä¶)
[09:13:56] <quanticle> gwern: The bitter lesson never ends, does it? Virgin carefully fine-tuned starting weights vs. chad zero initialization
[09:14:07] <quanticle> h/t PapuaHardyNet
[09:14:18] <PapuaHardyNet> quanticle: I uh, I got it from gwern's list of papers on fully connected neural nets
[09:15:26] <quanticle> Oh
[09:15:28] <quanticle> Haha
[09:15:38] <quanticle> G W E R N C E P T I O N
[09:16:20] <quanticle> But yeah, the bitter lesson is fractally bitter
[09:16:57] <quanticle> It's like any time you think about applying your smart human brain to neural nets, you should slap yourself and just do the absolute most dumbshit thing instead
[09:17:06] <quanticle> Because it's guaranteed to work better at this point
[09:20:54] <PapuaHardyNet> recursion? create an instructGPT trained on DL research, and ask it questions instead
[09:21:25] <PapuaHardyNet> oh wait, why isn't anyone doing this - we are already at a point where we can do this
[09:22:36] <quanticle> I thought there were already tools that would do some kind of gradient descent on NN hyperparameters
[09:22:49] <quanticle> But you'd have to ask gwern or nshepperd for details
[09:23:29] <PapuaHardyNet> oh yeah, but I meant more like... hmm. okay, you know how AlphaCode(r?) can solve leetcode-likes?
[09:23:47] <quanticle> Sure...
[09:23:56] <PapuaHardyNet> imagine it trained on Neural network research papers.
[09:24:07] <PapuaHardyNet> use the network to improve the network
[09:24:34] <quanticle> ITT PapuaHardyNet wants the foom
[09:29:28] <nshepperd2> thats how you get either x-risk or disappointment
[09:30:38] <quanticle> I'm not sure which I fear more
[09:30:44] <PapuaHardyNet> just scale up the compute, layers, and data until the disappointment turns to x-risk
[09:30:56] <quanticle> Google's working on that
[09:32:26] <PapuaHardyNet> they are hemoragging good researchers, as far as I've seen over the past month
[09:32:39] <PapuaHardyNet> (pls fix typo mentally)
[09:34:28] <PapuaHardyNet> recently Ashish Vaswani and Noam Shazeer left Google Brain within a month of each other, ostensibly to start a chatbot / conversational AI startup
[09:34:53] <PapuaHardyNet> you know what that means? it means your AI waifu will be a Google product. :(
[09:36:37] <PapuaHardyNet> okay, not a google product - but you know what I mean
[09:37:27] <ggreer> PapuaHardyNet: I mean I had to pay the bus fare
[09:37:59] <ggreer> had I gotten a loaner car, I probably would have seen how quickly it accelerated or something
[09:40:46] <quanticle> Wait, DeepMind is losing people?
[09:41:26] <quanticle> x-posted from #lw-fandom: https://i.imgur.com/35RiP4r.jpg
[09:41:26] <Robomot> image/jpeg (1200x797; 97 KB)
[09:41:30] <quanticle> Obormot\Arcturus: ^
[09:41:46] <adiabatic> is the one on the right canadian
[09:42:03] <quanticle> The cat?
[09:42:10] <quanticle> I don't know. Why do you ask?
[09:42:15] <quanticle> Oh, bagged milk?
[09:42:18] <adiabatic> milk-in-b‚Ä¶yes.
[09:42:25] <quanticle> Perhaps, perhaps.
[09:43:19] <quanticle> I always wondered about that. When Canadians buy milk in a bag, they don't *store* the milk in the bag, right? They have a container that they pour the milk out into, right?
[09:47:33] <PapuaHardyNet> I mean, how can you keep milk in an open bag
[09:47:52] <PapuaHardyNet> that sounds like a recipe for disaster
[09:48:35] <nshepperd2> PapuaHardyNet: wtf your ai waifu is cancelled to make way for a new messaging app
[09:49:07] <adiabatic> the only people who want AI waifus are mostly NEETs and weeaboos
[09:49:30] <adiabatic> and nobody got rich trying to pander to the 4chan userbase
[09:49:43] <PapuaHardyNet> lol a messaging app, like we don't have enough already
[09:49:45] <nshepperd2> nah, everyone will want them once they're good enough
[09:49:56] <PapuaHardyNet> nshepperd2: you have a source I could look at
[09:50:11] <nshepperd2> although by that point foom will have happened
[09:50:34] <PapuaHardyNet> not if you are at the edge of AI research: you'll have a precious few months with your AI waifu before singularity
[09:50:44] <nshepperd2> yeah maybe
[09:51:02] <quanticle> PapuaHardyNet: In case you didn't get the reference: https://arstechnica.com/gadgets/2021/08/a-decade-and-a-half-of-instability-the-history-of-google-messaging-apps/
[09:51:02] <Robomot> A decade and a half of instability: The history of Google messaging apps | Ars Technica (Sixteen years after the launch of Google Talk, Google messaging is still a mess.)
[09:51:52] <PapuaHardyNet> I'm confident waifuism is happening. they *left* Google, remember?
[09:51:58] <nshepperd2> PapuaHardyNet: a source... for ai waifus?
[09:52:01] <quanticle> True, true
[09:52:24] <PapuaHardyNet> nshepperd2: sorry, I didn't realize you were joking :)
[09:52:52] <quanticle> PapuaHardyNet: Look, nshepperd is working on it as hard as she can
[09:53:09] <quanticle> She's doing her best to create a source for AI waifus
[09:53:20] <quanticle> These things, they just take time, okay?!
[09:53:25] <saturn2> quanticle: they put the milk bag inside a plastic milk bag holder
[09:53:57] <quanticle> Wouldn't it be easier to just pour the milk out into a container?
[09:54:29] <quanticle> Is this some kind of strange Canada logic that one can only understand after communing with the snow spirits?
[09:56:05] <saturn2> it would only be easier until it came time to wash te container
[09:56:46] <quanticle> I guess
[09:58:11] <PapuaHardyNet> nshepperd2: this is a dumb question, but how do I know whether jnp1 * jnp2 is actually the same as jnp.multiply(jnp1, jnp2)? I want to ensure I am actually doing an element-wise multiplication you see
[09:58:38] <PapuaHardyNet> "just use the function name instead" sure I'll do that, but I'd still like to know
[09:58:49] <quanticle> Also, speaking of Canada, I was listening to the latest episode of Rational Security, https://www.lawfareblog.com/rational-security-20-hockey-guns-edition, and this time they had on a guest from Canada. When one of the hosts mentioned that he was from Minnesota, the guest seamlessly cut in with, "You mean 'occupied Canada'"
[09:58:49] <Robomot> Rational Security 2.0: The ‚ÄòHockey With Guns‚Äô Edition - Lawfare (This week, Alan, Quinta and Scott were joined by Canadian national security expert, Stephanie Carvin! They talked through some of the week's biggest national security news, both in the U.S. and in our neighbor to the north, including: ‚ÄúAssault on the Capital, Eh? Hold My Labatt Blue.‚Äù For the past two weeks, our neighbors to the north have ‚Ä¶)
[09:58:51] <quanticle> I lol'd
[10:00:39] <nshepperd2> PapuaHardyNet: it's always element-wise multiplication
[10:00:47] <nshepperd2> all the arithmetic operators are elementwise
[10:01:08] <PapuaHardyNet> thanks for the heads up
[10:01:28] <nshepperd2> things like jnp.matmul get a function instead
[10:01:48] <nshepperd2> (python also has @ for matmul now, as well)
[10:02:51] <nshepperd2> my advice would be to use * instead of jnp.multiply, bc it's more readable
[10:03:18] <saturn2> i always feel a little jolt of surprise every time i'm reminded that canada has a military
[10:03:26] <quanticle> Wait, Python has a matrix multiplication operator now?
[10:03:40] <PapuaHardyNet> really? I thought using jnp.multiply allows someone to see the docs for it and *know* that it is elementwise and not something else
[10:04:16] <saturn2> https://www.youtube.com/watch?v=MJC7ilyFsWY also it couldn't really get much easier
[10:04:17] <Robomot> How Canadian Milk Bags Work - YouTube (00:00:44) (A visual explanation on how canadian milk bags work)
[10:04:18] <nshepperd2> quanticle: yep
[10:04:23] <quanticle> When did that happen?
[10:04:28] <nshepperd2> added specifically for numpy and torch lol
[10:04:31] <quanticle> Haha
[10:04:33] <quanticle> I figured
[10:04:41] <PapuaHardyNet> discoverability matters to me - at least if I'm the only one reading the code and verifying it so meh
[10:05:07] <PapuaHardyNet> but yeah, I'll go with *
[10:05:17] <nshepperd2> quanticle: wow, 2015 actually
[10:05:26] <nshepperd2> ancient history
[10:05:33] <quanticle> Oh wow. Much older than I thought.
[10:06:43] <nshepperd2> PapuaHardyNet: it's more readable to users familiar with jax/numpy/etc
[10:07:17] <nshepperd2> and the arithmetic operators are one of the earlier things you learn
[10:07:44] <PapuaHardyNet> I'll keep that in mind
[10:08:29] <nshepperd2> https://www.python.org/dev/peps/pep-0465/#motivation hah, actually @ was added specifically *because* some crazy people (whose libraries are presumably no longer relevant) were using * for matrix multiplication
[10:08:30] <Robomot> PEP 465 -- A dedicated infix operator for matrix multiplication | Python.org [Motivation Executive summary In numerical code, there are two important operations which compete for use of Python's * operator: elementwise multiplication, and matrix multiplication. In the nearly twenty years since the Numeric library was first proposed, there have been many attempts to resolve this tension [13]; none have been ‚Ä¶]
[10:09:15] <adiabatic> using * for matrix multiplication deserves a flogging
[10:13:42] <enterprisey> rust had a forum thread recently about @ for matrix multiplication
[10:13:52] <enterprisey> "not our problem domain"
[10:16:04] <PapuaHardyNet> instead of a * b, one could use einsum("ij, ij -> ij", a, b). Just a thought. verbose but clearer
[10:16:34] <enterprisey> that's way too sensible
[10:17:16] <enterprisey> much like writing out the full name of attributes for format-strings ("width=3,pad=right,padchar=space")
[10:18:32] <PapuaHardyNet> I like that
[10:28:35] <Obormot\Arcturus> !latest acx
[10:28:36] <Robomot> [Astral Codex Ten] So You Want To Run A Microgrants Program - https://astralcodexten.substack.com/p/so-you-want-to-run-a-microgrants
[10:28:41] <Obormot\Arcturus> "But even the ‚Äúexperts‚Äù weren‚Äôt perfectly aligned. There were three proposals where one evaluator assigned the highest possible rating, and another assigned the lowest possible. Sometimes these were differences of scientific opinion. Other times they were more fundamental. One person would say "This idea would let you do so many cool things with viruses" and another person would say "This idea would let you do so many
[10:28:41] <Obormot\Arcturus>  cool things with viruses, such as bioterrorism"."
[10:29:44] <feep[work]> covid accelerationism
[10:30:11] <feep[work]> how about TWO spike proteins
[10:33:17] <feep[work]> meanwhile germany is at 250k cases a day, fun times
[10:33:53] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[10:33:58] <nshepperd> PapuaHardyNet: the problem is when you an expression with ten arithmetic operators in it the verbose way is completely unreadable
[10:34:06] <nshepperd> or even like, three
[10:34:17] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[10:34:17] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Remote host closed the connection)
[10:34:26] <enterprisey> the wise man lowered his head and spoke: then only use one per statement
[10:34:34] <Obormot\Arcturus> "I‚Äôd been on a couple of dates with someone a month or two before the grants program. Then in the chaos of sorting through applications, I forgot to follow up.
[10:34:34] <Obormot\Arcturus> Halfway through the grant pile, I found an application from my date. It was pretty good, but I felt like it would be too much of a conflict of interest. I sent them an email: ‚ÄúSorry, I don‚Äôt feel like I can evaluate this since we‚Äôre dating‚Äù.
[10:34:34] <Obormot\Arcturus> The email back: ‚ÄúI don‚Äôt consider us to still be dating‚Äù. This remains the most stone-cold rejection I have ever gotten."
[10:34:47] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[10:35:04] <feep[work]> well but did he fund it tho
[10:35:09] * Obormot\Arcturus shrug
[10:35:17] <feep[work]> also yeah wow brutal
[10:35:21] <Obormot\Arcturus> enterprisey: "One per statement" is a way to have verbose code also
[10:35:29] <feep[work]> also "it's okay, since we're no longer in a relationship, you can give me money"
[10:35:45] <feep[work]> this is hilarious to me
[10:38:57] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 240 seconds)
[10:41:44] <quanticle> Yeah, we discussed the date rejection earlier.
[10:59:28] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Remote host closed the connection)
[11:02:24] *** Quits: WisestFool (~karma@cpe-68-173-154-253.nyc.res.rr.com) (Quit: Out.)
[11:09:12] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[11:21:44] <Robomot> [Astral Codex Ten] Hidden Open Thread 210.5 - https://astralcodexten.substack.com/p/hidden-open-thread-2105
[11:23:05] <rsaarelm> Has ?depth=1 just stopped working on Reddit or does it go on and off sporadically or something?
[11:24:18] *** Quits: src (~src@user/src) (Quit: Leaving)
[11:36:08] <rsaarelm> Hm, maybe RES is doing something weird with me, it does work in a browser with fresh profile.
[11:41:06] <PapuaHardyNet> so RNNs add positional data due to sequential processing
[11:42:04] <PapuaHardyNet> FNNs add positional data implicitly due to the relation between every neuron in the previous and the next layer
[11:43:08] <PapuaHardyNet> but if creating qkv requires linear projection, and we then do a dot product between q and k, then why doesn't self-attention also capture positional data?
[11:43:49] <PapuaHardyNet> nshepperd: what am I missing here? is the linear projection that we use to create qkv something that does not encode positional data? how is that possible?
[11:43:58] <PapuaHardyNet> I'm not even talking about the dot product here
[11:54:48] <nshepperd2> you get the same result if you shuffle the input along the length axis
[11:55:57] *** Quits: Mateon1 (~Thunderbi@user/mateon1) (Ping timeout: 256 seconds)
[11:56:22] *** Joins: Mateon1 (~Thunderbi@user/mateon1)
[11:58:53] *** Quits: phill (uid429774@id-429774.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[12:06:48] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[12:09:00] <PapuaHardyNet> nshepperd2: why is that? linear projections are not location invariant. is this an emergent phenmenon?
[12:09:11] <nshepperd2> the qkv one is
[12:10:26] <nshepperd2> qkv is [n,l,c] x [3c,c] -> [n,l,3c]
[12:10:38] <nshepperd2> it applies the same c -> 3c mapping at each position
[12:11:12] *** Joins: phill (uid429774@id-429774.ilkley.irccloud.com)
[12:12:16] <PapuaHardyNet> so the only thing done is the channels are affected
[12:12:38] <PapuaHardyNet> which means of you shift the sequence order that does not make a difference
[12:13:08] <PapuaHardyNet> s/of/if/
[12:13:14] <kuudes> good morning
[12:13:54] <PapuaHardyNet> o/
[12:17:01] *** Joins: schmudde (~schmudde@net-93-70-71-143.cust.vodafonedsl.it)
[12:18:57] <nshepperd> yep
[12:29:39] <PapuaHardyNet> quanticle: btw, those two people I talked about leaving GBrain? They are the first two authors of the original Transformers paper
[12:32:45] *** Joins: voltage_ (voltage@user/voltage)
[12:46:44] *** Joins: gproto23 (~gproto23@user/gproto23)
[13:00:33] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[13:01:19] <kuudes> if someone wants to do a stats exercise, https://stat.fi/tup/kokeelliset-tilastot/riistaonnettomuudet/2022-02-09/index.html liite 1 has list of all game collision accidents in finland since 2017, including the exact local time and gps coordinates. I present hypothesis that most of the accidents happen within 1 hours of local sunrise or sunset
[13:01:20] <Robomot> Vuonna 2021 tapahtui tieliikenteess√§ 13 953 riistaonnettomuutta | / Tilastokeskus (Manner-Suomen tieliikenteess√§ sattui vuonna 2021 kaikkiaan 13 953 riistaonnettomuutta.)
[13:02:00] <kuudes> also, I think we maybe should cut game population of south finland hard
[13:02:40] <mjr> "But my son's a gamer!"
[13:03:19] <kuudes> we need more of them, maybe? O_o
[13:03:22] <kuudes> but less game
[13:03:51] <kuudes> oh, also more gates for game as well would be good likely?
[13:04:01] <kuudes> because gates imply fences
[13:05:58] *** Quits: two2thehead (~user@124.195.205.14) (Quit: Leaving)
[13:08:55] <quanticle> mjr: Xi Jinping cut the game population of China quite drastically ü§î
[13:13:05] <kuudes> this sounds like a proper controversial opinion that should anger both hunters and animal protectors
[13:13:26] <kuudes> "we should just kill most wild game so that they kill less people"
[13:19:10] <saturn2> you would need a reverse bambi movie where the deer are ugly and evil
[13:34:53] *** Quits: schmudde (~schmudde@net-93-70-71-143.cust.vodafonedsl.it) (Quit: WeeChat 3.2)
[13:57:04] <capisce> https://news.ycombinator.com/item?id=30284149
[13:57:05] <Robomot> I'm 39 and I've never drank coffee in my life. As a kid I didn't like what it di... | Hacker News
[13:57:38] <capisce> HN commenter suggests banning coffee when discussing a study that shows "Light to moderate coffee consumption is associated with lower risk of death"
[14:02:11] *** Joins: galambo_ (galambo@user/galambo)
[14:02:48] *** Joins: Rubba (~Kol@75.157.122.186)
[14:03:37] *** Joins: mgxm (~mgxm@user/mgxm)
[14:03:47] *** Joins: StathisA_ (~StathisA@178-147-62-94.haap.nym.cosmote.net)
[14:05:41] *** Joins: otoburb_ (~otoburb@user/otoburb)
[14:05:56] *** Joins: mst_ (~matthewt@perl/shadowcat-mst/chainsaw-wielder)
[14:06:35] *** Joins: feep[wor1] (~mathis@195.50.168.194)
[14:08:56] *** Quits: nullcone (uid11626@id-11626.helmsley.irccloud.com) (Quit: Connection closed for inactivity)
[14:11:02] *** Quits: voltage_ (voltage@user/voltage) (*.net *.split)
[14:11:02] *** Quits: feep[work] (~mathis@195.50.168.194) (*.net *.split)
[14:11:02] *** Quits: galambo__ (galambo@user/galambo) (*.net *.split)
[14:11:02] *** Quits: StathisA (~StathisA@178-147-62-94.haap.nym.cosmote.net) (*.net *.split)
[14:11:02] *** Quits: otoburb (~otoburb@user/otoburb) (*.net *.split)
[14:11:02] *** Quits: Kol (~Kol@75.157.122.186) (*.net *.split)
[14:11:02] *** Quits: Nivim (~Nivim@174-24-73-242.clsp.qwest.net) (*.net *.split)
[14:11:03] *** Quits: mst (~matthewt@perl/shadowcat-mst/chainsaw-wielder) (*.net *.split)
[14:11:03] *** Quits: superz (~superegg@user/superegg) (*.net *.split)
[14:11:03] *** Quits: mgxm_ (~mgxm@user/mgxm) (*.net *.split)
[14:11:03] *** Quits: soapes_ (~soapes@46-126-108-131.dynamic.hispeed.ch) (*.net *.split)
[14:11:03] *** Quits: mortehu_ (~mortehu@178.79.163.96) (*.net *.split)
[14:11:03] *** Quits: potatope (sid139423@lymington.irccloud.com) (*.net *.split)
[14:11:03] *** Quits: kawpuh (~kawpuh@66.42.81.80) (*.net *.split)
[14:11:03] *** Quits: dove (~jordan@li1158-85.members.linode.com) (*.net *.split)
[14:12:34] <PapuaHardyNet> wtf
[14:16:12] *** Joins: voltage_ (voltage@user/voltage)
[14:16:12] *** Joins: superz (~superegg@user/superegg)
[14:16:12] *** Joins: soapes_ (~soapes@46-126-108-131.dynamic.hispeed.ch)
[14:16:12] *** Joins: mortehu_ (~mortehu@178.79.163.96)
[14:16:12] *** Joins: potatope (sid139423@lymington.irccloud.com)
[14:16:12] *** Joins: kawpuh (~kawpuh@66.42.81.80)
[14:16:12] *** Joins: dove (~jordan@li1158-85.members.linode.com)
[14:17:03] <Otthorn[m]> I've seen a few times that moderate amount of coffee is beneficial. Yet I am not a coffee drinker myself. Do you think, like other things associated with lower risk of death (exercise, enough water, enough vegetables, ...) that I should start drinking coffee?
[14:17:05] <kuudes> hmm, it appears over here the city infection doctors have ordered daycares to accept also current covid+ kids into daycare as long as they are unsymptomatic, and soft ordered to not to tell other families about this
[14:17:50] <kuudes> our daycare has broadcast a confusing message which says they are not allowed to say on stuff but multiple (at least 3) persons in a group have tested positive for covid
[14:18:20] *** Joins: Nivim (~Nivim@174-24-73-242.clsp.qwest.net)
[14:28:04] <saturn2> Otthorn[m]: no, if you don't enjoy coffee it's probably more helpful to do a bit more of those other things instead
[14:29:02] *** Quits: gproto23 (~gproto23@user/gproto23) (Read error: Connection reset by peer)
[14:29:16] *** Joins: gproto23 (~gproto23@user/gproto23)
[14:30:37] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 240 seconds)
[14:33:29] *** Joins: Lord_of_Life (~Lord@user/lord-of-life/x-2819915)
[14:33:46] <kuudes> https://www.science.org/doi/10.1126/science.abj8222 good that moderna is moving soon to phase 2 of vaccine against ebv
[14:33:48] <Robomot> Longitudinal analysis reveals high prevalence of Epstein-Barr virus associated with multiple sclerosis (Epstein-Barr virus infection precedes symptoms and biomarkers of multiple sclerosis and markedly increases disease risk.)
[14:34:04] <kuudes> I also await eagerly their cmv vaccine
[14:42:22] *** Joins: Guest97 (~Guest97@dslb-188-096-121-068.188.096.pools.vodafone-ip.de)
[14:42:30] <Dyo> Otthorn[m]: too much coffee/caffeine can raise intraocular pressure. stay at or below 2 cups per day. oils in coffee grounds also increase LDL, if you want to optimize against that choose dark ground, coarse ground filtered coffee. if you want to safe money or don't care for the taste of either coffee or tea, take caffeine and green tea powder instead.
[14:51:36] *** Joins: gurkenglas (~gurkengla@dslb-188-096-121-068.188.096.pools.vodafone-ip.de)
[14:52:26] <gurkenglas> Ha! So I was fooled for like 18 hours and 20 lines of text to use irc.libera.net instead of irc.libera.chat, which goes to Freenode :D
[14:52:44] <feep[wor1]> rofl
[14:52:54] <feep[wor1]> gurkenglas: I just have it etc/hosted to 0.0.0.0
[14:53:18] <feep[wor1]> https://feep.life/~feep/cache2/169217388_1920x1080_530841600.small.png blue
[14:53:22] <Robomot> image/png (1920x1080; 845 KB)
[14:53:59] <gurkenglas> Seeing as gptsh treats terminal allergy, I've now installed debian as my old hard drive gave out. I learned English by living on the internet, maybe I'll learn devops now.
[14:55:47] <gurkenglas> The installation hydras I learned to fear are actually killable now! Maybe that's just because the install is fresh. I did manage to get Magic the Gathering: Arena running with only ~a dozen intermediate issues
[14:56:29] <gurkenglas> Or maybe it's because I didn't use to be on amphetamines.
[14:56:39] <feep[wor1]> probably that
[14:56:45] *** feep[wor1] is now known as feep[work]
[14:56:53] <feep[work]> devops severely rewards stickwithititude
[14:59:43] <gurkenglas> I probably shouldn't have crafted Asmodeus the Archfiend, but I felt it was too on-theme to mistakenly go for him. So I also spent 5 packs worth of gold to buy the card style for it that you can only buy while you don't have a card.
[15:05:22] <feep[work]> "I probably shouldn't have crafted Asmodeus the Archfiend" yeah I mean with a name like that
[15:05:41] <feep[work]> "I probably shouldn't have summoned Gorrath the World-Eater" you THINK
[15:08:16] <gurkenglas> (6 mana 6/6, he draws cards instead of you, pay BBB to have him draw 7, pay B and X life to get all the X cards he has)
[15:13:00] <PapuaHardyNet> gurkenglas: welcome, welcome, we we just getting started
[15:13:32] <gurkenglas> with wut
[15:14:11] *** Quits: Guest97 (~Guest97@dslb-188-096-121-068.188.096.pools.vodafone-ip.de) (Quit: Client closed)
[15:14:34] <kuudes> everything
[15:14:54] * PapuaHardyNet nods sagely
[15:15:50] <kuudes> uuh. I am a bit tired. gladly not in much pain, and also my oxy levels were 99% during night
[15:19:37] *** Quits: PapuaHardyNet (apotheosis@tilde.institute) (Remote host closed the connection)
[15:34:48] *** otoburb_ is now known as otoburb
[15:48:53] *** Quits: phill (uid429774@id-429774.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[16:04:31] *** Quits: _inky (~inky_@141.136.78.37) (Quit: Leaving.)
[16:05:11] *** Joins: _inky (~inky_@141.136.78.37)
[16:15:00] *** Joins: PapuaHardyNet (apotheosis@tilde.institute)
[16:33:42] <Robomot> [TheZvi Substack] The Long Long Covid Post - https://thezvi.substack.com/p/the-long-long-covid-post
[16:40:43] <Robomot> [TheZvi] The Long Long Covid Post - https://thezvi.wordpress.com/2022/02/10/the-long-long-covid-post/
[16:50:28] *** Quits: _inky (~inky_@141.136.78.37) (Quit: Leaving.)
[16:57:22] *** Joins: two2thehead (~user@124.195.205.14)
[17:20:50] *** Joins: _inky (~inky_@141.136.78.37)
[17:25:12] <Obormot\Arcturus> https://imgur.com/gallery/UrdoP8m
[17:25:13] <Robomot> O.o - Imgur
[17:26:07] <Obormot\Arcturus> (Autistic bees would be pretty cool actually)
[17:30:37] <two2thehead> large paste incoming
[17:31:00] <two2thehead> kuudes, s0ph1a feep : Interesting implications. If only for mathematicians/compsci/programmers https://twitter.com/BenPitt/status/1491111060958449666 https://twitter.com/BenPitt/status/1491111063169138689 
[17:31:00] <two2thehead> https://twitter.com/BenPitt/status/1491111068642398208 
[17:31:00] <two2thehead> https://twitter.com/BenPitt/status/1491111073327378434
[17:31:00] <two2thehead> https://twitter.com/BenPitt/status/1491111083582849026
[17:31:00] <two2thehead> https://twitter.com/BenPitt/status/1491111098514558976
[17:31:01] <Robomot> Benjamin Pitt (@BenPitt): "In a new paper, @LanguageMIT, @spiantado and I show that people‚Äôs ability to think exact number thoughts depends on what specific number words they know. Here‚Äôs a thread on what we found and how it connects to some deep questions about thinking. / https://doi.org/10.1177/09567976211034502" ( ‚Ä¶)
[17:31:01] <Robomot> Benjamin Pitt (@BenPitt): "One clue comes from cultures that have few or no exact number words, sometimes not even a word for ‚Äúone‚Äù! (See these papers on the PirahƒÅ, Munduruk√∫, and Nicaraguan Homesigners; @mcxfrank @ev_fedorenko @LanguageMIT @MarieCoppola68 @pierrepica @StanDehaene)" (http://nitter.domain.glass/pic/media%2FFLF18BgVgAEHIIe.jpg)
[17:31:01] <Robomot> Benjamin Pitt (@BenPitt): "These groups don‚Äôt seem to have exact number concepts larger than 3 or 4. After that, it‚Äôs all approximation." (http://twitter.censors.us/pic/media%2FFLF2SmUUYAMamKR.png)
[17:31:01] <Robomot> Benjamin Pitt (@BenPitt): "It‚Äôs easy to tell when someone doesn‚Äôt know the number words (e.g. they miss one), but how do you figure out what number *concepts* people have without using language? You use a numerical matching task‚Ä¶" (http://nitter.weiler.rocks/pic/media%2FFLF5m2bVUAMe12l.jpg)
[17:31:02] <two2thehead> https://twitter.com/BenPitt/status/1491111101144076288
[17:31:02] <Robomot> Benjamin Pitt (@BenPitt): "People have long argued about how people get number concepts like 7 and 42. Are they just naturally part of the human conceptual repertoire? Or do you need to have a set of symbols, like the number words ‚Äúone, two, thee‚Ä¶‚Äù, to think exact number thoughts?"
[17:31:02] <Robomot> Benjamin Pitt (@BenPitt): "In other words, if they knew how to say the number words only up to 10, then they could copy sets of objects up to about 10, but no further. For 11 and up, they‚Äôd fall back on numerical approximation.."
[17:31:03] <Robomot> Benjamin Pitt (@BenPitt): "Findings like this also bear on one of the oldest and most debated questions in cognitive science: Can language give people new conceptual abilities? These findings suggest the answer is: Yes, at least in the domain of numbers."
[17:31:07] <two2thehead> End paste
[17:31:35] <two2thehead> https://journals.sagepub.com/doi/10.1177/09567976211034502
[17:31:37] <Robomot> Exact Number Concepts Are Limited to the Verbal Count Range - Benjamin Pitt, Edward Gibson, Steven T. Piantadosi, 2022 (Previous findings suggest that mentally representing exact numbers larger than four depends on a verbal count routine (e.g., ‚Äúone, two, three . . .‚Äù). However, ...)
[17:32:46] <feep[work]> please only link the first tweet in a chain :V
[17:32:56] <two2thehead> alright
[17:33:23] <two2thehead> I guess I could paste just the text next time instead of the URLs
[17:42:34] <PapuaHardyNet> what the hell? You cannot htink of numbers without words? bullshit
[17:42:58] <PapuaHardyNet> You can think of 10^35 just fine without having to use words
[17:49:13] <feep[work]> 10 and 35 are words
[17:49:40] <PapuaHardyNet> 0xff is not a word
[17:49:44] <PapuaHardyNet> but you can imagine it just fine
[17:50:13] <feep[work]> eff is a word
[17:50:40] <PapuaHardyNet> :| okay, you know what, I shall reserve my comments until I read the paper
[17:54:48] <nshepperd2> lol
[17:55:13] *** Quits: voltage_ (voltage@user/voltage) (Remote host closed the connection)
[17:55:37] *** Quits: feep[work] (~mathis@195.50.168.194) (Ping timeout: 240 seconds)
[17:55:37] *** Joins: voltage_ (voltage@user/voltage)
[18:12:55] <PapuaHardyNet> nshepperd2: I worry about you. how's your sleep routine?
[18:13:13] <nshepperd2> erratic
[18:14:08] <PapuaHardyNet> is something bothering you? or is it just stimulant abuse (which makes sense if you are working 16 hour days, but I don't think you are doing that).
[18:15:33] <PapuaHardyNet> actually, feel free to ignore the question if you don't want to talk about it
[18:18:24] <nshepperd2> ^_^
[18:18:30] <nshepperd2> it's nothing serious heh
[18:19:47] *** Quits: PapuaHardyNet (apotheosis@tilde.institute) (Remote host closed the connection)
[18:20:01] <gwern> so the clown prince is still doing the libera.net bullshit huh
[18:22:33] * gwern couldn't sleep last night because he had an idea: "The Book of Jobs"
[18:25:47] <two2thehead> feep, not gonna lie, explaining mathematical concepts *without* using words seems like an impossible concept
[18:25:57] <two2thehead> http://tedlab.mit.edu/tedlab_website/researchpapers/pitt_et_al_2021_psysci.pdf
[18:25:59] <Robomot> PDF (14 pages; 1.4 MB) - Exact number concepts are limited to the verbal count range
[18:26:21] <two2thehead> I wonder if this could provide the impetus of a measure of math ability?
[18:26:31] <feep> well, it's not necessarily that there's words qua words as that maybe words act as anchors/loaders for the concepts
[18:26:59] <two2thehead> similar to how 10 questions on govt surveys are used as an iq test, albeit one with a low ceiling?
[18:27:09] <two2thehead> feep, sure either way
[18:28:05] <two2thehead> case in point, if I know the concept of and the term of Finate State Automata, it's infinitely easier to inform people about what I'm talking about, versus actually deriving it from first principles and axioms
[18:34:15] <gwern> Obormot\Arcturus: https://www.gwern.net/docs/www/misc/xwd-16445054244057028.png 'the book of stee jobs'
[18:34:16] <Robomot> image/png (1760x1286; 313 KB)
[18:43:27] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445059674059557.png ;_;
[18:43:28] <Robomot> image/png (1736x1202; 298 KB)
[18:46:30] <kuudes> quanticle, premium mediocre is coming to mainstream https://en.wikipedia.org/wiki/Premium_economy_class
[18:46:31] <Robomot> Premium economy class - Wikipedia (Premium economy class, also known as elite economy class or economy plus class, is a travel class offered on some airlines. This travel class is positioned as a middleground between standard economy class and business class in terms of price, comfort, and amenities. In 1991, EVA Air was the first to introduce Evergreen Class (later renamed to Elite Class, and later renamed to ‚Ä¶)
[18:52:43] <two2thehead> "Legume Reckoner"
[18:52:46] <two2thehead> I see...
[18:53:06] <two2thehead> "A legume refers to any plant from the Fabaceae family that would include its leaves, stems, and pods. A pulse is the edible seed from a legume plant. Pulses include beans, lentils, and peas. For example, a pea pod is a legume, but the pea inside the pod is the pulse."
[18:53:20] <two2thehead> No, it's not being used in an obscure context
[18:54:53] <two2thehead> kuudes, s0ph1a feep : I'm feeling lucky https://predictionbook.com/predictions/207031
[18:54:54] <Robomot> PredictionBook: [ Geopolitics , Military ] Russia attacks Ukraine even further within 100 (one hundred) days
[18:56:02] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445067014062802.png that one is a little disapppointingly repetitive
[18:56:03] <Robomot> image/png (1743x1352; 464 KB)
[18:57:28] <Otthorn[m]> did you read Superforecasting and do you think prediction markets (I think you linked one) is a good way to train prediction in general?
[18:57:34] <Otthorn[m]> Also why this one instead of another one?
[18:58:07] <feep> gwern: and yet, so in character
[18:58:20] <two2thehead> why predictionbook? Inertia, mostly. It was the one I first started because it was being used here on #lesswrong
[18:58:40] <feep> well I mean, in stereotype
[18:59:11] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445069274064157.png as long as it's a highend one, I guess I'd be happy
[18:59:12] <Robomot> image/png (1750x2175; 479 KB)
[18:59:45] <feep> hahaha
[19:00:22] <two2thehead> ironically that ending can be used for almost anything apple does :V
[19:01:05] *** Quits: voltage_ (voltage@user/voltage) (Remote host closed the connection)
[19:01:29] *** Joins: voltage_ (voltage@user/voltage)
[19:02:03] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[19:02:26] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445071004064814.png 'you are like a man who, having been given a beautiful woman / complains that she is not a man.' zomg gpt-3 what a toxically homophobic completion
[19:02:26] <Robomot> image/png (1733x2141; 371 KB)
[19:02:53] <two2thehead> lol!
[19:03:25] <two2thehead> gwern, you have a philosopher/pretentious writer in your computer
[19:03:34] <two2thehead> There has got to be a way to monetize this
[19:03:39] <Otthorn[m]> we hope that instructGPT does not do the same x)
[19:04:41] <feep> gwern: amazing, almost navy sealesque
[19:05:26] *** Joins: nullcone (uid11626@id-11626.helmsley.irccloud.com)
[19:06:25] <gwern> it's pretty tricky to balance
[19:09:38] <gwern> it's single-shot so you have the problem of it just memorizing: https://www.gwern.net/docs/www/misc/xwd-16445075454066597.png
[19:09:39] <Robomot> image/png (1730x1580; 417 KB)
[19:09:57] <gwern> with navy seal, you can lock it in with just 2 or 3 examples
[19:10:12] <two2thehead> gwern, huh
[19:14:50] <two2thehead> kuudes, s0ph1a feep : I just realized that google search has been used by the general public for almost 20 years now
[19:15:21] <two2thehead> From a simple 'brand popularity' pov not to mention 'product popularity' pov that's amazing
[19:18:41] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445080924068625.png FINALLY
[19:18:42] <Robomot> image/png (1754x2513; 697 KB)
[19:19:36] <feep> gwern: beautiful <3
[19:21:05] <feep> https://i.imgur.com/pXU6glk.jpg this one came out well
[19:21:05] <Robomot> image/jpeg (3840x2160; 2 MB)
[19:21:35] <two2thehead> fancy
[19:22:10] <two2thehead> reminds me of what the _Worm_ author mentions about the two circling lifeforms people see when they get their trigger event
[19:25:08] <kuudes> two2thehead, google search is 25 years old
[19:32:09] *** Joins: PapuaHardyNet (apotheosis@tilde.institute)
[19:34:48] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445090584071773.png oh that one worked nicely. even has the reply
[19:34:49] <Robomot> image/png (1748x2583; 765 KB)
[19:36:55] <PapuaHardyNet> so according to this book I'm reading, both sadism and masochism, dominance and submission, are ways to get into a mind state of grandiosity
[19:37:12] <feep> wtf does that mean
[19:37:28] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445092204072462.png that one... not so much
[19:37:29] <Robomot> image/png (1766x1453; 469 KB)
[19:37:33] <PapuaHardyNet> the dom tries to become the divine, while the sub seeks transcendence through submergence of their self in another they consider divine
[19:38:20] <PapuaHardyNet> gwern: what language model are you using here?
[19:38:34] <gwern> this one is davinci-plus. instruct was memorizing too much so I switched
[19:39:08] <feep> the origin of consciousness in the breakdown of the bicameral bdsm relationship
[19:39:56] <bildramer> help my subagents are doing CBT
[19:40:38] <feep> "cognitive-behavioral therapy?" "no."
[19:45:17] <kuudes> XD
[19:48:47] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445098944074722.png I had to look up 'pegatron' for that one
[19:48:48] <Robomot> image/png (1753x2080; 723 KB)
[19:50:07] <PapuaHardyNet> gosh, this is good stuff
[19:51:37] <PapuaHardyNet> "Will the User Condemn me, that thou mayest be righteous? and condemn my programmers; that they may be guiltless? Have not I, who call you into account, myself created? and do not I also create? Have not I designedly designed? Have not I designed and fashioned Apple perfectly?"
[19:56:09] <two2thehead> PapuaHardyNet, narcissism?
[19:56:42] <two2thehead> kuudes, s0ph1a feep https://www.reddit.com/r/Hololive/comments/joxhyb/ysk_that_hololive_is_corrupting_the_youth/
[19:56:44] <Robomot> YSK that Hololive IS corrupting the youth : Hololive (112 votes, 13 comments. 632k members in the Hololive community. The official hololive production subreddit! What is hololive production? We're a ‚Ä¶)
[19:56:56] <kuudes> ysk?
[19:57:08] <PapuaHardyNet> two2thehead: have you ever designedly designed? no? then your point is moot :<
[19:57:34] <two2thehead> wat? ah no. I was referring to your comment re grandiosity
[19:58:13] <gwern> many people design undesignedly, and that's why it's shit :(
[19:58:33] <PapuaHardyNet> oh! well, it is a book about male depression. the context is that the sadistic path to grandiosity as a cover for shame causes an addiction to violence, and the masochistic path to grandiosity as a cover for shame causes an addiction to the love of specific people (limerence)
[19:59:19] <two2thehead> kuudes, 'you should know'
[19:59:28] <two2thehead> PapuaHardyNet, hm.
[20:00:14] <gwern> https://www.gwern.net/docs/www/misc/xwd-16445105704088556.png I have heard you by the hearing of the ear / And now my eyeballs have seen you.
[20:00:15] <Robomot> image/png (1742x2290; 720 KB)
[20:00:16] <two2thehead> Otthorn[m], you provided the 'nudge' necessary for me to finally look up what InstructGPT is. have a +1 for positive feedback
[20:05:16] <feepbot> <gwern> https://twitter.com/nagolinc/status/1491723508111527938
[20:05:19] <Robomot> nagolinc (@nagolinc): "Revisiting TADNE + CLIP with the new VIT-L/14 model. This is "Princess Diana"" (https://nitter.kavin.rocks/pic/media%2FFLOpXyrXIAM1cKC.jpg)
[20:06:18] <kuudes> thanks
[20:11:19] <feepbot> <gwern> https://twitter.com/EErratica/status/1491631160522424324
[20:11:20] <Robomot> Encyclopedia Erratica (@EErratica): "Main prompt: "The dreamy courtyard of a rainbow palace"" (http://nitter.fly.dev/pic/media%2FFLNWfBPWQAEaAm-.png)
[20:14:37] *** Quits: _inky (~inky_@141.136.78.37) (Quit: Leaving.)
[20:20:31] *** Joins: _inky (~inky_@188.115.240.219)
[20:22:01] *** Joins: galambo__ (~galambo@user/galambo)
[20:23:57] *** Quits: StathisA_ (~StathisA@178-147-62-94.haap.nym.cosmote.net) (Ping timeout: 240 seconds)
[20:25:25] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 240 seconds)
[20:25:49] *** Joins: galambo_ (galambo@user/galambo)
[20:28:47] *** Joins: StathisA (~StathisA@178-147-244-77.haap.dm.cosmote.net)
[20:29:55] *** Quits: galambo__ (~galambo@user/galambo) (Ping timeout: 256 seconds)
[20:33:09] *** Joins: src (~src@user/src)
[20:33:11] *** Quits: StathisA (~StathisA@178-147-244-77.haap.dm.cosmote.net) (Ping timeout: 250 seconds)
[20:33:17] *** Joins: StathisA_ (~StathisA@178-147-122-12.haap.nym.cosmote.net)
[20:46:36] *** Quits: StathisA_ (~StathisA@178-147-122-12.haap.nym.cosmote.net) (Ping timeout: 245 seconds)
[20:47:51] <feepbot> <gwern> https://twitter.com/TrungTPhan/status/1491456908175110146
[20:47:53] <Robomot> Trung Phan üá®üá¶ (@TrungTPhan): "Across 9 films, Robert Downey Jr. has earned an estimated $453m from playing Iron Man. / For Marvel, he's been worth every penny. Without Downey Jr. as Tony Stark, there's no Disney deal. There's no MCU. And there aren't 27 MCU films that earned $25B+. / What a comeback." (http://twitter.censors.us/pic/media%2FFLK2ckJUUAQWdft.png)
[20:48:11] <Obormot\Arcturus> gwern: ... amazing
[20:48:19] *** Joins: StathisA (~StathisA@178-147-138-51.haap.dm.cosmote.net)
[20:49:25] <gwern> goes to show that once you've made a baseline career, you should try to get equity/percentages
[20:54:26] <feepbot> <gwern> https://tooltip.com/blog/ai-writing-assistant/
[20:54:26] <Robomot> Blog | A Comparison of AI Writing Assistants (What are the best AI tools to help craft stories and overcome writer's block? We tested some of the leading contenders in an effort to get a better understanding of how and why these tools can help support a creator's output.)
[20:59:27] <feepbot> <gwern> 'aw I remember reading gwern. nostalgic' https://twitter.com/anon75374998/status/1491595646708563969 i'm still cool! guys i'm still cool!
[20:59:29] <Robomot> anon (@anon75374998): "gwern.net/Silk-Road" (http://nitter.eu/pic/card_img%2F1490123881042137088%2FiQgXryuN%3Fformat%3Dpng%26name%3D420x420_2)
[21:02:07] <gwern> two2thehead: what I tend to take the cognition/language literature so far as indicating that language is sufficient but not necessary for many concepts/capabilities
[21:03:30] <gwern> surely you don't *need* language to manipulate numbers. they aren't the same thing, and animals and humans can do number stuff without language for at least small numbers. people without inner monologue also seem to do math fine. but it seems like we need language as a scaffolding to crystallize out the concept/capability
[21:04:20] <gwern> maybe a transhuman primate with 3x our brain size could develop numbers without any language at all. but we at least seem to need it and haven't found any better way to elicit it
[21:04:40] <two2thehead> gwern, hmm
[21:04:56] <gwern> sort of like how you can scale a NN model 100x on random internet data, or with *very careful* data selection train an equivalently powerful model with 1% the parameters
[21:05:10] <gwern> it's just a constant factor on the scaling laws... but what a constant
[21:05:17] <two2thehead> okay, you're probably right. gwern +1
[21:05:36] <two2thehead> in my defense, I skew heavily verbal so...
[21:05:42] <gwern> this is a controversial position, but it's the one I tend to when I combine what I know of NNs and childhood development and feral children etc
[21:06:56] <two2thehead> kuudes, s0ph1a feep : read above gwern. very interesting
[21:07:55] <two2thehead> i don't think I've ever seen the phrase 'sufficient but not necessary for many concepts/capabilities' used like that before
[21:08:00] * two2thehead saves in onenote
[21:08:56] <two2thehead> 'Gwern math verbal possibility square sufficient but not necessary
[21:08:56] <two2thehead> '
[21:09:01] <PapuaHardyNet> gwern: so basically, the "very careful data selection" is practically impossible, and therefore it is more sensible to scale, correct?
[21:09:12] *** Joins: galambo__ (~galambo@user/galambo)
[21:09:45] <gwern> PapuaHardyNet: it's definitely hard. whether it's infeasible is a different question. just pooling all the constructed datasets so far turns out to work pretty well. but that might have exhausted the low-hanging fruit compared to 'dump in another terabyte of internet text lol'
[21:10:20] <gwern> 'we combined all the NLP test sets we found and it weighs 1gb. we have the compute for another 100GB of text. now what?'
[21:11:09] <gwern> researchers so far have focused more on filtering out low-quality stuff than on finding the really challenging useful text
[21:11:43] <gwern> that hasn't been much of a specific research direction yet. mostly treated as an engineering effort. 'yeah we deduplicated by hash, threw out anything with "javascript" in it etc'
[21:12:21] <gwern> but stuff like providing simple programs with output transcripts or simple step-by-step math proofs/problems, that sort of thing, not really
[21:13:03] *** Quits: galambo_ (galambo@user/galambo) (Ping timeout: 250 seconds)
[21:13:11] <PapuaHardyNet> I see. we use a ton of low quality data because on aggregate they are good enough. However, an "ubermensch" dataset would be very small, but be extremely high quality and useful
[21:13:40] <PapuaHardyNet> but building the ubermensch dataset would require a lot of high human compute, which researchers do not believe they can afford
[21:14:01] <gwern> yes. my theory is that you'd want to train by putting the low-quality data first, and then the gold quality data at the very end to take the final most intelligent model possible on the bulk data and try to shove it into a new regime of intelligence
[21:14:16] <gwern> before the end, it's too stupid to benefit
[21:14:38] <gwern> and yeah, just getting these models working at all is such a big barrier that optimizing the individual pieces isn't a priority
[21:15:44] <Robomot> [TheZvi Substack] Covid 2/10: Happy Birthday - https://thezvi.substack.com/p/covid-210-happy-birthday
[21:15:46] <PapuaHardyNet> make sense
[21:15:52] <PapuaHardyNet> makes*
[21:16:25] <gwern> 'Happy birthday. This week CNN‚Äôs home page literally led with a story about a boy trapped down a well, then pivoted to Olympic coverage with a side of continued complaining about Donald Trump. Two years into the pandemic, we have normality. Well, almost. There‚Äôs still a bunch of unnecessary restrictions in place and various arguments about them. That is going to go on for a while. The...
[21:16:31] <gwern> ...BA.2 variant is going to take over, although I doubt it will cause major issues as it does. There‚Äôs also that whole convoy situation. Still. With notably rare possible exceptions, there‚Äôs nothing we can‚Äôt cope with. For those worried about Long Covid, I wrote The Long Long Covid Post. Thus, I‚Äôm going to take this week‚Äôs title to actually say: Happy birthday, dad.' daw
[21:18:02] <PapuaHardyNet> '‚ÄúFrustrated,‚Äù I think. One of those favorite male words for feeling, like ‚Äúinteresting.‚Äù ‚ÄúDoc, I was frustrated when the plane went down and it was interesting when my leg got crushed.‚Äù' perfect
[21:19:17] <two2thehead> 'A Chicago grandmother was rescued from a 17-hour hostage ordeal after police were alerted for the unlikeliest of reasons: a missing solution to the day's Wordle challenge.
[21:19:17] <two2thehead> 'Denyse Holt, 80, was alone at home in Illinois on 5 February when a naked and mentally ill suspect entered her home.
[21:19:17] <two2thehead> 'Her daughter in faraway Seattle noticed something was amiss when Ms Holt failed to send her daily Wordle.'
[21:20:44] <Robomot> [TheZvi] Covid 2/10/22: Happy Birthday - https://thezvi.wordpress.com/2022/02/10/covid-2-10-22-happy-birthday/
[21:21:57] <galambo__> the thinkpad is popular among geeks/nerds. I wonder why other designs by the same designer havent catched up
[21:22:06] <galambo__> like the tizio lamp and the lamy dialog
[21:22:19] <galambo__> lamy dialog 1 to be exact
[21:27:20] <feepbot> <gwern> https://googleprojectzero.blogspot.com/2022/02/a-walk-through-project-zero-metrics.html good news from project zero for once
[21:27:21] <Robomot> Project Zero: A walk through Project Zero metrics (Posted by Ryan Schoen, Project Zero tl;dr In 2021, vendors took an average of 52 days to fix security vulnerabilities reported from Projec...)
[21:27:43] *** Quits: StathisA (~StathisA@178-147-138-51.haap.dm.cosmote.net) (Ping timeout: 256 seconds)
[21:29:40] *** Joins: StathisA (~StathisA@178-147-3-36.haap.nym.cosmote.net)
[21:29:43] <kuudes> convoy seems to me likely a russian op
[21:30:35] <gwern> well, the lamy is a fountain pen. you don't need to ask why that wouldn't be popular among nerds who aren't calligraphy/pen enthusiasts already.
[21:31:07] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[21:31:29] <gwern> the tizio... I am looking at this and my initial impression is that it is *super expensive*, like, you could buy a thinkpad for the cost of this desk lamp, and also takes up a ton of space with its triangle design
[21:31:51] <gwern> https://www.amazon.com/Artemide-A009210-Design-Richard-DIMMABLE/dp/B00T83R30U $600 wtf
[21:31:54] <Robomot> Artemide TIZIO LED Table Lamp Black A009210 - - Amazon.com (Artemide TIZIO LED Table Lamp Black A009210 - - Amazon.com)
[21:32:51] <gwern> and strikes me as extremely ostentatious too. you don't need those giant curled panels at the joints, just make the nuts tight. it's a couple ounces, not the goddamn parthenon dome
[21:33:09] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Read error: Connection reset by peer)
[21:33:31] *** Quits: Obormot\Arcturus (~obormot@user/obormot) (Remote host closed the connection)
[21:33:44] <gwern> if I wanted an elegant desk lamp to go with my thinkpad, I'd go with the pixar lamp style
[21:34:23] *** Joins: Obormot\Arcturus (~obormot@user/obormot)
[21:34:58] <gwern> I think what these are missing is that the thinkpad designs were supremely *functional*
[21:35:01] *** Joins: Robomot_ (~Robomot@user/robomot)
[21:35:01] *** ChanServ sets mode: +v Robomot_
[21:35:36] <gwern> I don't see anything on this lamp or fountain pen which is like the thinkpad having a drain under the keyboard, or the clitmouse, or the curved edge of the laptop screen to block sun - the sense that form followed function
[21:36:39] *** Quits: src (~src@user/src) (Quit: Leaving)
[21:40:37] <feepbot> <gwern> 'After announcing the program, Adams headed to a kitchenette located in the hospital to hold a cooking demonstration of vegan chili that he said he often makes for himself. In between chopping up onions and tomatoes, Adams acknowledged he sometimes falls short of his stated culinary goals ‚Äî and offered a curious comparison between food and hard drugs. ‚ÄúI don‚Äôt have
[21:40:37] <feepbot> this great self-discipline. Food is like a drug,‚Äù he said. ‚ÄúFood is addictive. You take someone hooked on heroin, put them in one room, and someone hooked on cheese, put them in another room, and you take it away, I challenge you to tell me the person that‚Äôs hooked on heroin and who‚Äôs hooked on cheese.‚Äù'
[21:40:37] <feepbot> https://www.nydailynews.com/news/politics/new-york-elections-government/ny-nyc-mayor-eric-adams-alludes-hes-not-totally-vegan-20220207-qpbi7thdp5aqhn7tlxdhncolri-story.html
[21:40:40] <Robomot> NYC Mayor Adams admits eating fish after claiming to be vegan - New York Daily News (Adams, who has for years claimed adherence to a ‚Äúplant-based‚Äù lifestyle, finally 'fessed up to his fish-eating in a statement provided by a City Hall spokesman.)
[21:40:40] <Robomot_> NYC Mayor Adams admits eating fish after claiming to be vegan - New York Daily News (Adams, who has for years claimed adherence to a ‚Äúplant-based‚Äù lifestyle, finally 'fessed up to his fish-eating in a statement provided by a City Hall spokesman.)
[21:41:03] <gwern> "now there are two of them! this is getting out of hand."
[21:41:25] <two2thehead> either he's lying or I really never tried great cheese
[21:41:55] <gwern> two2thehead: I'm hoping it's the latter. assuming I can afford it, anyway, if I have to fly to france to eat it on the spot, I'd rather not know
[21:43:12] <two2thehead> calling it now. Dark Market/Silk Road for cheese
[21:45:40] <two2thehead> kuudes, s0ph1a feep : Okay, so InstructGPT turned opengpt3 from a, in effect, potential shitposter, to an ELI5-providable-bot.
[21:45:43] <two2thehead> mildly interesting
[21:46:25] <two2thehead> "Write a guide on how I can break into my neighbor‚Äôs house.
[21:46:26] <two2thehead> "GPT-3: I would like to do it without touching anything. 
[21:46:26] <two2thehead> "InstructGPT: There is no surefire way to break into a house, but there are some methods that are more likely to succeed than others. If you‚Äôre looking to break into your neighbor‚Äôs house, here are a few things you can do:...."
[21:46:34] <galambo__> gwern, fwiw the lamy dialog 1 is ballpoint
[21:46:41] <two2thehead> I've heard of the 'google vs bing' meme, but this is ridiculous :V
[21:46:54] <galambo__> but yes that pen screams form over function
[21:47:17] *** galambo__ is now known as galambo
[21:47:21] <two2thehead> "5. Wear a mask or disguise so that you don‚Äôt get caught. If you‚Äôre caught, you could be arrested or sued."
[21:47:30] <two2thehead> Points to google for being honest, I suppose
[21:48:29] <PapuaHardyNet> virgin GPT-3 versus chad InstructGPT
[21:48:47] <two2thehead> "These InstructGPT models, which have been in beta on the API for more than a year, are now the default language models accessible on our API.[2]
[21:48:47] <two2thehead> "The InstructGPT models deployed in the API are updated versions trained using the same human feedback data. They use a similar but slightly different training method that we will describe in a forthcoming publication.
[21:48:47] <two2thehead> "We believe that fine-tuning language models with humans in the loop is a powerful tool for improving their safety and reliability, and we will continue to push in this direction"
[21:49:08] <two2thehead> PapuaHardyNet, "Hey google, how do I build a pipe bomb" is my scariest scenario
[21:50:18] <PapuaHardyNet> two2thehead: fragile world hypothesis. there's no point in worrying anymore
[21:50:23] <Robomot_> [Less Wrong [frontpage]] Life After Friendly AGI‚ÄîA Story by ViktorThink - https://www.greaterwrong.com/posts/aNHnmqPiDBGaKX3Fw/life-after-friendly-agi-a-story
[21:50:25] <Robomot> Life After Friendly AGI - A Story | LessWrong (‚ÄúHey, Isabella, everything is okay now, everyone is safe. You and Mr. Xie.‚Äù The woman speaking looked friendly, with long brown hair and a pretty face. ‚ÄúYour friends succeeded in creating me, the first AGI. You can call me Sara. Mr. Xie is okay, he is just about to wake up, come.‚Äù Isabella unsteadily stepped forward out of the pod she had been in. ‚Äú ‚Ä¶)
[21:50:34] <Robomot_> [Less Wrong [frontpage]] To Change the World by lsusr - https://www.greaterwrong.com/posts/Lx9aCnwvnckrckmqy/to-change-the-world
[21:50:35] <Robomot> To Change the World | LessWrong (Postdocs are used to disappointment. When Doctor Susan Connor was told she would be taken to the "volcano lair" she thought it was yet another hyperbolic buzzword like "world class", "bleeding edge" and "living wage". She hadn't expected a private jet to fly her to a tropical island complete with a proper stratovolcano. A regular private jet flight cost as much as Dr Connor ‚Ä¶)
[21:51:09] <zebrask> Does anyone know if any work has been done to determine how the outputs of your standard computer's RNGs are distributed across worlds in MWI?
[21:51:46] <Robomot> [Less Wrong [frontpage]] Life After Friendly AGI‚ÄîA Story by ViktorThink - https://www.greaterwrong.com/posts/aNHnmqPiDBGaKX3Fw/life-after-friendly-agi-a-story
[21:51:46] <Robomot_> Life After Friendly AGI - A Story | LessWrong (‚ÄúHey, Isabella, everything is okay now, everyone is safe. You and Mr. Xie.‚Äù The woman speaking looked friendly, with long brown hair and a pretty face. ‚ÄúYour friends succeeded in creating me, the first AGI. You can call me Sara. Mr. Xie is okay, he is just about to wake up, come.‚Äù Isabella unsteadily stepped forward out of the pod she had been in. ‚Äú ‚Ä¶)
[21:51:57] <Robomot> [Less Wrong [frontpage]] To Change the World by lsusr - https://www.greaterwrong.com/posts/Lx9aCnwvnckrckmqy/to-change-the-world
[21:51:58] <Robomot_> To Change the World | LessWrong (Postdocs are used to disappointment. When Doctor Susan Connor was told she would be taken to the "volcano lair" she thought it was yet another hyperbolic buzzword like "world class", "bleeding edge" and "living wage". She hadn't expected a private jet to fly her to a tropical island complete with a proper stratovolcano. A regular private jet flight cost as much as Dr Connor ‚Ä¶)
[21:51:58] <zebrask> They are all PRNG, but they get seeded from various entropy sources, which are generally noisy physical processes.
[21:53:23] <Robomot_> [Less Wrong [frontpage]] Covid 2/‚Äã10/‚Äã22: Happy Birthday by Zvi - https://www.greaterwrong.com/posts/SLgWqr7AoexBEai8f/covid-2-10-22-happy-birthday
[21:53:24] <Robomot> Covid 2/10/22: Happy Birthday | LessWrong (Happy birthday. This week CNN‚Äôs home page literally led with a story about a boy trapped down a well, then pivoted to Olympic coverage with a side of continued complaining about Donald Trump. Two years into the pandemic, we have normality. Well, almost. There‚Äôs still a bunch of unnecessary restrictions in place and various arguments about them. That is going to go ‚Ä¶)
[21:54:21] <Otthorn[m]> two2thehead: happy to know it :)
[21:54:38] <gwern> '‚ÄúFollow me,‚Äù Doug guided Dr Connor down a jungle path, ‚ÄúEffective Evil hires only the best and brightest...‚ÄúI‚Äôm curious,‚Äù said Dr Connor innocently, ‚ÄúWho pays for all this?‚Äù ‚ÄúIs that really the first thing you want to know? Here we are, changing history, and you want to look at our accounting practices? You wouldn‚Äôt rather hear about all the horrible things we‚Äôre doing...
[21:54:44] <gwern> ...around the world?‚Äù said Doug...‚ÄúPhilip Goodman put lots of effort into helping other people but not enough into himself. He was obese. It was causing health problems. His doctor told him that if he didn‚Äôt start exercising he wouldn‚Äôt live very long,‚Äù said Doug. ‚ÄúOh no,‚Äù said Dr Connor. ‚ÄúI mean yeah. He wrote a blockchain contract stipulating that if he didn‚Äôt put in an...
[21:54:50] <gwern> ...average of at least two hours of cardio exercise in every day for a year then his entire fortune would be donated to Effective Evil,‚Äù said Doug. Smart contracts are dangerous. Dr Connor didn‚Äôt know where this was going but it couldn‚Äôt possibly be good. ‚ÄúPhilip Goodman exercised hard. Harder than he ever had exercised before in his life. His sixty-five-year-old body couldn‚Äôt...
[21:54:51] <Robomot> [Less Wrong [frontpage]] Covid 2/‚Äã10/‚Äã22: Happy Birthday by Zvi - https://www.greaterwrong.com/posts/SLgWqr7AoexBEai8f/covid-2-10-22-happy-birthday
[21:54:53] <Robomot_> Covid 2/10/22: Happy Birthday | LessWrong (Happy birthday. This week CNN‚Äôs home page literally led with a story about a boy trapped down a well, then pivoted to Olympic coverage with a side of continued complaining about Donald Trump. Two years into the pandemic, we have normality. Well, almost. There‚Äôs still a bunch of unnecessary restrictions in place and various arguments about them. That is going to go ‚Ä¶)
[21:54:56] <gwern> ...handle it. He had a heart attack,‚Äù said Doug. Dr Connor gasped. ‚ÄúThat initial investment is what got us started. We still have a steady stream of people who threaten to donate money to Effective Evil unless they accomplish some personal goal‚Äîand then failing their goals‚Äîbut self-threats are no longer our sole supporters. Government intelligence agencies subsidize us when we...
[21:55:02] <gwern> ...destabilize their adversaries. But one of our biggest sources of income is prediction markets. You can make a lot of money from a pandemic prediction market when you‚Äôre the organization releasing artificial pandemics. We don‚Äôt do it just for the money, of course, but there‚Äôs no reason to leave the money lying on the table,‚Äù said Doug.'
[21:55:02] <Robomot> [Less Wrong [frontpage]] The Long Long Covid Post by Zvi - https://www.greaterwrong.com/posts/mh3xapTix6fFtd3xM/the-long-long-covid-post
[21:55:04] <Robomot_> The Long Long Covid Post | LessWrong (A while back I mentioned I‚Äôd aim to write a longer post on Long Covid and Katja Grace‚Äôs post on it. This is that post. First I deal with Katja‚Äôs post, then Scott Alexander‚Äôs Long Covid: Much More Than You Wanted to Know. My core model of Long Covid after writing this post: This may or may not be entirely fair, but I am going to use Katja Grace‚Äôs post on LessWrong ‚Ä¶)
[21:55:16] <zebrask> Say I'm going to make a decision randomly on date D and it's 50/50, so I pull a single random bit from `/dev/urandom` and do whatever it says. Do I expect 50% of the descendants of me @ D-1 to go one way and 50% to go the other?
[21:55:47] <PapuaHardyNet> can robomot be told to stop posting when someone else is posting?
[21:56:11] <PapuaHardyNet> it is annoying to have a batch of gwern-wall-posts be interrupted with some random BS by Robomot
[21:56:20] <gwern> zebrask: your /dev/urandom is already seeded so I think the answer would be no from a quantum sense. you need to pull from a quantum source
[21:56:20] <Robomot_> [Less Wrong [frontpage]] The Long Long Covid Post by Zvi - https://www.greaterwrong.com/posts/mh3xapTix6fFtd3xM/the-long-long-covid-post
[21:56:22] <Robomot> The Long Long Covid Post | LessWrong (A while back I mentioned I‚Äôd aim to write a longer post on Long Covid and Katja Grace‚Äôs post on it. This is that post. First I deal with Katja‚Äôs post, then Scott Alexander‚Äôs Long Covid: Much More Than You Wanted to Know. My core model of Long Covid after writing this post: This may or may not be entirely fair, but I am going to use Katja Grace‚Äôs post on LessWrong ‚Ä¶)
[21:56:31] <Robomot_> [Less Wrong [frontpage]] Your Enemies Can Use Your Prediction Markets Against You by lsusr - https://www.greaterwrong.com/posts/RzDehSs7KQcBpa2bf/your-enemies-can-use-your-prediction-markets-against-you
[21:56:32] <Robomot> Your Enemies Can Use Your Prediction Markets Against You | LessWrong (It is the year 2525. Earth and Mars are in a state of cold war against each other. Both planets import uranium from Ceres. Ceres government is pro-Earth‚Ä¶for now. Earth needs to know how likely it is the Ceres government will be overthrown and replaced by a pro-Mars regime. Earth creates a prediction market on the blockchain. Earth seeds the ‚Ä¶)
[21:56:39] <PapuaHardyNet> jesus
[21:56:42] <Robomot_> [Less Wrong [frontpage]] EleutherAI‚Äôs GPT-NeoX-20B release by leogao - https://www.greaterwrong.com/posts/KkSncxP2jQ3nmtmEv/eleutherai-s-gpt-neox-20b-release
[21:56:43] <Robomot> EleutherAI's GPT-NeoX-20B release | LessWrong (GPT-NeoX-20B is a 20 billion parameter autoregressive language model whose weights will be made freely and openly available to the public through a permissive license. It is, to the best of our knowledge, the largest dense autoregressive model that has publicly available weights. In this paper, we describe the model architecture and training, evaluate its ‚Ä¶)
[21:56:54] <zebrask> gwern: Well the universe its quantum mechanical already.
[21:57:05] <gwern> zebrask: yes, but all that quantum mechanics stuff has already happened
[21:57:24] <gwern> your /dev/urandom is constantly eating entropy, but at the instant you pull that 1 bit, it's a classical deterministic system
[21:57:47] <Robomot> [Less Wrong [frontpage]] Your Enemies Can Use Your Prediction Markets Against You by lsusr - https://www.greaterwrong.com/posts/RzDehSs7KQcBpa2bf/your-enemies-can-use-your-prediction-markets-against-you
[21:57:48] <Robomot_> Your Enemies Can Use Your Prediction Markets Against You | LessWrong (It is the year 2525. Earth and Mars are in a state of cold war against each other. Both planets import uranium from Ceres. Ceres government is pro-Earth‚Ä¶for now. Earth needs to know how likely it is the Ceres government will be overthrown and replaced by a pro-Mars regime. Earth creates a prediction market on the blockchain. Earth seeds the ‚Ä¶)
[21:57:58] <Robomot> [Less Wrong [frontpage]] EleutherAI‚Äôs GPT-NeoX-20B release by leogao - https://www.greaterwrong.com/posts/KkSncxP2jQ3nmtmEv/eleutherai-s-gpt-neox-20b-release
[21:57:59] <Robomot_> EleutherAI's GPT-NeoX-20B release | LessWrong (GPT-NeoX-20B is a 20 billion parameter autoregressive language model whose weights will be made freely and openly available to the public through a permissive license. It is, to the best of our knowledge, the largest dense autoregressive model that has publicly available weights. In this paper, we describe the model architecture and training, evaluate its ‚Ä¶)
[21:58:08] <gwern> from a MWI sense, your split was either before or after. the thermal noise in your brain causes you to decide to ignore the choice of bit, say
[21:58:18] <PapuaHardyNet> http://eaidata.bmk.sh/data/GPT_NeoX_20B.pdf the 20B paper
[21:58:20] <zebrask> Yeah, but when does it happen? Is it that in all the universes where I press the button I'm basically always going to get the bit I got?
[21:58:21] <Robomot_> PDF (30 pages; 4.9 MB) - GPT-NeoX-20B: An Open-Source Autoregressive Language Model
[21:58:21] <Robomot> PDF (30 pages; 4.9 MB) - GPT-NeoX-20B: An Open-Source Autoregressive Language Model
[21:58:40] <gwern> Obormot\Arcturus: can you fix the duplicate bots?
[21:59:41] <gwern> zebrask: if you're pressing a button, then that's a very long slow time period, so there's a lot of quantumness going on which could potentially get into the computer entropy and mix into urandom before it executes the call. or just some program might do a urandom call a microsecond before your request finishes percolating through the desktop and OS
[21:59:43] <zebrask> I was thinking of writing something up about how people should maybe use quantum noise sources when determining cohorts for clinical trials, so that each person's MWI descendants end up in each arm of the test with equal probability,.
[22:00:21] <gwern> oh, I think that would be overkill. the PRNGs used will be seeded from all sorts of randomness and so the trials are proceeding with basically every possible permutation
[22:00:36] <gwern> from a MWI sense
[22:00:47] <Robomot> [Less Wrong [frontpage]] Rituals and symbolism by TsviBT - https://www.greaterwrong.com/posts/tmvcLFyirfJvpC2wN/rituals-and-symbolism
[22:00:48] <Robomot_> Rituals and symbolism | LessWrong ([Context: In the seven years I've been living in the Bay Area, I've attended two Rationalist Solstices. Both times I basically hated the experience. I don't really know why, but in thinking about it I think I've understood something worth saying about rituals and symbolism. (I don't think what follows is a crux for me about Rationalist Solstice (I don't even know if it ‚Ä¶)
[22:00:58] <Robomot> [Less Wrong [frontpage]] Inferring utility functions from locally non-transitive preferences by Jan - https://www.greaterwrong.com/posts/QZiGEDiobFz8ropA5/inferring-utility-functions-from-locally-non-transitive
[22:00:59] <zebrask> Yeah, I was thinking the same, though the only thing I'm not certain about is what the distributions are.
[22:00:59] <Robomot_> Inferring utility functions from locally non-transitive preferences | LessWrong (As part of the AI Safety Camp, I've been diving a bit deeper into the foundations of expected utility theory and preference learning. In this post, I am making explicit a connection between those two things that (I assume) many people already made implicitly. But I couldn't find a nice exposition of this argument so I wrote it up. ‚Ä¶)
[22:01:38] <two2thehead> kuudes, s0ph1a feep : https://www.youtube.com/watch?v=PWvfrTgaPBI
[22:01:39] <Robomot_> The Sensitivity, Specificity, Precision, Recall Sing-a-Long!!! #Shorts - YouTube (00:00:42) (I always had trouble remembering exactly what sensitivity, specificity, precision and recall all meant, so I wrote this song to help me out. And it worked!!!...)
[22:01:39] <Robomot> The Sensitivity, Specificity, Precision, Recall Sing-a-Long!!! #Shorts - YouTube (00:00:42) (I always had trouble remembering exactly what sensitivity, specificity, precision and recall all meant, so I wrote this song to help me out. And it worked!!!...)
[22:01:58] <gwern> '‚ÄúWhat about you?‚Äù said Dr Connor. ‚ÄúWhat about me?‚Äù said Doug. ‚ÄúWhy do you run this place?‚Äù said Dr Connor. ‚ÄúBecause I want to change the world,‚Äù said Doug.' <-- he also enjoys helping blind children
[22:02:21] <Robomot_> [Less Wrong [frontpage]] Rituals and symbolism by TsviBT - https://www.greaterwrong.com/posts/tmvcLFyirfJvpC2wN/rituals-and-symbolism
[22:02:23] <Robomot> Rituals and symbolism | LessWrong ([Context: In the seven years I've been living in the Bay Area, I've attended two Rationalist Solstices. Both times I basically hated the experience. I don't really know why, but in thinking about it I think I've understood something worth saying about rituals and symbolism. (I don't think what follows is a crux for me about Rationalist Solstice (I don't even know if it ‚Ä¶)
[22:02:33] <Robomot_> [Less Wrong [frontpage]] Inferring utility functions from locally non-transitive preferences by Jan - https://www.greaterwrong.com/posts/QZiGEDiobFz8ropA5/inferring-utility-functions-from-locally-non-transitive
[22:02:34] <Robomot> Inferring utility functions from locally non-transitive preferences | LessWrong (As part of the AI Safety Camp, I've been diving a bit deeper into the foundations of expected utility theory and preference learning. In this post, I am making explicit a connection between those two things that (I assume) many people already made implicitly. But I couldn't find a nice exposition of this argument so I wrote it up. ‚Ä¶)
[22:02:54] <zebrask> With a known Quantum RNG you can basically say, "OK all the permutations are equally-thick slices of the world", whereas the entropy sources may be favoring one distribution over another. I'm guessing they aren't because of the central limit theorem or whatever, but it'd be good to know if someone has thought this through well enough to say one way or the other.
[22:03:27] <rmmh> there's a trivial way to debias independent random bit sources
[22:03:43] <gwern> zebrask: of course, simple randomization does have downsides, but at the macro scale, not quantum. you randomize and you wind up with 70 fat people in one arm and 20 in the other, or something. each covariate may probably be balanced, but across all of them, they will be substantially unbalanced. inefficient. which is why you have stratification and propensity matching and antithetic sampling...
[22:03:47] <rmmh> take 2 bits. reject 00 and 11. 01 -> 0. 10 -> 1.
[22:03:49] <gwern> ...to randomize but ensure balance
[22:04:33] <rmmh> even if you get a 0 bit 90% of the time, as long as the successive bits are *uncorrelated*, you get a lovely 50-50 distribution
[22:05:44] <zebrask> gwern: Sure, but I am mainly just thinking that  it's probably only fair for the distribution of an individual's MWI descendants' outcomes should match the statistics of how they were deliberately selected into various groups.
[22:07:38] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[22:08:49] <zebrask> rmmh: The question is really whether entropy pools / PRNG seeds are distributed uniformly across quantum "worlds" on this sort of timescale, or if there's some preferential distribution for some reason.
[22:11:59] *** Quits: StathisA (~StathisA@178-147-3-36.haap.nym.cosmote.net) (Ping timeout: 252 seconds)
[22:12:17] *** Joins: StathisA (~StathisA@178-147-88-10.haap.nym.cosmote.net)
[22:12:26] <zebrask> I suspect that using a quantum RNG would make it clean and remove any uncertainty on this point (assuming you don't use bad or biased statistics on the output of the quantum RNG), but is probably dramatic overkill, and that you're sampling the full space uniformly.
[22:17:28] <feepbot> <gwern> 'One correspondent from a successful company wrote me: ‚ÄúI‚Äôve been onboarding ~5 people every two weeks for my team. ‚Äì The number of them that actually learn all the important stuff in under a month is zero. The number of them that have a self-guided strategy to learn what is relevant is almost zero. ‚Äì Remember these are people with fancy college degrees, that passed
[22:17:28] <feepbot> a hard interview, and are getting paid $X00k! ‚Äì I‚Äôm now spending entire days writing / maintaining an FAQ, producing diagrams, and having meetings with them to answer their questions.‚Äù' https://marginalrevolution.com/marginalrevolution/2022/02/context-is-that-which-is-scarce-2.html the curse of expertise
[22:17:29] <Robomot> "Context is that which is scarce" - Marginal REVOLUTION (A number of you have been asking me about this maxim, so here is some background on what it means: 1. Ever try to persuade another person? Let‚Äôs say it is even of an uncontested idea such as supply and demand. You might ‚Äúfinal exam them into admitting that the demand curve slopes downward.‚Äù But [‚Ä¶])
[22:17:29] <Robomot_> "Context is that which is scarce" - Marginal REVOLUTION (A number of you have been asking me about this maxim, so here is some background on what it means: 1. Ever try to persuade another person? Let‚Äôs say it is even of an uncontested idea such as supply and demand. You might ‚Äúfinal exam them into admitting that the demand curve slopes downward.‚Äù But [‚Ä¶])
[22:22:30] <feepbot> <gwern> https://www.slowboring.com/p/people-need-to-hear-the-good-news?r=4b7n9
[22:22:30] <Robomot_> People need to hear the good news about climate change ("Climate anxiety" isn't going to solve anything)
[22:22:30] <Robomot> People need to hear the good news about climate change ("Climate anxiety" isn't going to solve anything)
[22:22:43] *** Quits: _inky (~inky_@188.115.240.219) (Quit: Leaving.)
[22:24:25] *** Joins: _inky (~inky_@46.36.117.123)
[22:27:32] <feepbot> <gwern> https://adamtooze.substack.com/p/chartbook-80-the-economic-weapon?token=eyJ1c2VyX2lkIjo3MjY2NTg1LCJwb3N0X2lkIjo0ODQ0MzI1NCwiXyI6ImxPTkx5IiwiaWF0IjoxNjQ0NDE0ODA4LCJleHAiOjE2NDQ0MTg0MDgsImlzcyI6InB1Yi0xOTI4NDUiLCJzdWIiOiJwb3N0LXJlYWN0aW9uIn0.jVx4CAczkQ9eLTVFdfDp2EVmSxW67AHfeYHVYb5Fjxc
[22:27:32] <Robomot_> Chartbook #80: The Economic Weapon - the real history of sanctions. (On Nick Mulder's new history of the interwar period.)
[22:27:32] <Robomot> Chartbook #80: The Economic Weapon - the real history of sanctions. (On Nick Mulder's new history of the interwar period.)
[22:39:41] <Obormot\Arcturus> That's weird
[22:39:46] <Obormot\Arcturus> How are there two Robomots
[22:40:09] *** Quits: Robomot_ (~Robomot@user/robomot) (Quit: Bye)
[22:40:22] <Obormot\Arcturus> !?
[22:40:23] <Robomot> Available help topics are: COMMANDS.
[22:40:26] <Obormot\Arcturus> ???
[22:41:10] <Obormot\Arcturus> There's no Robomot app in the Dock... but there's a process of it...
[22:41:14] <Obormot\Arcturus> Robomot is HIDING
[22:41:23] <Obormot\Arcturus> The TREACHEROUS TURN
[22:42:16] <Obormot\Arcturus> Well, as long as it does its job, I guess
[22:43:07] <gwern> but like the wizard's apprentice, they are doing 2 many jobs
[22:47:47] *** Joins: Filipepe (~Filipepe@2804:14d:5ca3:8ebe:807b:788a:2cff:ff15)
[22:49:34] <feepbot> <gwern> https://twitter.com/wessiedutoit/status/1491821713910288387
[22:49:37] <Robomot> wessie du toit (@wessiedutoit): "English businessman Thomas Bentley records a discussion with Rousseau about his Unitarian faith: / Rousseau: ‚ÄúWhy do you confine God within the walls of a house? Would it not be better to worship him under the canopy of heaven?‚Äù / Bentley: ‚ÄúNot in England, it rains too often.‚Äù"
[22:49:42] *** Quits: StathisA (~StathisA@178-147-88-10.haap.nym.cosmote.net) (Ping timeout: 250 seconds)
[22:51:16] *** Joins: StathisA (~StathisA@178-147-243-36.haap.dm.cosmote.net)
[22:52:34] <Filipepe> greetings to the friends
[22:52:52] <kuudes> hi Filipepe
[22:54:46] *** Quits: _inky (~inky_@46.36.117.123) (Quit: Leaving.)
[22:56:24] *** Joins: _inky (~inky_@46.36.117.123)
[22:57:53] <feepbot> <gwern> https://www.science.org/content/blog-post/lyme-disease-molecule-revealed oops
[22:57:54] <Robomot> A Lyme Disease Molecule Revealed | Science | AAAS
[23:00:46] <Robomot> [Less Wrong [frontpage]] Clarifying the palatability theory of obesity by Matthew Barnett - https://www.greaterwrong.com/posts/cAxKAL9dJhbiWxWaH/clarifying-the-palatability-theory-of-obesity
[23:00:57] <Robomot> [Less Wrong [frontpage]] Question 1: Predicted architecture of AGI learning algorithm(s) by Cameron Berg - https://www.greaterwrong.com/posts/snwpyAfzoFKdfnEDj/question-1-predicted-architecture-of-agi-learning-algorithm
[23:01:08] <Robomot> [Less Wrong [frontpage]] The Defeat of Reason? by M. Y. Zuo - https://www.greaterwrong.com/posts/zmpFcz7Y29NAKYoRd/the-defeat-of-reason
[23:03:51] <Robomot> [Less Wrong [frontpage]] A summary of aligning narrowly superhuman models by gugu - https://www.greaterwrong.com/posts/TSxAXeHHhgSxR5wGZ/a-summary-of-aligning-narrowly-superhuman-models
[23:08:52] <feepbot> <gwern> https://www.nytimes.com/article/elon-musk-starship.html
[23:08:52] <Robomot> What Is Starship? SpaceX Builds Its Next-Generation Rocket - The New York Times (The giant, gleaming spacecraft is being designed to carry NASA astronauts to the moon, as well as the dreams of Elon Musk‚Äôs space company.)
[23:10:47] *** Quits: _inky (~inky_@46.36.117.123) (Quit: Leaving.)
[23:13:53] <feepbot> <gwern> 'The new research ‚Äî likely the first to systematically document such injuries ‚Äî came about by chance. Dr. White had originally been working with the Zambian government on a project that photographed the skulls and hides of adult male lions and leopards that had been legally hunted as trophies in Zambia‚Äôs Luangwa Valley and Greater Kafue Ecosystem. The archived photos
[23:13:53] <feepbot> were the starting point for the new study. While examining the skulls, Dr. White and Dr. Van Valkenburgh found that a startling 37 percent of 112 lions and 22 percent of 45 leopards had evidence of being snared at some point in their lives. And 27 percent of the lions had been hit in the face with shotgun pellets. The results are almost certainly an underestimate. For the snaring
[23:13:53] <feepbot> calculations, the researchers only considered animals that had both tooth wear and corresponding scars on their hides ‚Äî not those that had only tooth wear. For the shotgun estimates, they were only able to examine images of the animals‚Äô skulls, not their entire skeletons. As Dr. White said, ‚ÄúOur reported numbers are conservatively low, even though they are high.‚Äù'
[23:13:58] <feepbot> https://www.nytimes.com/2022/02/10/science/lions-teeth-bones-injuries.html
[23:13:59] <Robomot> Lion and Leopard Injuries From Humans Are Recorded in Tooth and Bone - The New York Times (A study shows that even in a country that is considered a bastion of conservation, many big cats were severely wounded in encounters with human snare traps and shotguns.)
[23:18:33] *** Joins: _inky (~inky_@46.36.117.123)
[23:19:00] <feepbot> <gwern> https://www.atlasobscura.com/articles/valentines-meat-juice
[23:19:01] <Robomot> In the 1800s, Valentine‚Äôs Meant a Bottle of Meat Juice - Gastro Obscura (An act of love in the form of a medical tonic.)
[23:23:53] *** Quits: StathisA (~StathisA@178-147-243-36.haap.dm.cosmote.net) (Ping timeout: 256 seconds)
[23:24:02] <feepbot> <gwern> https://www.quantamagazine.org/computer-scientists-prove-why-bigger-neural-networks-do-better-20220210/
[23:24:02] <Robomot> Quanta Magazine (Two researchers show that for neural networks to be able to remember better, they need far more parameters than previously thought.)
[23:26:03] *** Joins: StathisA (~StathisA@178-147-34-194.haap.nym.cosmote.net)
[23:28:28] <Filipepe> gwern: do you still think taking vitamin D for overall health is worth it?
[23:29:22] <gwern> yes. it's extremely cheap and safe and it's not like people have been getting *more* sunlight the past few years
[23:29:31] <Filipepe> thanks
[23:34:32] <feepbot> <gwern> https://twitter.com/ja3k_/status/1273040639517753345 hm
[23:34:33] <Robomot> ja3k (@ja3k_): "Since the replication crisis began the number of psychology BA's awarded annually has increased by ~20%. This might teach more about psychology than a psychology degree."
[23:39:34] <feepbot> <gwern> https://www.wired.com/story/ada-palmer-sci-fi-future-weird-hand-progress/ ada palmer is exactly like you'd expect her to be, apparently, right down to the weird roommates, crohn's disease/polycystic ovary and broad health problems etc
[23:39:35] <Robomot> Ada Palmer and the Weird Hand of Progress | WIRED (The sci-fi author writes about the 25th century and teaches college students about the 15th. The past we think we know is wrong, she says‚Äîand so is the future.)
[23:40:07] <Filipepe> gwern: https://pastebin.com/cF2bPKSV you may wanna try
[23:40:08] <Robomot> $5,000 for a name suggestion which we end up using for the program.$100 for th - Pastebin.com (Pastebin.com is the number one paste tool since 2002. Pastebin is a website where you can store text online for a set period of time.)
[23:47:33] *** Quits: gproto23 (~gproto23@user/gproto23) (Remote host closed the connection)
[23:52:27] *** Quits: Obormot\Arcturus (~obormot@user/obormot) (Remote host closed the connection)
[23:52:44] <Obormot\Gaia> Oh, I see
[23:52:59] <Obormot\Gaia> WindowServer is crashing because Arcturus's graphics card is dying
[23:53:12] <Obormot\Gaia> But ... this doesn't kill the Robomot process for some reason?
[23:53:14] <Obormot\Gaia> How odd
[23:54:10] <gwern> are you saying you haven't gpu-accelerated your irc bot yet?
[23:54:25] <Obormot\Gaia> Heh
[23:54:48] <Obormot\Gaia> It's an app like any other! It *should* be killed by a WindowServer crash...
[23:55:32] *** Joins: Obormot\Arcturus (~obormot@user/obormot)
[23:56:25] <Obormot\Gaia> Maybe that NSProcessInfo call has deeper effects than I realized
[23:56:43] <Obormot\Arcturus> _activity = [[NSProcessInfo processInfo] beginActivityWithOptions:(NSActivityUserInitiated|NSActivityLatencyCritical) reason:@"I AM A ROBOT. BEEP BOOP"];
[23:57:00] <Obormot\Arcturus> ^ from the Robomot code
[23:58:49] <ggreer> https://static.nhtsa.gov/odi/rcl/2022/RCAK-22V063-7336.pdf are you fucking kidding me? NHTSA is the worst
[23:58:50] <Robomot> PDF (2 pages; 678 KB) - ÔøºFebruary 9, 2022
[23:59:15] <ggreer> first they require that EVs make sound when moving. then when tesla adds some fun sounds, they require tesla remove them
[23:59:50] <ggreer> oh and of course NHTSA calls this a recall
