[00:17:30] *** Quits: ec_ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[00:28:00] *** Joins: ec_ (~ec@gateway/tor-sasl/ec)
[00:36:49] *** Quits: shka (~herr@109.231.62.239) (Ping timeout: 252 seconds)
[01:01:04] *** LispyLights is now known as Aurora_v_kosmose
[01:01:42] *** Quits: ec_ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[01:11:31] *** Joins: razzy (~razzy@user/razzy)
[01:11:56] *** Joins: ec_ (~ec@gateway/tor-sasl/ec)
[01:33:28] *** Joins: CrashTestDummy3 (~CrashTest@ool-ad02813b.dyn.optonline.net)
[01:36:49] *** Quits: CrashTestDummy2 (~CrashTest@ool-ad02813b.dyn.optonline.net) (Ping timeout: 252 seconds)
[01:47:12] *** Quits: ec_ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[01:52:05] *** Quits: selwyn (~selwyn@user/selwyn) (Read error: Connection reset by peer)
[01:52:15] *** Joins: ec_ (~ec@gateway/tor-sasl/ec)
[02:21:31] *** Quits: minion (~minion@common-lisp.net) (Remote host closed the connection)
[02:21:36] *** Joins: dec0d3r (~dec0d3r@2001:8003:4810:9600:7275:1afb:1707:8eaa)
[02:23:44] *** Joins: minion (~minion@common-lisp.net)
[02:28:15] *** Joins: v3ga (~cyberocto@c-73-39-172-34.hsd1.md.comcast.net)
[02:32:42] *** Quits: ec_ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[02:37:46] *** Joins: ec_ (~ec@gateway/tor-sasl/ec)
[03:03:15] *** Quits: ec_ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[03:09:30] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[03:16:10] *** Quits: v3ga (~cyberocto@c-73-39-172-34.hsd1.md.comcast.net) (Ping timeout: 240 seconds)
[03:38:59] *** Joins: CrashTestDummy2 (~CrashTest@ool-ad02813b.dyn.optonline.net)
[03:42:13] *** Quits: CrashTestDummy3 (~CrashTest@ool-ad02813b.dyn.optonline.net) (Ping timeout: 252 seconds)
[03:58:02] <hayley> https://www.youtube.com/watch?v=N6KmkAPWx98
[03:58:02] -ixelp- Conversation (Live 1980) - YouTube
[04:00:21] <dave0> maw
[04:00:54] *** Joins: v3ga (~cyberocto@c-73-39-172-34.hsd1.md.comcast.net)
[04:01:11] <hayley> Hey dave0
[04:03:38] <dave0> hi hayley, how's it going?
[04:03:57] <hayley> Fine, how are you?
[04:04:12] <dave0> alright, it's payday today
[04:16:36] *** Joins: lad (~lad@user/lad)
[04:18:39] <hayley> gilberth: https://gist.github.com/no-defun-allowed/63fdbec5074ae054c011a0636be7e135
[04:18:39] -ixelp- Notes on Pauseless Immix with Thread-Local Heaps (sometimes) · GitHub
[04:28:25] *** Quits: random-nick (~random-ni@87.116.165.220) (Ping timeout: 252 seconds)
[04:31:01] *** Quits: v3ga (~cyberocto@c-73-39-172-34.hsd1.md.comcast.net) (Ping timeout: 244 seconds)
[04:33:50] <hayley> Hm, I wonder if I could change the object representation so that all the xxxxx..11 values are heap allocated, and everything else is immediate. That keeps 00 and 10 for fixnums and 01 for floats and characters I guess.
[04:35:31] <hayley> Won't work, there's three types of heap allocated value (cons, standard object, rack) and I'd get in trouble for 16-byte alignment surely.
[04:38:51] <hayley> Though racks aren't objects, and they don't escape functions, so surely we could eliminate a tag for them, making everything work.
[04:39:14] *** Joins: v3ga (~cyberocto@c-73-39-172-34.hsd1.md.comcast.net)
[04:49:43] <moon-child> hm, would 16-byte alignment be so terrible?  Conses and standard objects are both two words, so there'd be no cost to making them 16-byte-aligned anyway
[04:51:59] <hayley> True. And we'd only waste, what, 33% overhead on a vector of 3 elements at worst.
[04:56:09] <hayley> It'd also reduce straddling cache lines, too. And IIRC SBCL allocates with 16 byte alignment already?
[04:58:10] <hayley> Yes, SBCL uses four bit tags.
[04:58:13] <moon-child> the only problem is, increasing alignment also leaves extra tag space just _asking_ to be used.  Functions, specialised vectors...--and then it's the same problem again
[04:59:40] <hayley> Right. The SBCL internals manual communicates it well enough, though we don't have "wide tags" or function pointers, and we don't have a NIL-cons hack.
[05:00:47] <moon-child> what's a wide tag?  Tag is variable-width?
[05:01:00] <hayley> Dunno, sorry.
[05:11:56] <moon-child> hmm.  Looks like 6? overall tag bits for non-conses?  Docs and code are not super clear
[05:12:19] <hayley> For SICL or SBCL?
[05:13:00] <moon-child> sbcl
[05:15:51] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[05:17:49] <hayley> After making the tag bits more regular, the read barrier code is still pretty miserable. It has one branch instead of two, but still a mess.
[05:23:51] <moon-child> considered cmov over the branch?  Maybe slightly bigger code, maybe worth it
[05:24:59] <hayley> That could work. And CMOV doesn't do a load if the test fails?
[05:25:05] <moon-child> I was thinking recently about similarly using faults to do branchfree boundschecking.  Btb bloat and inflight-branch limit is a worry, though I don't know how well founded
[05:25:23] <moon-child> hayley: no I mean, loading a register with a known-good pointer and then conditionally overwriting it
[05:26:03] <hayley> Okay. The Intel manual states that a move is not performed if the test fails, so it should be fine to avoid faulting.
[05:26:17] <moon-child> that's (good) news to me!
[05:27:27] <moon-child> hmm, it seems to fault on an invalid address in either case
[05:28:24] <moon-child> and the 'operation' pseudocode does include an unconditional load
[05:28:50] <hayley> Dammit, you're right.
[05:30:37] <hayley> Though note that the Pauseless GC only protects regions it is going to move, which are relatively few and so a trap should be unlikely.
[05:31:15] <gilberth> Of course a cmov would work, as I proposed initially.
[05:31:59] <hayley> No, it unconditionally reads the source, and so CMOV<c> RAX, [RBX] will fault if <c> fails and RBX is bogus still. 
[05:32:17] <gilberth> Really? That's poor.
[05:32:36] <hayley> The idea is to avoid branch prediction, so I guess it wouldn't work to be conditional.
[05:33:45] <gilberth> Well, from the perspective of a CPU designer, I don't see why. But if it works that way, then so be it.
[05:44:47] <moon-child> I don't think there's any instruction with a memory operand that doesn't read/write it, on x86
[05:45:26] <moon-child> maybe it makes more sense if you consider it a mask/pick operation, with two source operands one of which is also the destination
[05:46:03] *** Quits: recordgroovy (~recordgro@c-67-185-152-122.hsd1.wa.comcast.net) (Quit: leaving)
[05:50:06] <hayley> Hm, my thread-local-nursery-until-proven-otherwise plan probably is worse at reducing global allocation rates, because it tosses out a whole region at a time, rather than moving objects selectively.
[05:50:28] <gilberth> That's all premature without actually having a benchmark.
[05:51:34] <hayley> Was thinking to use multiple smaller regions, and then have remembered sets for which regions reference which, but I doubt it would fare any better.
[05:51:38] <moon-child> hayley: if you can infer which objects are likely to be made global, you can allocate them in a 'probably-global' nursery.  Then you can move them all at once instead of one at a time
[05:51:54] <moon-child> so it's not such a clear loss.  And I agree with gilberth 
[05:52:32] <hayley> Okay, the only nursery I have serves that purpose.
[05:52:51] <hayley> OTOH it beats no thread local GC, and it beats no thread local allocation buffers.
[06:15:10] *** Quits: waleee (~waleee@h-98-128-228-119.NA.cust.bahnhof.se) (Ping timeout: 240 seconds)
[07:12:24] <gilberth> hayley: I did the most simple benchmark, traversing a list with once with a check for a forwarding pointer using the LSB. I can't measure an overhead. Either I am doing sth wrong, or there is no overhead.
[07:12:44] <hayley> Hm, branch prediction?
[07:12:56] <gilberth> http://bauhh.dyndns.org:8000/gilbert/forwarding.c
[07:13:03] <gilberth> Find my mistake.
[07:13:24] <gilberth> hayley: Yes, that is what I believe.
[07:13:53] <hayley> Though the Pauseless test is rather to possibly emit a bogus load for the value, in order to trip the MMU.
[07:13:58] <gilberth> I still can't believe that and suspect some optimization, I can't see.
[07:15:08] <gilberth> hayley: I was interested in the not-tripped case, as that would be the common case. And tripping the MMU would imply the OS overhead, which might be way lower for CLOSOS.
[07:16:05] <hayley> idk, the barrier is fast enough to not be too bothered on Linux (like 2µs). Not amazing, of course, but given we trip only rarely...
[07:16:45] <moon-child> now I wanna test how fast the fault is on bare metal
[07:16:49] <gilberth> 2us? That is pretty slow, if you ask me.
[07:17:20] <hayley> Sure, it's slow, but I can live with it.
[07:17:29] <gilberth> moon-child: I wanted to do that and wrote something to get me into long mode without an OS. It's just that I don't have bare metal to test with.
[07:17:43] <moon-child> gilberth: screw getting into long mode without an os, uefi is where it's at!
[07:17:59] <gilberth> lol
[07:18:44] <gilberth> Setting a handfull CPU flags is easier than figuring UEFI.
[07:18:57] <moon-child> ne, I prefer efi
[07:19:14] <moon-child> single, canonical, well-defined set of apis.  Sure it's icky and huge and pe, but ehhh
[07:20:13] <hayley> Screw it, just use Multiboot, but that only gets you into 32-bit mode.
[07:20:20] <gilberth> I don't need much. And: I have all that already. And I have no idea, if UEFI would let me to setup page tables as I need them and the handler as I want it.
[07:20:42] <moon-child> you just use uefi to load your binary and give you memmap and framebuffer
[07:20:46] <moon-child> then you jettison it
[07:21:02] <gilberth> Multiboot does the same.
[07:21:20] <moon-child> yeah but it adds a dependency, and just gives you prot mode
[07:22:04] <gilberth> I already figured out how to get into long mode. It's not hard.
[07:24:40] <gilberth> Actually it's setting up paging which is more work.
[07:25:58] <moon-child> that's what sasos is for!
[07:26:15] <moon-child> (well, unless you wanna use the mmu for barriers.  But I haven't done that yet)
[07:26:20] <moon-child> (don't even have multicore yet)
[07:27:33] <gilberth> Listen, I wanted to have nothing between me and the CPU.
[07:28:24] <moon-child> sasos means single address space os.  So no complicated mappings, just everything flat
[07:28:59] <gilberth> I wanted to have paging to begin with.
[07:30:35] <gilberth> The initial idea was to measure the minimum cycles needed from the MMU fault to any handler. w/o a context switch and thus not through a task gate, or what ever that is called in AMD64.
[07:35:10] <hayley> https://www.youtube.com/watch?v=jY7dbRyoHfE
[07:35:11] -ixelp- King Crimson - Islands - YouTube
[07:55:20] *** Quits: aeth (~aeth@user/aeth) (Ping timeout: 256 seconds)
[07:57:11] *** Joins: aeth (~aeth@user/aeth)
[08:00:45] <copec> What would you all recommend to read on bytecode design for an interpreter?
[08:01:16] <White_Flame> it's way too contextual to have any sort of recommended way of doing it
[08:01:56] <White_Flame> but one thing that I will say is right from the very beginning, put a version number in your bytestream for when you change it
[08:02:19] <copec> okay
[08:06:02] <copec> There’s a lot of references for various bytecodes so I’ll just read them for a while
[08:06:03] <moon-child> there's a nice text on the elisp bytecode somewhere
[08:06:27] <copec> I’ll google that moon-child thanks
[08:06:58] <hayley> Smalltalk-80?
[08:07:52] <hayley> https://www.reddit.com/r/programmingcirclejerk/comments/pft3vu/the_entirety_of_cratesio_is_only_63_gib_that/ Average rustc user's computer
[08:07:54] -ixelp- The entirety of crates.io [...] is only 63 GiB. That means it easily fits in the ram of my new computer. So, I can grep  [...]
[08:08:56] <moon-child> copec: also recommend considering a compiler over an interpreter.  A really dumb compiler will get similar performance to a really smart interpreter, for probably less effort; and it's much easier to smarten a dumb compiler than it is to turn any kind of interpreter into any kind of compiler
[08:09:22] <hayley> FYI it took 25 seconds cause they used ripgrep and not clex2^Wone-more-re-nightmare
[08:10:17] <moon-child> e.g. http://canonical.org/~kragen/sw/urscheme/compiler.scm.html  a self-hosting scheme compiler in like 2k loc
[08:10:18] -ixelp- compiler.scm
[08:11:07] <hayley> If I had 128 threads, each doing the 400MB/s or so the olde compiler could do, let's say I'd saturate memory bandwidth pretty quickly.
[08:19:54] <hayley> Maybe the ramdisk is too slow with that many files?
[08:21:43] <moon-child> mmap!
[08:22:20] <hayley> Well, if you mmap too much, you blow out TLB or something. So you use a heuristic to either eagerly read or mmap.
[08:22:48] <hayley> Still, I haven't counted how many files are on crates.io. And my grep clone was still slower than GNU grep last time I checked.
[08:28:24] <copec> moon-child: Thanks for the adviceit's mostly that I wanted to know if there is well 
[08:28:50] <copec> I wanted to know if there is well established theory of how it should be done
[08:29:17] <copec> Or if everybody has just sort of created it bespoke
[08:29:46] <copec> shaped by each's specific goals
[08:33:46] <copec> It seems like there would be an almost natural representation that would be like a generic assembly before register allocation
[08:36:56] <copec> For that size you should use zgrep and keep it gzipped, because that indexes it
[08:37:08] <copec> ^re: crates.io
[08:38:41] <gilberth> copec: Sure there is. You could boil it down to (setq v1 (op v1 .. vn)), where op is one of your primitives, (setq v1 v2), (setq v0 (funcall v1 ... vn)), and (if v1 (go L1)), this is pretty much what instructions look like.
[08:39:49] <gilberth> Oh. and (setq v1 'sexpr)
[08:40:16] <moon-child> well, there's a big dichotomy of register/stack machines.  You just showed a register machine
[08:41:08] <gilberth> Sure, but optimizations like copy-propagation is easier on such a representation.
[08:42:43] <hayley> Can't afford IR?
[08:43:12] <gilberth> The H, L, or M version?
[08:43:36] <copec> You should make a lisp to forth compiler
[08:43:40] <White_Flame> copec: even things like the number of registers you have, and if they're orthogonal, make huge changes to bytecodes
[08:43:51] <hayley> gilberth's been there, done that.
[08:43:52] <White_Flame> assuming you bitpack into words
[08:44:05] <gilberth> copec: Would Lisp to PS do?
[08:44:41] <gilberth> Actually PS could be viewed as a reasonable BC.
[08:45:09] <gilberth> copec: A register machine and a stack machine map to each other. See: <http://bauhh.dyndns.org:8000/gilbert/tiny-bc/fib-jitted.lisp>
[08:45:13] <moon-child> gilberth: sure, but how much optimization are you gonna do on bytecode?
[08:45:37] <moon-child> again, a really dumb compiler and a really smart interpreter will perform similarly
[08:45:57] <gilberth> moon-child: None. I would do those before.
[08:46:24] <gilberth> There also is threaded code as a way between a compiler and byte code.
[08:46:29] <lotuseater> good morning @all
[08:46:59] <hayley> Bytecode -> IR?
[08:48:03] <gilberth> hayley: We could map code as we wish between all sorts of representations.
[08:48:25] <hayley> some crap -> Cleavir -> some more crap
[08:49:05] <moon-child> it sounds like an issue of semantics
[08:49:54] <hayley> https://dilbert.com/strip/2005-07-10
[08:49:55] -ixelp- Dilbert Comic Strip on 2005-07-10 | Dilbert by Scott Adams
[08:50:21] <moon-child> what do we mean by 'bytecode'?  I think of it in the present context as a representation of code to be interpreted directly, designed primarily for size and speed of execution.  But it's also used to mean a persistent, portable format with which you may do something more interesting, like jvm bytecode or llvm 'bitcode'
[08:51:37] <gilberth> Well, taken this way a bytecode is just an ISA like any other.
[08:52:19] <moon-child> sure.  But an ISA is not a bytecode
[08:52:23] <moon-child> not 'like any other'
[08:52:40] <gilberth> Or: Is the instruction set of the Lisp machine a byte code or an instruction set? If the latter, why?
[08:52:59] <White_Flame> a CPU is a hardware interpreter for an ISA
[08:53:23] <moon-child> gilberth: again, it is entirely a question of how you define your terms.  I gave 1.5 definitions for 'bytecode' that I think are fairly commonly used
[08:53:46] <gilberth> Is the Lisp machine byte code interpreted by hardware? Or by some program, called microcode, interpreting it?
[08:54:04] <White_Flame> all major ISAs match those 1.5 definitions
[08:54:29] <White_Flame> hmm, well I guess micro-op decode does kind of work against the 1st
[08:54:37] <White_Flame> but it wasn't really so in the beginning
[08:54:38] <moon-child> 'to be interpreted directly' and 'portable' don't really describe x86
[08:54:45] <moon-child> obviously by 'interpreted' I meant 'interpreted by software'
[08:54:53] <White_Flame> x86 is extremely portable across their different "runtimes" (hardware CPUs)
[08:55:29] <gilberth> A microcode program is software, too.
[08:55:30] <White_Flame> I propose that there is no semantic difference in a software runtime executing bytecode, and a hardware cpu executing ISA
[08:56:04] * gilberth agrees.
[08:56:28] <moon-child> what do you mean by 'semantic difference'?  Obviously it's all languages, and implementations of those languages.  I am talking about the semantics of english.  The semantics of the english words 'bytecode' and 'ISA'.  They have different connotations
[08:56:46] <White_Flame> the semantics of interpret/execute and bytecode/isa
[08:57:32] <White_Flame> an ISA is a bytecode made for hardware CPUs
[08:57:47] <gilberth> What is called an ISA could also be interpreted by HW. Or JITed in HW.
[08:58:06] <White_Flame> that doesn't make an ISA not a bytecode
[08:58:07] <moon-child> White_Flame: yes
[08:58:47] <moon-child> when you say 'ISA' you are implying that you are talking about a language that is implemented in hardware.  When you say 'bytecode', you are implying that you are talking about a language that is implemented in software
[08:58:57] <hayley> Don't forget some ISAs have software emulate some instructions.
[08:59:06] <White_Flame> sure, but that's not a material difference
[08:59:17] <White_Flame> they both can be executed by eitehr
[08:59:27] * moon-child gives up
[08:59:29] <White_Flame> it's just in the design phase, there are differing tradeoffs
[08:59:30] <hayley> And some bytecodes are run in hardware, but it is a dumb idea (c.f. Jazelle)
[08:59:33] <gilberth> Even pure RISC designs have an instruction decoder, mapping the instructions into sth else.
[09:00:06] <White_Flame> like, when I was making acheronvm, I first made it with heavily bitpacked fields
[09:00:21] <White_Flame> that woudl work great in hardware, but ended up way too slow and cumbersome for software decode
[09:00:48] <White_Flame> so I split things out into individual bytes, and the VM became much faster & smaller to implement
[09:01:09] <White_Flame> but, there's no reason it can't exist as a hardware ISA even in this state
[09:12:35] *** Joins: kakuhen (~kakuhen@user/kakuhen)
[09:16:05] <hayley> Maybe I should just use Hunchentoot as a benchmark. Crank the connection limit up and you have a shitty parallel CLOS-heavy benchmark.
[09:38:41] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[09:43:20] *** Joins: retropikzel (~retropikz@2001:999:20e:11a2:3909:9512:b3d1:ecdc)
[10:00:52] <copec> Nice reference for what I presume is a well thought out bytecode http://wiki.luajit.org/Bytecode-2.0
[10:00:53] -ixelp- LuaJIT 2.0 Bytecode Instructions
[10:02:25] *** Joins: nihaal (~nihaal@171.60.228.170)
[10:03:04] <hayley> If you can stomach a lot of message sends, I wrote https://cal-coop.gitlab.io/utena/utena-specification/main.pdf p.6 which has everything for prototype OO including tail-calls and APPLY.
[10:05:10] <dave0> maw
[10:05:19] <hayley> Hey dave0 
[10:05:24] <dave0> hi hayley 
[10:07:00] * copec checks out Hayley’s draft
[10:07:30] <lotuseater> maw dave0 
[10:10:23] * hayley runs Shenandoah GC instead of G1 and the latency is always worse. Go figure.
[10:12:28] <hayley> Also, apparently Clozure has the lowest latency GC, which seems silly.
[10:12:44] <dave0> maw lotuseater 
[10:14:38] * hayley looks through the JVM collection to find one which doesn't barf module errors but has a better low-latency GC.
[10:20:27] * hayley uploaded an image: (48KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/MEoKGeayPvovfXKlKsiaFBOg/hunchentoot-latency.png >
[10:22:30] <gilberth> very nice
[10:22:30] <hayley> So, on this very scientific test, ZGC is barely slower than G1, and has lower worst-case pauses.
[10:24:38] <hayley> Apparently lockdowns will end here when they get 70% of people vaccinated, which should be in 3 weeks. But I am still waiting to see supply of the one that won't kill me.
[10:26:15] <hayley> Also note that I consider 75% load to be putting 75% of the maximum throughput, and I probably should pay more attention to heap size, but every implementation understands (or doesn't) the "size" differently.
[10:28:58] <kakuhen> one thing id be interested in is a per-architecture benchmark
[10:29:02] *** Joins: shka (~herr@109.231.62.239)
[10:29:07] <kakuhen> i expect ccl latency to be much bigger on register-starved archs like i386
[10:29:18] <kakuhen> due to how it partitions the registers for the gc
[10:29:36] <hayley> Well, I am on x86-64, which is not great for registers, but i386 would indeed be worse.
[10:29:39] <kakuhen> basically it tries to split them in half, one half will contain "live lisp objects" and the other half something else
[10:29:43] <shka> this is a known problem 
[10:29:46] <shka> actually
[10:29:50] <kakuhen> and for i386 ccl has to do really gross hacks
[10:30:09] <shka> writing gc for i386 is challenging
[10:30:11] <kakuhen> (and given low i386 usage nowadays theyre even considering cutting off i386 support entirely)
[10:30:30] <hayley> .oO( Now, based on this graph, say something flamey about your favourite implementation...3, 2, 1, go! )
[10:31:00] <shka> sicl does not exists
[10:31:05] <kakuhen> ^
[10:31:08] <kakuhen> yeah where's sicl here?
[10:31:16] <shka> it is a scam!!!!
[10:31:26] <hayley> Yes, SICL does not exist. Correct.
[10:31:30] <shka> kakuhen: well, for starters, you can't benchmark it
[10:31:34] <shka> so...
[10:31:41] <kakuhen> metacircular benchmarks when
[10:31:50] <gilberth> I wonder how CLISP would fare.
[10:31:56] <kakuhen> oh gilberth has a good point
[10:32:31] <kakuhen> and that's also where my per-architecture suggestion would be interesting, i think
[10:32:37] <kakuhen> like a breakdown of sbcl, clisp, and ecl across different archs
[10:34:13] <hayley> shka: beach wants to use the Go GC basically to start with.
[10:35:09] <shka> i guess you have to start somewhere 
[10:40:29] <shka> and currently Go gc even performs well
[10:43:03] <moon-child> go gc performs really badly, but has good latency
[10:44:37] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 245 seconds)
[10:46:48] *** Joins: razzy (~razzy@user/razzy)
[10:56:06] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[11:02:41] *** Joins: razzy (~razzy@user/razzy)
[11:11:22] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 245 seconds)
[11:35:22] <hayley> He did say that thread local heaps would be used for stuff with really short lifetimes, but unless you have O(1)-ish migration to the global heap, it seems a dubious idea.
[11:56:27] <shka> hayley: i think that it is a pretty decent idea actually 
[11:56:56] <shka> worth of checking at least
[12:03:49] *** Quits: retropikzel (~retropikz@2001:999:20e:11a2:3909:9512:b3d1:ecdc) (Ping timeout: 252 seconds)
[12:08:36] *** Joins: razzy (~razzy@user/razzy)
[12:17:38] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 252 seconds)
[12:17:49] *** Joins: razzy (~razzy@user/razzy)
[12:20:13] *** Joins: retropikzel (~retropikz@2001:999:20e:11a2:3909:9512:b3d1:ecdc)
[12:29:02] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[12:34:16] *** Joins: razzy (~razzy@user/razzy)
[12:37:42] * hayley checks more computer part sites and finds cheaper parts every time.
[12:40:26] <dave0> our price are so low you'd think we have brain damage!
[12:40:45] <shka> try buying GPU
[12:41:10] <shka> but China wants to limit video games, so prices might go down
[12:41:15] <hayley> https://www.youtube.com/watch?v=BhYKN21olBw
[12:41:15] -ixelp- Brain Damage - YouTube
[12:41:26] <hayley> Yes, I'm buying everything but the GPU right now.
[12:41:42] <hayley> Given that we seem to be disk speed bound, and then I can't put in a M.2 drive cause there's no M.2 port.
[12:42:32] <shka> i could buy a more efficient CPU cooler
[12:42:50] <shka> i am running on the stock AMD RGB cooler 
[12:42:55] <shka> dunno how it is called
[12:43:04] <shka> it works, but is a little bit nosiy
[12:45:28] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[12:48:26] <shka> Wraith PRISM
[12:48:31] <shka> that's how it is called
[12:52:30] <shka> and that RGB is seriously annoying
[13:00:43] *** Joins: razzy (~razzy@user/razzy)
[13:12:37] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 245 seconds)
[13:40:16] <shka> so i bought Noctua NH-D9L
[13:40:32] <shka> this should handle that CPU with ease!
[14:00:25] <kakuhen> wow building llvm turns my laptop into a jet engine
[14:01:38] <hayley> I gave up re-building Clasp when it wanted to git clone LLVM.
[14:01:53] <kakuhen> poor fans and cpu are at full speed right now
[14:07:22] <shka> you can't install NH-9L into laptop... sadly
[14:17:22] <kakuhen> oo thankfully llvm 11 had a binary already
[14:17:26] <kakuhen> but llvm 10 took quite a bit
[14:20:31] <hayley> https://www.youtube.com/watch?v=v2Ve3v0rM9g
[14:20:32] -ixelp- Robert Fripp and the League of Gentlemen - God Save the King (HD) - YouTube
[14:27:47] *** Quits: jasom (~aidenn@2600:8802:7fa0:b00:69c9:7281:b072:31aa) (Ping timeout: 240 seconds)
[14:47:14] *** Joins: jasom (~aidenn@2600:8802:7fa0:b00:69c9:7281:b072:31aa)
[14:54:41] *** Quits: kakuhen (~kakuhen@user/kakuhen) (Quit: Leaving...)
[15:04:46] *** Quits: jasom (~aidenn@2600:8802:7fa0:b00:69c9:7281:b072:31aa) (Ping timeout: 252 seconds)
[15:18:28] *** Joins: jasom (~aidenn@2600:8802:7fa0:b00:69c9:7281:b072:31aa)
[15:23:19] *** Quits: retropikzel (~retropikz@2001:999:20e:11a2:3909:9512:b3d1:ecdc) (Quit: Leaving)
[15:52:29] *** Joins: santiagopim (~user@90.167.66.93)
[16:02:32] *** Joins: random-nick (~random-ni@87.116.183.125)
[16:17:32] *** Quits: JSharp (sid4580@id-4580.tooting.irccloud.com) ()
[16:17:48] *** Joins: JSharp (sid4580@id-4580.lymington.irccloud.com)
[16:33:55] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[16:45:47] *** Joins: razzy (~razzy@user/razzy)
[16:50:16] *** Joins: slyrus_ (~slyrus@192-184-223-165.static.sonic.net)
[16:50:17] *** Quits: slyrus (~slyrus@192-184-223-165.static.sonic.net) (Ping timeout: 250 seconds)
[16:56:22] *** Joins: slyrus (~slyrus@192-184-223-165.static.sonic.net)
[16:57:36] *** Quits: slyrus_ (~slyrus@192-184-223-165.static.sonic.net) (Ping timeout: 244 seconds)
[17:27:34] *** Quits: nihaal (~nihaal@171.60.228.170) (Ping timeout: 244 seconds)
[17:40:42] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 256 seconds)
[17:50:12] <hayley> What's funny is I'm pretty sure I got even my idea of software maximalism (compare to software minimalism) from beach. He said something about making a "smörgåsbord" of tools with the Cleavir framework, then I did something similar in decentralise2 basically.
[17:53:40] *** Joins: makomo (~makomo@user/makomo)
[17:54:32] *** Joins: nihaal (~nihaal@171.60.228.170)
[18:09:02] *** Quits: lad (~lad@user/lad) (Ping timeout: 256 seconds)
[18:11:14] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[18:22:02] <copec> M.2 NVME to PCIe 3.0 x4 Adapter with Aluminum Heatsink Solution https://www.amazon.com/dp/B07JJTVGZM/ref=cm_sw_r_cp_api_glt_fabc_HDR7CFPBNZW5HVA6KASP?_encoding=UTF8&psc=1
[18:22:34] <copec> sorry for Amazon link, that’s my American goto
[18:22:58] <copec> Could you do something like that Hayley?
[18:23:23] <hayley> Yeah, I only have spare x1 ports which is rubbish.
[18:23:34] <hayley> Or rather, no I couldn't do that.
[18:24:38] <hayley> I'm trying to make sure I don't mess it up again, and get a motherboard with more connectors in case I need them. Which seems cheaper with AMD boards but I could be very wrong.
[18:28:16] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 252 seconds)
[18:33:38] <copec> Did you glance at the popcorn Linux research Hayley? I thought it was interesting
[18:34:23] <copec> Try migrating a CL thread into another CL image
[18:34:42] <copec> On a different architecture 
[18:44:42] *** Quits: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd) (Ping timeout: 245 seconds)
[18:46:27] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[18:54:59] *** Quits: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd) (Quit: WeeChat 3.2)
[19:03:43] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[19:15:02] *** Quits: dec0d3r (~dec0d3r@2001:8003:4810:9600:7275:1afb:1707:8eaa) (Remote host closed the connection)
[19:46:25] *** Quits: nihaal (~nihaal@171.60.228.170) (Quit: nihaal)
[20:04:24] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Ping timeout: 276 seconds)
[20:04:25] *** Quits: micro (~micro@user/micro) (Ping timeout: 248 seconds)
[20:04:58] *** Joins: chiselfuse (~chiselfus@user/chiselfuse)
[20:05:18] *** Joins: micro (~micro@user/micro)
[20:29:56] <clothespin> the MOP is thirty years old this year
[20:48:43] *** Joins: razzy (~razzy@user/razzy)
[20:56:12] *** Quits: Balooga (sid407689@tooting.irccloud.com) ()
[20:56:27] *** Joins: Balooga (sid407689@id-407689.lymington.irccloud.com)
[20:58:32] <lotuseater> yay
[21:01:39] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Remote host closed the connection)
[21:01:55] *** Joins: chiselfuse (~chiselfus@user/chiselfuse)
[21:06:13] *** Joins: lad (~lad@user/lad)
[21:36:41] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[21:37:02] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[22:07:46] *** Joins: ec_ (~ec@gateway/tor-sasl/ec)
[22:29:08] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[22:31:13] *** Joins: razzy (~razzy@user/razzy)
[22:31:23] *** Joins: ec__ (~ec@gateway/tor-sasl/ec)
[22:34:11] <gilberth> Good morning #lispcafe!
[22:35:51] *** Quits: ec_ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[22:37:09] *** Quits: ec__ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[22:47:16] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 256 seconds)
[22:47:28] <clothespin> good morning gilberth
[22:49:07] *** Joins: razzy (~razzy@user/razzy)
[22:53:53] *** Quits: Mandus (~aasmundo@0.51-175-33.customer.lyse.net) (Quit: WeeChat 3.0.1)
[22:53:59] *** Joins: ec__ (~ec@gateway/tor-sasl/ec)
[22:55:37] *** Joins: Mandus (~aasmundo@0.51-175-33.customer.lyse.net)
[23:15:30] *** Joins: Jacobis9000 (~josephash@host86-139-59-58.range86-139.btcentralplus.com)
[23:15:30] *** Quits: ec__ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[23:15:39] <Jacobis9000> hi!
[23:15:47] <Jacobis9000> Common Lisp a Gentle Intro arrived today
[23:16:07] <Jacobis9000> the whole CAR and CDR and CDDR and CDDAR and CARDDR and all that is extremely confusing
[23:16:51] <gilberth> What is confusing about that?
[23:17:39] <Jacobis9000> CAR and CDR are straightforward. Left pointer, right pointer. How the names of the other functions relate to what they do is unclear, as is how they do what they do.
[23:18:11] <White_Flame> (cadr x) = (car (cdr x))
[23:18:18] <gilberth> They are short hands.
[23:19:09] <gilberth> You have (CxyzR x) = (CxR (CyR (CzR x))) ;if that makes sense.
[23:19:10] *** Quits: APic (apic@apic.name) (Ping timeout: 240 seconds)
[23:19:12] <White_Flame> I do kinda wish the letters were reversed, though, so they'd be in order of application instead of in lexical order
[23:19:30] <Jacobis9000> ah that does make sense
[23:19:43] <gilberth> White_Flame: You like postfix?
[23:20:11] <copec> White_Flame, that's what always made me pause and think to make sure I'm using the right one too
[23:20:13] <White_Flame> that's not how I view this though
[23:20:25] <White_Flame> I view it as a traversal order through the cons tree
[23:20:42] <White_Flame> caddr = follow through the cdr, cdr, then car to find the value
[23:20:44] *** Joins: ec__ (~ec@gateway/tor-sasl/ec)
[23:22:14] <Jacobis9000> when you do (CAR (CDR x)) you are plugging CDR x into CAR x to get the CAR of the CDR of x right? So in MUSHcode I'd write it [car(cdr(x))]
[23:22:36] <Jacobis9000> no wait [car([cdr(x)])]
[23:22:42] <Jacobis9000> that would be the MUSHcode version :D
[23:23:18] <Jacobis9000> CDR x into CAR to get CAR of CDR of x I mean
[23:23:24] <gilberth> Whatever MUSHcode is. Yes, you first CDR and then CAR.
[23:23:48] <Jacobis9000> Ok I will re-read that section and see if I get it now
[23:23:58] <Jacobis9000> I am ill with covid so not thinking at 100% efficiency
[23:24:20] <gilberth> Or: You apply CAR to (CDR x}, which is (CAR {CDR x)) which has shorthand (CADR x)
[23:24:45] <Jacobis9000> MUSHcode is a functional programming language for text based games called MUSHes, it's the reason I'm learning LISP, I wanted to learn a big-boy functional programming language that works outside of a game
[23:24:47] <gilberth> s/}/)/
[23:25:06] *** Quits: razzy (~razzy@user/razzy) (Ping timeout: 244 seconds)
[23:25:52] <Jacobis9000> thanks for your help
[23:27:12] *** Joins: razzy (~razzy@user/razzy)
[23:27:35] <Jacobis9000> I think I might add an if condition to my bash prompt with a little yellow ! that pops up if the previous command had a non-zero exit status
[23:27:51] <Jacobis9000> gah don't get distracted
[23:28:07] <gilberth> Jacobis9000: Get well soon.
[23:28:19] <Jacobis9000> thanks man, I'm pretty much ok now
[23:28:31] <Jacobis9000> just a stuffy head and a bit of faintness and nausea
[23:28:50] <Jacobis9000> my Nan and Granch have it too, they're on the mend though I think
[23:29:00] <Jacobis9000> my Nan had it the worst, I've been looking after her all week
[23:29:29] <Jacobis9000> oh and I've lost my sense of taste and smell
[23:29:31] <Jacobis9000> which is weird as
[23:30:41] <Jacobis9000> Dr Pepper just tasted like fizzy water, I can still taste sweetness though
[23:30:59] <gilberth> Had you not been vaccinated?
[23:31:08] <Jacobis9000> we've all been vaccinated
[23:31:16] <Jacobis9000> I was only vaccinated two months ago
[23:31:26] <Jacobis9000> they may have had it worse because they were vaccinated four months ago
[23:31:37] <gilberth> Oops, that sounds pretty bad.
[23:33:42] <Jacobis9000> ok I've re-read the section and I'm following it now
[23:34:32] <Jacobis9000> do you recommend Portacle to just start LISP programming?
[23:34:41] <Jacobis9000> or is it better to set things up on my own?
[23:35:39] *** Quits: ec__ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[23:40:28] *** Joins: ec__ (~ec@gateway/tor-sasl/ec)
[23:40:34] <moon-child> White_Flame: it's like right/left-associativity
[23:40:38] <moon-child> top-down/bottom-up construction
[23:43:48] <gilberth> Jacobis9000: Sorry, I don't know Portacle.
[23:46:46] <clothespin> get emacs get slime get sbcl and hack
[23:46:47] <gilberth> Nah, get CCL instead ;)
[23:46:47] <moon-child> whattabout clis--no, don't!
[23:46:47] <Jacobis9000> I can't get it working on my Mac anyway due to the Mac's really annoying and horrible "security" features blocking apps from outside their app store
[23:46:47] <Jacobis9000> Portacle is bundled and about eight things try to run and are blocked every time I try to open it
[23:46:47] <Jacobis9000> even if I allow them the Mac doesn't seem to remember
[23:46:47] <Jacobis9000> so I will just have to set up emacs and all that myself, why can we not just write lisp code in a file, compile and run it?
[23:47:05] <Jacobis9000> yeah can't get Portacle working
[23:47:06] <clothespin> you can but it will be a very inefficient workflow
[23:47:13] <Jacobis9000> sometimes I bloody well hate Macs
[23:47:28] <Jacobis9000> let me make my own decisions about security please Apple
[23:47:34] <clothespin> emacs has nothing to do with Macs
[23:48:02] <gilberth> Anyhow, I agree. Get Emacs and SLIME.
[23:49:01] <clothespin> you can override the security settings
[23:50:23] <Jacobis9000> I have tried, it's not working
[23:50:32] <Jacobis9000> what is SLIME anyway?
[23:50:36] *** Quits: ec__ (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[23:51:03] <clothespin> it attaches lisp to emacs
[23:51:45] <Jacobis9000> there is a lot here I do not understand. Why can't I just write a hello_world.lisp file, and download a compiler?
[23:51:55] <clothespin> you can
[23:52:52] <contrapunctus> Jacobis9000: but then you're missing out on interactive development, and getting caught in the edit-compile-restart antipattern of most other languages.
[23:54:20] <gilberth> Jacobis9000: But with Lisp you usally don't work that way and load the file each time you modify your program. SLIME is an Emacs package, which runs your Lisp inside Emacs and you will have a REPL to try things and when you modify a function definition in your source file, you could send that new version of just that function by typing c-c c-c in the Lisp source file buffer to the Lisp.
[23:55:05] <gilberth> That's the interactive nature of Lisp development.
[23:55:09] <Jacobis9000> ok let's see if I can get it set up
[23:55:17] *** Joins: ec__ (~ec@gateway/tor-sasl/ec)
[23:56:17] <lotuseater> hey Jacobis9000 :)
[23:56:17] <Jacobis9000> downloading emacs now, got SBCL the other day
[23:56:24] <Jacobis9000> hey lotuseater, what's up?!
[23:56:57] <lotuseater> if you're used maybe to vim you could also try the spacemacs distribution and see how things work out for you
[23:57:10] <Jacobis9000> yes I am used to vim
[23:57:14] <Jacobis9000> is spacemacs like vim?
[23:57:15] <lotuseater> ah i just looked into the channel and saw your nick
[23:57:31] <lotuseater> no, it's emacs with integrated vim
[23:57:43] *** Quits: v3ga (~cyberocto@c-73-39-172-34.hsd1.md.comcast.net) (Ping timeout: 252 seconds)
[23:58:39] <lotuseater> spacemacs.org
