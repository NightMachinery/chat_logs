[00:08:57] *** Joins: nb (~nb@fedora/ansible.user.nb)
[00:14:11] *** Quits: nb (~nb@fedora/ansible.user.nb) (Quit: The Lounge - https://thelounge.chat)
[00:17:39] *** Joins: nb (~nb@fedora/ansible.user.nb)
[00:37:18] *** Quits: nb (~nb@fedora/ansible.user.nb) (Quit: The Lounge - https://thelounge.chat)
[00:44:31] *** Joins: nb (~nb@fedora/ansible.user.nb)
[01:09:36] <Xgc> pi0: An instructor can be associated with 0 to many courses.  You removed the reference from students to courses.
[01:12:12] *** Quits: mthall_ (~quassel@mail.thalliman.com) (Ping timeout: 240 seconds)
[01:13:04] *** Joins: mthall (~quassel@mail.thalliman.com)
[01:13:51] *** Quits: DrowningElysium (uid190788@user/drowningelysium) (Quit: Connection closed for inactivity)
[01:25:36] <relipse> If I have access to the machine (Windows 2012), how do I reset the root password?
[01:42:05] *** Quits: mthall (~quassel@mail.thalliman.com) (Ping timeout: 272 seconds)
[01:45:37] *** Quits: lsrtl_ (~lsrtl@user/lsrtl) (Remote host closed the connection)
[01:45:54] *** Joins: mthall (~quassel@mail.thalliman.com)
[01:45:55] *** Joins: lsrtl_ (~lsrtl@user/lsrtl)
[01:56:18] <jacekowski> --skip-grant-tables
[01:56:57] *** Quits: nb (~nb@fedora/ansible.user.nb) (Quit: Ping timeout (120 seconds))
[02:02:36] *** Quits: mthall (~quassel@mail.thalliman.com) (Ping timeout: 240 seconds)
[02:03:01] *** Joins: nb (~nb@fedora/ansible.user.nb)
[02:03:43] *** Quits: acidsys (~LSD@2a03:4000:55:d20::3) (Excess Flood)
[02:05:20] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) ()
[02:10:53] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[02:15:04] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Read error: Connection reset by peer)
[02:23:57] *** Quits: lsrtl_ (~lsrtl@user/lsrtl) (Ping timeout: 252 seconds)
[02:26:33] *** Joins: acidsys (~LSD@2a03:4000:55:d20::3)
[02:34:37] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[02:49:08] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) ()
[02:51:28] *** Quits: adas (adas@adas.shelltalk.net) (*.net *.split)
[02:51:28] *** Quits: MrTrick (uid181961@id-181961.uxbridge.irccloud.com) (*.net *.split)
[02:51:28] *** Quits: shokohsc (~shokohsc@lfbn-idf2-1-1472-129.w92-169.abo.wanadoo.fr) (*.net *.split)
[02:51:28] *** Quits: KnowledgeShark (~Knowledge@50.34.198.222) (*.net *.split)
[02:51:28] *** Quits: jancoow (~jancoow@user/jancoow) (*.net *.split)
[02:51:28] *** Quits: highrate (~presonic@user/highrate) (*.net *.split)
[02:51:28] *** Quits: montywi (~monty_@83-245-178-47.elisa-laajakaista.fi) (*.net *.split)
[02:51:28] *** Quits: Thedarkb1-Work (~Thedarkb@62.232.253.82) (*.net *.split)
[02:51:28] *** Quits: mixfix41 (~sdenyninn@user/mixfix41) (*.net *.split)
[02:51:28] *** Quits: jlc (~jlc@cpe-107-15-173-212.nc.res.rr.com) (*.net *.split)
[02:51:28] *** Quits: NiKaN (sid385034@id-385034.helmsley.irccloud.com) (*.net *.split)
[02:51:28] *** Quits: itok (sid418430@ilkley.irccloud.com) (*.net *.split)
[02:51:28] *** Quits: finsternis (~X@23.226.237.192) (*.net *.split)
[02:51:28] *** Quits: rvgate (~rvgate@user/rvgate) (*.net *.split)
[02:51:28] *** Quits: Henry151 (~bishop@user/henry151) (*.net *.split)
[02:51:28] *** Quits: xMopx (~xMopx-lib@192.95.23.134) (*.net *.split)
[02:51:28] *** Quits: simoneb_ (~simone@static.39.20.203.116.clients.your-server.de) (*.net *.split)
[02:51:28] *** Quits: Azundris (azundris@user/azundris) (*.net *.split)
[02:51:28] *** Quits: roidelapluie (~roidelapl@ethylix.be) (*.net *.split)
[02:51:28] *** Quits: fipar (~fipar@67.205.180.153) (*.net *.split)
[02:51:28] *** Quits: Dev0n (~Dev0n@user/dev0n) (*.net *.split)
[02:53:47] *** Joins: adas (adas@adas.shelltalk.net)
[02:53:47] *** Joins: MrTrick (uid181961@id-181961.uxbridge.irccloud.com)
[02:53:47] *** Joins: shokohsc (~shokohsc@lfbn-idf2-1-1472-129.w92-169.abo.wanadoo.fr)
[02:53:47] *** Joins: KnowledgeShark (~Knowledge@50.34.198.222)
[02:53:47] *** Joins: jancoow (~jancoow@user/jancoow)
[02:53:47] *** Joins: highrate (~presonic@user/highrate)
[02:53:47] *** Joins: montywi (~monty_@83-245-178-47.elisa-laajakaista.fi)
[02:53:47] *** Joins: Thedarkb1-Work (~Thedarkb@62.232.253.82)
[02:53:47] *** Joins: mixfix41 (~sdenyninn@user/mixfix41)
[02:53:47] *** Joins: jlc (~jlc@cpe-107-15-173-212.nc.res.rr.com)
[02:53:47] *** Joins: NiKaN (sid385034@id-385034.helmsley.irccloud.com)
[02:53:47] *** Joins: itok (sid418430@ilkley.irccloud.com)
[02:53:47] *** Joins: finsternis (~X@23.226.237.192)
[02:53:47] *** Joins: rvgate (~rvgate@user/rvgate)
[02:53:47] *** Joins: Henry151 (~bishop@user/henry151)
[02:53:47] *** Joins: xMopx (~xMopx-lib@192.95.23.134)
[02:53:47] *** Joins: simoneb_ (~simone@static.39.20.203.116.clients.your-server.de)
[02:53:47] *** Joins: Azundris (azundris@user/azundris)
[02:53:47] *** Joins: roidelapluie (~roidelapl@ethylix.be)
[02:53:47] *** Joins: fipar (~fipar@67.205.180.153)
[02:53:47] *** Joins: Dev0n (~Dev0n@user/dev0n)
[02:53:47] *** Quits: mixfix41 (~sdenyninn@user/mixfix41) (Max SendQ exceeded)
[02:53:47] *** Quits: finsternis (~X@23.226.237.192) (Max SendQ exceeded)
[02:53:47] *** Quits: shokohsc (~shokohsc@lfbn-idf2-1-1472-129.w92-169.abo.wanadoo.fr) (Max SendQ exceeded)
[02:53:47] *** Quits: rvgate (~rvgate@user/rvgate) (Max SendQ exceeded)
[02:54:20] *** Joins: finsternis (~X@23.226.237.192)
[02:54:23] *** Joins: rvgate (~rvgate@user/rvgate)
[02:54:31] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[02:55:03] *** Joins: shokohsc (~shokohsc@lfbn-idf2-1-1472-129.w92-169.abo.wanadoo.fr)
[02:56:52] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Client Quit)
[02:57:23] *** Quits: NiKaN (sid385034@id-385034.helmsley.irccloud.com) (Ping timeout: 250 seconds)
[02:57:23] *** Quits: itok (sid418430@ilkley.irccloud.com) (Ping timeout: 250 seconds)
[02:59:26] *** Joins: itok (sid418430@id-418430.ilkley.irccloud.com)
[02:59:29] *** Joins: NiKaN (sid385034@id-385034.helmsley.irccloud.com)
[03:09:58] *** Joins: lsrtl_ (~lsrtl@user/lsrtl)
[03:20:52] *** Quits: lsrtl_ (~lsrtl@user/lsrtl) (Ping timeout: 272 seconds)
[03:21:09] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[03:25:23] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[03:32:45] *** Joins: Guest1264 (~Thunderbi@p10605177-ipngn25001marunouchi.tokyo.ocn.ne.jp)
[03:39:48] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Ping timeout: 240 seconds)
[03:43:33] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[03:47:24] *** Quits: Guest1264 (~Thunderbi@p10605177-ipngn25001marunouchi.tokyo.ocn.ne.jp) (Ping timeout: 240 seconds)
[03:52:09] *** Joins: ferdna (~ferdna@user/ferdna)
[04:00:20] *** Joins: Guest155 (~Thunderbi@p10605177-ipngn25001marunouchi.tokyo.ocn.ne.jp)
[04:31:48] <znf> On a server with ~640GB RAM, with innodb_buffer_pool_size=320G, is there any point where the size of innodb_log_file_size is detrimental somehow?
[04:31:48] *** Quits: Guest155 (~Thunderbi@p10605177-ipngn25001marunouchi.tokyo.ocn.ne.jp) (Ping timeout: 272 seconds)
[04:33:59] <znf> oh, wait, innodb_buffer_pool_instances can not be larger than 64
[04:53:52] <KnowledgeShark> Isotopp: Thank you again for coding the python sql loader for json. I am working out the bugs on my end; I have been modifying the code for data types and removing "not" from certain datatype columns for "not null" and changing certain "too long for column" to text and re-processing. So far I have made it to 270,160 rows / 1.8 million. Getting there :) Hope all is well. Best Regards, Brandon
[05:21:15] <KnowledgeShark> Isotopp: How did you generate the schema for the tables in the python script? Is there a special module or application that maps a schema with default templates or was this all individually decided?
[05:23:40] <KnowledgeShark> Isotopp: I know learning to scrape with beautifulsoup4 and apply SqlAlchemy to create a table (it automatically generates a schema); which is interesting because I am getting "data too long for column" (same error on a different parse project, also json [courtlistener.com bulk data files - which contains the fulltext of the opinions that harvard CAP bulk data does not] However; once I changed the database table schema data types for the column
[05:23:40] <KnowledgeShark> that was too long to longtext and re-ran it; it didn't work. It's like sqlalchemy automatically re-maps it. I probably have to specify the dialects. Getting closer!
[05:26:34] <litheum> KnowledgeShark: why don't you write a tool that gathers information about the data *before* you try to insert it? Like, how long each field is, etc.?
[05:36:17] <KnowledgeShark> litheum: What's the best approach to determining the length of each field? The data is very large several hundred megs - 3gb per json. I am able to inspect the different keys and values by using a free tool I found called "Dadroit JSON Viewer". I don't know how I would analyze field length, though.
[05:42:20] <litheum> it's json, can't you just cruise through the whole thing using whatever python library deals with json and keep track of the length of each field you come across?
[05:44:49] <KnowledgeShark> litheum: That's a great idea. I wish I understood Python enough to be able to accomplish that. I am picking up some new Python library books & SQL Query ones that I have on hold. I'll keep that logic in mind; great way to approach this! Thank you.
[07:07:34] *** Joins: Azem (~haise01@user/haise01)
[07:08:06] <litheum> KnowledgeShark: were you the one working with that jsonl file?
[07:10:30] *** Quits: Emet-Selch (~haise01@user/haise01) (Ping timeout: 252 seconds)
[07:11:28] <litheum> It seems like you're really over-thinking this whole thing... you read the file line-by-line, parse each line as a json document, keep track of the size of each field in some data structure. I get it that you don't have enough python knowledge to do this without having to look a few things up, but this is *really* trivial.
[07:18:38] <KnowledgeShark> litheum: the harvard CAP bulk data US metadata json that Isotopp wrote a rough loader for? Yes, that's me. I'm slow; it takes me a while to understand certain things and concepts. Examples are the best way for me to learn.
[07:20:02] <KnowledgeShark> litheum: Perhaps it's trivial to you; I revere those who are in the Freenode/Libera.Chat/OpenSource as Geniuses and Legends. To me; it's a huge deal learning and completing these tasks. And being able to learn enough to apply the same concepts/code blocks to other data I intend to parse.
[07:20:08] <litheum> I think I talked to you about this a couple days ago, that's when I looked up what jsonl was
[07:20:35] <KnowledgeShark> litheum: Thank you for reminding me. You did and linked me to the top google result.
[07:20:42] <litheum> You're lucky that you're working with this jsonl thing, which is a bunch of tiny json structures, and not some massive thing that requires tons of memory to interact with
[07:21:30] <KnowledgeShark> litheum: Glad to know this. I am also working with millions of .html files offline. All the goals/obstacles intertwine to a much larger picture.
[07:21:45] <KnowledgeShark> I haven't experienced the memory load on processing millions of files, yet.
[07:24:27] <litheum> millions of html files! why? what is in those?
[07:35:55] <KnowledgeShark> litheum: KJV/KJV1611 Holy Bible and More American Law
[07:50:32] <litheum> but in html files for some reason? why?
[07:51:16] <KnowledgeShark> Because I didn't know how to parse live websites at the time; so I just archived it offline with WGET. Which is highly practical.
[07:53:32] <KnowledgeShark> Now I have a ton of different types of datasets offline (some tarred, some not), awaiting parsing to MariaDB :)
[07:53:55] <KnowledgeShark> Once I parse to MariaDB; then I can create a very large database correctly.
[07:58:25] <litheum> Hoo boy
[07:59:13] <litheum> what are you going to do with this database once you have imported all the random stuff into it?
[08:00:33] <KnowledgeShark> Give it to my people (Country Men) and study it (I'm a Law Student) - Constitutional Law
[08:08:53] *** Quits: victori (~victori@cpe-76-89-139-69.socal.res.rr.com) (Quit: ZNC 1.8.2 - https://znc.in)
[08:13:05] *** Joins: victori (~victori@cpe-76-89-139-69.socal.res.rr.com)
[08:26:07] *** Quits: ferdna (~ferdna@user/ferdna) (Quit: Leaving)
[09:09:01] *** Quits: brentaarnold (~brentaarn@24.112.58.14) (Ping timeout: 240 seconds)
[09:09:37] *** Joins: brentaarnold (~brentaarn@24.112.58.14)
[09:38:43] *** Joins: travisghansen6 (~travisgha@192.74.130.86)
[09:39:25] *** Quits: trace987 (~trace@user/trace) (Remote host closed the connection)
[09:39:26] *** Joins: trace987 (~trace@user/trace)
[09:40:36] *** Quits: travisghansen (~travisgha@192.74.130.86) (Ping timeout: 240 seconds)
[09:40:45] *** travisghansen6 is now known as travisghansen
[10:21:00] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Ping timeout: 240 seconds)
[10:22:31] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[10:27:44] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Ping timeout: 272 seconds)
[11:21:55] *** Quits: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6) (Ping timeout: 256 seconds)
[11:22:07] *** Joins: Naktibalda (~Naktibald@88.135.22.17)
[11:32:33] *** Joins: palasso (~palasso@user/palasso)
[11:33:35] *** Quits: tribo (~tribo@p5b0fb69c.dip0.t-ipconnect.de) (Quit: WeeChat 2.8)
[11:36:57] *** Quits: adas (adas@adas.shelltalk.net) (Ping timeout: 250 seconds)
[11:39:27] *** Quits: stutz (~stutz@user/stutz) (Ping timeout: 252 seconds)
[11:44:02] *** Joins: adas (adas@adas.shelltalk.net)
[11:44:17] *** Joins: stutz (~stutz@p200300e88f133100b25adafffe87820c.dip0.t-ipconnect.de)
[11:44:17] *** Quits: stutz (~stutz@p200300e88f133100b25adafffe87820c.dip0.t-ipconnect.de) (Changing host)
[11:44:17] *** Joins: stutz (~stutz@user/stutz)
[11:46:36] *** Quits: gr33nR10t (~greenriot@user/gr33nr10t) (Ping timeout: 252 seconds)
[11:48:45] *** Joins: gr33nR10t (~greenriot@user/gr33nr10t)
[12:34:47] *** Joins: tribo (~tribo@p5b0fb69c.dip0.t-ipconnect.de)
[12:49:45] *** Quits: HvszrStykp (~X@81.171.62.84) (Ping timeout: 256 seconds)
[13:33:30] <Isotopp> KnowledgeShark: I generated the schema by looking at a single line of loaded jsonl, and identifying sub-objects. I added the sub-objects as a table, taking the attribute names as column names. I guessed the data types, often wrongly.
[13:34:43] <Isotopp> KnowledgeShark: mysql won't be able to handle things larger than max_allowed_packet. setting max_allowed_packet larger than say 64M is not a good idea for most people
[13:35:12] <Isotopp> KnowledgeShark: you are better off storing very large pieces of data in files and record the pathname in the database
[13:37:42] <Isotopp> KnowledgeShark: the schema -- i loaded the first three lines of jsonl, reading a line, and using json.loads() on it. I then receive a python object that is equivalent to the json, a dict with string keys and scalars as values, or with list() or dict() as values. The result from json.loads() can be fed to pprint.pprint() to pretty print the python object. that is a good view to look at the data structure.
[13:37:51] <Isotopp> It does not require external tools.
[13:38:20] <Isotopp> assuming that the top level dict is your main data (the case table, except that 'case' is a reserved word, so I chose 'us_case' for it)
[13:39:37] <Isotopp> a subdict such as the juristdiction data is then a different table. you will notice that there are many cases that refer to the same jurisdiction, but a case is always in exactly one jurisdiction.
[13:39:41] <Isotopp> that means two things:
[13:40:31] <Isotopp> 1. on load we take the juristdiction from the current case, and try to put it into the jurisdiction table. that may fail due to the key already existing. we can ignore this error: data in the jsonl is duplicated, in our jurisdiction table we deduplicate it.
[13:41:30] <Isotopp> 2. on read later we have a jurisdiction_id in our us_case table. it points to the relevant entry in the juristdiction table. that is jurisdiction.jurisdiction_id is a primary key in jurisdiction, and us_case.jurisdiction_id is a foreign key of jurisdiction is us_case.
[13:41:46] <Isotopp> this is the language that data modelling uses to describe this relationship.
[13:42:20] <Isotopp> us_case to jurisdiction have a n:1 relationship: many cases are in one jurisdiction, but a single case is always in exactly one jurisdiction.
[13:42:34] <Isotopp> this is common, and our implementation of that is also common.
[13:42:49] <Isotopp> in one case there was no id value provided in the subdict.
[13:43:39] <Isotopp> for that we check if a record that matches on all fields is already in our subtable, and if so, we return the id we find. if not, we insert the record and generate an id using mysql auto_increment, then return that id. That is find_or_insert() in the loader.
[13:43:45] <Isotopp> it is being used only in this one case.
[13:45:14] <Isotopp> then there is also one instance of a n:m relationship, the citation. a case may be referenced by many cases, and a case may city many cases. we model this in sql by creating a citation table, and a case_citation_relationship. the relationship table that n:m relates the tables a and b we always call a_b_rel, if it only contains a (a_id, b_id) pair.
[13:45:36] <Isotopp> in our case it was, if I remember correctly case_citation_rel with (case_id, citation_id) pairs.
[13:47:10] <Isotopp> if there are additional attributes we must find the function of the relationship in our business process and name it properly. for example, we may have courses and pupils, and a course contains multiple pupils, but a pupil can also be in multiple courses. a course_pupil_rel can also contain a book_date, or a flag "supervisor_approved" or things like that.
[13:47:56] <Isotopp> in this case, squinting at the business process, we can probably see that the function of the course_pupil_rel is actually a booking, and we can call the table booking (course_id, pupil_id, supervisor_approved, book_date).
[13:48:36] <Isotopp> data modelling is a task that takes a thorough understanding of the business process to be modelled and a bit of experience.
[13:49:16] <Isotopp> a model is a representation of a real world work agreement between people in data in the machine. it is always an aspect or certain view that we want to model, it is not the real world, but the view on the real world that we want
[13:49:52] <Isotopp> that is why you need to understand the business process (the real world work agreement, a process is "who needs to talk when to whom about what to get which permission, agreement or information")
[13:50:17] <Isotopp> and why you need a bit of experience because certain things are usually expressed in a certain way in certain systems
[13:50:32] <Isotopp> there is also the concept of "normal form" in relational databases that you need to look up and learn.
[13:51:12] <Isotopp> normal forms are simple, a friend of me at oracle, Azundris, explains them like this https://blog.koehntopp.info/2005/09/11/nermalisation.html
[13:52:12] <Isotopp> normal forms start at the first normal ("no arrays or dicts, all columns are scalars") and go to the degerate dknf (domain key normal form) or 6nf, which are not useful in current day database systems very much
[13:52:41] <Isotopp> most people aim for a thing close to the 3nf (third normal form) maybe with a few targetted denormalzations to accelerate certain operations.
[13:56:44] <Isotopp> KnowledgeShark: I said further above that the jurisdiction subdict is becoming a separate table, and that an id is provided, we deduplicate by ignoring duplicate key errors.
[13:56:54] <Isotopp> why do the duplicate key errors happen in the first place?
[13:57:31] <Isotopp> we normalize to the third normal form to avoid the problems Azundris addresses in the nermalisation blog post, but she is not saying the words normal form, and insert anomaly, update anomaly or delete anomaly in her text
[13:59:19] <Isotopp> a delete anomaly is for example a web shop forgetting a customers address when we delete all orders from that customer: the customer entry with their address is duplicated in each order, and by deleting each order we also remove all copies of the address. clearly the customer identity is an entity that should exist on its own and not as part of the order. we need to split it out, and establish a link from
[13:59:25] <Isotopp> the order to the customer by adding a customer_id ...
[13:59:27] <Isotopp> ... to the order instead of having the literal customer data in each order.
[14:00:20] <Isotopp> an update anomaly is related: when fixing a customer address in a single order, we have corrected an error in one place, but other orders from the same customer would still have the same error, if the customer data is copied literally into each order.
[14:01:16] <Isotopp> again, we may want to extract the delivery address into a separate entry from the order. when we fix the single copy of a delivery address, we fix the address data in all places that refer to it by id instead of literally copying the street name into the order.
[14:02:00] <Isotopp> are delivery addresses separate entities from customers? likely yes, because first normal form says "scalar values only, no list() or dict()", and a customer may have more than one delivery address.
[14:03:01] <Isotopp> insert anomaly is also related: if we do not make a customer separate from an order, we cannot create a customer that has not yet ordered anything.
[14:22:36] *** Joins: freeman_h (~freeman_h@37.120.159.215)
[14:23:01] <freeman_h> Hi all got a weird error Numeric value out of range: 1264 Out of range value for column amounts
[14:23:11] <freeman_h> amounts is decimal 8,2
[14:27:41] *** Joins: lara99 (~lara99@93-36-163-139.ip61.fastwebnet.it)
[14:28:37] <Isotopp> And what is the value that is out of range?
[14:34:46] *** Quits: bytestream (~bytestrea@user/bytestream) (Remote host closed the connection)
[14:45:23] <freeman_h> based on the error is says
[14:45:30] <freeman_h> Numeric value out of range: 1264 Out of range  @Isotopp
[14:45:40] <freeman_h> so guessing it's 1264
[14:50:10] <freeman_h> Isotopp, the value is 7682
[14:50:45] <freeman_h> or 884083.4
[15:15:35] <Isotopp> see
[15:15:40] <Isotopp> 1264 is the error number
[15:16:24] <Isotopp> Standard SQL requires that DECIMAL(5,2) be able to store any value with five digits and two decimals, so values that can be stored in the salary column range from -999.99 to 999.99.
[15:16:30] <Isotopp> https://dev.mysql.com/doc/refman/8.0/en/fixed-point-types.html
[15:16:41] <Isotopp> 884083.40 should fit a decimal(8,2)
[15:16:55] <Isotopp> because the range is from -999999.99 to +999999.99
[15:17:01] <Isotopp> that is not the problem here.
[15:55:12] *** Quits: Naktibalda (~Naktibald@88.135.22.17) (Ping timeout: 252 seconds)
[16:04:11] *** Quits: lara99 (~lara99@93-36-163-139.ip61.fastwebnet.it) (Quit: Client closed)
[16:09:39] *** Joins: freeman_h1 (~freeman_h@cpc94282-ward11-2-0-cust375.10-2.cable.virginm.net)
[16:10:28] *** Joins: Naktibalda (~Naktibald@88.135.22.17)
[16:10:48] *** Joins: DrowningElysium (uid190788@user/drowningelysium)
[16:13:21] *** Quits: freeman_h (~freeman_h@37.120.159.215) (Ping timeout: 252 seconds)
[16:13:48] *** Quits: freeman_h1 (~freeman_h@cpc94282-ward11-2-0-cust375.10-2.cable.virginm.net) (Ping timeout: 240 seconds)
[16:15:41] *** Joins: bytestream (~bytestrea@user/bytestream)
[16:42:55] *** Joins: lara99 (~lara99@93-36-163-139.ip61.fastwebnet.it)
[17:31:07] *** Joins: freeman_h1 (~freeman_h@37.120.159.215)
[17:31:31] <freeman_h1> I am looking on mysql threads I see a column call "time" and another one says " command"
[17:31:43] <freeman_h1> what is the time for?
[17:33:20] *** Quits: kevr (~kevr@user/kevr) (Remote host closed the connection)
[17:33:40] *** Joins: kevr (~kevr@user/kevr)
[17:35:58] *** Azem is now known as Emet-Selch
[17:48:44] <Isotopp> what version of mysql are you using specifically, and where ?
[17:48:51] <Isotopp> What command did you run exactly?
[18:07:48] *** Quits: stutz (~stutz@user/stutz) (Ping timeout: 240 seconds)
[18:13:30] *** Joins: stutz (~stutz@p200300e88f13310000000000000004cf.dip0.t-ipconnect.de)
[18:13:43] *** Quits: stutz (~stutz@p200300e88f13310000000000000004cf.dip0.t-ipconnect.de) (Changing host)
[18:13:43] *** Joins: stutz (~stutz@user/stutz)
[18:19:33] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6)
[18:22:49] *** Quits: lara99 (~lara99@93-36-163-139.ip61.fastwebnet.it) (Quit: Client closed)
[19:23:01] *** Joins: jamiejackson (~jamiejack@131.106.140.145)
[19:56:26] *** Quits: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6) (Quit: Client closed)
[20:04:40] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6)
[21:30:43] *** Joins: freeman_h2 (~freeman_h@cpc94282-ward11-2-0-cust375.10-2.cable.virginm.net)
[21:35:16] *** Quits: freeman_h1 (~freeman_h@37.120.159.215) (Ping timeout: 272 seconds)
[21:35:26] *** Joins: freeman_h1 (~freeman_h@188.241.156.65)
[21:38:26] *** Quits: freeman_h2 (~freeman_h@cpc94282-ward11-2-0-cust375.10-2.cable.virginm.net) (Ping timeout: 272 seconds)
[21:38:53] *** Joins: freeman_h2 (~freeman_h@cpc94282-ward11-2-0-cust375.10-2.cable.virginm.net)
[21:41:00] *** Quits: freeman_h1 (~freeman_h@188.241.156.65) (Ping timeout: 240 seconds)
[22:22:47] *** Joins: sfdebug (~AdiIRC@187.21.202.127)
[22:41:00] *** Joins: lsrtl (~lsrtl@user/lsrtl)
[22:41:08] <lsrtl> hey hey
[22:41:14] <lsrtl> licensing question
[22:41:41] <lsrtl> the community edition supports partitioning and all other features ?
[22:42:46] <lsrtl> how come that standard edition does not have partitioning and enterprise has ?
[22:44:57] *** Quits: finsternis (~X@23.226.237.192) (Ping timeout: 252 seconds)
[22:45:07] <litheum> lsrtl: some marketing/sales execs decided that'd be how it worked!
[22:45:58] <lsrtl> Am I missing something? I can use all the features in community ed for free and in standard starting from 2k I won't have all the features ?!
[22:46:42] <lsrtl> Or it has socket limitation set to 1 or something ?
[22:47:12] <litheum> do you want support from Oracle? or access to any non-GPL features?
[22:47:22] <lsrtl> nope
[22:47:45] <litheum> great, then ignore all the Standard/Enterprise stuff, and go explore all the joy you can find in the GPL Community edition :-)
[22:47:55] <lsrtl> just want to understand what edition to use if I need certain features like partitioning, replication etc
[22:48:26] <lsrtl> litheum, ic
[22:50:22] <litheum> if you don't intend to fork over money to Oracle, you can ignore https://www.mysql.com/products/ completely. if the feature you want doesn't exist in the Community Edition, and you aren't gonna pay, then you're out of luck, and maybe you should consider MariaDB or Percona Server
[22:53:21] <lsrtl> for now, community has more than needed. the only concern is supported socket number. because pricing of the products is based on supported sockets, 1-4, and 5+
[22:53:31] <lsrtl> does community has to do anything with it ?
[22:54:55] <lsrtl> or have socket support limitation ?
[22:59:08] *** Quits: mifritscher (~mifritsch@mifritscher.de) (Quit: Quit)
[23:00:15] *** Joins: mifritscher (~mifritsch@mifritscher.de)
[23:07:44] <litheum> lsrtl: Socket: is defined as a slot that houses a chip (or a multi-chip module), which contains a collection of one or more cores. Regardless of the number of cores, each chip (or multi-chip module) counts as a single socket. All occupied sockets on which the Oracle programs is installed and/or running must be licensed.
[23:07:44] *** Quits: sfdebug (~AdiIRC@187.21.202.127) (Read error: Connection reset by peer)
[23:08:36] *** Joins: sfdebug (~AdiIRC@187.21.202.127)
[23:08:46] <litheum> the software doesn't care how many sockets or cores or hyperthreads or any of that stuff you have. it's a sales thing.
[23:12:33] *** Quits: Naktibalda (~Naktibald@88.135.22.17) (Quit: Clap on! , Clap off! Clap@#&$NO CARRIER)
[23:14:23] <lsrtl> should be fine then
[23:14:23] *** Quits: sfdebug (~AdiIRC@187.21.202.127) (Read error: Connection reset by peer)
[23:15:13] *** Joins: sfdebug (~AdiIRC@187.21.202.127)
[23:21:14] *** Quits: sfdebug (~AdiIRC@187.21.202.127) (Read error: Connection reset by peer)
[23:21:53] *** Joins: sfdebug (~AdiIRC@2804:14d:7e89:45e1:d836:ce73:ac5d:f356)
[23:26:19] *** Joins: jimender2 (~jimender2@165.225.62.134)
[23:44:28] *** Quits: brentaarnold (~brentaarn@24.112.58.14) (Ping timeout: 272 seconds)
[23:51:23] *** Joins: teslt (~teslt@2804:14d:7e89:45e1:d836:ce73:ac5d:f356)
[23:51:28] *** Quits: teslt (~teslt@2804:14d:7e89:45e1:d836:ce73:ac5d:f356) (Remote host closed the connection)
[23:52:11] *** Joins: Guest2 (~Guest2@2804:14d:7e89:45e1:d836:ce73:ac5d:f356)
[23:52:26] *** Parts: Guest2 (~Guest2@2804:14d:7e89:45e1:d836:ce73:ac5d:f356) ()
