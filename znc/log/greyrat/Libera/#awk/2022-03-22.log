[01:29:30] *** Joins: wurstwasser_3 (~frank.hol@2001:a61:3576:a801:77aa:93b2:decc:40a1)
[01:30:16] *** Quits: wurstwasser_2 (~frank.hol@2001:a61:3576:a801:77aa:93b2:decc:40a1) (Remote host closed the connection)
[01:38:51] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[01:54:55] <Earnestly> https://github.com/jecolon/zed
[01:59:32] *** Joins: seninha (~seninha@user/seninha)
[02:00:23] *** Quits: user51 (~user51@77.124.35.94) (Remote host closed the connection)
[02:00:31] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[02:31:14] *** Joins: roarde (~roarde@user/roarde)
[03:05:51] *** Joins: Torr (~Torr@user/torr)
[03:12:16] *** Quits: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk) (Quit: Leaving)
[03:20:39] *** Quits: Torr (~Torr@user/torr) (Remote host closed the connection)
[03:31:38] *** Quits: wurstwasser_3 (~frank.hol@2001:a61:3576:a801:77aa:93b2:decc:40a1) (Remote host closed the connection)
[03:58:10] <tag> columns within recoeds.
[04:02:16] *** Joins: junebug (~junebug@2600:1700:3db0:2540:481:39cc:c7b4:e39c)
[04:02:47] <tag> I have no idea why someone would want to recreate awk. The benefit of awk is that its everywhere. By the time I want to process inputs in a more sophisticated language, the parsing of records and columns has to be the least of my concerns.
[04:10:53] *** Quits: junebug (~junebug@2600:1700:3db0:2540:481:39cc:c7b4:e39c) (Quit: Leaving)
[04:16:06] *** Joins: junebug (~junebug@104-0-169-217.lightspeed.miamfl.sbcglobal.net)
[04:21:48] *** Quits: junebug (~junebug@104-0-169-217.lightspeed.miamfl.sbcglobal.net) (Quit: Leaving)
[04:22:00] <yeti> let's put some pressure on some minor additions to standard awk
[04:22:13] <yeti> e.g. -We and bit ops
[04:23:38] <yeti> as widespread as awk is, that would need time to spread
[04:24:37] <tag> POSIX moves slow for a reason.
[04:25:30] *** Quits: Fozzworth (~Fozzworth@user/fozzworth) (Read error: Connection reset by peer)
[04:45:50] * yeti too
[05:38:37] *** Parts: eck (~root@user/eck) (PIRCH98:WIN 95/98/WIN NT:1.0 (build 1.0.1.1190))
[05:58:47] *** Quits: seninha (~seninha@user/seninha) (Remote host closed the connection)
[06:02:04] *** Joins: seninha (~seninha@user/seninha)
[06:04:55] *** Joins: seninha_ (~seninha@user/seninha)
[06:07:18] *** Quits: seninha_ (~seninha@user/seninha) (Remote host closed the connection)
[06:07:32] *** Quits: seninha (~seninha@user/seninha) (Ping timeout: 240 seconds)
[06:07:51] *** Joins: seninha_ (~seninha@user/seninha)
[06:10:13] *** Quits: seninha_ (~seninha@user/seninha) (Remote host closed the connection)
[06:11:42] *** Joins: seninha (~seninha@user/seninha)
[06:12:52] *** Quits: seninha (~seninha@user/seninha) (Remote host closed the connection)
[06:13:00] *** Joins: Torr (~Torr@user/torr)
[06:13:05] *** Quits: Torr (~Torr@user/torr) (Client Quit)
[06:13:18] *** Joins: Torr (~Torr@user/torr)
[06:22:27] *** Joins: seninha (~seninha@user/seninha)
[06:27:00] *** Quits: Thanatermesis (~Thanaterm@191.92.148.122) (Ping timeout: 252 seconds)
[06:34:00] *** Quits: seninha (~seninha@user/seninha) (Quit: Leaving)
[06:37:39] <Torr> Awk is simply awesome.
[06:38:02] <Torr> The more I learn about it, the more I realise how underated it is.
[06:41:21] <mute> welcome. we agree :)
[06:42:02] <nmz> :(
[06:43:47] <nmz> what awk lacks is implementation
[06:44:00] <nmz> and a few features
[06:52:40] <Torr> mute: Thank you
[06:52:52] <Torr> nmz: What u have in mind?
[06:53:10] <nmz> basically everything that lua has
[06:53:19] <nmz> apart from the pascal syntax
[06:54:15] <nmz> I would also like the go method of setting global/local variables
[06:54:28] <nmz> uppercase=global, lowercase=local
[06:56:20] <Torr> I hope your dreams remain just dreams.
[07:09:17] <nmz> what's wrong with having the ability to pass arrays around like values?
[07:09:24] <nmz> or having locals
[07:09:30] <nmz> functions too
[07:09:40] <nmz> having everything not be global
[07:11:38] <Torr> I could be ok with local variables, except for case based syntax. But importing everything from Lua is too much.
[07:12:58] <Torr> One of the beauties of Awk is its simplicity.
[07:14:47] <Torr> But I agree with u that a Lua without the wicked syntax would be cool.
[07:15:20] <yeti> and then we'd get fennel in awk?
[07:16:29] <yeti> looking at the resistance against adding stuff our wishlist should be short
[07:17:07] <yeti> local vars, -We/-E and a FFI
[07:17:29] <yeti> would be my top 3
[07:18:32] <mute> can simulate local vars by placing them last in function arguments of course
[07:18:40] <yeti> I know
[07:19:09] <mute> some hacks to do similar with arrays.. passing those would be sweet though
[07:19:51] <Torr> yeti: This: https://sr.ht/~technomancy/fennel/ ?
[07:19:58] <yeti> yip
[07:19:59] *** Parts: larryv (~larryv@zsh/patchmanager/larryv) ()
[07:20:37] <yeti> when awk would contain more lua, then why not have fennel atop that?
[07:20:48] <yeti> but maybe it makes more sense the other way round
[07:20:55] <yeti> write an awk atop lua
[07:21:20] <Torr> Does their tables, or arrays, start at 1?
[07:22:35] <yeti> https://www.tutorialspoint.com/lua/lua_tables.htm <<< are more like awk's dicts
[07:23:44] <Torr> No, they're not.
[07:27:24] <nmz> yeti: It's what I'm doing now
[07:27:26] <nmz> well
[07:27:29] <nmz> just an iterator
[07:28:13] <nmz> luiz has said himself that the tables where inspired by awk
[07:28:58] <yeti> !
[07:29:06] <nmz> or something like that, its in https://www.oreilly.com/library/view/masterminds-of-programming/9780596801670/
[07:29:11] <nmz> PS: good book
[07:30:34] <nmz> I think aho gets interviewed as well
[07:30:55] <Torr> Lemme save this, will read the book later.
[07:31:33] <yeti> meanwhile there is a whole ecosystem of languages atop lua
[07:31:47] <yeti> it might become a Mono competitor
[07:31:54] <yeti> or .Net
[07:32:28] <yeti> days are too short to explore all the interesting stuff
[07:33:27] <Torr> My point is, this:  `list = {"a","b"}; print(list[0])` won't work, but this `print(list[0])`
[07:33:30] <Torr> will
[07:34:36] <nmz> in where?
[07:34:51] <Torr> Lua tables have some list behavior, whereas Awk just doesn't have arrays to begin with. Which is fine.
[07:35:04] <Torr> Ops
[07:35:34] <Torr> It's `print(list[1])`
[07:35:39] <nmz> awks fault tolerance is friggin amazing
[07:35:43] <Torr> the working one.
[07:35:47] <Torr> on Lua.
[07:35:55] <nmz> ah, the arrays start at 1 argument?
[07:35:58] <nmz> meh
[07:36:31] <nmz> tis a silly argument
[07:37:05] <Torr> I can't live with that.
[07:38:03] <Torr> I have nothing against other people using Lua. But touching it... with that index... no.
[07:38:28] <nmz> lol
[07:39:02] <nmz> just set 0 to be whatever
[07:39:11] <nmz> I like it
[07:39:19] <nmz> I use [0] for metadata
[07:39:24] <nmz> and everything works as normal
[07:39:56] <yeti> does that cost zucktax now?  METAdata?
[07:40:04] <nmz> HA
[07:40:08] <Torr> Lol
[07:40:13] <nmz> zuckbucks
[07:40:22] <nmz> the new zuckcoin
[07:40:28] <Torr> Careful, he may sue u.
[07:40:47] <nmz> has he?
[07:40:49] *** Joins: Norkle_ (~norkle@admin.nasa-g0v.com)
[07:40:56] <nmz> he has to steal my ideas first
[07:40:59] <nmz> then sue
[07:41:06] *** Joins: asdflkj1 (~asdflkj@bsdforall.org)
[07:41:12] *** Joins: tangy (~tangy@user/tangy)
[07:41:18] *** Joins: mcint1 (mcint@pox.ocf.berkeley.edu)
[07:41:29] *** Quits: tangyQED (~tangy@user/tangy) (*.net *.split)
[07:41:29] *** Quits: asdflkj_sh (asdflkj@2605:6400:10:fe:bebd:57ba:41a5:636d) (*.net *.split)
[07:41:29] *** Quits: Norkle (~norkle@admin.nasa-g0v.com) (*.net *.split)
[07:41:29] *** Quits: mcint (mcint@user/mcint) (*.net *.split)
[07:41:39] <Torr> He's been training for this his while life, don't underestimate him.
[07:41:40] <yeti> Metaverse is 30yrs old - Why Facebook is late to the party - Computerphile  >>>  https://tube.cadence.moe/watch?v=vw7602ULHWA  <<<  they shoold sue the zuck!
[07:41:54] <Torr> whole* life
[07:43:43] *** Norkle_ is now known as Norkle
[07:52:12] <Torr> Eh
[07:52:48] <Torr> We know they won't though :(
[07:54:23] <Torr> Leaving here gentlemen, see ya.
[07:54:37] *** Quits: Torr (~Torr@user/torr) ()
[07:55:00] <yeti> _o/"
[07:58:32] <nmz> I don't have any horses
[08:17:26] *** Joins: malina (~malina@user/malina)
[08:19:14] *** Quits: Nahra (~user@static.161.95.99.88.clients.your-server.de) (Remote host closed the connection)
[09:14:53] *** Joins: larryv (~larryv@zsh/patchmanager/larryv)
[09:20:14] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 252 seconds)
[09:25:29] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[10:08:53] *** Joins: sagax (~sagax_nb@user/sagax)
[10:13:37] *** Quits: toulene (~toulene@user/toulene) (Ping timeout: 256 seconds)
[10:14:24] *** Joins: toulene (~toulene@user/toulene)
[10:30:00] *** Joins: larryv_ (~larryv@zsh/patchmanager/larryv)
[10:32:13] *** Quits: larryv_ (~larryv@zsh/patchmanager/larryv) (Client Quit)
[10:32:53] *** Quits: larryv (~larryv@zsh/patchmanager/larryv) (Ping timeout: 256 seconds)
[10:36:05] *** Joins: lgc (~lgc@user/lgc)
[10:37:00] *** Quits: lgc (~lgc@user/lgc) (Client Quit)
[10:41:52] *** Joins: kmuc (~kmuc@109.126.36.28)
[10:48:02] *** Quits: malina (~malina@user/malina) (Ping timeout: 240 seconds)
[10:48:27] *** Joins: malina (~malina@user/malina)
[10:56:07] *** Quits: vinipsmaker (~vinipsmak@187.106.197.220) (Ping timeout: 256 seconds)
[11:00:54] *** Quits: malina (~malina@user/malina) (Ping timeout: 252 seconds)
[11:13:52] *** Joins: malina (~malina@user/malina)
[11:16:04] *** Quits: Strykar (~wakka@signald/Strykar) (Remote host closed the connection)
[11:16:52] *** Joins: Strykar (~wakka@signald/Strykar)
[11:18:30] *** Quits: malina (~malina@user/malina) (Ping timeout: 252 seconds)
[11:30:52] *** Joins: malina (~malina@user/malina)
[11:38:57] *** Joins: promach[m] (~promach@2001:470:69fc:105::ca1)
[11:40:45] *** Joins: user51 (~user51@77.124.35.94)
[11:58:41] *** Quits: malina (~malina@user/malina) (Ping timeout: 256 seconds)
[12:01:35] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[12:13:26] *** Joins: loganlee[gnu] (~Thunderbi@user/loganlee)
[12:20:46] *** Quits: roarde (~roarde@user/roarde) (Quit: Leaving)
[12:38:15] *** Joins: lavaball (felix@31.204.155.215)
[12:51:00] *** Quits: loganlee[gnu] (~Thunderbi@user/loganlee) (Quit: loganlee[gnu])
[13:06:32] *** Joins: vinipsmaker (~vinipsmak@179.222.178.148)
[13:07:43] <promach[m]> Could anyone help with https://www.reddit.com/r/awk/comments/tjyctr/duplicated_line_removal_exception_for_awk_visited0/ ?
[13:14:50] *** Quits: kmuc (~kmuc@109.126.36.28) (Remote host closed the connection)
[13:17:12] <Patsie> awk '/current_instance/ || !visited[$0]++'
[13:23:06] <geirha> promach[m]: don't cross-post
[13:26:32] <promach[m]> geirha: Patsie: but if I want to remove duplicated lines containing only "current_instance" , but not to remove duplicated lines containing "current_instance other_character_other_than_whitespace"
[13:27:02] <geirha> change the regex accordingly ...
[13:27:47] <geirha> awk '/current_instance \{/ || !visited[$0]++'
[14:25:22] *** isabella is now known as izabera
[14:27:46] *** Joins: eoli3n (~eoli3n@82-64-112-150.subs.proxad.net)
[14:27:49] <eoli3n> Hi
[14:27:55] <Patsie> hi
[14:28:52] <eoli3n> echo -e "coucou;toto;tata;salut\n commentcava" | awk -F';' '{print $1";"$2";"$3";\""$4"\""}'
[14:28:56] <eoli3n> how to make awk ignore \n
[14:29:06] <eoli3n> i want it to quote $4
[14:29:11] <eoli3n> double*
[14:29:33] <Patsie> use a read csv tool
[14:29:36] <Patsie> real*
[14:29:48] <eoli3n> like ?
[14:29:52] <Patsie> \n is a default record separator
[14:30:02] <eoli3n> i tried to force RS=""
[14:30:09] <eoli3n> but its didn't do the trick
[14:31:49] <eoli3n> ok, did it by forcing \r between lines and set RS="\r"
[14:32:30] <Patsie> uw...
[14:32:35] <eoli3n> yeah...
[14:34:27] <eoli3n> echo -e "coucou;toto;tata;salut\n commentcava\r\ncoucou;toto;tata;salut\n commentcava" | awk -F';' '{ RS="\r" } {print $1";"$2";"$3";\""$4"\""}'
[14:34:44] <eoli3n> with my exemple, it doesn't parse the first line as the second one
[14:35:29] <eoli3n> Patsie: use a read csv tool  -> which kind ?
[14:37:21] <Patsie> I dunno, I never use csv
[14:38:13] <eoli3n> here my real use case :
[14:38:22] <eoli3n> apt-mark showmanual | sort -u | grep -Ev '^xfce|^lib|^gnome|^printer|^yaru|^language|^ubuntu|^grub|^fonts|^xserver|^xubuntu|^xdg|^thunderbird-|^firefox-' | xargs dpkg-query --show --showformat="\${Package};\${Version};\${Section};\${Description}\r" | tr -d '"' | awk -F';' '{ RS="\r" } {print $1";"$2";"$3";\""$4"\""}'
[14:38:29] <eoli3n> on a debian based host
[14:38:44] <eoli3n> i want to generate a csv from package list
[14:38:52] <eoli3n> problem is that description contains some '"'
[14:39:23] <eoli3n> i want to remove them, but if i decompose my command by generating a app list, and iterating over it, it take infinite time to process
[14:39:50] <eoli3n> so the only fast way i found, is to generate the whole text, then tr -d '"', then add " where i need it
[14:43:26] *** izabera is now known as isabella
[14:45:20] *** Quits: toulene (~toulene@user/toulene) (Quit: Ping timeout (120 seconds))
[14:46:04] *** Joins: toulene (~toulene@user/toulene)
[15:04:55] *** Quits: toulene (~toulene@user/toulene) (Quit: Ping timeout (120 seconds))
[15:05:41] *** Joins: toulene (~toulene@user/toulene)
[15:23:55] <eoli3n> i can't understand why my last echo -e exemple doesnt parse the first line as the second 
[15:23:57] <eoli3n> echo -e "coucou;toto;tata;salut\n commentcava\rcoucou;toto;tata;salut\n commentcava\rcoucou;toto;tata;salut\n commentcava\rcoucou;toto;tata;salut\n commentcava\r" | awk -F';' '{ RS="\r" } {print $1";"$2";"$3";\""$4"\""}'
[15:24:07] <eoli3n> and the end bug too
[15:26:57] *** Joins: seninha (~seninha@user/seninha)
[15:27:22] <Patsie> why do people here keep refering to things they don't understand as 'bugs' ?
[15:27:50] <Patsie> just because you don't see why a program does what it does, doesn't mean it's a bug, it means you don't understand the program
[15:27:51] <eoli3n> why beeing so passive aggressive instead of helping ?
[15:28:08] <Patsie> because I'm at work
[15:28:17] <eoli3n> so feel free to ignore
[15:37:01] *** Joins: vlm (~vlm@user/vlm)
[15:38:29] <Earnestly> That is what I choose to do
[15:39:08] <eoli3n> i'm trying to understand how to solve my problem. You're obviously not ignoring, but just beeing passive aggressive too.
[15:41:49] *** Quits: vlm (~vlm@user/vlm) (Ping timeout: 240 seconds)
[15:41:52] <eoli3n> each dpkg-query in 500ms, for any query
[15:42:08] <eoli3n> so i can't query each field to each app and then recompose the csv
[15:42:55] <eoli3n> i need a oneline solution: as far as record separator is contained in the description field, i can't get what i want
[15:43:47] <eoli3n> so i'm trying to split my records with \r, to be able to ignore \n in description, and then recompose my csv with my double quotes
[15:44:27] <eoli3n> any other idea is welcome
[15:49:06] *** Joins: vlm (~vlm@user/vlm)
[15:53:17] *** Quits: vlm (~vlm@user/vlm) (Ping timeout: 240 seconds)
[16:10:55] *** flooded is now known as _flood
[16:27:21] *** Joins: vlm (~vlm@user/vlm)
[16:31:18] *** Quits: toulene (~toulene@user/toulene) (Read error: Connection reset by peer)
[16:31:28] *** Joins: toulene (~toulene@user/toulene)
[16:34:12] *** Joins: emanuele6 (~emanuele6@user/emanuele6)
[17:30:43] <Patsie> you're right eoli3n, this ignoring you is really helping out! :D
[17:31:27] <Patsie> let me continue with it
[17:35:49] <eoli3n> beeing a dick, will not help you, for sure
[17:42:37] *** Quits: toulene (~toulene@user/toulene) (Ping timeout: 240 seconds)
[17:43:50] *** Joins: toulene (~toulene@user/toulene)
[18:02:32] *** Joins: TenochSLB (~Tenochyy@108-216-74-215.lightspeed.wchtks.sbcglobal.net)
[18:31:53] *** Quits: treble (~treble@user/treble) (Ping timeout: 252 seconds)
[18:33:04] *** Quits: vlm (~vlm@user/vlm) (Read error: Connection reset by peer)
[18:34:06] *** Joins: treble (~treble@user/treble)
[18:40:33] *** Joins: Thanatermesis (~Thanaterm@191.92.148.122)
[18:40:47] *** Quits: treble (~treble@user/treble) (Ping timeout: 256 seconds)
[18:48:30] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[18:53:47] *** Joins: vlm (~vlm@user/vlm)
[19:00:16] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[19:00:39] *** Joins: vlm (~vlm@user/vlm)
[19:02:37] *** Joins: treble (~treble@user/treble)
[19:08:57] *** Quits: vlm (~vlm@user/vlm) (Read error: Connection reset by peer)
[19:12:08] *** Joins: vlm (~vlm@user/vlm)
[19:35:40] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[19:36:03] *** Joins: vlm (~vlm@user/vlm)
[19:40:27] *** Joins: lavaball (felix@31.204.155.215)
[19:44:17] *** Quits: TenochSLB (~Tenochyy@108-216-74-215.lightspeed.wchtks.sbcglobal.net) (Ping timeout: 240 seconds)
[19:58:59] *** Quits: vlm (~vlm@user/vlm) (Read error: Connection reset by peer)
[20:01:09] *** Joins: vlm (~vlm@user/vlm)
[20:07:35] *** Quits: eoli3n (~eoli3n@82-64-112-150.subs.proxad.net) (Remote host closed the connection)
[20:09:00] *** Joins: eoli3n (~eoli3n@82-64-112-150.subs.proxad.net)
[20:36:23] *** Joins: TenochSLB (~Tenochyy@108-216-74-215.lightspeed.wchtks.sbcglobal.net)
[20:41:46] *** Joins: uuidNuni1 (~weechat@193.123.227.17)
[20:50:19] *** Quits: emanuele6 (~emanuele6@user/emanuele6) (Quit: Client closed)
[20:53:38] <nmz> ha
[20:53:48] <nmz> eoli3n: you solved it already?
[20:56:39] <nmz> eoli3n: fwiw, you don't get rid of " in csv, the way csv escapes " is by using continuous ", so a gsub("\"","\"\"") is sufficient
[21:00:27] <nmz> because you have control of the input, I'd suggest printing a control character instead, then function csvexport() {gsub("\"","\"\"");printf "%s" $1;for (i=2;i<=NF;i++){ printf ",%s" $i } } to convert awk's fields to csv
[21:00:30] <nmz> nontested btw
[21:01:50] <nmz> I tend to use FS=\037;OFS="," you can just print instead
[21:44:42] *** Joins: larryv (~larryv@zsh/patchmanager/larryv)
[22:00:12] *** Quits: vlm (~vlm@user/vlm) (Ping timeout: 240 seconds)
[22:06:06] *** Joins: vlm (~vlm@user/vlm)
[22:06:59] *** Quits: vlm (~vlm@user/vlm) (Remote host closed the connection)
[22:08:04] *** Joins: vlm (~vlm@user/vlm)
[22:14:33] <eoli3n> nmz thanks, I will regive it a shot tommorow
[22:28:37] *** Quits: vlm (~vlm@user/vlm) (Ping timeout: 268 seconds)
[23:03:05] *** Joins: Guest25 (~Guest25@138.199.58.71)
