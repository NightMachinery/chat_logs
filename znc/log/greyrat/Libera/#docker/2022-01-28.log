[00:00:00] *** Quits: lithium (~lithium@user/lithium) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[00:03:08] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[00:03:27] *** Joins: ExeciN (~ExeciN@user/nicexe)
[00:07:11] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[00:07:30] *** Joins: ExeciN (~ExeciN@user/nicexe)
[00:10:05] *** Quits: PeGaSuS (ubuntu@user/pegasus) (Quit: Goodbye! - WeeChat 3.4)
[00:10:46] *** Joins: PeGaSuS (ubuntu@user/pegasus)
[00:15:41] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[00:16:00] *** Joins: ExeciN (~ExeciN@user/nicexe)
[00:17:18] *** Quits: zer0bitz (~zer0bitz@2001:2003:f444:a000:a9ef:8cb1:3f34:9694) (Read error: Connection reset by peer)
[00:20:30] *** Quits: luva (~luva@37.120.197.54) (Remote host closed the connection)
[00:21:12] *** Joins: luva (~luva@146.70.62.236)
[00:21:17] *** Quits: symb0l_ (~symb0l@user/symb0l) (Quit: symb0l_)
[00:25:55] *** Quits: l4yer (~l4yer@2001:ac8:31:8900:1011:34c9:7321:99e2) (Remote host closed the connection)
[00:28:24] *** Joins: jarthur (~jarthur@2603-8080-1540-002d-35e0-06b2-095d-de4d.res6.spectrum.com)
[00:33:06] <Tach> Will a docker container never use the hostsfile of a docker host ? My tests say no
[00:34:56] <tabakhase> Tach yep
[00:35:18] <tabakhase> ad-hosts or aliases exists tho to solve either need you may have
[00:35:45] *** Joins: vidbina (~vid@dynamic-077-011-006-180.77.11.pool.telefonica.de)
[00:37:47] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[00:38:06] *** Joins: ExeciN (~ExeciN@user/nicexe)
[00:44:56] *** Joins: [diablo]4 (~diablo]@user/diablo/x-9068044)
[00:46:20] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[00:46:42] *** Quits: [diablo] (~diablo]@user/diablo/x-9068044) (Ping timeout: 260 seconds)
[00:46:43] *** [diablo]4 is now known as [diablo]
[00:55:33] *** Quits: PeGaSuS (ubuntu@user/pegasus) (Remote host closed the connection)
[00:56:11] *** Joins: PeGaSuS (ubuntu@user/pegasus)
[00:59:26] *** Quits: _mikey (~mikey@user/mikey/x-4335048) (Quit: WeeChat 3.4)
[00:59:47] *** Joins: _mikey (~mikey@user/mikey/x-4335048)
[00:59:54] <Tach> tabakhase I don't have the need, I wanted to avoid it... so that's why :) thanks!
[01:00:42] <Tach> and needed to make sure :D
[01:00:47] <Tach> tabakhase beer ?
[01:02:24] *** Quits: emx (~emx@adsl-84-226-68-198.adslplus.ch) (Ping timeout: 256 seconds)
[01:02:58] *** Quits: [diablo] (~diablo]@user/diablo/x-9068044) (Ping timeout: 256 seconds)
[01:08:24] *** Quits: jkwnki (~jkwnki@p2e5796b1.dip0.t-ipconnect.de) (Ping timeout: 250 seconds)
[01:11:08] *** Joins: [diablo] (~diablo]@user/diablo/x-9068044)
[01:17:03] *** Joins: drillbyt_ (drillbyt@user/drillbyt)
[01:17:35] *** Quits: drillbyt (drillbyt@user/drillbyt) (Ping timeout: 268 seconds)
[01:22:49] *** Joins: transhumanist (~steven@2601:196:8800:35f0:d396:27cb:9287:9f2d)
[01:25:04] <transhumanist> does docker now support things like asterisk running in containers but allow the support of RTP other ranges besides 10000-10200 for ports? in other words it must tunnel it , right? and would be a security issue?
[01:27:50] *** Quits: boubou (~boubou@hide.my.ip.upsidehosting.com) (Remote host closed the connection)
[01:43:49] *** Joins: yuesbeez (uid458354@id-458354.tinside.irccloud.com)
[01:46:58] *** Quits: gproto23 (~gproto23@user/gproto23) (Ping timeout: 250 seconds)
[01:47:47] *** Quits: errororous (~errororou@178.17.16.67) (Quit: Client closed)
[01:52:16] <programmerq> transhumanist: last time I ran asterisk, I remember it really hating any NAT at all. For running it in Docker, you could run a macvlan or ipvlan docker networking driver. RTP runs on top of udp, right? I'm not aware of any restrictions that docker places on udp ports-- can you elaborate?
[01:53:22] *** Quits: DrowningElysium (uid190788@user/drowningelysium) (Quit: Connection closed for inactivity)
[01:55:04] <programmerq> if you are using the docker nat stuff and want to publish a range of ports, that is possible. You might want to disable the docker userspace proxy if using the bridge driver in conjunction with that
[01:55:34] <programmerq> but if you're going to publish thousands of ports, then you might as well switch to macvlan or ipvlan or just skip any fuss at all and do host mode networking.
[01:57:01] <tabakhase> wasnt there also some deal that docker "publishes each port on its own"? - so iptables fales and one generic rule is more reasonable - dont remember the exact details there tho, that may only be a proxy not iptables limitation
[02:01:31] <tabakhase> "hates nating" is bit of a yesno - it hates natting it is not aware of, but as long as you maintain that remote networks list things are supposedly fine ((its more SIP that providers always want the shortest everthing and also cabled-lan only please :P))  [[my pbx is 3-hops-away inc. vpns, but not docker so dont quote me on anything of that]]
[02:04:27] <transhumanist> I refer to this blurb on  the subject as the source of my query...   https://community.freepbx.org/t/freepbx-in-lxd-container/77753/2
[02:06:12] <transhumanist> yes RTP works over UTP
[02:07:34] *** Quits: vidbina (~vid@dynamic-077-011-006-180.77.11.pool.telefonica.de) (Ping timeout: 256 seconds)
[02:08:23] *** Quits: drillbyt_ (drillbyt@user/drillbyt) (Quit: Leaving)
[02:09:09] <tabakhase> transhumanist this (linked) comment is fairly bang on - not fully, but generally a "yes"
[02:15:09] <transhumanist> is there any way around this issue or should I be looking at LXC or LXD or something?  I notice  this section: """ Docker, iptables and docker-proxy  """ of this page:  https://hub.docker.com/r/mlan/asterisk   indicates a couple potential work arounds mainly the use of --network-host might work better, but I am not sure of the security ramifications on doing it. (assuming dedicated raspberry pi dedicated box for the purpose) 
[02:16:49] <tabakhase> transhumanist security "when using hostmode"? - just that it has more access to the host it normally wouldnt (namely, its localhost) - just "disables the network-issolation part of docker"
[02:17:28] <transhumanist> so if its a dedicated box the only thing to worry about is its lan access
[02:18:24] <transhumanist> seems like its a promising way of making easily configurable asterisk docker container that takes advantage of docker , am I missing something?
[02:18:42] <tabakhase> why even docker it then? ;-) -- and were talking asterisk-asterisk, or freeipx as that forum thread? - for the second, dont they provide a whole distro?...
[02:19:21] <transhumanist> for easy deployability is what I was thinking
[02:19:32] <tabakhase> "dockerizing" somethign is a lot more than just "Installing it in a container" or even just "runing it in a container"
[02:20:10] <transhumanist> I guess just building a custom image for a pi would be all that would be needed, and it avoids all the containerization slow down and stuff.
[02:20:22] <transhumanist> ok thanks got what you are saying
[02:20:39] <tabakhase> http://www.raspberry-asterisk.org/
[02:21:36] <transhumanist> oh wow ok, I can certainly customize that to my liking! thanks!
[02:22:39] <tabakhase> and like, Q becomes what you call "dockerizing" too --- does one expect it to create the admin-user from env-vars? - or are you expected to be able to ship in your sip-trunk details via env-vars? - or do you exec in and run the createdb script? - where to draw the line there is kinda impossible to answer
[02:23:42] <tabakhase> and at that point you are kinda better off with a maintainable VM than a dead-in-the-water container cause 2 years down the road config has spread all over and "rebuild && recreating" breaks everything horrifically :D
[02:26:19] <transhumanist> only thing is due to the hardware of the PI I am likely to run into traffic limitations. I was thinking to give some background using asterisk to distribute my own custom telephone exchange among participants, I have a certain idea/concept in mind that would serve as an alternative to the existing telephone network with a very custom set of features.I want to test it out, thus lets say 20 Raspberry PI's would be the testing "te
[02:26:19] <transhumanist> twork"
[02:26:51] <transhumanist> as you point out I could just use VM's for this purpose and save money on raspberry pi's
[02:27:17] <tabakhase> homelab/homeoffice/smb?
[02:27:31] <transhumanist> homelab
[02:27:36] <transhumanist> I work in IT 
[02:27:52] <transhumanist> (as much as I hate working for others in IT...lol)
[02:29:17] <tabakhase> then something like a proxmox host likely belongs into your cabinet ;-)  (webgui for lxc&kvm)
[02:29:30] <transhumanist> oh ok
[02:29:43] <transhumanist> I used to use that about 10 years ago, I guess its probably come a long way
[02:29:44] *** Quits: symb0l (~symb0l@user/symb0l) (Read error: Connection reset by peer)
[02:31:25] <transhumanist> right now I run kvm on my home computer, but its wowfully insufficient running multiple VM's < reallly need to by a real nice dual or quad socket mobo with thread ripper or one with like 128 cores , that is need to spend like 10k that I dont have
[02:32:46] <transhumanist> I just recently returned to work after 5 years absence and it will take another year of help desk work to move up the corporate ladder so I can afford such equipment
[02:33:20] *** Quits: Tach (~Tach@user/tach) (Quit: Tach)
[02:33:49] <tabakhase> just snag a fleet of recycled dells on ebay :P
[02:34:10] <tabakhase> zfs replica and you even got pooor-mans-HA in pve :D
[02:35:48] *** Joins: symb0l (~symb0l@user/symb0l)
[02:38:06] <transhumanist> right , if only I could spend like 2k minimum! lol
[02:38:40] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[02:38:40] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Remote host closed the connection)
[02:38:54] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[02:44:18] *** Quits: ryu` (~ryusaku@user/ryu/x-3206151) (Quit: SCV ready!)
[02:54:56] *** Quits: _mikey (~mikey@user/mikey/x-4335048) (Quit: WeeChat 3.4)
[02:56:46] *** Joins: dox (~dox@dox.la)
[02:57:15] *** Joins: _mikey (~mikey@user/mikey/x-4335048)
[02:59:12] <rawtaz> transhumanist: if its for a limited amount of time and/or resource usage, consider free tiers at e.g. AWS, Azure and so on. they have time limited (usually 12 months) and up to a certain amount of monies or similar for free. just make sure youre only using the free services and not some that costs :P
[03:07:03] *** Quits: fedenix (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[03:07:31] <transhumanist> rawtaz, sadly I have already used my free time up... but thanks for the idea
[03:08:10] <transhumanist> I could rent like 20 .99 cent VPS from england or something
[03:12:54] *** Quits: remote (~self@user/hackers) (Ping timeout: 268 seconds)
[03:14:31] *** Joins: Tach (~Tach@user/tach)
[03:14:32] *** Joins: remote (~self@user/hackers)
[03:15:02] *** Quits: Haxxa (~Haxxa@89nnjg0xckz9ggn6r5xm.ip6.superloop.com) (Ping timeout: 240 seconds)
[03:15:39] *** Joins: Haxxa (~Haxxa@125-253-30-218.ip4.superloop.com)
[03:21:29] <minimal> transhumanist: or try using a lightweight OS for your VMs on your home computer? (e.g. Alpine Linux)
[03:26:29] <rawtaz> transhumanist: but you can create new accounts
[03:27:25] <rawtaz> ive tried it, it works :P i never used the second one but still. i created one years ago that expired because i never got to testing stuff. so a couple years ago i had to create a new account to get a new free tier. this was with AWS
[03:28:23] <rawtaz> i used my regular email address (same as the previous/main account) but with +foo right before the @ - this makes the mails go to your regular email account, but AWS considers it to be different so you can create a new account that way.
[03:28:30] <rawtaz> instead of having to use a completely new mail account.
[03:31:09] *** Quits: null23 (~null23@h-37-123-160-123.A251.priv.bahnhof.se) (Ping timeout: 250 seconds)
[03:31:59] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Remote host closed the connection)
[03:32:42] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[03:34:49] *** Joins: vidbina (~vid@dynamic-077-011-006-180.77.11.pool.telefonica.de)
[03:36:10] *** Joins: martums5 (~martums@user/martums)
[03:36:38] *** Quits: matdev (~matdev@2a01:6e60:10:793:666:feed:dead:beef) (Remote host closed the connection)
[03:37:02] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Ping timeout: 260 seconds)
[03:38:57] *** Quits: Raito_Bezarius (~Raito@wireguard/tunneler/raito-bezarius) (Ping timeout: 250 seconds)
[03:39:31] *** Joins: Raito_Bezarius (~Raito@wireguard/tunneler/raito-bezarius)
[03:43:08] *** Quits: Raito_Bezarius (~Raito@wireguard/tunneler/raito-bezarius) (Excess Flood)
[03:43:43] *** Joins: Raito_Bezarius (~Raito@wireguard/tunneler/raito-bezarius)
[03:44:45] *** Quits: itsalexjones (~itsalexjo@82.4.99.241) (Read error: Connection reset by peer)
[03:45:35] <transhumanist> I like the idea of using alpine linux for the vms, then I can do it here! thanks for the idea
[03:46:00] <transhumanist> I can shutdown my windows vm which I dont need now and run all alpine guests, thanks for reminding me
[03:46:36] *** Joins: symb0l_ (~symb0l@user/symb0l)
[03:47:35] *** Joins: jazzy (~jaziz@user/jaziz)
[03:50:57] *** Quits: symb0l (~symb0l@user/symb0l) (Ping timeout: 240 seconds)
[03:50:57] *** symb0l_ is now known as symb0l
[03:51:17] *** Quits: Raito_Bezarius (~Raito@wireguard/tunneler/raito-bezarius) (Ping timeout: 240 seconds)
[03:53:09] *** Joins: symb0l_ (~symb0l@user/symb0l)
[03:54:21] *** Joins: Raito_Bezarius (~Raito@wireguard/tunneler/raito-bezarius)
[03:58:38] *** Quits: symb0l (~symb0l@user/symb0l) (Ping timeout: 256 seconds)
[03:58:42] *** Quits: symb0l_ (~symb0l@user/symb0l) (Ping timeout: 250 seconds)
[03:59:34] *** Joins: symb0l (~symb0l@user/symb0l)
[04:00:11] *** Joins: luckiswithme (~luckiswit@103.226.104.2)
[04:00:26] *** Joins: symb0l_ (~symb0l@user/symb0l)
[04:05:17] <minimal> transhumanist: I build custom small Alpine VMs (even smaller than "normal") myself :-)
[04:05:55] <minimal> transhumanist: FYI: my script: https://github.com/dermotbradley/create-alpine-disk-image
[04:05:58] <rawtaz> transhumanist: what do you actually need to run anyway? some kubernetes-like thing, or just several containers?
[04:06:00] <minimal> its a work-in-progress
[04:08:51] *** Quits: luckiswithme (~luckiswit@103.226.104.2) (Remote host closed the connection)
[04:15:01] <dskull> Q: when i pull a docker repo (ie php:fpm-alpine) do i need to specify that i want ARM somehow (for apple m1) or does it compile based on my architecture?
[04:16:54] *** Quits: vidbina (~vid@dynamic-077-011-006-180.77.11.pool.telefonica.de) (Ping timeout: 250 seconds)
[04:18:24] *** Joins: travaldo (~travaldo@159.203.88.148)
[04:20:17] <rawtaz> dskull: considering that https://docs.docker.com/desktop/mac/apple-silicon/ says "Not all images are available for ARM64 architecture. You can add --platform linux/amd64 to run an Intel image under emulation" i would expect it to try to pull the correct arch automatically (But it may fail if that isnt available)
[04:20:26] <rawtaz> that said, i havent tried it so i cant say for sure
[04:20:34] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[04:22:27] <dskull> well i had notice one image (not this one specifically) had warned me it was running amd emulation in the gui, this particular one doesn't give me a notice, but it is performing quite slow (I'm running a maxed out pro, so seemed odd to me)
[04:23:20] <dskull> i'm trying to compare my image id or other values to what's under https://hub.docker.com/_/php?tab=tags&page=1 but i've only just been searching 5-10min
[04:23:34] *** Quits: cotko (~cotko@188-230-251-153.dynamic.t-2.net) (Ping timeout: 256 seconds)
[04:24:55] <rawtaz> i guess that image wasnt available for your arch then and for that reason it pulled another one? i dont know. what image is it?
[04:25:14] *** Quits: ivii (~ivan@user/ivii) (Remote host closed the connection)
[04:25:31] <dskull> this one i believe (i did a docker pull 7.4-fpm-alpine) https://hub.docker.com/layers/php/library/php/7.4-fpm-alpine/images/sha256-7777c550394c3fd439abda51ee64c86b115efc92663ea62dd987a018a0d13c31?context=explore
[04:31:08] <dskull> i'm not quite sure how to get the info from my local image aside from just "7.4-fpm-alpine"
[04:32:10] <rawtaz> yeah its the one listed here: https://hub.docker.com/_/php?tab=tags&name=7.4-fpm-alpine&page=1
[04:33:15] <transhumanist> rawaz going to run asterisk
[04:34:24] <rawtaz> yeah i get that but i asked how basically, i guess
[04:35:22] <rawtaz> dskull: so that one is the one with hash 7777 in the beginning and thats for amd64, which is what you observed. the image does however exist for arm as well, see the other entries there
[04:35:40] <rawtaz> dskull: im not sure what your question is/was, but you can pull th arm ones if you want and try to run them instead
[04:36:56] <dskull> thanks, i'll play with it a bit more, just getting the hang of things really
[04:37:14] <rawtaz> good :)
[04:38:30] *** Quits: akurilin_ (uid322841@id-322841.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[04:39:43] *** Quits: symb0l (~symb0l@user/symb0l) (Quit: symb0l)
[04:41:43] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Remote host closed the connection)
[04:41:57] *** Joins: luckiswithme (~luckiswit@103.226.104.2)
[04:43:48] <transhumanist> guys who are current on Alpine linux, how good are the virtual drivers for it for KVM I guess they would be virtio drivers?
[04:49:28] *** Quits: jushur (~human@user/jushur) (Quit:  ¯\_(ツ)_/¯)
[05:01:17] *** Quits: jazzy (~jaziz@user/jaziz) (Ping timeout: 240 seconds)
[05:02:07] <queue-> so programmerq: i found a solution
[05:02:17] <queue-> you can set docker NAT to external in hyper-v
[05:02:18] <queue-> lol
[05:02:33] *** Joins: jazzy (~jaziz@user/jaziz)
[05:02:35] <queue-> or you can bridge w/ the wsl and create ethernet -> win
[05:05:58] <transhumanist> from all the talk about alpine linux, I was thinking perhaps I should convert my old desktop to alpine linux, breath new life in it, but it doesnt seem to run chrome sadly, and worse it doesnt run nvidia and cuda so I cant use it as a desktop, too bad
[05:06:08] <transhumanist> also I wonder if kvm works with it
[05:06:27] <transhumanist> in other words can I run kvm on alpine linux
[05:07:14] <transhumanist> guees it does run kvm
[05:07:34] <transhumanist> but the nvidia is the problem because I do not have pcie pass through
[05:08:19] <transhumanist> guess I will avoid it for now
[05:08:30] *** Quits: luckiswithme (~luckiswit@103.226.104.2) (Ping timeout: 260 seconds)
[05:08:44] <transhumanist> will keep host with ubuntu
[05:10:30] <queue-> uh on docker?
[05:10:33] <queue-> gpu passthrough is ez
[05:10:39] <queue-> do you have a newer nvidia
[05:10:48] <queue-> or are you on a shitty version of virtualization
[05:10:53] <queue-> that wont allow gpu passthru
[05:11:00] <queue-> cause we can hotplug that badboy
[05:11:06] <queue-> send it straight to one of your kvm's
[05:11:24] <transhumanist> yes old shit..
[05:11:31] <queue-> is it an old nvidia?
[05:11:35] <queue-> if so it generally wont work
[05:11:41] <queue-> and u wouldnt have a major want for it to work there anyway
[05:11:42] <transhumanist> yup it has about 50 cuda cores
[05:11:44] <queue-> the CPU can probably process more
[05:12:00] <queue-> so if you allow hardware acceleration you'll just make it look like crap tbh
[05:12:07] <queue-> it is nice to try and take the load off of the cpu but
[05:12:16] <queue-> if the cost of that is quality, id think twice
[05:12:19] <transhumanist> yes I have been doing AI stuff for a while on this shit computer, just keep my stuff very small for tests 
[05:12:40] <queue-> i mean i show how to do gpu passthru within plex, its the same idea in docker
[05:12:41] <transhumanist> Yes I will keep ubuntu server miniumal with gui
[05:12:46] <queue-> https://github.com/awknode/docker-media-server
[05:12:58] <transhumanist> wow thanks!
[05:13:12] <queue-> np, everything commented out
[05:13:15] <queue-> thats waht u want
[05:13:15] <queue-> lol
[05:13:21] <transhumanist> cant wait till I can spend 3k on hardware and another 10 for video cards, but it will be at least two years
[05:13:33] <queue-> welcome to the party
[05:13:33] <queue-> :]
[05:13:46] <queue-> most of us run docker because we dont have money to just throw at random machines to run each app
[05:13:57] <queue-> plus its a bad utilization of resources at times
[05:14:01] <queue-> to NOT use docker
[05:15:08] *** Quits: bouncy (~ben@user/benoit) (Ping timeout: 256 seconds)
[05:15:42] *** Quits: Haxxa (~Haxxa@125-253-30-218.ip4.superloop.com) (Ping timeout: 256 seconds)
[05:16:43] <transhumanist> ya my worst enemy is nvidia stack , the fact that you cant have mulltiple copies of nvidia running in different containers with each one with a different cuda version and I still havent been able to figure out how to run the nvidia run time as a service to other containers
[05:17:16] <transhumanist> I forget what the container is called but you know the nvidia container I am referring too?
[05:17:46] <Flash> I ran into an issue with nvidia where the driver in my container was incompatible with the driver on my hardware
[05:18:00] <Flash> the container driver was too new
[05:18:55] <transhumanist> I have no idea how to run the runtime as a service to another container. this is what got me away from docker, I would like to stack containers like  a tree
[05:19:16] <transhumanist> have each container as a service to another 
[05:19:40] <transhumanist> cuts down the size and complexity and monolithic nature of the containers\
[05:21:44] <transhumanist> think its called nvidia-docker
[05:23:34] <transhumanist> this is what led to wsl2 and windows and nvidia as a combination. with docker-desktop, but this has the problem of breaking each time there is a patch and stuff that might be ok in a few years but not now
[05:23:50] <transhumanist> I was able to run models on it
[05:24:05] <transhumanist> but I started doing more iwth google colab because of all the limitations
[05:24:15] <transhumanist> you can pay for persistent storage on colab
[05:25:13] <transhumanist> anyway alpine on kvm is what I will try for this poject
[05:25:18] <transhumanist> project*
[05:30:22] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:32:27] *** Joins: DoofusCanadensis (~DoofusCan@2604:3d09:47c:f970:8af:e601:fdac:4bca)
[05:32:48] *** Joins: vlm (~vlm@user/vlm)
[05:32:58] *** Joins: alicef_ (~none@gentoo/developer/alicef)
[05:33:37] *** Quits: alicef (~none@gentoo/developer/alicef) (Ping timeout: 240 seconds)
[05:38:29] *** Quits: alicef_ (~none@gentoo/developer/alicef) (Quit: install gentoo)
[05:39:37] *** Joins: alicef (~none@gentoo/developer/alicef)
[05:44:17] *** Quits: tsal (~tsal@user/tsal) (Ping timeout: 240 seconds)
[05:51:29] *** Joins: tsal (~tsal@user/tsal)
[05:55:17] *** Joins: maryo_87 (~Maryo@user/maryo)
[06:00:13] <minimal> transhumsanist: re Alpine and KVM - I use virtio-scsi (rather than virtio-blk), virtio-rng, virtio-net with QEMU fine
[06:02:46] <transhumanist> thanks minimal
[06:03:29] <minimal> transhumanist: the Alpine "problem" with Nvidia is that Nvidia supply binary kernel module that is compiled for glibc - Alpine uses musl however as its libc
[06:03:43] *** Quits: stutz (~stutz@user/stutz) (Ping timeout: 268 seconds)
[06:04:43] <transhumanist> right it wont compile with musl (its an Nvidia problem , actually , I miss spoke
[06:05:32] <minimal> transhumanist: no, it *cannot* compile with musl as only Nvidia has the source code
[06:05:51] <transhumanist> ya bunch of tirants
[06:06:00] <transhumanist> tyrants*
[06:06:01] <minimal> they (Nvidia) might be able to compile it for musl but as musl-based distros are "niche" they're unlikely to do so
[06:06:34] <transhumanist> how about compile libc on musl?
[06:06:49] <transhumanist> then use it to compile nvidia
[06:07:10] *** Quits: jkovac1 (~jkovac1@user/jkovac1) (Remote host closed the connection)
[06:07:11] <minimal> eh? musl *is* a libc
[06:07:24] *** Joins: jkovac1 (~jkovac1@user/jkovac1)
[06:07:33] <minimal> in the same way that glibc and ulibc are also implementions of POSIX libcs
[06:08:02] *** Quits: yamchah2 (~yamchah2@user/yamchah2) (Ping timeout: 268 seconds)
[06:08:13] <transhumanist> sorry I meant compile glibc with musl so you can then compile nvidia with glibc?
[06:08:27] <minimal> part of the reason Alpine is so "lightweight" is because it uses libc. It you replaced Alpine's musl with glibc then its not really Alpine anymore
[06:09:02] <transhumanist> yes but it would work wouldnt it to get the graphics working on it?
[06:09:08] <minimal> you can't use the Nvidia unless you system uses gibc as its libc - basically everything on a Linux system is built for a single libc
[06:09:11] *** Joins: yamchah2 (~yamchah2@user/yamchah2)
[06:09:36] <minimal> you'd have to recompile the whole distro to do that - in which case why not just use another glibc-based distro?
[06:09:43] *** Joins: stutz (~stutz@user/stutz)
[06:09:55] <transhumanist> ah I miss understood I thought that once its compiled its all 1's and zeros at that point
[06:10:09] <transhumanist> that is machine language
[06:10:34] <minimal> normally binaries are dynamically linked to the libc
[06:10:37] <Flash> it's the difference between static linking and dynamic linking ... everything is dynamic these days
[06:10:47] <transhumanist> ah ok
[06:11:27] <minimal> you can statically link them but that's not often done (plus the size of the binaries grows as each then has a copy of parts of libc embedded)
[06:12:09] <minimal> Flash: apart from Go stuff typically?
[06:12:49] <transhumanist> so it would work perhaps to get video working on it? that is statically link the nvidia drivers and cuda and let the rest of the system be dynamically linked? Or do I miss understand?
[06:12:52] <Flash> go isn't an OS; the language support for go is probably dynamically linked as well?
[06:13:02] *** Quits: ssf (~ssf@user/ssf) (Ping timeout: 250 seconds)
[06:13:44] *** Quits: thekingofbandit (thekingofb@user/thekingofbandit) (Remote host closed the connection)
[06:14:03] *** Quits: DoofusCanadensis (~DoofusCan@2604:3d09:47c:f970:8af:e601:fdac:4bca) (Quit: So as you can see from this flowchSQUIRREL!!)
[06:15:20] <Flash> looks like go *is* statically linked
[06:15:48] <minimal> Flash: Go apps tend to be static - that's why there can be simple to turn into docker comtainers as you can just do "FROM scratch" and copy in the binary without any libs
[06:16:48] <transhumanist> so, whats the verdict it wouldnt work ?
[06:17:34] <minimal> transhumanist: Nvidia drivers you mean? use a glibc-based distro
[06:18:54] <transhumanist> ya but it sure would be great to use a super light distro as your root OS along with kqemu and have nvidia support, or are you suggesting if you have pcie pass through then its all ok except the shit desktop you would have for video support?
[06:21:20] *** Quits: thiras (~thiras@user/thiras) (Remote host closed the connection)
[06:21:32] <artok> debian-slim is quite slim
[06:21:40] *** Joins: thiras (~thiras@user/thiras)
[06:21:44] <artok> but adding nvidia there will be bloating it anyways =)
[06:22:11] <minimal> artok: debian-slim is a container though? transhuminist is talking about host OS  and VM OS
[06:22:36] <artok> well that minimal installation of debian for vm is also quite small
[06:22:56] <minimal> debian VM server image you mean?
[06:23:53] <artok> yeah what I recall, been a while since last time I installed debian on anything.. some vagrant magic was also used
[06:24:04] <transhumanist> I see ok
[06:24:10] <transhumanist> good to know
[06:24:36] <minimal> yeah you can make your own custom Debian images using things like debootstrap
[06:32:25] *** Quits: minimal (~minimal@user/minimal) (Quit: Leaving)
[06:50:25] *** Quits: travaldo (~travaldo@159.203.88.148) (Quit: travaldo)
[07:05:59] *** Quits: ada_ (uid242135@user/ada/x-9065485) (Quit: Connection closed for inactivity)
[07:06:30] *** Joins: nabidev (~nabidev@user/nabidev)
[07:07:45] *** Quits: nabidev (~nabidev@user/nabidev) (Client Quit)
[07:11:29] *** Quits: transhumanist (~steven@2601:196:8800:35f0:d396:27cb:9287:9f2d) (Remote host closed the connection)
[07:14:25] *** Quits: terrorjack (~terrorjac@2a01:4f8:1c1e:509a::1) (Quit: The Lounge - https://thelounge.chat)
[07:14:26] *** Quits: jjakob (~quassel@2a01:260:8028:10f0::62) (Quit: Either rebooting or something broke.)
[07:14:34] *** Quits: maryo_87 (~Maryo@user/maryo) (Ping timeout: 250 seconds)
[07:15:25] *** Joins: terrorjack (~terrorjac@2a01:4f8:1c1e:509a::1)
[07:17:15] *** Joins: jjakob (~quassel@2a01:260:8028:10f0::62)
[07:18:01] *** Joins: Atque (~Atque@user/atque)
[07:18:37] *** Quits: n0fun (~jack@94.134.88.64) (Ping timeout: 240 seconds)
[07:19:22] *** Joins: Haxxa (~Haxxa@125-253-30-155.ip4.superloop.com)
[07:25:57] *** Quits: Tabmow (~tabmow@user/tabmow) (Ping timeout: 240 seconds)
[07:28:25] *** Joins: Tabmow (~tabmow@user/tabmow)
[07:40:46] *** Quits: yuesbeez (uid458354@id-458354.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[07:50:25] <queue-> ok i lied
[07:50:30] <queue-> i couldnt get docker working on windwos lol
[07:50:38] <queue-> not on external devices
[07:50:47] <queue-> went back to vmware -> linux -> docker
[08:02:04] *** Joins: transhumanist (~steven@2601:196:8800:35f0:32d7:ebbd:e374:8a4)
[08:03:01] <transhumanist> o I have a peculiar problem, I try and edit using vi , vim or nano the repositories file to remove the comment from community and testing. Its a new install virtualized on kqemu and I am remote desktoping into it from windows over RDP (could be the problem I suppose) anyway the host os is ubuntu 20.04 with kqemu and running latest alpine. I CAN see the contents of the repositories file but I cant see it when I open it in the edi
[08:03:09] <transhumanist> any ideas from the alpine users here?
[08:05:04] <transhumanist> minimal rawtaz you around
[08:07:32] *** Quits: dinowilliam (~dinowilli@168.194.162.194) (Ping timeout: 240 seconds)
[08:13:09] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6)
[08:23:45] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[08:27:57] *** Quits: symb0l_ (~symb0l@user/symb0l) (Ping timeout: 240 seconds)
[08:29:59] *** Joins: symb0l (~symb0l@user/symb0l)
[08:54:14] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 250 seconds)
[09:13:22] *** Quits: Feuermagier (~Feuermagi@user/feuermagier) (Remote host closed the connection)
[09:17:01] *** Joins: Feuermagier (~Feuermagi@user/feuermagier)
[09:17:50] *** Joins: maryo_87 (~Maryo@user/maryo)
[09:25:41] *** Quits: Atque (~Atque@user/atque) (Quit: ...)
[09:26:50] *** Joins: statusbot1 (~statusbot@ec2-34-198-122-184.compute-1.amazonaws.com)
[09:27:31] *** Joins: Leonarbro_ (~Leonet@user/leonarbro)
[09:27:37] *** Joins: Flash_ (~Flash@user/flash)
[09:28:17] *** Joins: zuQe89 (~zuQe8@cpc105060-sgyl40-2-0-cust136.18-2.cable.virginm.net)
[09:28:22] *** Joins: cim4 (~cim@205.185.117.110)
[09:28:35] *** Quits: Cienisty (Cienisty@user/cienisty) (Killed (molybdenum.libera.chat (Nickname regained by services)))
[09:28:38] *** Joins: Cienisty (Cienisty@user/cienisty)
[09:29:10] *** Joins: jayray_ (~jayray@user/jayray)
[09:29:20] *** Joins: andypandy_ (~andypandy@h-178-174-148-234.A163.priv.bahnhof.se)
[09:29:41] *** Joins: Bitflux (~byte@byteflux.net)
[09:31:03] *** Joins: effprime_ (~effprime@user/effprime)
[09:31:17] *** Joins: packet_lozenge_ (~packet_lo@user/packet-lozenge/x-7125090)
[09:31:29] *** Joins: mjh4386_ (~mjh4386@165.22.53.231)
[09:31:49] *** Joins: Xat`_ (~Xat`@ns300217.ip-91-121-29.eu)
[09:31:55] *** Joins: SuperL4g (~akulbe@user/superlag)
[09:37:02] *** Joins: mihael (~mihael@ec2-54-189-227-26.us-west-2.compute.amazonaws.com)
[09:37:08] *** Quits: yamchah2 (~yamchah2@user/yamchah2) (*.net *.split)
[09:37:08] *** Quits: jkovac1 (~jkovac1@user/jkovac1) (*.net *.split)
[09:37:09] *** Quits: remote (~self@user/hackers) (*.net *.split)
[09:37:09] *** Quits: Tach (~Tach@user/tach) (*.net *.split)
[09:37:09] *** Quits: GeorgeK (~GeorgeK@cpe-70-92-5-228.wi.res.rr.com) (*.net *.split)
[09:37:09] *** Quits: andypandy (~andypandy@h-178-174-148-234.A163.priv.bahnhof.se) (*.net *.split)
[09:37:09] *** Quits: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net) (*.net *.split)
[09:37:09] *** Quits: Flash (~Flash@user/flash) (*.net *.split)
[09:37:09] *** Quits: LtHummus (~lthummus@97-126-121-3.tukw.qwest.net) (*.net *.split)
[09:37:09] *** Quits: denningsrogue (~denningsr@98.97.131.238) (*.net *.split)
[09:37:09] *** Quits: zuQe8 (~zuQe8@cpc105060-sgyl40-2-0-cust136.18-2.cable.virginm.net) (*.net *.split)
[09:37:09] *** Quits: simplicity (~yti@user/simplicity) (*.net *.split)
[09:37:09] *** Quits: setesat (~setesat@94.4.156.220) (*.net *.split)
[09:37:09] *** Quits: amnrst (~amnrst@45-79-201-163.ip.linodeusercontent.com) (*.net *.split)
[09:37:09] *** Quits: SuperLag (~akulbe@user/superlag) (*.net *.split)
[09:37:09] *** Quits: z8z (~x@ac255238.ppp.asahi-net.or.jp) (*.net *.split)
[09:37:09] *** Quits: mz` (~mz`@user/mz/x-8532539) (*.net *.split)
[09:37:09] *** Quits: chasmo77 (~chas77@c-71-193-246-4.hsd1.or.comcast.net) (*.net *.split)
[09:37:09] *** Quits: karstensrage (~karstensr@user/karstensrage) (*.net *.split)
[09:37:09] *** Quits: pfeilmann (~pfeilmann@c3po.mahr.pw) (*.net *.split)
[09:37:09] *** Quits: dlam (~dlam@dlam.me) (*.net *.split)
[09:37:09] *** Quits: queue- (~nerd@user/queue/x-7267619) (*.net *.split)
[09:37:09] *** Quits: jayray (~jayray@user/jayray) (*.net *.split)
[09:37:09] *** Quits: beenao (~beenao@user/beenao) (*.net *.split)
[09:37:09] *** Quits: scjosh (~scjosh@206.189.79.69) (*.net *.split)
[09:37:09] *** Quits: statusbot (~statusbot@ec2-34-198-122-184.compute-1.amazonaws.com) (*.net *.split)
[09:37:09] *** Quits: platta (~platta@pool-173-61-104-121.cmdnnj.fios.verizon.net) (*.net *.split)
[09:37:09] *** Quits: packet_lozenge (~packet_lo@user/packet-lozenge/x-7125090) (*.net *.split)
[09:37:09] *** Quits: Leonarbro (~Leonet@user/leonarbro) (*.net *.split)
[09:37:09] *** Quits: koolazer (~koo@user/koolazer) (*.net *.split)
[09:37:09] *** Quits: NOTevil (~notevil@user/notevil) (*.net *.split)
[09:37:09] *** Quits: ezekyel (~ezekyel@user/ezekyel) (*.net *.split)
[09:37:09] *** Quits: din0 (~dino@user/din0) (*.net *.split)
[09:37:09] *** Quits: compuguy (~ahall@user/compuguy) (*.net *.split)
[09:37:09] *** Quits: LordKalma (~LordKalma@server.ruilvo.com) (*.net *.split)
[09:37:09] *** Quits: DefiantN (~DefiantN@user/defiantn) (*.net *.split)
[09:37:09] *** Quits: Bossi (~quassel@p548379ef.dip0.t-ipconnect.de) (*.net *.split)
[09:37:09] *** Quits: BlackIkeEagle (~BlackIkeE@archlinux/trusteduser/blackikeeagle) (*.net *.split)
[09:37:09] *** Quits: Keridos_ (~Keridos@ironhide.de) (*.net *.split)
[09:37:09] *** Quits: effprime (~effprime@user/effprime) (*.net *.split)
[09:37:09] *** Quits: Byteflux (~byte@byteflux.net) (*.net *.split)
[09:37:09] *** Quits: Xat` (~Xat`@ns300217.ip-91-121-29.eu) (*.net *.split)
[09:37:09] *** Quits: cim (~cim@205.185.117.110) (*.net *.split)
[09:37:09] *** Quits: vinegar (~vinegar@user/vinegar) (*.net *.split)
[09:37:10] *** Quits: dox (~dox@dox.la) (*.net *.split)
[09:37:10] *** Quits: lazywalker (~lazywalke@user/lazywalker) (*.net *.split)
[09:37:10] *** Quits: opotin (~opotin@gyros.collabora.co.uk) (*.net *.split)
[09:37:10] *** Quits: programmerq (~programme@user/programmerq) (*.net *.split)
[09:37:10] *** Quits: vogelfrei (vogelfrei@user/vogelfrei) (*.net *.split)
[09:37:10] *** Quits: jaskal (~jaskal@user/jaskal) (*.net *.split)
[09:37:10] *** Quits: tetrapod (~tetrapod@user/tetrapod) (*.net *.split)
[09:37:10] *** Quits: archpc (~archpc@user/archpc) (*.net *.split)
[09:37:10] *** Quits: mjh4386 (~mjh4386@165.22.53.231) (*.net *.split)
[09:37:10] *** Quits: flynn (~mcbloch@user/flynn) (*.net *.split)
[09:37:11] *** zuQe89 is now known as zuQe8
[09:37:11] *** cim4 is now known as cim
[09:37:39] *** jayray_ is now known as jayray
[09:42:33] *** Joins: Atque (~Atque@user/atque)
[09:42:51] *** Joins: yamchah2 (~yamchah2@user/yamchah2)
[09:42:51] *** Joins: jkovac1 (~jkovac1@user/jkovac1)
[09:42:51] *** Joins: remote (~self@user/hackers)
[09:42:51] *** Joins: Tach (~Tach@user/tach)
[09:42:51] *** Joins: dox (~dox@dox.la)
[09:42:51] *** Joins: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net)
[09:42:51] *** Joins: denningsrogue (~denningsr@98.97.131.238)
[09:42:51] *** Joins: simplicity (~yti@user/simplicity)
[09:42:51] *** Joins: setesat (~setesat@94.4.156.220)
[09:42:51] *** Joins: amnrst (~amnrst@45-79-201-163.ip.linodeusercontent.com)
[09:42:51] *** Joins: z8z (~x@ac255238.ppp.asahi-net.or.jp)
[09:42:51] *** Joins: chasmo77 (~chas77@c-71-193-246-4.hsd1.or.comcast.net)
[09:42:51] *** Joins: pfeilmann (~pfeilmann@c3po.mahr.pw)
[09:42:51] *** Joins: dlam (~dlam@dlam.me)
[09:42:51] *** Joins: beenao (~beenao@user/beenao)
[09:42:51] *** Joins: scjosh (~scjosh@206.189.79.69)
[09:42:51] *** Joins: platta (~platta@pool-173-61-104-121.cmdnnj.fios.verizon.net)
[09:42:51] *** Joins: NOTevil (~notevil@user/notevil)
[09:42:51] *** Joins: ezekyel (~ezekyel@user/ezekyel)
[09:42:51] *** Joins: compuguy (~ahall@user/compuguy)
[09:42:51] *** Joins: LordKalma (~LordKalma@server.ruilvo.com)
[09:42:51] *** Joins: DefiantN (~DefiantN@user/defiantn)
[09:42:51] *** Joins: Bossi (~quassel@p548379ef.dip0.t-ipconnect.de)
[09:42:51] *** Joins: BlackIkeEagle (~BlackIkeE@archlinux/trusteduser/blackikeeagle)
[09:42:51] *** Joins: Keridos_ (~Keridos@ironhide.de)
[09:42:51] *** Joins: lazywalker (~lazywalke@user/lazywalker)
[09:42:51] *** Joins: opotin (~opotin@gyros.collabora.co.uk)
[09:42:51] *** Joins: vogelfrei (vogelfrei@user/vogelfrei)
[09:42:51] *** Joins: jaskal (~jaskal@user/jaskal)
[09:42:51] *** Joins: tetrapod (~tetrapod@user/tetrapod)
[09:42:51] *** Joins: archpc (~archpc@user/archpc)
[09:42:51] *** Joins: flynn (~mcbloch@user/flynn)
[09:44:50] *** Joins: mz` (~mz`@user/mz/x-8532539)
[09:45:08] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Remote host closed the connection)
[09:45:52] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[09:48:02] *** Quits: naicam| (~naicam|ne@wireguard/tunneler/naicamne) (Ping timeout: 252 seconds)
[09:50:22] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Ping timeout: 260 seconds)
[09:50:24] *** Quits: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6) (Quit: Client closed)
[09:53:36] *** Quits: emerent (~quassel@p200300cd57044312ba27ebfffed28a59.dip0.t-ipconnect.de) (Ping timeout: 250 seconds)
[09:53:45] *** Joins: emerent (~quassel@p200300cd57044332ba27ebfffed28a59.dip0.t-ipconnect.de)
[09:54:30] *** Joins: koolazer (~koo@user/koolazer)
[09:54:32] *** Quits: kenwoodfox (~quassel@user/kenwoodfox) (Ping timeout: 240 seconds)
[09:57:51] *** Quits: Czernobog (~Czernobog@user/czernobog) (Ping timeout: 245 seconds)
[10:02:24] *** Joins: maret (~maret@nat-88-212-37-89.antik.sk)
[10:13:49] *** Joins: kenwoodfox (~quassel@user/kenwoodfox)
[10:22:16] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6)
[10:34:06] *** Joins: phalanx54 (~thelounge@user/phalanx)
[10:34:28] *** Quits: jarthur (~jarthur@2603-8080-1540-002d-35e0-06b2-095d-de4d.res6.spectrum.com) (Quit: jarthur)
[10:35:57] *** Quits: phalanx5 (~thelounge@user/phalanx) (Ping timeout: 240 seconds)
[10:35:57] *** phalanx54 is now known as phalanx5
[10:40:50] *** Quits: phalanx5 (~thelounge@user/phalanx) (Ping timeout: 252 seconds)
[10:45:46] *** Quits: winstonsmith (~winstonsm@gateway/vpn/pia/winstonsmith) (Remote host closed the connection)
[10:46:32] *** Joins: winstonsmith (~winstonsm@gateway/vpn/pia/winstonsmith)
[10:48:24] *** Joins: phalanx5 (~thelounge@user/phalanx)
[11:02:07] *** Joins: ExeciN (~ExeciN@user/nicexe)
[11:06:11] *** Joins: martums54 (~martums@user/martums)
[11:09:00] *** Quits: martums5 (~martums@user/martums) (Ping timeout: 250 seconds)
[11:09:01] *** martums54 is now known as martums5
[11:12:38] *** Quits: bn_work (uid268505@id-268505.uxbridge.irccloud.com) (Quit: Connection closed for inactivity)
[11:13:49] *** Leonarbro_ is now known as Leonarbro
[11:13:51] *** Joins: CodeSpelunker (~CodeSpelu@user/codespelunker)
[11:29:48] *** Joins: emx (~emx@adsl-84-226-68-198.adslplus.ch)
[11:38:16] *** Flash_ is now known as Flash
[11:40:44] *** Joins: TheSilentLink_ (~TheSilent@user/thesilentlink)
[11:40:47] *** Quits: TheSilentLink (~TheSilent@user/thesilentlink) (Ping timeout: 252 seconds)
[11:42:08] *** TheSilentLink_ is now known as TheSilentLink
[11:47:16] *** Quits: remote (~self@user/hackers) (Ping timeout: 256 seconds)
[11:48:45] *** Joins: remote (~self@user/hackers)
[11:48:51] *** Joins: fedenix (~fedenix@gateway/tor-sasl/fedenix)
[11:49:02] *** Joins: lithium (~lithium@user/lithium)
[11:56:32] *** Quits: artok (~azo@mobile-access-bcee35-8.dhcp.inet.fi) (Ping timeout: 240 seconds)
[12:00:40] *** Joins: vidbina (~vid@dynamic-077-183-048-065.77.183.pool.telefonica.de)
[12:08:42] *** Joins: fibsifan (~quassel@2a01:c22:b1a7:6a00:ea40:93cb:19ac:a87a)
[12:11:50] *** Joins: iomari891 (~iomari891@105.112.138.38)
[12:11:57] *** Parts: emx (~emx@adsl-84-226-68-198.adslplus.ch) (Leaving)
[12:20:57] *** Quits: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469) (Ping timeout: 240 seconds)
[12:29:34] *** Quits: mihael (~mihael@ec2-54-189-227-26.us-west-2.compute.amazonaws.com) (Quit: Client closed)
[12:30:10] *** Joins: cotko (~cotko@188-230-251-153.dynamic.t-2.net)
[12:33:22] *** Joins: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469)
[12:35:06] *** Quits: sudoforge (~sudoforge@wireguard/tunneler/sudoforge) (Ping timeout: 260 seconds)
[12:49:22] *** Joins: dan01 (~dan01@2a02:2f0f:311c:1500:898d:8fc5:d036:d8fe)
[12:49:36] <dan01> Hey guys
[12:50:00] <dan01> In the Dockerfile can I build something locally and the only copy the build output to the container?
[12:53:27] <ikke> You cannot use a Dockerfile to run local commands
[12:54:00] <ikke> You could use multi-stage builds 
[12:59:35] *** Quits: _mikey (~mikey@user/mikey/x-4335048) (Quit: WeeChat 3.4)
[13:03:17] *** Quits: symb0l (~symb0l@user/symb0l) (Ping timeout: 240 seconds)
[13:06:47] <Sqaure> Im curious. I've been forced into using Nix because of project requirement. Have you heard about Nix/Nixos? Whats your view on it?
[13:12:02] *** Joins: TomyWork (~TomyLobo@p200300e80f0067002cd75dabac6c542d.dip0.t-ipconnect.de)
[13:16:54] *** Joins: zer0bitz (~zer0bitz@2001:2003:f444:a000:9102:5c27:2e48:97c2)
[13:25:12] *** Joins: locrian9 (~mike@211.sub-174-193-208.myvzw.com)
[13:32:44] <dan01> Sqaure: no idea
[13:34:58] *** Joins: astroda (astroda@gateway/vpn/airvpn/astroda)
[13:36:12] *** Quits: jjakob (~quassel@2a01:260:8028:10f0::62) (Quit: Either rebooting or something broke.)
[13:43:22] *** Joins: artok (~azo@mobile-access-b04849-185.dhcp.inet.fi)
[13:44:48] <ikke> I have heard, but not worked with it. What I hear is that the ideas behind Nix are sound, but it requires you to learn a complex custom language. 
[13:47:58] *** Joins: gproto23 (~gproto23@user/gproto23)
[13:50:47] *** Quits: CodeSpelunker (~CodeSpelu@user/codespelunker) (Quit: CodeSpelunker)
[13:51:55] <wez> nix?
[14:04:03] *** Quits: dan01 (~dan01@2a02:2f0f:311c:1500:898d:8fc5:d036:d8fe) (Ping timeout: 250 seconds)
[14:09:47] *** Quits: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469) (Remote host closed the connection)
[14:15:01] *** Quits: vidbina (~vid@dynamic-077-183-048-065.77.183.pool.telefonica.de) (Ping timeout: 240 seconds)
[14:15:31] *** Joins: ivii (~ivan@user/ivii)
[14:16:33] *** Joins: dan01 (~dan01@2a02:2f0f:311c:1500:898d:8fc5:d036:d8fe)
[14:19:50] *** Joins: bn_work (uid268505@id-268505.uxbridge.irccloud.com)
[14:32:10] *** Quits: remote (~self@user/hackers) (Ping timeout: 256 seconds)
[14:33:58] *** Joins: remote (~self@user/hackers)
[14:36:05] *** Quits: locrian9 (~mike@211.sub-174-193-208.myvzw.com) (Quit: Lost terminal)
[14:47:00] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[14:47:19] *** Joins: ExeciN (~ExeciN@user/nicexe)
[15:00:11] *** Joins: CoolerX (~CoolerX@user/coolerx)
[15:00:12] <CoolerX> Hi
[15:00:19] <CoolerX> I am not able to expose ports
[15:00:38] <CoolerX> When I do docker ps -a it shows the port as being exposed
[15:00:48] <CoolerX> but when I curl the port I get an empty response
[15:01:11] <CoolerX> so I went inside the container using docker exec -it <container-id> bash
[15:01:32] <CoolerX> and from inside the container when I curl localhost:8080 I get a different error
[15:01:43] <CoolerX> $ curl localhost:8080 
[15:01:44] <CoolerX> curl: (7) Failed to connect to ::1: Cannot assign requested address
[15:02:41] <CoolerX> I found this but there's no answer there https://stackoverflow.com/questions/61198348/cannot-assign-requested-address-1
[15:04:20] <simplicity> CoolerX: did you read this https://docs.docker.com/engine/reference/builder/#expose?
[15:04:45] <simplicity> The important part is "The EXPOSE instruction does not actually publish the port."
[15:06:40] *** Joins: maryo87 (~Maryo@user/maryo)
[15:09:37] *** Quits: maryo_87 (~Maryo@user/maryo) (Ping timeout: 240 seconds)
[15:09:43] *** Joins: luckiswithme (~luckiswit@103.226.104.2)
[15:09:47] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[15:10:06] *** Joins: ExeciN (~ExeciN@user/nicexe)
[15:12:15] <simplicity> Okay what I said is useless. Seems you've managed to publish the port correctly. Getting an empty response would mean that something works. What is in the container?
[15:12:26] *** Quits: zer0bitz (~zer0bitz@2001:2003:f444:a000:9102:5c27:2e48:97c2) (Read error: Connection reset by peer)
[15:16:57] *** Joins: itsalexjones (~itsalexjo@82.4.99.241)
[15:18:21] *** Quits: luckiswithme (~luckiswit@103.226.104.2) (Ping timeout: 250 seconds)
[15:21:19] <ash_worksi> CoolerX: what does it say exactly when for `docker ps` under PORTS ?
[15:21:26] <ash_worksi> CoolerX: what image are you using?
[15:22:56] <tabakhase> CoolerX use ipv4
[15:28:06] <CoolerX> ash_worksi, sorry I was afk
[15:28:35] <CoolerX> https://bpa.st/AJ3A
[15:28:46] <CoolerX> ash_worksi, I am using an image I just built
[15:28:57] <CoolerX> https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance
[15:29:22] <CoolerX> built using ./buildContainerImage.sh -x
[15:29:33] <ash_worksi> CoolerX: did you start this with docker-compose?
[15:29:45] <CoolerX> It's the Oracle database Express edition
[15:29:55] <CoolerX> ash_worksi, no I used docker run
[15:30:21] <CoolerX> $ docker run --rm -it --shm-size=1g -p 1521:1521 -p 8080:8080 -e ORACLE_PWD=mypass1234 oracle/database:21.3.0-xe
[15:30:53] <CoolerX> simplicity, yes ik
[15:31:12] <ash_worksi> hmmm
[15:31:25] <ash_worksi> it's a bit weird to be running the DB using -it
[15:31:33] <ash_worksi> are you sure you're not supposed to be using -d ?
[15:31:58] <CoolerX> ash_worksi, I have run other images that run servers on 8080 with the -it flag
[15:32:09] <CoolerX> and those didn't have this issue
[15:32:09] <ash_worksi> (btw, for testing purposes, if it makes seed loading easier you can use --tmpfs for the actual data dir)
[15:32:30] <CoolerX> ash_worksi, I am not mounting any volumes
[15:32:57] <ash_worksi> CoolerX: Idk oracle, but for PG, the entrypoint performs setup and then shuts down; if you don't run it -d you run into funkiness
[15:33:09] <ash_worksi> (I know, that was just a tip)
[15:34:43] <ash_worksi> but in any event, what does `docker logs condescending_goldstine` say?
[15:34:50] <ash_worksi> (the end anywy)
[15:34:52] <ash_worksi> anyway*
[15:35:37] <CoolerX> ash_worksi, the logs show the database as ready
[15:36:31] <CoolerX> https://termbin.com/i8gga
[15:37:13] *** Quits: maryo87 (~Maryo@user/maryo) (Ping timeout: 268 seconds)
[15:40:08] <ash_worksi> I am stumped
[15:41:03] <ash_worksi> are you using any custom scripts?
[15:41:19] <CoolerX> ash_worksi, where?
[15:41:29] <CoolerX> to run the image? no, I just pasted the command
[15:41:36] *** Joins: maryo (~Maryo@user/maryo)
[15:41:48] <ash_worksi> I mean, are the sql statements run from your scripts
[15:41:58] <CoolerX> ash_worksi, what script
[15:42:09] <CoolerX> I just did docker run
[15:42:11] <ash_worksi> (sounds like "no")
[15:42:13] <ash_worksi> okay
[15:42:15] <ash_worksi> just checking
[15:42:28] <CoolerX> and I am trying to curl the ports
[15:42:33] <CoolerX> curl localhost:8080
[15:42:36] <simplicity> https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance#running-oracle-database-21c18c-express-edition-in-a-container seems to show that what you're trying to reach on 8080 is actually on 5500?
[15:42:46] <CoolerX> curl localhost:1521
[15:43:02] <CoolerX> simplicity, hmm
[15:43:16] <CoolerX> simplicity, ok but the 1521 port should still work
[15:43:26] <simplicity> Maybe
[15:43:30] <CoolerX> return some sort of response, I think it uses Oracle's protocol
[15:43:35] <simplicity> You're not doing as they tell you to.
[15:43:58] <CoolerX> simplicity, I didn't see that section
[15:44:01] <ash_worksi> they mention 5500 in the log for enterprise edition
[15:44:14] <ash_worksi> erm "Enterprise Manager"
[15:44:14] <CoolerX> I was trying this https://github.com/oracle/docker-images/tree/main/OracleDatabase/SingleInstance#running-oracle-database-11gr2-express-edition-in-a-container
[15:44:58] <CoolerX> and there;s no way to expose a new port on a running container right?
[15:45:06] <CoolerX> just have to stop and start a new one>
[15:45:07] <CoolerX> ?
[15:45:28] <simplicity> Okay, I did not see that.
[15:45:35] <simplicity> I don't know. Life is too short to work with oracle products.
[15:46:43] <tabakhase> CoolerX use ipv4 *the second time
[15:46:44] *** Joins: vidbina (~vid@dynamic-077-183-048-065.77.183.pool.telefonica.de)
[15:47:09] <ash_worksi> fwiw, the Dockerfile says port.apex = 8080
[15:47:13] <CoolerX> tabakhase, what?
[15:47:21] <CoolerX> curl 127.0.0.1:8080 ?
[15:47:29] <tabakhase> yep
[15:47:41] <CoolerX> ok...
[15:48:12] <CoolerX> curl localhost:8080 has worked inside other containers
[15:48:25] <CoolerX> I guess it varies per image
[15:48:33] <ash_worksi> did 127.0.0.1 work in this one?
[15:48:55] <CoolerX> ash_worksi, I stopped that one, starting a new one
[15:48:58] <CoolerX> with port 5500
[15:49:14] <CoolerX> tabakhase, yeah it takes quite a while to start
[15:49:27] <CoolerX> simplicity, ^
[15:49:55] <CoolerX> It doesn't even have any data in it
[15:50:47] <ash_worksi> it _might_ speed it up to use `--tmpfs=/opt/oracle/oradata`
[15:50:50] <CoolerX> I wonder if it would be faster if I increased the shared memory from the default 64m
[15:51:05] <tabakhase> if anywhere, it may have worked inside THIS container - each container has its own localhost --- but thats kinda unrelated anyhow as the trouble seems to be curl resolving localhost to v6 not v4  (what kinda brings the followup of operatingsystem, how did you install docker, docker-version?)
[15:51:06] *** Joins: dinowilliam (~dinowilli@168.194.162.194)
[15:51:54] *** Joins: sultand (~sultand@office.rackhosting.com)
[15:52:01] * ash_worksi leaving this to tabakhase 
[15:52:42] <tabakhase> nana, not comming here to steal the party :P
[15:57:20] *** Quits: shokohsc (~shokohsc@lfbn-idf2-1-1472-129.w92-169.abo.wanadoo.fr) (Read error: Connection reset by peer)
[15:57:55] <CoolerX> simplicity, wow it's still only 40% complete
[15:58:07] <CoolerX> even slower than before somehow
[15:58:24] *** Joins: shokohsc (~shokohsc@lfbn-idf2-1-1472-129.w92-169.abo.wanadoo.fr)
[15:58:38] <CoolerX> tabakhase, it's curl inside the container
[15:58:38] *** Joins: zer0bitz (~zer0bitz@2001:2003:f444:a000:e4b0:adf8:305f:a850)
[15:59:02] <CoolerX> when I do curl from outside the container I get "52: empty response from server"
[15:59:21] *** Quits: jsmooth (~quassel@user/jsmooth) (Quit: jsmooth)
[15:59:52] <tabakhase> CoolerX so its working =) - as at least you are actually hitting whatever is in the container
[15:59:58] <CoolerX> tabakhase, the OS inside the container is Oracle Linux https://github.com/oracle/docker-images/blob/main/OracleDatabase/SingleInstance/dockerfiles/21.3.0/Dockerfile.xe#L21
[16:00:09] <tabakhase> (opposed to conenction refused or some other "early error")
[16:00:52] <CoolerX> tabakhase, oh is that what that is? I thought curl gives the "empty response" error even when nothing is listening on the port
[16:01:27] <CoolerX> $ curl localhost:8765
[16:01:27] <CoolerX> curl: (7) Failed to connect to localhost port 8765: Connection refused
[16:01:29] *** Joins: thiras (~thiras@user/thiras)
[16:01:30] <CoolerX> oh it is different
[16:01:42] <CoolerX> so when there's nothing listening it's connection refused
[16:02:00] <CoolerX> and when something is listening but there's no response then it's 52 empty response
[16:02:12] <CoolerX> curl: (52) Empty reply from server
[16:02:20] <tabakhase> CoolerX man in the middle it and find out (many example commands in that readme) https://github.com/nicolaka/netshoot - "empty response" is some kinda "TCP was fine, but the http in there was none/not-understood" or such likely
[16:02:25] *** Joins: kostkon_ (~androirc@2.142.66.94.static.otenet.gr)
[16:02:44] <CoolerX> $ curl localhost:5500
[16:02:45] <CoolerX> curl: (52) Empty reply from server
[16:02:54] <CoolerX> tabakhase, still doesn't work from outside
[16:04:12] <tabakhase> "To access OEM Express, start your browser and follow the URL: https://localhost:5500/em/ " -- note the S for example, trying to speak http to https will go poop for sure
[16:04:17] <CoolerX> tabakhase, https://bpa.st/5PXA
[16:04:22] <CoolerX> so I tried the ipv4
[16:04:28] <CoolerX> and it gives weird results
[16:04:53] <CoolerX> tabakhase, https? is it a self signed certificate?
[16:05:17] <tabakhase> what the hell i know - you are the one using some oracle crap image :D
[16:05:28] <CoolerX> tabakhase, you are right, it's https
[16:05:33] <CoolerX> and curl says it's invalid
[16:07:05] <CoolerX> tabakhase, https://bpa.st/7IFQ
[16:07:38] <tabakhase> lookn perfectly fine to me
[16:11:17] *** Quits: CoolerX (~CoolerX@user/coolerx) (Ping timeout: 240 seconds)
[16:16:30] *** Quits: fibsifan (~quassel@2a01:c22:b1a7:6a00:ea40:93cb:19ac:a87a) (Quit: https://quassel-irc.org)
[16:19:42] *** Quits: noex (~null@user/noex) (Ping timeout: 250 seconds)
[16:19:59] *** Quits: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net) (Quit: leaving)
[16:20:18] *** Joins: CoolerX (~CoolerX@user/coolerx)
[16:20:33] <CoolerX> I got dced
[16:20:41] <CoolerX> tabakhase, so it's working now
[16:20:49] <CoolerX> I am able to curl from inside the container
[16:20:51] *** Joins: noex (~null@user/noex)
[16:20:54] <CoolerX> get a 200 OK response
[16:21:46] *** Joins: FreEm1nD (~FreEm1nD@mail.guarapari.store)
[16:21:52] *** Quits: Trieste (T@user/pilgrim) (Ping timeout: 250 seconds)
[16:22:14] <tabakhase> you havent missied anything since "[13:37:37] <tabakhase> lookn perfectly fine to me"
[16:22:15] <CoolerX> but why does it say https://bpa.st/EJIQ
[16:22:26] <CoolerX> from outside the container
[16:22:45] <CoolerX> tabakhase, there's still some issue with docker port forwarding itself
[16:23:02] <CoolerX> I am not getting the same 200 OK from outside the container
[16:23:32] *** Joins: Trieste (T@user/pilgrim)
[16:24:04] <tabakhase> CoolerX thats up to curl/openssl - not docker routing
[16:24:09] <CoolerX> hmm https://stackoverflow.com/questions/45300911/curl-35-openssl-ssl-connect-ssl-error-syscall-in-connection-to-domain-com44
[16:24:32] <tabakhase> and sure, can be expected that your pc has different curl&openssl installed than some random container ;)
[16:24:57] <CoolerX> ok
[16:29:37] *** Joins: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net)
[16:43:31] *** Joins: gooble_gobble (~gooble_go@c-76-16-103-215.hsd1.il.comcast.net)
[16:50:28] *** Quits: CoolerX (~CoolerX@user/coolerx) (Read error: Connection reset by peer)
[16:51:11] *** Joins: CoolerX (~CoolerX@user/coolerx)
[16:57:04] *** Quits: gproto23 (~gproto23@user/gproto23) (Quit: Leaving)
[16:57:34] *** Joins: Jaro2k (~Jaro2k@host-185-78-133-160.jmdi.pl)
[16:58:15] *** Joins: ssf (~ssf@user/ssf)
[17:02:56] *** Quits: ssf (~ssf@user/ssf) (Ping timeout: 268 seconds)
[17:04:42] *** Joins: ssf (~ssf@user/ssf)
[17:08:24] *** Quits: Feuermagier (~Feuermagi@user/feuermagier) (Remote host closed the connection)
[17:08:41] *** Joins: Feuermagier (~Feuermagi@user/feuermagier)
[17:09:56] *** Joins: BinarySavior (~BinarySav@idlerpg/player/BinarySavior)
[17:10:04] *** Parts: Jaro2k (~Jaro2k@host-185-78-133-160.jmdi.pl) ()
[17:10:27] *** Joins: jazzy2 (~jaziz@user/jaziz)
[17:13:17] *** Quits: jazzy (~jaziz@user/jaziz) (Ping timeout: 240 seconds)
[17:15:58] *** Joins: Jaro2k (~Jaro2k@host-185-78-133-160.jmdi.pl)
[17:32:44] *** Joins: leitz (~LeamHall@072-182-158-027.res.spectrum.com)
[17:40:55] *** Joins: dino- (~dino@user/din0)
[17:42:03] *** Parts: Jaro2k (~Jaro2k@host-185-78-133-160.jmdi.pl) ()
[17:45:08] *** Joins: programmerq (~programme@user/programmerq)
[17:45:08] *** ChanServ sets mode: +o programmerq
[17:47:23] *** Joins: minimal (~minimal@user/minimal)
[17:49:01] *** Joins: almostdvs (~almostdvs@074-135-071-059.res.spectrum.com)
[17:49:45] <bn_work> during docker container run, ts there any way to ensure docker properly waits for container entrypoint to fully initialize vs just returning asynchronously?  Also, during docker stop, how to make docker gracefully signal shutdown vs just ripping the rug out and -9-ing it?
[17:53:54] *** Joins: symb0l (~symb0l@user/symb0l)
[17:58:51] <deuxexmachina> bn_work: maybe relevant https://forums.docker.com/t/gracefully-shutdown-docker-service/4066/2
[17:59:01] <tabakhase> bn_work for run (with -d) no, whatever else is using it has to wait, there is tooling like the "wait-for" or "wait-for-it" scripts/packages people generally use ((maybe one day healthchecks can be used to "wait in-engine" but nothing like this now)
[18:01:18] <programmerq> bn_work: yeah with -d you're just telling the docker cli to just start the container and then go into the background. You can introduce a healthcheck to the container and you could do a shell script that waits for the health status to flip to healthy.
[18:01:40] <tabakhase> bn_work for stopping, it shouldnt rugpull, if it does, means you messed up signals somewhere, make sure the container runs whatever the thing is as pid1 and uses "exec" if it has a entrypoint bashscript or so - if its a "fat container" with more than 1 thing, run an actual init-system (either dockers inbuild one, or runit,s6,dumb-init or whatever, just not systemd :D) -- for the rare case that 
[18:01:41] <tabakhase> you get signals, but your app is excotic on what it does https://docs.docker.com/engine/reference/builder/#stopsignal
[18:02:07] *** Joins: zer0bitz_ (~zer0bitz@2001:2003:f444:a000:4917:bc56:f54d:812b)
[18:02:36] <programmerq> the docker stop behavior is to send a sigterm to the containerized process and then wait for the process to exit for 10 seconds (configurable) and then send the kill. make your process handle the sigterm or use STOPSIGNAL like tabakhase mentioned if your containerized process needs something other than TERM for it to start its graceful shutdown procedure. Adjust the grace period too, if needed.
[18:03:05] <programmerq> I have one container that is a worker. I set the time for the graceful stop to several minutes to allow plenty of time for the current job to finish up before exiting.
[18:03:53] *** Quits: winstonsmith (~winstonsm@gateway/vpn/pia/winstonsmith) (Remote host closed the connection)
[18:04:13] *** Joins: winstonsmith (~winstonsm@gateway/vpn/pia/winstonsmith)
[18:05:52] *** Quits: zer0bitz (~zer0bitz@2001:2003:f444:a000:e4b0:adf8:305f:a850) (Ping timeout: 250 seconds)
[18:13:28] *** Joins: jarthur (~jarthur@2603-8080-1540-002d-35e0-06b2-095d-de4d.res6.spectrum.com)
[18:13:35] *** Joins: impermanence (~impermane@c-75-73-193-204.hsd1.mn.comcast.net)
[18:18:52] <bn_work> tabakhase: thanks, I'm wondering because when I do a docker start after a stop, there are stale PID files all over the place (not my choice to spit out PID files), I've been trying to write detection scripts on startup, but I feel I'm reinventing the wheel.  FWIW, I'm using alpine linux image, does it not include an init-system? 
[18:19:51] *** Joins: jkwnki (~jkwnki@p2e5796b1.dip0.t-ipconnect.de)
[18:20:27] <tabakhase> pretty sure all i mentioned also exist on alpine yes ;-) - heck, you can do it in pure bash/sh if you wanted :D
[18:21:28] <bn_work> programmerq: thanks, how do I adjust the grace period?  didn't see anything mentioned in https://docs.docker.com/engine/reference/builder/#stopsignal ?  also, this value probably varies depending on the hardware, is there not a way to make it only report success once the container entrypoint reports RC=0?  or is this like a fallback timeout value?
[18:21:53] <Tach> Has anyone compared the CPU/IO cycles between Ubuntu and Alpine ?
[18:22:13] <minimal> bn_work: as I just indicated to you the "standard/official" Alpine docker image is based on the Alpine mini root filesystem download which includes no init
[18:22:24] <tabakhase> Tach thats a nonvalid question i wanne say...
[18:22:48] <Tach> tabakhase and why is that by your meaning ?
[18:22:49] <programmerq> bn_work: I believe the stop grace period is only a runtime thing, unfortunately.
[18:22:50] <minimal> however there are plenty of Alpine-based docker images around that use various init's (tini, s6-overlay, etc)
[18:22:54] *** Quits: XV8 (~XV8@2601:5cb:c001:50:7138:38eb:1e16:f288) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[18:23:57] <programmerq> bn_work usually the signal needed to stop a process is specific to the application and not to the hardware. any linux thing no matter the hardware that looks for a sigterm will get a sigterm on arm or amd64 etc...
[18:24:41] <programmerq> minimal: docker also includes the capability of enabling an init without the need for the image to include one. docker run --init --rm -it alpine ps faux
[18:24:55] <programmerq> it shows up in the ps output as docker-init and iirc it's just tini
[18:26:27] <minimal> programmerq: yes I'm aware of that, its using tini as the init AFAIK
[18:26:37] *** Quits: polymorphic (~polymorph@user/polymorphic) (Ping timeout: 240 seconds)
[18:27:59] <tabakhase> Tach start by the deal that when in #docker - were generally talking about dead files on a disk, not even rly a distro -- the only somewhat relevant may be muslc, but where and what and how that actually shows up gets rather complicated and no generic "10% faster/slower" or such :D
[18:28:40] <programmerq> Tach: there are tons of comparisons of musl vs glibc for various situations (cpu cycles, memory usage, disk usage of compiled binaries, etc). benefits will vary by your specific application and usage pattern, but unless you're actively running into a performance issue with one or the other, both are sane choices.
[18:28:51] <programmerq> Are you trying to fill out a powerpoint slide to get buy-in from bosses?
[18:29:21] <tabakhase> if its for the poerpoint, that should be a alpine vs debian likely :P
[18:29:27] <Tach> tabakhase because everyone with docker talks about footprint... 
[18:29:35] <programmerq> lots of tech bosses know ubuntu but not debian
[18:29:35] <Tach> tabakhase same thing :)
[18:31:13] <programmerq> in general if you want to minimize your footprint, go with alpine if your application works nicely with musl. if your application doesn't support it, the ubuntu base image isn't too bad. Additionally, canonical has commercial support options so if you want to have someone to point a finger to if there's an issue, there's that.
[18:32:34] <programmerq> I use alpine regularly and I only worry about glibc vs musl in very few instances-- if I have a precompiled binary that is explicitly linked to glibc, then that's what I'll go with. Also, there's some subtle differences in the dns resolution stuff that can trip up some applications that depend on the glibc behavior, but I've only seen it cause an issue very rarely.
[18:32:56] <programmerq> Those are my anecdotes on alpine-vs-ubuntu 
[18:33:48] <minimal> yeah the main dns trip-up with Alpine is where someone assumes DNS lookup happens via the listed nameservers sequentually whereas Alpine does the lookups in parallel
[18:35:13] <minimal> some people expect to have their consul nameserver (e.g. for .consul TLD) consulted before their normal nameserver and stuff like that "breaks" in Alpine if any other listed nameserver gives a lookup failure before the consul nameserver
[18:40:50] *** Joins: DoofusCanadensis (~DoofusCan@2604:3d09:47c:f970:8af:e601:fdac:4bca)
[18:42:22] <symb0l> Yeah, we have to choose ubuntu > debian because they tend to drop security updates faster, + commercial support
[18:45:15] *** Quits: sultand (~sultand@office.rackhosting.com) (Ping timeout: 256 seconds)
[18:46:07] *** Quits: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6) (Quit: Client closed)
[18:47:17] *** Quits: jazzy2 (~jaziz@user/jaziz) (Ping timeout: 240 seconds)
[18:50:22] <bn_work> so just to backup a bit, and ensure I understand, having an init system will allow signals to properly propagate to shell launched children, ie: `&`, and avoids having to write something up in bash with traps, and wait, etc. (+ gives zombie reaping ability?).  Does tini have this?  
[18:51:57] <bn_work> minimal: that's good to know, does that apply for JVM (java)-based apps too?  or does it use it's own completely different DNS resolution libs?
[18:53:15] <minimal> bn_work: don't know about Java - apps in general go via the system's libc resolvers but no idea if the Java jvm bypasses this (doubt it but its possible)
[18:53:38] <minimal> bn_work: re init AFAIK is a very very basic init, so really just for the signal passing to children
[18:54:21] <tabakhase> Tach debian-slim (and i guess ubunutu has a analog) are fairly small already and usually get you well into the "download time is neglectable" range -- alpine comes kinda extra fancy for CI/tooling, if not going all-out and multistaging for binary-only or busybox or such
[18:54:41] <minimal> when you want to run multiple processes/services inside a single container and co-ordinate them (i.e. wait for ports to be listened on, etc) that's usually where something like s6-overlay comes in
[18:55:03] <Tach> tabakhase yeah indeed that is why I asked :)
[18:55:04] *** Joins: XV8 (~XV8@c-73-148-120-152.hsd1.va.comcast.net)
[18:55:06] <Tach> just curious
[18:55:18] <Tach> I want docker on Pine64's :P
[18:55:46] *** Joins: iniazi (~iniazi@47.150.4.234)
[18:56:19] <tabakhase> bn_work nothing will handle "random &"´s to all i know :D ((and if, then only for stop, but you may also need to restart an individual service)) - so, look how to ue the init of your choice i guess 
[18:56:45] *** Quits: iniazi (~iniazi@47.150.4.234) (Read error: Connection reset by peer)
[18:56:49] <tabakhase> (and as said, fat-containers are evil.... unless you have a very good reason to, just dont...)
[18:57:08] *** Joins: iniazi (~iniazi@47.150.4.234)
[18:58:30] <bn_work> hmm, didn't know Ubuntu did commercial support now, I guess they always did.  If it weren't for apt being awkward to use, I'd use it more :)
[18:58:43] <bn_work> yum (and so far apk) seem very easy to use
[19:00:45] <bn_work> tabakhase: yeah, not my choice on this fat container, seems it's an intermediary goal AFAICT
[19:00:53] <tabakhase> i used yum on suse in like.. 2002ish? to many bad memorys ;D debian kiddo ever after, ubuntu never been my jam...
[19:01:42] *** Joins: shutnoshut9 (~shutnoshu@ec2-52-29-68-122.eu-central-1.compute.amazonaws.com)
[19:02:10] *** Quits: maryo (~Maryo@user/maryo) (Remote host closed the connection)
[19:02:30] *** Joins: maryo (~Maryo@user/maryo)
[19:02:51] <bn_work> I just want a distro that has simple package management + optional commercial support to not scare away the windows users :)  I was on board with RH via CentOS but then it all went to s*it :(
[19:04:57] <tabakhase> bn_work thats a mixed bag... - on one end, a "start into docker" can be simpler when you can kinda rebuild your old server in stage1... especially when "not everything is ready to use volumes&networking-service-discovery" - but its also "the most complicated container one could build", so kinda a very bad "start into docker"
[19:05:26] *** Joins: AnapodoPsalidaki (~AnapodoPs@2a02:587:291a:6af6:31c:73a9:8a76:1e6)
[19:06:07] <tabakhase> (that is, ignoring the legit uses like shared memory for a moment)
[19:06:37] *** Quits: maryo (~Maryo@user/maryo) (Ping timeout: 240 seconds)
[19:07:30] *** Quits: AnapodoPsalidi (~AnapodoPs@195.46.31.29) (Ping timeout: 268 seconds)
[19:12:11] *** Joins: rv1sr (~rv1sr@user/rv1sr)
[19:20:29] <bn_work> yes, I wasn't necessarily suggesting RH/CentOS images for containers, just that it met both the commercial support + easy to use package manager checkboxes :) 
[19:20:48] <bn_work> s/images for containers/easy images for containers/
[19:27:08] *** Quits: shutnoshut9 (~shutnoshu@ec2-52-29-68-122.eu-central-1.compute.amazonaws.com) (Quit: Bye!)
[19:31:29] *** Joins: rsx (~dummy@ppp-188-174-136-190.dynamic.mnet-online.de)
[19:32:09] *** Joins: gebbione (~gebbione@cpc152037-finc21-2-0-cust213.4-2.cable.virginm.net)
[19:34:23] *** Quits: dan01 (~dan01@2a02:2f0f:311c:1500:898d:8fc5:d036:d8fe) (Remote host closed the connection)
[19:34:47] *** Joins: dan01 (~dan01@2a02:2f0f:311c:1500:898d:8fc5:d036:d8fe)
[19:35:05] *** Quits: rsx (~dummy@ppp-188-174-136-190.dynamic.mnet-online.de) (Client Quit)
[19:35:09] *** Quits: jkwnki (~jkwnki@p2e5796b1.dip0.t-ipconnect.de) (Read error: Connection reset by peer)
[19:36:44] *** Quits: junktext (~junktext@gateway/vpn/pia/junktext) (Remote host closed the connection)
[19:37:06] *** Quits: ExeciN (~ExeciN@user/nicexe) (Remote host closed the connection)
[19:37:53] *** Joins: junktext (~junktext@gateway/vpn/pia/junktext)
[19:41:07] *** Joins: jkwnki (~jkwnki@p2e5796b1.dip0.t-ipconnect.de)
[19:41:09] <gebbione> I am running ... export UID && ... && docker-compose run composer bash and I have some volumes mounted in /home/composer that seem to be getting a restricted permission when i ls the folder. My understanding is I should be able to read and write and the folder should be owned by the UID user? What am I missing as currently the permission restrictions break functionality
[19:42:00] <gebbione> the docker-compose file has user: $UID in the service definition
[19:43:47] *** Quits: pvdp4 (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au) (Remote host closed the connection)
[19:50:32] *** Quits: CoolerX (~CoolerX@user/coolerx) (Read error: Connection reset by peer)
[19:52:59] *** Joins: CoolerX (~CoolerX@user/coolerx)
[19:53:27] <tabakhase> gebbione by volume do you mean bindmount? - and did this maybe not exist? - then its docker-daemon (as root) who creates the folder
[19:56:35] <gebbione> ok i must be doing something wrong in make
[19:56:49] <gebbione> i have this definition at the top
[19:56:50] <gebbione> COMPOSER_CACHE_DIR := $$HOME/.cache/composer
[19:57:11] <gebbione> my understanding is i need to use the two dollar signs to make that work correctly
[19:58:11] <gebbione> and indeed if i echo it i get the right absolute path to my folder on my machine
[19:58:50] <gebbione> so yeas a bind mount from the host using an absolute path
[19:59:09] <ikke> gebbione: where do you have this? := is not docker(-compose), not (ba)sh
[19:59:18] <gebbione> it is make
[19:59:20] <ikke> ah
[20:00:14] *** Quits: ssf (~ssf@user/ssf) (Quit: Lost terminal)
[20:00:30] <gebbione> i wonder if i need double quotes so this value fully expands in make too
[20:00:39] <gebbione> inside the make task
[20:02:10] *** Joins: maryo (~Maryo@user/maryo)
[20:03:18] *** Joins: XATRIX (~xatrix@88.81.252.19)
[20:19:47] *** Joins: ada_ (uid242135@user/ada/x-9065485)
[20:19:47] *** ChanServ sets mode: +o ada_
[20:20:30] *** Joins: jjakob (~quassel@2a01:260:8028:10f0::62)
[20:23:32] *** Joins: drillbyt (drillbyt@user/drillbyt)
[20:26:05] *** Quits: XV8 (~XV8@c-73-148-120-152.hsd1.va.comcast.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[20:28:30] *** Joins: AnapodoPsalidi (~AnapodoPs@154.57.4.229)
[20:31:02] *** Quits: AnapodoPsalidaki (~AnapodoPs@2a02:587:291a:6af6:31c:73a9:8a76:1e6) (Ping timeout: 240 seconds)
[20:34:11] *** Joins: sudoforge (~sudoforge@wireguard/tunneler/sudoforge)
[20:36:09] *** Joins: CoolerY (~CoolerX@user/coolerx)
[20:39:06] *** Quits: n9nes (~n9nes@user/n9nes) (Ping timeout: 245 seconds)
[20:39:56] *** Quits: CoolerX (~CoolerX@user/coolerx) (Ping timeout: 256 seconds)
[20:40:17] *** Quits: kostkon_ (~androirc@2.142.66.94.static.otenet.gr) (Quit: AndroIRC - Android IRC Client ( http://www.androirc.com ))
[20:46:31] *** Quits: gearnode (~gearnode@2a01cb000ce2c100f22f74fffedefec1.ipv6.abo.wanadoo.fr) (Quit: WeeChat 3.4)
[20:49:11] *** Quits: XATRIX (~xatrix@88.81.252.19) (Quit: Goodbye and wish you luck!)
[20:54:18] *** Quits: jarthur (~jarthur@2603-8080-1540-002d-35e0-06b2-095d-de4d.res6.spectrum.com) (Quit: jarthur)
[20:58:11] *** Joins: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469)
[20:58:33] *** Joins: svm_invictvs_ (~svm_invic@user/svm-invictvs/x-6696469)
[21:03:17] *** Joins: XV8 (~XV8@2601:5cb:c001:50:ddea:1b08:25c:b114)
[21:03:41] *** Quits: XV8 (~XV8@2601:5cb:c001:50:ddea:1b08:25c:b114) (Client Quit)
[21:03:44] *** Quits: rv1sr (~rv1sr@user/rv1sr) (Ping timeout: 256 seconds)
[21:06:49] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[21:07:25] *** Quits: CoolerY (~CoolerX@user/coolerx) (Ping timeout: 250 seconds)
[21:08:00] *** Joins: CoolerX (~CoolerX@user/coolerx)
[21:08:39] *** Joins: ExeciN (~ExeciN@user/nicexe)
[21:11:11] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Ping timeout: 245 seconds)
[21:11:14] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6)
[21:11:15] <statusbot1> Status update: The repositories API is experiencing intermittent failures. Our team is investigating. Serving of images (pulls) is functioning normally. -- https://status.docker.com/pages/incident/533c6539221ae15e3f000031/61f42ab9b599c8052dc4cb2f
[21:12:12] *** Quits: maryo (~Maryo@user/maryo) (Ping timeout: 250 seconds)
[21:17:11] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[21:22:50] *** Joins: maryo (~Maryo@user/maryo)
[21:28:07] *** Joins: jarthur (~jarthur@2603-8080-1540-002d-35e0-06b2-095d-de4d.res6.spectrum.com)
[21:34:54] *** Quits: remote (~self@user/hackers) (Ping timeout: 256 seconds)
[21:42:12] *** Quits: TomyWork (~TomyLobo@p200300e80f0067002cd75dabac6c542d.dip0.t-ipconnect.de) (Quit: Leaving)
[21:50:44] *** Quits: maryo (~Maryo@user/maryo) (Ping timeout: 252 seconds)
[21:52:15] *** Quits: jkwnki (~jkwnki@p2e5796b1.dip0.t-ipconnect.de) (Ping timeout: 250 seconds)
[21:54:40] *** Quits: bzyx (~quassel@89-69-20-238.dynamic.chello.pl) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[21:55:46] *** Quits: TheSilentLink (~TheSilent@user/thesilentlink) (Ping timeout: 245 seconds)
[21:58:44] *** Joins: TheSilentLink (~TheSilent@user/thesilentlink)
[22:00:36] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Remote host closed the connection)
[22:07:34] *** Joins: Jaro2k (~Jaro2k@host-185-78-133-160.jmdi.pl)
[22:09:07] *** Quits: svm_invictvs_ (~svm_invic@user/svm-invictvs/x-6696469) (Quit: Leaving)
[22:14:07] *** Joins: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553)
[22:16:45] *** Joins: zumba_addict24 (~zumba_add@c-71-194-58-34.hsd1.il.comcast.net)
[22:16:52] *** Joins: XATRIX (~xatrix@88.81.252.19)
[22:17:02] *** Parts: Jaro2k (~Jaro2k@host-185-78-133-160.jmdi.pl) ()
[22:17:14] <zumba_addict24> Hi all. I created a new account in docker and upgraded to pro. Do I use the username I created in docker login command?
[22:23:10] *** Joins: greatgatsby__ (~greatgats@bras-base-toroon0411w-grc-52-142-114-106-7.dsl.bell.ca)
[22:24:26] *** Joins: umoga (~yes@my.irc.rocks)
[22:24:59] *** Joins: russjr080 (~russjr08@fw.internal.russ.network)
[22:25:02] *** Joins: SmokenatorZ66 (~Smokenato@177.62.66.238)
[22:25:05] *** Joins: cryocaustik73 (~cryocaust@user/cryocaustik)
[22:25:10] *** Joins: jimmyb7 (~jimmyb@user/jimmyb)
[22:25:14] *** Quits: chodonne (~chodonne@ec2-3-18-56-136.us-east-2.compute.amazonaws.com) (Ping timeout: 256 seconds)
[22:25:14] *** Quits: ivaat (~yes@my.irc.rocks) (Ping timeout: 256 seconds)
[22:25:14] *** Quits: cryocaustik7 (~cryocaust@user/cryocaustik) (Read error: Connection reset by peer)
[22:25:14] *** Quits: jimmyb (~jimmyb@user/jimmyb) (Quit: Ping timeout (120 seconds))
[22:25:14] *** Quits: russjr08 (~russjr08@fw.internal.russ.network) (Read error: Connection reset by peer)
[22:25:14] *** Quits: dademurphy (~dademurph@45.63.16.83) (Ping timeout: 256 seconds)
[22:25:14] *** Quits: Jonno_FTW (~come@user/jonno-ftw/x-0835346) (Ping timeout: 256 seconds)
[22:25:14] *** russjr080 is now known as russjr08
[22:25:14] *** Quits: kraucrow (~polarizin@188.166.72.81) (Ping timeout: 256 seconds)
[22:25:14] *** Quits: adamus1red (~M@user/mrr) (Excess Flood)
[22:25:14] *** Quits: remolej (~kenoba@user/kenoba) (Read error: Connection reset by peer)
[22:25:14] *** cryocaustik73 is now known as cryocaustik7
[22:25:15] *** jimmyb7 is now known as jimmyb
[22:25:22] *** Joins: philivey9426 (~polarizin@188.166.72.81)
[22:25:33] *** Joins: remolej (~kenoba@user/kenoba)
[22:25:41] *** Quits: Forkk (~forkk@li926-228.members.linode.com) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: coc0nut (~coc0nut@user/coc0nut) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: SmokenatorZ6 (~Smokenato@177.62.66.238) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: beencubed (~beencubed@209.131.238.248) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: erhandsome (~erhandsom@user/erhandsome) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: L0j1k (~L0j1k@user/l0j1k) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: greatgatsby_ (~greatgats@bras-base-toroon0411w-grc-52-142-114-106-7.dsl.bell.ca) (Ping timeout: 256 seconds)
[22:25:41] *** SmokenatorZ66 is now known as SmokenatorZ6
[22:25:41] *** Quits: Fjord8 (~Fjord@c-73-14-198-35.hsd1.co.comcast.net) (Ping timeout: 256 seconds)
[22:25:41] *** Quits: feoh (~feoh@idlerpg/player/feoh) (Ping timeout: 256 seconds)
[22:25:45] *** Joins: chodonne (~chodonne@ec2-3-18-56-136.us-east-2.compute.amazonaws.com)
[22:26:01] *** Joins: feoh (~feoh@idlerpg/player/feoh)
[22:26:07] *** Joins: coc0nut (~coc0nut@user/coc0nut)
[22:26:08] *** Joins: dademurphy (~dademurph@45.63.16.83)
[22:26:15] *** Quits: dodo (~dodo@user/dodo) (Ping timeout: 256 seconds)
[22:26:16] *** Joins: adamus1red_ (~M@user/mrr)
[22:26:29] *** adamus1red_ is now known as adamus1red
[22:26:31] *** Joins: erhandsome (~erhandsom@user/erhandsome)
[22:26:35] *** Joins: dodo (~dodo@user/dodo)
[22:27:04] *** Joins: Fjord8 (~Fjord@c-73-14-198-35.hsd1.co.comcast.net)
[22:27:11] *** Joins: beencubed (~beencubed@209.131.238.248)
[22:27:42] *** Joins: L0j1k (~L0j1k@user/l0j1k)
[22:27:42] *** ChanServ sets mode: +o L0j1k
[22:29:57] *** Quits: pgloor (~petergloo@mix.cubus.space) (Read error: Connection reset by peer)
[22:30:05] *** Joins: pgloor1 (~petergloo@mix.cubus.space)
[22:30:28] *** Joins: Forkk (~forkk@li926-228.members.linode.com)
[22:30:38] *** Quits: vikonen (vikonen@seri.fi) (Read error: Connection reset by peer)
[22:30:54] *** Quits: Null_A (~null_a@2601:645:8700:2290:8935:4edf:b32:6553) (Remote host closed the connection)
[22:31:19] *** Quits: fedenix (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[22:31:32] *** Quits: dabbill (~dabbill@174.31.247.40) (Remote host closed the connection)
[22:31:40] *** Joins: fedenix (~fedenix@gateway/tor-sasl/fedenix)
[22:34:58] *** Quits: vidbina (~vid@dynamic-077-183-048-065.77.183.pool.telefonica.de) (Ping timeout: 256 seconds)
[22:35:19] *** Quits: thegodsquirrel (~thegodsqu@user/thegodsquirrel) (Ping timeout: 256 seconds)
[22:35:57] *** Joins: dabbill (~dabbill@174.31.247.40)
[22:38:35] *** Joins: thegodsquirrel (~thegodsqu@user/thegodsquirrel)
[22:41:25] *** withered_wolf is now known as thoughtfu
[22:43:18] *** thoughtfu is now known as withered_wolf
[22:43:48] <statusbot1> Status update: The problem has been identified and a fix is in progress. -- https://status.docker.com/pages/incident/533c6539221ae15e3f000031/61f42ab9b599c8052dc4cb2f
[22:48:05] <zumba_addict24> Is it possible to specify docker id/password in Dockerfile?
[22:48:26] <DoofusCanadensis> why would you want to do that?
[22:48:42] <BtbN> You can specify whatever you want in your Dockerfile, but putting secrets there seems unwise
[22:49:02] <zumba_addict24> i'm trying to figure out how to pull from docker hub then push to our internal repo
[22:49:22] <BtbN> What's there to figure out?
[22:49:23] <zumba_addict24> some of our projects use external images like nodejs
[22:49:36] <zumba_addict24> we are currently using docker login to login to our internal registry
[22:50:11] <zumba_addict24> so maybe, docker login to docker hub first and build the image, the docker login again to our internal registry
[22:50:32] <BtbN> Why log into docker hub at all, if all you're doing is pulling public images?
[22:50:39] <DoofusCanadensis> rate limits
[22:50:40] <tabakhase> its more a "both" than a "again" but sure if thats what you need
[22:50:47] <zumba_addict24> we were getting rate limits issues now
[22:51:02] <DoofusCanadensis> but that was well known for a while
[22:51:04] <zumba_addict24> we bought licenses today
[22:51:13] <zumba_addict24> we forgot about it
[22:51:15] <BtbN> Ah, just login like normal then.
[22:51:21] <tabakhase> (consider using reg to skip the unpacking on the daemon  https://github.com/genuinetools/reg )
[22:51:35] <DoofusCanadensis> docker can't log into more than one repository at a time?
[22:51:55] <zumba_addict24> what do you mean?
[22:52:09] <tabakhase> and if your issue is more CI  or builds in the LAN in the office, consider setting up a pull through cache instead -> https://docs.docker.com/registry/recipes/mirror/
[22:52:11] <zumba_addict24> the error I remember is "you've reached your rate limit"
[22:52:44] <zumba_addict24> the devs build nightly jobs
[22:53:20] <zumba_addict24> so I guess, anyting that is accessed a lot, we can put it in our existing internal registry(artifactory)
[22:53:50] <DoofusCanadensis> you add your account to artifactory and have it do the image pulls for you
[22:55:39] <zumba_addict24> what about the FROM line in every Dockerfile in the projects?
[22:56:47] <zumba_addict24> for example, FROM node:latest, and docker login is currently to our Artifactory. I just hope it knows where to pull it
[22:56:53] <tabakhase> if you mirror, you have to change them (use build args to prefix for example) -- pull through cache is a deamon-setting so nothing needs to be changed
[22:57:21] <zumba_addict24> is docker login not enough?
[22:57:33] <minimal> zumba_addict24: "FROM node:latest" makes no sense in that situation - the docker image you copy now and the one you copy in 10 minutes time may be completely different
[22:57:45] <tabakhase> docker login does literally nothing more but writing a json file
[22:58:07] <minimal> i.e would that be for instance version 1.2 of node? or version 1.2.1? or version 1.3?
[22:58:13] <zumba_addict24> Got it. Please help me since I'm confused on where to do the changes the best
[22:58:42] <zumba_addict24> so in Artifactory, I think I can find the username/password settings. However, i'm confused on the Dockerfile of users
[22:59:05] <tabakhase> dockerfile aint got nothing todo with auth
[22:59:06] <minimal> zumba_addict24: you should be using version numbers, not "latest"
[22:59:23] <statusbot1> Status update: The incident has been resolved. Some images pushed during this period may not appear in repository listings. Please re-push those images with a new tag. -- https://status.docker.com/pages/incident/533c6539221ae15e3f000031/61f42ab9b599c8052dc4cb2f
[23:00:07] <zumba_addict24> so tabakhase, that means, their FROM node:14.16.0 will remain like that but how will it know that it must pull it from our Artifactory instead of Docker Hub?
[23:00:31] <Flash> the registry is part of the name. Only DockerHub is implicit, and this cannot be changed
[23:00:39] <DoofusCanadensis> read Artifactory's documentation on how to set things up
[23:01:00] <tabakhase> zumba_addict no, only pull through cache allows to keep "FROM node" - anythign else needs "FROM myrepo.com:5000/node" or whatever it may be
[23:01:13] <Flash> so, FROM artifactory.yourco.com/docker/node:15.16.0
[23:01:36] <zumba_addict24> ah, I thought you said that developers doesn't need to do any changes
[23:01:57] <tabakhase> [20:26:53] <tabakhase> if you mirror, you have to change them (use build args to prefix for example) -- pull through cache is a deamon-setting so nothing needs to be changed
[23:02:00] <tabakhase> is a & b
[23:02:03] <zumba_addict24> ah
[23:02:07] <zumba_addict24> missed it, cool
[23:02:16] <zumba_addict24> I will check out their documentation on how to set things up
[23:03:26] <tabakhase> guess "nothing needs to be changed" is more precisely a "nothing needs to be changed on the individual builds" - as its a onetime change to /etc/docker/daemon.json ;-)
[23:03:38] <zumba_addict24> so i need to do 2 things. 1) Configure docker in Artifactory to use "docker id" 2) Inform developers to make changes to their Dockerfile(s) and point it instead to the internal one
[23:03:38] *** Quits: iomari891 (~iomari891@105.112.138.38) (Quit: WeeChat 3.3)
[23:05:04] <zumba_addict24> Thank you all. I hope I got it right
[23:08:15] <tabakhase> "mirroring" is rly more a auditing/backups thing usually - for ratelimits/performance hosting a pull through cache in your LAN is neater  ((say, for things like gitlab-dind builds its massive too even on a single host/runner))
[23:18:24] *** Joins: analogsalad (~analogsal@user/analogsalad)
[23:27:46] <zumba_addict24> oh got it. I can build a new machine too for that
[23:28:07] <zumba_addict24> for now, to get devs' builds working, I'll do that
[23:28:22] <zumba_addict24> that's the link you sent earlier right?
[23:28:39] <zumba_addict24> this -  https://docs.docker.com/registry/recipes/mirror/
[23:31:53] *** Quits: moldorcoder7 (~moldorcod@37.120.143.28) (Quit: %bye mirc%)
[23:32:45] *** Joins: moldorcoder7 (~moldorcod@37.120.143.28)
[23:39:34] *** Quits: cotko (~cotko@188-230-251-153.dynamic.t-2.net) (Ping timeout: 256 seconds)
[23:44:57] *** Quits: XATRIX (~xatrix@88.81.252.19) (Ping timeout: 240 seconds)
[23:50:39] <Tach> Is docker-compose not capable of creating a file which needs to be mapped ?
[23:51:28] <symb0l> Tach: You mean youre trying to volume mount a file that doesn't exist and want it to automatically create it?
[23:51:44] <Tach> symb0l exactly
[23:51:47] <symb0l> No
[23:51:55] <Tach> symb0l damn annoying
[23:52:37] <Flash> zumba_addict24: I abandoned docker mirroring on Artifactory; I only use it for our developed images. Also as a common practice, my Dockerfile has an ARG that defines the registry, so I can easily override it during image development
[23:52:54] <Tach> symb0l why not actually ? some -f tag on that line would have solved it
[23:54:40] <symb0l> I'm not a docker dev, no idea, I just know it doesn't :)
[23:55:05] <Tach> symb0l I hoped different but thanks :D
[23:55:18] <Tach> symb0l maybe there is a hidden option :P
