[00:01:10] *** Quits: TheGuestMovie (~TheGuestM@173.231.114.74) (Quit: Client closed)
[00:02:32] <ville> lpapp: you stick the __declspec((export)) on the specialization if i recall. when you include the header where you use the header/library the header's declaration should have a __declspec((dllimport))? i don't deal with windows very regularly
[00:05:12] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[00:10:18] <lpapp> but it does not seem to work like that according to the linker
[00:10:30] <lpapp> the linker seems to be looking for the implementation of the function template.
[00:11:26] <lpapp> I do not deal with templates and visibility much myself
[00:11:32] <lpapp> so, this is also new for me to learn.
[00:11:43] <lpapp> I only get visibility issues in new templated stuff
[00:12:37] <ville> you'd have to make a full example so people can see what it is exactly that you're doing
[00:13:07] <lpapp> do not worry, I will learn more about templates.
[00:13:14] <lpapp> it is a dark area of c++
[00:13:27] <ville> this is not about templates at this point
[00:13:32] <lpapp> it is
[00:13:37] <ville> this is about how windows does things
[00:13:44] <lpapp> everything else works fine except template stuff as mentioned already
[00:13:47] <lpapp> no
[00:13:54] <lpapp> if that was the case, no other methods would work
[00:13:56] <lpapp> or classes
[00:14:01] <lpapp> but that is not the case in my context at all
[00:14:14] <lpapp> I literally only get issues with the template stuff
[00:16:43] <ville> as far as c++ is concerned the templates are correct. you are now fighting windows idiosynchrasies
[00:18:52] <ville> and this is one of those cases where you would use a macro that resolves to __declspec((dllexport)) or __declspec((dllimport)) whether the dso is being built or being used by someone
[00:26:53] <lpapp> I do not think that is the issue myself.
[00:27:10] <lpapp> otherwise, like I said, other functions would have the same issue.
[00:27:16] <lpapp> if it was a generic windows issue.
[00:27:36] *** Quits: wootehfoot (~wootehfoo@user/wootehfoot) (Read error: Connection reset by peer)
[00:30:57] *** Joins: Leone (~Leo@45.72.233.136)
[00:33:07] *** Joins: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca)
[00:39:12] *** Quits: sord937 (~sord937@gateway/tor-sasl/sord937) (Quit: sord937)
[00:50:11] *** Quits: emerent (~quassel@p200300cd574855b5ba27ebfffed28a59.dip0.t-ipconnect.de) (Ping timeout: 260 seconds)
[00:50:19] *** Joins: emerent (~quassel@p200300cd57485529ba27ebfffed28a59.dip0.t-ipconnect.de)
[00:54:06] *** Joins: kurfen (~kurfen@45.152.181.20)
[01:03:13] *** Joins: CaCode_ (~CaCode@user/cacode)
[01:06:08] *** Quits: CaCode- (~CaCode@user/cacode) (Ping timeout: 268 seconds)
[01:08:39] *** Joins: CaCode- (~CaCode@user/cacode)
[01:09:58] *** Quits: vdamewood (~vdamewood@fedora/vdamewood) (Quit: My MacBook Pro has gone to sleep. ZZZzzz…)
[01:11:11] *** Quits: CaCode_ (~CaCode@user/cacode) (Ping timeout: 246 seconds)
[01:11:24] *** Quits: pulse (~pulse@user/pulse) (Read error: Connection reset by peer)
[01:15:27] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[01:18:46] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[01:20:06] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[01:27:13] *** Quits: CodeMouse92 (~CodeMouse@user/codemouse92) (Quit: Oh freddled gruntbuggly | Thy micturations are to me | As plurdled gabbleblotchits | On a lurgid bee)
[01:31:07] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[01:33:35] *** Quits: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net) (Ping timeout: 246 seconds)
[01:33:44] *** Joins: paule32_ (~paule32@user/paule32)
[01:35:55] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Ping timeout: 260 seconds)
[01:36:59] *** Quits: paule32 (~paule32@user/paule32) (Ping timeout: 264 seconds)
[01:37:13] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[01:37:21] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[01:37:21] *** ChanServ sets mode: +v npaperbot
[01:44:33] *** Joins: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net)
[01:47:29] *** Parts: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it) ()
[01:53:00] *** Quits: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca) (Ping timeout: 260 seconds)
[01:56:06] *** Quits: plastico (~plastico@neomutt/plastico) (Quit: WeeChat 3.3)
[01:59:43] *** Quits: kraa (~kraa@107-190-7-216.cpe.teksavvy.com) (Ping timeout: 260 seconds)
[02:03:27] *** Joins: pulse (~pulse@user/pulse)
[02:11:43] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:89ae:7a91:7b8d:9618)
[02:12:18] *** Quits: spaceangel (~spaceange@ip-89-176-181-220.net.upcbroadband.cz) (Remote host closed the connection)
[02:19:53] *** Quits: CalamityBlue (~CalamityB@cpe-108-185-144-94.socal.res.rr.com) (Read error: Connection reset by peer)
[02:22:10] *** Quits: Skyfire (~pyon@user/pyon) (Quit: WeeChat 3.3)
[02:27:16] *** Quits: AmR (~AmREiSa@156.199.244.83) (Ping timeout: 252 seconds)
[02:34:06] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[02:35:12] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[02:44:31] *** Quits: kenanmarasli (~kenanmara@user/kenanmarasli) (Quit: Leaving)
[02:45:15] *** Quits: Juliu (~Juliu@2a02:810b:c640:3ec0:89ae:7a91:7b8d:9618) (Quit: Quit)
[02:51:59] *** Quits: PJBoy (~PJBoy@user/pjboy) (Ping timeout: 260 seconds)
[02:53:41] *** Joins: vdamewood (~vdamewood@fedora/vdamewood)
[02:54:46] *** Joins: Skyfire (~pyon@user/pyon)
[02:56:03] *** Quits: betelgeuse (~betelgeus@94-225-47-8.access.telenet.be) (Quit: The Lounge - https://thelounge.chat)
[02:56:21] *** Quits: Inst__ (~Inst@2601:6c4:4080:3f80:258f:7b54:f932:b719) (Ping timeout: 245 seconds)
[02:58:36] *** Quits: dextercd (~dexter@2a02-a450-f25d-1-76d4-35ff-fefe-34c.fixed6.kpn.net) (Quit: WeeChat 3.3)
[03:02:11] *** Quits: Mooncairn (~mooncairn@user/mooncairn) (Ping timeout: 245 seconds)
[03:04:29] *** Quits: Tobbi (~Tobbi@2a02:8108:1240:48ec:2403:a3f7:8f00:c0d9) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[03:09:42] *** Quits: great_taste (~great_tas@190.32.235.20) (Quit: Client closed)
[03:15:46] *** Quits: m_ben_ (~m_ben@user/m-ben/x-7429725) (Quit: WeeChat 3.3)
[03:22:43] *** Quits: pulse (~pulse@user/pulse) (Quit: pulse)
[03:26:52] *** Quits: dostoyevsky2 (~sck@user/dostoyevsky2) (Ping timeout: 244 seconds)
[03:27:40] *** Joins: dostoyevsky2 (~sck@user/dostoyevsky2)
[03:38:07] *** Joins: sprout_ (~quassel@2a02:a467:ccd6:1:21d2:19c0:e01b:f66c)
[03:38:40] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:319c:b1d4:3651:39a5) (Ping timeout: 268 seconds)
[03:38:44] *** Quits: prime (~prime@user/prime) (Ping timeout: 244 seconds)
[03:41:05] *** Joins: prime (~prime@user/prime)
[03:52:22] *** Quits: Leone (~Leo@45.72.233.136) (Read error: Connection reset by peer)
[03:56:39] *** Quits: whupdup (~whupdup@pool-173-76-128-81.bstnma.fios.verizon.net) (Quit: Going offline, see ya! (www.adiirc.com))
[04:01:00] *** Quits: sprout_ (~quassel@2a02:a467:ccd6:1:21d2:19c0:e01b:f66c) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[04:01:09] *** Joins: manjaro-user (~manjaro-u@208.98.223.92)
[04:01:40] *** Joins: sprout (~quassel@2a02:a467:ccd6:1:21d2:19c0:e01b:f66c)
[04:07:15] *** Joins: lh_mouse (~lh_mouse@mingw-w64/developer/lhmouse)
[04:08:11] *** Quits: manjaro-user (~manjaro-u@208.98.223.92) (Remote host closed the connection)
[04:08:39] *** Joins: manjaro-user (~manjaro-u@208.98.223.92)
[04:13:51] *** Quits: manjaro-user (~manjaro-u@208.98.223.92) (Ping timeout: 245 seconds)
[04:16:42] *** Quits: LBV_User (~leonardo@45.183.248.98) (Quit: Konversation terminated!)
[04:26:08] *** Quits: joilerv_ (~joilerv@host86-191-93-41.range86-191.btcentralplus.com) (Ping timeout: 246 seconds)
[04:29:09] *** Joins: joilerv (~joilerv@host86-191-93-41.range86-191.btcentralplus.com)
[04:32:43] *** Joins: CaCode_ (~CaCode@user/cacode)
[04:35:14] *** Quits: CaCode- (~CaCode@user/cacode) (Ping timeout: 246 seconds)
[04:36:12] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[04:37:36] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:94f1:2518:b5f6:5be7)
[04:45:27] *** Joins: kraa (~kraa@107-190-7-216.cpe.teksavvy.com)
[04:46:32] *** Joins: ferdna (~ferdna@user/ferdna)
[04:52:50] *** Joins: ahlk (~user@2600:1700:31c0:3a10::43)
[04:56:02] *** Joins: The_Jag_ (~The_Jag@host-87-14-224-44.retail.telecomitalia.it)
[04:58:30] *** Quits: The_Jag (~The_Jag@host-95-252-5-94.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[05:04:38] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 246 seconds)
[05:05:03] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[05:06:15] *** Joins: peepsalot (~peepsalot@openscad/peepsalot)
[05:07:50] *** Quits: peeps[zen] (~peepsalot@openscad/peepsalot) (Ping timeout: 260 seconds)
[05:10:53] *** Quits: DrMax (~DrMax@node-1w7jra94757fz3yjk67sb2lm1.ipv6.telus.net) (Ping timeout: 258 seconds)
[05:11:13] *** Quits: xisop (~xisop@bnull.net) (Ping timeout: 244 seconds)
[05:11:57] *** Joins: xisop (~xisop@bnull.net)
[05:12:54] *** Joins: AmR (~AmREiSa@156.199.244.83)
[05:21:56] *** Joins: NiD27 (~nid27@49.205.144.7)
[05:24:05] *** Joins: DrMax (~DrMax@node-1w7jra94757g0jh5mf8vpb11v.ipv6.telus.net)
[05:37:14] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[05:37:22] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[05:37:22] *** ChanServ sets mode: +v npaperbot
[05:37:37] *** Joins: peeps[zen] (~peepsalot@openscad/peepsalot)
[05:38:35] *** Quits: peepsalot (~peepsalot@openscad/peepsalot) (Ping timeout: 260 seconds)
[05:41:46] *** Quits: Tokamak (~Tokamak@107.117.203.33) (Ping timeout: 245 seconds)
[05:43:25] *** Quits: NiD27 (~nid27@49.205.144.7) (Quit: Leaving)
[06:01:52] *** Quits: Juliu (~Juliu@2a02:810b:c640:3ec0:94f1:2518:b5f6:5be7) (Ping timeout: 258 seconds)
[06:01:54] *** Joins: peepsalot (~peepsalot@openscad/peepsalot)
[06:02:54] *** Joins: Tokamak (~Tokamak@107.117.203.33)
[06:03:19] *** Quits: peeps[zen] (~peepsalot@openscad/peepsalot) (Ping timeout: 260 seconds)
[06:05:39] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[06:06:06] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[06:19:44] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[06:28:38] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[06:29:09] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[06:29:29] *** Joins: JeffH (~JeffH@184-96-219-220.hlrn.qwest.net)
[06:30:12] <JeffH> Anyone know what standard introduced auto_ptr?
[06:31:23] *** Quits: CaCode_ (~CaCode@user/cacode) (Ping timeout: 258 seconds)
[06:31:54] *** Quits: JeffH (~JeffH@184-96-219-220.hlrn.qwest.net) (Remote host closed the connection)
[06:32:36] *** Joins: JeffH (~JeffH@184-96-219-220.hlrn.qwest.net)
[06:33:14] <computerquip> Probably C++98
[06:33:17] <RandomReader> the first one, '98 .. deprecated in 11, removed in 17
[06:33:33] <JeffH> Thanks
[06:33:58] <computerquip> In case it needs to be said... even if you can use it, you probably shouldn't.
[06:34:19] <computerquip> s/can/have to
[06:35:26] <JeffH> computerquip: even if my compiler is only up to 2003 standard?
[06:36:15] <RandomReader> I haven't had to deal with it at scale, but I think I'd prefer manual/explicit management over auto_ptr
[06:36:15] *** Quits: Tokamak (~Tokamak@107.117.203.33) (Quit: Textual IRC Client: www.textualapp.com)
[06:36:22] *** Quits: DSpider (~DSpider@82.79.237.129) (Quit: Leaving)
[06:36:54] <RandomReader> since there aren't any move semantics, there's no indication/marker of a transfer, auto_ptr just has unusual copy semantics
[06:37:12] <RandomReader> so it's surprising, not in a good way
[06:37:12] <Alipha> Implement a shared_ptr and use that instead
[06:37:25] <computerquip> Yeah, I probably wouldn't use it. Boost might have some clever work arounds for the older standards.
[06:37:49] <computerquip> I'm not sure shared_ptr is an appropriate replacement either
[06:38:43] <JeffH> Unfortunately I don’t think we have access to boost
[06:38:57] <computerquip> No, I'm saying browse it for ideas.
[06:39:08] <JeffH> Oh
[06:39:20] *** Quits: AmR (~AmREiSa@156.199.244.83) (Quit: Konversation terminated!)
[06:39:59] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Remote host closed the connection)
[06:40:28] <RandomReader> I wonder if a auto_ptr-like thing that didn't support copy, but required you call a .transfer(T& dest) function instead, might work out
[06:40:50] <JeffH> Would be fun if we had the ability to use all the latest bells and whistles.
[06:40:51] <RandomReader> and if that would be less annoying than full manual management
[06:40:59] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[06:41:43] <computerquip> Probably won't get that. C++11 changed a lot, move semantics alone flipped everything upside down.
[06:44:28] <JeffH> 03 feels like ancient history for c++
[06:45:06] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 245 seconds)
[06:45:26] <computerquip> What compiler do you have that only supports C++03?
[06:45:27] <RandomReader> 18 years old, the web wasn't even in most people's homes let alone mobile .. it's ancient history for the software world in general
[06:48:01] <JeffH> computerquip: I forget the version of gcc that ships with the rtos we use.
[06:50:42] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[06:55:35] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 264 seconds)
[07:05:56] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 245 seconds)
[07:06:21] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[07:16:57] *** Quits: JeffH (~JeffH@184-96-219-220.hlrn.qwest.net) (Read error: Connection reset by peer)
[07:17:13] *** Joins: JeffH (~JeffH@184-96-219-220.hlrn.qwest.net)
[07:17:47] *** Quits: JeffH (~JeffH@184-96-219-220.hlrn.qwest.net) (Read error: Connection reset by peer)
[07:17:49] *** Joins: JeffH_ (~JeffH@100.sub-174-245-195.myvzw.com)
[07:18:30] *** Quits: JeffH_ (~JeffH@100.sub-174-245-195.myvzw.com) (Remote host closed the connection)
[07:21:26] *** Quits: skapata (~Skapata@user/skapata) (Read error: Connection reset by peer)
[07:21:47] *** Quits: KombuchaKip (~kip@192.252.230.5) (Quit: Leaving.)
[07:22:03] *** Joins: great_taste (~great_tas@190.32.235.20)
[07:30:01] *** Quits: cactus (~shawn@103.206.188.183) (Quit: Leaving)
[07:41:59] *** Quits: great_taste (~great_tas@190.32.235.20) (Quit: Client closed)
[07:42:23] *** Joins: great_taste (~great_tas@190.32.235.20)
[07:45:10] <yolo_> vec1(super-large-vector); sort(vec1); -vs- multiset1(super-large-vector); automatically sorted. the latter is 10x faster, what's the point of using vector then? just multiset all the way?
[07:46:15] <yolo_> unless original order needs to be maitained, as set will sort at insertion, otherwise it seems I can always use multiset to replace vector
[07:47:13] *** Quits: Terminus (~null@user/terminus) (Quit: ZNC 1.8.2 - https://znc.in)
[07:47:31] *** Joins: Terminus (~null@user/terminus)
[07:51:27] <RandomReader> not really sure what the question is, there are more differences than just that between the two datastructures, like anything else you pick the one that has the best tradeoffs for the task...?
[08:04:07] <yolo_> question is: copy-then-sort a large vector is 10x slower than insert the large vector into a multiset
[08:05:10] <yolo_> end result is the same: a sorted container, both O(log(N))
[08:06:55] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[08:08:48] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[08:14:03] <RandomReader> that isn't surprising, since loading the vector requires copying all of the elements, then sorting it requires relocating all of them multiple times
[08:14:30] <RandomReader> but presumably that isn't the only thing you're ever going to do with the container, so the rest of it matters too :)
[08:14:47] <RandomReader> what do you mean by "both O(log(N))"?
[08:16:33] <yolo_> means further search/insertion/deletion while maintain the order for multiset, for vector it's involves more copy. yes vector might be using less memory and great at push_back/pop_back, other than i feel multiset is better
[08:16:55] <yolo_> and, you never know if vector just allocated a large piece of memory, so it might use more memory than multiset sometimes
[08:16:58] <RandomReader> but better at *what*?
[08:17:17] <yolo_> faster for insertion, deletion
[08:17:17] <InPhase> yolo_: I find it very surprising that a sort call on vector is more expensive than a multiset.  What are the elements?
[08:17:33] <yolo_> InPhase: the elements are a random list of integers
[08:17:39] <yolo_> let me post my code
[08:17:48] <RandomReader> you're being vague, what I'm pointing out is that the tradeoffs exist for each operation, and therefore the combination and counts of the operations you expect to do over its lifetime, not just a general thing in isolation
[08:17:55] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[08:18:15] <RandomReader> there's no "one container is almost always better" kind of blanket guideline that holds up
[08:19:08] <RandomReader> e.g. you can influence vector's allocation behavior with .reserve, depending on what you know about your input data
[08:21:00] <RandomReader> but yes, a multiset will be more efficient at insertion and deletion .. is that what you expect to do most often?
[08:21:12] <yolo_> yes
[08:21:31] <RandomReader> so it exists for the heck of it, you don't usually check what's in it? :)
[08:22:26] <InPhase> yolo_: In summary, are you sorting once and done?  Or are you sorting more often?
[08:22:29] <RandomReader> (if your code is showing what your use might be like, not just a benchmark, I'll wait to see it)
[08:22:32] <yolo_> https://wandbox.org/permlink/6dFTSJIZffkHRliA  sorry for the noise, just realized my g++ build has -g there which skewed the result, at wandbox with optimization multiset is 5 times slower :(
[08:22:48] <InPhase> Ok, that makes more sense.
[08:23:07] <InPhase> yolo_: vector's cache advantages are really hard to beat.
[08:23:15] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 260 seconds)
[08:24:02] <RandomReader> oh, so just a benchmark .. ok, unfortunately that's not usually representative of real-world behavior
[08:24:18] <RandomReader> what are you testing this for? what does your actual use case look like?
[08:24:28] *** Quits: Hello71 (~Hello71@wireguard/contributor/hello71) (Quit: Hello71)
[08:24:38] <yolo_> InPhase: yes, i now recall I read if vector contains primitive types it will be very efficient(cache hit), but if it contains non-primitive(e.g. a struct of large data), then list will win, as cache is no longer relevant for the most part
[08:25:23] <InPhase> yolo_: It's not quite that simple.
[08:25:35] <yolo_> RandomReader: just some random snippets I write to learn more c++ at night
[08:26:03] <RandomReader> H
[08:26:12] <InPhase> yolo_: It depends on the usage.  list has strengths for insertion and removal, and some extreme weaknesses if you ever needed random accessing.
[08:26:29] <RandomReader> ah .. I would probably try to come up with a more specific usage to play with container tradeoffs
[08:26:40] <RandomReader> such as, make it count the number of unique words in a document
[08:26:57] <RandomReader> and then give it different-sized text files for your tests
[08:26:59] <yolo_> that's a perfect set question
[08:27:11] <yolo_> anyways sign off now, midnight here. thanks folks
[08:27:16] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:94f1:2518:b5f6:5be7)
[08:27:55] <InPhase> yolo_: vector will pretty much ALWAYS win on cache gains, but you can hit a usage scenario where that doesn't matter, and the algorithmic order of something like random insertion obliterates the vector benefit.  Or perhaps you need to keep adding an element and sorting on a vector, and then multiset will be faster than repeated sorting on each element.
[08:28:34] <yolo_> InPhase: yes, make perfect sense, thanks!
[08:29:54] *** Joins: Hello71 (~Hello71@wireguard/contributor/hello71)
[08:30:58] <InPhase> yolo_: One slight exception to vector will always win on cache gains, is std::array, which will beat it out for compile-time-known-size data that's not too big.
[08:31:38] <InPhase> You skip the allocation, and the stack is almost always cached already.
[08:38:03] *** Quits: frost (~frost@user/frost) (Quit: Ping timeout (120 seconds))
[08:55:01] *** Joins: AbleBacon_ (~AbleBacon@user/AbleBacon)
[08:56:24] *** Quits: thad_the_man (~tlophd_be@2600:1700:3051:4370:21d:9ff:fe33:51f4) (Remote host closed the connection)
[08:56:47] *** Quits: bjs (sid190364@user/bjs) (Ping timeout: 264 seconds)
[08:57:15] *** Joins: bjs (sid190364@user/bjs)
[08:58:26] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Ping timeout: 245 seconds)
[08:58:35] *** Quits: lhtseng (sid15322@helmsley.irccloud.com) (Ping timeout: 264 seconds)
[08:58:58] *** Joins: lhtseng (sid15322@id-15322.helmsley.irccloud.com)
[09:01:38] *** Quits: nshire (~Neal@user/nshire) (Quit: Leaving)
[09:02:32] *** Quits: ferdna (~ferdna@user/ferdna) (Quit: Leaving)
[09:03:16] *** Joins: thad_the_man (~tlophd_be@2600:1700:3051:4370:21d:9ff:fe33:51f4)
[09:04:40] *** Joins: nshire (~Neal@user/nshire)
[09:07:08] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 268 seconds)
[09:07:47] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[09:19:42] *** Joins: manic_laughter (~manic_lau@2409:4072:215:a245:221e:23a6:d923:4452)
[09:30:59] *** Quits: kraa (~kraa@107-190-7-216.cpe.teksavvy.com) (Ping timeout: 260 seconds)
[09:32:03] *** Quits: manic_laughter (~manic_lau@2409:4072:215:a245:221e:23a6:d923:4452) (Quit: Leaving)
[09:35:32] *** Quits: luizfrds (~Luiz@152.250.243.147) (Ping timeout: 246 seconds)
[09:36:07] *** Joins: JohnMS_WORK (~kvirc@213.134.183.29)
[09:37:14] *** Quits: great_taste (~great_tas@190.32.235.20) (Quit: Client closed)
[09:37:14] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[09:37:23] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[09:37:23] *** ChanServ sets mode: +v npaperbot
[09:42:29] *** Quits: Juliu (~Juliu@2a02:810b:c640:3ec0:94f1:2518:b5f6:5be7) (Quit: Quit)
[09:44:43] *** Joins: sord937 (~sord937@gateway/tor-sasl/sord937)
[09:46:52] *** Quits: kapil (~kapil@2a01:4f9:c010:c9c3::1) (Quit: ZNC 1.7.5+deb4 - https://znc.in)
[09:48:53] *** Joins: kapil (~kapil@o-k.website)
[09:49:32] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[09:54:56] *** Quits: kapil (~kapil@o-k.website) (Quit: ZNC 1.7.5+deb4 - https://znc.in)
[09:54:59] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 264 seconds)
[09:56:36] *** Joins: Miyu (~hackkitte@158-139-100-005.ip-addr.inexio.net)
[09:57:58] *** Quits: hackkitten (~hackkitte@154-148-165-046.ip-addr.inexio.net) (Ping timeout: 244 seconds)
[10:01:10] *** Joins: kapil (~kapil@o-k.website)
[10:07:05] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[10:07:30] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[10:08:15] *** Joins: Serpent7776 (~Serpent77@90-156-31-193.internetia.net.pl)
[10:13:42] *** Joins: KombuchaKip (~kip@192.252.230.5)
[10:16:02] *** Joins: john99 (~john99@158.246.103.34.bc.googleusercontent.com)
[10:16:02] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[10:17:41] <john99> Hi, if i want launch exception if snprintf truncate a string (c/c++ code compatibilityi need handle char*) wich is the usual exception used for this case?
[10:22:10] *** Joins: ravan (~ravan@user/ravan)
[10:22:48] <RandomReader> these things don't seem related, you can get a char* without snprintf...
[10:23:17] <RandomReader> not sure there is a usual exception, perhaps std::length_error fits
[10:24:28] <john99> probably is not related, but i was tryng to handle the case of snprintf truncate the buffer and my idea was launch exception
[10:24:47] <john99> i dont know it is the good aproach
[10:24:54] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[10:25:21] <RandomReader> what's the overall task?
[10:25:49] <john99> upgrade legacy code where truncate buffer is not checked and cause problems
[10:26:28] <RandomReader> ah
[10:26:49] <john99> (legacy and bad code XD)
[10:27:12] <RandomReader> if it cannot be "fixed" in the same place (no useful action to take on truncate), then exception seems reasonable
[10:27:25] <john99> :)
[10:27:38] <john99> okay, i will go with length_error
[10:34:34] *** Quits: artok (~azo@mobile-access-bcee2b-18.dhcp.inet.fi) (Quit: worrk)
[10:34:34] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[10:35:54] *** Joins: Tobbi (~Tobbi@2a02:8108:1240:48ec:8447:b6ce:a77e:bb3c)
[10:37:03] *** Joins: interop_madness (~interop_m@user/interop-madness/x-0950004)
[10:38:00] *** Quits: ravan (~ravan@user/ravan) (Quit: Leaving)
[10:38:26] *** Joins: ravan (~ravan@user/ravan)
[10:39:12] *** Joins: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[10:40:09] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[10:42:02] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[10:42:59] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 264 seconds)
[10:43:28] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[10:45:41] *** Quits: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 264 seconds)
[10:47:04] *** Joins: andreasbuhr (~quassel@p548ddac6.dip0.t-ipconnect.de)
[10:47:14] *** Joins: lionkor (~lion@200116b80f21be003f77e013efe91b4f.dip.versatel-1u1.de)
[10:48:02] *** Quits: lionkor (~lion@200116b80f21be003f77e013efe91b4f.dip.versatel-1u1.de) (Client Quit)
[10:48:24] *** Joins: lionkor (~lion@200116b80f21be003f77e013efe91b4f.dip.versatel-1u1.de)
[10:48:34] *** Quits: lionkor (~lion@200116b80f21be003f77e013efe91b4f.dip.versatel-1u1.de) (Changing host)
[10:48:34] *** Joins: lionkor (~lion@beammp/staff/lionkor)
[10:48:48] *** Quits: lionkor (~lion@beammp/staff/lionkor) (Client Quit)
[10:49:19] *** Joins: lionkor (~lion@beammp/staff/lionkor)
[10:51:05] *** Joins: Haohmaru (~Haohmaru@195.24.53.110)
[10:52:11] *** Joins: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[11:01:17] *** Joins: kylese (~kylese@p5dd8b9e4.dip0.t-ipconnect.de)
[11:01:43] <johnny> i'm trying o go on a journey to represent the exact output of whatever happens when QVariant ends up with float value that is converted from a string
[11:01:43] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[11:02:05] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[11:02:38] <johnny> i do wanna replicate this for example, but i don't think it's that valuable 0.200000002980232
[11:03:30] <johnny> however replicating that exact amount would make my regression checking a lot easier
[11:03:44] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[11:05:48] *** Joins: lkor (~lion@beammp/staff/lionkor)
[11:06:10] *** Quits: lionkor (~lion@beammp/staff/lionkor) (Ping timeout: 265 seconds)
[11:06:16] *** lkor is now known as lionkor
[11:11:03] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[11:11:47] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Ping timeout: 260 seconds)
[11:15:55] <RandomReader> not entirely sure what you mean, but in general, a decimal string is only an approximation of a floating point value
[11:16:13] <RandomReader> and whether it can be round-tripped will depend on the conversions on both sides
[11:16:16] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[11:16:32] <RandomReader> I should say, approximation of float or double
[11:16:48] <RandomReader> obviously a floating point value that's actually decimal instead of binary would have different behavior...
[11:17:11] <johnny> yeah i'm suret's only an approximation, but the current approximation works
[11:17:34] <johnny> i'm only interested in matching output .. anyything else is concern for another time
[11:17:38] <RandomReader> what I mean is, the string is treated as an approximation on input, and then the output is also an approximation
[11:17:46] <RandomReader> and those might be *different*
[11:18:21] <RandomReader> unless the conversions used guarantee round-trip capabilities
[11:19:33] <johnny> oh sorry my fault. i didn't say a crucial thing to alleviate that concern. the application curretly generates xlsx files in which the floats look like that. so that's alreayd the case. i'm doing another output fomat, but without Qt
[11:20:03] <johnny> so the only important thing is that the output between my csv and the xlsx > csv look exactly the same
[11:21:04] <RandomReader> I don't know how that changes anything I just mentioned :P
[11:21:04] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[11:21:10] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 260 seconds)
[11:21:40] <johnny> you're making a huge assumtion that i care about it being round tripped or whatever aren't you?
[11:21:58] <RandomReader> no?
[11:22:03] *** Quits: Trollmann (~Trollmann@user/trollmann) (Ping timeout: 260 seconds)
[11:22:12] <RandomReader> you seemed to be asking about the specific values, I was pointing out that it depends on the converters involved
[11:23:00] <RandomReader> I don't know if you want it round-tripped or not, you just seemed to say that you wanted to know what happened .. so I'd start by looking for the converters
[11:23:17] <johnny> i'm tyring to find them in the qt source i have downloaded
[11:23:18] *** Joins: Trollmann (~Trollmann@user/trollmann)
[11:23:43] <johnny> i was hoping somebody who knew Qt could shortcircuit someof that for me since i only know the barest parts of Qt
[11:23:51] <RandomReader> oh
[11:24:09] <RandomReader> no idea, although usually these things are documented somewhere
[11:24:56] <johnny> there's so much stuff with QMETATYPE* macros and a bunch of calls that call other things, that it's a bit circular for me atm
[11:25:53] <lionkor> johnny: you're looking for the implementation of QVariant?
[11:26:05] <johnny> i *think* that a qvariant conversion to float ends up with QString::number(num, 'g', FloatingPointShortest) or something
[11:26:10] <johnny> lionkor, no, i found that part
[11:26:34] <johnny> but i'm not 100% sure.. that's the right path
[11:27:02] <johnny> but going deeper down there, it seems like it might rely on the double-conversion library, but it's also optional
[11:28:10] <johnny> i was *hoping* i could just do it with fmtlib somehow
[11:28:27] <RandomReader> https://wiki.qt.io/New_Features_in_Qt_5.7  says "Added the ability to convert a floating point to its shortest, exact string form, without having to pre-calculate how many digits that is; QVariant uses this" which implies they've got something specific in there
[11:28:55] <johnny> yeah, and i found it.. and i *think* it uses double-conversion, but again it's optional
[11:29:06] <johnny> uggh
[11:29:29] <johnny> i think i saw someone post a feature request to fmtlib for this feature but it was denied
[11:29:35] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[11:30:32] <johnny> man.. i swear google gets worse and worse at searching code stuff
[11:31:09] <RandomReader> google's getting worse at searching period, I had one the other day where it was flat-out refusing to search for what I specified, and coming up with some alternate meaning entirely
[11:31:37] <johnny> i think it's optimizing for more natural language queries, but that's not how i search
[11:31:39] <RandomReader> even quoting words didn't help, it still tried to interpret it as some non-technical english thing, I gave up and searched a different way
[11:32:08] <johnny> sorry... it's not think.. i know .. and i have an exampl
[11:32:19] <RandomReader> it used to have reasonable escapes, but those seem to be going away :(
[11:32:20] <johnny> i tried searching for something for probably a half an hour
[11:32:27] <johnny> i told my dad i couldn't find it
[11:32:29] <johnny> HE FOUND IT!
[11:33:04] <RandomReader> lol
[11:34:03] <johnny> it's all because he doesn't get all terse with it.. he wrotes like "how do i" or "what is", etc with other filler words
[11:34:48] <johnny> google still has the verbatim search, but that removes the ability to filter results by date
[11:36:47] <johnny> it seems silly to me to ask a text box questions like that, but i imagine the results speak for themselves :(
[11:37:55] *** Quits: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net) (Ping timeout: 260 seconds)
[11:39:05] <johnny> remember when they removed the + around the same time they were trying to make google+ a thig
[11:41:45] <johnny> please none of this :( #if !defined(QT_NO_DOUBLECONVERSION)
[11:45:13] *** Joins: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net)
[11:48:07] <lionkor> johnny: so you found what you're looking for?
[11:48:19] <johnny> not yet.. i'm browsing through Qt's sources
[11:50:14] <johnny> the first thing i needed to find out is my hunch that floats get converted to doubles.. and that seems to be true
[11:50:34] <TinoDidriksen> Can't you just set a breakpoint and step into exactly where it happens?
[11:51:41] <johnny> i suppose i'll have to isntall qt debug sources for that
[11:52:05] <LordKalma> what's the problem?
[11:52:23] <LordKalma> morning btw
[11:53:03] <johnny> I was trying to figure out how to get the exact same output as a QString::number(someFloat) which would led to output like this  0.200000002980232
[11:53:24] <LordKalma> mandatory https://0.30000000000000004.com/
[11:53:31] <johnny> but would also give the shortest representation available
[11:53:48] <johnny> and i just found out that it uses double-conversion to do so
[11:53:49] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[11:53:52] <johnny> or at least i think it does
[11:54:05] <LordKalma> 0.30000000000000004 happens with single-precision floats
[11:54:48] <johnny> as far as i can tell Qt casts all floats to doubles
[11:54:58] <lionkor> you mean because of qRound64?
[11:55:20] <johnny> i can't tell if that's related or not. i couldn't tell which side of the conversion to/or from so i kinda skipped it
[11:55:30] <LordKalma> https://doc.qt.io/qt-5/qstring.html#number
[11:55:46] <johnny> yes.. but first i had to discover what QVariant did.. since it's not exposed to me
[11:55:50] <LordKalma> sorry
[11:55:50] <LordKalma> https://doc.qt.io/qt-5/qstring.html#number-6
[11:55:51] <LordKalma> this one
[11:56:02] <johnny> yeah none of that is called dirctly, it happens intenrally in QVariant
[11:56:16] <LordKalma> what«s the relation to qvariant?
[11:56:20] <LordKalma> I don't get what's going on
[11:56:37] <johnny> write(int, int, QVariant)  is the call
[11:56:50] <johnny> and it's passed a float
[11:57:05] <LordKalma> a float where?
[11:57:17] <johnny> write(1, 1, 3.14)
[11:57:22] <lionkor> you're not looking for QVariant conversion of float to string, are you? because that definitely just uses String::number as you said earlier, doens't it?
[11:57:30] <LordKalma> that's not a float
[11:57:36] <LordKalma> literal 3.14 is a double
[11:57:37] <LordKalma> iirc
[11:58:19] <johnny> oh.. sorry i just picked a nuber with a decimal point. the data type is float of whatever's coming in.. i don't know what there values are
[11:58:19] <LordKalma> I still don't get what QVariant has to do with converting floats to string and the reverse
[11:58:24] <johnny> it does it inside
[11:58:47] <LordKalma> what?
[11:58:52] <lionkor> apparently you can put a float into a variant and ask it to give you back a qstring...?
[11:58:58] <LordKalma> QVariant doesn't convert anything?!?!
[11:58:59] <LordKalma> what?
[11:59:02] <johnny> it sure does
[11:59:09] <lionkor> im surprised, too...
[11:59:20] <LordKalma> https://doc.qt.io/qt-5/qvariant.html#toString
[11:59:22] <LordKalma> fuck, it really does
[11:59:38] <lionkor> thats so dumb.
[11:59:42] <LordKalma> anyway, knowing Qt core
[11:59:54] <LordKalma> I very much doubt it takes the liberty of converting to double
[11:59:58] <johnny> so you ultimately end up with QString::number(floatvalue, 'g', ShortestFloat)  which then ends up doing something with QLocale
[12:00:03] <LordKalma> you're probably initializing with double and not even noticing
[12:00:28] <johnny> LordKalma, you missed the the intro..  what is there, is some excel thing that takes bespoke binary format and prints out the data to an excel sheet
[12:00:35] <LordKalma> that said, regardless of precision, you'll have 0.30000000000000004-type bullshit
[12:00:40] <LordKalma> that's just floating points
[12:00:44] <johnny> i didn't write that part, but it uses qstring stuff
[12:00:52] <johnny> i mean qt apis
[12:01:02] <johnny> i'm doing a csv variant, with no qt libraries
[12:01:16] <lionkor> yeah as far as I see it does conver to double - QMetaTypeModuleHelper::convert invokes QString::number of which there only is an overload for double
[12:01:25] <LordKalma> you're not making much sense. Firsdt it was QString, then QVariant, not it's no Qt libraries
[12:01:26] <johnny> i'm trying to match the exact output of the generated excel sheets (converted to csv)
[12:01:28] <LordKalma> what the hell is going on
[12:01:35] <johnny> LordKalma, im trying tomatch qt's behaviour
[12:01:46] <LordKalma> you could have started with that
[12:01:52] <johnny> i did, before you got here :)
[12:02:01] <LordKalma> anyway, excel doesn't store the values magically either
[12:02:11] <johnny> that doesn't make a difference i think
[12:02:12] <LordKalma> it doesn't store 0.3, it stores 0.30000000000000004
[12:02:19] <LordKalma> it just "shows" you 0.3 and serializes 0.3
[12:02:19] <johnny> i know that. i can see the output
[12:02:46] <johnny> qt's locale thingy does a bit more than a simple 'g' specifier though when converting it to string
[12:02:48] <LordKalma> that's the word. you want to write an csv serializer
[12:02:50] <LordKalma> and that's nuances
[12:02:57] <LordKalma> nuanced*
[12:03:08] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[12:03:11] <johnny> it does something via double-conversion to get the shortest representation
[12:03:33] <johnny> but anyways, i'm gonna do what TinoDidriksen reminded me to do as soon as  i have the debug sources for qt installed
[12:04:40] <johnny> i just got off on a bit of tangent on the same things you both thought were uhmm.. interesting is the nice way to put it
[12:05:16] <johnny> because everything seems so freakin circular that it' hard to make sense of it all
[12:06:16] <LordKalma> if they have serialization build it into qvariant, I see only one reason
[12:06:19] <LordKalma> someone paid them to
[12:08:35] *** Joins: plastico (~plastico@neomutt/plastico)
[12:09:16] *** Parts: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) ()
[12:10:33] <lionkor> FYI I dont know what I'm talking about but as far as I can see it ends up invoking qt_doubleToAscii with form=DFDecimal and precision=FloatingPointShortest, then does some more processing in dtoString, what looks like adding a sign if its negative etc.
[12:12:44] *** Miyu is now known as hackkitten
[12:13:02] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[12:13:07] <lpapp> ville: : error LNK2019: unresolved external symbol "public: __cdecl ndk::Value::Value<double>(double const &)" (??$?0N@Value@ndk@@QEAA@AEBN@Z) referenced in function
[12:13:24] *** Joins: PJBoy (~PJBoy@user/pjboy)
[12:13:41] <lpapp> in the source: template <> Value::Value(const double     & data) : ...
[12:13:48] <johnny> lionkor, yeah i ended up there too. i wasn't srue if it ws right, but it probably is
[12:14:34] <lpapp> in the header: class DECLSPEC_MACRO Value { ... template <typename T> explicit Value(const T& data); ... }
[12:14:47] <lpapp> ville: this is what I have, and I am getting the unresolved symbol for.
[12:14:47] <lionkor> johnny: it ends up invoking snprintf(buf, buflen, "%.<precision>f\0", d)
[12:15:10] <lionkor> in qDoubleSnprintf
[12:15:22] <lionkor> that might be the answer you're looking for...?
[12:15:32] *** Quits: andreasbuhr (~quassel@p548ddac6.dip0.t-ipconnect.de) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[12:15:57] <lionkor> where `precision` seems to be std::numeric_limits<double>::max_digits10
[12:16:05] <lionkor> at least for FloatingPointShortest
[12:16:23] <johnny> wouldn't that cap the precision at 10? that doen't seem true in my actual output?
[12:16:35] <johnny> oh.. it converts to double first though
[12:16:39] <LordKalma> that's for std::cout
[12:17:17] <johnny> sadly fmtlib doesn't let you strip trailing digits
[12:18:07] <lionkor> yeah its a bit confusing
[12:18:20] <johnny> yeah it's all here https://github.com/fmtlib/fmt/issues/1551
[12:20:14] <johnny> https://github.com/vgc/vgc/blob/ae0617ebaf7a591c0c0b25e8f4a5818edb8d1838/libs/vgc/core/format.h#L295
[12:20:47] *** Quits: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) (Quit: Lost terminal)
[12:21:19] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[12:21:31] <lpapp> what is the recommended procedure for these template visibilities?
[12:22:59] <TinoDidriksen> Just keep templates fully in header.
[12:22:59] <ville> lpapp: question becomes does __cdeclspec on a class apply to member function templates or do you have to do something special to them on windows
[12:22:59] <lpapp> ah, no, that is not viable.
[12:22:59] <lionkor> johnny: max_digits10 doesn't return 10, it returns the max number of digits necessary to uniquely represent a double in this case, for double this is DBL_DECIMAL_DIG or std::ceil(std::numeric_limits<double>::digits * std::log10(2) + 1) so that's definitely gonna cause a lot of digits like you see
[12:23:28] <johnny> but it also doesn't ive you the shortest representation. unlike the code i just posted
[12:23:46] <johnny> look at how much it too to do it
[12:23:50] <lpapp> ville: are you mixing up __declspec and __cdecl?
[12:24:26] <lionkor> so just doing the same snprintf doesn't give you the same output? :(
[12:24:57] <ville> lpapp: right __declspec
[12:25:43] <lpapp> ville: https://stackoverflow.com/a/19684162
[12:25:46] <johnny> lionkor, well it's with fmtlib, but effectively the same
[12:25:51] <lpapp> Templated functions does not exist until they are instantiated. So that means that you can export only its instances not the template itself.
[12:25:59] <lpapp> "..." ^
[12:26:05] <lionkor> johnny well good luck :D
[12:26:29] <ville> lpapp: also no clue what your macro looks like exactly. to answer these kinds of questions we really need to see every detail. which is why i told you yesterday to make a simple testcase where you try to figure this out, so you can share the cod
[12:26:35] <ville> err code
[12:27:05] <lpapp> ville: the example that answer gives is the opposite of the description, so unless I am missing something, that is a low-quality top SO answer.
[12:27:19] <ville> lpapp: opposite of what?
[12:27:21] <lpapp> macro is a standard macro
[12:27:56] <lpapp> just switches __declspec(dllexport) / __declspec(dllimport) based on an EXPORT variable defined.
[12:28:19] <lpapp> if built as part of the library, MYEXPORT is defined via -DMYEXPORT in CMakeLists.txt
[12:28:24] <lpapp> if not, it is not definfed
[12:28:25] <johnny> lionkor, once you verified that it's all doubles, i can probalby just use double-conversion
[12:28:32] <lpapp> if MYEXPORT defined, dllexport, otherwise dllimport
[12:28:38] <lpapp> and of course only bother on windows
[12:29:34] <johnny> i just wasn't sure that that functions that accepted doubles not floats were relevant, but you seem to clarify that you always end up double anyways.. thus i should be good
[12:29:34] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[12:29:35] <lpapp> ville: if you read the SO answer, it writes: "Templated functions does not exist until they are instantiated. So that means that you can export only its instances not the template itself."
[12:29:37] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[12:29:49] <lpapp> However, the example it gives is this: template <typename T>
[12:29:49] <lpapp> DLL_Export void TestPointModule_Check(string name, T * value);
[12:30:01] <lpapp> and: // explicit instantiation
[12:30:01] <lpapp> template void TestPointModule_Check<SomeType>(string name, SomeType * value);
[12:30:07] <lpapp> so, it is contradicting itself from what I can see.
[12:30:38] *** Quits: lionkor (~lion@beammp/staff/lionkor) (Ping timeout: 268 seconds)
[12:32:11] <lpapp> ville: to me, the description makes sense, not the example, but that is what I am already doing, and it does not seem to work.
[12:34:32] <ville> wht is the contradition?
[12:34:44] <ville> err what is the contradiction?
[12:35:25] *** Joins: Juliu (~Juliu@2a02:810b:c640:3ec0:3c5a:ecb6:636d:9caa)
[12:36:55] <lpapp> ville: the description says to export the specialisation, not the template function, but the code does the opposite, exports the template function, and not the specialisation...
[12:37:48] <lpapp> hmm, this is template function instantiation, not template function specialisation... I actually do not know the difference between the two...
[12:38:12] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[12:38:37] <ville> right, the export should be on the explicit instantiation as far as i can tell. the definition is there just so the compiler can make the instantiation
[12:39:05] <lpapp> yes, so the example seems wrong
[12:39:06] *** Joins: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au)
[12:39:18] <lpapp> but again, I do not know the difference between template function instantiation and specialisation, what is it?
[12:40:33] <lpapp> I guess what I am doing is partial specialisation.
[12:40:49] <ville> again i would need to see exact code to tell what you are doing
[12:40:57] <PJBoy> all instantiations are specialisations, but explicit specialisations are also specialisations
[12:40:59] <ville> which is why i said you to make a simple testcase you can share...
[12:41:05] <PJBoy> partial specialisations are not specialisations
[12:41:59] *** Quits: john99 (~john99@158.246.103.34.bc.googleusercontent.com) (Quit: Client closed)
[12:42:06] <lpapp> ville: well, if you have Windows, it is easy to write a code to verify your concept, if you do not, showing code will not help anyway to test.
[12:42:07] *** Joins: rond_ (~rond_@2a02:a31a:a23c:f480:2fd7:e087:5546:a438)
[12:42:10] <lpapp> So, not sure how it would help.
[12:43:01] <rond_> I'm looking for a function of type: `vector<A> -> vector<B>` resembling `map` in functional programming. Is there one in std?
[12:43:37] <PJBoy> nothing in stdlib can produce a container
[12:43:48] <PJBoy> but there is std::transform
[12:44:08] <Juliu> Hi guys
[12:44:12] <lpapp> seems like specialisation and instantiation are the same thing
[12:44:14] *** Joins: kenanmarasli (~kenanmara@user/kenanmarasli)
[12:44:23] <lpapp> except that instantiation is for template class, and specialisation is for template function
[12:44:27] <PJBoy> that means you did read the difference I just point out
[12:44:29] <PJBoy> *didn't
[12:44:37] <LordKalma> PJBoy, the results of the latest qt drama are out: the motion of no-trust passed
[12:44:46] <PJBoy> spicy
[12:45:28] <lpapp> no trust of what in the Qt Project?
[12:45:42] <lpapp> PJBoy: I read what others wrote.
[12:46:01] <ville> lpapp: in general the onus is on you to provide as clear information as possible, not on us to ask every damned detail from you
[12:46:09] <rond_> PJBoy vector<B>(vecA.size()); std::transform(vecA.begin(), vecA.end(), vecB.begn(), [](const A& a){return a.bField});    is the way to go then?
[12:46:17] <lpapp> ville: I gave every detail I have.
[12:46:18] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Read error: Connection timed out)
[12:46:29] <lpapp> if you do not know the answer, that is fine, but I cannot give you more details.
[12:46:30] <PJBoy> template<typename T> void f(); <-- template, template<> void f<T>(); <-- explicit specialisation, not an instantiation, void g() { f<void>(); <-- instantiation (also a specialisation) }
[12:46:48] <ville> lpapp: it avoids problems where you are not familiar with some of the terms and may overlook some detail when you paraphrase the code in a snippet on irc
[12:47:01] <lpapp> I literally answered all questions that came up
[12:47:06] <lpapp> export, dllspec macro, etc.
[12:47:12] <ville> lpapp: the problem is i had to ask questions
[12:47:12] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[12:47:13] <lpapp> I do not see any unanswered question
[12:47:27] <lpapp> well, in debugging, you have to ask questions.
[12:47:29] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[12:47:31] <ville> lpapp: can you get a layout like: https://wandbox.org/permlink/jrkDWlpYmzu7FK1h to work then?
[12:47:46] <lpapp> but like I said, giving you code snippets without you having Windows is pointless anyway
[12:47:58] <lpapp> that is not windows code
[12:48:01] <lpapp> I told that several times
[12:48:05] <lpapp> it has no declspec in it
[12:48:11] <lpapp> it does not use the Windows os
[12:48:15] <lpapp> it does not use the msvc compiler
[12:48:19] <ville> well i guess the dllimport has to macroed in the header
[12:48:24] <lpapp> it is code written for Mac and Linux, and yes, that has always worked here.
[12:48:29] <lpapp> the issue comes up with Windows, really.
[12:48:38] <ville> lpapp: i am telling you to grab the files. make that simple testcase on your machine that builds a dll
[12:49:13] <lpapp> no, it is not that simple
[12:49:26] <lpapp> I am not that familiar with seting up dll builds from scratch myself.
[12:49:30] <lpapp> otherwise, I would have already done it.
[12:49:39] <lpapp> there is a lot more to it than just writing a struct and a function.
[12:50:47] <lpapp> you would actually also need a buildsystem like cmake to do things properly for you, or at least the equialent msvc commands, which I do not know.
[12:50:48] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[12:51:21] <PJBoy> making a DLL in visual studio is dead simple
[12:51:24] *** Joins: frost (~frost@user/frost)
[12:51:28] <lpapp> then go for it!
[12:51:40] <PJBoy> https://docs.microsoft.com/en-us/cpp/build/walkthrough-creating-and-using-a-dynamic-link-library-cpp
[12:51:40] <ville> lpapp: grab your current makefile or cmakelist.txt and cannibalize it to be main and a dso
[12:51:41] <lpapp> (and no, I am not using Visual Studio)
[12:51:49] <lpapp> no
[12:51:54] <lpapp> this is a complex project, a huge one.
[12:51:57] <PJBoy> seems like the tool for the job
[12:52:08] <lpapp> it would take ages to try to figure out which part is needed from where, etc.
[12:52:32] <lpapp> I am honestly not that familiar with the windows build process, so I would rather trust what we have currently.
[12:52:42] <lpapp> It would be a different project of its own to set this up, but that is not my task.
[12:53:25] <lpapp> but if anyone can send build files to test, for sure, I will try.
[12:53:44] <PJBoy> hm, you know you're like a RonaldsMazitis if he were a thousand times more intelligent
[12:55:15] *** Quits: LiaoTao (~LiaoTao@gateway/tor-sasl/liaotao) (Ping timeout: 276 seconds)
[12:55:17] <PJBoy> actually nah, even that's too harsh
[12:55:57] *** Joins: LiaoTao (~LiaoTao@gateway/tor-sasl/liaotao)
[12:56:45] <ville> lpapp: https://coliru.stacked-crooked.com/a/b38308a68e004302 ?
[12:56:46] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[12:57:54] <ville> https://coliru.stacked-crooked.com/a/41b8b4d7d924a190 i guess, anyway i don't really do cmake so that could be off. didn't test it
[12:58:17] <ville> ah crap didn't create the export  header...
[12:58:47] <ville> https://coliru.stacked-crooked.com/a/53d2f6f0ca50df1a ?
[12:58:48] <rond_> what's the prefered way to extend a std::vector with another one? something like vec1+vec2 in python?  is it vec1.insert(vec1.end(), vec2.begin(), vec2.end()); ?
[13:00:19] <lpapp> this looks like a detailed explanation on templates if anyone else finds this useful: https://stackoverflow.com/a/59614755
[13:01:15] <lpapp> ville: looks like your paste does not build on the webpage if you look at the bottom.
[13:02:14] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:02:21] <lpapp> ville: it is a deliberate decision that we make the code stand for itself, and not downstream buildsystem for upstream code, so things like GenerateExportHeader are not acceptable for us.
[13:02:55] <lpapp> I am actually not even sure why it is needed if you have a declspec macro.
[13:05:05] <lpapp> if someone knows the msvc nomenclature for this, that is also fine, it does not have to be cmake, but if you want me to provide a working testbed, I will not be able to get the msvc commands / buildsystem right myself within any reasonable amount of time as I have no experience with this.
[13:05:21] <lpapp> (I still think that is not required though, but if you insist...)
[13:06:51] <RandomReader> rond_ - that's probably the most straightforward approach yes
[13:07:40] *** Quits: vdamewood (~vdamewood@fedora/vdamewood) (Quit: Life beckons)
[13:08:32] <rond_> RandomReader so insert overwrites old memory and, if needed, allocates new one?
[13:08:36] *** Joins: m_ben (~m_ben@user/m-ben/x-7429725)
[13:08:54] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 258 seconds)
[13:08:57] <RandomReader> what do you mean by overwriting in this context?
[13:09:22] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[13:10:19] <Juliu> I'm using CMake to create the project files for my MSVC (Visual Studio). I can highly recommend that
[13:10:43] *** Quits: scoobydoo (~scooby@user/scoobydoo) (Ping timeout: 268 seconds)
[13:10:50] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:11:01] *** Joins: scoobydoo (~scooby@user/scoobydoo)
[13:14:49] <Juliu> I have a C++ related question: It seems that my program simply terminates without any error when a std::unordered_map gets too large. Is that possible?
[13:17:07] <TinoDidriksen> Allocation failures are exceptions, so yeah bad_alloc is possible. But you need to check what exactly happens.
[13:17:19] <rond_> RandomReader assert(vec1.size() < vec2.size()); vec1.insert(vec1.begin(), vec2.begin(), vec2.end());     // it will overwrite the whole vec1 and allocate memory and fill them with appropriate tail of vec2
[13:17:42] <rond_> is that true?
[13:17:54] <Juliu> Yes, sure. But shouldn't I get an error message if the program crashes because of an exception (which I don't capture) ?
[13:18:37] <RandomReader> rond_ - that's an odd use of "overwrite", if you mean it may require resizing the vector which has to transfer existing elements to a new space, then sure, same as any addition would
[13:19:08] <RandomReader> vec.push_back(val)   is equivalent to   vec.insert(vec.end(), val)   in terms of simply adding to the container
[13:19:19] <RandomReader> insert just has more options, like in this case adding several values
[13:19:27] <lpapp> TinoDidriksen: bad_alloc is not out of memory: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1404r1.html
[13:19:42] <RandomReader> whether that requires adjusting the storage depends on how much extra capacity the vector has
[13:20:29] <rond_> RandomReader ad. 'overwrite' - I meant that vec.insert(vec.begin(), val)  is more of vec[0] = val rather than vec.push_front(val)
[13:20:53] <RandomReader> rond_ - oh, no, it strictly adds new elements
[13:21:22] <lpapp> Juliu: maybe, you program exits, not crashes.
[13:21:25] <RandomReader> (so that is equivalent to .push_front)
[13:21:28] <ville> lpapp: https://wandbox.org/permlink/PYs7PpURtIbifhvR grab those 4 files and stick them in a directory, try buiding it for example: mkdir build && cd build && make -G "Ninja" ../ && ./ninja
[13:21:37] <rond_> RandomReader Okay, I wasn;t sure about this. thank you!
[13:21:48] <ville> lpapp: replace ninja with whatever you've available
[13:22:02] <TinoDidriksen> I am well aware what bad_alloc means.
[13:22:36] <Juliu> lpapp, the unordered_map is within a function, and when the function terminates there definitely would be an output. But I don't see any output. The program just ends
[13:22:42] <ville> lpapp: sorry typo aboe: mkdir build && cd build && cmake -G "Ninja" ../ && ./ninja
[13:24:31] <lpapp> Juliu: this could be because an exit, not other termination.
[13:24:33] <lpapp> of*
[13:24:39] <lpapp> try to put a breakpoint on _exit or something.
[13:25:11] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Remote host closed the connection)
[13:25:15] <lpapp> ville: I do not see the export definition in those commands, without that, dllexport will not work.
[13:25:45] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[13:25:51] <lpapp> this is why I am saying it is not simple :)
[13:25:55] <lpapp> otherwise, I would have already done it.
[13:25:55] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:26:01] <ville> lpapp: in what commands?
[13:26:15] <ville> lpapp: what file?
[13:26:26] <lpapp> ville: in order to have a proper declspec macro, you need to have a define for the compiler so that it knows when to import and export.
[13:26:36] *** Joins: lionkor (~lionkor@beammp/staff/lionkor)
[13:26:56] <ville> lpapp: CMakeLists.txt line 7?
[13:27:39] <lpapp> ah, you updated the CMakeLists.txt file
[13:28:03] *** Joins: joel135 (sid136450@hampstead.irccloud.com)
[13:28:13] <ville> forget whatever came before. grab those 4 files. don't mix with old ones
[13:28:17] <lpapp> I will try, by the way, if you use cmake --build, you do not need to choose between ninja and make.
[13:28:31] <lpapp> not explicitly, I mean.
[13:28:58] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[13:29:09] <lpapp> ville: you might need code also that consumes this library, and therefore dllimports it
[13:29:37] <ville> lpapp: the main file?
[13:29:43] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[13:29:49] <Juliu> lpapp, if something called exit, that would terminate the program
[13:29:55] <ville> lpapp: the tab with no name is supposed to be main.cxx
[13:30:00] <lpapp> Hmm, on a second look, this comes at the stage of building the dll, not when using the dll, so perhaps never mind what I wrote above.
[13:30:24] <lpapp> Juliu: yes, which is what is happening for you, exit without output.
[13:30:47] <joel135> hello. meshlab is compiled using cmake. i want to use this https://stackoverflow.com/a/42513/939402 on a certain file in the source tree. how do i do this?
[13:31:03] <joel135> i am using g++
[13:31:24] <Juliu> lpapp, yes, maybe. That is my question: If I don't catch the exception thrown by the std::unordered_map, will this maybe exit my program without any error?
[13:31:57] <lpapp> there may be no exception
[13:31:59] <lpapp> but it is easy to verify
[13:32:03] <lpapp> catch everything
[13:32:25] <Juliu> What happens in general if you don't catch an exception that was thrown?
[13:32:48] <lpapp> the program terminates
[13:33:10] <Juliu> Without any error?
[13:33:43] <lpapp> https://en.cppreference.com/w/cpp/error/terminate
[13:34:24] *** Joins: alsolionkor (~lion@beammp/staff/lionkor)
[13:34:35] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 264 seconds)
[13:35:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:36:02] *** Quits: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) (Quit: leaving)
[13:36:30] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[13:37:15] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[13:37:23] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[13:37:23] *** ChanServ sets mode: +v npaperbot
[13:38:41] <Juliu> Thanks, but if I call std::terminate() myself, then I at least get a system message that the program isn't working anymore
[13:38:51] <lpapp> ville: not sure if __WIN32__ is the right macro
[13:39:07] <lpapp> Juliu: that is why I suggested to put a breakpoint on exit/_exit
[13:39:09] <TinoDidriksen> Juliu, instead of guessing, attach a debugger.
[13:39:14] <lpapp> because it sounds like there is a normal exit going on.
[13:39:57] <Juliu> TinoDidriksen, how can I debug any error if my program terminates without any error
[13:40:04] *** Joins: DSpider (DSpider@2a02:2f00:4ff:ffff::646c:6b2c)
[13:40:10] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[13:40:28] <lpapp> Juliu: you can put a breakpoint before it exits.
[13:40:28] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:40:47] <PJBoy> maybe remove the line of code that says `if (size(table) > 10000) abort();`
[13:40:52] <Juliu> lpapp, I had cases (depending on what I try to put into the unordered_map) where it crashed and I get an error. But sometimes it simply exits my program without any error or output
[13:41:08] <PJBoy> this isn't a case of the out of memory killer is it?
[13:41:24] <ville> lpapp: i am not on windows. i've typed it out blind
[13:41:25] <PJBoy> maybe check dmesg or whatever
[13:41:27] <Juliu> PJBoy, even when I call std::abort() myself I get a system error message
[13:41:38] <PJBoy> fair
[13:41:53] <ville> lpapp: feel free to substitute whatever your real project uses to determine it's windows
[13:42:02] <Juliu> PJBoy, yes, this is probably after there are several gigabytes in the unordered_map and it runs out of memory
[13:42:25] <lpapp> ville: for this testbed, the macro is not even needed
[13:42:32] <lpapp> so, I will just remove it, but it is typically _WIN32
[13:42:50] <Juliu> PJBoy, is there anything known about an out of memory bug, or why did you ask?
[13:43:11] <PJBoy> on linux, the OOM killer is a thing that kills your program without giving it a chance to recover
[13:43:14] <TinoDidriksen> Some OSs have an OOM killer that will silently take down a memory hogging process.
[13:43:21] <PJBoy> so you bad_alloc never gets thrown etc.
[13:43:23] <lpapp> Juliu: by the way, you bashed unordered_map several times
[13:43:32] <lpapp> so, why are you even using it with GBs of memory?
[13:43:32] <PJBoy> you can disable it somehow
[13:43:35] <lpapp> you said it is useless :)
[13:43:44] <Juliu> PJBoy, that might be it, even though I'm using Windows
[13:44:06] <PJBoy> windows + WSL or just windows?
[13:44:15] <RandomReader> an uncaught exception on Windows will simply exit by default, but you'd see it if you attached a debugger
[13:44:35] <RandomReader> again, instead of guessing or arguing about it, just take a useful step
[13:44:47] <RandomReader> wastes less time and gives you a data point either way
[13:44:48] <Juliu> lpapp, I also bashed maps since they also are often just a quick and dirty extension for something that could have been done nicer. I use them just to find loops in my program as a quick and dirty way that I will remove late on
[13:45:21] <lpapp> lol
[13:45:31] <lpapp> map/unordered_map are useful
[13:45:53] <Juliu> lpapp, do you think I am that nuts that I would put several gigabytes of memory into an unordered_map just for fun?
[13:45:57] <lpapp> it can significantly speed up the average runtime complexity for repetitive work.
[13:46:18] <Juliu> Useful for people who can't design algorithms, indeed
[13:46:22] <lpapp> Yeah, I am not pretty sure why you put so much stuff in memory
[13:46:27] <lpapp> sounds like you need to optimise the space complexity.
[13:47:02] <Juliu> Because I am lazy and I simply put long output lines into a unordered_set until I reach a line that already happened befor
[13:47:05] <Juliu> e
[13:47:36] <ville> lpapp: yes you can remove it
[13:48:15] <lpapp> Juliu: sounds like you need to optimise the space complexity.
[13:48:22] <Juliu> lpapp, this is not the final version, I just use it to find infinity loops, that then will be removed by changing the algorithm
[13:48:30] <lpapp> I would rather do that personally than trying to detect OOM.
[13:48:52] <lpapp> yeah, just do the right thing now rather than the bad and work it around :)
[13:48:54] <Juliu> The final version will not have any unordered_map/unordered_set/map in it
[13:49:24] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:49:28] <Juliu> The right thing is creating a correct algorithm that can not get stuck in infinite loops, which I am trying
[13:49:55] <PJBoy> so in your eyes, map et al is a crutch
[13:50:31] <lpapp> ville: C:\Users\laszlo.papp\Projects\testbed\dso.cxx(7): error C2491: 'f': definition of dllimport function not allowed
[13:50:38] <Juliu> They have their place. But very often people (especially beginners) abuse them instead of redesigning their data structures and algorithms
[13:50:51] <lpapp> ville: something must be wrong with the macro variable as it should export, not import.
[13:50:59] <lpapp> when building dso.cxx
[13:50:59] <PJBoy> that's surprisingly fair assessment
[13:51:05] *** Quits: mitch0 (~mitch@84-236-16-46.pool.digikabel.hu) (Ping timeout: 260 seconds)
[13:51:23] *** Quits: baltazar (~baltazar@84-236-16-46.pool.digikabel.hu) (Ping timeout: 264 seconds)
[13:51:32] <Juliu> Beginners should be punched for using a map, since otherwise they will use a map everywhere instead of learning the right algorithm
[13:51:37] <ville> lpapp: did you try line 6 with out the DSO_DECLSPEC?
[13:51:59] <PJBoy> and that's considerably less fair
[13:52:42] <lpapp> ville: you mixed up BUILD_DSO vs DSO_BUILD
[13:52:55] *** Joins: baltazar (~baltazar@193-110-63-186.cable-modem.hdsnet.hu)
[13:52:59] *** Joins: mitch0 (~mitch@193-110-63-186.cable-modem.hdsnet.hu)
[13:53:05] <ville> lpapp: ok. like i said 0 test. just typed it all out
[13:53:06] <lpapp> Juliu: you literally claimed multiple times hash maps are bad
[13:53:09] <lpapp> they do not speed up algos.
[13:53:22] <lpapp> you even claimed it is O(n) in worst case (which is not correct for every hash map implementation)
[13:54:13] <PJBoy> hash maps are algorithmic magic
[13:54:14] <lpapp> but worst case also does not matter all that much for repetitive work if you can afford the extra space complexity.
[13:54:50] <lpapp> ville: LINK : fatal error LNK1104: cannot open file 'kernel32.lib'
[13:56:01] <lpapp> these are the kind of things I did not want to go down this route because the existing buildsystem has resolved all these issues ^_^
[13:56:18] <PJBoy> usual visual studio if you don't want build issues
[13:56:20] <PJBoy> *use
[13:56:23] <lpapp> I guess you need to declare the path to it in the cmake file.
[13:56:46] <lpapp> No, thanks, if anything, QtCreator and Visual Code as they are cross-platform
[13:56:46] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[13:56:51] <lpapp> but it is a bit overkill for a small testbed.
[13:56:56] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[13:57:01] <lpapp> (it also defeats the purpose of a small test bed)
[13:57:25] <PJBoy> I mean if you wanna continue stumbling over the build system, then yeah I guess it's overkill
[13:57:40] <lpapp> VS is a lot more stumbling.
[13:58:03] <PJBoy> how so?
[13:58:07] <lpapp> and definitely not a cross-platform solution that ville can also run on the web machine.
[13:58:16] <lpapp> or me on Mac, etc.
[13:58:26] <lpapp> it just does not make sense for cross-platform development like this :)
[13:58:29] <PJBoy> yeah for sure
[13:58:31] <ville> lpapp: that should be an easy fix... link it
[13:58:32] <PJBoy> but this is just a testcase
[13:58:42] <PJBoy> and you only care about the windows aspect of it
[13:58:52] <lpapp> no, the solution has to work on multiple platforms.
[13:59:08] <lpapp> ville: I will investigate, but I feel we are derailing from the real issue with all these extra subprojects added
[13:59:09] <PJBoy> yeah but you're concentrating on the windows bit, from what I've read
[13:59:20] <PJBoy> declspec being some windows shit
[13:59:23] <Juliu> lpapp, I never said hash-maps are bad. I said, if the hash-map has a size of Omega(f(n)) and you put n items in it, then the average runtime to access an item in the hash-map will be something like O(n / f(n)), or something like that
[13:59:30] <ville> lpapp: subprojects?
[14:00:04] <ville> lpapp: there is no subproject in that cmakelists.txt
[14:00:22] <lpapp> Juliu: no, you claimed it does not speed up the time complexity (has the logs)
[14:00:25] <lpapp> :)
[14:00:37] <lpapp> whereas that is the whole purpose of it to provide amortised O(1).
[14:00:47] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:00:51] <lpapp> ville: creating a test bed is a project of its own
[14:00:55] <Juliu> lpapp, and since a normal hash-map does not automatically change it's size (unlike std::unordered_map), you either need to know n in advance and make the hash-map O(n) large, or you will not get an average O(1) runtime
[14:01:00] <lpapp> and as you can see, not a 2 minutes job, or even 5.
[14:01:28] <Juliu> lpapp, yes, if you simply use a hash-map of constant size, that is as good or bad as not using any hash-map at all in theory
[14:01:29] <lpapp> Juliu: why would you need to know the size in advance?
[14:01:50] <Juliu> lpapp, see my sentence above
[14:02:02] <lpapp> std::unordered_map is a normal hash map, so I am not sure what you mean.
[14:02:46] <Juliu> I catched all exceptions thrown by inserting something into the unordered_map, and it did not catch anything, but my program crashed again. This time with a system error
[14:03:04] <lpapp> ville: I honestly have no idea how to link that, not a Windows guru myself.
[14:03:18] <TinoDidriksen> A big selling point of containers is that they will resize as needed. I'd say it's normal for a hash map to resize. It would be unusual for it not to, and that's the kind of thing I'd expect to see in the type a'la fixed_hash_map.
[14:03:19] <ville> lpapp: oh not really. you should have the capability to whipup a "default blank" project with a push of a button on your development machine. if you don't then that's something you definelty should remedy
[14:03:25] <lpapp> As I said before, this is not trivial and time-consuming, if someone has a testbed to try, I will.
[14:03:29] <PJBoy> Juliu, as in std::system_error?
[14:03:30] <lpapp> I would get back to the real issue myself.
[14:03:43] *** Quits: JohnMS_WORK (~kvirc@213.134.183.29) (Ping timeout: 258 seconds)
[14:03:45] <lpapp> I do not think so.
[14:04:01] <lpapp> I mean even you do not have it, with multiple mistakes along the way.
[14:04:07] <Juliu> lpapp, if you don't know n in advance, the size of your hash-map will always be a constant with respect to n, and this results in NO theoretical average-case speed-up at all
[14:04:12] <lpapp> I do not think it is that easy as you envision it in your head.
[14:04:23] *** AbleBacon_ is now known as AbleBacon
[14:04:41] <Juliu> PJBoy, as in Windows telling me that my program is no longer working and that it's trying to recover it
[14:04:52] <lpapp> Juliu: you do not know how hash maps are implemented, but not as stupidly as you imagine.
[14:05:00] <PJBoy> Juliu, right
[14:05:08] <PJBoy> Juliu, are you developing a Windows API app?
[14:05:13] <PJBoy> i.e. with winmain
[14:05:14] <lpapp> of course, they resize in an intelligent manner, not stupid.
[14:05:29] <PJBoy> because windows apps catch C++ exceptions using the windows vectored exception handler
[14:05:31] <PJBoy> it's real annoying
[14:05:33] <lpapp> I do not have to tell it again because someone already told you the other day they do increase the size of course.
[14:05:40] <lpapp> You do not have to know the size in advance at all.
[14:06:49] <Juliu> lpapp, std::unordered_map is not a hash-table. It's an automatically resizing and re-hashing data structure that utilizes a hash-table internally. But of course it all boils down what we mean by hash-table or hash-map, and often people mean such an automatic data structure, even though this technically is not a simple hash-table
[14:06:52] <lpapp> and adding elements to unordered_map is amortised O(1) not what you wrote. Let me find you the page that explains this
[14:07:41] <TinoDidriksen> In C++ we can assume data structures resize as needed. The ones that don't have this specified in the type.
[14:07:50] <Juliu> PJBoy, no, it's just a simple console program without any inputs from the user. It just calculates something and does some outputs on the console
[14:08:17] <PJBoy> and needless to say, you built in debug configuration and ran in debugger?
[14:08:25] <lpapp> Juliu: https://www.geeksforgeeks.org/unordered_map-in-cpp-stl/
[14:08:35] <PJBoy> oh god geeksforgeeks
[14:08:40] <PJBoy> burn it
[14:08:53] <lpapp> Practically, any language I know uses this concept.
[14:08:57] <Juliu> lpapp, yes, adding and accessing elements to/in a std::unordered_map is armortized O(1). I think, I never said otherwise
[14:09:00] <TinoDidriksen> So when talking about a hash table in C++ we should still assume resizing as needed.
[14:09:01] <lpapp> Juliu: so, I am not sure what you are referring to.
[14:09:22] <Juliu> lpapp, I am referring to a hash-table, as I said. Not a std::unordered_map
[14:09:23] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 264 seconds)
[14:09:28] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[14:09:36] <PJBoy> every single sentence on that page is wrong in one way or another
[14:09:58] <lpapp> No one is referring to what you are, it is pretty standard to mean std::unordered_map by default.
[14:10:16] <Juliu> TinoDidriksen, as I pointed out, a normal dumb hash-table that has no automatic resizing and rehashing is pretty useless, at least if you don't know n in advance
[14:10:38] <PJBoy> modulo definitions
[14:10:39] <TinoDidriksen> That may be what you mean, but that's an unusual position to insist on.
[14:10:54] <Juliu> PJBoy, lol
[14:11:11] <PJBoy> god that page even includes bits/stdc++.h
[14:11:15] <TinoDidriksen> 99% will assume that a hash table will resize. If you mean a non-resizing one, the onus is on you to specify that up front.
[14:11:15] <PJBoy> fuck that website
[14:11:18] <lpapp> yeah, practically no language means that which I have come across.
[14:11:43] <Juliu> TinoDidriksen, not my fault I am a PhD of computer science and know something about the theory, and lpapp is just someone who wants to get shit done
[14:11:53] <TinoDidriksen> Even hash tables in books will talk about growth strategies.
[14:12:12] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[14:12:34] <lpapp> PJBoy: you can troll as much as you like, however they are very correct about amortised O(1) - would be really dumb from you to debate that.
[14:12:35] <TinoDidriksen> This is #C++-general - not #compsci. In C++, containers grow as needed.
[14:12:43] <Juliu> TinoDidriksen, he even said the time-complexity of a program wasn't bound by its space-complexity, and the space-complexity wasn't bound by its time-complexity
[14:12:50] <PJBoy> lpapp, they don't even say amortized!
[14:12:56] <PJBoy> lpapp, I'm seriously not trolling
[14:13:02] <PJBoy> that website is fucking garbage
[14:13:05] <Juliu> TinoDidriksen, lpapp and I had this discussion in
[14:13:13] <Juliu> ... in #algorithms, not here
[14:13:20] <lpapp> PJBoy: yes, they do, they say on average.
[14:13:47] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[14:13:54] <Juliu> PJBoy, chill down, it's good enough for most normal people
[14:14:01] <lpapp> PJBoy: pleae maintain a more professional tone if possible.
[14:14:06] <lpapp> please*
[14:14:15] <PJBoy> it also says the worst case complexity is N^2
[14:14:28] <PJBoy> the worst case complexity is linear
[14:14:37] <lpapp> You said it more than once (although in this case, it is incorrect, they are correct about O(1) average), and in a more derogative way than needed.
[14:14:42] *** Joins: pah (~pah@user/pah)
[14:14:43] <PJBoy> and like, average is kinda close to amortized
[14:14:45] <Juliu> Worst-case of what operation?
[14:14:46] <PJBoy> but it's not the same
[14:15:10] <lpapp> PJBoy: no, you twist what they write
[14:15:10] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:15:14] <lpapp> they say "can go"
[14:15:17] <lpapp> and that is really correct.
[14:15:23] <lpapp> there are various ways of implementing it
[14:15:23] <PJBoy> naive quicksort is n log n "on average"
[14:15:27] <lpapp> in fact, O(n) is not the only way.
[14:15:34] <lpapp> it can even be O(logn).
[14:15:34] <PJBoy> but it's not n log n amortized over all inputs
[14:15:54] <lpapp> but I can see that you twist their words, so yeah, with twisting, it can be incorrect.
[14:16:02] <PJBoy> it can't go up to O(n^2) though
[14:16:06] <PJBoy> what am I twisting?
[14:16:27] <Juliu> PJBoy, maybe they mean if you insert n elements
[14:16:36] <PJBoy> even that's not N^2
[14:16:46] <Juliu> PJBoy, it is in the worst-case
[14:16:54] <lpapp> ville: if you know how to link that, I will amend it, otherwise I will not continue this path, took too much of my time, and the end of the tunnel is not close.
[14:16:54] <PJBoy> that'd be O(m n) for m elements
[14:17:01] <PJBoy> unless they literally mean doubling the size of the map
[14:17:02] <Juliu> PJBoy, what is m?
[14:17:07] <PJBoy> for m elements I said
[14:17:12] <PJBoy> m inserted elements
[14:17:14] <Juliu> PJBoy, sorry, I meant what is n?
[14:17:22] <PJBoy> n is the map.size()
[14:17:34] <PJBoy> for the worst case behaviour of rehashing
[14:17:53] <PJBoy> this is all documented accurately here https://en.cppreference.com/w/cpp/container/unordered_map/insert#Complexity
[14:17:59] <Juliu> PJBoy, for a map size of n inserting n elements leads to a runtime of O(n^2) in the worst-case
[14:18:10] <PJBoy> yeah that I'll agree with
[14:18:26] <Juliu> No clue what they meant, you read the text, not me
[14:18:53] <PJBoy> they talk about how the cost of search, insert and delete are O(1)
[14:19:00] <PJBoy> on average I guess
[14:19:00] <Juliu> Maybe one should not blindly trust what someone else writes on the internet
[14:19:16] <lpapp> you do not have to guess, they write clearly on average.
[14:19:21] <lpapp> I honestly think you are trolling.
[14:19:21] <PJBoy> I just really hate that website's guts
[14:19:26] <lpapp> what they write is correct.
[14:19:33] <lpapp> yes, trolling :)
[14:19:39] <PJBoy> they're clearly not correct about the O(n^2) thing
[14:19:51] <PJBoy> I can cite you the standard
[14:19:53] <Juliu> Amortized O(1) in the average-case, yes
[14:20:02] <PJBoy> would you like me to?
[14:20:07] <Juliu> Amortized O(n) in the worst-case
[14:20:11] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[14:20:13] *** Joins: pah_ (~pah@host-79-37-0-17.retail.telecomitalia.it)
[14:20:23] <PJBoy> nah it's O(n) in the worst case
[14:20:27] <PJBoy> pure
[14:20:49] <Juliu> Amortized means the average for one element, while average case means the average over all inputs of size n
[14:20:53] <lpapp> not sure what is amortised O(n)
[14:22:37] <PJBoy> amortisation is all about considering a sequence of operations and taking an average over that
[14:22:58] <PJBoy> like if I were to do k insert operations
[14:23:03] <Juliu> O(n) also means amortized O(n), and amortized O(n) also means O(n) for all but a constant number of elements, I would say. But ok, you are right, O(n) for every element is even worse, and it can happen
[14:23:18] <PJBoy> whereas average complexity analysis is all about considering the cost of the operation for all inputs / states
[14:23:30] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[14:23:30] <PJBoy> they're similar but different
[14:23:44] <Juliu> PJBoy, that is what I said, yes
[14:23:54] <lpapp> No, what I meant is what would be amortised O(n) here? Nothing?
[14:24:14] <PJBoy> worst case time complexity of unordered_map insert
[14:24:23] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Ping timeout: 264 seconds)
[14:24:26] <Juliu> lpapp, as I just wrote, that would imply O(n) for all but a constant number of elements
[14:24:30] <lpapp> ah, no, that is O(n) in the std implementation, I think.
[14:24:44] <lpapp> geeks2geeks probably means it can be implemented worse.
[14:25:02] <Juliu> I bet, I can implement it in O(n^3) :D
[14:25:09] <PJBoy> nah no props to geeks4geeks
[14:25:15] <lpapp> Juliu: please drop your weird concept about some weird hash table not applicable in C++ for unordered_map
[14:25:16] <Juliu> Challenge accepted :D
[14:25:29] <lpapp> when we discuss hash, unless explicitly stated, you can clearly assume it is a resizing unordered_map in C++.
[14:25:35] <Juliu> lpapp, dude, get your bachelors in computer science and we talk again
[14:25:53] <TinoDidriksen> No, when talking about C++, hash tables grow by default.
[14:26:02] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[14:26:12] <Juliu> lpapp, and I also always said that I am talking about hash-tables smaller than O(n)
[14:26:33] <rond_> insert is just O(n), no need for amortization here
[14:26:35] <Juliu> I said it like 7 times in total, I think
[14:26:47] <Juliu> rond_, that is incorrect
[14:27:03] <rond_> I'd be more than happy to learn why
[14:27:18] <PJBoy> it's amortized O(1), O(n) in the worst case
[14:27:30] <Juliu> rond_, inserting into a hash-table is amortized O(1) in the average case and O(n) in the worst-case
[14:27:37] <lpapp> ville: I figured out what the problem was.
[14:27:47] *** Quits: pah_ (~pah@host-79-37-0-17.retail.telecomitalia.it) (Ping timeout: 260 seconds)
[14:27:58] <PJBoy> the use of the word average here triggers me
[14:28:06] *** Joins: pah (~pah@user/pah)
[14:28:11] <Juliu> I mean a autmatically resizing hash-table of course, or a hash table that is at least O(n) in size
[14:28:16] <PJBoy> you normally only talk about average complexity when doing probabilistic algorithms
[14:28:19] <lpapp> ville: in any case, your example also does not involve a class
[14:28:44] <lpapp> PJBoy: wrong
[14:28:44] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:28:54] <Juliu> PJBoy, if you only concider the average case you run the risk that your program might be really really slow for some inputs
[14:29:04] <rond_> Juliu that doesn't prove my sentence wrong at all
[14:29:22] *** Joins: JohnMS_WORK (~kvirc@213.134.183.29)
[14:29:33] <PJBoy> well
[14:29:33] <Juliu> rond_, I think what you said is different from what PJBoy and I said, so you are wrong
[14:29:39] <PJBoy> let me back up my claim https://en.wikipedia.org/wiki/Average-case_complexity
[14:29:47] *** Joins: RoKenn (~RoKenn@2001:a61:3505:d101:ec80:67d5:e60e:9aab)
[14:29:47] *** Quits: RoKenn (~RoKenn@2001:a61:3505:d101:ec80:67d5:e60e:9aab) (Changing host)
[14:29:47] *** Joins: RoKenn (~RoKenn@user/rokenn)
[14:29:57] <rond_> Juliu obviously a statement that insert is O(n) is correct
[14:30:00] <rond_> no doubt here
[14:30:11] <rond_> under no circumstances it's more than linear
[14:30:13] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Client Quit)
[14:30:17] <rond_> hence, it's O(n)
[14:30:23] <Juliu> rond_, ok, whatever. Talking to you seems pointless
[14:30:33] <rond_> you should educate yourself before you tell people to 'get their diploma'
[14:30:37] <PJBoy> he is right though
[14:30:40] <rond_> which is offensive and rude
[14:31:00] <PJBoy> it's both amortized O(1) and O(n)
[14:31:14] <Juliu> rond_, fine, I see what you mean. You win. You didn't say it's O(n)-hard. Only that it is in O(n)
[14:31:29] <PJBoy> O(n)-hard isn't a thing
[14:31:31] <rond_> what's the definition of O(n)-hard?
[14:31:38] <rond_> did you mean Theta(n)?
[14:31:48] <Juliu> PJBoy, why not?
[14:31:56] <Juliu> Of course hardness is a thing
[14:32:02] <Juliu> It means you can't do it faster
[14:32:19] *** Quits: malloy (~jimery@116.30.221.89) (Quit: WeeChat 3.0)
[14:32:35] <PJBoy> hardness is expressed over complexity classes
[14:32:41] <PJBoy> not time complexities
[14:32:53] <PJBoy> you'd have to define O(n)-hard yourself
[14:33:01] <rond_> of course, his referring to Theta() and confusing concepts.
[14:33:04] <rond_> he's*
[14:33:14] <Juliu> For example you probably have heard about NP-complete problems. This means that the problem is in NP and simultaneously is NP-hard
[14:33:23] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[14:33:50] <lpapp> ville: main.obj : error LNK2019: unresolved external symbol "public: __cdecl Foo::Foo<char>(char const &)" (??$?0D@Foo@@QEAA@AEBD@Z) referenced in function main
[14:33:53] <lpapp> xxx.exe : fatal error LNK1120: 1 unresolved externals
[14:33:54] <lpapp> I was able to reproduce the same issue
[14:33:55] <lpapp> on the testbed
[14:33:59] <lpapp> ville: do you want the files?
[14:34:00] <Juliu> PJBoy, why would I have to define O(n)-hard? It's all problems that you can't do faster than O(n)
[14:34:11] <PJBoy> because there's no existing definition of it
[14:34:23] *** Joins: pah (~pah@user/pah)
[14:34:34] <PJBoy> hardness requires the notion of a reduction
[14:35:13] <PJBoy> and reductions in existing literature are like polynomial time transformations from one problem to another
[14:35:16] <ville> lpapp: did you get the function template one work?
[14:35:25] <PJBoy> there's no more granular notion
[14:35:43] <ville> lpapp: but sure stick them on wandbox
[14:36:29] <lpapp> testbed: https://paste.ofcode.org/tm44DkTpNMqwPavneavZFp
[14:36:33] <PJBoy> and as rond_ said, you're clearly talking about theta
[14:36:39] <lpapp> this reproduces the template unresolved symbol issue
[14:36:50] <lpapp> now, absolutely no reason to complain and moan for anyone :P
[14:37:32] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[14:37:44] <PJBoy> test case is always much appreciated
[14:38:14] <ville> lpapp: and did the function template one work?
[14:38:15] <Juliu> PJBoy, "This motivates the concept of a problem being hard for a complexity class. A problem X is hard for a class of problems C if every problem in C can be reduced to X. Thus no problem in C is harder than X, since an algorithm for X allows us to solve any problem in C." -- https://en.wikipedia.org/wiki/Computational_complexity_theory   and O(n) is a complexity class
[14:38:52] <PJBoy> O(n) is not a https://en.wikipedia.org/wiki/Complexity_class
[14:39:03] <lpapp> ville: do you see the linker error at the bottom?
[14:39:12] <lpapp> PJBoy: so, it is not fucking garbage?
[14:39:19] <ville> lpapp: answer the question so i know how to procede
[14:39:21] <lpapp> does not require persoanl insults?
[14:39:32] <PJBoy> lpapp, what's not garbage?
[14:39:34] <lpapp> ville: as you can see at the bottom, it has the same linker issue, as I said above...
[14:39:44] <PJBoy> I don't recall personal insults
[14:39:44] *** Quits: proller (~p@2a02:6b8:b081:a410::1:18) (Ping timeout: 268 seconds)
[14:39:58] <PJBoy> I recall saying you should use visual studio
[14:40:01] <lpapp> what is not inline with your opinion, apparently.
[14:40:05] <Juliu> PJBoy, of course O(n) time is a complexity class. It's even listed here:   https://complexityzoo.net/Complexity_Zoo:L#lin
[14:40:15] <PJBoy> and I recall saying geeks4geeks is gutter trash
[14:40:28] <PJBoy> I assume you're not the owner of that website
[14:40:40] <Juliu> Me?
[14:40:43] <lpapp> do I really have to repaste the personal insults or will you find them yourself
[14:40:45] <PJBoy> nah lpapp
[14:41:15] <lpapp> 11:23 < PJBoy> hm, you know you're like a RonaldsMazitis if he were a thousand times more intelligent
[14:41:15] <PJBoy> well I didn't think I did
[14:41:19] <lpapp> 11:24 < PJBoy> actually nah, even that's too harsh
[14:41:27] <PJBoy> look I took it back
[14:41:30] <PJBoy> give me some credit
[14:41:38] <lpapp> you should not say such things for others :/
[14:41:42] <PJBoy> it was more of an insult to Ronalds
[14:41:44] <lpapp> (in the first place)
[14:41:50] <Juliu> PJBoy, btw, pretty much everything you can make up that makes sense can be a complexity class. Saying something is not a complexity class is silly
[14:42:06] <LordKalma> I'll subscribe what PJBoy said, I don't mind
[14:42:14] <ville> lpapp: did you get the function template one to work? i need the answer to this question before i know what the next step could be
[14:42:29] <lpapp> ville: ah, the irrelevant one?
[14:42:36] <Juliu> Why are you guys fighting over if GeekForGeek is a good site or not? Will that change anything?
[14:42:36] <lpapp> Yes, that built.
[14:42:41] <PJBoy> Juliu, I'll admit this is the first time I've seen the notion of a complexity class that's constrained by time complexity
[14:42:46] <lpapp> but that is a different case.
[14:42:50] <lpapp> I thought?
[14:43:15] <ville> lpapp: it is not irrelevant. it is pertinent to know we can get at least _some_ function template work
[14:43:15] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:43:28] <Juliu> PJBoy, what are you talking about? Have you never heard of P or NP ? Those are also constrained by the time complexity
[14:43:38] <PJBoy> they're constrained by the type of turing machine used
[14:43:43] <PJBoy> deterministic vs non-determinstic
[14:43:49] <PJBoy> and that's the interesting aspect of P vs NP
[14:43:54] <PJBoy> are those two turing machine models the same?
[14:44:06] <lpapp> ville: ok, if it is helpful for you, then good, I guess.
[14:44:11] <Juliu> PJBoy, and what does the "P" in P or in NP stand for?
[14:44:20] <PJBoy> polynomial
[14:44:27] <Juliu> PJBoy, and what is polynomial?
[14:44:28] <PJBoy> and non-determinstic polynomial for NP
[14:44:37] <PJBoy> both classes are polynomial
[14:44:42] <PJBoy> only the turing machine is different
[14:44:42] <lpapp> I am curious what happened in the Qt Project
[14:44:45] *** tin- is now known as tin
[14:44:55] <Juliu> PJBoy, what property of the classes is polynomial?
[14:45:05] <PJBoy> the time required to solve a problem
[14:45:11] <PJBoy> where time is expressed in turing machine operations
[14:45:26] *** Joins: markong (~kvirc@213.146.188.203)
[14:45:30] <Juliu> PJBoy, and then why do you say that you have never heard of a complexity class being constrained by time?
[14:45:50] <PJBoy> I perhaps misworded what I wrote
[14:46:05] <PJBoy> I see your point though
[14:46:48] <PJBoy> wikipedia goes on to say that DTIME(n) is the formal name for the complexity class of P problems decidable in O(n) time
[14:46:49] <PJBoy> so there you go
[14:47:03] <Juliu> P = Union( O(n^k) for all k )
[14:47:32] <rond_> P = Union ( DTIME(n^k) for all k in N)
[14:47:54] <Juliu> DTIME(n) is what I was talking about, indeed. But not every problem in DTIME(n) is also DTIME(n) hard
[14:48:06] <Juliu> rond_, yes, yes, I was just talking about the time
[14:48:14] <rond_> :)
[14:48:22] <PJBoy> ...indeed haha
[14:48:23] <rond_> I know you did
[14:48:49] *** Joins: ARoxdale (~ARoxdale@84.203.31.229)
[14:48:54] <ville> lpapp: https://wandbox.org/permlink/xiZVRKBtJsYDXD8r
[14:48:55] <Juliu> What is way more uncommon are problems that are constrained by space (i.e. memory)
[14:49:15] <PJBoy> ugh
[14:49:16] <Juliu> L and NL are prominent examples
[14:49:26] <PJBoy> you're reminding me of the streaming algorithms we learnt in uni
[14:49:39] <ville> lpapp: the CMakeLists.txt is probably wrong, as it will fail with the kernel32.dll linker error, as you didn't share all the files and changes you had to make
[14:49:49] <Juliu> PJBoy, is that good or bad? :P
[14:49:56] <lpapp> ville: strictly speaking, you used template before rather than template<>
[14:50:00] <PJBoy> I hate those algorithms
[14:50:04] <lpapp> I would need to investigate whether that can make a difference
[14:50:07] <Juliu> PJBoy :)
[14:50:12] <PJBoy> they all required super mathematical analysis
[14:50:33] <Juliu> I'm working on a project related to L vs NL since 3 years
[14:50:36] <lpapp> ville: just in the template function version, I removed all declspec stuff, and still worked
[14:50:47] <lpapp> which makes sense as templates do not really need exporting
[14:51:24] <lpapp> ville: no change was made for that...
[14:51:30] <rond_> EXPECT_EQ() From GTest doesn't terminate my test, it prints the failure message and keeps going. IS it desired? How to switch it off?
[14:51:32] <lpapp> ville: had to use the VS prompt rather than git bash...
[14:51:35] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[14:51:40] <ville> lpapp: see my paste. i am still using templatate, not template<>, that differentiates explicit instantiation from explicit specialization
[14:51:47] <lpapp> ville: I shared all the fixes I made...
[14:51:54] <lpapp> ok, that is not good
[14:52:03] <lpapp> in my case, I need specialisation, aka. template<>
[14:52:14] <ville> lpapp: http://www.eelis.net/c++draft/temp.explicit#2
[14:52:14] <rond_> I'd like to terminate the test as soon as EXPECT_EQ(val1, val2) isn't true
[14:52:30] <lpapp> ville: where do you implement DSO_DECLSPEC void aa<char>::f(char);
[14:52:38] *** Joins: proller (~p@2002:50f0:d845:10:41a5:ca2e:e623:f4b4)
[14:52:46] <Juliu> My favorite complexity class is O(1). And I mean true O(1), not this fake O(1) measures in words, that would actually be O(log n)
[14:52:48] <ville> lpapp: http://www.eelis.net/c++draft/temp.expl.spec#1.9
[14:52:51] <fruitypunk> usually a bunch of tests run, some fail some succeed. not heard of terminating on a failed test before
[14:53:10] <PJBoy> but I love the RAM model
[14:53:16] <PJBoy> it makes radix sort good
[14:53:25] <ville> lpapp: dso.hxx line 6/8?
[14:53:34] <Juliu> Wait, since when is radix sort good? :P
[14:53:36] *** Quits: AbleBacon (~AbleBacon@user/AbleBacon) (Read error: Connection reset by peer)
[14:53:45] <PJBoy> it's amazing
[14:53:55] <Juliu> For integers maybe
[14:53:58] <urdh> rond_: some frameworks have REQUIRE_EQ which just aborts or whatever
[14:54:02] <lpapp> yes, small integers
[14:54:05] <PJBoy> yeah, but integers is a big use case
[14:54:10] <urdh> rond_: or you could just, you know, `assert`
[14:54:28] <lpapp> ville: I cannot see it there
[14:54:29] <PJBoy> ofc I mean radix + count + maybe some other stuff hybrid
[14:54:34] <lpapp> the specialisation is not implemented, just declared
[14:54:37] <lpapp> as instantiation
[14:54:38] <rond_> urdh what about GTest way?
[14:54:47] <lpapp> but what I have in my code, if you check my testbed, is special implementation.
[14:54:59] <ville> lpapp: misread. thought you asked about the macro
[14:55:07] <urdh> rond_: I dunno, doesn't GTest have documentation?
[14:55:08] <ville> lpapp: it's implemented in the .cxx
[14:55:26] <ville> lpapp: lines 5-7 is the general case
[14:55:31] <Juliu> My favorite sorting algorithm is bogo-sort. It tries all possible ways to arrange the n input numbers until it finds the right one
[14:55:46] <PJBoy> I thought bogo did random permutations
[14:55:47] *** Quits: frost (~frost@user/frost) (Quit: Ping timeout (120 seconds))
[14:55:53] <PJBoy> giving it an infinite worst case complexity
[14:56:00] <fruitypunk> bogo-sort ^.^
[14:56:08] <rond_> found it, nevermind
[14:56:19] <Juliu> Does it? Then I mean something else
[14:56:41] <ville> lpapp: this way if anyone tries to instantiate the general template with out using a type you've explicitly instantiated for they will get a linker error
[14:56:49] <urdh> rond_, ASSERT_*
[14:57:04] *** Joins: frost (~frost@user/frost)
[14:57:04] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[14:57:15] <lpapp> ville: but this is not what I need
[14:57:25] <lpapp> in my case, I need specialisation of a template function
[14:57:32] <Juliu> Anyway, it sounds pretty efficient to me. I mean, how many different permutations can there be?
[14:57:36] <lpapp> not instantiation of a template function
[14:57:53] <rond_> urdh yep, found it
[14:58:15] <Juliu> I mean, for n=100 we don't get that many different permutations, only 100!
[14:58:19] <lpapp> ville: it also does not compile: C:\Users\laszlo.papp\Projects\testbed3\dso.cxx(6): error C2988: unrecognizable template declaration/definition
[14:58:48] <ville> lpapp: ah right, aa is not a template
[14:59:13] *** Quits: RoKenn (~RoKenn@user/rokenn) (Quit: NSA proxy service interrupted)
[14:59:14] <Juliu> lpapp, are you guys still trying to fix this template problem?
[14:59:23] <ville> lpapp: https://wandbox.org/permlink/9DA723zI1o5XrtLe
[14:59:27] <PJBoy> nah they're just chatting for fun at this point >_>
[14:59:36] <lpapp> ville: I fixed that locally
[14:59:37] <lpapp> it builds
[14:59:40] <lpapp> but again, not what I need.
[14:59:50] <lpapp> do you have any idea how to link what I need?
[15:00:18] <lpapp> Juliu: yes, templates and Windows visibilities are a hard problem :)
[15:00:53] <lpapp> maybe, Rust got it simpler, but in c++, we are stuck with this template system and visibility stuff, I guess.
[15:01:18] <Juliu> lpapp, what do you mean by Windows visibilities?
[15:01:29] <urdh> lpapp: I haven't been paying attention, what's the problem?
[15:01:43] <ville> lpapp: https://wandbox.org/permlink/L6lf4ydZqJv8qU5P ?
[15:02:04] <Juliu> lpapp, are you sure the problem is not something like having the implementation of the template methods in a .cpp file?
[15:02:08] <PJBoy> I imagine you'd want to declare your specialisation in the header too
[15:02:11] <lpapp> Juliu: __declspec(dllexport/import)
[15:02:22] <ville> lpapp: only change there is to switch from an explicit instantiation to an explicit specialiazation
[15:02:27] <lpapp> + the attrib visibility on non-windows :)
[15:02:43] <PJBoy> { S().f(0); } /* header */ struct S { template<typename T> void f(T); }; template<> void S::f<int>(int); /* src file */ template<> void S::f<int>(int) { BARK; }
[15:02:43] <geordi> S::f(T) [with T = int]
[15:02:45] <PJBoy> something like that
[15:02:59] <Juliu> lpapp, as I understand it, templates are include-only
[15:03:11] <lpapp> study it a bit more as they are not.
[15:03:30] <lpapp> while some templates libraries are header-only, this is of course not the only way offered by the standard for compilation-time reduction.
[15:03:34] *** Joins: gggp (~gggp@li870-78.members.linode.com)
[15:03:54] <Juliu> lpapp, if you make it not include-only, you will only be able to link it for certain template parameters, and using a different one will cause a linker error later on
[15:04:16] <lpapp> where did you get that info from? Because it is not like that
[15:04:29] <lpapp> the whole point of templates is that you can instantiate them with anything
[15:04:36] <lpapp> the instnatiation is just optimisation
[15:04:40] <lpapp> and specialisation is diversion from the template.
[15:05:02] <Juliu> lpapp, actually it is
[15:05:38] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:05:44] <lpapp> ville: that built.
[15:05:45] <urdh> lpapp: there's explicit and implicit instantiation
[15:05:53] <ville> lpapp: there you go then?
[15:05:54] <lpapp> urdh: yes
[15:06:01] <Juliu> lpapp, you can not write the implementation of a template class into a .cpp file without wondering later on why you get linker errors
[15:06:13] <lpapp> urdh: explicit is the compilation-time speedup.
[15:06:23] <lpapp> Juliu: we have just done it successfully again...
[15:06:35] <Juliu> lpapp, I doubt that, but good luck with that
[15:06:35] <lpapp> check the examples above to see how it works.
[15:06:50] <lpapp> you can doubt it as much as you like, but of course you can implement templates in source files fine :)
[15:07:12] <PJBoy> you can implement templates in source files if you list all the types you're willing to work with
[15:07:17] <PJBoy> and suffer linker errors for any other types
[15:07:33] <Juliu> And then the code is only compiled for certain template parameters, and if you use others later on, you will get linker errors
[15:07:35] <lpapp> ville: the problem appears when I remove declspec from the specialisation
[15:07:42] <lpapp> ville: so, the missing bit was that, I think.
[15:07:52] <Juliu> PJBoy, exactly
[15:07:53] <PJBoy> or you can implement templates in the header, and then your explicit instantiations are just a build time optimisation
[15:07:54] <lpapp> every explicit specialisation need to be declspec'd on Windows for proper visibility.
[15:08:11] <ville> lpapp: well don't remove it then
[15:08:21] <lpapp> ville: no, I have to actually add it in my project.
[15:08:37] <lpapp> is this explained somewhere in an authoritative way thought rather than coding empirically to make sure?
[15:08:40] <lpapp> though*
[15:08:54] <ville> lpapp: but it should be relatively quick to iterate over the combinations whre to stick the DSO_DECLSPEC and where not to with the testcase
[15:08:58] <Juliu> I implement templates in a .inl file and include this at the end of my header file (within the pragma)
[15:09:18] *** Joins: lh_cat (~lh_mouse@mingw-w64/developer/lhmouse)
[15:09:22] <lpapp> Juliu: PJBoy: honestly, you are wrong
[15:09:28] <PJBoy> that's not true
[15:09:34] <urdh> lpapp: they're not, though
[15:09:42] <Juliu> lpapp, sure, whatever you say
[15:09:45] <lpapp> check the examples above, of course, you can implement templates in the source, and of course you can instantiate them implicitly with any type.
[15:09:58] <PJBoy> I'll give you a trivial counter example
[15:09:59] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 264 seconds)
[15:10:02] *** Quits: rond_ (~rond_@2a02:a31a:a23c:f480:2fd7:e087:5546:a438) (Quit: Client closed)
[15:10:07] <lpapp> if you need an extra type, you just add it to the list
[15:10:09] <lpapp> not a big deal
[15:10:15] <lpapp> and it should be done anyway for compilation time speedup.
[15:10:16] <Juliu> lpapp, what list?
[15:10:29] <PJBoy> { f<void>(); } template<typename> void f(); /* definition is in the source file */
[15:10:29] <geordi> error: undefined reference to 'void f<void>()'
[15:10:34] <PJBoy> note that linker error
[15:10:49] <lpapp> of course a linker error with the source file!
[15:10:55] <lpapp> without*
[15:11:04] <PJBoy> { f<void>(); } template<typename> void f(); \\ template<typename> void f() { BARK; }
[15:11:05] <geordi> Same error.
[15:11:07] <PJBoy> there, I added the source file
[15:11:11] <Juliu> lpapp uses a list ... probably of types he later wants to use. That explains everything
[15:11:33] <lpapp> PJBoy: still wrong, where is the supported list?
[15:11:45] <lpapp> the example you gave makes no sense
[15:11:51] <PJBoy> lpapp, yeah I said you needed the list of types you want to support
[15:11:55] <lpapp> if you do not care about compilation time, just put them into the header
[15:11:57] <urdh> lpapp: if you have to *list all supported types*, you can't really claim the template is possible to instantiate with *any* type
[15:12:00] <Juliu> A supported list for templates, lol. Ruining the whole idea of templates
[15:12:04] <lpapp> if you do care, put them in the source, and list the types you want to use.
[15:12:23] <lpapp> huh?
[15:12:23] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[15:12:29] <lpapp> running the whole idea of templates?
[15:12:33] <lpapp> ABsolutely not.
[15:12:40] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[15:12:42] <lpapp> Templates are also for avoid code dupes.
[15:12:43] <PJBoy> I said precisely that if you want template definitions in a source file, you need explicit instantiations for all types you don't want linker errors for
[15:12:45] *** Quits: lh_mouse (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 260 seconds)
[15:12:55] <PJBoy> and that seems to be something you agree with
[15:12:55] <lpapp> PJBoy: so, what is the problem? I do not see.
[15:13:03] <Juliu> If I had 1 wish, it would be just one day at which lpapp is listening to people
[15:13:15] <PJBoy> and the other thing I said was that if you don't ever want linker errors, you would define the template in the header
[15:13:20] <PJBoy> which is obviously true
[15:13:22] <lpapp> no
[15:13:28] <lpapp> do not use a library with types it was not meant for
[15:13:38] <lpapp> it is like using a library with a function it is not meant to provide
[15:13:40] <lpapp> that is user error
[15:13:50] <PJBoy> yeah well
[15:13:52] <PJBoy> there you go
[15:13:57] <Juliu> How can you include infinitely many types in a list?
[15:14:01] *** Quits: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it) (Quit: Leaving.)
[15:14:09] <LordKalma> well, that's not user error if you're smart enough to SFINAE or =delete any others
[15:14:11] <lpapp> this is a generic user error
[15:14:20] <lpapp> "not knowing that the library is meant to provide, and I want to use it differently"
[15:14:24] <lpapp> it is not related to templates in particular.
[15:14:29] <PJBoy> so what I said was correct
[15:14:41] <PJBoy> you will get linker errors if you provide the wrong template parameter unless you provide the template in the header
[15:14:45] <lpapp> Juliu: Why would you always want to have infinitely many tpes?
[15:14:46] <lpapp> types
[15:14:49] <lpapp> that does not make sense
[15:14:50] <PJBoy> and what you're saying is "that's OK in my use case"
[15:15:02] <lpapp> Basically, you are debating whether C++ should remove some useful features :)
[15:15:07] <lpapp> which I definitely do not agree with
[15:15:08] *** paule32_ is now known as paule32
[15:15:16] <lpapp> and I did listen, and I do not agree with.
[15:15:18] <Juliu> lpapp, not always, but for certain templates it makes a lot of sense to allow any type, and not just some
[15:15:26] <lpapp> but you can launch personal insults that people do not listen if they do not agree.
[15:15:37] <lpapp> PJBoy: no
[15:15:40] <PJBoy> no what?
[15:15:56] <lpapp> PJBoy: what I am saying is what the C++ Standard offers is good because certain options are good for some people, certain options are good for other people.
[15:15:59] <lpapp> it is not about "me"
[15:16:04] <lpapp> You do realise it is a C++ feature :)
[15:16:21] <PJBoy> what are you talking about?
[15:16:37] <PJBoy> I'm talking about where templates need to be defined depending on how you want to use them
[15:16:40] <lpapp> implementing templates in the source file
[15:16:50] <lpapp> explicit instantiation, specialisation, all the cool stuff that you need in many use cases.
[15:16:57] <PJBoy> then can be defined in the source file if you explicitly instantiate all the types you care about in the header
[15:17:08] <lpapp> yes, but it has nothing to do with me
[15:17:10] <lpapp> it is a generic feature.
[15:17:12] <PJBoy> and you would incur linker errors if you tried to use the templates with any other types
[15:17:14] <lpapp> Please stay objective.
[15:17:31] <PJBoy> what do you mean?
[15:17:37] <PJBoy> I'm aware templates are a C++ feature
[15:17:43] <PJBoy> I don't understand what point you're trying to make out of that
[15:17:48] <Juliu> lpapp, what if your compiler simply does not compile the templates for all the types in your list, because it realizes that they are never used anywhere in your code?
[15:18:06] <lpapp> ville: thanks for all the help!
[15:18:33] <PJBoy> do you disagree that templates don't need explicit instantiations to be usable when you don't define the template in the header?
[15:18:39] <PJBoy> because I have countless counter examples
[15:18:40] <lpapp> PJBoy: I honestly think you should become objective and avoid getting personal
[15:18:43] <lpapp> this is not the first time
[15:18:47] <PJBoy> what have I said that's personal?
[15:18:52] <lpapp> "in your case"
[15:18:55] <urdh> Juliu: that's what the explicit instantiations are for ;)
[15:18:58] <lpapp> it is not my case, it is many's case.
[15:19:01] <lpapp> urdh: exactly
[15:19:08] <PJBoy> you interpreted that too literally
[15:19:17] <PJBoy> just because it's your case doesn't mean it's no one else's case
[15:19:19] <lpapp> you could have been less personal, surely.
[15:19:31] <Juliu> urdh, I know. That list. But still the compiler could be smart and realize that those types and hence this code is never used anywhere, and simply drop it
[15:19:42] <lpapp> Juliu: no, that is the whole point of this C++ feature
[15:19:57] <lpapp> you tell the compiler that it is instantiated once here.
[15:20:01] <Juliu> lpapp, the point is that the compiler has to be dumb? Good luck with that
[15:20:05] <urdh> that said, unconstrained template parameters really are the typical case and explicit instantiation is usually something you do to solve a specific problem, not the default solution
[15:20:11] <lpapp> Not sure what is dumb about it.
[15:20:19] <PJBoy> my point is that "consumers" of a header containing a template declaration need to know the definition of the specialisation of that template whenever it's used
[15:20:29] <Juliu> lpapp, creating code that is never used anywhere is pretty dumb I would say
[15:20:31] <urdh> Juliu: it's not allowed to do that with explicit instantiations
[15:20:50] <PJBoy> either by including the template definition in the header, or by using explicit instantiations and deferring the template definition to a source file, thereby limiting what types can be used with that template
[15:20:51] <Juliu> urdh, that might be true. I am not sure how much the compiler is allowed to optimize
[15:20:51] <urdh> Juliu: granted, the linker might do that but at that point who cares
[15:20:54] <lpapp> Juliu: so a library offers a class Foo
[15:21:01] <lpapp> many users of the library does not use that particular class
[15:21:07] <lpapp> so, the library is dumb, and also the compiler?
[15:21:11] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:21:27] *** Quits: proller (~p@2002:50f0:d845:10:41a5:ca2e:e623:f4b4) (Ping timeout: 260 seconds)
[15:21:48] <Juliu> lpapp, depends if it's a library with early or with late binding
[15:21:57] <lpapp> no, just no.
[15:22:00] <lpapp> This is what libraries do
[15:22:03] <Juliu> Actually yes
[15:22:11] <lpapp> it is very unlikely that an app uses all symbols from a library.
[15:22:27] <urdh> the compiler is pretty limited in terms of what it's allowed to just remove, until you get to linking the full application (and at that point the linker is doing the work)
[15:22:34] <Juliu> Yes, that might be the case for libraries, but how is the compiler able to tell if it's a library or just normal code?
[15:22:43] <urdh> it can pretty much only eliminate unused things with internal linkage
[15:22:45] <lpapp> urdh: yes, exactly, that is the time to remove stuff if needed at all, usually not even eneded.
[15:22:48] <lpapp> needed*
[15:22:49] *** Joins: Leone (~Leo@45.72.233.136)
[15:22:53] <Juliu> urdh, indeed
[15:23:10] *** Quits: segnior (segnior@user/segnior) (Ping timeout: 260 seconds)
[15:23:16] <Juliu> urdh, so you had to tell it that all those classes in lpapp's list are meant to be for external use
[15:23:52] <lpapp> ville: I think it still makes sense to question whether specialisation makes sense here.
[15:24:12] <lpapp> ville: instead of regular overrides, but I guess it keeps the public header slightly cleaner.
[15:24:17] <lpapp> overloads*
[15:24:19] <PJBoy> for the case of a function template, specialisation is always a little questionable
[15:24:26] <urdh> Juliu: not really, explicit instantiation doesn't really affect linkage IIRC
[15:24:33] <PJBoy> you could always provide overloads that just invoke a function template
[15:24:40] <ville> lpapp: yes there are other options but at least that thing works now
[15:24:54] <lpapp> PJBoy: you are overlooking one thing
[15:24:59] <urdh> Juliu: what it tells the compiler is pretty much what any declaration does; "there's a definition for this somewhere, I promise"
[15:25:29] <PJBoy> lpapp, possible, what is it?
[15:25:37] <lpapp> PJBoy: what I have just said above
[15:25:45] <Juliu> urdh, I am not sure if the compiler is dumb enough to compile things that are not used anywhere
[15:25:48] <PJBoy> your idea of cleanness
[15:26:01] <PJBoy> I mean I'm not gonna argue coding style
[15:26:10] <PJBoy> but it would simplify things a little
[15:26:10] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[15:26:11] <lpapp> template is coding style :)
[15:26:14] <lpapp> you can dupe yourself
[15:26:16] <urdh> Juliu: it has to, if they don't have internal linkage
[15:26:32] <urdh> it's not a question of how clever the compiler is
[15:26:39] <PJBoy> by providing a template, you're allowing the user to use it with the wrong template parameters
[15:27:01] <lpapp> PJBoy: I do not.
[15:27:06] <PJBoy> by providing overloads, it requires more declarations, sure, but no chance of invoking template errors from the user
[15:27:16] <lpapp> and it is also true for overloads
[15:27:23] <lpapp> they can still call overloads that do not exist anyway
[15:27:29] <PJBoy> you can get overload resolution failure, yeah
[15:27:44] <PJBoy> but those occur at compile time
[15:27:50] <urdh> lpapp: I dunno, compile-time errors seem better than link-time errors
[15:27:53] <urdh> but w/e
[15:27:55] <PJBoy> so I consider them nicer than the linker errors you get from using the template wrong
[15:27:59] <lpapp> ville: yes, thanks, do we have an authoritative source on the behaviour of this?
[15:28:14] <PJBoy> although you do have the possibility of using static_assert in your template
[15:28:20] <lpapp> ville: but logically, I think it makes sense to export these, otherwise they would not be seen
[15:28:27] <lpapp> ville: so, maybe, never mind
[15:29:03] <lpapp> urdh: that is purely the matter of taste, I would say.
[15:29:22] <PJBoy> I'd say compile time errors are objectively better
[15:29:29] <lpapp> no?
[15:29:36] *** Joins: segnior (segnior@user/segnior)
[15:29:37] <PJBoy> better to fail early than late
[15:29:39] <Juliu> urdh, how does the compiler know something does have external linkage if you don't tell it?
[15:29:46] <PJBoy> also allows you to SFINAE on that function call
[15:29:48] <urdh> lpapp: this describes how declspec works for templates https://docs.microsoft.com/en-us/cpp/cpp/general-rules-and-limitations?view=msvc-160
[15:29:54] <PJBoy> those are two objective benefits
[15:30:10] *** Joins: horribleprogram (~user@2607:fea8:7040:830:f964:952e:6e13:b83b)
[15:30:15] <lpapp> urdh: thanks, after all, it comes down to general declspec'ing, I think
[15:30:23] <urdh> lpapp: yeah I'm with PJBoy I can't see how you would argue link-time errors are not objectively worse than compile-time ones
[15:30:26] <lpapp> once you have a specialisation, it is no longer the concept of a template, I think
[15:30:36] <lpapp> eventually, it is just a regular method from that point on as far as the linker is concerned.
[15:30:54] <lpapp> that is purely subjective
[15:30:56] <lpapp> nothing technical
[15:31:09] <lpapp> Actually, you will get the failure in the same build process.
[15:31:21] <lpapp> so, there is not much difference really, other than I like orange better than apple.
[15:31:26] <Juliu> PJBoy, I would agree since I HATE solving linker problems
[15:32:07] <PJBoy> you don't seem to understand that a function overload resolution failure occurs at compile time
[15:32:17] <lpapp> besides, it *should* be possible to have a generic implementation, too.
[15:32:25] <lpapp> with implicit instantiation.
[15:32:27] <PJBoy> a template cannot provide that functionality
[15:32:29] <Juliu> lpapp, are you sure you told the compiler for every instance of your template class that it's meant for external usage?
[15:32:40] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[15:32:53] <PJBoy> (I mean it can via static_assert or via concept constraint)
[15:32:54] <lpapp> PJBoy: really, after 15 years, I do not?
[15:33:04] <lpapp> Actually, you do not seem to understand that I do not compile and link separately.
[15:33:12] <lpapp> I call cmake --build ., that is it
[15:33:18] <lpapp> and most people do the same in my experience
[15:33:31] <PJBoy> > using your experience as an argument
[15:33:35] <PJBoy> what happened to objectivity
[15:33:36] <urdh> ...and what cmake does is to compile first, then link
[15:33:40] <lpapp> so, it is all one process as far as I am concerned - in other words, I will see the issue at the same time when I look at the build result.
[15:33:45] <urdh> by calling different executables doing different things
[15:33:46] <Juliu> lpapp, it still compiles first and then links later
[15:33:54] <lpapp> it does not matter
[15:33:59] <lpapp> build process failed: I see an erropr
[15:34:06] <PJBoy> failing early > failing late
[15:34:07] <lpapp> does not really matter whether it is build or compilation time, that is red-herring.
[15:34:14] <urdh> and if you're paying attention, the quality of the error messages are vastly different
[15:34:25] <PJBoy> you've already argued that build time matters to you
[15:34:26] <urdh> because the compiler simply has more contextual information
[15:34:31] <lpapp> urdh: maybe for you.
[15:34:40] <lpapp> I see no issues myself.
[15:34:46] <lpapp> I would also like to close the discussion about this with me.
[15:34:49] <lpapp> Since it is purely stylistic.
[15:34:52] <lpapp> and personal preference.
[15:34:56] <PJBoy> nah you're wrong
[15:35:05] <lpapp> and the most pressing thing to discuss is that you *should* be able to have a generic implementation
[15:35:09] <lpapp> that is the whole point of template function
[15:35:14] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:35:16] <urdh> I mean sure you clearly prefer linker errors, that's personal preference
[15:35:16] <lpapp> you have a generic implementation, which you can override if you want.
[15:35:41] <urdh> but you really can't chalk that up to a purely "stylistic" choice
[15:35:48] <lpapp> specialisation should be an opt out, not exclusive.
[15:35:53] <Juliu> lpapp, every .cpp file is compiled individually. You know that, right?
[15:35:54] <lpapp> so, really, I honestly do not see the issue.
[15:36:11] <lpapp> urdh: not against strongly opinionated people, no.
[15:36:24] <urdh> it's like saying the choice between walking normally and crawling to work is "purely stylistic"
[15:36:33] <lpapp> and like I said, you are focusing on the wrong thing
[15:36:33] <urdh> like, sure, both ways will get you there
[15:36:43] <lpapp> if you define a generic implementation and have specialisations, you are just fine
[15:36:44] <urdh> but one of them is objectively better
[15:36:51] <lpapp> your point about linker becomes totally moot.
[15:36:58] <PJBoy> are users allowed to use the generic implementation?
[15:37:04] <PJBoy> if so then it needs to be provided in the header
[15:37:09] <lpapp> yes, what is wrong with that man
[15:37:17] *** Quits: ShiftyLogic (~shiftylog@66.115.146.16) (Ping timeout: 264 seconds)
[15:37:20] <lpapp> the whole linker discussion is a big unproductive redherring
[15:37:27] <lpapp> if you want to provide generic implementation, provide it in the header
[15:37:36] <lpapp> and you provide what needs optimisation and/or customisation in the source
[15:37:49] <lpapp> I *honestly* see no issues, or any red-herrings about linker/compiler.
[15:38:02] <PJBoy> ok we're agreed on that point
[15:38:07] <PJBoy> I'm happy
[15:38:20] <Juliu> Are we talking about just 1 class? If so, just a single method implemented in a source file will make it non-generic
[15:38:45] <PJBoy> if you didn't need the generic implementation, then the function overloads would have been a valid alternative approach
[15:39:04] <PJBoy> and I thought you didn't need the generic implementation, because you said using unsupported types was a user error
[15:39:15] <PJBoy> and me being me, I don't like allowing user errors when I don't have to
[15:39:15] <lpapp> PJBoy: I do not, but if you want, you can have it
[15:39:19] <lpapp> I honestly do not see the problem
[15:39:25] <lpapp> c++ gives you all the flexibility
[15:39:26] <urdh> (and even if you do need the generic one, overloads are generally preferable to function template specialization)
[15:39:38] <lpapp> there is really no need to waste time on compiler/linker discussions.
[15:39:53] <PJBoy> yeah fine
[15:39:55] <lpapp> you can prefer them as much as you like
[15:40:06] <Juliu> I don't understand what lpapp wants or if he even knows what he wants
[15:40:14] <lpapp> but you can be a bit more open-minded and respectful to other people having different stylistic preferences.
[15:40:14] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[15:40:35] <PJBoy> I think you need to be more open minded about the objective benefits of function overloads compared to templates
[15:40:38] <lpapp> Juliu: yes, you are indeed lost
[15:40:45] <lpapp> there is no issues that you mention with templates at all
[15:40:53] <Juliu> lpapp, I think we all think that you are the one who is lost
[15:40:55] <lpapp> you can implement whatever you want in the source and for generic stuff, in the header.
[15:41:02] <PJBoy> I mean I'm with you, I don't care about this discussion anymore
[15:41:25] <PJBoy> but I'm not stubbornly rejecting the idea that templates are as good as function overloads here
[15:41:45] <PJBoy> you seem to be stubbornly rejecting the idea that function overloads may be better than templates
[15:42:01] <Juliu> Templates are more generic
[15:42:07] <PJBoy> but I've made my case, if we don't agree then whatever
[15:42:12] <PJBoy> we don't need to drag this out
[15:42:34] <lpapp> You must be bored to force others to have your style preferences.
[15:42:55] <PJBoy> recall my message about not caring
[15:43:28] <PJBoy> and recall your message about not wanting to talk about this anymore
[15:44:17] <Juliu> PJBoy, he was like that in #algorithm as well. Never listening, always wanting to just be right
[15:44:58] <lpapp> Juliu: hmm, odd claim, after others corrected you about hash map there, but happy to provide logs.
[15:45:07] <PJBoy> yeah I mean you're guilty of that too
[15:45:24] <Juliu> lpapp, no one corrected me since I was correct
[15:45:26] <lpapp> let me dig the hash discussions :)
[15:46:16] <Juliu> PJBoy, I'm stubborn, I know. But I can admit a mistake, and I try to listen to how people justify their opinion. And you were the one who was incorrect about hardness and complexity classes, not me :P
[15:46:33] <PJBoy> yeah I admit incorrectness
[15:46:37] <urdh> lol, "I going to badmouth you by pulling logs from earlier" is not a good look
[15:46:45] <urdh> leave well enough alone lpapp
[15:46:46] *** Quits: markong (~kvirc@213.146.188.203) (Ping timeout: 245 seconds)
[15:47:09] <lpapp> urdh: please stop this vibe.
[15:47:17] <Juliu> I just got tricked by urdh since of course x in O(1) also means x in O(n)
[15:47:24] *** pah is now known as pa
[15:47:30] <urdh> Juliu: uh, what?
[15:47:30] <lpapp> urdh: just because you cannot force your personal preference on every single developer, no need to become personal.
[15:47:58] <urdh> lpapp: you're brining the bad vibes, man
[15:48:07] <Juliu> urdh, was that not you who said inserting into a hash-map was in O(n) ?
[15:48:14] <urdh> I haven't tried to force any personal preference on anyone in this channel and you know it
[15:48:23] <PJBoy> Juliu, lets not bring up old shit
[15:48:29] <lpapp> urdh: you literally spent a long time to force something on someone who said multiple times it is your personal preference, but not one's.
[15:48:46] <Juliu> PJBoy, I'm just saying that I said something incorrect there at first, but then corrected myself
[15:48:48] <lpapp> please get more productive, this is really not great, it is ok for your personal preference to suck for others, or mine.
[15:48:55] <PJBoy> Juliu, ok fair enough
[15:49:07] <urdh> Juliu: very much not
[15:49:16] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[15:49:16] <Juliu> PJBoy, I mean about this O(n) inserting. Not about your understanding of complecity classes
[15:49:22] <PJBoy> I know
[15:49:33] <Juliu> urdh, oh. Then it was someone else with a short name
[15:49:42] <PJBoy> I'm glad I learnt something about complexity classes
[15:49:44] <Juliu> I'm bad with names
[15:50:26] <PJBoy> anyways
[15:50:37] <PJBoy> where are we with the declspec problem
[15:50:44] <Juliu> PJBoy, well, actually the wiki article would have continued with talking about certain types of reductions, so you have not been wrong entirely. So read the whole block and not just what I quoted ;)
[15:50:57] <urdh> lpapp: I didn't spend any time forcing anyone to do anything; I spent some time trying to argue that the trade-off between linker errors and compiler errors is not purely subjective
[15:51:05] <lpapp> urdh: stop. Please.
[15:51:12] <lpapp> I beg you.
[15:51:32] <PJBoy> my understanding currently is that you have a template function that only needs to require a few known types, the generic implementation does not need to be available to users
[15:51:45] <Juliu> PJBoy, and O(n) is not a complexity class. O(n) time (for deterministic turing machines) is, and I meant that
[15:51:51] <PJBoy> so you're declaring the template and some explicit instantiations, and you're defining those things in a source file
[15:51:58] <PJBoy> and the struggle is where to put the declspecs
[15:52:04] <PJBoy> does that sound right?
[15:52:24] <lpapp> PJBoy: Please stop. We already solved it.
[15:52:34] <PJBoy> yeah?
[15:52:46] <PJBoy> ok so we actually have nothing productive to discuss
[15:53:04] * PJBoy marks the chat as resolved
[15:53:23] <Juliu> My program still ends without any error message sometimes :/
[15:53:33] * lpapp marks the chat as religious discussion that every participant should reflect on
[15:53:41] <urdh> wow'
[15:53:49] <PJBoy> !give lpapp religion
[15:53:50] <nolyc> lpapp: #C++ is a secular channel. This means that the following topics, among others, may not be debated: emacs/vim, Linux/Mac/Windows/BSD, Qt/*, open/closed source. Matters directly related to standard C++ (including style) are ok as long as they are intellectual.
[15:54:14] <lpapp> ah, ok, so the secure channel rules were even violated
[15:54:14] <lpapp> nice
[15:54:16] <Juliu> Maybe the large unordered_map I use is not the problem, but the tiny allocation of something else that follows it!? Damn
[15:54:34] <PJBoy> technically this is #c++-general, so it doesn't apply
[15:54:34] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[15:54:41] <PJBoy> but thought it might make you chuckle
[15:55:55] <lpapp> do not think I could chuckle after a painful discussion.
[15:55:55] <Juliu> PJBoy, I thought coding choices were religion
[15:56:15] <PJBoy> ...
[15:56:20] <PJBoy> go eat some chocolate or something idk
[15:56:29] <Juliu> lpapp, the discussion would be less painful for everyone if you listened more
[15:56:43] <lpapp> I listened too much to nonsense, sadly.
[15:56:47] <lpapp> I will have to listen a lot less.
[15:56:59] <PJBoy> why so emotional?
[15:57:05] *** Quits: pa (~pah@user/pah) (Ping timeout: 260 seconds)
[15:57:07] <PJBoy> this has been a largely technical discussion
[15:57:28] <PJBoy> I mean there's been confusion, sure
[15:57:42] <lpapp> I do not have these painful discussions in my job or other circles
[15:57:50] *** Joins: pah (~pah@user/pah)
[15:57:54] <PJBoy> cool story bro
[15:57:56] <urdh> maybe people avoid them for some reason
[15:58:10] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[15:58:34] <PJBoy> I'd reflect on where this exasperation has come from
[15:58:48] <PJBoy> I feel like it started when I attacked geeks4geeks
[15:59:04] <PJBoy> which is easily one of the worst websites on the internet
[15:59:28] <lpapp> well, my shoutout goes to ville, he remained the most professional.
[15:59:29] <lpapp> and helpful.
[15:59:50] <PJBoy> yeah he asked you to make a testcase and you refused, so he made one *for* you
[15:59:59] <PJBoy> I'd be appreciative of that too
[16:00:11] <lpapp> you can get personal again since it seems to be your style.
[16:00:14] <PJBoy> hell you even got him to use wandbox
[16:00:20] <PJBoy> that's no easy feat
[16:00:32] <lpapp> but yeah, I could not make a test case for this myself within a short amount of time, do not think you should offend me for that, though.
[16:00:44] <PJBoy> I don't mean to offend you
[16:00:45] <lpapp> (or anyone else)
[16:00:49] <PJBoy> I've never meant to offend you
[16:01:06] <PJBoy> so yeah I'll happily continue to talk about how you should have been able to make that test case yourself
[16:01:25] <PJBoy> you come here asking for help and putting the bare minimum of effort into it
[16:01:35] <lpapp> do you mean the unproductive suggestion about visual studio for cross-platform?
[16:01:42] <lpapp> or the previous personal attacks?
[16:01:59] <lpapp> (even after asking multiple times to stop those)
[16:02:14] <PJBoy> I stand by that using visual studio would have helped you diagnose the declspec issue
[16:02:23] *** Parts: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) ()
[16:02:25] <PJBoy> being that it's a windows specific issue and that visual studio makes it trivial to set up a DLL library
[16:02:33] <PJBoy> I don't see how that's unproductive
[16:02:35] <urdh> holy crap, the dissonance
[16:02:53] <PJBoy> and the personal attack you're claiming on me was that Ronalds comment
[16:02:58] <PJBoy> which I took back immediately after
[16:03:04] <PJBoy> and was frankly more of an attack on Ronalds
[16:03:06] <PJBoy> who you don't even know
[16:03:18] <Juliu> PJBoy, really? I have such painful discussions all the time, since most people never listen
[16:03:18] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[16:03:21] <PJBoy> so let it go
[16:03:32] <urdh> i don't even know where to start but I can easliy imagine why this person doesn't have these kinds of discussions in real life
[16:03:40] <PJBoy> oh they left
[16:04:13] <PJBoy> yeah I know several other people that get defensive like that
[16:04:21] <urdh> namely, people avoid them because having these one-sided discussions filled with mischaracterizations and victim complexes is not very fun for the counterparty either
[16:04:37] *** Joins: paul424 (~tom@ip-31-0-126-125.multi.internet.cyfrowypolsat.pl)
[16:04:59] <urdh> (have fun pulling those logs later)
[16:05:08] <PJBoy> I kiiinda get it?
[16:05:17] <PJBoy> 'cause I used to be insanely defensive too when I was a teen
[16:05:41] <PJBoy> I got over it when my brother called me out on it hardcore
[16:05:55] <PJBoy> idk how to deal with it when it comes to other people
[16:06:23] <Juliu> My mother is still like that and she's over 70. Typical inferiority complex, I'd say
[16:07:05] *** Quits: alsolionkor (~lion@beammp/staff/lionkor) (Ping timeout: 268 seconds)
[16:07:37] <PJBoy> tell her that geeks4geeks is an internet cesspool
[16:07:44] <Juliu> Lol
[16:07:47] <PJBoy> I wanna know if she considers it a personal attack
[16:08:42] <Juliu> She would be like lpapp and say that it has to be O(n^2) if they say so
[16:08:42] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[16:09:53] <PJBoy> argh
[16:10:01] <PJBoy> that website hurts me
[16:10:07] <Juliu> In #algorithms he even had arguments like that the "experts" at google and facebook would say so, so it has to be like they say. The fact that he simply could have misunderstood them or that they were talking colloquially did not come to his mind
[16:10:20] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 246 seconds)
[16:10:21] *** Quits: gggp (~gggp@li870-78.members.linode.com) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[16:10:41] <paul424> naah back to my issue of hashing the position of two tiles of (x,y) pair. Now I do use the cantor pariing as this post on stackoverlow advised : https://stackoverflow.com/questions/682438/hash-function-providing-unique-uint-from-an-integer-coordinate-pair?noredirect=1&lq=1   Cantor's enumeration of pairs   n = ((x + y)*(x + y + 1)/2) + y
[16:10:43] <PJBoy> I liked his statement on being a 15 year experienced developer
[16:10:51] <PJBoy> and yet doesn't understand templates
[16:10:58] <Juliu> PJBoy, it's a blog where everyone can answer. What do you expect? It's probably still helpful for most people
[16:11:20] <paul424> I can STILL see repeatable patterns ! Is somethign wrong with the hash function or my perception ?
[16:11:25] <rpav> PJBoy: when you're 15 and have been doing something as long as you can remember, you seem experienced to you ;)
[16:11:35] <PJBoy> ahaha
[16:12:19] *** Quits: pah (~pah@user/pah) (Ping timeout: 260 seconds)
[16:12:29] <rpav> and to be fair it's something; what's kinda sad is when you get the college grad who's only been doing stuff since like their 2nd or 3rd year
[16:12:34] *** Joins: pah_ (~pah@host-87-3-64-32.retail.telecomitalia.it)
[16:13:30] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[16:14:32] <PJBoy> Juliu, I consider it to be the opposite of help
[16:14:42] <PJBoy> it's a distraction from literally any other resource
[16:15:37] <PJBoy> a misinforming distraction
[16:15:48] <PJBoy> hell, geeks4geeks might well have caused this guy's mental disorder
[16:16:01] *** Joins: proller (~p@2a02:6b8:0:40c:3fe5:78f3:414f:9acc)
[16:16:31] <Juliu> paul424, simply use    struct PairHash { template<class T1, class T2> std::size_t operator()( const pair<T1, T2> &pair ) const { return std::hash<T1>()( pair.first ) ^ std::hash<T2>()( p.second ); }; };    as the custom hash class for your std::unordered_set/_map
[16:16:55] <Juliu> * "std::pair"
[16:16:58] <PJBoy> that has the problem of the hashing being zero for all pair.first == pair.second
[16:17:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[16:17:24] <Juliu> PJBoy, I don't know, I can't remember if I have ever been there
[16:17:33] <rpav> steal boost's hash combiner
[16:17:37] <rpav> it's like 1loc
[16:17:37] <PJBoy> ^
[16:18:08] <rpav> it should also be in std because it's so damn useful, but
[16:18:16] *** Joins: whupdup (~whupdup@pool-173-76-128-81.bstnma.fios.verizon.net)
[16:18:24] <paul424> why everythings so complicated , can't we boil h where n =h(x,y) to some simple formula
[16:18:54] <PJBoy> it's been proposed
[16:19:00] <PJBoy> [p1406]
[16:19:00] <npaperbot> P1406R1: [LEWGI, Library Evolution, Library] Add more std::hash specializations <https://wg21.link/p1406r1> (by Alexander Zaitsev, Antony Polukhin) (2019-06-14) (Related: https://wg21.link/p1406r1/github)
[16:19:04] <urdh> paul424: what do you mean "repeatable patterns"? and what's the range of your input and the size of your output type?
[16:19:22] <Juliu> PJBoy, how about   hash(first) ^ hash(first^second)   ?
[16:19:25] <rpav> seed ^= hash_value(v) + 0x9e3779b9 + (seed << 6) + (seed >> 2);
[16:19:40] <rpav> https://www.boost.org/doc/libs/1_55_0/doc/html/hash/reference.html#boost.hash_combine <- the document seems to be way more annoying to find that now, but
[16:19:48] <paul424> oki ... urdh I will send a link size of an input is : 0...400 x 0...400 ( size of the map )
[16:20:17] <Juliu> The more hash-functions you provide in the standard, the more beginners will use them and think that hashing is a tool to magically solve all problems
[16:20:33] <paul424> and the output should be one of 8 values ... { 0,1,2,3,4,...7} each representing a diffrent tile outlook
[16:20:34] <PJBoy> that's better, but I couldn't possibly speak on its quality
[16:20:49] <PJBoy> > CONSENSUS: We will not pursue P1406 (Add more std::hash specializations
[16:20:50] <Juliu> PJBoy, me neither, I'm just making shit up as I go
[16:20:53] <PJBoy> oh well never mind then
[16:20:58] <PJBoy> wtf happened
[16:20:58] <rpav> dunno, it works well enough but i never bothered to pull apart what the magic value did .. it looks sortof symmetric though so
[16:21:36] <Juliu> Simply use a std::map instead of a std::unordered_map ;)
[16:21:41] <rpav> "more std::hash specializations" is silly, since hash_combine can easily make _making_ those easier ;P
[16:21:50] <rpav> e.g. what if you need to hash a struct
[16:21:54] <PJBoy> notably it provided a hash specialisation for pair and struct
[16:22:00] <PJBoy> pair and tuple, sorry
[16:22:00] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[16:22:10] <PJBoy> so you'd just use that
[16:22:13] <rpav> every member has a provided std::hash but you need to hash _those_ .. and writing good hashing functions is nontrivial
[16:22:20] <urdh> paul424: that doesn't sound like a hash at all though
[16:22:22] <rpav> oh
[16:22:27] <rpav> 🤔
[16:22:46] <rpav> if tuple has a hash specialization, that's _essentially_ a hash combiner right there
[16:22:50] <PJBoy> exactly
[16:22:55] <PJBoy> and it cited boost.hash
[16:23:05] <PJBoy> so it was clearly an attempt to standardise boost hash combine
[16:23:13] <Juliu> I would never include boost just to use a single function
[16:23:22] <rpav> sure .. but tuple is a great way to do this so problem solved
[16:23:30] <PJBoy> yeah 100%
[16:23:39] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[16:23:40] <paul424> urdh, no, it does .... I want a random face of a tile to appear in x,y position
[16:23:42] <Juliu> I hate hashing
[16:23:42] <PJBoy> I can't believe they didn't want to go through with it
[16:24:09] <lpapp> ville: do you know why I have to declspec the specialisation if the class in which it occurrs is already declspec'd? E.g. this is not required for other methods.
[16:24:39] <Juliu> paul424, hash( y * (max_x + 1) + x )
[16:24:44] *** Quits: Spirit532 (~Spirit532@mm-112-217-122-178.mgts.dynamic.pppoe.byfly.by) (Killed (NickServ (GHOST command used by Spirit5321!~Spirit532@37.45.255.70)))
[16:24:45] *** Joins: Spirit532 (~Spirit532@37.45.255.70)
[16:25:04] <ville> lpapp: template-ness?
[16:25:09] <paul424> Juliu, where hash is .... :D
[16:25:18] <PJBoy> the base template isn't aware of its specialisations
[16:25:37] <Juliu> paul424, maybe something like std::hash(x) % 8 ?
[16:25:45] <PJBoy> I guess the specialisations could theoretically inherit the declspec
[16:25:50] <paul424> Juliu, yes I do that all the time
[16:25:57] <Juliu> Where x is y * (max_x + 1) + x. Damn, I shouldn't have called it x
[16:25:59] <lpapp> ville: how do you mean?
[16:26:05] <paul424> I just need ... hmm there is a std::hash wait
[16:26:08] <Juliu> paul424, and?
[16:26:21] <rpav> better is std::hash(std::tuple(x, y, ...))
[16:26:33] <paul424> wait :D I type
[16:26:42] <ville> lpapp: the other member functions you've probably aren't function templates
[16:26:50] <urdh> paul424: i don't understand, what does that have to do with hashing?
[16:26:51] <Juliu> paul424, why don't you just use rand() & 8 ?
[16:26:55] <Juliu> I mean % 8
[16:27:15] <urdh> (or uniform_int
[16:27:18] <lpapp> ville: sure, but why would a special template function be an exception from the rule of make everything visible in this class if the class is marked as visible?
[16:27:24] <urdh> argh, fatfingering
[16:27:37] <urdh> uniform_int_distribution is what I meant to type
[16:27:37] <Juliu> What's uniform_int ?
[16:27:40] <ville> lpapp: no idea. don't deal with windows directly
[16:27:48] <lpapp> sounds like a bug to me.
[16:27:51] <urdh> Juliu: https://en.cppreference.com/w/cpp/numeric/random/uniform_int_distribution
[16:27:56] <Juliu> urdh, is that part of the "new" random standard library?
[16:27:58] <rpav> er, wait the syntax is of course more complicated, how do direct calls work again
[16:28:01] <lpapp> We have a workaround luckily, but I would like to understand why it is even required.
[16:28:18] <urdh> Juliu: the C++11 one, yes
[16:28:41] <Juliu> urdh, yeah, I should check out the "new" standard things C++ provides. I've been too lazy for doing it for random generators so far
[16:29:54] <PJBoy> !geordirandom
[16:29:55] <nolyc> { default_random_engine e(time(0)); uniform_int_distribution<> u(10, 30); for(int i = 0; i != 20; ++i) cout << u(e) << ' '; }
[16:29:56] <geordi> 12 11 29 13 30 19 30 23 16 26 23 14 14 16 27 17 14 30 23 10
[16:30:39] <PJBoy> ...generally used with a better seed than time(0)
[16:30:48] <PJBoy> usually random_device()()
[16:30:58] <paul424> Juliu, sure for that's for game and I want those tile faces to be repeatable in time .... I can use rand() if that guarantees the outcome would be the same each time hmm
[16:31:15] <Raziel> old rand() is quite bad to extremely shit, depending on implementation
[16:31:21] <Raziel> so yes, new std::random is a good idea
[16:31:24] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[16:31:29] *** Joins: gggpkm (~gggpkm@60.10.194.46)
[16:31:30] <Juliu> paul424, call srand(0) first
[16:31:37] *** Quits: gggpkm (~gggpkm@60.10.194.46) (Read error: Connection reset by peer)
[16:32:01] <paul424> Juliu, oki , let's suppress this discussion cause I need to go for the bus
[16:32:04] *** Joins: gggpkm (~gggpkm@60.10.194.46)
[16:32:05] <PJBoy> !randrangehint
[16:32:06] <nolyc> geordi { srand(40703218); string s("Use "); int lower = 'a', upper = 'a'+26; for(unsigned i = 0; i < 5; ++i) s += rand() % (upper - lower) + lower; cout << s; }
[16:32:07] <geordi> Use boost
[16:32:09] <paul424> sorry , bye all :)
[16:32:25] <Juliu> paul424, listen to what the other people in here said and use the new random generators C++11 provides
[16:32:36] <urdh> PJBoy: lol that's neat
[16:32:36] <paul424> oki will keep that in mind
[16:32:49] *** Quits: gggpkm (~gggpkm@60.10.194.46) (Max SendQ exceeded)
[16:32:59] <Juliu> nolyc, lol
[16:33:00] <nolyc> Land O' Lakes Tourist Association is a four-season destination for fun, relaxation, outdoor activities and adventure.
[16:33:18] *** Joins: gggpkm (~gggpkm@60.10.194.46)
[16:33:28] <rpav> PJBoy: i'm not actually seeing a tuple specialization for hash
[16:33:38] <PJBoy> it was part of the proposal
[16:33:41] <PJBoy> that got rejected
[16:33:46] *** pah_ is now known as pa
[16:33:50] <rpav> oh ... well then definitely _not_ solved
[16:34:09] <PJBoy> which I'm kinda pissed about
[16:34:09] *** Quits: pa (~pah@host-87-3-64-32.retail.telecomitalia.it) (Changing host)
[16:34:09] *** Joins: pa (~pah@user/pah)
[16:34:21] <PJBoy> how do we have a standard library with the 2nd bessel function thing
[16:34:26] <PJBoy> and not hash(tuple)
[16:34:27] *** Joins: gggpkm_ (~gggpkm@60.10.194.46)
[16:34:55] <PJBoy> <Asuka> pathetic
[16:35:03] <Juliu> PJBoy, I agree. But as I meantioned there is the risk that people start hashing everything
[16:35:14] <PJBoy> that's not a risk
[16:35:19] *** Quits: gggpkm_ (~gggpkm@60.10.194.46) (Remote host closed the connection)
[16:35:23] <Juliu> PJBoy, indeed, it's a disease
[16:35:27] <paul424> I will use some random generators , bye :) !
[16:35:36] *** Quits: paul424 (~tom@ip-31-0-126-125.multi.internet.cyfrowypolsat.pl) (Remote host closed the connection)
[16:35:37] <PJBoy> lets keep our stylistic choices to ourselves, ok?
[16:35:38] <Juliu> paul424, good luck. Bye
[16:35:43] *** Joins: gggpkm_ (~gggpkm@60.10.194.46)
[16:37:55] <Juliu> I still think   hash(first) ^ hash(first^second)   might be a good choice for a pair, since first^second is the bit-wise difference of first and second
[16:38:08] *** Quits: gggpkm (~gggpkm@60.10.194.46) (Ping timeout: 268 seconds)
[16:38:47] <urdh> what about my std::pair<std::string, std::size_t>, then, huh?
[16:39:32] <Juliu> Fine, fine.     hash(hash(first)) ^ hash(hash(first) ^ hash(second))    then
[16:41:02] *** Joins: kn07_ (~kn07_@86.121.23.168)
[16:42:12] <PJBoy> would still opt for boost
[16:42:27] <Juliu> How does boost do it?
[16:42:28] <PJBoy> or something that does what boost does that isn't boost
[16:42:41] <PJBoy> it does some calculation that I don't understand
[16:42:46] <Juliu> I hate including more and more dependencies just for tiny things
[16:42:59] <PJBoy> that's based on actual research
[16:43:23] <Juliu> Is there unactual research?
[16:44:06] <PJBoy> https://www.boost.org/doc/libs/1_64_0/boost/functional/hash/hash.hpp
[16:44:15] <PJBoy> yeah there's empirical research
[16:44:23] <PJBoy> where you just try shit until it works well enough
[16:44:32] <PJBoy> that's my idea of fake research
[16:44:44] <PJBoy> also see https://en.wikipedia.org/wiki/MurmurHash
[16:45:29] <rpav> eh boost's is 1 line, i posted it above, it's always seemed to work fine .. i just ripped off the 1-liner and made my own function
[16:45:31] <Juliu> Seems to only work for just 1 type of hash function
[16:45:39] *** Quits: horribleprogram (~user@2607:fea8:7040:830:f964:952e:6e13:b83b) (Changing host)
[16:45:39] *** Joins: horribleprogram (~user@user/horribleprogram)
[16:45:50] <Juliu> My approach works for all hash-functions, I think
[16:45:58] <rpav> simple xor is terrible
[16:46:01] <PJBoy> the boost implementation handles all the bells and whistles
[16:46:05] <rpav> at least do some bit offset or something but
[16:46:06] <Juliu> rpav, not that I did
[16:46:14] <Juliu> Look closely
[16:46:21] <Juliu> *what
[16:46:25] <rpav> oh you wrote a slightly less bad one above
[16:46:39] <Juliu> rpav,   hash(hash(first)) ^ hash(hash(first) ^ hash(second))
[16:47:04] <rpav> i wouldn't randomly subscribe to a hash function without a reasonable test
[16:47:30] <Juliu> Then test it and tell us what you found out
[16:47:30] <lpapp> PJBoy: boost is FG :D
[16:47:37] <PJBoy> what's FG?
[16:47:51] <rpav> it's not really on me to prove your hash function is any good ;)
[16:48:06] <Juliu> rpav, it's also not on me to prove anything
[16:49:17] <rpav> no, but the default assumption is your hash function is crap lacking evidence to the contrary
[16:49:17] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[16:49:27] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[16:49:33] <Juliu> rpav, I think it's pretty good
[16:49:34] <rpav> damn i can't find the page with the uniformity tester
[16:49:49] <PJBoy> the spectral analysis thing?
[16:49:53] <rpav> oh, well if you _think_ so, ;)
[16:50:08] <Juliu> rpav, yes, trust me blindly!
[16:50:22] <PJBoy> oh wait that was for RNGs
[16:50:29] <rpav> i'm not sure what it's called but there was like a 2d uniformity graph thing that was pretty telling for various functions
[16:50:34] <Juliu> In case you find your analysis tool, let me know what it says
[16:51:31] <rpav> in any case boost's is pretty good, i think i just added something like hash(Ts...) that repeatedly applied it
[16:51:43] <Juliu> And a good hash-function does not have to produce uniformly spaced outputs
[17:01:25] <rpav> https://softwareengineering.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed/145633#145633 <- those are the things i remember, though i thought it had its own blog entry
[17:10:04] *** Quits: m_ben (~m_ben@user/m-ben/x-7429725) (Quit: WeeChat 3.3)
[17:10:04] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:18:30] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[17:27:26] *** Quits: kylese (~kylese@p5dd8b9e4.dip0.t-ipconnect.de) (Quit: Leaving)
[17:30:52] *** Joins: Mooncairn (~mooncairn@user/mooncairn)
[17:31:15] *** Quits: JohnMS_WORK (~kvirc@213.134.183.29) (Quit: KVIrc 5.0.1 Aria http://www.kvirc.net/)
[17:31:15] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:34:20] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 246 seconds)
[17:34:30] *** Quits: smallville7123 (~smallvill@cpe-172-193-200-97.qld.foxtel.net.au) (Read error: Connection reset by peer)
[17:34:35] *** Joins: skapata (~Skapata@2804:14c:87b0:a6f9:882f:99b3:8330:1ef6)
[17:34:35] *** Quits: skapata (~Skapata@2804:14c:87b0:a6f9:882f:99b3:8330:1ef6) (Changing host)
[17:34:35] *** Joins: skapata (~Skapata@user/skapata)
[17:34:47] *** Joins: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse)
[17:37:15] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[17:37:23] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[17:37:23] *** ChanServ sets mode: +v npaperbot
[17:40:04] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[17:40:23] *** Joins: lh_mouse_ (~lh_mouse@mingw-w64/developer/lhmouse)
[17:43:29] *** Quits: lh_ideapad (~lh_mouse@mingw-w64/developer/lhmouse) (Remote host closed the connection)
[17:43:35] *** Quits: lh_cat (~lh_mouse@mingw-w64/developer/lhmouse) (Ping timeout: 264 seconds)
[17:44:01] *** Joins: RabidToaster (~Thunderbi@bras-base-otwaon234vw-grc-25-65-93-17-96.dsl.bell.ca)
[17:44:16] <Juliu> rpav, so, were you able to test "my" version?
[17:48:11] *** Quits: cbreak (~cbreak@77-58-201-132.dclient.hispeed.ch) (Read error: Connection reset by peer)
[17:51:02] *** Joins: cbreak (~cbreak@77-58-201-132.dclient.hispeed.ch)
[17:52:13] *** Parts: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) ()
[17:53:02] <rpav> why would i bother
[17:53:03] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[17:53:53] *** gggpkm_ is now known as gggpkm
[17:54:46] <rpav> also even if it were good, i think i'd avoid any function which required 4 individual calls to the hash function vs 1 per element
[17:56:56] <rpav> though at a glance, _also_ note that your hash function is probably equivalent to hash(first)
[17:57:36] <rpav> << hash<int>(1000)
[17:57:36] <geordi> error: could not convert '1000' from 'int' to '__hash_base<long unsigned int, int>'
[17:57:39] <rpav> err
[17:57:42] <rpav> << hash<int>{}(1000)
[17:57:42] <geordi> 1000
[17:58:45] <rpav> so once you start combining hashes, `hash(hash(a)) ^ hash(hash(a) ^ hash(b))` still reduces to `hash(a)` if a == b
[17:59:01] <rpav> and then you just pass that on
[18:01:36] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:02:52] <Juliu> rpav, :(
[18:03:44] <Juliu> rpav, hash(first) does not include the second value
[18:03:53] <rpav> precisely
[18:04:29] <Juliu> rpav, if a == b then it reduces to hash^2(first) ^ constant, indeed. Which is correct
[18:04:36] <rpav> you mean ^ 0
[18:04:59] <Juliu> Actually hash(0), but even if it was 0, 0 is a constant ;)
[18:05:13] <rpav> because hash(n) = n, and n ^ n is 0, and then hash(hash(n)) = n
[18:05:38] <rpav> basically your hash is doing nothing in the worst case
[18:05:46] <rpav> and in the best case probably very little
[18:05:46] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[18:05:48] <Juliu> rpav, what worst case?
[18:06:50] <Juliu> If you provide a hash function that does nothing, then my method also does nothing, which is not a problem but probably what is wanted by the user
[18:08:31] <rpav> it's pretty bad since it's reasoanble to simply map integers to the space of integers for the purpose of hashing, since you're guaranteed unique values ;)
[18:09:00] <Juliu> It's not bad at all but what the provided hash would do for a single value anyway
[18:09:06] <Juliu> Same hold for a == b
[18:09:10] <Juliu> *holds
[18:10:04] <Juliu> Almost no hash function is guaranteeing unique outputs for different inputs
[18:10:59] <rpav> ok fair but it doesn't answer general uniformity, and the double hashing is always useless
[18:11:46] <Juliu> The double hashing is only needed if the types of pair.first and pair.second are not both integers
[18:11:47] <rpav> it's not any different than a ^ (a^b) which is probably not a very good hash function
[18:12:10] <rpav> but the hash of anything is always an integer, so the double hashing never does anything
[18:12:12] <Juliu> Yes, I only did that to support strings and such types
[18:12:39] <Juliu> It's not meant to be differnt from hash(a) ^ hash(a ^ b)
[18:12:54] <rpav> those hashes still do nothing
[18:13:08] *** Joins: pulse (~pulse@user/pulse)
[18:13:25] <Juliu> Actuallly they do, since by doube hashing you can use my sceme for all types
[18:13:30] <rpav> hash(a ^ b) = a^b
[18:13:38] <Juliu> *scheme
[18:13:44] <rpav> hash(a) must = a because a^b compiles ;)
[18:14:02] <Juliu> I don't understand what you are talking about
[18:14:08] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:14:28] <rpav> but given some a' and b' hash values, produced via hash(a) and hash(b), your function is still `a' ^ (a' ^ b')`
[18:14:56] <Juliu> Yes it is. Like I said, that is precisely what I intended
[18:15:01] <rpav> for close values my guess is that produces a lot of collisions, since xor
[18:15:21] <Juliu> Well, actually it would be hash(a') ^ hash(a' ^ b')
[18:15:23] <rpav> actually for some class of similar values it probably collides a lot
[18:15:35] <rpav> Juliu: no, because hash(a') = a'
[18:15:44] <rpav> and hash(a' ^ b') = (a' ^ b')
[18:15:51] <Juliu> Name 2 pairs that would result in the same hash
[18:16:16] <Juliu> What are you talking about, hash(a') = a' ? What nonsense is that?
[18:16:28] <rpav> << hash<int>{}(1000)
[18:16:29] <geordi> 1000
[18:16:30] *** Quits: frost (~frost@user/frost) (Quit: Ping timeout (120 seconds))
[18:16:37] <rpav> a' = hash(a)
[18:16:46] *** Quits: proller (~p@2a02:6b8:0:40c:3fe5:78f3:414f:9acc) (Ping timeout: 245 seconds)
[18:16:52] <rpav> any number of hash^n(a') = a
[18:16:54] <rpav> err, a'
[18:16:54] <Juliu> Maybe you should pick a better hash function if you don't like yours
[18:17:16] <rpav> no i think i'll pick a better hash combiner and one that doesn't assume a random distribution of inputs heh
[18:17:50] <Juliu> My combiner is pretty good I think. You just don't like your own hash function and think it's the fault of my combiner, which is nonsense
[18:18:12] *** Joins: frost (~frost@user/frost)
[18:18:12] <rpav> note this is just the basic problem using it with std::hash; it doesn't even begin to address how probably-poorly the actual output is
[18:18:28] <Juliu> My combiner works pretty well for the identity hash function
[18:18:45] <rpav> well, you're entitled to opinions, but again... the default assumption is it's very poor, and i have yet to see anything to the contrary
[18:19:45] <Juliu> So you say it's poor for the hash function hash(x) = x ?
[18:19:45] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[18:22:05] *** Quits: kn07_ (~kn07_@86.121.23.168) (Quit: Leaving)
[18:22:06] *** Quits: horribleprogram (~user@user/horribleprogram) (Quit: ERC (IRC client for Emacs 27.2))
[18:22:40] <Juliu> I am pretty sure that I can proof that no matter how you make your combine, I can always find a hash function where your combine is bad. Mine is bad for hash(x) = x, which might be good, since it's easy to avoid that hash-function
[18:22:49] *** Joins: markong (~kvirc@213.146.188.203)
[18:23:07] <rpav> hash(x) = x for numbers is a perfect hash
[18:23:22] *** Joins: CaCode (~CaCode@user/cacode)
[18:23:22] *** Joins: ShiftyLogic (~shiftylog@66.115.146.16)
[18:23:29] <Juliu> Not for my combine. For whatever combine you suggest, I can also find a bad hash function
[18:23:33] <rpav> and specifically integers, since probably one only deals in ints for hash values
[18:24:14] <rpav> even if that's the case, which is highly dubious, the point is yours is bad for a very good and common hash function, rather than bad for a contrived and unlikely function
[18:24:23] <Juliu> hash(x) = x is only good if you want to insert the numbers 0...n-1 into a hash-table of size n. I doubt that that happens a lot
[18:25:03] <rpav> hash(x) = x is good if you want to maximize unique values for every input of the hash function, which is what a (non-crypto) hash function is meant to do
[18:27:28] <Juliu> I doubt that there is a reason to use a hash-table at all if you use hash(x) = x, but ok
[18:28:06] <rpav> plenty .. sparse indexed sets is a big one
[18:28:10] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:29:02] <Juliu> rpav, you don't make no sense to me. Either you don't understand how hash-tables work, or that a hash-table with hash(x) = x is worst than a simple vector/array
[18:29:02] <rpav> also that hash function _is_ cheap, which is a benefit if you don't have cryptographic needs, but then you can't rely on it to "mix up the bits" for you
[18:29:18] <Juliu> *worse
[18:29:36] *** Joins: AbleBacon (~AbleBacon@user/AbleBacon)
[18:30:14] <Juliu> If you use hash(x) = x and I call table.insert(0); and then table.insert(1000000000);, how would your hash-table do that? I don't get it
[18:30:18] <rpav> Juliu: a crappy hash table with chaining/bucketing/closed-addressing, sure, but you only use one of those if you're std and have no idea about your data ;)
[18:30:20] *** Joins: proller (~p@2a02:6b8:0:408:eef4:bbff:fe62:69c8)
[18:30:32] <rpav> um
[18:30:53] <rpav> if you don't get that then then i think you're missing fundamental knowledge about how hash tables work
[18:31:04] <Juliu> I think you don't get it yourself
[18:32:26] <rpav> a hash _table_ has either a closed-addressing scheme, e.g. buckets (a la unordered_map), and you can `bucket = hash_value % bucket_count`, or you have an open addressing scheme which picks the location via other means
[18:32:59] <rpav> e.g. 0,1,2,...bucket_count and then you loop, if you're not familiar with modulus
[18:32:59] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[18:33:01] <Juliu> Choose one!
[18:33:54] <Juliu> How large is your bucket count for my first and my second insert?
[18:34:42] <rpav> open addressing is generally a lot better and doesn't degenerate into a linked lists, but you have to have more knowledge about your data
[18:34:48] <rpav> um, it doesn't matter
[18:34:54] <rpav> do you understand how modulus works?
[18:35:10] <Juliu> Algorithms don't work with "doesn't matter", so tell me precisely
[18:35:15] <rpav> literally there can be one bucket, and the hash table would be a linked list, but it would still work
[18:35:33] <rpav> i think you need to go back and study some very basic things at this point
[18:35:34] <Juliu> So there are 2 buckets for my second insert?
[18:36:06] <rpav> you can pick however many buckets you'd like, generally you want something reasonably close to the _number of elements_ (not the size of indices)
[18:36:26] <Juliu> I am asking you how much your hashing datastructure picks
[18:36:36] <Juliu> So tell me
[18:36:36] <rpav> why does it matter?
[18:36:45] <Juliu> Why not just tell me?
[18:36:55] <rpav> i said it would literally work with 1
[18:37:01] <Juliu> If it doesn't matter then I choose bucket_count = 0 all the time
[18:37:07] <rpav> it would work with 4 or 8 or 128 or however many
[18:37:15] <Juliu> So there is only 1 bucket?
[18:37:44] <rpav> _it doesn't matter_, like i said you want to pick a bucket count close to your _element count_, or rehash if you significantly deviate
[18:38:04] <rpav> std::unordered_map likely does this, or at least can on demand
[18:38:08] <Juliu> I am asking you, how many buckets does your method have for my second insert
[18:38:22] <Juliu> 2 ?
[18:38:22] <rpav> let's say 2
[18:38:26] <rpav> there are 2 elements
[18:38:31] <rpav> that would be a fine number
[18:38:33] <Juliu> Good. How much is 1000000000 % 2 ?
[18:38:35] *** Joins: gggpkm_ (~gggpkm@60.10.194.46)
[18:38:41] *** Quits: lionkor (~lionkor@beammp/staff/lionkor) (Remote host closed the connection)
[18:38:42] <rpav> << 1000000000 % 2
[18:38:42] <geordi> 0
[18:38:57] <Juliu> You need to calculate that??
[18:39:04] *** Joins: lionkor (~lionkor@beammp/staff/lionkor)
[18:39:11] <Juliu> And how much is 0 % 1 ?
[18:39:12] <rpav> you apparently need to ask how many buckets are specifically in a hash table
[18:39:49] *** Quits: gggpkm_ (~gggpkm@60.10.194.46) (Remote host closed the connection)
[18:39:51] <rpav> this conversation is over until you can demonstrate some coherent level of CS101 knowledge
[18:39:58] <Juliu> << 0 % 1
[18:39:58] <geordi> 0
[18:40:04] <Juliu> Is 0 == 0 ?
[18:40:15] <PJBoy> what's up with these question?
[18:40:15] *** Joins: gggpkm_ (~gggpkm@60.10.194.46)
[18:40:24] <kalven> PJBoy: juliu learns has tables 101
[18:40:29] <Juliu> PJBoy, I am just demonstrating how his hashing algorithm is terrible
[18:40:32] <rpav> i have no idea, but they clearly don't have the slightest understanding of hashing or hash tables heh
[18:41:06] <Juliu> rpav, apparently you have no idea how bad your hashing table would be
[18:41:20] <rpav> or wait, is this the same person who had extremely confused ideas about big-O ... 🤔
[18:41:37] <kalven> { unordered_set<int> table; table.insert(0); table.insert(1); cout << table.bucket_count(); }
[18:41:37] <geordi> 13
[18:41:42] <kalven> oh look, a prime.. curious...
[18:41:43] <Juliu> rpav, I have no confusing ideas about big O, you do
[18:42:05] *** Quits: gggpkm (~gggpkm@60.10.194.46) (Ping timeout: 268 seconds)
[18:42:13] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:42:21] <yolo_> "The Directions Group of which Bjarne is a part, listed networking as an important component of the standard library. But no mention of it in this keynote. Networking TS has now been effectively killed off by Eric Niebler, Kirk Shoop, Lewis Baker, Bryce Lelbach, and nVIDIA. They are in control of what std networking will look like. In my opinion, WG21 no longer represents the C++ community"
[18:42:34] <yolo_> comments under C++20 talk https://www.youtube.com/watch?v=15QF2q66NhU
[18:43:26] <rpav> i dunno, the way std does things, std::networking would likely be of limited use in any case ;/
[18:43:28] <kalven> yolo_: just fyi, vinnie falco is not an impartial spectator
[18:44:04] <PJBoy> { unordered_set<int> table; for (int i : views::iota(0, 100000)) table.insert(i); cout << table.bucket_count(); }
[18:44:05] <geordi> 172933
[18:44:19] <Juliu> kalven, yes, primes are nice for modulo because they have a higher chance of being closer to a generator of a group in terms of how many distinct numbers 2^x mod prime gives, unlike what rpav suggested
[18:44:24] <PJBoy> 172933 is also prime
[18:44:42] <Juliu> PJBoy, primes are nice :)
[18:44:55] <rpav> yeah, i shouldn't have picked a non-pri... err
[18:44:55] <Juliu> Apparently rpav has no clue what his hash table is actually doing
[18:45:00] *** Joins: useful_idiot (~useful_id@gateway/vpn/pia/usefulidiot/x-43226899)
[18:45:28] <rpav> (i mean obvioulsy 2 is a shitty number of buckets, but if you're even asking, it's like 🤷
[18:46:05] <PJBoy> yolo_, have you seen [p2464]?
[18:46:05] <npaperbot> P2464R0: [Library Evolution] Ruminations on networking and executors <https://wg21.link/p2464r0> (by Ville Voutilainen) (2021-09-29) (Related: https://wg21.link/p2464r0/github)
[18:46:23] <Juliu> Since no efficient prime generator is known, I wonder how they do it in practice? Simple have a list of primes approximately spaced every 2^n or something like that?
[18:47:49] <Juliu> rpav, I agree on what you said for my combiner being bad for hash(x) = x. But what you said about how hash tables work was pretty much nonsense
[18:47:49] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[18:48:08] <PJBoy> we can generate primes efficiently can't we?
[18:48:16] <Juliu> PJBoy, no we can't
[18:48:42] <Juliu> PJBoy, well, ok, to be fair, not consecutive primes
[18:48:52] <PJBoy> the Atkin sieve is O(N / log(log(N)))
[18:48:59] <PJBoy> and it generates all primes less than N
[18:49:04] <PJBoy> that's incredibly efficient
[18:49:12] <Juliu> Just primes might be possible by getting a quasi prime and then testing if it is a prime
[18:49:39] <PJBoy> even the Eratosthenes sieve is O(N)
[18:49:47] <rpav> that's bad though
[18:49:52] <Juliu> PJBoy, testing if a number is prime is not the same as finding a prime since primes are spaces more and more distant apart on average, exponentially distant
[18:50:10] <rpav> you'd want constant time genration of prime K close to value N
[18:50:10] <PJBoy> you said generating primes, not testing primality
[18:50:17] <Juliu> Also what is N in your O(N) ?
[18:50:28] <PJBoy> > and it generates all primes less than N
[18:50:36] <rpav> instead it's probably doing N iterations to find primes up to N
[18:50:40] <Juliu> PJBoy, yes, generating primes. That is hard
[18:50:53] <PJBoy> I think N / log(log(N)) is pretty good
[18:50:58] <rpav> i mean that's better than like n^2 but i dunno if you'd want it for rehashing
[18:51:00] <Juliu> PJBoy, you can't generate all primes less than N efficiently
[18:51:12] <Juliu> I mean, maybe you can, but we don't know how
[18:51:22] <rpav> PJBoy: but n/log(log(n)) is "strictly better than (but close to) n"
[18:51:22] <PJBoy> I think N / log(log(N)) is pretty good
[18:51:29] <Juliu> PJBoy, what is N ?
[18:51:37] <PJBoy> it generates all primes less than N
[18:51:44] <SuperNintendoSUX> N is a variable
[18:52:06] <SuperNintendoSUX> usually the size of your data set. or a parameter for your simulation
[18:52:17] <Juliu> So N is the number, not the number of bits? Fine. Then PJBoy's algorithm is exponential in the input size, and hence definitely NOT efficient
[18:52:19] <SuperNintendoSUX> you can have more variables when doing complexity analysis
[18:52:56] <PJBoy> primes don't grow exponentially
[18:52:57] <Juliu> There is no known efficient prime generator, as far as I know
[18:53:03] <SuperNintendoSUX> yup
[18:53:07] <Juliu> PJBoy, actually primes grow exponentially
[18:53:09] <SuperNintendoSUX> unless you have a small N
[18:53:27] <PJBoy> https://en.wikipedia.org/wiki/Prime-counting_function says they grow at rate x / log(x)
[18:53:36] <kalven> has tables that use primes for bucket counts have a list of primes in them, they don't go looking for them...
[18:53:39] <rpav> apparently very odd ideas about how primes work too, or perhaps what "exponential" means
[18:53:40] <kalven> *hash tables
[18:53:45] <Juliu> PJBoy, the number of primes less than N converges to log(N) when N approaches infinity
[18:53:50] *** Joins: kraa (~kraa@107-190-7-216.cpe.teksavvy.com)
[18:53:50] <SuperNintendoSUX> who has tables? :D
[18:53:58] <PJBoy> oeis for a start
[18:54:01] <SuperNintendoSUX> that typo made me wonder for a while
[18:54:09] <Juliu> PJBoy, yes, that's what I meant
[18:54:42] <PJBoy> so it's not quite exponential
[18:54:56] <SuperNintendoSUX> 'quite'
[18:55:04] <Juliu> PJBoy, fine. But enough to make it super-polynomial in the input size to find one
[18:55:06] <SuperNintendoSUX> it's a little less exponential right? :D
[18:55:11] <PJBoy> it's off by an exponential factor of 1/log(x)
[18:55:16] <rpav> SuperNintendoSUX: "a little"
[18:55:16] <Juliu> SuperNintendoSUX, :D
[18:55:54] <PJBoy> the area between polynomial and exponential is a grey area for "efficient" IMO
[18:56:07] *** Quits: gggpkm_ (~gggpkm@60.10.194.46) (Ping timeout: 260 seconds)
[18:56:13] <SuperNintendoSUX> usually a brown area I would say
[18:56:15] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[18:57:10] <PJBoy> besides
[18:57:13] <PJBoy> the maximum N is what
[18:57:19] <PJBoy> less than SIZE_MAX
[18:57:26] <Juliu> Usually for large N even N^2 is not efficient at all
[18:57:28] <PJBoy> so technically that prime generation is constant time for stdlib
[18:57:45] <rpav> ;)
[18:58:01] <Juliu> PJBoy, the best known prime generators have super-polynomial runtime, and you claim they have constant runtime? lol
[18:58:19] <SuperNintendoSUX> sometimes I think PJBoy is smart. then I see such sentences and I don't know what to think anymore
[18:58:22] <rpav> though not really, N is the target number, not the size of the addressable int space
[18:58:23] <PJBoy> yeah, within the constraint that I just wrote
[18:58:34] <Juliu> PJBoy, cheater ;)
[18:58:36] <PJBoy> exactly
[18:59:23] <PJBoy> to be fair though
[18:59:29] <Juliu> Even what people consider constant is actually O(log n) most of the time for a turing machine
[18:59:36] <PJBoy> the standard doesn't care about the time complexity of such trivial matters as prime generation
[18:59:56] <PJBoy> considering that deque and deallocate and reallocate an entire table in "constant time"
[18:59:58] <rpav> it cares about time complexity quite a bit
[19:00:09] <PJBoy> *considering that deque can deallocate and reallocate an entire table in "constant time"
[19:00:25] <PJBoy> not even amortized
[19:01:02] <PJBoy> it doesn't dismiss time complexity entirely, I'm not saying that
[19:01:12] <rpav> err, where does it claim this
[19:01:23] <PJBoy> but containers don't care about the time complexity of operations that don't involve operations on the elements
[19:01:23] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[19:01:54] <PJBoy> see the discussion here https://en.cppreference.com/w/Talk:cpp/container/deque
[19:02:20] <rpav> https://en.cppreference.com/w/cpp/container/unordered_map/rehash
[19:02:23] *** Joins: AmR (~AmREiSa@156.199.244.83)
[19:02:33] <rpav> "worst case quadratic" so maybe they are allowing for "find a prime"
[19:03:36] <PJBoy> worst case is worst case insertion for every element
[19:03:40] <PJBoy> I would have thought
[19:04:03] <PJBoy> like if your rehash ends up hashing every element to the same index for example
[19:04:08] *** Joins: m_ben (~m_ben@user/m-ben/x-7429725)
[19:04:18] <rpav> PJBoy: i don't think you're reading it quite correctly
[19:04:43] <rpav> PJBoy: the point is complexity is specified _with respect to_ elements, but not recursively
[19:05:00] <PJBoy> well I mean
[19:05:08] <PJBoy> deque is specified for push_back to be constant time
[19:05:22] <PJBoy> and it *has* to spend linear time to reallocate its table of pointers
[19:05:26] <rpav> i.e. the vector<vector<..>> example; operations are linear, even though with all types considered they may be super-linear
[19:05:36] <PJBoy> so the standard is 100% dismissing that operation
[19:05:38] <rpav> PJBoy: deque is not a vector, it uses blocks
[19:05:49] <PJBoy> I know what deque is
[19:06:05] <PJBoy> it's roughly a vector<unique_ptr<array<T, block_size>>>
[19:06:17] <PJBoy> and that vector needs resizing sometimes
[19:06:27] <rpav> it should use blocks for pointers too if it's not
[19:06:43] <PJBoy> implementations aren't doing so
[19:06:51] <rpav> although 🤔
[19:07:44] <PJBoy> plus the standardese interpretation that Cubbi uses reads perfectly to me
[19:07:53] <rpav> ok fair point
[19:08:31] <rpav> well
[19:08:33] <Juliu> Ok, what I said about the growth of primes was bullshit. They seem to approach growing almost linearly (i.e. x / log(x) probably)
[19:08:44] <Juliu> But that is still exponential in the input size
[19:08:53] <PJBoy> I still argue it's subexponential
[19:09:04] <PJBoy> exponential is defined by growth rate x
[19:09:14] <Juliu> Fine, you win
[19:09:20] <rpav> it's very clearly not exponential if you look at the graph of primes
[19:09:27] *** Joins: great_taste (~great_tas@190.32.235.20)
[19:09:29] <Juliu> Almost exponential ... which is what I said first ... or at least meant
[19:09:45] <PJBoy> well as long as we're on the same page
[19:10:19] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:12:15] *** Joins: spaceangel (~spaceange@ip-89-176-181-220.net.upcbroadband.cz)
[19:14:04] <Juliu> rpav, you have to consider that the input size b = log(n) for a number of n, and that the number of primes less than n is approaching n / log(n). So overall that makes about 2^b / log(2^b) = 2^b / b which is quasi exponential
[19:14:50] <Juliu> But PJBoy is correct, it's still sub-exponential if you want to be precise. But pretty much as bad as exponential
[19:17:03] <Juliu> PJBoy, the interesting question is: I actually did (by mistake) NOT say consecutive primes. So is finding just any sequence of distinct primes still that hard? As far as I remember, sadly the answer is Yes and we do NOT know how to efficiently find primes
[19:20:08] <Juliu> If you knew how to efficiently find primes, you could efficiently crack a lot of encryption standards :)
[19:23:51] *** Quits: Serpent7776 (~Serpent77@90-156-31-193.internetia.net.pl) (Quit: leaving)
[19:25:56] <PJBoy> that's not true
[19:26:07] <Juliu> ?
[19:26:12] <PJBoy> crypto assumes prime numbers are easy to find
[19:26:24] <PJBoy> factorisation is hard
[19:26:28] <PJBoy> discrete log is hard
[19:26:37] <PJBoy> but not finding primes themselves
[19:27:06] <Juliu> 1. You can't know if factorization is hard or not since this is not known to the public. 2. Factorization is not hard if you can generate primes efficiently
[19:27:19] *** Joins: magla (~gelignite@55d46190.access.ecotel.net)
[19:27:21] <PJBoy> you're clueless
[19:27:34] <Juliu> 3. If factorization is not hard, then the discrete log is also not hard
[19:27:38] <Juliu> No, you are clueless
[19:27:58] <PJBoy> suppose I can find primes efficiently, how does that help me factorise?
[19:28:08] <Juliu> Finding primes is hard, or at least we don't know how to do it well. Deal with it
[19:28:25] <PJBoy> I'll wait
[19:29:25] <PJBoy> https://primes.utm.edu/nthprime/ this page will give you any one of the first trillion primes on demand
[19:29:29] <LordKalma> yall need some fucking tea these days
[19:29:38] <PJBoy> I'll give you an RSA key to factorise
[19:29:48] <PJBoy> try to get back to me before either of us dies
[19:30:11] <rpav> well it should really only take a year or so with a reasonable cluster these days right
[19:30:27] <PJBoy> to factor an RSA key or to generate that list?
[19:30:31] <Juliu> PJBoy, there are papers about it. I don't have a link at the moment since it's been a longer time since I read about it
[19:30:32] <rpav> factor RSA
[19:30:38] <PJBoy> no
[19:30:39] <rpav> though obviously that depends on keysize
[19:30:49] <PJBoy> ok yeah, for small enough key sizes I guess
[19:30:50] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[19:30:56] <rpav> ooh apparently it's still way better than i thought
[19:30:58] <PJBoy> but certainly not for 1024 bit RSA
[19:31:14] <Friithian> PJBoy: give them some slack, giv ethem until the heat death of the universe
[19:31:20] <PJBoy> :D
[19:31:27] <Juliu> PJBoy, I am talking big O notation here, so the actual size does not matter
[19:31:35] <rpav> at least the top google blurb says "It would take a classical computer around 300 trillion years to break a RSA-2048 bit encryption key", though the accuracy of those is a dice roll, but
[19:31:45] <PJBoy> by all means, fill me in on this efficient factorisation algorithm you know
[19:31:52] <PJBoy> I promise I won't tell NSA
[19:31:53] <Friithian> won't get them anywhere, but still fun
[19:31:59] <rpav> (i assume recommended keysize is still 2048)
[19:32:01] <Juliu> PJBoy, and I said certain encryption standards, and by that I meant those based on the discrete log, not elliptic curves
[19:32:26] <PJBoy> what you said was "Factorization is not hard if you can generate primes efficiently"
[19:32:40] <PJBoy> which is something only someone with no crypto education would say
[19:33:11] <rpav> or like, some kind of time complexity consideration really, and some idea of the size of the numbers involved i think
[19:33:17] <Juliu> PJBoy, yes, that is what I said and meant
[19:33:37] <PJBoy> I mean it's an open problem whether it's hard or not, of course
[19:33:51] <PJBoy> but there's certainly no known polynomial time algorithm for it
[19:34:04] <PJBoy> and generating primes
[19:34:04] <Juliu> PJBoy, for what?
[19:34:11] <PJBoy> I mean we generate primes to generate keys in the first place
[19:34:23] <Juliu> PJBoy, yes, you can generate some primes
[19:34:45] <Friithian> if my algo prof was dead he'd be rolling in his grave right now
[19:35:04] <rpav> aw the above site only goes up to 10^12
[19:35:09] <Juliu> You guys don't seem to have a clue
[19:35:26] <Friithian> I'm pretty sure the combined IQ of this channel at least gets us to 50
[19:35:37] <PJBoy> tell me the algorithm to factor RSA keys given efficient prime generation
[19:35:43] *** Joins: andreasbuhr (~quassel@p548ddac6.dip0.t-ipconnect.de)
[19:35:47] <Friithian> no really please do I could make so much money from that
[19:36:21] <Juliu> PJBoy, as I said, I forgot where I read about it, and I'm trying to find it again ... which might be hopeless
[19:36:27] <PJBoy> yeah and I'm not surprised
[19:36:47] <PJBoy> maybe the feds took it down
[19:37:02] <rpav> but they probably forgot about webarchive!
[19:37:08] <Friithian> "I know this thing that proves the moon landing was fake but I can't find it!"
[19:38:23] <Juliu> PJBoy, lol
[19:38:46] *** Parts: joel135 (sid136450@hampstead.irccloud.com) ()
[19:38:57] *** Joins: peeps[zen] (~peepsalot@openscad/peepsalot)
[19:39:06] *** Quits: interop_madness (~interop_m@user/interop-madness/x-0950004) (Quit: Leaving)
[19:39:07] <Juliu> They don't need any primes to crack your encryption since they already accieved that some years ago
[19:39:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[19:40:07] *** Quits: lh_mouse_ (~lh_mouse@mingw-w64/developer/lhmouse) (Read error: Connection reset by peer)
[19:40:35] *** Quits: peepsalot (~peepsalot@openscad/peepsalot) (Ping timeout: 264 seconds)
[19:43:53] *** Joins: dextercd (~dexter@2a02-a450-f25d-1-76d4-35ff-fefe-34c.fixed6.kpn.net)
[19:45:47] <rpav> anyway .. what we need are lazy / implicit lambda parameters
[19:45:57] <rpav> we could probably do some interesting shit
[19:47:24] <rpav> e.g. void foo(lazy int x) { .. }, where foo(expr) => foo([&]() -> int { return EXPR; }), and the first reference of `x` in `foo` resolves the value thereafter
[19:48:07] <rpav> no actually .. allow/require x() for repeated evaluation
[19:48:36] <rpav> and `lazy void f` would work
[19:49:57] <rpav> `void my_while(lazy bool e, lazy void body) { top: if(e()) { body(); goto top; } }`
[19:50:06] <rpav> my_while(x, x--);
[19:55:02] *** Joins: peepsalot (~peepsalot@openscad/peepsalot)
[19:56:42] *** Quits: peeps[zen] (~peepsalot@openscad/peepsalot) (Ping timeout: 268 seconds)
[20:02:27] <Juliu> PJBoy, I can't find anything now but I think I remember that I read somewhere in a paper that the discrete log could be calculated efficiently with the help of efficient prime generators and the chinese ramainder theorem, or something like that. Can't remember clearly
[20:04:33] *** Quits: Youmu (uid129469@user/condy) (Ping timeout: 244 seconds)
[20:06:00] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:06:37] *** Joins: Youmu (uid129469@user/condy)
[20:08:20] *** Quits: Haohmaru (~Haohmaru@195.24.53.110) ()
[20:14:28] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[20:20:52] *** Joins: paul424 (~tom@ip-31-0-122-31.multi.internet.cyfrowypolsat.pl)
[20:21:23] <paul424> Hello , what type should I use     std::uniform_int_distribution<T> distribution(0,mTileSet->getTileValues(tile->getTileVisual()).at(index).size()); because whatever I try I get errors
[20:21:30] <paul424> size_t doesn';t work either . ..
[20:21:46] *** Quits: markong (~kvirc@213.146.188.203) (Ping timeout: 268 seconds)
[20:22:08] <LordKalma> auto
[20:22:10] * LordKalma runs
[20:22:25] <LordKalma> you can probablty just omit the <T> part and let it deduce it, iirc
[20:24:47] <kalven> what's the error?
[20:25:42] <Juliu> PJBoy, maybe I remember incorrectly and you are right. I don't know. But saying that I understand nothing about cryptography is mean
[20:26:25] <paul424>  error: missing template arguments before ‘distribution’, LordKalma so no
[20:27:36] <LordKalma> {std::vector bananas{1,2,3,4};}
[20:27:36] <geordi>  
[20:27:42] <Juliu> paul424, for a start to keep things simple, you could do the quick&dirty approach and simply use   rand() % 8   :D
[20:28:00] *** Joins: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com)
[20:28:19] <paul424> I follow what's here : https://www.cplusplus.com/reference/random/uniform_int_distribution/
[20:29:40] *** Parts: lpapp (~lpapp@ec2-15-161-137-233.eu-south-1.compute.amazonaws.com) ()
[20:32:15] <paul424> hmm errors : https://pastebin.com/tGm8LtbM
[20:32:15] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:32:30] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[20:34:56] *** Joins: undeclared3 (nullx@user/undeclared)
[20:35:55] *** Joins: ethrl_ (uid524335@user/doforlove33)
[20:36:52] <Juliu> paul424, here is some little code I wrote for these "new" C++11 random generator(s). Seems to work:   https://wandbox.org/permlink/BtQlA4pWhONk4Bjc
[20:37:43] *** Joins: DrMax__ (~DrMax@132.215.96.34)
[20:37:43] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:38:20] <Juliu> Oops, there is an "<int>" missing after "vector", but it compiles anyway :)
[20:38:34] *** Joins: very_sneaky_ (~very_snea@user/very-sneaky/x-7432109)
[20:39:20] <TinoDidriksen> Deduction is nice like that.
[20:39:47] <Juliu> paul424, all you need is   std::mt19937 gen;  std::uniform_int_distribution<int> dist( 0, N-1 );   and then you get a new random number each time you call   dist( gen )
[20:40:14] <Juliu> TinoDidriksen, who are you referring to?
[20:40:28] <TinoDidriksen> The missing <int>
[20:41:01] *** Quits: paul424 (~tom@ip-31-0-122-31.multi.internet.cyfrowypolsat.pl) (Killed (NickServ (GHOST command used by tom_)))
[20:41:03] <Juliu> Yeah, I didn't even notice the missing <int> since it compiled anyway. Shitty compiler. I hate when machines try to be smart
[20:41:31] *** Joins: paul424 (~tom@ip-31-0-122-31.multi.internet.cyfrowypolsat.pl)
[20:41:47] <paul424> ahh my computer crashed . not for the first time
[20:42:02] <Juliu> paul424, did you see what I wrote to you?
[20:42:08] <paul424> yes thanks
[20:42:12] <Juliu> Ok
[20:42:17] <TinoDidriksen> There are logs even if he didn't.
[20:42:41] <Juliu> TinoDidriksen, I don't see what people write when my IRC client isn't running
[20:42:50] <TinoDidriksen> You can in this channel.
[20:42:58] <Juliu> How?
[20:42:59] <TinoDidriksen> !logs
[20:43:00] <nolyc> Logs and stats are found at https://i.pjj.cc/lb ; 48h of C++ https://i.pjj.cc/lb/logs/%23c++/ ; All of C++-general https://i.pjj.cc/lb/logs/%23c++-general/
[20:43:06] <Juliu> ok
[20:43:19] *** Quits: undeclared (nullx@user/undeclared) (*.net *.split)
[20:43:19] *** Quits: ethrl (uid524335@user/doforlove33) (*.net *.split)
[20:43:19] *** Quits: DrMax_ (~DrMax@132.215.96.34) (*.net *.split)
[20:43:19] *** Quits: very_sneaky (~very_snea@user/very-sneaky/x-7432109) (*.net *.split)
[20:43:20] *** undeclared3 is now known as undeclared
[20:43:20] *** ethrl_ is now known as ethrl
[20:43:20] <Juliu> So you guys are spying on me ;)
[20:43:43] <TinoDidriksen> Mhm. I spy on everyone. But I'm nice about it.
[20:44:36] <LordKalma> If TinoDidriksen stops being nice about it, they'll just change the nick to MetaTino
[20:45:52] <Juliu> TinoDidriksen, I am also nice when I empty your bank account once I find out your PIN ;)
[20:46:22] <TinoDidriksen> Got government 2FA on that.
[20:46:32] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[20:46:47] <Juliu> So I have to call your mom and ask for your first pet's name
[20:47:37] <TinoDidriksen> Anyway, deduction isn't the compiler trying to be smart. It's not merely an educated guess - it's the only possible result.
[20:48:08] <Juliu> It should still give an error since my code isn't C++
[20:48:15] <TinoDidriksen> Yes it is.
[20:48:23] <Juliu> I don't think so
[20:48:30] <TinoDidriksen> That kind of deduction is standard.
[20:48:41] <Juliu> Since when?
[20:49:14] <TinoDidriksen> https://en.cppreference.com/w/cpp/language/class_template_argument_deduction - C++17
[20:49:22] <ARoxdale> 1971?
[20:49:49] <ARoxdale> Oh wait, this is C++-general
[20:50:17] <ARoxdale> Oh CTAD. Isn't that the thing the committee totally screwed up?
[20:50:27] <TinoDidriksen> How so?
[20:50:55] <Juliu> I tried it in my Visual Studio Community 2015, and I get an error
[20:51:05] <TinoDidriksen> 2015? Well yeah...
[20:51:12] <Juliu> So it's pretty "new"
[20:51:31] <TinoDidriksen> It's C++17
[20:51:32] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[20:51:59] <Juliu> Yes, like I said, "new"
[20:52:03] <paul424> hmm when     std::mt19937 gen; is local to a function everything is fine , when its a private field of a class compilation fails with strange errors
[20:52:14] <ARoxdale> I remember watching a "ask the committee" video and they more or less agreed that they screwed it up
[20:52:38] <TinoDidriksen> Careful with having an mt199937 as member. That thing is 3kb.
[20:52:44] <Juliu> paul424, what do the errors say?
[20:52:57] <ARoxdale> I'm mean it's a pretty sketchy thing. People already have issues with overloaded function deduction.
[20:53:09] <Juliu> paul424, did you include <random> at the top of your class's .h file?
[20:53:40] <paul424> why at the top, I put where it was suitable to ....
[20:54:31] <paul424> it's between memory and string to be exact
[20:54:38] *** Parts: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it) ()
[20:54:50] <paul424> #include's
[20:54:54] <Juliu> paul424, if you have a variable of type std::mt199937 in your class, then you have to include <random> somewhere in front of the beginning of the declaration of your class, I'd say
[20:55:16] <paul424> I know
[20:55:23] <paul424> !paul424
[20:55:25] <nolyc> paul424: Error: "paul424" is not a valid command.
[20:55:31] <paul424> !get paul424
[20:55:31] <nolyc> paul424: Error: 'paul424' is not a valid id.
[20:55:56] *** Quits: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net) (Ping timeout: 245 seconds)
[20:56:27] <Ameisen_> I legitimately cannot think of a time I'd ever want to use mt19937 as a generator, anyways
[20:58:21] <Juliu> Ameisen_, I just copied it from somewhere since I have no clue what I'm doing
[20:58:24] <ARoxdale> Ameisen_: What's wrong with it? It's cheap and effective.
[20:58:52] <Ameisen_> It's slow and huge
[20:59:00] <Ameisen_> and the output isn't particularly good
[20:59:03] <kalven> there are modern alternatives that are faster and much smaller
[20:59:20] <Ameisen_> even xorshift outperforms it in basically... all aspects
[20:59:21] <Juliu> Tell us some good alternatives
[20:59:22] <TinoDidriksen> E.g. https://www.pcg-random.org/
[20:59:25] <ARoxdale> But are they more complicated?
[20:59:30] <Ameisen_> ... no
[20:59:38] <Ameisen_> mt19937 is about as complicated as you can get.
[20:59:54] <Ameisen_> xorshift is like 5 lines
[21:00:04] <Ameisen_> and still outperforms the mersenne twister in statistical tests
[21:00:12] <Ameisen_> it's just an awful RNG
[21:00:27] <Ameisen_> I have no idea why it was included in <random>, it was way obsolete even when it was proposed...
[21:00:34] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[21:01:23] <ARoxdale> I may have been thinking of https://en.cppreference.com/w/cpp/numeric/random/linear_congruential_engine. But I recall using mt19937 and being pretty satisfied with the results
[21:02:01] <paul424> ahh me stupido . I was working inside a const member function
[21:02:03] <TinoDidriksen> mt19937 is fine, but it's huge and not the best.
[21:02:14] <kalven> ARoxdale: then you'd be pretty satisfied with xorshift and pcg, but without the 3kb state
[21:02:39] <paul424> the game is huge, the gamemap is only a singleton
[21:02:40] <ARoxdale> I guess I need to pay more attention to what comes out of <random>
[21:02:52] <paul424> so the overlap of 3kb doesn't change anything
[21:03:42] *** Joins: Guest93 (~Guest93@174.138.39.154)
[21:03:50] <Juliu> I just call rand() and so far it was always good enough for me :D
[21:03:55] <Ameisen_> the main problems with mt19937, as said, are that its state is huge, it's quite complex, it is pretty slow, and statistically the output is worse than much, much simpler RNGs
[21:04:34] <TinoDidriksen> rand() on Windows is just a sad joke. Elsewhere it's usable for dirty stuff.
[21:04:39] <Guest93> hello, please need the book  "Extreme c" ..someone can share with me?
[21:04:48] <Juliu> TinoDidriksen, I use it on Windows
[21:05:11] <TinoDidriksen> Guest93, if it's a free book, surely you can find it yourself.
[21:05:42] <cbreak> have you tried switching to C++? It's worth it.
[21:05:42] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[21:05:43] <Juliu> TinoDidriksen, if it's a free book he would probably not have asked. Lol
[21:05:46] <Guest93> TinoDidriksen No it is not free
[21:05:47] <TinoDidriksen> rand() is only 16 bits on Windows. Kinda useless.
[21:06:01] <TinoDidriksen> Guest93, then no, we can't help you obtain warez.
[21:06:09] <Ameisen_> cbreak: if I wrote a book called "Extreme C", it would just teach them to use C++
[21:06:13] <Ameisen_> that's how extreme it would be.
[21:06:16] <cbreak> heh
[21:06:19] <cbreak> good idea
[21:06:41] <Juliu> TinoDidriksen, yes, it's only 16 bits. Almost always enough for me, and if not I just bitwise shift and and two rand()s
[21:06:50] *** Joins: unixpro1970 (~unixpro19@c-73-181-185-205.hsd1.wa.comcast.net)
[21:07:20] <cbreak> Juliu: I don't think it's uniformly distributed 16 bit
[21:07:47] <ARoxdale> I think reading a book like "Extreme C" should be a mandatory pre-requisite to learning C++
[21:07:50] <Juliu> cbreak, I hope it is, at least that should be the case for a random number generator
[21:08:28] <Juliu> ARoxdale, I read Extreme C and learned that I better program in ++C. It's more efficient ;)
[21:08:32] <Guest93> ARoxdale you are true and it is a great book
[21:09:08] <ARoxdale> Sometimes, especially on Windows, I feel like the underlying "infrastructure" of C/C++ stopped evolving sometime around 1995 and has gone backwards in areas.
[21:09:32] <ARoxdale> Juliu: I can tell you favour pre-fix incrementing.
[21:09:40] <Juliu> ARoxdale, as if there were any useful changes after C++11
[21:09:51] <Juliu> ARoxdale, I do, but actually I was just joking
[21:10:29] *** Quits: pulse (~pulse@user/pulse) (Quit: pulse)
[21:11:05] <whupdup> I'm curious if you use MSVC on windows, I've been pretty stubborn about only using MinGW personally, which isn't always without its challenges, but overall I'm happy to not use anything related to VS
[21:11:34] <Juliu> Who is "you" ?
[21:11:34] <Ameisen_> I usually will prefer to use clang-cl on Windows.
[21:11:42] <Ameisen_> since it maintains compatibility, mostly, with msvc
[21:11:58] <whupdup> anyone who was talking about using C++ on windows just now, or anyone else with a relevant opinion
[21:12:04] <whupdup> not like you're banned from responding
[21:12:08] <Juliu> I use some older Visual Studio version
[21:12:54] <paul424> Juliu, yeah no when I don;'t work with const member class function everything's fine , many thanks for your help
[21:13:20] *** Joins: TheGuestMovie (~TheGuestM@173.231.114.74)
[21:14:38] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[21:15:05] <paul424> err wait ... those Tile faces aren't persistent in time... when I do reload the game from Save Load, wouldn't they be diffrent face set ?
[21:15:12] <paul424> s/they/there
[21:17:19] <paul424> arght ! I said from the begging I need rather a hash function , so the tile face is a function of it's position (x,y) :(
[21:17:30] <paul424> beginning*
[21:19:33] <Juliu> paul424, I don't know. It probably depends on the initialisation (i.e. the seed value) and the implementation of the generator
[21:19:34] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[21:20:19] <Juliu> paul424, in case the implementation and the seed doesn't chance, you should always get the same sequenc of random numbers
[21:21:54] <Juliu> If the implementation of the hash-function you would use instead changes, you would also get different numbers each time it changes
[21:23:01] *** Joins: pulse (~pulse@user/pulse)
[21:23:25] <paul424> Juliu, seed doesn't ... change ... you mean >? Sorry my English a bit rusty
[21:23:45] <Juliu> The only thing you should do when using a random number generator is initialize it to some seed value (for example 0) at the beginning of your method, or you will get different random numbers each time you call the method multiple times
[21:24:41] <Juliu> paul424, I think you can provide a seed value to "gen". This is something like that starting value for the randum number generator
[21:25:11] <rpav> Ameisen_: no, far better to drop all C stuff and start by teaching actual C++
[21:25:27] <paul424> https://www.cplusplus.com/reference/random/mersenne_twister_engine/mersenne_twister_engine/ hmm here it claims there is a default value for seed but ok
[21:25:31] <rpav> the overlap these days is far less than it even used to be anyway
[21:25:46] <Juliu> rpav, pretty much everything in C89 is also C++
[21:26:48] <Ameisen_> cbreak: distribution doesn't seem to be too bad
[21:27:19] <Juliu> paul424, yes, there probably is a default value, which is why I wrote "gen;" and not "gen( 0 );" in my code. But if you call the same method several times, you will get different random values in each call. If you don't want that, set the same seed each time at the beginning of your method
[21:27:21] <Ameisen_> 1 billion iterations, incrementing RAND_MAX buckets... Max was 1,955,276 Min was 1,950,919
[21:27:37] *** Quits: Guest93 (~Guest93@174.138.39.154) (Quit: Client closed)
[21:27:56] <Juliu> Ameisen_, my little code example tests the distribution quite simplistically, and it seems quite uniform. Maybe a bit too uniform for my taste
[21:28:32] <Juliu> Might be due to the small number of buckets (8) I used
[21:28:40] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[21:28:42] <Ameisen_> int rand() { return current_rand++ % RAND_MAX; }
[21:28:47] <Ameisen_> :)
[21:28:54] <rpav> heh
[21:28:58] <Ameisen_> I used RAND_MAX buckets, so it was out of the full range it could do
[21:29:07] <Ameisen_> deviation wasn't bad
[21:29:27] <kalven> what was RAND_MAX?
[21:29:30] <Juliu> Might still be slow and large
[21:29:41] <paul424> Juliu, ah I did what you said , and it seems that between diffrent game sessions -- SAVE and re-running the application the Tile layout is always the same. That's what I wanted , I thank you
[21:29:45] <Ameisen_> RAND_MAX on Windows is 0x7FFF
[21:30:02] <Juliu> paul424, you're welcome
[21:30:17] <kalven> trying to square that number with ~2M per bucket and 1B iterations
[21:31:10] <paul424> Juliu, only if that g++ would print a reasonable error info when working with const methods
[21:31:16] <Juliu> kalven, how can you get more buckets than RAND_MAX - RAND_MIN + 1 ?
[21:31:49] <Juliu> paul424, I don't use g++ so I don't have these problems :)
[21:31:59] *** Joins: _ShiftyLogic_ (~shiftylog@66.115.146.16)
[21:32:07] <Juliu> ... I have different problems instead :D
[21:32:11] <kalven> Juliu: why are you asking this?
[21:32:26] <Juliu> kalven, because I don't understand what you are suggesting
[21:34:13] <kalven> okay
[21:34:13] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[21:34:30] <Juliu> kalven, so will you elaborate what you meant?
[21:34:34] <kalven> no
[21:34:40] <Juliu> ok :/
[21:35:03] *** Joins: m_ben_ (~m_ben@user/m-ben/x-7429725)
[21:36:32] *** Quits: pa (~pah@user/pah) (Ping timeout: 246 seconds)
[21:37:16] *** Quits: npaperbot (~npaperbot@dodecahedron.m-ou.se) (Remote host closed the connection)
[21:37:23] *** Joins: npaperbot (~npaperbot@dodecahedron.m-ou.se)
[21:37:23] *** ChanServ sets mode: +v npaperbot
[21:38:47] *** Joins: pah (~pah@user/pah)
[21:38:47] *** Quits: m_ben (~m_ben@user/m-ben/x-7429725) (Ping timeout: 264 seconds)
[21:40:29] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[21:42:43] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[21:46:29] *** Joins: linexpert (~linexpert@104.248.118.188)
[21:51:46] *** Quits: andreasbuhr (~quassel@p548ddac6.dip0.t-ipconnect.de) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[21:54:40] <TheGuestMovie> I gotta implement an evaluation function that's based on a few dozen boolean inputs. Depending on the inputs, it outputs one of 20 results. I was able to simplify the implementation and checks/done in 200 lines, but I'm wondering if this was a good idea, if it's more maintainable to instead have some brute force montrosity that evaluated all 20
[21:54:40] <TheGuestMovie> outputs sequentially. (e.g. if (cond1 && cond2 && cond3 && cond4 && ...) return result3; else if (cond1 && !cond2 && !cond3 && ...) return result5; ...). Thoughts?
[21:55:19] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[21:55:29] <TheGuestMovie> I can't post it unfortunately
[21:56:16] <Juliu> TheGuestMovie, how many different booneans?
[21:56:25] <rpav> TheGuestMovie: if only there were some way to map a set of bits to some values
[21:56:43] <Juliu> rpav, lol
[21:56:50] *** pah is now known as pa
[21:56:53] *** Quits: linexpert (~linexpert@104.248.118.188) (Quit: Client closed)
[21:57:20] <rpav> even better if you could _load_ the mapping and it was like, 5loc and you could change the mapping without even having to recompile
[21:57:22] <TheGuestMovie> rpav: how does that help me write maintainable code?
[21:57:42] <rpav> TheGuestMovie: because `return map[key];` is pretty maintainable
[21:58:37] <rpav> or, really, like `if(auto it = map.find(key); ..) { .. } return some_default;` of course, but
[21:58:40] <TheGuestMovie> rpav: that implies you already wrote the code that generated the mapping
[21:58:54] <rpav> then you have a nicely formatted, maintainable file that you load into a map, and bam
[21:59:30] <Juliu> Seems TheGuestMovie does not want to answer me :(
[21:59:46] <TheGuestMovie> I think I'm missing something. Let's say my input conditions are "system 1 online" "system1 offline" "system1 property1 == true" "system1 propert1 == false" "systemN propertyN == true"
[22:00:22] <TheGuestMovie> Juliu: oops sorry, thought I did, I canceled my typing to answer rpav  :) about 45 in total
[22:01:10] <Juliu> TheGuestMovie, it seems you are looking for some scheme to simplify all your different combinations that lead to a certain result
[22:02:10] <TheGuestMovie> yeah. I wrote the simplification using my MENTAL ABILITIES and will be writing tests to hope it covers it. But I'm wondering if I should have done it in a way more maintainable by someone else to whom my simplification might not be obvious.
[22:03:02] <Juliu> If your simplifications are indeed simpler, this simpler version should actually be easier to understand for someone else
[22:03:06] <TheGuestMovie> it's barely obvious to me, I'll be relying on tests
[22:03:20] <TheGuestMovie> it's not that it's simpler, it's that I can take shortcuts to reduce the number of condition checks
[22:03:21] <rpav> yeah, a file that's like "system1 prop1", !"system2 prop2", ... = value
[22:03:46] <Juliu> rpav, that would be 2^45 entries
[22:03:53] <rpav> { set: [ "prop1", "prop5" ], off: ["prop3"], value: 42 }
[22:03:53] <geordi> error: expected identifier before string constant
[22:04:08] <rpav> or like whatever model fits your actual conditions
[22:04:15] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:05:03] <rpav> but take that, build keys out of each and test vs a map or whatever also fits your data .. it's hard to know without really seeing specifics or knowing odd cases
[22:05:23] <TheGuestMovie> rpav: what's the benefit of doing this in a text file instead of C++ like I mentioned above? It's still brute force in the end.
[22:06:08] <rpav> TheGuestMovie: it's not brute force at all, you could make like `key = 000001011110` (or series of keys, or whatever), then again you basically have `map.find(key)`
[22:06:28] <rpav> TheGuestMovie: the benefit is you can then maintain a nice, readable _data file_
[22:06:58] <kalven> or 00X0XX010011, I'm guessing some bits are ignored for certain conditions.
[22:07:02] <rpav> you can write easy checks to ensure duplicate conditions don't happen, test the code, make additions/etc
[22:07:15] <TheGuestMovie> ah, when I said brute force, I was talking about defining the (input -> output) data, not performance. I dont have performance concerns here, I'm optimizing for readability
[22:07:43] <rpav> well it's slightly brute force, but not knowing more about your data it's hard to say how you could maek that "nice," but at that point it's a UI problem not a data or maintainability problem
[22:08:00] <Juliu> TheGuestMovie, I think the most maintainable form is introducing some new variables that make sense(!), like notAllGatesClosed = gate1open or gate2open or gate3open, and then use these new variables at different places in your actual conditions
[22:08:06] <rpav> e.g. "system1.* == true, system2.prop3 == false -> 100"
[22:08:22] <rpav> you could have a gui tool or whatever worked for whoever's using it
[22:08:48] <rpav> but doing that _without_ data is impossible .. you're stuck with 200 lines of if-else that may break or have subtle bugs at any time
[22:10:02] <TheGuestMovie> is there some standard tool/format to model that data for this sort of situation? I figure there's gotta be
[22:10:02] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:10:17] <TheGuestMovie> if I'm gonna be using external files, might as well use something that someone can view in a GUI
[22:10:17] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:10:23] <rpav> can you say more about your data
[22:11:19] <rpav> i mean .. there are databases, spreadsheets, etc, but those are a lot more generalized than your specific thing most likely, and if your tool is _pretty_ specific, then probably something doesn't exist
[22:11:29] <TheGuestMovie> it's just properties/state from a few interrelated systems. Combination of states are meant to produce one of a few text values, ordered by priority
[22:11:53] <TheGuestMovie> the end result is showing 1 or 4 textual values that are a shortcut to which states the systems are in
[22:12:02] <TheGuestMovie> * 1 to 4
[22:12:07] <Juliu> TheGuestMovie, here is a list of methods to minimize your boolean formulas. Maybe that helps:   https://en.wikipedia.org/wiki/Logic_optimization#Circuit_minimization_in_Boolean_algebra
[22:12:33] <rpav> i don't know .. like that could apply to a lot of things, e.g. game flags and dialogue lines or choices or something
[22:13:09] <rpav> if your industry/topic/etc doesn't have an existing tool, i mean .. it probably wouldn't be a huge lift to write one, and if you need to maintain this stuff at all then likely worth the effort
[22:13:18] <TheGuestMovie> it's a minimalist dashboard of sorts for farm equipment
[22:13:19] <rpav> if it _is_ a game, there are probably systems
[22:13:34] <rpav> ahh neat
[22:14:54] <rpav> well assuming that doesn't exist, and you need to maintain it a lot, then like some kind of simple-ish input file shouldn't take more than a day or so to write and test
[22:15:03] <rpav> i mean maybe
[22:15:35] <rpav> if what you wrote will rarely need maintained and works as-is .. tossup maybe
[22:15:35] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:15:36] <TheGuestMovie> Juliu: checking them out, thanks. I'm sure there's gotta be a standard tool for that.
[22:18:09] <TheGuestMovie> https://en.wikipedia.org/wiki/Quine%E2%80%93McCluskey_algorithm
[22:18:25] <TheGuestMovie> in the end it's all brute force eh
[22:18:53] <rpav> well you can simplify your states but that's more a choice optimization, not a good interface for configuration
[22:19:21] <rpav> i'd think more "how can i reduce my _specification_ for relevant states"
[22:19:38] <TheGuestMovie> I think I'll go with the brute force approach, because then at least there's little room left for flaws in the developer's thinking
[22:19:45] <TheGuestMovie> instead of reducing
[22:19:47] <TheGuestMovie> it's all there on the table
[22:23:50] *** Quits: proller (~p@2a02:6b8:0:408:eef4:bbff:fe62:69c8) (Ping timeout: 260 seconds)
[22:24:20] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:30:06] *** Quits: pa (~pah@user/pah) (Ping timeout: 258 seconds)
[22:30:06] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:30:21] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:32:00] *** Joins: pah (~pah@user/pah)
[22:32:36] *** Parts: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it) ()
[22:36:12] <Juliu> TheGuestMovie, in the general case there is no method known to the public that is significantly faster in optimizing boolean formulas than a brute force approach, indeed
[22:36:12] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:36:22] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:36:56] <Juliu> But I doubt that your cases are this complicated
[22:38:37] *** Quits: KombuchaKip (~kip@192.252.230.5) (Quit: Leaving.)
[22:39:02] *** Joins: KombuchaKip (~kip@192.252.230.5)
[22:39:04] *** Quits: _ShiftyLogic_ (~shiftylog@66.115.146.16) (Quit: leaving)
[22:39:42] *** Joins: _ShiftyLogic_ (~shiftylog@66.115.146.16)
[22:41:40] *** Joins: wootehfoot (~wootehfoo@user/wootehfoot)
[22:41:40] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:42:23] *** Quits: Mooncairn (~mooncairn@user/mooncairn) (Ping timeout: 264 seconds)
[22:43:54] *** Quits: pah (~pah@user/pah) (Ping timeout: 258 seconds)
[22:50:27] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[22:51:39] *** Joins: pah (~pah@user/pah)
[22:53:12] <johnny> no negative nan please "if (b[3] == 'a') { ++begin; } // Convert "-nan" to "nan""
[22:55:18] <rpav> negative naan
[22:55:23] <johnny> i was thinking that too
[22:55:24] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[22:56:03] <johnny> so why is -nan even allowed as a return anyways?
[22:56:11] *** Joins: pah_ (~pah@host-79-54-72-130.retail.telecomitalia.it)
[22:56:23] <rpav> sign bit? why is there 0 and -0
[22:56:36] <johnny> sure, but at least 0 is actually a number
[22:56:47] *** Quits: pah (~pah@user/pah) (Ping timeout: 264 seconds)
[22:56:49] <rpav> but -0 is not a distinct number
[22:57:27] <johnny> is it just for easier debugging?
[22:57:33] <rpav> inf isn't "a number" though there is definitely +/- inf
[22:57:43] <rpav> no idea .. how does one actually produce a NaN now
[22:58:01] <rpav> division by zero _ought_ to produce it, but on here i get inf
[22:58:01] <johnny> i couldn't tell ya
[22:59:09] <johnny> see i went on a bit of a journey to provide similar output as QString::number(someFloat, 'g', shortestFloat) (or whatever hte 3rd param is really called) and i ended up seeing this
[22:59:17] <johnny> https://github.com/vgc/vgc/blob/ae0617ebaf7a591c0c0b25e8f4a5818edb8d1838/libs/vgc/core/format.h#L282
[22:59:48] <johnny> although qt does have similar code in regards to handling nan/-nan though
[23:00:06] <rpav> ok 0/0 _does_ do it, but _literal_ 0.0/0.0 is inf, wtf
[23:00:23] <rpav> oddly it produces -nan
[23:00:35] <rpav> maybe all nan is -
[23:00:57] <rpav> << std::nan
[23:00:57] <geordi> 0x4787a0
[23:01:28] <johnny> should have tried -0/0
[23:01:54] <johnny> numbers, what are they even good for
[23:02:14] <rpav> << f()/f(); auto f() { return 0.0f; }
[23:02:15] <geordi> -nan
[23:02:33] <rpav> << 0.0f/0.0f
[23:02:34] <geordi> -nan
[23:02:38] <rpav> 🤔
[23:02:52] <johnny> well i guess you learned something about nan then
[23:03:48] <rpav> ah, non-0 divided-by-zero is inf (still, wtf)
[23:04:12] <rpav> i don't think i've seen a non-"negative" nan yet
[23:04:30] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[23:05:02] <rpav> << std::nan("");
[23:05:02] <geordi> nan
[23:05:27] <johnny> good job C+
[23:05:30] <johnny> c++*
[23:07:11] *** Quits: wootehfoot (~wootehfoo@user/wootehfoot) (Ping timeout: 246 seconds)
[23:07:55] <InPhase> << std::nan("1"), std::nan("-1"), std::nan("foo");
[23:07:56] <geordi> nan, nan, nan
[23:08:11] <InPhase> Ok...  Batman.
[23:08:28] <rpav> easy cheesy
[23:12:00] *** Joins: CaCode_ (~CaCode@user/cacode)
[23:12:01] <InPhase> { cout << hex << X(std::nan("1")), X(std::nan("-2")), X(std::nan("foo")); } auto X(double n) { uint64_t ui; std::copy((char*)&n, 8+(char*)&n, (char*)&ui); return ui; }
[23:12:02] <geordi> 7ff8000000000001, 7ff8000000000002, 7ff8000000000000
[23:12:15] <InPhase> So negatives are ignored, and unrecognized strings are 0.
[23:12:32] <Juliu> << 0/0
[23:12:32] <geordi> warning: division by zero
[23:13:06] <johnny> why is division by zero a warning in C++ anyways?
[23:13:14] <Juliu> << 0.0/0.0
[23:13:15] <geordi> -nan
[23:13:16] *** Quits: CaCode_ (~CaCode@user/cacode) (Remote host closed the connection)
[23:13:47] <Juliu> << -0.0/0.0
[23:13:48] <geordi> -nan
[23:13:49] <johnny> ah.. you can't rely on exceptions, so maybe that's why
[23:13:53] <InPhase> johnny: Well it's UB.
[23:14:11] *** Quits: CaCode (~CaCode@user/cacode) (Ping timeout: 264 seconds)
[23:14:35] <johnny> i've seen it as quite defined behaviour in other languages such that it's an exception or error of some kind
[23:15:01] <Juliu> << -(0.0/0.0)
[23:15:01] <geordi> nan
[23:15:26] <InPhase> johnny: C++ follows the "you don't pay for what you don't need" philosophy under the assumption that you don't need reliable behavior.
[23:15:33] <rpav> other languages may have provisions for such .. anything not portable behavior is probably UB in C
[23:15:46] <johnny> yeah..it's gotta be something like that
[23:16:23] <johnny> i figured it might be something like a segfault a total crash
[23:16:35] <rpav> it might be with floating point exceptions enabled
[23:16:40] <rpav> SIGFPE
[23:16:50] <rpav> i really really wish it was more often ;P
[23:17:01] <Juliu> << (1.0/0.0) / (1.0/0.0)
[23:17:02] <geordi> -nan
[23:17:03] <rpav> i think there's a way to enable that stuff but i forget if i ever did where it mattered
[23:17:42] <Juliu> << (1.0/0.0) - (1.0/0.0)
[23:17:43] <geordi> -nan
[23:18:01] *** Joins: proller (~p@2002:50f0:d845:10:41a5:ca2e:e623:f4b4)
[23:18:22] <TinoDidriksen> SIGFPE is usually integer division by zero, not floating point.
[23:18:29] <rpav> oh is it? ;/
[23:18:38] <rpav> er.. wait why is "FPE" then
[23:19:28] <TinoDidriksen> "The SIGFPE signal reports a fatal arithmetic error. Although the name is derived from “floating-point exception”, this signal actually covers all arithmetic errors, including division by zero and overflow."
[23:19:38] <InPhase> Floating point divide by zero is not an error.  There's a defined result for this.
[23:19:59] <rpav> ... ah yeah i see .. that makes sense, and i'd take either tbh
[23:19:59] *** Quits: Kebianizao (~Kebianiza@188.127.161.90) (Read error: Connection reset by peer)
[23:20:03] <InPhase> You could choose definitions for integer divide by zero, such as max int, but this is not standard.
[23:20:30] <rpav> InPhase: the point is it's _probably_ an _actual_ error and it's vastly more useful to knwo about it when it happens than accumulate nans
[23:20:30] <Juliu> << (1.0/0.0) + (1.0/0.0)
[23:20:30] <geordi> inf
[23:20:30] *** Quits: tm604 (~tom@perlsite.default.entitypark.uk0.bigv.io) (Remote host closed the connection)
[23:20:50] <rpav> tracking down the source of nans can be an incredible pita
[23:21:15] <Juliu> I like pita and naan and also normal bread
[23:21:16] <InPhase> rpav: That is frequently true, yes.
[23:21:38] <rpav> i'd rather track down segfaults ;/
[23:21:41] <InPhase> rpav: I previously found errors in a peer reviewed publication that I traced to a divide by zero in someone's code.
[23:21:56] <rpav> InPhase: eesh .. nice catch though ;)
[23:22:13] <InPhase> rpav: There were entire explanatory theories being created to explain the results of that divide by zero in terms of real world phenomena, but it wasn't even real.
[23:22:24] <rpav> "we found FTL!" "is it NaN?" "..."
[23:22:33] *** pah_ is now known as pa
[23:22:44] <Juliu> peer reviewed = some student assistent with zero motivation looked at it for 5 minutes
[23:22:54] *** Quits: pa (~pah@host-79-54-72-130.retail.telecomitalia.it) (Changing host)
[23:22:54] *** Joins: pa (~pah@user/pah)
[23:23:00] <InPhase> rpav: Actually, now that I think about it, that happened twice.  Both times there were explanatory theories being created.
[23:23:15] <rpav> InPhase: crappy .. really should default that stuff on more ;/
[23:23:57] <InPhase> rpav: It was only noticed by me because in both instances I was reimplementing the same thing from scratch.
[23:24:07] <InPhase> rpav: And...  I did not divide by zero, I checked for it.
[23:24:19] *** Quits: skapata (~Skapata@user/skapata) (Remote host closed the connection)
[23:24:23] <Juliu> - (0.0/0.0) - (0.0/0.0) should result in 2 nan
[23:25:08] <Juliu> InPhase, well done
[23:25:10] <rpav> replication is important!
[23:25:22] <InPhase> Well at first it looked like a failure to replicate.
[23:25:33] <InPhase> But, yeah.
[23:25:42] <Juliu> Aint nobody got time for replications
[23:25:55] <InPhase> Mostly I just wanted clean code I trusted.
[23:26:27] <Juliu> InPhase, you incorrectly reproduced their error
[23:30:44] *** Joins: RoKenn (~RoKenn@2001:a61:3505:d101:8921:8beb:ebb8:6ab2)
[23:30:44] *** Quits: RoKenn (~RoKenn@2001:a61:3505:d101:8921:8beb:ebb8:6ab2) (Changing host)
[23:30:44] *** Joins: RoKenn (~RoKenn@user/rokenn)
[23:34:13] *** Quits: sord937 (~sord937@gateway/tor-sasl/sord937) (Quit: sord937)
[23:34:14] *** Joins: Kebianizao (~Kebianiza@188.127.161.90)
[23:37:47] <rpav> / /nick no-one
[23:37:56] <rpav> "hi you can trust me! everyone says so!"
[23:38:23] <rpav> homer for the modern era
[23:40:11] <Juliu> Homer Simpson said, if you don't succeed on the first try, give up. Sounds like a real philosopher
[23:49:13] *** Joins: blackout69 (~blackout6@net-31-156-121-187.cust.vodafonedsl.it)
[23:49:51] *** Joins: pull (~tcz@91.150.165.88)
[23:54:47] *** Quits: X-Scale (~ARM@46.50.5.8) (Ping timeout: 260 seconds)
[23:55:43] *** Joins: vdamewood (~vdamewood@fedora/vdamewood)
[23:57:28] *** Joins: X-Scale (~ARM@50.77.166.178.rev.vodafone.pt)
[23:57:52] *** Joins: markong (~kvirc@213.146.188.203)
