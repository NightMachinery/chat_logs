[00:13:29] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[00:15:08] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[00:29:33] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 276 seconds)
[00:32:25] *** Quits: dfdx (~F@user/dfdx) (Remote host closed the connection)
[00:35:55] *** Quits: mnl (~mnl@user/mnl) (Ping timeout: 256 seconds)
[00:39:49] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[00:42:12] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[00:48:26] *** Joins: mnl (~mnl@user/mnl)
[01:00:47] *** Quits: mnl (~mnl@user/mnl) (Quit: cya~)
[01:06:54] *** Quits: debianero (~debianero@60.132.134.77.rev.sfr.net) (Quit: Leaving)
[01:07:36] *** Joins: peddie (~peddie@2001:470:69fc:105::25d)
[01:24:47] *** Joins: capjack[m] (~raffaem@2001:470:69fc:105::393)
[01:24:47] *** Joins: saltrocklamp[m] (~hexology@user/hexology)
[01:47:51] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[01:51:42] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[02:03:17] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Ping timeout: 240 seconds)
[02:12:40] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[02:38:57] *** Quits: usr725635 (~User@cpe-45-47-86-32.twcny.res.rr.com) (Ping timeout: 240 seconds)
[02:56:57] *** Quits: palasso (~palasso@user/palasso) (Quit: I am not a quitter!)
[04:27:43] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[04:29:18] *** Quits: rinzewind (~rinzewind@user/rinzewind) (Quit: leaving)
[04:40:57] *** Quits: m5zs7k (aquares@web10.mydevil.net) (Ping timeout: 256 seconds)
[05:56:39] *** Joins: rickyrick (~rickyrick@S0106bc3e07341783.vf.shawcable.net)
[06:07:39] *** Quits: rickyrick (~rickyrick@S0106bc3e07341783.vf.shawcable.net) (Ping timeout: 250 seconds)
[06:50:34] *** Joins: rickyrick (~rickyrick@S0106bc3e07341783.vf.shawcable.net)
[07:09:03] *** Joins: m5zs7k (aquares@web10.mydevil.net)
[07:25:37] *** Quits: rickyrick (~rickyrick@S0106bc3e07341783.vf.shawcable.net) (Ping timeout: 240 seconds)
[07:40:53] *** Joins: twrk_ (~user@user/twrk)
[07:43:05] *** Quits: twrk (~user@user/twrk) (Ping timeout: 256 seconds)
[07:52:48] *** Quits: mefistofeles (~mefistofe@user/mefistofeles) (Quit: Hay te huacho!)
[08:07:09] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 276 seconds)
[08:19:05] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[08:50:09] *** Quits: drbeco (~beco@2804:351c:dd01:b700:1b03:6b85:20d4:ad73) (Quit: Leaving)
[09:06:58] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[11:34:37] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Ping timeout: 240 seconds)
[11:36:09] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[11:40:31] *** Joins: palasso (~palasso@user/palasso)
[11:57:50] *** Quits: redrum88 (redrum88@user/redrum88) (Ping timeout: 252 seconds)
[12:06:39] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[12:20:51] *** Joins: redrum88 (redrum88@user/redrum88)
[13:04:44] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Quit: :^))
[14:09:39] *** Joins: mnl (~mnl@user/mnl)
[14:22:12] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 276 seconds)
[14:23:21] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[14:25:15] *** Joins: usr725635 (~User@cpe-45-47-86-32.twcny.res.rr.com)
[15:16:09] *** Quits: nvuafo (~usrnvuafo@user/nvuafo) (Remote host closed the connection)
[15:21:21] *** Joins: nvuafo (~usrnvuafo@user/nvuafo)
[16:05:09] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Remote host closed the connection)
[16:05:35] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[16:26:19] *** Joins: debianero (~debianero@60.132.134.77.rev.sfr.net)
[16:30:04] *** Joins: rinzewind (~rinzewind@user/rinzewind)
[17:46:42] *** Quits: confuzeus (~h_m@186-149-117-154.bitcointernet.co.za) (Remote host closed the connection)
[18:22:13] *** Joins: mefistofeles (~mefistofe@user/mefistofeles)
[18:24:40] *** Quits: mnl (~mnl@user/mnl) (Quit: cya~)
[18:28:20] *** Joins: confuzeus (~h_m@186-149-117-154.bitcointernet.co.za)
[18:38:31] <nvuafo> how would you compare a model which is partitioned into two parts against the full model?\
[18:52:11] <fendur> can you describe _how_ it's partitioned?
[19:01:17] <nvuafo> fendur: the data is partitioned with like the smallest 20 and the largest 20 predictors ( or explanatory points).
[19:01:29] <nvuafo> each partitioned is modeled under a simple linear regression.
[19:01:54] <nvuafo> I want to treat these two partitioned models as one, to compare against another model.
[19:02:34] <fendur> nvuafo: i'd rather build a single model that incorporates that distinction.
[19:02:55] <nvuafo> are there programs or libraries for that?
[19:02:59] <fendur> does that mean you allow the parameters to vary by "size of predictor"? (not sure wehat "size of predictor" means, actually.
[19:04:23] <nvuafo> for example, say the predictors under the full data set is (1,2,3,...,40). I partition by smallest 20 (1,2,3,...20) and largest 20 (21,22,...,40)
[19:05:16] <nvuafo> then build a linear regression model for each partition. But how do we treat them as one?
[19:05:34] <nvuafo> so I can compare against another model
[19:06:01] <nvuafo> model(partition1, partition 2) against full_model
[19:08:16] <fendur> it sounds like the result of that distinction is that your models fit a different parameter depending on whether the predictor surpasses a threshold. this could be incorporated into a single model with an interaction between that variable and a separate indicator that says whether the value is greater than the thereshold
[19:09:31] <fendur> alternatively, i believe you could just incorporate the predictors in two separate variables valued at their original value if on the "correct" side of the threshold and zero otherwise.
[19:09:40] <fendur> "correct" probably not the right word. but maybe you'll get my drift
[19:30:51] <Bayes> I need to make a point to use metaprogramming more
[19:31:58] <Bayes> nvuafo it seems to me that despite having "two partitioned models", you need to combine them somehow to create _one_ prediction
[19:32:24] <Bayes> and then compare that _one_ prediction vs the prediction generated by the full model
[19:32:37] *** Parts: zaratustra_ (~zaratustr@idlerpg/player/zaratustra) (WeeChat 2.3)
[19:33:15] <Bayes> it's one so much that you compare /models/, but a quantity generated by that model. So you still need to bridge that gap and decide how you want to use ur partitioned models to generate a prediciton
[19:33:19] <Bayes> prediction even
[19:47:01] <fendur> im still confused about how it was accomplished. what if one predictor was under the threshold and the other was over it? where does that data point go?
[19:47:17] <fendur> which probablyu means i don't understand some basics of the problem
[19:50:59] <fendur> ugh. finalizing one of the most challenging peer review responses of my life. 
[19:51:35] <fendur> probably second worst. reminds me why i can't stand leading papers.
[19:52:01] <Bayes> sorry to hear that fendur
[19:52:07] <Bayes> what is it that made it challenging?
[19:52:39] <fendur> a reviewer that has great confidence in some not so solid beliefs. Isn't that always the case? :)
[19:52:45] <Bayes> was it like a too-good critic of your submission that made it challenging?
[19:53:02] <Bayes> oh ok, I was hoping you had lucked out and get that reasonable reviewer that knows their limits out there
[19:53:27] <fendur> demanding sensitivity anlyses that require revising data draw scripts from highly secured data that we don't have suepr easy access to.
[19:53:54] <fendur> this reviewer is asking a lot. it's in the name of good science
[19:53:58] <fendur> but it's a lot
[19:54:26] <Bayes> highly secured data as in national security or as in "very obscure corporate structure"
[19:54:26] <fendur> and their confidence in errors we've made have not been borne out at all.
[19:54:41] <fendur> medical data
[19:54:55] <Bayes> hm yeah I get that, it puts you in a situation where... damned if you do damned if you don't
[19:55:45] <Bayes> as in... "sure it's an okay concern generally speaking but in this case it's not strong enough to lift all the weight you're asking"
[19:55:51] <Bayes> ^ damned if you do
[19:56:13] <Bayes> I wish more people understood the concept of reasonability in the stuff their ask
[19:56:30] <Bayes> hopefully they'll come around fendur, fingers crossed
[19:57:02] <fendur> im fininshing the response to the second review. i will poop my pants if a third one comes
[19:58:12] <fendur> i mean i already revised once. this is the second time.
[19:58:52] <Bayes> dang man that's some PNAS level publishing
[19:59:07] <nvuafo> Bayes: Yeah that would be my issue. How do you combine them? Is there some sorta function or package for that?
[19:59:40] <fendur> Bayes: Am. J. Epidemiology. Not PNAS level, but pretty good.
[19:59:50] <Bayes> nvuafo I'm afraid that's a methodological question and not so much a programming language question that would be solved by a function, package, or pattern
[20:01:00] <Bayes> fendur make health great again!
[20:01:49] <fendur> \o/
[20:02:25] <Bayes> nvuafo typically you either want to assign any new data point to one of your partitions and use it to generate the prediction, or have each partition make one prediction and combine it somehow (eg, mean, weighted mean)
[20:02:47] <Bayes> nvuafo but it seems it needs some thought on the specifics of your modeling strategy
[20:04:05] <nvuafo> https://stats.stackexchange.com/questions/9027/is-there-an-easy-way-to-combine-two-glm-models-in-r so something like this?
[20:06:07] <nvuafo> could you decipher which would be best by doing anovas on each model? so anova(modelpartion1), anova(modelpartition2), and anova(fullmodel)?
[20:06:40] <nvuafo> I'm not sure if that's one methodology that is used.
[20:12:28] <Bayes> nvuafo sure, that's one way to do it
[20:13:20] <Bayes> not really anova, which is used to study "effects" of predictors in the model, but more like `predict(modelpatition1, Xnew)`
[20:13:58] <Bayes> but really nvuafo it'd seem to me that you need to figure out your modeling strategy before getting into the R code
[20:14:34] <Bayes> feels more like a stats question than a programming question
[20:14:47] <Bayes> sorry to be that guy :(
[20:20:42] <nvuafo> No, it's fine. I can move this over to ##statistics.
[20:24:22] <nvuafo> In R, what is a way a nice tool to obtain adjusted R^2 from my custom fitted values. I'm interested in obtain SSR and SSE to calculate adjusted R^2.
[20:26:38] <Bayes> nvuafo https://www.statology.org/sst-ssr-sse-in-r/ step 3
[20:27:08] <Bayes> `sse <- sum((fitted - actual)^2)` is as easy as it gets
[20:27:51] <nvuafo> yeah I'm just lazy lol
[20:28:00] <nvuafo> but I'll do it manually.
[20:28:09] <Bayes> ¯\_(ツ)_/¯
[20:28:47] <Bayes> I mean you just got a random statistician to google that for you, how much lazier can you get
[20:31:53] <Bayes> is there any kind of more or less homogeneous ML pack a la scikit-learn?
[20:32:20] <Bayes> I mean there's caret, but caret is just an interface and I believe scikit-learn is a homogeneous implementation of the methods
[20:32:27] <Bayes> I could be wrong tho
[20:34:25] <Bayes> I'm going by this https://cran.r-project.org/web/views/MachineLearning.html
[20:34:33] <Bayes> "meta packages"
[21:35:10] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[21:49:53] *** Quits: OnlineCop (~OnlineCop@user/onlinecop) (Remote host closed the connection)
[21:50:07] *** Joins: OnlineCop (~OnlineCop@user/onlinecop)
[21:51:02] *** Parts: OnlineCop (~OnlineCop@user/onlinecop) ()
[22:15:38] *** Joins: resistor4u (~resistor4@2601:5c2:102:33d0:6902:eb09:2666:1193)
[22:46:37] <resistor4u> blanking here, but in rmarkdown i can specify all the libs needed at one time
[22:46:56] <resistor4u> but there are some libs that replace or sub out functions of others
[22:47:33] <resistor4u> should i be worried about this when some code runs later in the document? 
[22:47:44] <resistor4u> i guess it would let me know if it errors out
[22:55:30] <fendur> you can. but i'd manage them throughout the script
[22:55:55] <fendur> like unload them after you're done with them or load them in an order throughout the script that suits your needs
[23:01:59] <resistor4u> 10-4
[23:02:26] <resistor4u> i haven't advanced to using sep. scripts yet, althgout prolly should
[23:08:06] <fendur> that's not my suggestion. but that can be a helpful technique to clean up the Rmd.
[23:09:32] <rickyrick> I just have an initial chunk that loads packages in a reproducible order
[23:09:48] <rickyrick> That way I can always manually specify pkg::function later
[23:10:05] <rickyrick> IIRC unloading packages and their namespaces are a bit annoying
[23:14:03] <fendur> right. i second that. be explicit with the function call.
[23:39:21] <Bayes> remember when they told you for first time that "data.frames are just lists"?
[23:39:54] <Bayes> well, I never considered that this would be a valid data frame https://i.imgur.com/HYLJZ2p.png o.o
[23:40:48] <rickyrick> lol
