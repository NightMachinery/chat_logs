[00:00:09] *** Quits: funhouse (~funhouse@user/funhouse) (Quit: Client closed)
[00:12:37] *** Joins: zumba_addict (~zumba_add@2601:240:4500:8320:224:1dff:fec8:64f6)
[00:23:46] *** Joins: yuesbeez (uid458354@id-458354.tinside.irccloud.com)
[00:48:41] *** Quits: acidsys (~LSD@2a03:4000:55:d20::3) (Excess Flood)
[00:49:14] *** Quits: freeworld (~vit@chello085216193138.chello.sk) (Quit: Konversation terminated!)
[00:52:59] *** Joins: acidsys (~LSD@2a03:4000:55:d20::3)
[00:58:19] <litheum> doug16k: at some point you're gonna have to take all the information you find in the documentation and start filling in the gaps for yourself. i wouldn't trust my application to the interpretation of internet strangers when it comes to something pretty important and very detailed like this
[01:02:57] *** Quits: ikwyl6 (~ikwyl6@142.167.173.36) (Ping timeout: 240 seconds)
[01:03:24] *** Quits: sharpertool (sid80151@id-80151.hampstead.irccloud.com) (Ping timeout: 240 seconds)
[01:03:28] *** Quits: Lewix__ (sid158496@id-158496.tinside.irccloud.com) (Read error: Connection reset by peer)
[01:03:35] *** Joins: Lewix__ (sid158496@id-158496.tinside.irccloud.com)
[01:04:12] *** Quits: braxas (sid508886@id-508886.lymington.irccloud.com) (Ping timeout: 240 seconds)
[01:04:36] *** Quits: relipse (sid16131@id-16131.tinside.irccloud.com) (Ping timeout: 240 seconds)
[01:05:10] *** Joins: ikwyl6 (~ikwyl6@195.206.105.2)
[01:05:35] *** Joins: sharpertool (sid80151@id-80151.hampstead.irccloud.com)
[01:05:56] *** Joins: braxas (sid508886@id-508886.lymington.irccloud.com)
[01:06:02] *** Joins: relipse (sid16131@id-16131.tinside.irccloud.com)
[01:08:53] *** Quits: acidsys (~LSD@2a03:4000:55:d20::3) (Excess Flood)
[01:09:31] *** Quits: ikwyl6 (~ikwyl6@195.206.105.2) (Client Quit)
[01:09:47] *** Joins: ikwyl6 (~ikwyl6@195.206.105.2)
[01:10:04] *** Joins: acidsys (~LSD@2a03:4000:55:d20::3)
[02:29:18] *** Joins: lsrtl_ (~lsrtl@user/lsrtl)
[02:31:37] *** Quits: lsrtl (~lsrtl@user/lsrtl) (Ping timeout: 240 seconds)
[02:45:45] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Ping timeout: 252 seconds)
[03:06:21] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[03:31:50] *** Joins: funhouse (~funhouse@user/funhouse)
[03:40:04] *** Joins: ferdna (~ferdna@user/ferdna)
[03:50:11] *** Joins: coder7of9 (~coder7of9@user/coder7of9)
[03:50:45] <KnowledgeShark> Isotopp: I am on 976334 out of 1.8 million (I am getting 1 output of count / case id per second average); I calculated and 1 million more should take 11.5 days. Do you know any ways to speed the loader up? At first it was going very fast; then it slowed down. It appears heavy on CPU. I ran it in a Virtual Machine (could be the reason why); CPU is max. I appreciate the details you last broke down; some of which I do not understand and some I do.
[03:50:45] <KnowledgeShark> Again, thanks!
[03:54:03] <coder7of9> i have table "values" with columns tea(tinyint), coffee(tinyint) and table mapping with  columns field,value,text   and rows  tea, 0, none  :   tea, 1, one cup :   tea, 2, tow cups :   tea, 3, more than two cups   ... coffee etc     can i pull the text matched to the values  in sql or is it betst to pull the data and then do a
[03:54:04] <coder7of9> second query to get the text
[04:06:31] <thumbs> coder7of9: what is the expected output?
[04:07:44] <coder7of9> more than two cups
[04:08:00] <thumbs> coder7of9: be more specific. Provide a clear example
[04:11:09] <coder7of9> i think this is too confusing to describe here and i can  make a paste   but an example  would be     SELECT text as tea FROM values LEFT JOIN mapping ON mapping.value = values.tea AND values.field = 'tea';
[04:11:41] <coder7of9> this works but if i have a half dozen fields it is not proactical
[04:11:46] <coder7of9> practical
[04:12:06] <thumbs> coder7of9: described the desired output clearly, again
[04:12:10] <thumbs> describe*
[04:12:23] <coder7of9> i will male a paste
[04:12:26] <coder7of9> make
[04:21:09] <coder7of9> https://controlc.com/41c7c4fe
[04:21:39] <coder7of9> this is an unrealistic example for a table with many items to map from integers to text.
[04:22:34] <coder7of9> obviously i could do a data pull from items and another from mapping and then loop in code. i thought to see if i could so it in sql first
[04:30:50] <thumbs> and the actual desired output?
[04:31:05] <thumbs> maybe I should ask for it 7 times
[04:31:33] <coder7of9> it is in the paste    i wish to reaplce the int value with text from another table
[04:32:18] <coder7of9> so if column tes = 2   and the mapping table has field tea value 2 and text two cups
[04:33:15] <coder7of9> thsi code in the paste works but it cannot scale to a dozen fields and 100000 rows
[04:33:20] <thumbs> still doesn't tell me what output you are expecting
[04:33:32] <thumbs> can you show a grid view of what you need?
[04:33:46] <thumbs> or, alternately, explain it better, in plain English terms
[04:33:58] <coder7of9> / for items.tea = 2:   outputs "two cups"
[04:34:13] <thumbs> a single string, 'two cups'?
[04:34:17] <coder7of9> yes
[04:34:25] <thumbs> so what is the problem with that?
[04:34:36] <coder7of9> two cups instead of in t 2
[04:35:24] <thumbs> where does 'in', 't' and '2' come from here?
[04:35:34] <coder7of9> int 2
[04:36:00] <thumbs> so select value instead of textvalue?
[04:37:17] <thumbs> it is always incredibly frustrating to get proper questions and requirements out of you
[04:37:32] <coder7of9> did you look at the paste
[04:37:49] <thumbs> yes. Your requirements are not clear.
[04:49:54] <coder7of9> here is a clear example
[04:49:55] <coder7of9> https://controlc.com/fcd90617
[04:50:18] <coder7of9> but i need something like this to scale to many fields
[04:51:35] <coder7of9> small error in the field name
[04:51:36] <coder7of9> https://controlc.com/index.php?act=submit
[04:51:54] <coder7of9> https://controlc.com/86c951d8
[04:52:00] <thumbs> so I see it returns two rows. What did you expect?
[04:52:52] <coder7of9> this is a crude example   i need to scale this for multiple fields and rows.
[04:53:44] <thumbs> sigh, still not clear. Maybe you want a pivot, maybe you want group_concat(). Impossible to tell
[04:53:50] <coder7of9> i should redesign the mapping table to have the same column names
[04:54:11] <coder7of9> yes a pivot
[04:54:22] <thumbs> so you want a dynamic pivot?
[04:54:46] <thumbs> do you know all the possible values?
[04:55:30] <coder7of9> yes i know all the values and text
[04:55:32] <coder7of9> just looking at this example to get the text for both tea and sugar in the sql is not intuitive
[04:56:15] <thumbs> mapping.field IN ('tea','sugar')
[04:56:44] <thumbs> but without the final desired output, we can't give you the answer
[04:58:20] <coder7of9> using these 2 tables  i would have a similar output for all fields where the text replaces the int value
[04:58:28] <coder7of9> i will look at mapping
[05:01:02] <coder7of9> perhaps the most efficient way would be to hard code the values in the sql for each field...   however this is not a great approach for maintainability.   still it is better than looping in code
[05:01:04] <coder7of9> thanks
[05:02:10] *** Quits: coder7of9 (~coder7of9@user/coder7of9) (Quit: Client closed)
[05:02:27] <thumbs> sigh
[06:56:28] *** Joins: Jonno_FTW (~come@user/jonno-ftw/x-0835346)
[06:57:05] <Jonno_FTW> hello, I'm using event_scheduler, my event occurs every hour, what happens if 1 execution of this event takes longer than 1 hour? does it just start another one?
[07:00:42] *** Quits: passage (~passage@user/passage) (Quit: Lost terminal)
[07:05:44] *** Joins: passage (~passage@user/passage)
[07:07:16] *** Joins: Emet-Selch (~haise01@user/haise01)
[07:10:41] *** Quits: Azem (~haise01@user/haise01) (Ping timeout: 256 seconds)
[07:43:34] *** Quits: yuesbeez (uid458354@id-458354.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[08:38:40] *** Quits: ferdna (~ferdna@user/ferdna) (Quit: Leaving)
[09:45:24] *** Quits: adas (adas@adas.shelltalk.net) (Ping timeout: 252 seconds)
[09:47:05] *** Quits: litheum (~kolbe@user/kolbe) (Ping timeout: 256 seconds)
[09:48:41] *** Joins: litheum (~kolbe@user/kolbe)
[09:52:14] *** Joins: adas (adas@adas.shelltalk.net)
[10:28:45] *** Joins: Naktibalda (~Naktibald@88.135.22.17)
[10:50:07] *** Quits: jamiejackson (~jamiejack@131.106.140.145) (Quit: Connection closed)
[10:57:23] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[10:58:09] *** Joins: Junxter (~Junxter@222.95.164.193)
[11:11:22] <skyfall> I'm curious how a table with multiple primary keys work. In this case: https://stackoverflow.com/a/1590611/13217668 the table `salaries` include two primary keys `dep_id` and `an_id`, but why do we need to have two primary keys? Like, what are the use case of this? I know a table can only have a single primary key which would uniquely identify a
[11:11:22] <skyfall> row in the table (and is unique to the entire table).
[11:16:55] <Naktibalda> it hasn't got multiple primary key, it has one composire primary key
[11:17:22] <Naktibalda> the combination of 2 fields uniquely identifies the row
[11:18:34] <Naktibalda> all the answers to that question say that you can have only one primary key
[11:25:56] *** Joins: palasso (~palasso@user/palasso)
[11:28:25] <ss23> As a real world example, you could imagine that to unqiuely identify a function, you can use the namespace of the function and the name of the function. Neither row individually is a primary key for a function, but together, it is. Not super real world, but might help conceptualy, skyfall
[11:29:40] *** Joins: [twisti] (~twisti@toadwater.com)
[11:30:47] <[twisti]> i have an odd phenomenon: during using mysqldump, i (sometimes, cant figure out what causes it) the error `mysqldump: Couldn't execute 'show table status like 'cardinal\_directions'': Unknown database 'my_database' (1049)`
[11:30:55] <[twisti]> the two '' are verbatim from the error
[11:31:31] <[twisti]> it dumps all the other stuff from that database just fine, and wtf kind of error is that, unknown database, when it dumps other things from the database in the same invocation ?
[11:32:39] <[twisti]> i use the `--databases my_database` syntax, for what its worth
[11:45:30] *** Quits: Furai (~Furai@furai.pl) (Quit: WeeChat 3.4)
[11:47:41] *** Joins: _xxoxx (~Junxter@222.95.164.193)
[11:47:42] *** Quits: _xxoxx (~Junxter@222.95.164.193) (Remote host closed the connection)
[11:49:57] *** Joins: Furai (~Furai@furai.pl)
[11:50:53] *** Quits: Junxter (~Junxter@222.95.164.193) (Ping timeout: 256 seconds)
[13:02:15] <lembron> [twisti] how big is it? / long does it take? - any --force / --quick and there like?
[13:08:31] <[twisti]> lembron: thanks, already figured it out via another channel - we are dumping and reimporting under a different name, and something went wrong with the renaming, so we were reimporting the dump (which includes a DROP DATABASE) into the very table we were dumping, mid dump, thats why the error appeared (and was actually correct)
[13:09:23] <lembron> [twisti] noice - and also ouch! - good to hear tho =)
[13:10:28] <lembron> just wanted to poke into that corner as ive seen "funny things happening" once your dump is a few hundret gigs and take over an hour even on nvme ;-)
[13:17:30] *** Quits: acidsys (~LSD@2a03:4000:55:d20::3) (Excess Flood)
[13:19:29] *** Joins: acidsys (~LSD@2a03:4000:55:d20::3)
[13:24:53] <Isotopp> KnowledgeShark: databases keep indexes in memory. this database is using the innodb buffer pool to keep indexes and data in memory
[13:25:27] <Isotopp> you need to check the size of your vm, the size of the mysqld process and increase the innodb_buffer_pool_size variable as much as possible, BUT under no circumstances must the database swap.
[13:25:37] <Isotopp> If you are in a VM, maybe use a larger VM with more memory
[13:26:05] <Isotopp> If you are willing to take the risk (it is a toy project, as I understand it) you can switch the database to YOLO mode
[13:26:18] <Isotopp> and set innodb_flush_log_on_trx_commit = 2.
[13:26:39] <Isotopp> that will reduce the number of disk writes, and make you less tightly coupled to the disk performance.
[13:27:15] <Isotopp> if the database is in AWS, disk performance of EBS is limited by EBS volume size
[13:27:46] <Isotopp> if you are willing to use EC2 instead of AWS RDS mysql consider using a i3.4xlarge instead of a db.m5.8xlarge
[13:28:18] <Isotopp> this instance has local NVME and can write to disk much more quickly than EBS can. Or you consider provisioning EBS io volumes instead gp volumes instead
[13:28:34] <Isotopp> otoh, this has cost and may not be suitable for a hobby thing
[13:29:10] <Isotopp> where is your data directory located and what type of storage does your vm provide? what is your memory size and mysqld process size ?
[13:31:34] <[twisti]> YOLO mode :D
[13:43:25] *** Quits: kuhilas (~kuhilas@2001:470:69fc:105::3040) (Quit: Bridge terminating on SIGTERM)
[13:43:27] *** Quits: Celmor[m] (~celmor@2001:470:69fc:105::434) (Quit: Bridge terminating on SIGTERM)
[13:43:28] *** Quits: Hansuke[m] (~hansukema@2001:470:69fc:105::1:86bb) (Quit: Bridge terminating on SIGTERM)
[13:43:28] *** Quits: Mids_IRC (~midfairyd@2001:470:69fc:105::3f22) (Quit: Bridge terminating on SIGTERM)
[13:43:29] *** Quits: Mushfiq[m] (~mushfiqma@2001:470:69fc:105::1:b3f7) (Quit: Bridge terminating on SIGTERM)
[13:48:08] *** Joins: kuhilas (~kuhilas@2001:470:69fc:105::3040)
[14:09:52] *** Quits: bytestream (~bytestrea@user/bytestream) (Remote host closed the connection)
[14:17:02] *** Joins: Junxter (~Junxter@222.95.164.193)
[14:19:43] *** Joins: Celmor[m] (~celmor@2001:470:69fc:105::434)
[14:19:43] *** Joins: Hansuke[m] (~hansukema@2001:470:69fc:105::1:86bb)
[15:18:24] *** Joins: lara99 (~lara99@93-36-163-139.ip61.fastwebnet.it)
[15:19:40] *** Joins: DrowningElysium (uid190788@user/drowningelysium)
[15:20:40] *** Joins: greenriot (~greenriot@user/gr33nr10t)
[15:20:45] *** Quits: gr33nR10t (~greenriot@user/gr33nr10t) (Ping timeout: 272 seconds)
[15:32:41] *** Quits: montywi (~monty_@83-245-178-47.elisa-laajakaista.fi) (Remote host closed the connection)
[16:03:14] *** Joins: bytestream (~bytestrea@user/bytestream)
[17:53:57] <CyberCr33p> I run this query https://dpaste.com/4VD937UQK.txt to delete duplicate entries from a table with ~ 60 million rows. It runs for 1 hour but still doesn't delete anything. Any idea if the query is wrong or if it's another way to delete duplicate entries?
[17:54:09] *** Joins: Mushfiq[m] (~mushfiqma@2001:470:69fc:105::1:b3f7)
[17:54:21] *** Joins: Mids_IRC (~midfairyd@2001:470:69fc:105::3f22)
[18:20:21] <lsrtl_> CyberCr33p, if version allows http://ix.io/3PX3. not sure about syntax, haven't tried, but should work according to the doc. If what meta_id to leave doesn't matter, order by can be removed
[18:22:24] <lsrtl_> if not, try batch approach - place the dups records in a separate table first. then chunk by chunk(say 1000 rec size) remove from the target by JOIN or EXISTS from the targer
[18:22:27] <lsrtl_> *target
[18:29:51] <Naktibalda> if table is innodb, you won't see any different until that statement finishes its job
[18:30:54] <Naktibalda> you can prepend EXPLAIN to that stament and check execution plan to see if it can finish in the next century
[18:31:35] <Naktibalda> 60mln * 60mln would literally take forever, but I hope that you have index on post_id, so it will take less
[18:32:04] *** Joins: OnkelTem (~OnkelTem@user/onkeltem)
[18:32:46] <Naktibalda> KEY(post_id, meta_value) would make it faster.
[19:00:36] *** Quits: DrowningElysium (uid190788@user/drowningelysium) (Ping timeout: 240 seconds)
[19:01:05] *** Joins: DrowningElysium (uid190788@user/drowningelysium)
[19:04:53] *** Quits: passage (~passage@user/passage) (Read error: Connection reset by peer)
[19:08:51] *** Joins: passage (~passage@user/passage)
[19:48:36] *** Quits: DrowningElysium (uid190788@user/drowningelysium) (Ping timeout: 240 seconds)
[19:50:49] *** Joins: DrowningElysium (uid190788@user/drowningelysium)
[19:53:48] <CyberCr33p> Naktibalda it's better to KEY(post_id, meta_value)  or KEY(post_id, meta_value,meta_id)  ?
[19:54:45] <Naktibalda> latter is a bit better. are you going to make it unique later?
[19:55:27] <Naktibalda> if you statement is still running and you kill it, it may take the same time to rollback.
[19:56:11] <CyberCr33p> Naktibalda ok thank you
[19:56:16] <CyberCr33p> lsrtl_ thank you too
[20:01:16] *** Quits: DrowningElysium (uid190788@user/drowningelysium) (Read error: No route to host)
[20:01:43] *** Joins: DrowningElysium (uid190788@user/drowningelysium)
[20:14:49] *** Quits: OnkelTem (~OnkelTem@user/onkeltem) (Quit: WeeChat 2.8)
[20:33:38] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[20:34:59] *** Joins: palasso (~palasso@user/palasso)
[20:40:03] *** Quits: DrowningElysium (uid190788@user/drowningelysium) (Read error: No route to host)
[20:40:37] *** Joins: DrowningElysium (uid190788@user/drowningelysium)
[20:45:33] *** Quits: lsrtl_ (~lsrtl@user/lsrtl) (Ping timeout: 256 seconds)
[20:46:23] *** Joins: vit (~vit@chello085216193138.chello.sk)
[20:46:47] *** vit is now known as Guest6792
[20:47:38] *** Guest6792 is now known as freeworld
[21:00:41] *** Quits: lara99 (~lara99@93-36-163-139.ip61.fastwebnet.it) (Quit: Client closed)
[21:08:18] *** Quits: lamneth (~IceChat95@modemcable025.99-56-74.mc.videotron.ca) (Quit: Give a man a fish and he will eat for a day. Teach him how to fish, and he will sit in a boat and drink beer all day)
[23:03:14] *** Quits: Junxter (~Junxter@222.95.164.193) (Read error: Connection reset by peer)
[23:56:02] *** Joins: forgotmynick (uid24625@id-24625.hampstead.irccloud.com)
