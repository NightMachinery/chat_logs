[00:25:53] *** Quits: Exuma (~Exuma@47-208-155-156.erkacmtk03.res.dyn.suddenlink.net) (Quit: Textual IRC Client: www.textualapp.com)
[00:25:54] *** Quits: hans (uid529825@id-529825.helmsley.irccloud.com) (Quit: Connection closed for inactivity)
[00:35:35] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 240 seconds)
[00:36:48] *** Joins: Colombo (~jmoravec@2406:e003:1df7:7601:80b6:e65b:bdf0:481a)
[00:51:48] *** Quits: usr725635_ (~User@cpe-45-47-86-32.twcny.res.rr.com) (Ping timeout: 240 seconds)
[00:56:53] *** Joins: hextr (~h@S010664777d8ff843.cg.shawcable.net)
[01:07:24] *** Joins: Exuma (~Exuma@47-208-155-156.erkacmtk03.res.dyn.suddenlink.net)
[01:15:10] *** Quits: Exuma (~Exuma@47-208-155-156.erkacmtk03.res.dyn.suddenlink.net) (Quit: Textual IRC Client: www.textualapp.com)
[01:15:41] *** Quits: hextr (~h@S010664777d8ff843.cg.shawcable.net) (Ping timeout: 256 seconds)
[01:23:01] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[01:28:07] *** Quits: debianero (~debianero@60.132.134.77.rev.sfr.net) (Quit: Leaving)
[01:28:13] *** Joins: hextr (~h@S010664777d8ff843.cg.shawcable.net)
[01:35:15] *** Quits: hextr (~h@S010664777d8ff843.cg.shawcable.net) (Quit: Going offline, see ya! (www.adiirc.com))
[02:29:31] *** Quits: nvuafo (~usrnvuafo@user/nvuafo) (Remote host closed the connection)
[02:34:41] *** Joins: nvuafo (~usrnvuafo@user/nvuafo)
[02:52:00] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[03:40:02] *** Quits: flip214 (~marek@user/flip214) (Read error: Connection reset by peer)
[03:43:50] *** Quits: rinzewind (~rinzewind@user/rinzewind) (Quit: leaving)
[03:44:13] *** Joins: flip214 (~marek@user/flip214)
[04:38:19] *** Joins: redrum88 (~redrum88@user/redrum88)
[05:15:07] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Remote host closed the connection)
[05:15:35] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[06:28:04] <ns12> Hello, if I am using R from the command line, is there a more user friendly alternative to the "dataentry" spreadsheet-like GUI that appears when I use "View()" or "edit()"?
[06:29:28] <ns12> One issue I have with the default spreadsheet-like GUI is that it lacks sorting and search functionality.
[06:49:39] <Colombo> ns12: why do you need spreadsheet-like GUI in R?
[06:50:14] <Colombo> ns12: generate data in text editor or any excel-like thing and load them in R with read.table or similar function
[06:51:05] <Colombo> ns12: maybe if you describe your problem, we might come to a better solution?
[07:25:55] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 240 seconds)
[08:13:39] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[10:16:53] *** Joins: palasso (~palasso@user/palasso)
[11:54:35] <ns12> Colombo: "why do you need spreadsheet-like GUI in R?" - It already exists. That's what "View()" and "edit()" do.
[11:54:35] <ns12> Excel-like programs such as Libreoffice Calc are heavyweight. Takes too long to start.
[12:22:16] <Colombo> ns12: I know that it exists in R. But why do you need it?
[12:22:41] <Colombo> ns12: you could always edit stuff in vim
[12:23:06] <Colombo> https://www.vim.org/scripts/script.php?script_id=558
[12:40:54] *** Quits: confuzeus (~h_m@186-149-117-154.bitcointernet.co.za) (Read error: Connection reset by peer)
[12:42:01] *** Quits: Colombo (~jmoravec@2406:e003:1df7:7601:80b6:e65b:bdf0:481a) (Quit: Leaving.)
[12:46:31] *** Joins: confuzeus (~h_m@186-149-117-154.bitcointernet.co.za)
[12:59:35] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4.1)
[13:01:01] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[13:15:36] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4.1)
[13:16:56] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[13:34:30] *** Quits: LogIN_ (~LogIN@104.248.160.203) (Remote host closed the connection)
[13:54:27] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4.1)
[13:54:42] <since_> ns12: learn some vim and awk? :D
[13:55:08] <since_> Block select and ! is magic
[13:55:34] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[13:55:39] <since_> (e.g. ctrl-v)
[13:59:59] *** Joins: usr725635_ (~User@cpe-45-47-86-32.twcny.res.rr.com)
[14:09:33] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4.1)
[14:11:26] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[14:17:22] *** Joins: hans (uid529825@id-529825.helmsley.irccloud.com)
[14:17:38] *** Parts: hans (uid529825@id-529825.helmsley.irccloud.com) ()
[14:20:04] *** Joins: debianero (~debianero@60.132.134.77.rev.sfr.net)
[14:47:55] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 240 seconds)
[14:48:12] *** Joins: rinzewind (~rinzewind@user/rinzewind)
[14:53:19] *** Joins: sea_h0rse (~user_nam3@220-245-42-113.tpgi.com.au)
[14:57:40] *** Quits: sea_h0rse (~user_nam3@220-245-42-113.tpgi.com.au) (Quit: Quit)
[15:03:00] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[15:20:38] <fendur> if i were going to have a whole bunch of data hand entered, i'd probably find a way to make a nice form that could minimize errors. it would not be done in R or excel.
[15:43:08] *** Joins: sprout_ (~quassel@2a02:a467:ccd6:1:f9b9:c2d3:ad62:759d)
[15:47:04] *** Quits: sprout (~quassel@2a02:a467:ccd6:1:dc5b:897:dfbc:2d30) (Ping timeout: 268 seconds)
[16:08:39] <fendur> maybe im just using an older or crappier version of rstudio right now, but on a long script, the scroll bar got so small i can't even see it anymore. clever.
[16:19:33] *** Joins: Tajan (~Tajan@user/Tajan)
[16:20:06] <Tajan> hello, I would like to make an online certification for data science skills. which one would you recommend?
[16:21:27] <since_> "500 Stars on Github" Certificate
[16:22:51] <since_> i.e. do a cool little project and learn something by doing it
[16:23:39] <Tajan> since_, that is no issue, I am not referring to learning. I mean a certification as a demonstration that I have the skills.
[16:24:05] <Tajan> of course, a project is a demonstration, too. but perhaps alongside that
[16:24:45] <Tajan> github has many free courses, but I cant find an assessment
[16:24:58] <Tajan> I mean there are, but from xyz people
[16:25:12] <since_> But i can understand that in a world with obviously wrong performance metrics and the need to earn money that those paper certificates may help you. But i am a bit sceptical about those (i.e. its a way to make money for them by printing paper). But apparently the industry wants that? (I am curious)
[16:26:14] <confuzeus> Tajan: sounds like you have been blinded by data science? what is wrong with plumbing (most lucrative), gender studies, climate, ...
[16:26:32] <Tajan> since_ I mean exactly one of those shitty paper things (or digital). as you say, I dont see it necessary at all from my personal point
[16:27:06] <Tajan> confuzeus, I presume you mean I may be caught by some fad? no that is not the case.
[16:27:52] <Tajan> so it is just that I need this otherwise redundant thing, and I will be glad if you can tell me which one can do the job.
[16:27:56] <since_> I can understand that people want to be able to present their skills in a way that HR people understand. so i don't judge
[16:30:13] <since_> I saw people doing those MIT-X courses for personal interest, and you can buy a PDF from them if you passed an automated test in the end or sth.
[16:36:45] <ns12> since_: "learn some vim and awk? :D" - How does awk help?
[16:37:12] <confuzeus> Tajan: what do you think is the opportunity cost of doing something redundant? if your current skills are already good then projects that demonstrate your skills will be more valuable than an online course. personally, online courses are likely a cheatfest.
[16:38:17] <fendur> they are worth whatever the employers say they are worth
[16:38:44] <since_> ns12: thats what the R website guide  recommends for data manipulation. Its quick and dirty. :D - but maybe its of little use in your case
[16:38:50] <fendur> granted, knowing an employer values that among all else might send YOU a message.
[16:40:07] <fendur> *sigh*, it's CITI training refreshment day
[16:43:55] <confuzeus> true, knowing the requirements of the field you wish to get into helps a lot.
[16:46:08] <Tajan> having viewed one such program (which is either highly popular or its marketing makes it seem so), it has a highly simplified list of subjects, a handful (I cant see their actual contents). in the case of a job search, does an "employer" really call one as "data analyst" based on that?
[16:46:32] <Tajan> or rely on that "title" ?
[16:46:45] <since_> Tajan: don't forget to include the job description in your CV in 1pt white font on white background. helps to pass automated pre HR filtering - (100% match!)
[16:47:13] <Tajan> white font on white bg? :)
[16:47:36] <since_> so its not visible in the pdf, but for the computer its in the pdf
[16:47:45] <Tajan> why should it not be visible in the pdf? 
[16:48:01] <fendur> so only the computer reads it
[16:48:25] <since_> i mean the complete job posting
[16:48:29] <Tajan> right
[16:50:17] <Tajan> so, looks like to convince some dorks, you can just go through things you already know and get a cert. that is what I infer.
[16:50:39] <fendur> i think you knew that when you joined #R
[16:51:35] <fendur> i mean, depends on the dorks. but in a lot of cases, yeah, that can work.
[16:51:56] <fendur> like others have said, though, sometimes just a great demo will do the job and papers don't matter.
[16:52:21] <Tajan> no, I didnt know much about what went on there, and wondered if one could really get some higher-level challenge and that it would at the end work to show that one could take higher-level challenges
[16:52:38] <fendur> that's what those certs are intended for.
[16:52:51] <fendur> well, that's what they are marketed as.
[16:53:55] <Tajan> fendur, intended for higher-level challenges?
[16:54:14] <confuzeus> also, you are likely to be given an actual task to do during recruitment to demonstrate th skills.
[16:54:19] <fendur> yes, and in particular, whether you can defeat them.
[16:54:20] <Tajan> surely
[17:15:48] <Tajan> well, yes, I suppose I just do one in this case while a project is always more interesting and rewarding for me, too, as you've mentioned 
[17:16:52] <Tajan> thank you everyone, it was nice talking to you
[17:17:19] *** Joins: baffodoro (~raffaem@95.74.70.148)
[17:17:35] <fendur> I built a predictive model that I used to fill out a March Madness bracket and documented it with RMarkdown.
[17:35:51] *** Quits: baffodoro (~raffaem@95.74.70.148) (Ping timeout: 252 seconds)
[17:56:51] *** Joins: mefistofeles (~mefistofe@user/mefistofeles)
[18:10:55] *** Joins: resistor4u (~resistor4@2601:5c2:102:33d0:959e:8aab:dabf:fc19)
[18:14:16] <Tajan> https://www.dataquest.io/blog/data-science-certificate/
[18:18:45] <Tajan> summary; projects count. certs only little.
[18:23:35] <confuzeus> they are way cheaper than a 1 year masters in data science, so it is a matter of opportunity cost.
[18:28:39] *** Quits: Tajan (~Tajan@user/Tajan) (Ping timeout: 252 seconds)
[18:36:53] <Bayes> I've seen two R conferences now that are more python friendly, as in "how R and python can operate in harmony"
[18:39:42] <confuzeus> why does that sound not new in 2010 already or may be it's rstudio conferences i am thinking about?
[18:40:18] <Bayes> idk, maybe it's not new, but it was the first time I realized R conferences were shooting for that now
[18:40:28] <Bayes> maybe it's my bubble
[18:40:58] <Bayes> I'm wondering what kind of python-R interoperatibility are most used or needed out there
[18:41:17] <Bayes> like, it'd seems R is better suited for data munging, python is more suited maybe for deployment and such
[18:41:45] <Bayes> but kind of interoperability models have been explored out there?
[18:41:51] <confuzeus> i think there is reticulate that you can use python and r simultaneously in one rmarkdown. i have not needed it yet.
[18:42:19] <Bayes> yeah that's what I'm wondering, what kind of stuff people need R and python for
[18:44:24] <confuzeus> idk, these conferences may be eye openers for you
[18:44:41] <resistor4u> good question in general, b/c it's one i wondered about when asking myself "*should* i learn R or Python?"
[18:46:39] <resistor4u> people would try to make the case that one is better suited for certain purposes over others, but IMHO the answer is how user friendly the REPL is, i.e. how helpful its error indications are 
[18:47:49] <resistor4u> "-------------^ hey dumdum you forgot the quote here"
[18:54:55] <fendur> Stan opened my eyes to high quality error messages :)
[18:56:41] <mefistofeles> yeah, a lot of language adoption is about use space tools, not the languages themselves
[18:56:56] <mefistofeles> I think that's why Pytohn is so popular and useful in such different scenarios
[18:56:59] <mefistofeles> *Python
[18:58:45] <Bayes> I agree, you could use one and stick with it no problem most of the times
[18:59:36] *** Joins: OP-0 (~pca290122@adsl-d146.84-47-79.t-com.sk)
[19:00:00] <Bayes> but there are definitely clear advantages for one over the other for specific uses and tools
[19:00:10] *** Quits: OP-0 (~pca290122@adsl-d146.84-47-79.t-com.sk) (Client Quit)
[19:00:22] <Bayes> I mean you'd probably first think of python and not R if you're working on something wsgi heavy
[19:01:08] <Bayes> also, if you're application is heavy on traditional ML methods I think one could argue for scikit over R
[19:01:29] <mefistofeles> right, for ML/DL Python just has a larger code base
[19:01:37] <mefistofeles> but for comp-stats in general, R might be better
[19:01:41] <Bayes> similarly, one could argue strongly for R for data munging as well as for more niche stats-y models
[19:02:30] <Bayes> agreed
[19:08:15] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Quit: :^))
[19:09:03] *** Joins: resistor_ (~resistor4@67-165-135-150.dynamic.arizona.edu)
[19:09:56] <confuzeus> i wonder what the data would say (i.e. looking at both stats/data science journals) as to what languages are being used.
[19:10:45] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[19:12:12] *** Quits: resistor4u (~resistor4@2601:5c2:102:33d0:959e:8aab:dabf:fc19) (Ping timeout: 240 seconds)
[19:14:22] *** Joins: Tajan (~Tajan@user/Tajan)
[19:18:37] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Quit: :^))
[19:23:05] <mefistofeles> confuzeus: one could use the paperswithcode API to get the repos and then the github (or whatever service) api to check the languages
[19:31:29] *** Joins: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net)
[19:35:58] *** Joins: dfdx (~F@user/dfdx)
[19:36:30] <dfdx> Hi #R, I just installed R on a new machine. I am trying to install a library and it keeps wanting to install in /home/dfdx/R/ -- how can I change that default path?
[19:37:02] <dfdx> nvm... I think i have to edit $R_LIBS_USER....
[19:46:03] <rickyrick> Sounds about right :^)
[20:22:37] *** Quits: JoshStark (~JoshStark@linuxserver.io/stark) (Ping timeout: 256 seconds)
[20:23:54] *** Joins: JoshStark (~JoshStark@linuxserver.io/stark)
[20:24:49] <confuzeus> mefistofeles: thanks. will put this on my business devel time.
[20:28:51] *** Joins: monstar (~monstar@gateway/tor-sasl/monstar)
[20:33:21] *** Quits: resistor_ (~resistor4@67-165-135-150.dynamic.arizona.edu) (Quit: Leaving...)
[20:44:36] *** Joins: rickyrick_ (~rickyrick@S01069050ca454523.vf.shawcable.net)
[20:44:36] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Killed (NickServ (GHOST command used by rickyrick_)))
[20:50:43] *** rickyrick_ is now known as rickyrick
[21:01:26] <Bayes> is there anything in base R that does this? http://ix.io/3T5V I'm just making sure I'm not reinventing the wheel with my function
[21:01:54] <rickyrick> Base, no
[21:01:59] <Bayes> k awesome
[21:02:12] <rickyrick> Well
[21:02:22] <rickyrick> You might be able to bodge reshape() into doing it but idk
[21:02:24] <Bayes> I just noticed also that flatten_matrix was not the best name, probably melt_matrix or something like that
[21:02:38] <rickyrick> I've seen it called a triplet matrix before
[21:02:46] <Bayes> triplet?
[21:02:52] <rickyrick> As in triplets (row, col, value)
[21:02:57] <Bayes> nice name
[21:03:14] * rickyrick farts
[21:03:30] <Bayes> I typically go with "tuple" for anything > 2
[21:04:40] <Bayes> renaming this to as.triplet.matrix :D
[21:05:17] <rickyrick> I think the slam package uses that function name (^:
[21:05:56] <rickyrick> I think it's also a lot faster to just assign to dim(x) instead of as.vector()ing
[21:15:29] <Bayes> assign to dim? the triplet doesn't have a dim, I think, as I have no row names or so?
[21:16:52] <rickyrick> As in dim(x) <- nrow(x) * ncol(x) instead of x = as.vector(x)
[21:19:23] <Bayes> oh gotcha
[21:23:05] * rickyrick farts
[21:23:32] <rickyrick> This arrow package keeps crashing R
[21:23:36] <rickyrick> idk what I'm doing wrong
[21:27:29] *** Quits: px (~px@ool-457980ed.dyn.optonline.net) (Changing host)
[21:27:29] *** Joins: px (~px@user/px)
[21:39:01] *** Quits: Tajan (~Tajan@user/Tajan) (Ping timeout: 240 seconds)
[21:44:11] *** Joins: rickyrick_ (~rickyrick@S01069050ca454523.vf.shawcable.net)
[21:44:11] *** Quits: rickyrick (~rickyrick@S01069050ca454523.vf.shawcable.net) (Killed (NickServ (GHOST command used by rickyrick_)))
[21:52:00] *** rickyrick_ is now known as rickyrick
[21:54:28] <Bayes> are you constrained to arrow by your infrastructure or can you switch to something else, e.g., https://cran.r-project.org/web/packages/bigmemory/index.html?
[21:56:37] <rickyrick> No just trying out arrow
[21:56:40] <rickyrick> bigmemory was super slow for me
[21:57:01] <rickyrick> Particularly because I need to access a random subset of rows repeatedly :^)
[22:04:00] <confuzeus> they badly want to beat data.table so they have optimised it to the death of R...
[22:04:25] <rickyrick> lel
[22:05:28] <shrysr> mebbe outdated lib dep? Therez atleast one "Installing cpp11 [0.4.2] ... ".  loox like the arrow package takes a while to install... still installing :( 
[22:06:09] <rickyrick> Just tried updating R and all my packages
[22:06:39] *** Quits: redrum88 (~redrum88@user/redrum88) (Ping timeout: 256 seconds)
[22:09:47] <rickyrick> I guess it just doesn't like the parquet file I have
[22:15:14] *** Quits: Kilroy7 (~thelounge@user/Kilroy) (Quit: Bye)
[22:15:15] <rickyrick> Well, read_parquet loads it in fine but open_dataset bombs out
[22:23:29] *** Quits: baconator (~bacon@c-73-73-223-91.hsd1.il.comcast.net) (Ping timeout: 252 seconds)
[22:23:45] <Bayes> confuzeus who tried to beat DT, bigmemory?
[22:24:16] <Bayes> rickyrick does arrow work ootb or do you need to install 3rd party dependencies or run on some specific hw?
[22:24:23] <confuzeus> arrow
[22:24:35] <Bayes> oh gotcha, arrow vs DT
[22:24:41] <confuzeus> on reading csv files
[22:24:48] <Bayes> DT is my butter and bread, love it so much
[22:24:55] <rickyrick> OOTB
[22:25:01] <rickyrick> The sample file works, but my big fat file doesn't
[22:25:18] <Bayes> in fact DT is my de facto data frame package for anything that's not trivially done in base R
[22:25:27] <Bayes> rickyrick heh good to know it works ootb
[22:25:32] <rickyrick> ( ͡° ͜ʖ ͡°)
[22:28:11] <flip214> can somebody tell me how I get geom_density() and stat_peaks() to work together in the same plot? I'd like to highlight, and show the x-coordinate, of the density peaks 
[22:30:48] *** Joins: baconator (~bacon@c-73-73-223-91.hsd1.il.comcast.net)
[22:31:07] <rickyrick> What package is stat_peaks from
[22:34:24] <rickyrick> nvm found it
[22:36:36] <rickyrick> I think you need to convert the density estimate into actual data first
[22:56:44] <rickyrick> This ff package is some arcane shit
[22:58:35] <Bayes> mfw shit is too complex https://i.imgur.com/DBjmI3z.png (◕︵◕)
[23:01:32] <confuzeus> flip214: i like how you consider the density some magical thing. 
[23:01:34] <rickyrick> feelsbadman.jpg
[23:03:26] <shrysr> rickyrick: data too big for sqlite? 
[23:07:10] <flip214> confuzeus: well, for an R amateur it's kind of magic. I just write a few text lines and get beautiful graphics.
[23:07:44] <Bayes> ^ it's okay not to know everything
[23:07:50] <Bayes> so no need to explain really
[23:09:16] <flip214> rickyrick: by hand, using the density function? need to run that for each of several data sets then, hmmm
[23:10:07] <flip214> https://stackoverflow.com/questions/53841391/what-is-the-best-way-to-calculate-and-display-peaks-of-a-ggplot2geom-density might be an idea
[23:12:00] <Bayes> what does stat_peaks do?
[23:12:44] <Bayes> I mean it seems to go find which.max(x) and then what?
[23:12:54] <Bayes> does it print a line or what?
[23:13:36] <Bayes> Both stats return a subset of data with rows matching for peaks or valleys with formatted character labels added.
[23:13:42] <Bayes> oh does it print a text?
[23:14:30] <Bayes> if so, just add an extra column to your df with your label on the peaks and an NA otherwise and do something like geom_text(aes(label = mylabel))
[23:15:06] <Bayes> or create a smaller data frame with the peaks only and this extra label column then geom_text(aes(label = mylabel), labelDF)
[23:19:13] <rickyrick> shrysr: That's the only method that works right now
[23:20:27] <rickyrick> fpbppfbpflbplpt
[23:20:43] <rickyrick> ff's read csv ffdf also bombs out
[23:20:44] <rickyrick> great
[23:21:13] <confuzeus> xsv?
[23:21:57] <rickyrick> wat
[23:22:53] <confuzeus> it's some command line program that is very efficient for large files. not sure about subsetting though
[23:23:20] <rickyrick> I mean I just want to random access a big table that's larger than RAM
[23:23:40] <rickyrick> Guess I'm gonna switch to Python :^)
[23:23:42] <confuzeus> oh.
[23:24:04] <rickyrick> The only feasible method that's worked so far is SQLite
[23:24:31] <rickyrick> bigmemory takes an order of magnitude longer to access a batch of non-contiguous rows
[23:25:00] <shrysr> hmm afaik  larger than memory problems usually move to using Spark ? 
[23:25:08] <shrysr> sparklyr
[23:27:10] <rickyrick> :^|
[23:32:39] <Bayes> try C
[23:32:46] <Bayes> ( ͡° ͜ʖ ͡°)
[23:32:50] <rickyrick> ( ͠° ͟ʖ ͡°)
[23:37:16] <shrysr> hmm i dont rem that python is better than R at handling bigger data. in fact i seem to recall pandas gets exponentially slower as you reach 1Gb..
[23:37:26] <rickyrick> ( ͡° ͜ʖ ͡°)
[23:37:45] <rickyrick> I got arrow to work with a shortened version of the same dataset
[23:37:49] <rickyrick> idk why it craps out on the full one
[23:38:44] <shrysr> hey rickyrick if sqlite was working... then why arrow? for fun?  
[23:38:54] <rickyrick> Just wanted to see if it can go faster
[23:39:01] <shrysr> ah. yeah.
[23:39:30] <rickyrick> Well that's dumb
[23:39:39] <rickyrick> I got arrow to work once with the full dataset, but it consumed all my memory in the process
[23:41:37] <rickyrick> Time to give up on arrow
[23:41:56] <confuzeus> this is the tool i was referring to, albeit not relevant for your task https://github.com/BurntSushi/xsv
[23:42:12] <rickyrick> neat
[23:42:26] <rickyrick> That's a huge binary lmao
[23:42:41] <rickyrick> Oh I was looking at the GNU
[23:43:09] <confuzeus> it is written in rust...
[23:43:36] <rickyrick> Yeah the windows-gnu binary is 28MB uncompressed
[23:45:23] <shrysr> I dont get it though rickyrick, if we're looking at NOT reading in the whole data since its larger than memory - how does arrow help at all in your case? i.e isnt that expected of arrow :- to access the data, you have to create/read in the arrow object? 
[23:45:40] <rickyrick> Yeah I was hoping it would be able to fetch the desired portions from disk
[23:46:17] <rickyrick> Guess I misunderstood what arrow was offering beyond a storage format
[23:46:23] <shrysr> yea. 
[23:46:29] <rickyrick> ¯\_(ツ)_?¯
[23:46:43] <shrysr> well atleast I have received confirmation that my brain is working today.
[23:46:50] * Bayes plays sad adele song for rickyrick
[23:46:51] <Bayes> RIP
[23:47:01] * rickyrick uncorks for a sad fart
[23:47:14] <shrysr> lmao uncorks
[23:50:23] <shrysr> burntsushi ... actually sounds like a familiar handle
[23:50:40] <shrysr> hmm the guy wrote ripgrep apparently. 
[23:55:35] <confuzeus> yup. though they take their time to fix bugs
[23:58:06] <Bayes> alias rgr="rg --type=r" :D
