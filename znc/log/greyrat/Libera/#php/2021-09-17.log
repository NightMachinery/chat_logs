[00:01:10] *** Joins: ArchNoob (~maotora@user/archnoob)
[00:02:15] *** Joins: Alexander-47u (~Alexander@a44107.upc-a.chello.nl)
[00:02:16] <Alexander-47u> hi guys
[00:02:27] <Alexander-47u> whats the best way to go from a base64 pdf, to a html download button
[00:02:31] <Alexander-47u> or href
[00:02:59] <omegatron> "to go from" ... ?
[00:03:28] <omegatron> please more details ..
[00:03:37] <Alexander-47u> I have a base64 encoded pdf file, I want to make it downloadable through href, but only on click
[00:03:58] <Alexander-47u> the API im using, returns an invoice as base64 data
[00:04:02] <Sammitch> break your question down into smaller tasks rather than trying to solve the entire thing all at once
[00:04:12] <Alexander-47u> I want to make a download button for my wifes customers
[00:04:31] *** Quits: guidoc (~guido@host-79-43-248-222.retail.telecomitalia.it) (Quit: WeeChat 3.2)
[00:04:45] <Sammitch> and which portion of that is giving you trouble?
[00:04:59] <biberu> the wife?
[00:05:07] <omegatron> =D
[00:05:07] <Sammitch> borat.jpeg
[00:05:13] <Alexander-47u> hahahhahaha
[00:05:15] <Alexander-47u> not today
[00:08:03] <omegatron> this base64 encoded file .. I assume it only exists within the browser at some time (maybe from some shop system?) ?
[00:08:25] <Alexander-47u> on click, api call is made, retrieves base64 code
[00:08:26] <omegatron> and not somewhere on the server's disk?
[00:08:57] <Alexander-47u> https://stackoverflow.com/questions/34698016/download-pdf-from-base64-string/34698092
[00:09:00] <Alexander-47u> I think this will work
[00:10:10] <Byteflux> It can be achieved with either PHP or JavaScript.
[00:10:16] <Sammitch>  yeah basically
[00:10:18] <Alexander-47u> ye this will work
[00:10:20] <omegatron> well, yes, something like that would have been my suggestion
[00:10:34] <Alexander-47u> I'll just create a function
[00:10:41] <Alexander-47u> then a button, with on click, run that php function
[00:11:06] <Alexander-47u> so it only downloads the invoice when the button is clicked, and not when the page is loaded
[00:11:16] <Byteflux> If you choose to do it server side, it would be worth considering whether it makes sense to cache the file to disk for repeated downloads.
[00:11:35] <Alexander-47u> no it does not
[00:11:41] <Alexander-47u> so live api retrieval is fine
[00:12:01] <Sammitch> iff it's an invoice I'd assume that it's only pertinent to exactly one user
[00:12:01] <Alexander-47u> not that many people want to download their invoice at the same time
[00:12:26] <Sammitch> *one user once, in most cases
[00:13:28] <Sammitch> and in the accepted answer it writes the data toa file, which is pointless since it just reads it back out and deletes the file.
[00:13:43] <Alexander-47u> hey will this cost me bandwith btw xD?
[00:13:58] <Sammitch> will downloading files cost bandwidth?
[00:14:11] <Alexander-47u> yea it will lol
[00:14:20] <Alexander-47u> shit. anyways ill see how it goes xD
[00:14:24] <Sammitch> if the answer is ever "no" the answerer will be rich
[00:15:04] <Byteflux> You could save on the bandwidth by making the client make the API request from JavaScript
[00:15:34] <Sammitch> assuming that the user is permitted to touch the API with _the user's_ credentials
[00:16:07] <Alexander-47u> nah, too much hassles.
[00:16:18] <Alexander-47u> ill do it through php, then I dont have to think about it being safe or not
[00:16:24] <Byteflux> Right. Also caching with a CDN like Cloudflare is another option but that still incurs bandwidth from the very first request for any given PDF.
[00:16:39] <Alexander-47u> yeah, if its a problem ill just call and request more bandth
[00:16:44] <Alexander-47u> bandwith
[00:17:16] <Sammitch> bandwidth-free downloads: 1. send the client the filesize and checksum. 2. generate random data of size $filesize until $checksum matches. 3. ??? 4. profit!
[00:17:51] <Byteflux> "???" -> "wait a million years for step 2 to complete"
[00:17:53] <Sammitch> the Million Monkey Typewriter solution ;)
[00:18:41] <Sammitch> its vaguely blockchain-ish, so I'll bet I could get a bunch of rich rubes to invest :P
[00:19:02] <Albright> Use the DNS network to store tiny fragments as TEXT records of several domain names
[00:19:28] <Sammitch> DHT, but for DNS
[00:20:42] <Sammitch> my brainchild from the other day was BitTorrent + Blockchain for decentralized software licensing and distribution :3c
[00:21:54] <omegatron> split the content into small fragments, store them on various online platforms with a unique keyword and let the client with a sophisticated javascript, which gets the keyword via URL fragment  collect and reconstruct them itself ..
[00:25:14] <Alexander-47u> too much hassles man
[00:25:16] <Alexander-47u> :P
[00:25:17] <Albright> Edit a Wikipedia article with the content of the file. Even if the edit gets reverted you can still access the old revisio
[00:25:46] <Sammitch> you still have to use bandwidth to squirrel away the bits of the file :P
[00:27:26] <omegatron> send out immortal network packets which travel all around the globe and eventually to the receiver, which is the only one who knows, what to do with them (every other machine just ignores it) ..
[00:27:52] <omegatron> (ok, I made that up, I admit)
[00:30:26] <Sammitch> TTL=INF
[00:32:12] <Sammitch> in college a classmate took down half the college's network during a client/server lab because he used a broadcast address and the school's network wasn't filtering properly :D
[00:33:17] <Sammitch> everyone's computer just froze. we were wondering what was going on when the instructor next door came in and asked if all of our computers were frozen as well.
[00:33:45] <Sammitch> then a VERY flustered tech burst into the room and demanded we all unplug our network cables
[00:45:23] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[00:50:19] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 252 seconds)
[01:15:44] *** Joins: glumanda (~manu@194-208-201-025.tele.net)
[01:20:36] *** Quits: sumthing1980 (~sumthing1@94.54.64.154) (Quit: Leaving)
[01:26:04] *** Quits: goddard (~goddard@user/goddard) (Ping timeout: 252 seconds)
[01:26:22] *** Quits: Poboy (~Poboy@user/poboy) (Quit: Client closed)
[01:30:51] *** Joins: junktext (~junktext@109.201.152.173)
[01:50:04] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[01:52:47] *** Quits: shailangsa (~shailangs@host86-186-132-44.range86-186.btcentralplus.com) ()
[01:55:03] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 268 seconds)
[01:55:06] *** Joins: harpia (~harpia@58.148.205.168.dynamic.vibefibra.com.br)
[01:57:28] *** Quits: magla (~gelignite@55d458e1.access.ecotel.net) (Quit: Stay safe!)
[02:08:21] *** Quits: glumanda (~manu@194-208-201-025.tele.net) (Quit: WeeChat 3.2.1)
[02:15:24] <Sammitch> or just have "future macguffin" technology that makes cell phones ok
[02:15:26] <Sammitch> mt
[02:15:32] <Sammitch> mt <_<;
[02:19:14] *** Joins: shailangsa (~shailangs@host86-186-132-44.range86-186.btcentralplus.com)
[02:33:37] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[02:39:07] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 252 seconds)
[02:58:19] *** Quits: freeworld (~vit@chello085216193138.chello.sk) (Ping timeout: 252 seconds)
[03:01:37] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 252 seconds)
[03:11:19] *** Joins: keypusher (keypusher@user/keypusher)
[03:16:17] *** Quits: LucaTM (~LucaTM@user/lucatm) (Quit: Textual IRC Client: www.textualapp.com)
[03:16:28] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[03:16:59] *** Quits: harpia (~harpia@58.148.205.168.dynamic.vibefibra.com.br) (Quit: harpia)
[03:20:50] *** Quits: N3X15 (~nexis@mail.nexisonline.net) (Remote host closed the connection)
[03:21:06] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 260 seconds)
[03:21:10] *** Joins: N3X15 (~nexis@mail.nexisonline.net)
[03:29:43] *** Quits: semeion (~semeion@user/semeion) (Ping timeout: 252 seconds)
[03:39:47] *** Quits: onizu (uid373383@id-373383.uxbridge.irccloud.com) (Quit: Connection closed for inactivity)
[03:44:14] *** Joins: semeion (~semeion@user/semeion)
[03:46:41] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[03:51:23] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 268 seconds)
[03:52:25] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[03:57:09] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 268 seconds)
[04:03:43] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[04:08:52] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 268 seconds)
[04:10:07] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[04:15:02] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 268 seconds)
[04:18:30] *** Joins: ferdna (~ferdna@user/ferdna)
[04:26:48] *** Quits: Alexander-47u (~Alexander@a44107.upc-a.chello.nl) (Remote host closed the connection)
[04:41:52] *** Quits: semeion (~semeion@user/semeion) (Ping timeout: 265 seconds)
[04:47:24] *** Quits: genomc (uid245282@id-245282.hampstead.irccloud.com) (Quit: Connection closed for inactivity)
[04:54:52] *** Joins: semeion (~semeion@user/semeion)
[05:15:42] *** Quits: ArchNoob (~maotora@user/archnoob) (Ping timeout: 265 seconds)
[05:25:52] *** Joins: Hiccup (cHoy@2404:8000:1003:14fe::510)
[05:29:02] *** Quits: mishehu (~mishehu@mira001.eyepeeveesicks.shavedgoats.net) (Ping timeout: 268 seconds)
[05:29:43] *** Joins: mishehu (~mishehu@mira001.eyepeeveesicks.shavedgoats.net)
[05:30:27] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:31:52] *** Joins: Junxter (~Junxter@222.95.222.185)
[05:34:51] *** Joins: vlm (~vlm@user/vlm)
[06:09:34] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 260 seconds)
[06:11:34] *** Joins: keypusher (keypusher@user/keypusher)
[06:49:50] *** Quits: pmercado_ (~pmercado@186.107.63.213) (Quit: Konversation terminated!)
[06:52:40] *** Quits: jetchisel (jetchisel@user/jetchisel) (Ping timeout: 252 seconds)
[07:05:34] *** Joins: Rockwood (~Rocky@user/rocky)
[07:10:15] *** Quits: mr_gant (~mr_gant@144.48.37.132) (Ping timeout: 265 seconds)
[07:24:58] *** Joins: mr_gant (~mr_gant@203-206-182-122.perm.iinet.net.au)
[08:06:17] *** Joins: jetchisel (jetchisel@user/jetchisel)
[08:11:13] *** Quits: jetchisel (jetchisel@user/jetchisel) (Ping timeout: 268 seconds)
[08:13:54] *** Quits: sebbu (~sebbu@user/sebbu) (Quit: Quitte)
[08:17:44] *** Quits: Xaldafax (~xaldafax@cpe-198-72-160-101.socal.res.rr.com) (Quit: Bye...)
[08:27:31] <fakuve> Hey guys , just thowing thisone out for curiosity , how do the captive portals manage to retrieve all that information from the Client Browser , meaning they manage to get `Ip addr, MAC Address ...` I'm dipping my toes in PHP and I can see by querying the superglobals you can get the (REMOTE_ADDR) and the (REMOTE_PORT) . What functionality are they using to get this?
[08:28:01] <__adrian> it's provided by the browser
[08:28:20] <__adrian> well, i mean, all the other info
[08:28:34] <__adrian> ip is pretty obvious, the portal is assigning it
[08:29:05] <fakuve> Yeah obviously that is the server DHCP so they have that info already
[08:29:31] <fakuve> but the MAC address? What is the method they use? Is JS?
[08:30:22] <Rockwood> __adrian, hi how are you sir?
[08:30:28] <Rockwood> me too vaccinated
[08:34:55] *** Quits: junktext (~junktext@109.201.152.173) (Ping timeout: 252 seconds)
[08:37:11] <__adrian> the router knows the mac address because it's literally connected to it
[08:37:19] <__adrian> this isn't the website that knows
[08:52:56] *** Quits: semeion (~semeion@user/semeion) (Ping timeout: 268 seconds)
[09:05:21] <grawity> fakuve: when I was implementing a captive portal (in PHP!), I looked at the system's neighbour table (i.e. the ARP cache for IPv4) – roughly `ip --json nei show IPADDR` via popen() or something like that
[09:05:37] *** Joins: semeion (~semeion@user/semeion)
[09:05:44] <grawity> fakuve: the captive portal *has* to be running on the PC's direct gateway for this stuff to work
[09:06:20] <grawity> or hmm, maybe not necessarily the direct gateway, but definitely on the same subnet, now that I think of it
[09:06:27] <grawity> (but it is *usually* on the gateway)
[09:06:55] <grawity> but the PC is pretty much guaranteed to show up in the neighbour table because it's already talking to the app
[09:17:13] *** Quits: ferdna (~ferdna@user/ferdna) (Quit: Leaving)
[09:23:52] <fakuve> grawity: thats pretty interesting the insight . Thanks
[09:25:47] *** Joins: sebbu (~sebbu@user/sebbu)
[09:33:14] *** Joins: Rockwood_ (~Rocky@user/rocky)
[09:34:43] *** Joins: freeworld (~vit@chello085216193138.chello.sk)
[09:36:10] *** Quits: Tempesta (~Tempesta@user/tempesta) (Ping timeout: 250 seconds)
[09:36:46] *** Quits: Rockwood (~Rocky@user/rocky) (Ping timeout: 260 seconds)
[09:37:34] *** Quits: xSavitar (~xSavitar@user/xsavitar) (Quit: ZNC 1.9.x-git-141-9cd36055 - https://znc.in)
[09:47:30] <dag> how long is it feasable to just use a db.json instead of an actual db? im thinking the first hurdle is too many processes wants to write to it and needs to wait for lock
[09:48:31] *** Joins: carlino3 (~carlino3@user/carlino3)
[09:48:35] <carlino3> \o
[09:48:42] <grawity> if you want a file-based DB, use sqlite, at least it has all the locking and concurrent updating figured out...
[09:49:18] <dag> true grawity. i just find it a bit of a hazzle to create sql queries and prepared statements all over
[09:49:34] <carlino3> implementing a database from scratch?
[09:50:12] <dag> no i just need some storage and im considering a flat file
[09:50:20] <carlino3> oh
[09:51:07] *** Quits: mr_gant (~mr_gant@203-206-182-122.perm.iinet.net.au) (Ping timeout: 268 seconds)
[09:51:31] *** Joins: mr_gant (~mr_gant@144.48.37.37)
[09:51:32] <grawity> hmm, $pdo->prepare("SELECT * FROM foo WHERE bar = :bar")->execute([$bar])
[09:52:07] <dag> mhm you are right. im being silly
[09:52:17] <dag> ill go for sqlite3
[09:56:03] <grawity> there *are* key-value file-based DBs too, the 'dba' extension allows accessing several types
[09:57:27] <grawity> but now that I think of it, they don't give much advantage over <key>.json (one file per key)
[09:57:43] <grawity> hmm maybe they do
[09:58:34] <TinoDidriksen> Just use SQLite. It's better in every way.
[09:59:52] <grawity> I can totally imagine a 15-line class that gives a key/value interface around a sqlite table, too
[10:03:19] <Rockwood_> bye cya
[10:03:36] *** Quits: Rockwood_ (~Rocky@user/rocky) (Quit: The Time is Over)
[10:03:58] *** Joins: Rockwood (~Rocky@user/rocky)
[10:04:57] *** Quits: Rockwood (~Rocky@user/rocky) (Client Quit)
[10:24:49] *** Quits: fukawi2 (~quassel@archlinux/support/fukawi2) (Quit: Going offline.)
[10:27:09] *** Joins: fukawi2 (~quassel@archlinux/support/fukawi2)
[10:28:13] *** Quits: fukawi2 (~quassel@archlinux/support/fukawi2) (Client Quit)
[10:32:05] *** Joins: fukawi2 (~quassel@archlinux/support/fukawi2)
[10:34:54] *** Quits: fukawi2 (~quassel@archlinux/support/fukawi2) (Client Quit)
[10:36:10] *** Joins: fukawi2 (~quassel@archlinux/support/fukawi2)
[10:37:14] *** Joins: genomc (uid245282@id-245282.hampstead.irccloud.com)
[11:04:27] *** Joins: Naktibalda (~Naktibald@88.135.22.17)
[11:04:41] *** Joins: guido (~guido@2001:b07:6455:ac4f:3641:5dff:fe55:2a8f)
[11:21:54] *** Joins: fahrradToken (~fahrradTo@2a02:810b:149f:f0f4::3f1)
[11:22:05] *** Quits: carlino3 (~carlino3@user/carlino3) (Quit: Client closed)
[11:25:26] *** Joins: jetchisel (jetchisel@user/jetchisel)
[11:33:54] *** Joins: CrazyEddy (crazyed@2603:300a:1d10:c000:de4a:3eff:fe88:cc5f)
[12:01:00] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[12:21:17] *** Quits: shokohsc8 (~shokohsc@161.88.195.77.rev.sfr.net) (Read error: Connection reset by peer)
[12:23:09] *** Joins: shokohsc8 (~shokohsc@161.88.195.77.rev.sfr.net)
[12:30:31] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728)
[12:46:58] *** Joins: DevAntoi_ (~DevAntoin@2a01:e34:ec4e:a200:41f8:c798:693c:7ff5)
[12:48:02] *** Joins: ArchNoob (~maotora@user/archnoob)
[12:50:58] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c53e:fa76:3047:f728) (Ping timeout: 268 seconds)
[12:51:29] *** Joins: xSavitar (~xSavitar@user/xsavitar)
[12:53:07] *** Joins: LucaTM (~LucaTM@user/lucatm)
[13:02:41] *** Quits: anomander (~anomander@vps-e9abfd3d.vps.ovh.net) (Quit: Caesar si viveret, ad remum dareris)
[13:20:32] *** Quits: semeion (~semeion@user/semeion) (Quit: WeeChat 3.2)
[13:37:32] *** Quits: Hiccup (cHoy@2404:8000:1003:14fe::510) (Ping timeout: 250 seconds)
[13:53:23] *** Joins: Tempesta (Tempesta@user/tempesta)
[14:00:12] *** Joins: olle (~olle@p5785bfee.dip0.t-ipconnect.de)
[14:02:55] <olle> Sup?
[14:32:52] <olle> How to teach your colleagues about testability?
[14:33:00] <olle> Did I ask this before?
[14:37:15] <biberu> olle: you can e.g. look at tests (or lack of them) during code reviews, have coverage requirements
[14:39:49] <olle> biberu: hm, we really need to outline practice for code reviews
[14:39:55] <biberu> olle: make them work with the coverage reports too, they are great for finding important things you might have missed
[14:39:59] <olle> coverage requirement is a good idea. can be checked in CI too
[14:40:38] <biberu> i simply fail builds if a module lacks coverage
[14:42:24] <olle> biberu: Yeah. Problem is with so much legacy. But for new code, absolutely.
[14:42:36] <olle> biberu: Which tool do you use to track coverage?
[14:43:09] <biberu> if someone isn't writing testable code it'll be painful very quickly, and it'll also make people think about needless branching and other things that can improve code quality (since branches need to be tested)
[14:43:29] <biberu> olle: nothing that's relevant here, it's been a while since i did php, someone else might have suggestions
[14:43:39] <olle> hm
[14:43:44] <dag> imho testable code and tests only works fine with above average developers
[14:43:58] <olle> dag: Might be a problem
[14:44:06] <biberu> reviews and coaching
[14:44:25] <biberu> you won't improve without putting an effort into it
[14:44:53] <dag> a developer who has never written a test dont see any problem with service locators like $client = Http::getClient() littered all over
[14:46:19] <biberu> yeah, but something like that shouldn't be allowed into mainline, it should be caught and explained during review, and maybe a more senior dev should help out with showing the test framework used and explaining benefits while refactoring the code *together*
[14:47:24] <biberu> (with varying requirements depending on your project ofc, this is just general talk)
[14:47:37] <olle> I'd like very much for a static tool to catch cases like that (Http::getClient(), that is, implicit dependencies)
[14:47:51] <biberu> reviews are king
[14:48:27] <biberu> they are opportunities for teaching and sharing knowledge
[14:48:38] <olle> biberu: Extremely so
[14:48:57] <olle> And only thing to catch issues impossible to check statically currently, like naming
[14:49:04] <biberu> yeah
[14:49:29] <olle> Althought I guess a tool could check naming convention like verb + [adj] + noun
[14:51:49] <Blondie101010> ah come on
[14:52:07] <olle> ?
[14:52:25] <Blondie101010> well that is a bit ridiculous
[14:52:55] <Blondie101010> you might as well look for better programmers
[14:53:03] <Blondie101010> or coach them properly
[14:54:00] <biberu> yeah, don't assume people just are and will remain below average, set some expectations and help them get there
[14:54:17] <biberu> *positive* expectations
[14:55:58] <olle> No matter the quality of coders, bug rate is between 15-50 for 1k LOC
[14:56:00] <biberu> if bade code is allowed into mainline that is also a problem with leads and process, not just inexperienced devs
[14:56:13] <olle> Oh yes
[14:58:40] <Blondie101010> 15-50 bugs per 1K lines!?!
[14:58:50] <Blondie101010> you really need to do a better job
[15:00:00] <olle> Blondie101010: That's not me, that
[15:00:07] <olle> that's software engineering estimate
[15:00:23] <olle> Although those numbers are hard to estimate
[15:00:29] <Blondie101010> ughhhh so pointless information
[15:01:10] <Blondie101010> olle:  if your programmers don't do a good job, you need to address it with them
[15:01:34] <biberu> and it's primarily a people problem, not a technical/tool problem
[15:09:00] <olle> Blondie101010: I think it's extremely interesting and important information. :)
[15:09:22] <Blondie101010> not based on what you say
[15:09:30] <biberu> olle: in what way is it actionable?
[15:10:09] <olle> biberu: One study used it to compare fault density in code clones compared to "normal" code.
[15:10:20] <Blondie101010> since you started working there you've been complaining about the code and devs, and looking for ways to impose your methodology *without* involving them nor having the required authority
[15:10:34] <biberu> olle: concretely, what are you doing based on that number?
[15:10:55] <Blondie101010> complaining about static analysis being insufficient
[15:11:05] <olle> biberu: Me? Not much, need more time to apply code duplication tool properly
[15:11:17] <biberu> i still don't believe in that idea
[15:11:25] <biberu> the same code may not be duplicated code
[15:11:26] <Blondie101010> why don't you do more productive things?
[15:11:46] <olle> biberu: Then it's not a duplicate ^^ But a false positive
[15:11:56] <Blondie101010> searching duplicate code will NOT improve the app
[15:12:21] <Blondie101010> that would in the best case scenario in worse patched code
[15:12:22] <olle> Blondie101010: Empirical research tells otherwise. ;) But this argumentation is moot.
[15:12:45] <Blondie101010> you'll end up creating patches instead of fixing the design
[15:13:31] <biberu> olle: did you start doing reviews?
[15:16:31] <olle> biberu: Yes, but we need to discuss the practice more in the team
[15:17:23] <Blondie101010> do you have the authority to impose all changes to be reviewed?
[15:19:05] <biberu> olle: sure, it's a process, starting is the first step
[15:27:36] <olle> Blondie101010: Code review step is already part of our kanban board
[15:29:27] <olle> OK, added task to new sprint to check code coverage tools. :) +1 thanks
[15:29:31] <olle> next sprint*
[15:32:35] *** Quits: DevAntoi_ (~DevAntoin@2a01:e34:ec4e:a200:41f8:c798:693c:7ff5) (Remote host closed the connection)
[15:37:36] <biberu> i guess someone in here is using something like that for php?
[15:40:36] <biberu> olle: i guess it doesn't really need mentioning, coverage itself isn't enough, you've still got to ensure that the tests are valuable, testing the right thing etc., that's also for the code reviews to handle, but it's a great help
[15:45:09] <olle> biberu: sure, just better than nothing :)
[15:56:27] *** Joins: tex (~dee@user/dix)
[15:57:03] *** Quits: seand (~seand@69.54.142.196) (Quit: Leaving)
[15:57:37] *** Quits: guido (~guido@2001:b07:6455:ac4f:3641:5dff:fe55:2a8f) (Quit: WeeChat 3.2)
[16:22:53] <olle> How do you prove business impact on anything you develop?
[16:44:00] *** Joins: Norkle (~norkle@admin.nasa-g0v.com)
[16:51:39] *** Joins: guido (~guido@host-87-10-17-127.retail.telecomitalia.it)
[16:53:53] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c1b4:c34c:c482:361d)
[17:00:47] *** Joins: cadfael (~tshone@2a02-a453-4c64-1-4229-70c6-1990-6227.fixed6.kpn.net)
[17:00:56] *** Parts: cadfael (~tshone@2a02-a453-4c64-1-4229-70c6-1990-6227.fixed6.kpn.net) ()
[17:14:07] <TernaryOperator> olle: have an outage
[17:33:24] <olle> TernaryOperator: Oh, you mean remove the new feature and see what happens? :D
[17:35:28] <olle> A/B testing...
[17:44:27] <TernaryOperator> nah more it's been my observation that mangagement value the `hero` who puts it back up when it falls over the person who quietly would have made sure it didn't fall over in the first place
[17:45:00] <TernaryOperator> I mean if you had a fireman who fought *more* fires than any other firefighter..you'd wonder where he kept the matches ;)
[17:54:10] <olle> True, there's some psychology like that
[17:57:03] *** Quits: fahrradToken (~fahrradTo@2a02:810b:149f:f0f4::3f1) (Ping timeout: 268 seconds)
[18:06:10] *** Joins: anomander (~anomander@vps-e9abfd3d.vps.ovh.net)
[18:40:46] *** Joins: mooz (~none@23.254.112.158)
[18:41:26] *** Joins: junktext (~junktext@109.201.152.167)
[18:41:52] *** Joins: Hiccup (cHoy@2404:8000:1003:1c2e::420)
[19:15:14] *** Joins: jess (~jess@libera/staff/jess)
[19:20:56] <TernaryOperator> sadly yes
[19:21:05] <TernaryOperator> it is what it is though
[19:21:29] <biberu> soft skills are important
[19:34:31] *** Quits: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk) (Ping timeout: 252 seconds)
[19:39:31] *** Quits: Hiccup (cHoy@2404:8000:1003:1c2e::420) (Remote host closed the connection)
[19:55:43] *** Quits: guido (~guido@host-87-10-17-127.retail.telecomitalia.it) (Quit: WeeChat 3.2.1)
[19:56:23] *** Joins: guido (~guido@host-87-10-17-127.retail.telecomitalia.it)
[20:03:31] *** Joins: glumanda (~manu@194-208-201-025.tele.net)
[20:11:12] <TernaryOperator> Agreed, a good dev with good soft skills will get promoted faster than a great dev with terrible soft skills - it's not *fair* but you can also make the argument that the former is a better net benefit to the business than the later
[20:11:23] <TernaryOperator> everyone has met a brilliant arsehole enough that it gets old
[20:17:47] <biberu> it matters all the time, e.g. when trying to explain the value of your suggestions
[20:18:39] <biberu> brilliant improvements are worthless if you can't get someone else to believe in you / them
[20:22:13] *** Quits: junktext (~junktext@109.201.152.167) (Ping timeout: 252 seconds)
[20:33:07] *** Quits: tex (~dee@user/dix) (Quit: Konversation terminated!)
[20:33:55] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Ping timeout: 252 seconds)
[20:36:45] *** Joins: magla (~gelignite@55d4cb04.access.ecotel.net)
[20:41:05] *** Quits: glumanda (~manu@194-208-201-025.tele.net) (Quit: WeeChat 3.2.1)
[20:41:38] <Sammitch> TernaryOperator: that fireman analogy is apparently a real problem :P
[20:46:25] *** Quits: olle (~olle@p5785bfee.dip0.t-ipconnect.de) (Ping timeout: 252 seconds)
[21:02:03] *** Joins: WishBoy (~WishBoy@user/wishboy)
[21:08:53] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[21:36:07] <arash> Hello, When i try to install php in ubuntu using "apt install php7.4" it tries to install some other packages like "apache2 apache2-bin apache2-data", are they necessary? I mean don't php work without apache and only with nginx?
[21:36:45] <TinoDidriksen> If you only want cli, install php-cli
[21:37:04] <AllenJB> That's likely a distro packaging decision for legacy reasons. Try php-cli or php-fpm
[21:37:26] <arash> copy. thank you
[21:46:56] <TernaryOperator> or php-fpm if you are using nginx
[21:47:15] <TernaryOperator> sorry AllenJB missed your post
[21:50:29] <Sammitch> IIRC the same happens on Centos, the 'php' package is the apache module and pulls in apache if you're not paying attention :/
[21:51:07] *** Joins: clarjon1 (~clarjon1@user/clarjon1)
[21:51:21] <TernaryOperator> debian and it's descendants last time did at one point don't know if they still do
[21:52:19] <s17> its
[21:52:19] <Sammitch> it's probably just legacy at this point. at least it doesn't also pull in mysql :P
[21:52:21] <TernaryOperator> mostly what I see these days is FROM php:8.0.9-fpm-alpine
[21:52:54] <TernaryOperator> which honestly, I do kinda prefer, docker isn't bad but holy shit that learning curve if you aren't a 20 year linux veteran :)
[21:52:59] <Sammitch> RUN apk add mysql redis elasticsearch kitchen-sink docker-tears
[21:53:38] <Sammitch> TernaryOperator: I want to say it's not that bad, but I'm also a 20-year linux veteran, so...
[21:53:41] <Sammitch> ¯\_(ツ)_/¯
[21:54:22] <Sammitch> currently working on being a container veteran so I can keep being stinky about how people build containers :P
[21:55:47] <TernaryOperator> pff, if you don't multi-stage build are you even *trying*, amateurs! ;)
[21:56:10] <TernaryOperator> but yeah, I don't know how anyone gets into modern web dev, the amount to learn if you haven't picked it up organically over time is intimidating
[21:56:24] <TernaryOperator> I guess thats why Heroku and Laravel Forge make so much money ;)
[21:57:01] <Sammitch> anytime someone talks about "serverless" I get the ol stabbin urge
[21:57:59] <Sammitch> but hey multi-stage build can save you a LOT of hassle down the road
[21:58:11] <TernaryOperator> yes other barry, yes it can
[21:58:38] <Sammitch> not using multi-stage? well other barry, that's how you get ants.
[21:58:40] <TernaryOperator> it also lets you do some nifty tricks, like feed in a filesystem and get back the build artifacts idempotently across any number of machines/os's which is neat
[22:00:19] <Sammitch> and if you ever have to touch the POS that is node/npm it's useful to be able to abandon the TENS OF THOUSANDS of garbage files it litters the FS with
[22:00:33] <TernaryOperator> that's literally the case I just mentioned :D
[22:00:51] <TernaryOperator> npm ci "oh you have a slightly different version of npm, well let me just ruin you day for you"
[22:01:12] <TernaryOperator> all that mess goes away because it's all inside the container and locked to exact version - virtualising an entire OS to simulate make :D
[22:01:15] <TernaryOperator> 2021 things
[22:01:18] <Sammitch> I do devops for a node shop and the devs be all like "why the deploy take so long? the images aren't that big!" and then I scream at them about inodes for 30 consecutive minutes
[22:01:50] <TernaryOperator> heh - worked at a place where they build every container on every devs machine :)
[22:02:07] <TernaryOperator> I was like...you know you can build this once when it changes and then just pull it in and mount your volumes...
[22:02:24] <TernaryOperator> 25 minutes to 20s (w/ good bandwidth)
[22:02:30] <Sammitch> aye
[22:02:37] <Sammitch> and layer caching/sharing
[22:03:04] <da_wunder> hmm, we're using docker for dev and literally each developer has their own dev containers running - I don't see problem there
[22:03:49] <Byteflux> That's fine, but they shouldn't be building their own image
[22:04:09] <Byteflux> The image should be built already and deployed to an internal/private registry with CI/CD
[22:04:18] <Sammitch> running sure, but you should only be _building_ the containers locally that you're actively working on, not the entire env
[22:04:40] <Sammitch> [depending on how many containers comprise your app]
[22:04:49] *** Joins: Rockwood (~Rocky@user/rocky)
[22:04:59] <Byteflux> Right, might be building some images here and there, but as your app/infra grows, this becomes a huge waste of time.
[22:05:24] <Rockwood> Byteflux, o/
[22:05:50] <Rockwood> dammit PHP can grow images :D
[22:07:42] <TernaryOperator> https://github.com/wagoodman/dive is superb if you want to know *why* your image blew up
[22:08:06] <Sammitch> one thing that I kind of like here is how they already had "base" images more or less defined. they take a stock node image, drop in a bit of common config, a stack of shared libraries, and then the microservices get built on top of that. a lot of people don't appreciate how much build/deploy time something like that saves.
[22:08:28] <Rockwood> TernaryOperator, o/
[22:09:48] <TernaryOperator> evening Rockwood
[22:10:37] <TernaryOperator> the problem with docker in so far as there is one is that the documentation is vast and there isn't a lot of material that bridges the gap between beginner and the kind of thing you'd want to run in production
[22:10:49] <TernaryOperator> and that's before Kubernetes enters the conversation
[22:10:54] <Sammitch> and then they'd switch out the version of node, trigger a world rebuild, and the jenkins VM would bloat up so much they'd tip over other infra :P
[22:11:32] * Sammitch smugly lords over his k8s clusters. :3c
[22:11:38] <TernaryOperator> that's javascript ecosystem for you, determined to rewrite the last 50 years of computer science/software engineering
[22:12:29] <Sammitch> well that seems to be due to the fact that neither JS nor node ever actually bothered to implement something like stdlib
[22:13:00] <Sammitch> so every buttlord either writes their own basic string library, or pulls in one of the 50 random packages from NPM
[22:13:27] <TernaryOperator> thats a big part of it, that and instead of learning the existing tools they just leeroy jenkins it and create their own
[22:14:01] <Sammitch> and then someone gets salty and deletes the 'left-pad' package and the internet stops working
[22:14:04] <TernaryOperator> it amazes me how *fast* js is (well technically v8) the millions of person-hours pays off and it's impressive as hell what they managed to do
[22:14:36] <Sammitch> imagine what would have happend if they started with a language that _isn't_ a horrid dumpsterfire?
[22:14:55] <Rockwood> TernaryOperator, whatsup in code?
[22:15:21] <TernaryOperator> heh, psalm gets smarter and smarter, it properly respects phpstan-import-type now which mean previously passing code started failing :D
[22:15:43] <Sammitch> like yeah you can polish a turd to a diamond finish with millions of man-hours, but... y tho?
[22:15:45] <TernaryOperator> because it found the phpstan support up the hierarchy then decided that my type was less specific (which it was because at the time it didn't do that)
[22:15:53] *** Joins: ash_worksi (~ash_m@user/ash-m/x-3292451)
[22:16:10] <Sammitch> speaking of which <_<
[22:16:14] <Rockwood> TernaryOperator, o/ sorry
[22:18:38] *** Joins: DevAntoi_ (~DevAntoin@2a01:e34:ec4e:a200:cdc3:5cf:e42b:7e5)
[22:20:04] *** Joins: jgrim2367 (~jgrim@d60-65-99-197.col.wideopenwest.com)
[22:20:48] *** Joins: jgrim2364 (~jgrim@172.56.11.3)
[22:20:59] *** Quits: jgrim236 (~jgrim@d60-65-99-197.col.wideopenwest.com) (Ping timeout: 268 seconds)
[22:20:59] *** jgrim2364 is now known as jgrim236
[22:21:29] *** Quits: Rockwood (~Rocky@user/rocky) (Quit: The Time is Over)
[22:22:34] *** Quits: ash_worksi (~ash_m@user/ash-m/x-3292451) (Ping timeout: 260 seconds)
[22:22:50] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec4e:a200:c1b4:c34c:c482:361d) (Ping timeout: 268 seconds)
[22:24:05] *** Joins: jgrim2361 (~jgrim@d60-65-99-197.col.wideopenwest.com)
[22:24:54] *** Quits: jgrim2367 (~jgrim@d60-65-99-197.col.wideopenwest.com) (Ping timeout: 260 seconds)
[22:25:58] *** Quits: jgrim236 (~jgrim@172.56.11.3) (Ping timeout: 252 seconds)
[22:25:58] *** jgrim2361 is now known as jgrim236
[22:32:19] *** Joins: ash_worksi (~ash_m@user/ash-m/x-3292451)
[22:40:41] *** Joins: semeion (~semeion@user/semeion)
[22:41:40] *** Joins: carlino3 (~carlino3@user/carlino3)
[22:43:48] *** Joins: tlaxkit (~hexchat@170.253.35.150)
[22:54:22] *** Joins: coder7of9 (~coder7of9@modemcable007.22-130-66.mc.videotron.ca)
[23:00:14] *** Joins: funhouse (~funhouse@user/funhouse)
[23:01:32] <coder7of9> i am deciding a best scenario.. i will connect from apache php to a loacl nodejs server and use puppeteer to create on the fly pdf files which i will then server back to a user who clicked the pdf button on a page.    that is the sole purpose of the nodejs server.  scenarios 1) run an open nodejs server on port 8080 and send the request directly 2)
[23:01:33] <coder7of9> run nodejs on localhost only and use proxypass and connect voa a /nodejs/ url through apache and php and send the urls directly to this path 3) run nodejs on localhost only and access a php page which uses curl to fetch the pdf byes from the nodejs server ....    i think option 1 is most efficient but exposes an ugly long url, option 2  is the same
[23:01:33] <coder7of9> as option 1 but slightly more secure - extra overhead?   option 3 most secure but curl overhead?   what do you think
[23:02:39] <da_wunder> coder7of9: I would recommend you to use external service for pdf creation, like - https://github.com/by-pinja/pdf-storage
[23:02:44] *** Quits: funhouse (~funhouse@user/funhouse) (Client Quit)
[23:03:05] *** Quits: Junxter (~Junxter@222.95.222.185) (Read error: Connection reset by peer)
[23:03:24] *** Joins: Junxter (~Junxter@222.95.222.185)
[23:03:53] <da_wunder> coder7of9: with that you just make that create request, you get instant response with URL that has that PDF - users can just open that url and they will see actual PDF or "generating pdf" notice if that pdf is not yet generated
[23:04:20] <da_wunder> coder7of9: and that service can literally create thousands of pdf's
[23:05:21] <coder7of9> it looks interesting....
[23:06:34] <coder7of9> it still needs to run on my domain.... so just an alternative to nodejs and puppeteer?
[23:13:03] <carlino3> coder7of9 not familiar with puppeteer, but i can see by a quick search that it is some kind of headless browser driver
[23:13:20] *** Quits: tlaxkit (~hexchat@170.253.35.150) (Quit: Leaving)
[23:13:30] <carlino3> what are you trying to do? print a website to PDF?
[23:13:33] *** Joins: funhouse (~funhouse@user/funhouse)
[23:14:43] <coder7of9> yes... similar... users have differnt reports. many will be available to save as a pdf. so the service receives a custom url with a time constrained token to access the page.
[23:15:38] <carlino3> do you control these URLs that you have to print, or these are external services?
[23:15:50] <coder7of9> i control the urls.
[23:16:11] <carlino3> then why launching a headless browser? generate a PDF server side and server that to the users
[23:18:38] <coder7of9> puppeteer will reate the pdf in context of the user... logos, and other artifacts. so there is a need to view the page as a user.   setting up templates for each pdf would be time consuming, and require maintenance.   i think a dumb url passed to a service which only runs loaclhost.... and a check on the url to ensure it complies with what is
[23:18:39] <coder7of9> expected.
[23:19:29] <coder7of9> plus of course the time token.... which allows the logn
[23:19:42] <coder7of9> 30. seconds
[23:20:03] <__adrian> none of that answers why you need a headless browser
[23:20:28] <__adrian> a better question than "do you control the URL" might be "do you control the content"
[23:20:35] <coder7of9> yes
[23:20:49] <coder7of9> how woudl i create pdf on the fly
[23:20:49] <__adrian> the implication there is "why don't you just generate the PDF directly?"
[23:21:06] <__adrian> there's no need to launch a browser to get content you literally already have
[23:21:18] <coder7of9> i will not use those dodgey jcreatpdjs services
[23:21:25] <__adrian> what?
[23:21:28] <carlino3> or maybe just add a "print" button and let the user print it to a PDF or whatever they want
[23:21:32] <coder7of9> how to generate the pdf
[23:21:55] <coder7of9> i seelet the browser save to pdf
[23:22:03] <coder7of9> i see let ...
[23:22:06] <__adrian> there are plenty of pdf libraries, even ones that take html as input. i'd assumed you already had one.
[23:22:10] <coder7of9> yes is an option.
[23:22:46] <coder7of9> the pages have graphs and use highcharts for example so it has to render
[23:23:15] <carlino3> i would generate the PDF server side as i said, with a PHP library for that.
[23:24:44] <coder7of9> i will investigate this option.  the only way to create apdf of some pages would be a screenshot, or a render, or some library which can understand the charts
[23:25:00] <coder7of9> i used a pdf generator previously and it was a lot of work.
[23:25:15] <coder7of9> headless is dumb and simple.
[23:25:16] <Byteflux> Headless Chromium doesn't sound like a terrible idea, I assume you are wanting to use the "Print to PDF" feature.
[23:25:26] <Byteflux> Which you can with headless.
[23:25:49] <TinoDidriksen> wkhtmltopdf still works wonderfully.
[23:25:53] <carlino3> in any case, if you go for the headless browser solution, get a PHP driver for that and forgot about messing with node
[23:25:53] <coder7of9> yes i have aworking model.  end to end
[23:26:02] <carlino3> but i don't think that's a good solution for me
[23:26:15] <coder7of9> php driver can't trasfer efficiently via sockets....
[23:26:18] <coder7of9> some issues
[23:26:37] <coder7of9> php to node you mean?
[23:27:01] <coder7of9> i looked into php to node... better curl or proxypasss
[23:27:21] <Byteflux> Scripting Chrome with Puppeteer is how you're supposed to do it, so Node is a good choice if you went that route.
[23:27:42] <carlino3> i mean launching and controlling the headless browser via PHP
[23:27:53] <coder7of9> really
[23:27:59] <coder7of9> php can do that
[23:28:01] <Byteflux> Puppeteer was made specifically by Google for scripting Chrome
[23:28:06] <Byteflux> THere is no equivalent PHP library to my knowledge
[23:28:48] <carlino3> selenium?
[23:29:12] <coder7of9> thanks for your input.  i will try proxypass and if i have performance issues switch to am accessible port
[23:29:36] <coder7of9> not localost
[23:31:11] <Byteflux> Depending on the complexity of your needs, you might be able to just get away with using the command line options for printing to PDF, though it isn't as fully customizable as Puppeteer, I don't think.
[23:32:46] <Byteflux> All of the visual customizations you'd need to make, if any, should be easily doable with a `@media print { ... }` in CSS.
[23:33:06] <Byteflux> So I think you'd have success with just the command-line based headless chrome.
[23:33:40] <coder7of9> command line will create the pdf? however i thought to only return the bytes.
[23:33:57] <Byteflux> Yes, you can print to PDF with headless command-line.
[23:34:17] <coder7of9> that would require passthru?   and it saves a pdf to the disk or returns bytes?
[23:34:31] <Byteflux> chrome --headless --print-to-pdf filename.pdf https://www.google.com
[23:34:55] <Byteflux> I don't think it's wise to passthru even if you could.
[23:34:56] <coder7of9> with node i never need to save the pdf to disk...
[23:35:01] *** Quits: Naktibalda (~Naktibald@88.135.22.17) (Quit: IceChat - Keeping PC's cool since 2000)
[23:35:17] <coder7of9> how would you do command line from php
[23:35:20] <Byteflux> Ideally you would have a queue running in the background.
[23:35:23] <Byteflux> Which you send a job to
[23:35:37] <coder7of9> okay like cron checking
[23:35:49] <coder7of9> the queue
[23:36:20] <Byteflux> Not really like cron, but I guess you could if you wanted to...
[23:36:33] *** Joins: junktext (~junktext@109.201.152.164)
[23:36:44] <Byteflux> Point being that someone shouldn't be able to just spin a headless Chrome instance every time they download a PDF
[23:37:16] <coder7of9> what would run the commnd line
[23:38:12] <coder7of9> daemon process
[23:38:40] <coder7of9> it has to be timely ....
[23:40:06] <coder7of9> php exec or system ?
[23:40:32] <coder7of9> or another process which monitors a quque
[23:40:40] <coder7of9> queue
[23:41:31] <Byteflux> If you're asking how to do this then I think you'll have an easier time just running a Browserless Docker container and using its REST API :P
[23:41:53] <Byteflux> It'll run in the background as a web server, you just need to call its API with PHP
[23:42:01] <Byteflux> And if you want, you can passthru the response
[23:42:14] <coder7of9> thanks... i will investigate
[23:42:22] <Byteflux> https://hub.docker.com/r/browserless/chrome
[23:42:28] <Byteflux> https://docs.browserless.io/docs/pdf.html
[23:42:37] <Byteflux> Very simple.
[23:42:52] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[23:46:31] <coder7of9> addesses much of what i am looking for... replacing nodejs with docker...
[23:47:07] <coder7of9> and a command line access point
[23:47:32] *** Joins: tlaxkit (~hexchat@170.253.35.150)
[23:48:03] <coder7of9> but is it really that different... it still runs a server.
[23:48:35] <coder7of9> creates a queue?
[23:50:03] *** Joins: Bushmaster (~Goondog@user/bushmaster)
[23:50:23] <Bushmaster> server is working cool AllenJB
[23:50:38] <Bushmaster> PHP is all functioning in Apache
[23:52:45] <da_wunder> just saying that creating PDF's on the fly could be really tricky - you literally cannot handle thousands of parallel requests without using massive computer...
[23:53:09] <da_wunder> that is why eg. we created that pdf-storage microservice to handle stuff like that properly
[23:54:08] <da_wunder> and as Byteflux mentioned earlier - that service is using queue to handle those jobs with n workers
[23:55:50] *** Parts: Bushmaster (~Goondog@user/bushmaster) (later folks)
[23:59:11] *** Quits: coder7of9 (~coder7of9@modemcable007.22-130-66.mc.videotron.ca) (Quit: Ping timeout (120 seconds))
