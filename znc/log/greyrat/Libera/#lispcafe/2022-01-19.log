[00:00:36] <White_Flame> there are no registers, but a logical notion "conveyor belt" of the last N generated values that can be further used as inputs (and scratchpad, stack, etc for what doesn't fit in flight)
[00:01:25] <White_Flame> the memory model, execution model, protection model, lookahead, cache, etc are all rethought and advanced, in a really well thought out holistic interoperation with each other
[00:01:35] <White_Flame> but we'll see if practice follows theory
[00:02:20] <shka> important part about mill
[00:02:29] <sm2n> wish they put made their patent pool free for hackers
[00:02:30] <shka> is that this whole thing really pivots on jit
[00:02:45] <White_Flame> right, first thing I mentioned ;)
[00:02:57] <selwyn> jit seems popular enough?
[00:03:09] <White_Flame> not really
[00:03:31] <White_Flame> all the JITs are part of the binary blob execution layer, and tons of applications don't jit
[00:04:05] <White_Flame> especially with python being as popular as it is :-P
[00:04:29] <sm2n> there is pypy
[00:04:34] <moon-child> and graalpython
[00:04:40] <White_Flame> there is, but most people use default cpython
[00:04:45] <White_Flame> (or whatever it's called)
[00:05:25] <selwyn> so the efficiency advantages won't be apparent for things that aren't jitted?
[00:05:33] <White_Flame> we also need a "graal" where the portable language layer is CL
[00:05:58] <White_Flame> selwyn: the assembly code of the machine is never exposed
[00:06:15] <White_Flame> the mill isa gets compiled to the specific cpu it's running on
[00:06:25] <White_Flame> and actually, it's AOT, not JIT, as it doesn't recompile at runtime
[00:06:55] <White_Flame> and mill supplies the mill isa -> binary compiler themselves
[00:07:10] <sm2n> Now I am confused
[00:07:15] <White_Flame> the portable code is basically a dataflow network representation
[00:07:30] <White_Flame> sm2n: you get a program, on first run it compiles it to your specific cpu
[00:07:59] <White_Flame> adn thus the CPU itself doesn't have to do any weird scheduling
[00:08:00] <sm2n> So you can't actually program against intruction latencies?
[00:08:14] <White_Flame> that's what the compiler is for
[00:08:25] <sm2n> ehhhhhh
[00:08:26] <White_Flame> and different models in the cpu line have different tradeoffs
[00:08:43] <White_Flame> I'm sure you could generate your own CPU-specific code, but why?
[00:08:46] <sm2n> I don't know if I buy it
[00:08:47] <White_Flame> it wouldn't be portable
[00:08:59] <sm2n> Well, the state of the art autovectorizers are still... really bad
[00:08:59] *** Joins: molson (~molson@2001:48f8:704a:123d::75f:1021)
[00:09:05] <White_Flame> the model seems thorough, the team is extremely experienced, etc
[00:09:06] <White_Flame> no
[00:09:09] <White_Flame> there are no autovectorizers
[00:09:18] <White_Flame> vectorization is expressed in the portable code
[00:09:39] <sm2n> you still need to know latencies to write good compute kernel style things
[00:09:39] <White_Flame> and then the local compiler casts that down into the specific hardware instructions & sizes it supports
[00:10:08] <White_Flame> sure, if you're going to hand-write code for 30+ different processors within the family :-P
[00:10:18] <sm2n> Well that's what metaprogramming is for
[00:10:22] <White_Flame> what sort of decisions are you considering that wouldn't be portable?
[00:10:28] <White_Flame> their whole system is metaprogrammed
[00:10:36] <White_Flame> their hardware ISA per chip is auto generated
[00:10:40] <Alfr> sm2n, autovectorization isn't really the problem, but the languages we use to express problems usually don't let us state what we want in vectorized form in the first place.
[00:10:48] <White_Flame> the compiler is configured per processor parameters
[00:11:15] <sm2n> Alfr: that's true
[00:11:44] <sm2n> White_Flame: Hmm, I suppose it seems plausible that it wouldn't really matter
[00:12:00] <White_Flame> I'm a big fan of their model, but I'm not blind fanboy about any idea of if it'll ship or what it's actual real world performance/power will be
[00:12:27] <Alfr> sm2n, e.g. matlab/octave do use vectorized operations and the language you can write in actually beg for this.
[00:13:10] <Alfr> sm2n, though I wouldn't recommend using them for general stuff.
[00:13:17] <sm2n> Alfr: Of course, I think the most dramatic form of this co-dfns apl
[00:13:32] <moon-child> 'the portable code is basically a dataflow network representation'  ehh this is kinda irrelevant
[00:13:57] <moon-child> machine code is _already_ processed as a dataflow graph, passed through from the compiler to the processor
[00:14:02] <epony> https://en.wikipedia.org/wiki/Tremont_(microarchitecture)#Processors_for_base_transceiver_stations_(Snow_Ridge)
[00:14:04] <White_Flame> meaning it has no bearing at all (nor implicit limitations) of any static machine model
[00:14:30] <moon-child> sm2n: apl is not really 'auto' vectorization though, it's just vectorization; the language semantics are inherently parallel
[00:14:40] <sm2n> yeah
[00:14:48] <White_Flame> right, I presume "autovectorization" means turning manual loops into hardware vector instructions
[00:15:10] <sm2n> That is kind of what I was getting at
[00:15:25] <sm2n> Though having vectorized primitives is enough much of the time
[00:15:33] <moon-child> I mean, I wouldn't call turning a loop where you call _mm256_andpd into VANDPD an autovectorizer
[00:15:34] <White_Flame> they've got a loop pipelining model as well, which is quite cool
[00:15:42] <White_Flame> anyway, as I said, I like their model :-P
[00:16:16] <sm2n> moon-child: I am not talking about intrinsics
[00:16:18] <White_Flame> moon-child: loop of a[x]=b[x]+c[x]
[00:16:44] <moon-child> White_Flame: indeed.  Except most useful cases are a lot more interesting than that :P
[00:17:04] <sm2n> Everything is a matrix if you look at it hard enough
[00:17:11] <moon-child> (but apl has no stinking loops to autovectorize in the first place)
[00:17:17] <White_Flame> however, the one downside I see of the mill is that it's very C-oriented, and doing intersting things with multiple stacks or whatever have some impedance mismatch
[00:17:45] <sm2n> does it make implementing continuations harder?
[00:18:07] <sm2n> multi-shot to be clear
[00:18:13] <moon-child> ah yeah, I have similar worries about forwardcom
[00:19:35] <Alfr> White_Flame, autovectorizing that for C may get you into hell when the regions of a, b, c overlap in an unfortunate manner.
[00:20:59] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 268 seconds)
[00:21:36] <White_Flame> sm2n: right, the stack is hardware-managed in its security model, and I don't know how willy-nilly you can get with flinging around SP everywhere
[00:22:04] <sm2n> ew
[00:23:42] * moon-child spots read_call_stack, write_call_stack in forwardcom manual.  Very heavy-handed instructions.  No efficient nonlocal control-flow
[00:23:47] * moon-child looks at mill wiki
[00:24:13] <sham1> sm2n: a tensor, not a matrix
[00:29:32] <moon-child> hmm, mill does not seem to be able to do nonlocal returns
[00:29:33] <moon-child> :/
[00:30:02] <White_Flame> well,t heir goal is running stock C linux on it, so surely the need setjmp/longjmp support
[00:30:14] <White_Flame> and I thought they already had a bunch running on their simulators on their ISAs
[00:31:18] <moon-child> iirc they are running l4
[00:32:05] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 268 seconds)
[00:32:30] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[00:39:29] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 268 seconds)
[00:40:38] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Remote host closed the connection)
[00:41:02] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[00:41:10] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[00:49:02] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 240 seconds)
[00:51:22] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[01:12:23] <shka> https://marketplace.visualstudio.com/items?itemName=ailisp.commonlisp-vscode anybody tried using this?
[01:12:24] -ixelp- Common Lisp - Visual Studio Marketplace
[01:15:47] <drakonis> if i recall correctly, the correct option is alive
[01:18:59] * moon-child doesn't understand why anyone would use vscode
[01:19:09] <moon-child> vs is somewhat interesting.  vscode is just ... ... what's the point?
[01:19:52] <moon-child> also slow
[01:20:28] *** Quits: kevingal (~quassel@2001:770:c0:401:896d:e00e:eb5c:d428) (Remote host closed the connection)
[01:28:40] <sm2n> what is interesting about vs?
[01:29:13] <shka> sm2n: good for C#, also pretty good for C++
[01:29:20] <sm2n> vscode is emacs for people who enjoy javascript and corporate capture, which worryingly is a large market
[01:29:20] <shka> has really nice C++ profiler
[01:29:25] <moon-child> deep integration with its c compiler, refined over ~30 years
[01:29:28] <sm2n> ah
[01:29:35] <moon-child> clangd is, what, 10 years old?  Can't really compete
[01:30:03] <sm2n> it has worked pretty well for me, but I have not really used vs to compare
[01:30:03] <shka> eh, that C compiler integration... is not that deep actually :D
[01:30:08] <sm2n> I
[01:30:16] <sm2n> 've only heard good things about its debugger
[01:30:19] <moon-child> clangd was crap last time I used it
[01:30:27] <sm2n> but people have moved on now for that too I think
[01:30:37] <shka> sm2n: debugger is fine, but profiler is just great 
[01:30:39] <sm2n> moon-child: what was wrong?
[01:31:03] <shka> the problem w MS C compiler is that it does not lend itself toward use in IDE
[01:31:32] <moon-child> crashed repeatedly.  Did not have high-quality autocompletions.  Didn't know what to do about header files
[01:32:13] <sm2n> moon-child: did you generate the compile_commands.json thing?
[01:32:34] <sm2n> the crashing has been more or less fixed, I think
[01:32:34] <moon-child> yes
[01:32:55] <sm2n> there is also ccls which was always more stable in my experience
[01:33:00] <moon-child> I mean, the problem is that compile_commands.json doesn't tell you how to compile headers.  So it's understandable it was confused
[01:33:11] *** Joins: dec0d3r (~dec0d3r@2001:8003:480a:e00:e07:e7c3:7efc:ed0f)
[01:33:34] <sm2n> oh, were you working on some header-only thing?
[01:33:44] <moon-child> no.  But I still had headers
[01:33:55] <moon-child> occurs to me I coulda maybe tried precompiled headers, but headers don't stand on their own so eh idk how well that woulda worked
[01:34:20] <sm2n> That should be fine? It just needs to know what headers to parse using your linker options as I understand it
[01:34:31] <sm2n> it should parse the #include directives after that
[01:34:34] <shka> anyway, the problem with emacs, is that it has somewhat steep learning curve
[01:34:41] <shka> on to of CL learning curve 
[01:35:07] <shka> which is not the most practical 
[01:35:14] <selwyn> yes
[01:35:16] <shka> and VS is widely popular
[01:35:25] <shka> there is also something for atom
[01:35:35] <selwyn> currently struggling to convince people to learn due to this
[01:35:47] <selwyn> shka: i know someone who gave up atom for emacs eventually
[01:35:48] <sm2n> Also, I was under the impression that vs was infamous for crashing all the time
[01:36:11] <shka> sm2n: i only know about that blinking cursor 
[01:36:18] <shka> it was funny :-)
[01:36:58] <shka> selwyn: i honestly think that emacs is actually superior editor to atom or vs code, so i see that
[01:37:02] <moon-child> sm2n: well, idk, but it didn't do that
[01:37:19] <shka> https://old.reddit.com/r/programming/comments/612v99/vs_code_uses_13_cpu_when_idle_due_to_blinking/
[01:37:21] -ixelp- VS Code Uses 13% CPU When Idle Due to Blinking Cursor Rendering : programming
[01:37:33] <sm2n> heh
[01:37:51] <sm2n> moon-child: idk; how were you using it?
[01:38:02] <selwyn> the guy is also the biggest python weenie i know, lol
[01:38:14] <moon-child> sm2n: emacs irony-mode and clion
[01:38:21] <moon-child> may have also hooked it up to vim at one point
[01:38:37] *** Quits: molson (~molson@2001:48f8:704a:123d::75f:1021) (Quit: Leaving)
[01:38:54] <shka> https://www.youtube.com/watch?v=BRxtE5G_oCk that video 
[01:38:54] -ixelp- Visual Studio Epic Cursors Live Demo - YouTube
[01:39:01] <shka> what a soundtrack
[01:39:13] <sm2n> I just use the default emacs c-mode with eglot and clangd
[01:39:26] <sm2n> it works fine for it with barely any config
[01:39:29] <sm2n> s/it/me/
[01:40:05] <moon-child> eh
[01:40:15] <shka> well, what i like about emacs is that it is universal
[01:40:19] <moon-child> ultimately what I want is really high-quality contextual autocompletion, which it wasn't able to provide when it did work
[01:40:24] <moon-child> so not a huge value loss either way
[01:40:29] <shka> no matter what you are trying to do, emacs has got you covered
[01:40:33] <shka> unless you are doing java
[01:41:07] <moon-child> for a moment, no idea why, I mistook 'java' for 'sex'
[01:41:22] <moon-child> and was going to point out that people have, in fact, made teledildonics packages for emacs
[01:41:25] <shka> oh, no, i suspect that emacs has modules for sex
[01:41:30] <sm2n> it does
[01:41:32] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 240 seconds)
[01:41:36] <shka> well, here you go
[01:41:42] <sm2n> at any rate, emacs does have java stuff nowadays
[01:41:45] <shka> emacs users achieved the sex
[01:41:51] <shka> but refuse to do java
[01:42:10] <sm2n> I've heard of people who do java in vim
[01:42:17] <sm2n> vanilla vim even
[01:42:20] <shka> weird
[01:42:25] <moon-child> I did that once
[01:42:30] <moon-child> of course I didn't really know java
[01:42:55] <sm2n> I think the main thing about java is that typical codebases have really weird heavy-handed abstractions
[01:43:14] <shka> i found java to be unbearable without IDE that generates stuff at a key-press to be a bad time 
[01:43:14] <sm2n> so the claim is that you need fancy automatic refactoring tools
[01:43:21] <shka> well, java in general is a bad time 
[01:43:39] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[01:43:39] <sm2n> shka: iirc emacs has java autocompletion and stuff now
[01:43:58] <sm2n> <http://skybert.net/emacs/java-programming-in-emacs-with-meghanada-mode/>
[01:43:59] -ixelp- Java programming in Emacs with Meghanada mode | skybert.net
[01:44:01] <sm2n> for instance
[01:44:04] <shka> hopefully i won't have to use it but thanks :D
[01:44:10] <shka> i don't enjoy programming in java
[01:44:21] <sm2n> I've never used it
[01:44:52] <shka> back to lisp editors
[01:45:05] <shka> i have a feeling that atom-slime will be better 
[01:45:06] <moon-child> the main thing I want from an editing environment is good buffer management.  I haven't found a good solution yet.  I can not abide typiing in the name of a buffer to switch to it, which seems to be what emacs wants you to do
[01:45:33] <moon-child> need something that takes good advantage of temporal locality, without compromising orientation
[01:45:40] <sm2n> moon-child: there are alternative approaches
[01:45:53] <sm2n> such as tabs, "present window"-esque stuff, etc
[01:46:03] <shka> good night all
[01:46:06] <sm2n> night
[01:46:07] <moon-child> shka: night
[01:46:31] <selwyn> goodnight
[01:46:38] <moon-child> sm2n: how do they solve the conflict between temporal locality and orientation?
[01:46:48] <sm2n> I'm not sure what you mean by orientation
[01:47:38] <moon-child> maybe that's better called spatial locality.  I orient myself such that I know, when I am at buffer X, where buffer Y is wrt me
[01:48:04] <sm2n> moon-child: What wm do you use?
[01:48:08] <moon-child> fvwm
[01:48:35] <sm2n> hmmm
[01:49:05] <sm2n> Do you have the same issue there?
[01:50:13] <moon-child> sort of.  Not really, only because I tend to have relatively few x-level windows open at a given time.  But stratification is a problem.  My browser has one window/buffer abstraction, my mail client another, my irc client another, my editor another, terminal multiplexer another...
[01:50:55] <moon-child> In some respects, these form a logical hierarchy, so it's not as bad as it could be, but it's still disconcertingly ununified
[01:51:01] <sm2n> Right, I have the issue
[01:51:07] <sm2n> (arcan)
[01:51:20] <sm2n> death to widgets etc etc
[01:51:40] <selwyn> https://www.youtube.com/watch?v=y_bwKW6V1lw
[01:51:40] -ixelp- Epic Cycling on Ice - YouTube
[01:51:43] <sm2n> What do you think of paperwm wrt spatial locality?
[01:51:48] <moon-child> widgets compose, at least, so long as you only have one widget abstraction
[01:51:55] * moon-child looks up paperwm
[01:54:02] *** Quits: shka (~herr@109.231.0.226) (Ping timeout: 240 seconds)
[01:55:40] <moon-child> 1-d layout is a shame
[01:55:46] * selwyn read that as papereum
[01:56:05] <selwyn> an exciting new cryptocurrency using paper notes and backed by fiat
[01:56:11] <moon-child> I have 2-d layout (3x3 vdesktops) in fvwm
[01:57:30] <moon-child> workspace model is interesting.  I'm not quite sure if that's the right place to draw the line, but
[01:58:53] <moon-child> wrt locality I think that, just as a window is a view into a buffer, so should there be a 'workspace' which encapsulates a collection of buffers, and some sort of 'view' which permits access to buffers from selected relevant workspaces
[02:00:42] <sm2n> moon-child: have you used eyebrowse?
[02:01:15] <moon-child> nope
[02:01:17] * moon-child looks
[02:05:49] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 268 seconds)
[02:07:15] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[02:10:04] <hayley> https://www.youtube.com/watch?v=EAFu1wj2f44
[02:10:04] -ixelp- Telekon - YouTube
[02:14:05] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[02:14:56] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[02:25:59] *** Quits: random-nick (~random-ni@87.116.181.150) (Ping timeout: 256 seconds)
[02:30:02] *** Joins: notzmv (~zmv@user/notzmv)
[02:32:57] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 268 seconds)
[02:33:10] <sm2n> selwyn: <https://noplacetohide.org.uk/> what is going on
[02:33:10] -ixelp- No Place to Hide
[02:34:36] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[02:35:58] <selwyn> no-one knows how the 14 million figure was come up with
[02:36:09] <selwyn> except it simply seems to be the number of children in the uk
[02:38:17] * moon-child makes a note never to move to the uk
[02:38:40] * hayley wasn't planning on going to TERF island before
[02:40:46] <moon-child> a trans friend moved from the uk to de, and says drugs were much easier to come by in the former
[02:41:02] <moon-child> but yeah political situation in uk has never been great
[02:41:08] <selwyn> its also thought that this campaign is a cheap attempt to distract from the governments fuckups
[02:41:42] <selwyn> it is also noted that the website uses ssl, lol
[02:43:44] <lagash> moon-child: you mean the sex-changing kind of hormones/drugs?
[02:45:27] <lagash> selwyn: gov't hypocrisy eh?
[02:48:58] <selwyn> these idiots appear to genuinely believe that end to end encryption is invulnerable
[02:49:02] <selwyn> don't know what backdoors are
[02:50:11] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 256 seconds)
[02:51:55] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[02:54:34] *** Joins: molson (~molson@2001-48F8-704A-123D-0-0-75F-101F-static.midco.net)
[02:54:49] <selwyn> its also impossible to get people to care about this
[03:01:04] <pl> https://github.com/water111/jak-project some mad lispers (is there any other kind?) decompiled Jak&Dexter back to GOAL and started implementing PC version of GOAL
[03:01:04] -ixelp- GitHub - water111/jak-project
[03:01:59] <White_Flame> heh, cool.  there's enough description about GOAL that it sounded relatively straightforward, from an ABI perspective
[03:02:52] <pl> though, uh, uncool for reimplementing the compiler/devtools in C++
[03:03:03] <pl> White_Flame: in terms of ABI it was pretty simple, yes
[03:03:04] <White_Flame> ugh
[03:03:25] <White_Flame> but the yeah, the function bodies are still the typical reverse engineering isseu
[03:03:33] <pl> at least the game continues to be implemented in a lisp
[03:06:08] <hayley> https://github.com/water111/jak-project/blob/142961a74788cd986a9624bc1d34762bbb4ec63c/goal_src/engine/entity/entity.gc Someone make a PR to fix all the dangling parens?
[03:06:08] -ixelp- jak-project/entity.gc at 142961a74788cd986a9624bc1d34762bbb4ec63c · water111/jak-project · GitHub
[03:06:50] *** Joins: kevingal (~quassel@2a02:8084:4140:f300:dc6a:cea3:1af:140f)
[03:10:08] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[03:18:26] <selwyn> pl: damn
[03:19:43] *** Joins: pjb (~pjb@user/pjb)
[03:19:43] <selwyn> it seems like they are on course to finish soon?
[03:23:52] <Catie> Oh I'm so pumped
[03:24:12] *** Quits: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net) (Ping timeout: 256 seconds)
[03:27:19] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[03:37:12] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[03:43:52] <Gnuxie> <hayley> "https://github.com/water111/jak..." <- Iirc Andy Gavin wrote like that too so LwL
[03:44:05] * hayley uploaded an image: (11KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/suQfIhUNleqtcBUZpnykULFq/bruhcha.jpg >
[03:44:50] <Gnuxie> Insomniac games also made GOAL redundant even in naughty dog 
[03:46:14] <Gnuxie> My source is Mike Stout he says in one of the R&C commentary videos 
[03:50:41] <pl> Gnuxie: Redundant in what way? Last I checked, the official story was that they faced a bit of underinvestment in GOAL support combined with getting bought by Sony who wanted their chops focused on providing tech for other teams and that meant C++, combined with biggest issue which was PS3 requiring completely new backend (two, in fact)
[03:51:07] <pl> they continued to use Lisp (mostly PLTScheme/Racket) for tooling
[03:51:23] <pl> (and of course GOOL kinda resurrected itself in Uncharted)
[03:54:35] <Gnuxie> Can't remember but they replaced the need for it, insomniac obviously didn't think everyone could be assed to read lisp so they replaced it with some c junk and gave that junk back to ND as part of their tech share thing
[03:58:14] <pl> That's not exactly a workable story, afaik 
[03:58:56] <pl> Insomniac might have shared some modules in C++, but ND continued to write custom engines, just in C++
[03:59:26] <pl> And GOAL was more replacement of GCC than an engine 
[03:59:56] <pl> The Lisp based tooling continued till at least first The Last of Us, afaik 
[04:03:20] <Gnuxie> Dunno story is from an Insomniac 
[04:04:14] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[04:07:15] <pl> Gnuxie: there was a jak&daxter game developed by another studio of former insomniac developers, who used ratchet&clank engine 
[04:09:09] <Gnuxie> Naa
[04:09:14] <Gnuxie> I cba to find the video 
[04:09:31] <Gnuxie> But I migjt 
[04:11:04] <pl> The remake for ps4 is also a complet redo 
[04:11:29] <pl> But that was vicarious games essentially reversing it
[04:14:30] <Gnuxie> R&C remake was disgusting 
[04:15:29] <Gnuxie> Plumber should be back with hard hitting critique of socio economic disparity 
[04:16:08] <pl> Dunno about R&C. Crash Bandicoot remake was done by essentially super imposing render from original game and working till the new code behaved exactly the same but with more detail 
[04:36:02] *** Quits: waleee-cl (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 240 seconds)
[04:40:21] *** Joins: waleee-cl (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
[04:43:33] <White_Flame> yeah, I was really disappointed in the R&C remake.  I guess it was more of a movie tie-in than anything
[04:43:44] <White_Flame> looked pretty, though :-P  but the story was just gone
[05:34:48] *** Quits: waleee-cl (~waleee@h-98-128-229-110.NA.cust.bahnhof.se) (Remote host closed the connection)
[05:35:13] *** Joins: waleee-cl (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[05:43:32] *** Quits: molson (~molson@2001-48F8-704A-123D-0-0-75F-101F-static.midco.net) (Ping timeout: 240 seconds)
[05:46:33] *** Quits: kevingal (~quassel@2a02:8084:4140:f300:dc6a:cea3:1af:140f) (Remote host closed the connection)
[05:57:04] *** Quits: waleee-cl (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 268 seconds)
[06:00:46] * hayley has a new mouse that actually tracks on the desk now.
[06:01:00] <hayley> The packaging says it is a "business mouse", whereas it says "gaming mouse" on the mouse. Confusing.
[06:02:32] <moon-child> is gaming not business?
[06:04:06] <hayley> Depends on what your job is.
[06:04:10] * hayley needs to make another meme to test this mouse.
[06:14:38] <hayley> https://www.reddit.com/r/LispMemes/comments/s7fckr/savelispanddie_hard/
[06:14:39] -ixelp- SAVE-LISP-AND-DIE Hard : LispMemes
[06:20:36] <mfiano> White_Flame: I want to bug you again but I don't :)
[06:21:39] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[06:27:41] <mfiano> Or anyone good at the bit twiddlies
[06:30:58] <hayley> Go on then.
[06:31:02] <mfiano> https://gist.github.com/mfiano/3d66ecad014be2c5a0e9381d4b6b3a50
[06:31:02] -ixelp- cmyk.lisp · GitHub
[06:31:07] <mfiano> See TODO
[06:32:54] <hayley> You want to make this work with 16-bit components?
[06:33:10] <White_Flame> just remove the (* _ #x101) if the input is already 16-bit
[06:33:31] <mfiano> I tried that
[06:33:56] <White_Flame> your example in the comments uses (* 32 #xff) instead of (* 32 #x101)
[06:34:13] <White_Flame> assuming that multiplication is the 8->16 bit conversion
[06:34:54] <mfiano> Oh no wonder
[06:35:02] <mfiano> Off by 2 error :/
[06:35:31] <hayley> Such is life.
[06:35:36] *** Joins: molson (~molson@2001-48F8-704A-123D-0-0-75F-1021-static.midco.net)
[06:35:47] <White_Flame> test failed: problem in test
[06:36:03] <White_Flame> *problem in test itself
[06:36:22] <mfiano> Haha
[06:36:54] <hayley> https://www.ribbonfarm.com/2020/06/23/two-spooks/
[06:36:55] -ixelp- Two Spooks
[06:49:25] *** Quits: molson (~molson@2001-48F8-704A-123D-0-0-75F-1021-static.midco.net) (Remote host closed the connection)
[06:50:00] *** Joins: molson (~molson@2001-48F8-704A-123D-0-0-75F-1021-static.midco.net)
[06:50:59] <mfiano> How can I derive #x101, #x10101, ... from bit widths 8, 16, ... ?
[06:53:57] <hayley> (loop for n from 0 to bytes collect (expt 256 n))?
[06:54:45] <mfiano> I thought there'd be a clean instruction or two than an iterative solution. Maybe not...
[06:55:13] <moon-child> you'd want #x10001 for 16, no?
[06:55:17] <mfiano> No
[06:55:20] <moon-child> well, depends on what you want it to do
[06:55:26] <hayley> I was thinking of a sort of "broadcast" operation.
[06:55:26] <moon-child> I assumed you want to replicate 16->32 bits
[06:55:49] <moon-child> #x10101 would be 8->24
[06:55:51] <mfiano> I want the equivalent of (logior x (ash x 8) (ash x 16)) stopping at the given bit width (here 16)
[06:56:00] <mfiano> That would be (* x #x10101)
[06:56:15] <mfiano> Rather than using the logior, I'm trying to map 16 to #x10101
[06:56:29] <mfiano> and 8 to #x101, etc
[06:57:23] <moon-child> (loop for i below (1+ (/ x 8)) sum (expt 256 i))
[06:58:21] <mfiano> Ok fine, I'll iterate :)
[06:58:56] <moon-child> don't like loop?
[06:59:29] <mfiano> It's not that, I was just trying to express it like someone that just read Hacker's Delight :)
[07:00:13] <moon-child> hmm.  Given (1- (ash 1 (ash x -3))), if you scatter the bits you'll get the right result
[07:00:31] <moon-child> possibly add a 1+ there if you care to, I don't buy that your doubly-open ranges are sensible but
[07:02:28] <moon-child> (however I'm not sure the best way to do that without lookup tables.  Are lookup tables hacker'sdelight-koscher?)
[07:04:24] *** Quits: molson (~molson@2001-48F8-704A-123D-0-0-75F-1021-static.midco.net) (Remote host closed the connection)
[07:05:26] *** Joins: molson (~molson@2001-48F8-704A-123D-0-0-75F-1021-static.midco.net)
[07:15:58] <gilberth> mfiano, moon-child: What is wrong with (/ (1- (expt 2 x)) (1- (expt 2 8)))?
[07:17:02] <mfiano> Well besides it not meeting the specifications, not much.
[07:18:33] <moon-child> mfiano: you want (expt 2 (+ x 8)) because your ranges are doubly-open
[07:19:52] <gilberth> mfiano: What's the specification then?
[07:20:34] <mfiano> gilberth: x=16 would be the result of (logior x (ash x 8) (ash x 16)) aka #x10101 not #x101
[07:21:31] * moon-child starts mfiano's array indices at 1
[07:21:50] <gilberth> Odd. then say (/ (1- (expt 2 (+ x 8))) (1- (expt 2 x))). I wonder what that should do. You said you want #x101 for 16 earlier.
[07:22:29] <mfiano> The algorithm I am porting makes use of #x101 for 8bpc colors and #x10101 for 16bpc colors
[07:22:47] <mfiano> It has many other odd coefficients too
[07:22:55] <gilberth> Then add the extra 8 and be set.
[07:23:07] <mfiano> Ok thanks
[07:23:57] <gilberth> It isn't so odd #x101 = (/ (1- (expt 2 16)) (1- (expt 2 8))) and #x10101 is (/ (1- (expt 2 24)) (1- (expt 2 8)))
[07:24:21] <moon-child> ^
[07:24:22] <gilberth> I believe this is where it comes from. We had this topic recently.
[07:25:08] * hayley contemplates how to get runtime feedback for loop iteration counts.
[07:26:33] <mfiano> I also pointed out another way which makes it far from odd. And no, not odd I guess. It is quite a common pattern in C to x = x || x << 8
[07:27:55] *** Quits: dec0d3r (~dec0d3r@2001:8003:480a:e00:e07:e7c3:7efc:ed0f) (Quit: Leaving)
[07:28:12] <mfiano> or wait isn't that single pipe? C and its similar operators and precedence rules. I'm going back to parens
[07:28:15] <gilberth> Which again is multiplication by #x101
[07:28:25] <moon-child> hayley: I think you must pgo, unless you have compiler support
[07:28:39] <gilberth> mfiano: Yep, | = logior, || = or
[07:29:12] <hayley> All I have right now is deciding if I want to use SIMD to run a loop or not. And that would be by observing how many iterations of the loop are run.
[07:29:24] <mfiano> gilberth: Right, but why do a mul when you can do it in less than 1/3 of the cpu cycles.
[07:29:24] <moon-child> (in particular, note that #x101 is #x100 + 1.  And + is xor with extra steps, that is or when no bits are in common.  So x | x << 8 is x + x << 8 is x + x * #x100 is x(1 + #x100))
[07:29:48] <hayley> Say, maybe it pays off if I skip 10 characters or not. If I decide I made the wrong guess, then I update a flag. Upon entering the loop, I test the flag (which shouldn't be so awful).
[07:29:52] <moon-child> mfiano: code size
[07:30:04] <moon-child> maybe register pressure
[07:30:08] <hayley> How did you count the cycles?
[07:30:20] <mfiano> I didn't, moon-child did.
[07:30:20] <gilberth> mfiano: Because (1) you see what is going and (2) if that three instructions are really faster, let the compiler do.
[07:30:23] <moon-child> also overall latency is not the same as actual latency due to bypass network
[07:31:02] <moon-child> mfiano: I didn't, agner did
[07:31:06] <hayley> x | x << 8 is a OR and a SHL. ok. Two cycle latency. IMUL has 3 cycle latency on Zen 1.
[07:31:10] <gilberth> Most CPU these days have a MUL instruction.
[07:31:41] <mfiano> moon-child pointed out that shift/add were like 0.3 cycles and mul was 3
[07:31:52] <mfiano> on whatever cpu arch he was referencing
[07:31:53] <moon-child> mfiano: that is throughput, not latency
[07:32:03] <mfiano> I wasn't saying it was latency
[07:32:10] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[07:32:16] <gilberth> I say: Let the compiler do this machine specific optimization.
[07:32:20] <moon-child> I think I mentioned that.  Though I guess you're shifting a bunch of things
[07:32:36] <moon-child> gilberth: I rather say, don't optimize until it is slow.  But I am having fun regardless
[07:32:51] <dave0> maw
[07:33:12] <gilberth> moon-child: Right. As you said.
[07:35:13] <hayley> But still, should I stash the flag for use between calls (I would expect a RE to be applied to fairly homogenous haystacks), and how? Close over all the flags? That could work.
[07:35:57] <hayley> ...and should I use a Schmitt trigger and only transition SIMD -> sequential for e.g. 7 characters, and sequential -> SIMD for 13? Lotsa questions.
[07:47:18] <hayley> That might actually be useful, because having multiple threads flip a flag either way would be slow.
[07:47:19] <hayley> dave0: maw
[07:47:34] <dave0> hi hayley, freshen your tea?
[07:47:36] <hayley> And if we are pretty close to the break-even point, then there isn't much of a point wasting time flipping the flag.
[07:53:53] <hayley> If I show up for the Coffee Compiler Club at 05:00 here, who else would show up?
[07:55:07] <moon-child> what's that in west coast time?
[07:56:00] <hayley> 10am PDT, I'd have to convert...
[07:56:09] <moon-child> ah ok
[07:56:11] <moon-child> hmm
[07:56:31] <hayley> Pretty easy conversion apparently. 10am
[08:12:08] <hayley> https://matrix.org/_matrix/media/v1/download/matrix.org/qJLvuutgQRGpyUtktxrLsuGP OS comparison
[08:13:33] <moon-child> where's synthesis
[08:13:35] <moon-child> and hydros
[08:13:44] <hayley> ¯\_(ツ)_/¯
[08:17:00] <hayley> Maybe I need a sequel. SqueakNOS: *out of hot air balloon* "you fool, you moron" Synthesis: "Inter-procedure optimisation is boring, y not inter-process optimisation" Singularity: "haha linear type message goes BRRRR"
[08:19:32] <moon-child> plan9: 'so, we took the unix and made it more unixy.  That's a good thing, right?'
[08:20:56] * hayley uploaded an image: (13KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/vQKmXUpKkxWzftKTPtzMEUBC/Screenshot_2022-01-19_16-00-13.png >
[08:22:43] *** Joins: semz_ (~semz@user/semz)
[08:25:02] *** Quits: semz (~semz@user/semz) (Ping timeout: 240 seconds)
[08:25:38] <sm2n> hayley: who's invited?
[08:25:48] <hayley> Anyone who can show up?
[08:26:15] <sm2n> I can probably make that
[08:26:36] <sm2n> not much a compiler hacker though
[08:30:51] <hayley> That's the problem.
[08:31:12] <hayley> Can't find anyone up who hacks compilers and is available.
[08:31:30] <sm2n> why do you want someone?
[08:31:53] <hayley> Mostly that I'll be half-awake at 5am.
[08:32:52] <sm2n> isn't that what the coffee is for?
[08:33:04] <hayley> I don't drink coffee. Tea though, maybe.
[08:34:05] <sm2n> neither do I, actually
[08:34:22] <sm2n> surely we are both disqualified from the coffee compiler club
[08:37:49] * hayley needs to think of 3 more OSes
[08:38:16] <hayley> Part 1 had Multics, Unix, ITS, GNU/Linux and BSD, Genera, Redox and CLOSOS. Part 2 has Smalltalk, Synthesis, Singularity and Plan 9 so far.
[08:38:20] * gilberth regrets not having made the read pointer increment explicit in the DFA.
[08:38:55] <hayley> Such is life.
[08:40:05] <gilberth> Yeah, I now get states, which are just a GOTO. That is they go to another state always, no matter what the input is.
[08:40:17] <hayley> I could make a "average hobby OS" where it's just someone perfectly imitating Unix.
[08:41:09] <gilberth> Why not just port V7 e.g.?
[08:42:03] <gilberth> I mean, wasn't that supposed to be portable? Especially all the assembler in there sure is.
[08:42:20] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 268 seconds)
[08:45:53] <sm2n> hayley: You forgor the most obvious one — windows
[08:45:59] <hayley> sm2n: No fun.
[08:46:05] <sm2n> hahaha
[08:46:14] <hayley> Making fun of Windows is verboten.
[08:46:24] <hayley> ...at least according to some parts of the Internet.
[08:46:32] <sm2n> who says that?
[08:47:03] <hayley> People who think you look like a FSF weenie or something, with all that edge.
[08:47:35] <hayley> There is already a Microsoft press conference joke though.
[08:47:48] <moon-child> hayley: hydros!
[08:48:03] <hayley> "It's 30% faster to use software to enforce process isolation, compared to hardware." "Why enforce process isolation then?" "We will not be taking further questions today."
[08:48:16] <moon-child> haha
[08:48:23] <moon-child> what andy giveth, bill taketh away?
[08:48:33] <hayley> The Erlang unikernel thing?
[08:48:47] <moon-child> yeah
[08:49:08] <sm2n> is that the one based on sel4?
[08:49:15] <moon-child> I don't think so
[08:49:16] <hayley> Don't know any Erlang jokes other than "Hello Joe." "Hello Mike."
[08:49:20] <sm2n> oh
[08:49:55] <sm2n> this is what I was thinking of <https://kry10.com/>
[08:49:55] -ixelp- Kry10 · Assurance Led Innovation
[08:50:03] <hayley> IIRC I made a phone joke in the "[very biased] timeline of functional programming history".
[08:50:20] * hayley uploaded an image: (187KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/sGAZtcdQEzFSVeadXkgKsLBF/functional-programming-timeline.png >
[08:50:21] <hayley> Smack bang in the middle.
[08:51:34] <sm2n> what's with the sudden drew post
[08:51:53] <hayley> That was new as of when this timeline was made.
[08:52:35] <sm2n> oh
[08:52:48] <sm2n> now that's a hot take
[08:53:26] <sm2n> what's the one prior to drew?
[08:53:45] <hayley> Map-reduce and such distributed computing things.
[08:54:03] <sm2n> oh
[08:54:10] <moon-child> isn't mapreduce like, 20 years old?
[08:54:22] <moon-child> or hadoop, whatever the prototypical one is
[08:54:31] <sm2n> I think it was from 2006 or so?
[08:55:04] <hayley> idk, it getting big feels recent. Or maybe everything feels recent since I only really started serious hacking in 2018.
[08:55:13] <sm2n> "The MapReduce programming paradigm was also described in Danny Hillis's 1985 thesis [41] and was widely used at the time to program the Connection Machine, which had special hardware support to accelerate both map and reduce."
[08:55:17] <sm2n> <https://en.wikipedia.org/wiki/MapReduce>
[08:55:19] <sm2n> nice
[08:55:38] <sm2n> google's patent apparently goes back to 2004
[08:55:51] <hayley> But, more generally the "oh shit I have multiple cores what do I do now" thing is recent.
[08:57:06] <sm2n> there are a bunch of other hobby os's listed on tunes.org
[08:57:27] <sm2n> iirc there's a java based one and a python based one, among others
[08:58:11] <moon-child> 'death of single-core scaling'  was predicted a long time ago.  I read some crackpot book by ray kurzweil from ca 2000 where he predicted moore's law was absolute and single-core scaling would continue forever, and people deny this because they don't understand exponential growth
[08:58:53] <sm2n> lol
[08:59:08] <moon-child> when somebody puts it so blatantly, it becomes pretty obvious
[08:59:13] <sm2n> I mean it follows from basic physics
[08:59:21] <moon-child> yeah
[08:59:24] <aeth> to be fair
[08:59:32] <aeth> there were reasons to be optimistic
[09:00:00] <aeth> For all we know, there's a 500x improvement by switching from silicon. It's just not even economical to investigate right now. Too much money behind silicon.
[09:00:35] <sm2n> yeah, but even that is not unbounded
[09:00:37] <aeth> I don't think we're near the limits of computation... let me check. https://en.wikipedia.org/wiki/Limits_of_computation
[09:00:51] <aeth> until we are, we're practically unbounded, although the slowing of the exponential was anyone's guess
[09:00:57] <aeth> in the past, miracles came just int ime
[09:00:57] <moon-child> optimistic, maybe (I would still be sceptical); but no reason to be so confident as to say it's a certainty
[09:01:09] <moon-child> and nb. sigmoids are more common than exponentials
[09:01:18] <moon-child> (I won't say 'more common'.  Just 'common')
[09:01:46] <aeth> This? Is this the right limit? https://en.wikipedia.org/wiki/Bremermann%27s_limit
[09:02:12] * hayley still needs to find another OS that she can come up with jokes for.
[09:02:20] <aeth> I wouldn't be surprised if there are quite a few 0s in the 10...0 times improvements left, but that's very specialized to cryptography and not translated to general compute
[09:02:40] <aeth> (of course, we might never get close to the theoretical physically possible maximum)
[09:03:11] <sm2n> something something deconstruct mars!
[09:03:36] <sm2n> (I do not actually advocate for deconstructing mars)
[09:03:48] <moon-child> hmm.  Say 10tflops in a gpu, gpu is 1/10 kg, a float is 10bits.  That's ~10^14/10^50
[09:03:50] <moon-child> buuut
[09:04:13] <moon-child> there's a lot of intermediate junk happening in there too aside from the final result
[09:04:17] <aeth> the limit is 1.36×10⁵⁰ bits per second per kilogram...
[09:04:23] <aeth> for anyone too lazy to open a web browser
[09:04:39] <moon-child> probably not 10^36x worth, but still, napkin math is insufficient :/
[09:04:40] <aeth> so, yeah, a lot of 0s left
[09:05:03] <sm2n> the point is that those 0s are not available to silicon transistor logic
[09:05:32] <aeth> sm2n: you might not, but the YouTube channel Kurzgesagt wants us to disassemble Mercury to build a Dyson sphere
[09:05:35] <aeth> (in the long run)
[09:05:50] <sm2n> aeth: yeah, I know there are many that advocate for it
[09:06:05] <sm2n> dumb singularitarians
[09:06:10] <moon-child> lol
[09:06:19] <aeth> sm2n: and, yeah, as I said abandoning silicon probably could give us some more, unspecified years of 0s in single core performance improvements
[09:06:28] <sm2n> ironically the person who wrote the famous book about it thinks that it's a cult
[09:06:39] <aeth> good luck, though. Foundries are already the most expensive and thus risky manufacturing ever
[09:06:45] <aeth> so good luck abandoning silicon until it's absolutely necessary
[09:06:50] <sm2n> (charles stross)
[09:06:50] <aeth> but then you might see a big, sudden jump
[09:06:55] <moon-child> what if we go by transistor count instead?  1e10 transistors in a cpu * 1e2 cpus per kg * 1e9 cycles per second
[09:07:11] <moon-child> overestimate, because they won't all switch every cycle
[09:07:29] <sm2n> moon-child: that's not really great because it doesn't take volume into account
[09:07:32] <moon-child> and that's 21.  So yeah still way behind.  But hmm I guess it's plausible some of them do things more than once per cycle
[09:07:39] <sm2n> for sequential processing you need density
[09:07:42] <aeth> moon-child: the physical limit is the physical limit, though. Like, of physics.
[09:08:00] <aeth> trying to put it in other terms might leave out novel ways to do computation
[09:08:03] <moon-child> aeth: yes.  I'm trying to compare what we've reached so far to that limit
[09:08:30] <moon-child> even though I'm not a cpu designer nor know anything about cpu design...
[09:08:52] <sm2n> Fermi estimation!
[09:09:15] * hayley uploaded an image: (154KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/yBeuuxwJwcdPNHJRGaNNCfLa/os-guide-2.png >
[09:09:24] <moon-child> oh, yes, I have a quip about that
[09:09:35] <moon-child> fermi analysis is what happens when you try to do statistics but you forget tolerances
[09:09:43] <moon-child> when you remember the tolerances, it's just called statistics
[09:10:27] <sm2n> lol
[09:11:35] <sm2n> There is a thin line between fermi estimation and bayesian reasoning
[09:12:15] <sm2n> hayley: I don't recall tunes ever having anything about partial evaluation, and I'm pretty sure I've read the entire website
[09:12:25] <sm2n> did I forget something?
[09:12:43] <hayley> http://tunes.org/HLL/principles.html C-f "partial"
[09:12:44] -ixelp- Tunes HLL Principles
[09:13:37] <sm2n> oh, like haskell, not like futamura projections
[09:14:08] <hayley> Right. Though there was also a sketch of a theory of meta-programming which gets close to Futamura projections.
[09:17:14] <aeth> just precompute everything inside of macros
[09:17:19] <aeth> solves the cpu speed problem
[09:17:27] <aeth> just becomes a memory lookup problem now
[09:17:33] <hayley> http://fare.tunes.org/articles/ll99/mpfas.html section 2.1
[09:17:34] -ixelp- Metaprogramming and Free Availability of Sources Two Challenges for Computing Today
[09:34:44] <White_Flame> welp, SOFI got their bank charter.  I might actually have some long option calls that are profitable for once!
[09:49:58] *** Joins: shka (~herr@109.231.0.226)
[10:34:38] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 250 seconds)
[10:37:39] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[10:42:35] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 268 seconds)
[10:42:54] <ck_> are we at the point where it is unclear what comes first, end of the unix epoch or end of the financial system?
[10:43:34] <shka> ck_: the end of the world
[10:43:43] <shka> we are stuck in this horrible machine
[10:43:44] <moon-child> ck_: nothing is certain but ddeath and taxes
[10:43:53] <shka> and machine is waiting to die
[10:44:29] *** Quits: scymtym (~user@ip-94-114-248-79.unity-media.net) (Ping timeout: 256 seconds)
[10:45:11] <ck_> ddeath is like ddos but with death?
[10:45:35] <ck_> mine isn't distributed yet, no redundancy at all actually. have to get on that
[10:46:43] <moon-child> does that mean you make sure to have vital organs on multiple continents?
[10:47:10] <ck_> I prefer to call them "availability zones", but yes.
[10:47:34] *** Joins: scymtym (~user@ip-94-114-248-79.unity-media.net)
[10:47:38] <ck_> they aren't actually there, think of them like derivatives. I have to purchase the option to obtain donor organs from independently available zones
[10:48:13] *** Quits: pjb (~pjb@user/pjb) (Remote host closed the connection)
[10:51:28] <gilberth> I wish -Wconversion would be more clever. It does not recognize that given uint16_t a; uint32_t b; the assignment a = (b >> 16) & 0xFFFF; is safe. I mean, I was explicit about throwing bits away. What is funny is that when I say uint32_t t = b >> 16; a = t & 0xFFFF; the compiler is happy again. *sigh*
[10:55:14] <moon-child> sometimes I have a macro like  #define C(x,y,z) ((!!x)<<2|(!!y)<<1|!!z)  and then  switch(C(x,y,z)) { case C(0,0,0): case C(0,0,1) ... }
[10:55:32] <hayley> \delta_c ck_
[10:55:33] <moon-child> it should warn me if I forget one
[10:55:52] <moon-child> and I think (forget) there is also some related case where it warns, but obviously shouldn't
[10:56:23] <gilberth> And what isn't caught, is int32_t a; uint16_t b; a = (b << 16); No warning here, yet the sign could flip.
[10:57:57] <gilberth> moon-child: Handy macro!!
[11:04:18] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[11:16:10] *** Joins: notzmv (~zmv@user/notzmv)
[11:35:30] *** Joins: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net)
[11:46:37] <selwyn> good morning everyone
[11:47:02] <hayley> Good morning beach!
[11:48:54] <dave0> c is getting dumber
[11:49:23] <dave0> they have finally decided to mandate 2's complement for signed integers, but integer overflow is still undefined behaviour
[11:56:11] <selwyn> https://www.youtube.com/watch?v=VFWbuKr5-I8
[11:56:12] -ixelp- Why You Wouldn't Want to Fly On The Soviet Concorde - The TU-144 Story - YouTube
[11:56:19] <selwyn> tf is this thing
[12:01:11] *** Joins: pjb (~pjb@user/pjb)
[12:05:28] <sham1> The TU-144
[12:13:47] * hayley lives with idiots
[12:14:45] <hayley> Dad: "Every number minus one that is divisible by six is prime." Me: "Some prime numbers are of that form, but not all numbers like that are prime." "Really?" "Yep. 7 is prime...13 is prime...19 is prime..." "So you doubt your father?" "25 is composite."
[12:15:29] <selwyn> he actually said that?
[12:15:34] <hayley> Yes.
[12:15:41] <selwyn> hahaha
[12:15:58] <selwyn> i see greek mathematics has come a long way since euclid
[12:16:22] <hayley> He was born in New Zealand, achsually.
[12:17:14] <selwyn> tell him about x^2 - x + 41
[12:18:14] <hayley> I don't think he can comprehend quadratics.
[12:18:55] <selwyn> i wonder if he is available for peer review
[12:19:33] <moon-child> selwyn: ur dad peer reviewed me last night
[12:20:25] <selwyn> https://c.tenor.com/2pTm9VuMwOIAAAAC/ohsnap-omg.gif
[12:21:03] <dave0> is that answer imaginary?
[12:21:23] <dave0> or pretend
[12:56:30] <ck_> There he Gauß again, with his pretend numbers
[13:04:32] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 240 seconds)
[13:16:58] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[13:22:13] *** Joins: kevingal (~quassel@2a02:8084:4140:f300:7406:7abe:8241:4b9f)
[13:24:04] *** Quits: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475) (Ping timeout: 250 seconds)
[13:26:17] *** Joins: mon_aaraj (~MonAaraj@user/mon-aaraj/x-4416475)
[13:45:33] *** Joins: rogersm (~rogersm@90.166.180.250)
[14:39:42] * hayley uploaded an image: (40KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/eXkQEiWciFMktObhJozyUVHg/20220119_220822.jpg >
[15:12:56] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[15:17:17] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[15:18:09] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Client Quit)
[15:28:51] <contrapunctus> moon-child: re: "CLOS classes", I meant to say this earlier...I seem to remember a lot of Lisp literature using the term "Lisp object" (for any Lisp data structure), and "object" seems to be an overloaded term in general, so I thought I'd be specific by saying "CLOS classes" 🤔️ (I suppose I'll now be told that "in Common Lisp, all Lisp objects are also CLOS objects" or something 😄️)
[15:29:41] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[16:12:41] *** Quits: greyrat (~greyrat@ip202.ip-51-178-215.eu) (Bye)
[16:13:02] *** Joins: greyrat_ (~greyrat@ip202.ip-51-178-215.eu)
[16:13:03] *** Joins: derwolf_ (~DerWolf@2a01:4f8:c0c:554a::1)
[16:13:43] *** Joins: robin__ (~robin@user/terpri)
[16:14:13] *** Joins: szkl_ (uid110435@uxbridge.irccloud.com)
[16:14:38] *** Joins: lagash_ (lagash@lagash.shelltalk.net)
[16:15:07] *** Joins: |3b|` (bbb@user/3b/x-2324788)
[16:15:53] *** Joins: SAL9000_ (~SAL9000@shirakumo/sal9000)
[16:16:06] *** Quits: remexre (~remexre@user/remexre) (Ping timeout: 240 seconds)
[16:16:06] *** Quits: greyrat (~greyrat@ip202.ip-51-178-215.eu) (Ping timeout: 240 seconds)
[16:16:06] *** Quits: lagash (lagash@lagash.shelltalk.net) (Ping timeout: 240 seconds)
[16:16:06] *** Quits: kagevf (~jfh@ip68-108-33-76.lv.lv.cox.net) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: szkl (uid110435@id-110435.uxbridge.irccloud.com) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: drakonis (drakonis@user/drakonis) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: GreaseMonkey (greaser@user/greasemonkey) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: |3b| (bbb@user/3b/x-2324788) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: Inline (~Inline@aftr-37-201-240-204.unity-media.net) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: gko (~user@user/gko) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: ck_ (~ck@plskthx.org) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: robin (~robin@user/terpri) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: derwolf (~DerWolf@static.143.125.47.78.clients.your-server.de) (Ping timeout: 240 seconds)
[16:16:07] *** Quits: Catie (~user@user/catie) (Ping timeout: 240 seconds)
[16:16:08] *** Quits: hugo (znc@verdigris.lysator.liu.se) (Ping timeout: 240 seconds)
[16:16:08] *** Quits: luis (~luis@lisp/luis) (Ping timeout: 240 seconds)
[16:16:08] *** Quits: SAL9000 (~SAL9000@shirakumo/sal9000) (Ping timeout: 240 seconds)
[16:16:09] *** Server sets mode: +nrt 
[16:16:13] *** luis7 is now known as luis
[16:16:23] *** Joins: remexre (~remexre@user/remexre)
[16:18:12] *** Joins: drakonis (drakonis@user/drakonis)
[16:19:57] *** Quits: szkl_ (uid110435@uxbridge.irccloud.com) (Ping timeout: 256 seconds)
[16:38:13] *** semz_ is now known as semz
[16:43:52] <gilberth> Has git some provision to preserve mode bits? I want that some files are just 444.
[16:45:31] <sham1> Yes
[16:45:36] <sham1> It should do that by default
[16:46:13] <gilberth> It didn't for me. It preserves the 'x' bit though, which is handy for scripts.
[16:59:56] *** robin__ is now known as robin
[17:07:27] *** Joins: ck_ (~ck@plskthx.org)
[17:07:40] <ck_> omg what have I missed
[17:09:21] <selwyn> contrapunctus: if in doubt you can refer to the clhs glossary for the meanings of terms
[17:19:43] *** Quits: kevingal (~quassel@2a02:8084:4140:f300:7406:7abe:8241:4b9f) (Ping timeout: 268 seconds)
[17:36:30] <selwyn> wondering if there is a way to cite common lisp
[17:37:28] <shka> selwyn: you can cite standard 
[17:37:31] <shka> no problem
[17:37:47] <selwyn> good idea
[17:42:23] <shka> you can also cite common lisp: the language but standard is a better idea
[17:45:14] <selwyn> would be amusing if a referee were to make an issue of that
[17:48:03] <contrapunctus> s/classes/objects/g
[17:48:39] *** Joins: vats (~vats@180.149.226.41)
[17:49:03] <selwyn> i feel silly citing a programming language but it is the name of the game
[17:57:22] *** Joins: random-nick (~random-ni@87.116.167.125)
[18:07:07] <ck_> you don't actually feel silly -- what you feel is the POWER OF THE CONS IN THE PALM OF YOUR .. and so on
[18:22:43] <selwyn> why does the ansi standard have 94 editions
[18:23:53] *** Joins: domovod (~domovod@176.196.122.197)
[18:28:38] <ck_> yes.
[18:36:50] <selwyn> sigh
[18:46:09] *** Quits: vats (~vats@180.149.226.41) (Ping timeout: 256 seconds)
[18:52:50] *** hugo- is now known as hugo
[18:57:30] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[18:59:25] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[19:03:20] *** Joins: kevingal (~quassel@2001:770:c0:401:c05c:9bd4:6992:748e)
[19:07:00] <selwyn> this is the personal website of someone i am citing via mathoverflow
[19:07:02] <selwyn> http://www.fuckyeah.biz/
[19:07:02] -ixelp- Fuck Yeah! -- Back Door
[19:09:54] <ck_> :D
[19:10:41] <ck_> with banjo picture and tibetan prayer flags (or whatever these are called)
[19:10:50] <ck_> deserves a chef's hand's kiss
[19:13:07] <selwyn> my new homepage
[19:14:51] <ck_> quote it on your application
[19:15:01] <ck_> seems like the exact vibe needed.  "FUCKYEAH.BIZ--because YOU are the drug America needs most!"
[19:16:00] <semz> now that is how you make a site
[19:16:38] <ck_> <META content="MSHTML 6.00.2600.0" name=GENERATOR>
[19:28:26] *** Quits: mgl (~mgl@cpc87455-finc19-2-0-cust234.4-2.cable.virginm.net) (Quit: Client closed)
[19:37:03] *** |3b|` is now known as |3b|
[19:38:57] <gilberth> It never occurred to me that xargs is brain dead in treating spaces and escapes and single quotes special. Most pain would go away, when it would treat only newlines special. Not save either, but whoever puts a newline into a filename ought to be put into a space capsule and be banned from any computer for eternity.
[19:40:32] <gilberth> Actually the whole shell design is brain dead. And I specifically don't mean the shell glob(1)ing for you, that is actually fine for the most part.
[19:40:48] <selwyn> ck: lol
[19:40:55] <semz> the shell is an repl, just a really really shitty one
[19:40:59] <semz> and xargs is a really really shitty apply
[19:41:17] <semz> fwiw i think gnu xargs has a null terminator option
[19:41:22] <lagash_> gilberth: what about a null in a filename? :P
[19:41:36] <lagash_> semz: yeah --print0 or something like that
[19:43:02] <gilberth> And the whole idea to limit the size of argv[] is just silly. I could see that for a poor 64kB PDP-11, but not for our machines. Even when space is an issue: Why not read command line arguments from a stream, like some OSes do?
[19:44:07] <gilberth> lapash_: NUL cannot be in a filename. And no, the -z option to xargs does not solve my problem. How would you teach grep that?
[19:45:05] <gilberth> This -print0 works with find only. What if I want to say: find . -type f | grep this | grep that | sort | xargs ls -ld ?
[19:45:51] <gilberth> Or in my case grep the-file-i-am-looking-for.txt ~/MANIFEST.
[19:47:37] <gilberth> For what it is worth BSD xargs has a -0 option, too. But doesn't solve my problem. Or should I stick tr '\n' '\0' in between?
[19:51:48] <gilberth> So may I have an "nargs"? Which treats NL as seperator only? Shouldn't be too hard to write. Who imposes the argv[] limit?
[19:52:46] *** SAL9000_ is now known as SAL9000
[19:53:03] <semz> terrible ad-hoc format conversions within pipelines are the unix way :-)
[19:55:04] <gilberth> alias xargs='tr "\\n" "\\0" | xargs -0' # will do
[19:57:29] <gilberth> Why haven't I come up with that earlier?
[20:02:11] <gilberth> BTW I once hacked Samba, so that our clueless Windows users could not put spaces into their file names.
[20:25:27] *** Joins: wheelsucker (~user@2600:8801:8c24:d000:25e1:aacc:8c79:dcd3)
[20:26:02] *** Joins: santiagopim (~user@90.167.94.91)
[20:27:25] *** Joins: Catie (~user@user/catie)
[20:39:51] *** Joins: treflip (~user@user/treflip)
[20:40:46] *** Quits: domovod (~domovod@176.196.122.197) (Quit: WeeChat 3.4)
[20:43:07] <contrapunctus> phoe: what's this "community debate"?
[20:43:59] <phoe> contrapunctus: a mostly incorrect summary would be "ASDF versus SBCL" meets "people being rude towards each other"
[20:44:14] <phoe> but that is mostly incorrect
[20:44:24] <contrapunctus> wat
[20:45:34] <contrapunctus> phoe: any reading material on the subject?
[20:46:08] <phoe> contrapunctus: https://plaster.tymoon.eu/view/2882#2882
[20:46:30] <phoe> I assume you can dig the links out yourself
[20:46:40] <selwyn> asdf vs sbcl sounds like one of those youtube meme videos
[20:47:14] <phoe> it kinda is
[20:48:03] <shka> oh, the drama
[20:48:45] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[20:49:13] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[20:49:40] <selwyn> shka: have you done cardio yet
[20:49:49] <shka> not yet 
[20:59:26] * contrapunctus went running today (after a bit of a gap) \o/
[21:04:55] *** Quits: wheelsucker (~user@2600:8801:8c24:d000:25e1:aacc:8c79:dcd3) (Remote host closed the connection)
[21:05:39] <ck_> excellent choice
[21:13:09] <aeth> phoe: wait, someone else is trying to claim my position as sole worthy leader of the Common Lisp community at large? wow.
[21:16:30] <ck_> I know someone who could help debunk some things
[21:21:08] <selwyn> https://www.bitdefender.com/blog/hotforsecurity/nine-year-old-kids-are-launching-ddos-attacks-against-schools/
[21:21:10] <selwyn> lol
[21:21:10] -ixelp- Nine-year-old kids are launching DDoS attacks against schools
[21:21:53] <selwyn> in which nine year old script kiddies are considered able recruits for the cyber industry
[21:22:03] <ck_> "a life of cybercrime"
[21:22:47] <selwyn> thug 4 lyfe
[21:22:52] <sm2n> aeth: Did you forget about hexguy
[21:25:34] <ck_> he's in there, sm2n, emoji-reacting to some comments
[21:25:55] <sm2n> in where
[21:26:23] <ck_> in one of the github threads that pertain to this drama
[21:26:55] <ck_> well it would be nice if things just worked out, I don't know how to get there though
[21:28:55] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[21:29:11] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[21:29:29] <aeth> social media was a mistake
[21:29:42] <aeth> and treating github threads like social media is... just why
[21:29:50] <aeth> they shouldn't even be threads, they should be issues, as in actionable tasks
[21:30:23] <sm2n> Would like to point out that I think you can technically emoji react to messages here, as this room is mirrored on matrix
[21:30:51] <ck_> ✍️
[21:31:13] <sm2n> I actually wonder if that survives bridging at all
[21:33:04] <ck_> why not
[21:33:26] <sm2n> It's up to whoever wrote the bridge
[21:33:45] <ck_> "; DROP TABLE matrix; --
[21:34:15] <sm2n> sql injection is passé
[21:34:38] <ck_> I'm a nostalgic person
[21:35:00] <sm2n> it's all about ${JNDI:...} now
[21:35:06] <ck_> of course4j
[21:42:30] <aeth> sm2n: it probably doesn't survive the bridging because Libera.Chat probably doesn't implement that part of IRCv3 yet
[21:42:38] <aeth> sm2n: but they might... my client doesn't have it if they do
[21:42:52] <aeth> it's an in-terminal client but they probably could just append it to the end of the line, or have it on a separate line
[21:44:40] *** Joins: ln43 (~ln43@user/ln43)
[21:46:29] <ln43> Hi all !
[22:00:16] <shka> selwyn: yeah, first 5 minutes are not a problem for my grip, then it gets difficult
[22:10:10] <selwyn> i should do cardio some time lol
[22:12:53] <shka> also my legs still hurt a little, which is bad because my form got worse
[22:26:34] <selwyn> grip is weird
[22:26:54] <ck_> just eat more chalk, it's easy
[22:27:00] <selwyn> when you do pull ups, if you simply grip harder
[22:27:06] <selwyn> you can squeeze out more reps
[22:27:27] <selwyn> if you are cycling in a sprint, grip the handlebars harder in order to go faster
[22:27:30] <selwyn> it really does work
[22:27:43] <ck_> psychosomatic. purely psychosomatic
[22:27:57] <selwyn> (not a good idea for actual sprinting)
[22:28:24] <ck_> so that's why there is relay racing 
[22:28:29] <ck_> portable handlebar
[22:30:29] *** Quits: treflip (~user@user/treflip) (Quit: good night ☺/)
[22:30:39] <selwyn> even if it is psychosomatic (i don't think so) it is still a good practice to adopt
[22:30:49] <selwyn> seeing as how the goal is ultimately to be able to do more stuff
[22:31:48] <ck_> difficult to test, but I'll try to do more introspection with this in mind
[22:36:17] <ck_> you can try the opposite experiment: think real hard about gripping more, but don't ;)
[22:37:55] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 268 seconds)
[22:38:44] <ck_> clicking buttons in torn is definitely the easiest way to exercise though
[22:40:39] <selwyn> the grease the groove guy discusses this phenomenon
[22:44:32] <ck_> how does he explain it? I can only think of a change in the perception of how exhausted you are, like raising a hormonal threshold or something
[22:47:45] <selwyn> he doesn't really explain it but offers a rough neuroscience explanation
[22:48:16] <selwyn> when muscles contract, it increases the intensity of the neighbouring muscles contractions via nerves
[22:48:22] <selwyn> things that wire together fire together etc.
[22:48:59] <selwyn> and offers testimony from various athletes that demonstrate the principle
[22:49:45] <selwyn> he is an interesting guy - he has this whole post soviet schtick that is irritating/amusing
[22:50:19] <selwyn> but in his appearances and writings you can tell that he really does genuinely approach strength and the body like a genuine researcher
[22:50:22] <selwyn> and that is really rare
[22:51:51] <ck_> I see. That is understandable to me, but the immediate benefit you describe is still somewhat of a mystery
[22:52:10] <ck_> maybe because my understanding of how muscle activation works is flawed
[22:52:25] <ck_> that's most likely of course -- I am not a clever man
[22:52:30] <selwyn> idk if anyone truly understands this stuff
[22:54:16] <selwyn> strength involves the neuromuscular system which involves the brain
[22:54:20] <selwyn> and we don't have a unified theory of that
[23:01:15] <ck_> maybe someday
[23:01:33] <ck_> on a more humorous note, this scrolled by the feed today and I like it quite a lot https://www.linkedin.com/posts/ai4diversity_customer-demo-activity-6886613612845264896-lVvP
[23:01:34] -ixelp- AI4Diversity on LinkedIn: Customer Demo | 1213 comments
[23:03:42] *** Quits: kevingal (~quassel@2001:770:c0:401:c05c:9bd4:6992:748e) (Remote host closed the connection)
[23:23:12] *** Joins: GreaseMonkey (greaser@user/greasemonkey)
[23:32:57] <ln43> i was trying to find a sufficient good linux host to do some experiments... for example buildroots or something similar
[23:33:07] <ln43> but ok, just to start doing something ...
[23:40:03] <contrapunctus> re: running, today was my second fastest run since I resumed running last month - https://paste.rs/bmt
[23:40:40] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Remote host closed the connection)
[23:41:11] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[23:51:51] <sm2n> aeth: IRCv3 has emoji reactions‽
[23:52:11] <semz> ew really?
[23:53:09] <sm2n> idk ask aeth 
[23:56:00] *** Quits: ln43 (~ln43@user/ln43) (Quit: Connection closed)
[23:59:25] <edgar-rft> yes, emojis are a merely reactionary thing :-)
