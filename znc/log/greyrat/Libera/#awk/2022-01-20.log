[00:07:58] *** Quits: mingdao_ (~mingdao@107-146-172-064.res.spectrum.com) (Quit: leaving)
[00:08:08] *** Joins: mingdao (~mingdao@wireguard/tunneler/mingdao)
[00:13:31] *** Joins: kensanata (~user@user/kensanata)
[00:21:49] *** Joins: timm (~timm@2a02:810d:4c40:a68:224:d7ff:fe18:af78)
[00:53:57] *** Quits: timm (~timm@2a02:810d:4c40:a68:224:d7ff:fe18:af78) (Changing host)
[00:53:57] *** Joins: timm (~timm@user/timm)
[01:04:11] *** Quits: user51 (~user51@176.228.148.215) (Remote host closed the connection)
[01:06:32] *** Quits: aetnaeus (~qpls@cpeb4750e67d202-cmf81d0fad5840.cpe.net.fido.ca) (Ping timeout: 268 seconds)
[01:10:30] *** Joins: bluedust_ (~bluedust@185.248.85.41)
[01:11:48] *** Joins: aetnaeus (~qpls@cpeb4750e67d202-cmf81d0fad5840.cpe.net.fido.ca)
[01:12:37] *** Quits: bluedust (~bluedust@59.89.209.234) (Ping timeout: 240 seconds)
[01:17:37] *** Quits: bluedust_ (~bluedust@185.248.85.41) (Ping timeout: 240 seconds)
[01:18:14] *** Joins: malina (~malina@user/malina)
[01:24:08] *** Joins: bluedust (~bluedust@static-198-54-131-105.cust.tzulo.com)
[01:27:53] *** Joins: bluedust_ (~bluedust@103.160.233.171)
[01:31:24] *** Quits: Torr (~Torr@user/torr) (Remote host closed the connection)
[01:31:38] *** Quits: bluedust (~bluedust@static-198-54-131-105.cust.tzulo.com) (Ping timeout: 250 seconds)
[01:32:00] *** Joins: Torr (~Torr@user/torr)
[01:33:24] *** Quits: bluedust_ (~bluedust@103.160.233.171) (Remote host closed the connection)
[01:35:57] *** Joins: vlm (~vlm@user/vlm)
[01:39:45] *** Quits: seninha (~seninha@user/seninha) (Quit: Leaving)
[01:49:05] *** Quits: timm (~timm@user/timm) (Ping timeout: 268 seconds)
[01:49:56] *** Joins: larryv (~larryv@zsh/patchmanager/larryv)
[01:58:40] *** Quits: malina (~malina@user/malina) (Remote host closed the connection)
[02:02:24] *** Quits: waldo323__ (~waldo323@d14-69-96-170.try.wideopenwest.com) (Ping timeout: 250 seconds)
[02:06:54] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[02:07:20] *** Quits: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk) (Quit: Leaving)
[02:25:58] *** Quits: Torr (~Torr@user/torr) ()
[02:55:41] *** Quits: kensanata (~user@user/kensanata) (Ping timeout: 268 seconds)
[03:06:16] *** Quits: mknod (~mknod@user/mknod) (Quit: mknod)
[03:47:02] *** Quits: emanuele6 (~emanuele6@user/emanuele6) (Ping timeout: 240 seconds)
[04:10:23] *** Joins: emanuele6 (~emanuele6@user/emanuele6)
[04:36:13] *** Quits: emanuele6 (~emanuele6@user/emanuele6) (Read error: Connection reset by peer)
[04:37:40] *** Joins: emanuele6 (~emanuele6@user/emanuele6)
[05:07:00] *** Joins: Torr (~Torr@user/torr)
[05:08:22] *** Quits: Torr (~Torr@user/torr) (Client Quit)
[05:30:22] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[07:13:38] *** Joins: ham5 (iamfive@user/ham5)
[07:16:46] *** Quits: tirnanog (~tirnanog@user/tirnanog) (Quit: = "")
[07:18:15] <ham5> paragraphs in my file seperated by new line, I want to search needle and print the full paragraph.. when I have two paragraphs with the same needle, how do I seperate the paragraphs with a newline? I use: awk -v RS='' "/needle/" haystackfile
[07:19:12] <ham5> I get both paragraphs, but how to get a new line between, END didnt work as expected I figure its matching the very first new line and the very last?
[07:33:38] <e36freak> '/needle/{print; print ""}'
[07:33:55] <e36freak> or '/needle/{printf("%s\n\n", $0)}'
[07:35:11] <larryv> or awk -v RS='' -v ORS='\n\n' '/needle/' haystackfile
[07:36:48] <e36freak> or that
[07:37:26] <ham5> thanks guys!
[07:40:45] *** Quits: yuesbeez (uid458354@id-458354.tinside.irccloud.com) (Quit: Connection closed for inactivity)
[08:37:53] *** Quits: defjam (~eb0t@90.203.120.248) (Read error: Connection reset by peer)
[08:43:42] *** Joins: defjam (~eb0t@90.209.247.249)
[08:50:10] *** Joins: user51 (~user51@176.228.148.215)
[08:51:37] *** Joins: bluedust (~bluedust@103.160.233.171)
[09:09:03] *** Joins: birkoff (birkoff@birkoff.thunderirc.net)
[09:09:03] *** Quits: birkoff (birkoff@birkoff.thunderirc.net) (Changing host)
[09:09:03] *** Joins: birkoff (birkoff@user/birkoff)
[09:09:32] *** Quits: larryv (~larryv@zsh/patchmanager/larryv) (Quit: larryv)
[09:25:11] *** Joins: bluedust_ (~bluedust@static-198-54-130-137.cust.tzulo.com)
[09:25:18] *** Quits: bluedust (~bluedust@103.160.233.171) (Remote host closed the connection)
[09:26:33] *** Joins: bluedust (~bluedust@103.160.233.171)
[09:29:35] *** Quits: bluedust_ (~bluedust@static-198-54-130-137.cust.tzulo.com) (Ping timeout: 256 seconds)
[09:39:30] *** Quits: roarde (~roarde@user/roarde) (Quit: Leaving)
[10:20:20] *** Joins: malina (~malina@user/malina)
[10:40:08] *** Quits: bluedust (~bluedust@103.160.233.171) (Read error: Connection reset by peer)
[10:40:31] *** Joins: bluedust (~bluedust@103.160.233.171)
[11:46:59] *** Quits: _flood (flooded@gateway/vpn/protonvpn/flood/x-43489060) (Remote host closed the connection)
[11:47:19] *** Joins: _flood (flooded@gateway/vpn/protonvpn/flood/x-43489060)
[11:56:13] *** Joins: lavaball (felix@31.204.155.215)
[12:00:37] *** Quits: _flood (flooded@gateway/vpn/protonvpn/flood/x-43489060) (Ping timeout: 240 seconds)
[12:07:07] *** Quits: aetnaeus (~qpls@cpeb4750e67d202-cmf81d0fad5840.cpe.net.fido.ca) (Ping timeout: 256 seconds)
[12:11:37] *** Quits: malina (~malina@user/malina) (Ping timeout: 240 seconds)
[12:57:45] *** Joins: seninha (~seninha@user/seninha)
[13:09:39] *** Joins: sqz (~sqz@178.62.201.14)
[13:51:28] *** Joins: malina (~malina@user/malina)
[13:59:46] *** Joins: taeaad (~taeaad@user/taeaad)
[14:01:43] <taeaad> The following works to split out a csv based on values in a column:
[14:01:45] <taeaad> awk -F\| '{print>"/home/user/data/out_"$2".csv"}' $f
[14:02:02] <taeaad> Here $f is the original CSV file.
[14:02:23] <taeaad> But how can I change the folder "data" based on a shell variable?
[14:02:54] <taeaad> awk -F\| '{print>"/home/user/$d/out_"$2".csv"}' $f, for example, is not correct awk code.
[14:04:10] <emanuele6> -F'|' -v d="$d" '{ print > "/home/user/" d "/out_" $2 ".csv" }'
[14:04:45] <taeaad> emanuele6: Great, thanks!
[14:06:34] <emanuele6> i don't think this is a good way to do it personally
[14:06:52] <emanuele6> iirc awk is only required to handle at most 9 open files at the time.
[14:08:02] <emanuele6> it would be better to append and close
[14:08:42] <emanuele6> (and maybe keep a record of the files you have opened at least once, so you can truncate files the first time you open them)
[14:12:24] <emanuele6> like  '{ file = "/home/user/" d "/out_" $2 ".csv"; if (!f[file]++) print > file; else print >> file; close(file) }'
[14:16:52] <taeaad> emanuele6: What would that help for?
[14:17:01] <emanuele6> <emanuele6> iirc awk is only required to handle at most 9 open files at the time.
[14:17:14] <emanuele6> <emanuele6> -F'|' -v d="$d" '{ print > "/home/user/" d "/out_" $2 ".csv" }'
[14:17:17] <taeaad> So could it lead to errors?
[14:17:49] <emanuele6> ^ that opens a file for every value of $2 that is encountered and never closes it until the end
[14:18:23] <taeaad> The previous approach I had was using a lookup in Perl with everything in memory, but the issue is that I have a relatively fast SSD but not a lot of memory.
[14:20:59] <taeaad> It will end up splitting out at least 100 files, which is much more than 9.
[14:22:29] <emanuele6> but even if you ignore the standard specified awk limit, even on linux by default, every process has a hard limit of ~1000 fd. so yours is not a very wise solution.
[14:22:46] <taeaad> emanuele6: What does this mean? "if (!f[file]++)"
[14:23:00] <emanuele6> f[] is an associative array
[14:23:28] <emanuele6> f[file] is a number pointed by the  file  that is the path to which you are trying to output
[14:24:02] <emanuele6> !f[file]   is true only if f[file] is 0
[14:24:16] <emanuele6> (so only the first time you are trying to output to file
[14:24:33] <emanuele6> after checking, you increment that number with f[file]++
[14:24:45] <emanuele6> so basically   if (!f[file]++) print > file; else print >> file;
[14:25:02] <emanuele6> runs    print > file    the first time you are trying to output to file
[14:25:13] <emanuele6> and runs   print >> file   all the other times
[14:25:51] <taeaad> But it closes the file after every line, which solves the issue you are pointing out.
[14:25:51] <emanuele6>  print > file  will open file for writing if it is not already open and write the current record to it
[14:26:25] <emanuele6> print >> file  will open file for writing (in appending mode) if it is not already open and append the current record to it
[14:26:46] <emanuele6> then after writing to it with print, you close file with close(file)
[14:26:57] <taeaad> I thought that my original code did close the file, since someone mentioned that ">" can mean ">>" if it's in the same line of code. So I assumed somehow that amount of files open would only be the current one.
[14:26:59] <emanuele6> this way there is only one file open at a time
[14:27:12] <emanuele6> taeaad: no, awk is not like bash
[14:27:25] <emanuele6> >, >>, |  don't close
[14:27:29] <taeaad> Alright, good to know.
[14:27:47] <emanuele6> they open if the file is not already open, otherwise they just redirect
[14:34:07] *** Joins: timm (~timm@user/timm)
[14:44:41] *** Joins: mknod (~mknod@user/mknod)
[14:54:51] *** Quits: lopid (~lopid@user/lopid) (Ping timeout: 256 seconds)
[14:55:15] <emanuele6> i can't find any specification defined file descriptor limit (i was probably thinking of sed), not even on the manuals of gawk and nawk; still it is not a good idea to open a potentially infinite amount of file descriptors
[14:56:00] *** Joins: BSaboia (~bsaboia@189.45.78.253)
[14:56:32] <emanuele6> but interestingly, it seems that GNU awk is able to do some optimisation that allows it to go over the os file descriptor limit
[14:57:05] <emanuele6> # mkdir awk; cd awk; nawk 'BEGIN { for (i = 1; i <= 4000; ++i) print "hello" > i }'; a=( * ); printf '%s files in the current directory'
[14:57:06] <shbot> emanuele6: nawk: can't open file 1022
[14:57:06] <shbot> emanuele6:  source line number 1
[14:57:06] <shbot> emanuele6:  files in the current directory
[14:57:13] <emanuele6> # mkdir awk; cd awk; gawk 'BEGIN { for (i = 1; i <= 4000; ++i) print "hello" > i }'; a=( * ); printf '%s files in the current directory'
[14:57:19] <shbot> emanuele6:  files in the current directory
[14:57:23] <emanuele6> oops
[14:57:30] <emanuele6> # mkdir awk; cd awk; gawk 'BEGIN { for (i = 1; i <= 4000; ++i) print "hello" > i }'; a=( * ); printf '%s files in the current directory' "${#a[@]}"
[14:57:32] *** Joins: lopid (~lopid@user/lopid)
[14:57:36] <shbot> emanuele6: 4000 files in the current directory
[15:00:34] <emanuele6> probably something like close() the file descriptor used less recently to open a new one, and then reopen the closed file descriptor for append next time you need to write to it? i don't know
[15:18:10] <emanuele6> yeah, it is basically the trick i mentioned, not an optimisation 
[15:21:10] <emanuele6> i wonder why they needed to implement that...
[16:11:39] <ang> easy, because GNU
[16:12:42] <ang> I wrote part of a log based irc client in awk and didn't really think about fd limits
[16:12:52] <ang> this was a good reminder to mention it somewhere
[16:39:23] *** Joins: lgc (~lgc@user/lgc)
[17:01:53] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[17:09:23] *** Joins: _flood (flooded@gateway/vpn/protonvpn/flood/x-43489060)
[17:38:45] *** Quits: lgc (~lgc@user/lgc) (Quit: WeeChat 3.2-dev)
[17:41:23] <sqz> awesome, I've just added a rule-engine (using few lines of awk) to the output of another program.
[17:43:54] <sqz> It's basically sending out notifications to slack (based on certain keywords) while it's printing out a (timeconsuming) building process to stdout.
[17:44:31] <sqz> 0 repositories have been forked, 0 developers have been disturbed, 0 feature-requests have been made ;)
[18:09:24] *** Quits: timm (~timm@user/timm) (Ping timeout: 256 seconds)
[18:10:13] *** Joins: timm (~timm@user/timm)
[18:29:55] *** Joins: Thanatermesis (~Thanaterm@191.92.148.122)
[18:47:31] *** Joins: bluedust_ (~bluedust@117.241.183.103)
[18:49:13] *** Quits: mknod (~mknod@user/mknod) (Quit: mknod)
[18:51:09] *** Quits: bluedust (~bluedust@103.160.233.171) (Ping timeout: 256 seconds)
[19:03:30] *** int is now known as Ox4
[19:24:10] *** Quits: bluedust_ (~bluedust@117.241.183.103) (Remote host closed the connection)
[19:43:07] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[19:43:28] *** Quits: BSaboia (~bsaboia@189.45.78.253) (Quit: This computer has gone to sleep)
[19:43:51] *** Joins: BSaboia (~bsaboia@189.45.78.253)
[19:44:36] *** Joins: roarde (~roarde@user/roarde)
[19:59:54] *** Quits: timm (~timm@user/timm) (Quit: Leaving)
[20:36:37] *** Quits: emanuele6 (~emanuele6@user/emanuele6) (Ping timeout: 240 seconds)
[20:40:52] *** Joins: emanuele6 (~emanuele6@user/emanuele6)
[20:59:23] *** Joins: bluedust (~bluedust@117.241.183.103)
[21:05:42] *** Quits: bluedust (~bluedust@117.241.183.103) (Remote host closed the connection)
[21:08:58] *** Joins: timm (~timm@user/timm)
[21:43:54] *** Joins: larryv (~larryv@zsh/patchmanager/larryv)
[22:19:55] *** Joins: lavaball (felix@31.204.155.215)
[22:47:08] *** Joins: YaoNai (~YaoNai@user/yaonai)
[22:47:25] *** Quits: lavaball (felix@31.204.155.215) (Remote host closed the connection)
[23:06:20] *** Joins: bluedust (~bluedust@117.241.183.103)
[23:10:37] *** Quits: bluedust (~bluedust@117.241.183.103) (Ping timeout: 240 seconds)
[23:17:22] *** Joins: mknod (~mknod@user/mknod)
[23:53:32] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:16af:8d6b:42b4:6731) (Ping timeout: 240 seconds)
[23:55:54] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:9d95:c71:11e4:3e0f)
