[00:29:19] *** Joins: pjb (~pjb@user/pjb)
[00:31:17] *** Quits: pjb (~pjb@user/pjb) (Read error: Connection reset by peer)
[00:42:42] *** Joins: notzmv (~zmv@user/notzmv)
[00:46:38] *** Quits: marcoxa (~user@77-57-64-215.dclient.hispeed.ch) (Ping timeout: 260 seconds)
[01:12:19] <hayley> https://www.youtube.com/watch?v=wjdQqz79ZBo
[01:12:20] -ixelp- I Believe the Impossible - YouTube
[01:48:26] *** Joins: pjb (~pjb@user/pjb)
[02:36:32] *** Quits: winningluser (~wl@2601:8c1:80:70d0::e17b) (Quit: nyaa~)
[02:39:08] *** Quits: random-nick (~random-ni@87.116.181.93) (Ping timeout: 256 seconds)
[03:05:57] <hayley> https://groups.google.com/g/comp.lang.lisp/c/cC5410Dw3x4/m/R4dOWjCHPRAJ
[03:05:58] -ixelp- Cdr-coding
[03:06:11] <hayley> Apparently the Cyc system from '97 used cdr-coding on stock machines.
[03:17:34] <hayley> gilberth: "The most spectacular [GC flaw] on the SMBX machine was the fact that creating an array caused the micro code to visit every element 3 times. So long as the entire array fit into memory, this was fine, but if it did not, then the machine became a zombie for a very long time as it uninterruptibly paged itself like crazy to initialize the array."
[03:51:49] *** Quits: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se) (Ping timeout: 240 seconds)
[04:07:09] *** Quits: Alfr (~Alfr@user/alfr) (Remote host closed the connection)
[04:07:38] *** Joins: Alfr (~Alfr@user/alfr)
[04:19:44] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 252 seconds)
[04:47:33] <hayley> https://www.youtube.com/watch?v=LA8YXaDnqGA
[04:47:34] -ixelp- Overclocking can be useful?! Let's try with my GameBoy & Arduino - YouTube
[06:13:44] <hayley> https://github.com/riscv/riscv-CMOs/blob/master/specifications/cmobase-v1.0-rc2.pdf So you can zero out a cache line and save bandwidth with a RISC-V extension. Nice.
[06:13:45] -ixelp- riscv-CMOs/cmobase-v1.0-rc2.pdf at master ¬∑ riscv/riscv-CMOs ¬∑ GitHub
[06:17:27] <moon-child> CLZERO!
[06:20:17] <hayley> "It can not be used to allocate a cache line without a memory access, and should not be used to quickly zero memory." per https://en.wikichip.org/wiki/x86/clzero
[06:30:46] *** Joins: notzmv (~zmv@user/notzmv)
[07:05:20] <moon-child> https://www.smbc-comics.com/comic/2013-01-22
[07:05:21] -ixelp- Saturday Morning Breakfast Cereal - 2013-01-22
[07:28:22] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 268 seconds)
[07:55:11] *** Quits: clothespin_ (~awolven@c-73-209-95-92.hsd1.il.comcast.net) (Remote host closed the connection)
[07:58:05] *** Quits: semz (~none@user/semz) (Ping timeout: 252 seconds)
[08:06:10] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[08:06:43] <dave0> maw
[08:10:29] *** Joins: semz (~none@user/semz)
[08:23:44] *** Joins: notzmv (~zmv@user/notzmv)
[08:33:31] <hayley> maw
[08:34:18] <dave0> hi hayley 
[08:34:22] <dave0> how are you?
[08:37:20] <dave0> dave0: i am fine, how are you?
[08:37:30] <dave0> dave0: i dont want to talk about it
[09:01:14] <hayley> Just came back from a walk, had a minor epiphany about concurrent compacting GC.
[09:02:07] <dave0> nice
[09:02:46] <dave0> walking is my favorite :-)
[09:03:52] <hayley> Suppose, instead of a fully concurrent compacting collector, with requisite read barrier, I just had a mostly-concurrent compacting collector which stopped the world to do phase changes, and compaction would only be used if the heap is fragmented enough. 
[09:05:03] <hayley> Then, if we only compact 1 in every N cycles, whatever latency there is at X nines due to mostly-concurrent compaction would be at X + log‚ÇÅ‚ÇÄ(N) nines instead. This could lead to a pretty happy balance between latency and throughput, if played right. 
[09:05:41] <hayley> IIRC https://dl.acm.org/doi/10.1145/1029873.1029877 does exactly that for Java, but I can't remember how concurrent the mark-sweep part is.
[09:05:42] -ixelp- Mostly concurrent compaction for mark-sweep GC | Proceedings of the 4th international symposium on Memory management
[09:07:22] <hayley> More interesting than how I found myself arguing about async again. "Have fun with processing on one core!" "Yes, but I was IO bound anyway." "Wanna bet?"
[09:08:08] <moon-child> iirc G1 will compact only one 'region' at a time
[09:08:34] <hayley> Not one, but still not close to all of them.
[09:09:52] <hayley> G1 maintains remembered sets for inter-region references, and uses those so that it only has to fix pointers in a fraction of the heap. But I would rather have an incremental fixup phase, and just stop the world to copy and fix up the roots.
[09:11:07] <hayley> Could use both approaches, of course, they are pretty orthogonal. But G1 has fairly heavy write barriers to my knowledge, as the barriers have to do snapshot-at-the-beginning work and inter-region work.
[09:11:35] * moon-child nods
[09:13:27] <hayley> Of course, in SICL, the write barrier also has to check if it is going to make a old->new reference, but you can probably eliminate some redundant tests in both barriers. 
[09:16:14] <hayley> Also G1 (AIUI) only reclaims memory by copying, whereas I am suggesting to do on-the-fly mark-sweep where possible, and then fall back to a mostly-concurrent compactor if necessary. 
[09:55:44] *** Quits: v3ga (~v3ga@2603-6080-5204-3b35-0000-0000-0000-18ad.res6.spectrum.com) (Ping timeout: 268 seconds)
[09:57:10] *** Joins: v3ga (~v3ga@cpe-98-25-21-91.sc.res.rr.com)
[10:18:05] *** Joins: treflip (~user@user/treflip)
[10:28:02] * hayley got a phone call with someone from university following up about a question she asked about how the credit system worked.
[10:29:42] <hayley> "Well, over this year I got hired to work on a compiler part-time, and then implemented a fairly fast regular expression engine with an unpublished technique, do you think I'd have a chance at getting credit for the Computing Theory class rather than an elective?" "You could ask [the course coordinator]." "I could, but it's just a hypothetical, I'm fine with either way."
[10:34:59] *** Quits: robin (~robin@user/terpri) (Quit: Leaving)
[10:39:37] *** Joins: robin (~robin@user/terpri)
[10:46:59] <ck_> what did you expect?
[10:51:38] <treflip> I finally read this article: https://applied-langua.ge/posts/lisp-curse-redemption-arc.html. It is very motivating ‚òª
[10:51:39] -ixelp- The Lisp "Curse" Redemption Arc, or How I Learned To Stop Worrying And Love The CONS
[11:03:01] *** Joins: shka (~herr@109.231.0.226)
[11:04:26] *** Parts: contrapunctus (a75f5b1571@2a00:c70:1:178:170:40:189:1) ()
[11:06:09] <hayley> treflip: Thanks!
[11:07:03] <hayley> ck_: I'd have liked a yes/no answer, even if it could be wrong.
[11:07:35] <hayley> Like, if I didn't study it all in my past university, what do I have to do instead? Should I write the entire compiler next time?
[11:19:57] *** Joins: contrapunctus (a75f5b1571@2a00:c70:1:178:170:40:189:1)
[11:26:08] <hayley> https://www.youtube.com/watch?v=On-k-E5HpcQ
[11:26:09] -ixelp- Computer Architecture is Back: Parallel Computing Landscape - YouTube
[11:41:47] <hayley> "Our basic approach is to give each CPU an M-element cache of objects called a magazine, by analogy with automatic weapons. Each CPU‚Äôs magazine can satisfy M allocations before the CPU needs to reload ‚Äì that is, exchange its empty magazine for a full one."
[11:42:24] <hayley> Why do C programmers have to make thread-local allocation buffers so violent? /me remains hypocritical by measuring "infant mortality" in generational GC.
[11:43:19] <shka> hayley: because computing is a battlefield 
[11:44:11] <sham1> T'is a hard world out there
[11:44:26] <dave0> you could call it a kitten or puppy
[11:45:46] <shka> interview! https://www.youtube.com/watch?v=gcuOSXjevGs
[11:45:46] -ixelp- Talking about Rocket Lab‚Äôs Neutron with Peter Beck - YouTube
[11:45:54] <shka> about that james bond rocket :P
[11:46:33] <dave0> reload the cache with a litter of kittens/puppies
[11:46:40] <shka> damn kiwis
[11:47:05] <shka> dave0: in the grim dark future of 2022, there is only war
[11:47:07] <shka> :P
[11:47:51] <dave0> shit it's less than 2 weeks to 2022
[11:48:43] <mfiano> this just in: 2022 cancelled
[11:50:17] *** Quits: makomo (~makomo@user/makomo) (Ping timeout: 240 seconds)
[11:56:37] <semz> eternal december?
[11:57:21] <mfiano> Nah, we are overflowing to -2023 because "C makes the world tick", complete with useless padding in their 12bit struct.
[11:58:40] <hayley> lol
[12:01:51] <treflip> "C makes the world tick like a time bomb"
[12:02:48] <ck_> 2038 is not far away, can't wait..
[12:03:01] <hayley> I did indeed say "time bomb".
[12:04:34] <hayley> https://github.com/robert-strandh/SICL/blob/master/Talks/ILC-2014/slides.tex#L262 ‚Üê beach suggests using the Compactor for a global heap. 
[12:04:35] -ixelp- SICL/slides.tex at master ¬∑ robert-strandh/SICL ¬∑ GitHub
[13:14:09] <gilberth> With Rust, when I want to mutate an object at one spot, I need to write 'mut'. When I want an object with dynamic extent, but of variable size, I need to write Box<T>, when I want to mutate from multiple places, I need to write RefCell<T> or Mutex<T>, when dynamic extent isn't suffice, I need Rc<T>. When I need to pass an object to other threads, I need Arc<T> and Mutex<T>. Shouldn't all of this be the job of the compiler?
[13:16:42] <gilberth> When I want non-local exit, I need a whole program transformation with Result<T>. All of these <T>'s are whole program transformations. So much for modularity.
[13:18:16] <hayley> Thankyou Paul Wilson.
[13:18:17] <gilberth> When I need to increment a refcount, I need to say .clone() or .borrow() or .borrow_mut(). When I want to read an object, I need to say .lock().unwrap(). Perhaps I have forgotten something.
[13:18:39] <moon-child> 'non-local exit' Result isn't really non-local, though, is it?  Just syntax sugar
[13:19:08] <hayley> "Garbage collection is necessary for fully modular programming, to avoid introducing inter-module dependencies."
[13:19:27] <hayley> ...per Wilson's GC survey paper.
[13:19:31] <gilberth> moon-child: Yes, it is just sugar. This is what I meant by whole program transformation, you need to sneak that in into every return value, to get what you would get with non-local exit otherwise.
[13:20:13] <moon-child> hayley: yes.  That was something somebody brought up at ismm last year too: people were discussing rust, and somebody said: gc means apis may be polymorphic over ownership because they do not have to explicate it
[13:20:31] <hayley> Maybe I should go to ISMM then.
[13:20:36] <gilberth> Every function would return a Result<T> and you need to check for it being Ok(x) or Err(x). The foo()? syntax is syntactic sugar for that.
[13:20:57] <moon-child> it was free and online, so I went.  I don't know if they'll do it that way in the future
[13:21:01] <moon-child> also I got to chat with emery berger
[13:21:14] <hayley> "bro u posted cringe paper prepare to lose subscriber"
[13:21:23] <moon-child> coz is still cool tho
[13:21:41] <hayley> The Berger giveth, the Berger taketh away.
[13:21:55] <moon-child> heh!
[13:23:41] <hayley> Not exactly his fault the paper is misinterpreted to make anti-GC points...except for the part where it's called "Quantifying the Performance of Garbage Collection vs. Explicit Memory Management" I guess.
[13:24:20] <hayley> Wouldn't mind some words in the abstract with meaning like "We use oracles to make malloc/free behave, but you're not a damn oracle now, are ya?"
[13:26:09] <gilberth> Hence, coming from C, Rust is an improvement with regard to safety. But it still is a joke and it's GC is the most shitty GC, I ever saw with, a 20000% performance hit.
[13:26:23] <hayley> ...and since the time/memory curves in the paper go like _, even ¬±10% would greatly throw off break-even memory claims.
[13:26:30] * gilberth has lost another single quote.
[13:26:55] <hayley> You left it in "it's"
[13:27:45] <gilberth> Yes, this is why I said "lost". Its not in my pocket anymore.
[13:28:35] * hayley uploaded an image: (48KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/ZiqDXBXRaPmLSlTUqcEZTisr/Screenshot%20from%202021-12-20%2020-58-15.png >
[13:29:32] <hayley> But look at this graph. You'd get a pretty different conclusion if you were, say, 20% more slack than an oracle machine (the solid line at the bottom). 2.5√ó heap still isn't pleasant on paper, but it's a lot better than 6√ó.
[13:30:17] *** Quits: aeth (~aeth@user/aeth) (Ping timeout: 252 seconds)
[13:30:34] <gilberth> Well, does the oracle solve the halting problem?
[13:30:43] <hayley> YES!
[13:31:15] <moon-child> lol.  Tbf gc can't either, and uses reachability as a proxy for liveness
[13:31:42] <hayley> The authors claim that these results are useful for practitioners when choosing languages. Must be trying to compliment the reader by stating they are an oracle machine. Wonder if the reviewers pointed that out.
[13:32:16] *** Joins: aeth (~aeth@user/aeth)
[13:36:21] <shka> also, since computing is a battlefield, CL stands for COMBAT LISP
[13:38:55] <gilberth> Who we are at war with?
[13:39:02] <hayley> Crabs?
[13:39:21] <gilberth> Am I? They don't bother me.
[13:40:08] <hayley> What the fuck did you just fucking say about me, you little crab? I‚Äôll have you know I graduated top of my class in the Rocket Realtime School, and I‚Äôve been involved in numerous secret raids on Mozilla, and I have over 300 confirmed clone families. I am trained in pony warfare and I‚Äôm the top shitposter in the entire #... (full message at
[13:40:08] <hayley> https://libera.ems.host/_matrix/media/r0/download/libera.chat/538c636fda604b6e67b9f26569dac1ea5b569a38)
[13:40:14] <shka> combat-lisp is probably a good library name :P
[13:44:25] <hayley> shka: What the fuck did you just fucking say about me, you little crab? I‚Äôll have you know I graduated top of my class in the Rocket Realtime School, and I‚Äôve been involved in numerous secret raids on Mozilla, and I have over 300 confirmed clone families. I am trained in pony warfare and I‚Äôm the top shitposter in the entire #lispcafe.
[13:44:32] <hayley> You are nothing to me but just another luser. I will wipe you the fuck out with macros the likes of which have never been seen before on this Earth, mark my fucking words. You think you can get away with saying that shit to me over the Internet? Think again, fucker. As we speak I am contacting my secret network of uniques across the planet and your VM is being traced right now so you better prepare for the storm, maggot.
[13:44:38] <hayley> The storm that wipes out the pathetic little thing you call your code. You‚Äôre fucking dead, kid. I can be anywhere, anytime, and I can kill you in over seven hundred ways, and that‚Äôs just with my bare REPL.
[13:44:38] <shka> hayley: stop it
[13:44:44] <hayley> sorry
[13:45:17] * hayley stops looking through copypasta pile and goes back to work
[13:45:18] <shka> i will accept progressive rock from Australia as a token of friendship
[13:46:38] <hayley> https://soundcloud.com/user-308419292/time-clocks-and-events/s-Ad9IxXIMVLD The one track on my next album that isn't boring and doesn't have words yet.
[13:46:39] -ixelp- Stream Time, Clocks And Events by theemacsshibe | Listen online for free on SoundCloud
[13:49:07] * hayley uploaded an image: (9KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/GxiUBGQLGeFtUqFAbGrrvVGT/Screenshot%20from%202021-12-20%2021-18-49.png >
[13:51:16] <ck_> gilberth: maybe that (crabs) was what Orwell meant with "Oceania"
[13:52:50] <shka> hayley: lol, you sound like early porcupine tree now :D
[13:53:31] <hayley> shka: I'd send the link to the rest of the (draft) album, but you'd have to hear me sing.
[13:54:54] <shka> hayley: https://www.youtube.com/watch?v=Hp2qVJLzASI
[13:54:55] -ixelp- The Nostalgia Factory - YouTube
[13:56:32] <shka> hayley: do i look like a little bitch to ya? bring it on! :P
[13:56:46] * hayley sends in PM
[14:02:57] * hayley now engages in review of someone else's language with a crab
[14:03:04] <hayley> "Please zero size types, thx" "Please language specification, thx" 
[14:06:13] <moon-child> meh spec is a waste of time while you are iterating design
[14:06:28] <moon-child> may be helpful to flesh out ideas--and if so, great;--but if not, then no reason to bother
[14:08:27] <hayley> If you are doing Serious Programming (as one is supposed to with Rust), it'd be nice. At least knowing the order of evaluation for *foo.borrow_mut() = 1+ *foo.borrow(); would be nice.
[14:10:22] <moon-child> oh this is for rust
[14:10:30] <moon-child> I thought it was for a new thing
[14:10:33] <hayley> Yes.
[14:10:46] <hayley> The review is for a new thing, but "please language specification" is pointed at Rust.
[14:11:07] <hayley> ...and the person doing this is compiling to JS, so good luck having zero size objects.
[14:11:39] <moon-child> what is a zero-sized object?  A unit type?
[14:12:30] <hayley> A zero sized type is just somewhere to hang more types, for use in modelling stuff. It's basically a unit type, sure.
[14:12:55] <hayley> https://doc.rust-lang.org/std/marker/struct.PhantomData.html This one's probably most "famous".
[14:12:55] -ixelp- PhantomData in std::marker - Rust
[14:13:01] <sham1> A zero-size object is basically just a compile time thing. Doesn't actually exist at runtime
[14:13:31] <moon-child> then why can you not have one when compiling to js?
[14:14:32] <hayley> Hm, I guess you can have a unit value. But "zero sized" implies you have to optimize it out somehow, to me.
[14:15:07] <hayley> ...though, without referencing actual implementation details, it's true that there is only one instance of the unit type, and that requires 0 bits to represent.
[14:15:09] <moon-child> sure.  But I don't see why compiling to js would preclude that
[14:15:18] <moon-child> it is just another compilation target
[14:15:48] <hayley> I guess then you'd just not materialize the slots and variables which hold zero sized types then. nvm
[14:24:48] <sham1> That's how it works. Indeed, I don't see why something like Rust couldn't be compiled to JS when it can be for WASM
[14:24:57] <sham1> The same idea basically
[14:25:52] <shka> isn't WASM a subset of JS?
[14:25:57] <shka> or rather i
[14:26:07] <shka> isn't WASM part of JS
[14:26:10] <hayley> JS doesn't expose any idea of "object layout", whereas anything on the heap on WASM is all object layout.
[14:26:10] <sham1> No
[14:26:17] <shka> ok
[14:26:37] <sham1> WASM is technically a separate technology from javascript, although they're often used in tandem because, well, web
[14:27:25] <moon-child> wasm is ... meh.  I feel like it didn't really solve a problem that anybody needed to be solved.  (Though, I could say the same for the web)
[14:27:33] <moon-child> and iirc WASI is ... not done quite right
[14:27:38] <sham1> It's trying to solve the same problem Java tried to solve
[14:28:31] <moon-child> sort of.  But we already have high-quality java implementations
[14:28:53] <hayley> "Anyone else have criticisms or complaints about The Lorax by Dr. Seuss?" "those are not trees doctor Seuss clearly did not touch grass"
[14:29:22] <sham1> moon-child: well reinventing the wheel isn't exactly a new thing for the web
[14:29:51] * hayley taps https://arxiv.org/abs/2111.01421 sign
[14:30:14] <hayley> Java has dynamic class loading, a garbage collector, and OO-based polymorphism. WASM seems to avoid all that.
[15:11:06] <shka> which is funny because java is used as a static language
[15:13:05] <hayley> Java however does not have UPDATE-INSTANCE-FOR-REDEFINED-CLASS.
[15:14:11] <hayley> But you already knew that; it is not awfully usable as a dynamic language.
[15:15:38] <hayley> https://www.youtube.com/watch?v=eUJ_ifjKopM
[15:15:39] -ixelp- Sparks - "This Town Ain't Big Enough For Both Of Us" (official video) - YouTube
[15:17:12] <shka> hayley: always thought that this was Siouxsie song
[15:20:48] <hayley> I mean, C on POSIX has dlopen, but your average C implementation is a batch compiler.
[15:26:48] <sham1> Well tbf, dlopen is more just meant for stuff like plugins and loading libraries when needed. It's usually not meant for the more "core" stuff
[15:27:13] <hayley> The same for misusing class loaders in Java to load code at runtime.
[15:28:34] <sham1> Yes
[15:28:40] <hayley> defineClass() (yes, it is called that) is only protected, so just you just add a method that can call defineClass to load code.
[15:28:53] <hayley> s/so just/so/
[15:29:15] <sham1> No need to even do that. Reflection
[15:29:41] <hayley> Huh.
[15:29:56] <hayley> That is what I did to test HIR-to-JVM still.
[15:31:39] <sham1> Although, to pop the stack a bit, one thing that might be interesting would be to generate webassembly on the fly, within some WASM code. A REPL, let's say
[15:31:57] <sham1> Of course, the real problem would be the interaction between the REPL and the newly generated code
[15:32:46] <sham1> Like one could imagine a Common Lisp (or a Scheme) implementation compiled to WASM and compiling itself stuff to WASM
[15:34:23] *** Joins: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4)
[15:36:39] <gilberth> The real problem would be that event driven nature. Hence, no READ for you and no PRINT.
[15:38:37] <hayley> Can WASM modules share a heap? I guess they would in order to be modules.
[15:38:56] <sham1> Well you could have the stuff be asynchronous. It'd look different than what you'd usually have for a REPL though
[15:40:34] <gilberth> hayley: I very much doubt that. I would be surprised when WASM could do more than JS here.
[15:41:56] <hayley> Hm, I don't think modules work as I am thinking. They are statically linked executables, more or less.
[15:43:08] * hayley wrong, there is dynamic linking in WASM.
[15:44:16] <hayley> But I suspect it's going to be hairy to make newly compiled code run in the same address space...somehow.
[15:44:44] <sham1> Most probably
[15:44:58] <gilberth> sham1: Yes, but compiling CL will get pointless, when you need to call continuations in one single loop without using a call stack. That's called threaded code and is not what you would usually call native compiled code.
[15:46:47] <hayley> Apparently "generate wasm at runtime" is a common search query for Google, yet the results are crap.
[15:47:23] <hayley> Must be why. You look at the results, scratch your head, go for a walk, then search again, then look at the results...
[15:47:50] <hayley> "Implementable inside server/client web apps, WebAssembly emphasizes portability and predictability. Alongside RISC-V, it‚Äôs a relatively new instruction set architecture (ISA) developed over the last decade able to run alongside host languages."
[15:47:56] <hayley> I only find shit articles these days.
[15:48:50] *** Joins: OlCe (~user@lfbn-nic-1-588-65.w90-118.abo.wanadoo.fr)
[15:49:05] <hayley> Apparently the Java IO stuffs suffers from portability issues, so it wasn't "write once, run anywhere" but the WASM interface (WASI) somehow avoids this. Not.
[15:50:32] <moon-child> gilberth: I think chicken scheme does that, and is reasonably fast
[15:50:52] <hayley> Best of luck implementing GC still.
[15:51:39] <hayley> "You can compile every language on WASM, as long as every language looks like C" -- someone in the Bytecode Alliance
[15:52:01] <moon-child> they are adding a gc thing.  But I don't remember whether they were planning on letting you do your own tagging or not
[15:52:03] <gilberth> moon-child: Well, a byte interpreter is reasonable fast, too.
[15:52:15] <moon-child> gilberth: chicken compiles to c
[15:53:16] <gilberth> moon-child: Didn't you say, it compiles to threaded code?
[15:53:26] <hayley> .oO(The Bytecode Alliance? Do they have Smalltalk-80 bytecode people too? JVM perhaps more common? What an arrogant name.)
[15:53:48] <hayley> .oO(And do I sound like ep*ny now?)
[15:54:37] <gilberth> But, yes, the initial C implementation was using that technique and not a native code compiler.
[15:54:49] <moon-child> gilberth: I don't entirely remember.  But I think it compiles to chains of functions, each of which tail-calls the next, passing it a continuation
[15:55:24] <gilberth> moon-child: C has no tail-call. Does WASM have that?
[15:55:42] <hayley> gilberth: Cheney on the MTA
[15:56:01] <moon-child> c has no tail call, but you can assume that gcc will do it for you anyway
[15:56:02] <hayley> It doesn't matter if you tail call or not, when you can GC the stack anyway.
[15:56:03] <gilberth> When you have tail-calls it is easy. JS doesn't have tail-calls for instance, so it gets very slow.
[15:57:06] <gilberth> hayley: Then you have one single top level loop with a program counter calling bits of code == threaded code.
[15:57:30] <gilberth> Good luck implementing Cheney with WASM.
[15:58:20] <gilberth> WASM sure has arrays. Use indices as pointers into a CAR array and a CDR array. Easy.
[15:59:07] <hayley> Wrong, WASM just has one global heap and your pointers are just indices into the heap.
[15:59:27] <hayley> https://plover.com/~mjd/misc/hbaker-archive/CheneyMTA.html
[15:59:28] -ixelp- Cheney on the M.T.A.
[15:59:41] <hayley> No continuation loop, just more calling.
[16:00:09] <hayley> "A key point is that since¬†only live objects are traced--i.e., garbage (including the C frames, which are all dead) is not traced--the GC does not have to know the format of a stack frame and can be written in C itself."
[16:00:17] <gilberth> hayley: Has WASM tail calls?
[16:00:41] <hayley> No, but you don't need them to ride the MTA.
[16:01:10] <gilberth> Heh, what keeps you from overflowing the stack then?
[16:01:42] <hayley> True, you cannot inspect the stack depth. Guess?
[16:02:50] <gilberth> You can bet. I did that with JS, but it turned out to be slow, as closures in JS are very slow somehow.
[16:03:42] <sham1> Probably goes to the slow path
[16:03:47] <hayley> Hey, Henry Baker also did this lazy heap allocation thing which tries to allocate on the heap--oh, wait, both won't work simultaneously.
[16:03:55] <gilberth> With JS there is no point though, as the closures are not allocated on the stack.
[16:04:13] <hayley> Not that he could have cared, since cache misses got 1.618e42 times worse since 1991.
[16:04:34] <hayley> You don't know that.
[16:05:02] <hayley> But, again, CPS means you either don't pop frames, or you return continuations and thus break stack order.
[16:05:05] <gilberth> ?
[16:07:04] <gilberth> Well, with the event driven model, I need to be prepare to get hold of the current continuation fit to be stashed somewhere at the heap to be invoked later from the top level again. This implies that the continuation can't live on the stack.
[16:07:54] <hayley> You won't win from stack allocating closures that are used to implement a callback system.
[16:07:58] <gilberth> Or need to be evacuated from the stack.
[16:08:22] <hayley> More accurately, you can't stack allocate those closures--right.
[16:08:30] <hayley> Poor wording on my behalf.
[16:08:52] <gilberth> Yes, as I said. Been there.
[16:09:11] <hayley> https://plover.com/~mjd/misc/hbaker-archive/cboyer13.c
[16:14:13] * hayley has clang on her phone, so runs the program.
[16:14:37] <hayley> 50.4ms on default settings, and I didn't even bother with -O either.
[16:15:20] * hayley tries -O3 and clang takes its time.
[16:16:33] <hayley> I can only afford -O1, which runs in 24ms.
[16:17:27] <gilberth> Don't you have a "clang Gold Membership"?
[16:18:36] *** Joins: random-nick (~random-ni@87.116.180.98)
[16:18:42] <hayley> No.
[16:18:59] <hayley> That's the rustc developers, with their 96 core VM for compiling rustc.
[16:20:53] <hayley> Okay, it's been 3.5 minutes, clearly clang is not designed to run on phones. And this phone is old enough for SBCL developers to complain it's old.
[16:27:15] <hayley> Funny that you can see something like cache blowout. With a 500k stack, there are 112 collections and it takes 20ms. With a 5M stack, there are 12 collections and it takes 50ms.
[16:27:17] *** Quits: aeth (~aeth@user/aeth) (Ping timeout: 240 seconds)
[16:29:22] *** Joins: aeth (~aeth@user/aeth)
[16:39:40] <dave0> less than a week until christmas
[16:42:38] <sham1> Indeed. 4 days. Well, technically 5 but at least here the eve is more important than the day itself
[16:46:00] <gilberth> Eve is more important here too.
[16:49:16] <gilberth> This year will be quiet an peaceful again as I don't have to take a tour visiting my wife's family.
[17:33:27] <contrapunctus> hayley: I've commited the changes I spoke of before, but I'm yet to finish reading the entire document. Would you rather a make an MR now, or once I finish reading (with possibly more changes)?
[17:59:12] *** Quits: Alfr (~Alfr@user/alfr) (Ping timeout: 268 seconds)
[18:02:58] *** Joins: Alfr (~Alfr@user/alfr)
[18:20:01] <Alfr> Good morning.
[18:20:11] <selwyn>  good morning
[18:30:48] <contrapunctus> Good evening.
[18:32:30] <ck_> and good night
[18:36:57] *** Quits: euandreh (~euandreh@2804:14c:33:9fe5:995c:e86e:470c:8a37) (Ping timeout: 240 seconds)
[18:53:35] <contrapunctus> Gnuxie, hayley: "There was an argument about [statically vs dynamically typed systems]" - an argument from or with whom? ü§îÔ∏è
[19:01:50] <contrapunctus> Also, this might just be me and my lack of experience with using or implementing statically typed languages, but the conclusion of that paragraph ("So yes, static languages and their implementations are hopeless.") seems a little sudden and broad. (The latter could be alleviated with something like - "current implementations of static languages have no hope of meeting our requirements.")
[19:03:00] <dave0> nite all
[19:03:12] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[19:10:39] <contrapunctus> Gnuxie, hayley: "sterilising objects to disk"...an error, or a deliberate choice of word? üòÑÔ∏è
[19:12:59] <Gnuxie> LwL
[19:14:32] <Gnuxie> An unfortunate error
[19:15:02] <Gnuxie> Have you put these onto the repo? 
[19:17:11] <contrapunctus> I'll change that, then ;)
[19:21:19] <Gnuxie> As for static vs dynamic, we're supposed to argue that the properties of dynamic languages aren't expressible in static ones by definition & design 
[19:22:11] <Gnuxie> But we could probably do that better
[19:33:25] <contrapunctus> Gnuxie: as I wrote above (but didn't ping you, inexplicably), I can make the PR now, or later (with possibly more changes) after I've finished reading - let me know your preference.
[19:37:44] *** Joins: euandreh (~euandreh@2804:14c:33:9fe5:b7fd:fa95:80d6:f41)
[19:43:46] *** Joins: makomo (~makomo@user/makomo)
[19:57:30] *** Quits: luis (~luis@lisp/luis) (Quit: The Lounge - https://thelounge.chat)
[20:02:03] *** Quits: treflip (~user@user/treflip) (Remote host closed the connection)
[20:02:27] *** Joins: treflip (~user@user/treflip)
[20:02:53] *** Joins: luis (~luis@lisp/luis)
[20:03:56] <Gnuxie> contrapunctus: later if it suits you idk we probably won't look at it straight away 
[20:22:14] *** Quits: treflip (~user@user/treflip) (Remote host closed the connection)
[20:22:39] *** Joins: treflip (~user@user/treflip)
[20:33:04] *** Joins: Catie (~user@user/catie)
[20:53:43] *** Joins: clothespin_ (~awolven@c-73-209-95-92.hsd1.il.comcast.net)
[21:30:05] <gilberth> I wonder of m-expressions have ever been really used.
[21:32:05] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[21:32:27] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[21:41:26] <gilberth> Also I wonder, if (CAR 'A) would crash Lisp 1.5. CAR and CDR don't do any type checking. Symbols have the word 77777 at their CAR. It's not said what 77777 is. The CDR of a symbol is its plist. Numbers have their CAR also being 77777.
[21:52:45] <Alfr> gilberth, what's at 2^16-1?
[21:53:13] <Alfr> (Assuming those numbers are octal.)
[21:54:01] <gilberth> They are octal. The memory map says the loader is at 77600 to 77777.
[21:55:37] <gilberth> I have no clue, if that is a kind of boot ROM. They could however have put something sane there as a guard.
[21:58:50] <gilberth> Symbol names however also carry bare words. Those names are linked lists of 6 characters bare words padded with 77. (The names are stored at the PNAME property in a symbols property list).
[22:03:20] <gilberth> This confuses me. 6 chars = 18 bits, while 77777, also called -1, = 15 bits.
[22:03:26] <edgar-rft> do we really want to see bare words?
[22:03:52] <gilberth> I don't. I just wonder how safe Lisp 1.5 was.
[22:06:18] <gilberth> I could learn 7090 assembler and read the code, but I don't feel like it.
[22:09:04] *** Quits: treflip (~user@user/treflip) (Quit: good night ‚ú®)
[22:29:40] <Alfr> gilberth, it could conveniently encode nil ... just store 77777 there and have addition overflow return max-integer, i.e. 77777+1=77777, then (cdr nil) would also give nil. lol
[22:30:45] <Alfr> Though that wouldn't fix (car some-symbol).
[22:30:56] *** Quits: waleee (~waleee@2001:9b0:21d:fc00:398f:b003:b90d:acf4) (Ping timeout: 252 seconds)
[22:31:29] <gilberth> NIL is at 00000 says the manual. And yes, taking the CDR of 77777 would overflow or wrap around. Hmm. So when 77777 would point to itself, that would be an atom with an empty plist.
[22:33:02] *** Joins: waleee (~waleee@h-98-128-229-110.NA.cust.bahnhof.se)
[22:33:30] <gilberth> That is (atom <77777>) -> *T* and (cdr <77777>) -> NIL. That should work. (Atom is any pointer with (CAR p) = 77777). It's then a symbol with no name and no value.
[22:35:48] <Alfr> Ah ... so, atoms are symbols with no (in contrast to some or an empty) name and an empty plist?
[22:36:48] <gilberth> No. Atoms are pointers to a pair with 77777 in it's CAR and either the numerical value in its CDR or the plist (if it's a symbol).
[22:37:37] <Alfr> Okay.
[22:38:49] <gilberth> When I use <...> for bare words and <"..">¬† to represent packed 6-bit chars. The symbol EXAMPLE is (<77777> . (PNAME (<"EXAMPL"> <"E?????">))
[22:42:17] <Alfr> )
[22:42:41] <gilberth> Yep. Indeed. And I lost another single quote.
[22:42:44] <Alfr> gilberth, what are the question marks?
[22:43:12] <gilberth> That is the char 77, which is said to be some void or illegal char.
[22:43:43] <gilberth> To pad the name.
[22:45:12] <Alfr> Understood. (And, am I glad, that I don't /have to/ dig into this ...)
[22:47:58] <gilberth> Maclisp still uses the same representation. Alfr, I am just curious. Otherwise it's fun to see how much has survived in Lisp from that time.
[22:50:02] <gilberth> And I get a better grasp of where some things in muLISP for the 8080 came from. An implementation I used with CP/M-80 and which is so well made, that you could do quite a bit in that 64kB address space. When I am bored I try to dig the disassembly.
[22:54:53] <gilberth> To save space muLISP skips the COND and the PROG. In a function you can use ((NULL X) NIL) as a form, which then is like (WHEN (NULL X) (RETURN NIL)).
[23:15:25] *** Joins: marcoxa (~user@77-57-64-215.dclient.hispeed.ch)
[23:16:33] <gilberth> K)
[23:16:39] <gilberth> Oops.
[23:17:40] <gilberth> Anyhow, I wonder if I should make PROGV a special form in my "Core Lisp". Without multithreading you could implement dynamic scope by yourself, but with multithreading you really want to have thread local bindings.
[23:26:23] <gilberth> And I wonder, why they have chosen (<key-1> <val-1> ... <key-n> <val-n>) for property lists instead of using alists? This must have some reason, because otherwise e.g. ASSOC could have been reused and applied directly to symbols. There also would not have been confusion between flags and properties. Given that space was tight, why the alternative format?
[23:30:21] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 268 seconds)
[23:31:24] <gilberth> Lisp 1.5. does not have PROGV as a special form, but symbols carry a flag bit saying whether they are special or not.
[23:38:54] <shka> hmmmmm
[23:39:06] <shka> gilberth: not everything is special?
[23:39:15] <shka> well, every variable that is
[23:39:24] <gilberth> No, the compiler implements lexical scope.
[23:40:08] <gilberth> Though there are no lexical closures.
[23:46:33] <gilberth> You could have closures, but only dynamic closures. This isn't actually documented but referred to, so I could only guess. It's called FUNARG and the CADR Lisp machine has this as ENCLOSE (IIRC) it would take a function and close it over a dynamic environment. That is when you invoke the function, that dynamic environment would be established around the invokation.
[23:47:53] <gilberth> The Lisp on the CADR uses this to implement object oriented programming. The slots live in that dynamic environment closed over and objects are then then such closures. Invoking a method mean FUNCALLing the object with a message selector as the first argument.
[23:49:52] <gilberth> Like: (DEFUN RECTANGLE (MSG) (CASE MSG (:AREA (* WIDTH HEIGHT)) ...) (SETQ OBJ (ENCLOSE RECTANGLE '((WIDTH . 3) (HEIGHT . 4))) (FUNCALL OBJ ':AREA) => 12
