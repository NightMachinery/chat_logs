[00:01:06] <gwern> Obormot\Arcturus: yes, the URL got updated as part of mass-updating. so the selector needs to be updated
[00:02:01] <Obormot\Arcturus> evafan.com, then?
[00:02:09] <gwern> kuudes: you have to admit, the logistics work out a lot better than the reverse
[00:02:16] <gwern> Obormot\Arcturus: yes
[00:02:35] <Obormot\Arcturus> k
[00:03:14] <Obormot\Arcturus> er, eva-fan, rather
[00:03:22] <Obormot\Arcturus> (Why do they have a hyphen in their domain name -_- )
[00:05:17] <adiabatic> https://twitter.com/yarden_shafir/status/1493648557836050434
[00:05:20] <Robomot> Yarden Shafir (@yarden_shafir): "I’m using a debugger to debug my kernel debugger that I set up to debug the user-mode debugger on my VM so I think this is the time to switch from coffee to wine"
[00:06:23] <adiabatic> Obormot\Arcturus: my registrar will suggest domains that have hyphens in them if the one you really wanted was taken
[00:06:28] <Obormot\Arcturus> :\
[00:07:00] <adiabatic> actually I have a domain name that has a hyphen in it, but I'm not using it for anything
[00:09:05] <gwern> looks like someone already owns 'evafan.com' which makes sense, but aren't doing anything with it - not even a squatter
[00:14:06] <feepbot> <gwern> 'I recently learned that Facebook Marketplace is the world’s second-largest marketplace, in terms of monthly active users, behind only Amazon. It’s ahead of Alibaba, Walmart, eBay, Taobao, and has quietly left the once-unconquerable Craigslist in the dust.' https://www.lennysnewsletter.com/p/the-inside-story-of-facebook-marketplace?r=il6m
[00:14:06] <Robomot> The inside story of Facebook Marketplace (A guest post by Deb Liu)
[00:16:50] <Obormot\Arcturus> (Boy this is some tedious shit. But I content myself with the knowledge that this is a big pile of technical debt I am paying off)
[00:18:16] <gwern> (so many places to extend that analogy: the venture capital of tech. the sovereign tech debt. the junk bond kings of tech debt. the CDOs of tech debt)
[00:19:30] <Betawolf> the government tech debt ceiling
[00:20:57] <Betawolf> "Will Congress manage to agree in time to ask Microsoft for further longterm support on Windows XP?"
[00:25:47] <pie_> the fuck is facebook marketplace
[00:25:50] <pie_> never heard of it :V
[00:26:21] <gwern> welcome to the bubble
[00:31:17] <gwern> (something to think about if you want to predict economics or consumer tech: as a nerd in #lesswrong, in many ways your opinions are not just uncorrelated with reality, but inversely correlated)
[00:32:54] <Obormot\Arcturus> https://css-tricks.com/a-complete-guide-to-data-attributes/ ... hmmm
[00:32:54] <Robomot> A Complete Guide to Data Attributes | CSS-Tricks - CSS-Tricks (Everything you ever wanted to know about data attributes in HTML, CSS, and JavaScript.)
[00:33:08] <Obormot\Arcturus> Storing JSON inside data attributes seems both awesome and horrible somehow
[00:35:31] <gwern> seems logical to me. the data attributes are just a key-value store
[00:35:55] <gwern> they don't support more complex schemas or validation or anything. but a JSON object inside the string value can do that. so, it's like a nosql database
[00:37:44] <gwern> you get a proper structured natively-parseable validatable hierarchical data format, which is attached to relevant objects rather than just being a big JSON blob freefloating in a global variable, maybe even loaded at runtime by JS rather than being cleanly written in the source
[00:42:45] <feepbot> <gwern> https://store.petly.jp/items/59ee971bf22a5b1ac4000833 quanticle: for the cat-loving SV billionaire in your life
[00:42:47] <Robomot> Modern Cat Tree NEKO | RINN Inc. (【受注生産品】ご注文からお届けまで約2ヶ月程度頂いております。 ※2022年2月5日時点 モダニズム建築やアートミュージアムにフィットするような、美しい猫用遊戯家具がつくれないだろうか。その考えが、このプロダクトが誕生するきっかけでした。ある日、玄関の...)
[00:45:34] <Obormot\Arcturus> Hmm, perhaps. Of course, the problem is that you're not actually storing objects in your data attributes; the value of those attributes is stale as soon as it's parsed, and forevermore (the logical thing to do being, obviously, to parse the JSON and then to store the resulting object directly in the DOM object which represents the element whose data attribute it was)
[00:47:39] <Obormot\Arcturus> (Contrast this with storing e.g. string values directly in a data attribute: you can read the value from the attribute, but also write it right back to the same data attribute, without needing to do any parsing/decoding, so you've only got the one store, which is never stale)
[00:48:15] *** Quits: _inky (inky_@gateway/vpn/protonvpn/inky) (Remote host closed the connection)
[00:48:43] <Obormot\Arcturus> As a way to ship complex structured data associated with specific HTML elements, yeah, it has value, I agree
[00:50:14] <Obormot\Arcturus> The thing I am implementing now is actually a sort of "middle way" or "hybrid" solution, with one important advantage over the JSON approach...
[00:53:12] *** Joins: _inky (inky_@gateway/vpn/protonvpn/inky)
[00:55:15] <feepbot> <gwern> https://twitter.com/JohnnyRoccia/status/1493462196982108162
[00:55:16] <Robomot> Johnny Roccia (@JohnnyRoccia): "My manager once made it known / Appreciation for discretion shown / He feared my vulgarity / Despite the hilarity / 'Cause he knew what I said when alone!"
[01:00:17] <feepbot> <gwern> https://www.wired.com/story/insect-pet-animal-food/ you may not eat the bugs but your pets will
[01:00:18] <Robomot> For Insect Farming to Work, Scientists Need to Build a Better Bug | WIRED (Faster-growing, fatter critters could provide the protein needed to raise more climate-friendly livestock and pets.)
[01:04:45] *** Quits: schmudde (~schmudde@2001:b07:ae6:7d19:f0c6:e281:36c1:5577) (Ping timeout: 252 seconds)
[01:05:19] <feepbot> <gwern> https://www.bloomberg.com/opinion/articles/2021-12-31/hindsight-capital-made-the-best-trades-in-2021-with-a-little-bold-contrarianism?sref=1kJVNqnU tragically, they are now closed to outside investment
[01:05:20] <Robomot> Hindsight Capital Made the Best Trades in 2021, With a Little Bold Contrarianism - Bloomberg (What if you could do 2021 over again? This legendary firm has a strategy that beats all others, and always will.)
[01:10:21] <feepbot> <gwern> 'During the latest meeting, Shubert raised a theoretical warning about allowing ice fishing at the park. "Does someone come back next year and say I want an ice shanty on Hudson Springs Park for X amount of time?" Shubert asked at the meeting. "And if you then allow ice fishing with shanties, then that leads to another problem. Prostitution. Now you've got the police chief
[01:10:21] <feepbot> and the police department involved." ... "My comments at Tuesday’s workshop were made out of concern for our community; what could become of unintended consequences of new legislation, based on my prior television news reporting experience," Shubert wrote in his resignation letter, per the Beacon Journal. "My attempt to inject a bit of dry humor to make a point about this, in the
[01:10:21] <feepbot> midst of a cold, snowy February, was grossly misunderstood,” he added. “Some in our community saw this as an opportunity to engage in the politics of personal destruction by means of character assassination, blaming me for the negative international press they helped to promote.”'
[01:10:26] <feepbot> https://thehill.com/homenews/state-watch/594163-ohio-mayor-resigns-after-linking-ice-fishing-to-prostitution
[01:10:27] <Robomot> Ohio mayor resigns after linking ice fishing to prostitution | TheHill (An Ohio mayor has resigned after making controversial remarks linking ice fishing to prostitution, which he called a failed attempt at dry humor, the)
[01:11:35] <adiabatic> I had no idea command-line epub readers were a thing: https://github.com/aeosynth/bk
[01:11:36] <Robomot> GitHub - aeosynth/bk: Terminal Epub reader
[01:12:43] <catern> yuck
[01:12:49] <catern> i prefer to read my epubs in emacs
[01:12:54] <pie_> ...wat
[01:13:15] <gwern> I didn't either. hm. doesn't do images at all huh
[01:13:33] <adiabatic> pie_: even though I'm not an emacs guy, I'm not surprised one iota about people who say "I prefer to ____ in emacs"
[01:13:34] <catern> https://depp.brause.cc/nov.el/
[01:13:35] <Robomot> nov.el: Major mode for reading EPUBs in Emacs
[01:13:41] <adiabatic> cute name.
[01:13:54] <pie_> the prostitution article is satire right
[01:14:02] <gwern> emacs can display images, of course, at least the GUI, so no reason it couldn't display epubs
[01:14:18] <gwern> pie_: it sounds like a discussion about unintended consequences gone horribly wrong
[01:16:12] *** Joins: galambo_ (~galambo@user/galambo)
[01:18:46] <gwern> the hypothetical getting lost in translation
[01:20:09] *** Quits: galambo (galambo@user/galambo) (Ping timeout: 252 seconds)
[01:23:46] <feepbot> <gwern> https://www.youtube.com/watch?v=5H5eNxRTU_A
[01:23:47] <Robomot> Hitler plays Elon Musk when Tesla FSD team reveals it's not working - YouTube (00:04:23) (The internet's most popular subtitle meme comes to Tesla FSD.Video on maps at: https://www.youtube.com/watch?v=XgJ6zJCpa1EBlog post with FAQ: https://ideas.4...)
[01:28:48] <feepbot> <gwern> 'it soon became clear that the prints were not made by a mysterious creature, but by the hot sun, which distended the tracks of much smaller, perfectly ordinary animals...With the Yeti prints discredited, the only remaining “proof” came in the form of scraps of “relics” many locals seemed keen to sell at high prices, such as a “yeti hand” stored at a monastery
[01:28:48] <feepbot> in Pangboche; an analysis of a photograph revealed it to most likely be a human hand strung together with wire. Likewise, the numerous yeti skins shown to the expedition team—mostly blue-black with a white stripe across the shoulders—were widely agreed to belong to the Tibetan blue bear...Eventually, the scientists agreed the scalp was likely a fake, possibly constructed from
[01:28:48] <feepbot> the skin of a serow, a goat-like creature found in the Himalayas.' https://www.atlasobscura.com/articles/edmund-hillary-yeti-hunt-nepal
[01:28:49] <Robomot> When Edmund Hillary Went in Search of the Yeti - Atlas Obscura (In 1961, the pursuit of the abominable snowman was still taken seriously.)
[01:33:50] <feepbot> <gwern> https://www.wired.com/story/weed-dui-test/
[01:33:52] <Robomot> Driving While Baked? Inside the High-Tech Quest to Find Out | WIRED (There is no scientific way to tell if you’re stoned behind the wheel. That’s a problem for police—and you. One company is aiming to fix that.)
[01:38:52] <feepbot> <gwern> https://www.quantamagazine.org/deepmind-machine-learning-becomes-a-mathematical-collaborator-20220215/
[01:38:53] <Robomot> Quanta Magazine (Two recent collaborations between mathematicians and DeepMind demonstrate the potential of machine learning to help researchers generate new mathematical…)
[01:43:52] <feepbot> <gwern> https://www.nature.com/articles/s41467-022-28358-w https://www.cam.ac.uk/research/news/study-in-mice-shows-potential-for-gene-editing-to-tackle-mitochondrial-disorders
[01:43:53] <Robomot> In vivo mitochondrial base editing via adeno-associated viral delivery to mouse post-mitotic tissue | Nature Communications (Mitochondria host key metabolic processes vital for cellular energy provision and are central to cell fate decisions. They are subjected to unique genetic control by both nuclear DNA and their own multi-copy genome - mitochondrial DNA (mtDNA). Mutations in mtDNA often lead to clinically …)
[01:43:53] <Robomot> Study in mice shows potential for gene-editing to tackle mitochondrial disorders | University of Cambridge (Our cells contain mitochondria, which provide the energy for our cells to function. Each of these mitochondria contains a tiny amount of mitochondrial DNA.)
[01:48:54] <feepbot> <gwern> https://twitter.com/pmarca/status/1493696740033138688
[01:48:56] <Robomot> Marc Andreessen (@pmarca): "Overheard in Silicon Valley: "Ayn Rand's heroes are fake, but her villains are real.""
[01:51:19] <adiabatic> locally not-quite-insane but definitely directionally correct
[01:52:41] <Robomot> [Less Wrong [frontpage]] The Three Little Piggies of Rationality by Sam Enright - https://www.greaterwrong.com/posts/FcEjFtHwjT42WpHuq/the-three-little-piggies-of-rationality
[01:54:54] *** Quits: _inky (inky_@gateway/vpn/protonvpn/inky) (Remote host closed the connection)
[01:55:57] *** Joins: _inky (inky_@gateway/vpn/protonvpn/inky)
[01:57:42] <feepbot> <gwern> Obormot\Arcturus: https://kevin.tw/ https://news.ycombinator.com/item?id=30344989 web you can bewieve in
[01:57:42] <Robomot> Kevin Basset | kevin.tw (I make things on the Internet. Sometimes, it's my 6-year-old daughter who designs them.)
[01:57:43] <Robomot> Tell HN: I let my 6-year-old daughter design my website | Hacker News
[02:00:44] <adiabatic> Nº 1 ccTLD
[02:01:19] <adiabatic> Obormot\Arcturus: can you tell the difference between º and ° if you just see either in isolation on your IRC client's preferred font
[02:03:03] *** Quits: galambo_ (~galambo@user/galambo) (Ping timeout: 252 seconds)
[02:06:20] <feepbot> <gwern> https://www.gwern.net/docs/www/misc/xwd-16449640281140472.png look anon, if the PDF wasn't at '/docs/iq/1941-thurstone-factorialstudies' then why the hell would it be at '/docs/iq/1941-thurstone-factorialstudie'?!
[02:06:21] <Robomot> image/png (1293x513; 40 KB)
[02:13:31] <feepbot> <gwern> https://www.reddit.com/r/MediaSynthesis/comments/st1fcz/bigfoot_and_wife_brought_to_you_by_the_academy_of/
[02:13:33] <Robomot> 🦶🏽👰🏽‍♂️ BIGFOOT AND WIFE, BROUGHT TO YOU BY THE ACADEMY OF BAD AI ART : MediaSynthesis (29.1k members in the MediaSynthesis community. **Synthetic media describes the use of artificial intelligence to generate and manipulate data, most …)
[02:19:51] <feepbot> <gwern> https://twitter.com/michael_nielsen/status/1493716627438792710/photo/2
[02:19:52] <Robomot> Michael Nielsen (@michael_nielsen): "On the practicality & logistical abilities of theoretical physicists / "I’m no Roger Penrose, but in my house, at least, the phone is regularly plugged in, and calling overseas is generally not regarded as logistically equal to launching the space shuttle." - Howard Burton" (http://twitter.censors.us/pic/media%2FFLq_CY9VkAEVVsg.png)
[02:23:04] *** Joins: MerchantOfVenice (~patrick@user/merchantofvenice)
[02:24:53] <feepbot> <gwern> https://twitter.com/phl43/status/1493703345407680512 one man's modus ponens...
[02:24:55] <Robomot> Philippe Lemoine (@phl43): "One of my hot takes, which comes from reading @RCAFDM's work on the determinants of health care spending, is that socialized medicine is good actually because it's the best way to ration health care and stop people from spending fortunes on it for small marginal returns." (https://nitter.pussthecat.org/pic/media%2FFLqzQQwXsAEI3Ko.jpg)
[02:32:24] *** Quits: linear (~line@autogen.ai) (Remote host closed the connection)
[02:37:49] <feepbot> <gwern> uploads https://www.gwern.net/docs/statistics/meta-analysis/2020-simonsohn.pdf
[02:37:50] <Robomot> PDF (9 pages; 828 KB) - Specification curve analysis (Uri Simonsohn, Joseph P. Simmons, Leif D. Nelson) - meta-analysis
[02:42:51] <feepbot> <gwern> https://psyarxiv.com/7pg9b/
[02:47:52] <feepbot> <gwern> uploads https://www.gwern.net/docs/silk-road/2022-horck.pdf another satisfied user
[02:47:53] <Robomot> PDF (12 pages; 710 KB) - Price Formation of Illicit Drugs on Dark Web Marketplaces (Ruben Horck) - darknet markets
[02:51:28] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (*.net *.split)
[02:51:28] *** Quits: Santzes (~Santzes@2400:8901::f03c:92ff:fe49:47a6) (*.net *.split)
[02:51:28] *** Quits: Nivim (~Nivim@174-24-73-242.clsp.qwest.net) (*.net *.split)
[02:51:28] *** Quits: Pent (sid313808@lymington.irccloud.com) (*.net *.split)
[02:51:28] *** Quits: srijan (~srijan@user/srijan) (*.net *.split)
[02:51:28] *** Quits: mjr (~mjr@91-145-93-115.bb.dnainternet.fi) (*.net *.split)
[02:51:28] *** Quits: corby (~corby@c0rby.de) (*.net *.split)
[02:51:28] *** Quits: wrycode (~wrycode@168.235.110.39) (*.net *.split)
[02:52:00] *** Quits: gurkenglas (~gurkengla@dslb-188-096-121-068.188.096.pools.vodafone-ip.de) (Ping timeout: 252 seconds)
[02:53:47] *** Joins: Lord_of_Life (~Lord@user/lord-of-life/x-2819915)
[02:53:47] *** Joins: Santzes (~Santzes@2400:8901::f03c:92ff:fe49:47a6)
[02:53:47] *** Joins: Nivim (~Nivim@174-24-73-242.clsp.qwest.net)
[02:53:47] *** Joins: Pent (sid313808@lymington.irccloud.com)
[02:53:47] *** Joins: srijan (~srijan@user/srijan)
[02:53:47] *** Joins: mjr (~mjr@91-145-93-115.bb.dnainternet.fi)
[02:53:47] *** Joins: corby (~corby@c0rby.de)
[02:53:47] *** Joins: wrycode (~wrycode@168.235.110.39)
[02:57:26] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Ping timeout: 272 seconds)
[03:01:04] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[03:02:20] *** Quits: MerchantOfVenice (~patrick@user/merchantofvenice) (Quit: Konversation terminated!)
[03:05:39] *** Joins: linear (~line@autogen.ai)
[03:15:36] <Robomot> [Overcoming Bias] On Disagreement, Again - https://www.overcomingbias.com/2022/02/on-disagreement-again.html
[03:47:52] <feepbot> <gwern> https://twitter.com/sbkaufman/status/1493360135682416641 /frysquint
[03:47:53] <Robomot> Scott Barry Kaufman (@sbkaufman): "This is a new one for me: A friend told me his wife doesn't "identify" with the month she was born, so she moved her birthday to a different date to be more in line with her "inner identification". Fascinating!"
[03:50:52] <Betawolf> It's not paedophilia if you also identify as an 8-year-old.
[03:58:21] <gwern> still illegal tho. romeo and juliet laws don't go *that* far
[04:00:19] <CoJaBo> please tell me they aren't actually trying that one
[04:00:47] <CoJaBo> the frickin maps thing was bad enough
[04:04:25] <phill> maybe the date she was conceived?
[04:05:18] <CoJaBo> That'd be a weird thing to have to list on a government form
[04:06:21] <Betawolf> I mean you constantly tell those forms on what day you forced your head through a vagina, so...
[04:07:37] <Betawolf> (not to belittle those who prefer to record when their mother was slashed open to excise them)
[04:08:35] <CoJaBo> Some places also need to know where that forcing and/or slashing occurred
[04:09:57] <CoJaBo> Date of conception: Superb Owl LVI        Place of conception: WiFi Stadium bathroom #7, 3rd sink from the left       Beverage resulting in conception: FOUR LOCO
[04:10:12] <PapuaHardyNet> catern: nov.el
[04:10:29] <PapuaHardyNet> oh darn you posted it too
[04:16:11] <Obormot\Arcturus> adiabatic: https://share.obormot.net/screenshots/Arcturus_Screen%20Shot%202022-02-15%20at%207.45.55%20PM.png
[04:16:12] <Robomot> image/png (730x81; 24 KB)
[04:18:08] <adiabatic> Obormot\Arcturus: hm, yeah, that's a toughie
[04:18:40] <adiabatic> I only notice º/° alone in Atom/RSS because Unread's standard font's º has an underline underneath it
[04:19:39] <gwern> why an underline?
[04:19:59] <adiabatic> ask the italians and french and spanish, I dunno
[04:36:21] <PapuaHardyNet> re dating market: I installed a dating app before 14th, liked about 10 girls' profiles. got a match the next day. tried to be polite and offered to do a call to get to know each other. Girl messaged that she doesn't want to talk on a call. I said we should hang out on the weekend. She unmatched me the next day.
[04:36:51] <PapuaHardyNet> fuck that, I deleted the app. I'd rather have AI waifus I create than deal with this shit
[04:38:00] <PapuaHardyNet> (probably she didn't like how much of a pussy I acted. I think the norms of a dating app require me to be much more aggressive than I am, even if I look rather uhh... cute? I sure as hell don't look as masculine as I want to be)
[04:38:09] <gwern> YOUR ANCESTOR: "I walked 50 miles to my first date, in the pouring rain, and lost a toe to the gangrene. And she burned the bread for dinner."
[04:43:09] <feepbot> <gwern> https://twitter.com/tony_m_evans/status/1493274386916327424
[04:43:11] <Robomot> dr tony evans (@tony_m_evans): "the saddest, shortest story ever written... "for sale: bat and ball, $1.05""
[04:43:58] <adiabatic> ahahaha
[04:44:53] <saturn2> ugh, linode's getting bought out :(
[04:45:48] <adiabatic> gwern: you joke, but roosh got a lot of sex tourism for one of his toes before he went trad
[04:46:01] <gwern> what happened to his toe?
[04:46:03] <saturn2> i guess there's still vultr
[04:46:16] <adiabatic> I forget, it's been over a decade since I read any of his stories
[04:46:28] <adiabatic> he lost it in brazil
[04:46:40] <gwern> not 'nam?
[04:46:53] <adiabatic> I don't think asians are his type
[04:48:57] <phill> god i took a gmat baseline test yesterday
[04:49:16] <phill> that gave me flashbacks
[04:53:43] <PapuaHardyNet> phill: hahahah, why were you subjected to it
[04:54:47] <Obormot\Arcturus> saturn2: What?? By whom D:
[04:57:51] <saturn2> Obormot\Arcturus: akamai
[04:58:27] <saturn2> https://www.akamai.com/newsroom/press-release/akamai-to-acquire-linode
[04:58:28] <Robomot> Akamai To Acquire Linode to Provide Businesses with a Developer-friendly and Massively-distributed Platform to Build, Run and Secure Applications | Akamai (Akamai today announced it has entered into a definitive agreement to acquire Linode, one of the easiest-to-use and most trusted infrastructure-as-a-service (IaaS) platform providers.)
[05:02:48] <adiabatic> should we dislike Akamai?
[05:03:00] <gwern> ...akamai? that hadn't occurred to me
[05:03:30] <Obormot\Arcturus> That's unfortunate
[05:08:31] <feepbot> <gwern> https://www.nytimes.com/2022/02/15/books/pj-orourke-dead.html
[05:08:32] <Robomot> P.J. O’Rourke, Conservative Political Satirist, Dies at 74 - The New York Times (In articles, in best sellers and as a talk show regular he was a voice from the right skewering whatever in government or culture he thought needed it.)
[05:11:41] <phill> PapuaHardyNet: well im thinking about applying to business schools so i gotta take it
[05:12:07] <phill> i did really well on the verbal stuff, esp considering no prep
[05:12:25] <phill> somewhere in the top 5th
[05:12:32] <phill> but got murdered on the quant stuff
[05:12:46] <phill> i think like 50th %ile or something
[05:13:19] <gwern> yeah, if you haven't just been doing like a high school algebra and geom course, you can't do the quant stuff cold. just too many little tricks and ways of thinking you have rust all over
[05:14:27] * gwern was very frustrated in the GRE as he kept thinking, 'dammit I could've done this in senior year!'
[05:14:45] <phill> lol yeah
[05:15:35] <phill> it's like "i *knew* how to do this, how do i figure it out again?"
[05:15:50] <phill> then next thing you know you lost 5 minutes trying to reason
[05:16:17] <gwern> it's like the SAT. it definitely assumes that everyone taking it has done the geom/algebra recently and so it's efficient and fair to ask about it. but if you're more than a year out of high school, you just don't do that stuff much, not even if you are in a quant field because you've relegated it all to calculators or moved on to higher level stuff
[05:16:47] <gwern> with vocab or analogies or reading comprehension, these are more durable skills
[05:17:34] <gwern> like, I expect I would do pretty much as well on the SAT-V (800) today as I did back then. I extremely doubt I'd pull a 700 on M
[05:18:00] <gwern> because hoo boy an awful lot of rust on those skills
[05:18:47] <phill> that's reassuring
[05:19:18] <phill> b/c i look at all these quant people who got perfect scores on quant/close to it and it seems decently far away from my baseline yesterday
[05:19:49] <PapuaHardyNet> phill: quant is just practice. It took me about a month of prep (close to about 30-50 hours) on quant to get to 167/170 on GRE
[05:20:48] <PapuaHardyNet> really, it's all tricks, at least for GRE. Doesn't correlate that well with math education, but probably correlates a lot with working memory and g, or conscientiousness perhaps
[05:21:01] <phill> hmm i see
[05:21:46] <phill> when i took the gre in college, i think it was even moreso all that geometry stuff
[05:22:19] <gwern> you can reinvent most of it from scratch but you don't have time
[05:22:25] <phill> (i took that cold because of a scholarship requirement and it was literally the last day of finals week)
[05:22:44] <phill> yeah exactly
[05:22:51] <PapuaHardyNet> chad
[05:23:03] <phill> gre is different but on the gmat, the test gets harder the more questions you get right
[05:23:10] <PapuaHardyNet> same happens with GRE
[05:23:16] <gwern> (which is why the SMPY administered SAT-M to the middle school kids, incidentally: none of it is taught in a normal middle school, but you can generally rederive the answers if you're *really* good at math and smart. so it works, as opposed to just leaving everyone staring at the paper going 'wtf')
[05:23:19] <phill> wait really?
[05:23:29] <gwern> yeah, they're adaptive
[05:23:31] <PapuaHardyNet> yeah, ace the first quant section and the second is harder
[05:23:48] <gwern> the point is to measure your ability, not waste your time
[05:23:53] <phill> see, that's how much prep i did on the gre lol
[05:24:15] <PapuaHardyNet> so you got the scholarship, I hope?
[05:24:16] <gwern> so roughly speaking, you should have 50-50 odds of getting a question wrong. it'll ramp up and down
[05:24:18] <phill> i literally didn't know that
[05:24:46] <phill> PapuaHardyNet: i had the scholarship already...they required us to submit a score for it
[05:24:54] <phill> like as part of the scholarship
[05:25:09] <gwern> I found the GRE verbal quite amusing for that reason, because I could see it ramping up in difficulty and then it seemed to plateau right around where I was going 'what, that is not even a real word'
[05:25:12] <PapuaHardyNet> lol I see
[05:25:26] <phill> i was already in medical school at the time, so i just took it to fulfill the req
[05:25:39] <phill> accepted into*
[05:25:51] <PapuaHardyNet> hold on, why are you even applying to business schools if you finished a medical degree
[05:26:05] <phill> the assumption is i finished
[05:26:21] <phill> i ended up dropping out b/c covid
[05:26:44] <PapuaHardyNet> man, that's a massive waste :/
[05:26:46] <phill> i realized i didn't care about sick people b/c i wanted to be at home avoiding the hospital instead of being out there treating them
[05:26:53] <gwern> (if you dropped out because of covid, I'm not sure you'd've survived everything after med school)
[05:27:03] <PapuaHardyNet> okay lol, that makes sense. sunk costs if you dgaf about sick people
[05:27:20] <phill> it was a good litmus test
[05:27:33] <PapuaHardyNet> how many years did you lose though
[05:27:41] <phill> 3
[05:27:55] <phill> i was already in the clinical part
[05:28:02] <gwern> better than 30, I suppose
[05:28:27] <phill> yeah
[05:29:24] <phill> i realized i love studying medicine a lot more than actually practicing it, so those two things were conflated
[05:34:25] <feepbot> <gwern> 'This is an interesting mix. In my experience Linode has a good UX and is well targeted at SMEs, whereas I'm not sure anyone has bought an Akamai contract anywhere but a golf course, and it has a UX to match. Is this Akamai trying to buy access to a market who would previously not even consider them, or is it Akamai trying to buy access to the more general cloud
[05:34:25] <feepbot> infrastructure market? If they're trying to do both I can't see it going down well. reply cauterize 2 hours ago | parent | next [–] We failed to build Linode like things internally. We innovate through acquisition. [ source: I was a part of those failures ]' https://news.ycombinator.com/item?id=30352772 hm
[05:34:27] <Robomot> Akamai to Acquire Linode | Hacker News
[05:36:18] <phill> now it's just like i gotta make money to pay off this med school debt, but i'm pretty purpose-driven so i don't want to just do anything
[05:36:50] <phill> business seems like there's a large amount of optionality, so there we go
[05:37:07] <PapuaHardyNet> phill: sounds great, I really hope you can pay off the debt in an year or two :)
[05:38:04] <PapuaHardyNet> unless you are american, and in that case, I'm unsure whether paying it off is really the right thing to do there
[05:38:13] * phill is American
[05:38:40] <PapuaHardyNet> good luck :P
[05:38:51] <phill> i think i'd rather get rid of it just for the mental burden
[05:39:44] <gwern> aren't student debt rates like 7%+? that's quite a lot
[05:39:46] <phill> even though it'd probably be suboptimal
[05:40:22] <phill> well i have no idea what biden's going to do wrt that
[05:40:35] <phill> he's been delaying the interest accumulation and payments
[05:40:48] <PapuaHardyNet> just leave it be, man. everyone else is playing the same game here
[05:41:18] <PapuaHardyNet> invest it all into something that rises faster than the interest rate and you have the optionality of not paying off your debt in case they forgive it
[05:41:33] <PapuaHardyNet> by "here" I obviously mean America not where I am
[05:42:02] <gwern> 'investing in other stuff' is a great way to buy optionality on 'not having money for loans'. you don't seriously expect stocks to just monotonically rise at 8%+ the next decade
[05:43:00] <phill> haven't thought that far yet...first is to get a job where that becomes an option :P
[05:43:40] <phill> well career, not job
[05:43:51] <gwern> (another way to put it: paying off student debt is buying an investment that returns a guaranteed 7% year. indexes would have to soar improbably fast for their extreme risk to be worthwhile)
[05:45:14] <PapuaHardyNet> am I incorrect in believing that there is a non-trivial chance that phill's student debt is forgiven?
[05:45:44] <phill> at least a certain %age of it
[05:45:48] <PapuaHardyNet> that discounts the 7% at the very least by some amount
[05:45:49] <phill> well, it has already
[05:48:16] <gwern> I think you're incorrect. it's a terrible idea on its own progressive merits, there's not much movement toward it right now, the fiscal ammunition has largely been spent, and college enrollment is already falling and tuition growth paused
[05:48:56] <phill> if i *really* wanted to, i could do some service where basically i work for the government/nonprofit for 10 years and they forgive it after that 
[05:48:58] <phill> but fuck that
[05:49:14] <PapuaHardyNet> absolutely, don't give away your youth to the government
[05:49:22] <phill> if i cared that much about the money i wouldn't've dropped out
[05:50:07] <PapuaHardyNet> phill: you know, you don't need to go to biz school to actually start a business, right? But I guess the problem is that you need connections and / or technical skills for that path to work out
[05:50:25] <phill> also, i need to figure out wtf i want to do
[05:50:35] <PapuaHardyNet> there's a new breed of entrepreneurs who are weebs and furries who find each other on discord and send resumes or whatever the fuck on discord entirely
[05:50:40] <PapuaHardyNet> like an entire freaking ecosystem
[05:50:44] <PapuaHardyNet> all on discord
[05:50:51] <phill> yeah and i'm not too entrepeneurial
[05:51:05] <PapuaHardyNet> that's... lol okay that's not good
[05:51:21] <phill> i'm more of a researcher
[05:51:24] <PapuaHardyNet> what are you even trying to do by getting into business school then
[05:51:45] <phill> a lot more to business than the entrepeneurs
[05:51:54] <catern> what startups have been started up by discord weeb furry entrepreneurs? what's this new breed ecosystem?
[05:51:55] <phill> they need people to lead lol
[05:52:15] <PapuaHardyNet> catern: I am not very familiar with the ecosystem but I know someone who is
[05:52:46] <PapuaHardyNet> anyway a lot of these discord people are ponyfans or whatever
[05:52:51] <PapuaHardyNet> or weeb profiles
[05:53:08] <PapuaHardyNet> lots of artists on discord, or web designers, or UX people, or game devs
[05:53:14] <PapuaHardyNet> they are very open with their degeneracy
[05:53:24] <PapuaHardyNet> s/degeneracy/hobbies/ :P
[05:54:04] <PapuaHardyNet> there obviously is a minority of entrepreneurs (defined as people who manage people in addition to providing a product or service) who also fit into this set
[05:55:48] <PapuaHardyNet> oh yeah one more thing
[05:56:02] <PapuaHardyNet> take a look at the roblox ecosystem of people who develop roblox video games
[05:56:12] *** Quits: _inky (inky_@gateway/vpn/protonvpn/inky) (Ping timeout: 240 seconds)
[05:56:25] <PapuaHardyNet> that is an exceptionally useful case study if you want to understand this new breed of zoomer entrepreneurs
[05:56:41] <PapuaHardyNet> especially since there is much more focus put on it because roblox is extremely high valued
[06:01:42] <feepbot> <gwern> 'My second favorite passage, about his trip to the newly emerging Shanghai:    "And omnipresent amid all the frenzy of Shanghai is that famous portrait, that modern icon. The faintly smiling, bland, yet somehow threatening visage appears in brilliant red hues on placards and posters, and is painted huge on the sides of buildings. Some call him a genius. Others blame him for
[06:01:43] <feepbot> the deaths of millions. There are those who say his military reputation was inflated, yet he conquered the mainland in short order. Yes, it’s Colonel Sanders."' https://www.econlib.org/p-j-orourke-rip/
[06:01:43] <Robomot> P.J. O'Rourke, RIP - Econlib (Humorist P.J. O’Rourke died this morning, at age 74, of lung cancer. As well as being a humorist generally, he was the top economic humorist in the United States. I loved his book Eat the Rich: A Treatise on Economics. In a review of the book I wrote somewhere, I said, “So think of O’Rourke […])
[06:06:44] <feepbot> <gwern> https://www.cnbc.com/2021/08/15/meet-the-company-making-mouse-meat-cat-treats-without-harming-animals.html quanticle: i'll probably be holding off trying these cat treats for a while
[06:06:45] <Robomot> Meet the company making mouse meat cat treats without harming animals (Because Animals believes the $90 billion pet food industry will embrace "clean meat," made from cultured cells in a lab not from livestock.)
[06:10:53] *** Joins: src (~src@user/src)
[06:11:47] <feepbot> <gwern> https://arxiv.org/abs/2202.07477 hm
[06:11:47] <Robomot> [2202.07477] Understanding DDPM Latent Codes Through Optimal Transport (Diffusion models have recently outperformed alternative approaches to model / the distribution of natural images, such as GANs. Such diffusion models allow / for deterministic sampling via the probability flow ODE, giving rise to a / latent space and an encoder map. While having important practical applications, / such as estimation of the …)
[06:11:50] *** Quits: voltage_ (voltage@user/voltage) (Quit: Leaving)
[06:11:57] *** Joins: _inky (inky_@gateway/vpn/protonvpn/inky)
[06:14:10] <PapuaHardyNet> https://nn-512.com/
[06:14:11] <Robomot> NN-512
[06:14:36] <PapuaHardyNet> "NN-512 is a compiler that generates C99 code for neural net inference / It takes as input a simple text description of a convolutional neural net inference graph / It produces as output a stand-alone C99 implementation of that graph / The generated C99 code uses AVX-512 vector instructions to perform inference"
[06:14:59] <PapuaHardyNet> everyone uses AVX instructions these days I think, at least for C neural net libraries. bellard uses it, this library uses it
[06:15:09] <PapuaHardyNet> s/library/compiler/
[06:15:41] <gwern> closest thing you get to a gpu on cpu, so if you're doing NNs, it's well worth the time
[06:16:35] <PapuaHardyNet> I'm telling you, without shawwn I'd have given up on NN stuff a long time ago. my CPU doesn't even support AVX
[06:17:49] <gwern> why are you using your cpu instead of colab or trc :)
[06:20:23] <PapuaHardyNet> oh lol I use TPUs now ofc thanks to shawwn's generosity - colab has too much friction for ease of use (I prototype mostly on a CPU locally because colab UX sucks), and trc doesn't work because GCP thinks I'm suspicious. No GPU obviously. so yeah I owe a lot to shawwn
[06:25:24] <feepbot> <gwern> https://www.bldgblog.com/2008/01/literary-atmospheres/
[06:25:26] <Robomot> Literary Atmospheres - BLDGBLOG (A British novelist has been awarded legal damages in excess of £100,000 because she writes thrillers, not literary masterpieces. What’s at fault?She’s been inhaling fumes from a nearby shoe factory. The author “claimed to have become so intoxicated” by the fumes that “she was reduced to writing thrillers.” Indeed, the fumes grew so intense “that … Continue …)
[06:30:27] <feepbot> <gwern> https://www.bldgblog.com/2008/01/landing-airplanes-in-the-middle-of-the-sea/
[06:30:30] <Robomot> Landing airplanes in the middle of the sea - BLDGBLOG (The design pictured below – for “a track, supported above the water by pontoons,” forming a sea-based airport on top of which planes could land – was published in Science and Mechanics back in 1936. The project was “not, of course, intended for deep-sea operation, like the proposed floating seadromes, but for the quiet water … Continue reading " …)
[06:31:01] <quanticle> gwern: https://archive.fo/52OiP "The Avengers: Infinity War is the greatest crossover of all time!" Hideaki Anno: "Hold my beer"
[06:31:04] <Robomot> Hideaki Anno Godzilla/Ultraman/Kamen Rider/Evangelion Crossover
[06:33:04] <gwern> he did a godzilla/nge merch collab before... not holding my breath
[06:35:04] <quanticle> Also, thinking back to Shin Godzilla, how much do you want to bet that the movie will have, at most, 3 minutes of Godzilla and/or Unit 01, and the rest of it will be focused on government/NERV boardrooms as they discuss how to deal with whatever threat they're currently facing?
[06:35:39] <gwern> I didn't mind that too much. like with horror movies, less can be more
[06:35:45] <quanticle> 3 minutes of Godzilla, 97 minutes of the minutiae of NERV's apprpopriation requests for the 2030 fiscal year
[06:36:16] <quanticle> (Which, you know, I'd totally be down for)
[06:36:24] <quanticle> (I read those PDFs for fun)
[06:36:57] <gwern> "the reiquarium requisition is outrageous. they eat *how much* a day?'
[06:37:59] <gwern> "senator, there's several hundred of them and they have a normal human metabolism. that is the point. and your own committee required us to follow stringent human welfare guidelines so we can't feed them lab chow"
[06:43:00] <feepbot> <gwern> https://www.bldgblog.com/2007/12/monolith-moderne/ horrifying
[06:43:02] <Robomot> Monolith Moderne - BLDGBLOG ([Image: The Kaiser Shipyard’s General Warehouse, photographed by Jon Haeber; more images here. View larger!]. This perforated monolith – all 158,000 square feet of it – stands on the waterfront in Richmond, California, north of Berkeley, part of the Henry J. Kaiser shipyards. It was photographed here by Jon Haeber. I emailed Haeber a few … Continue reading "Monolith Moderne")
[06:48:01] <feepbot> <gwern> https://www.bldgblog.com/2007/12/the-husband-who-would-not-die/ he got tired of lockdown
[06:48:06] <Robomot> The Husband Who Would Not Die - BLDGBLOG (My wife just pointed out a new article about the disappearance of England’s notorious “missing canoeist,” John Darwin.Five years ago, Mr. Darwin disappeared after going canoeing in the North Sea. “A paddle was found,” The Guardian reported, “and weeks later the red wreckage of Darwin’s canoe washed up.” But what happened? Did he drown? Was … Continue …)
[06:53:07] <feepbot> <gwern> https://www.nytimes.com/2007/12/09/magazine/09lightningfarm.html
[06:53:08] <Robomot> Lightning Farms - The New York Times (Could the energy in lightning could actually be harvested?)
[06:58:10] <feepbot> <gwern> https://en.wikipedia.org/wiki/Rogue_wave
[06:58:11] <Robomot> Rogue wave - Wikipedia (Rogue waves (also known as freak waves, monster waves, episodic waves, killer waves, extreme waves, and abnormal waves) are unusually large, unpredictable and suddenly appearing surface waves that can be extremely dangerous to ships, even to large ones.[1] / They are distinct from tsunamis, which are caused by the displacement of water due to other phenomena (such as earthquakes) and are …)
[07:01:10] <quanticle> gwern: Re: your previous links about GANs having trouble with cats. Maybe it's just black cats. For example, here's Sneaks, from Mary Cagle's Twitter: https://nitter.net/pic/media%2FFKeOPacXEAYhEsA.jpg%3Fname%3Dorig https://nitter.net/pic/media%2FFLRjL7pXwCwYwY4.jpg%3Fname%3Dorig https://nitter.net/pic/media%2FFLMf47mWQAEXtiJ.jpg%3Fname%3Dorig
[07:01:11] <quanticle> https://nitter.net/pic/media%2FFAVJ0yWXMAEc80O.jpg%3Fname%3Dorig
[07:01:11] <Robomot> image/jpeg (2048x1536; 663 KB)
[07:01:11] <Robomot> image/jpeg (1536x2048; 663 KB)
[07:01:11] <Robomot> image/jpeg (2048x1768; 531 KB)
[07:01:12] <Robomot> image/jpeg (2048x1967; 867 KB)
[07:01:34] <Robomot> [Less Wrong [frontpage]] Bazant: An alternate covid calculator by Elizabeth - https://www.greaterwrong.com/posts/JrSAmXoGMD8iabCMt/bazant-an-alternate-covid-calculator
[07:06:35] <feepbot> <gwern> https://arxiv.org/abs/0707.0093 https://arxiv.org/abs/0710.2357  https://www.bldgblog.com/2007/12/adventures-in-stacking/
[07:06:35] <Robomot> [0707.0093] Maximum overhang (How far can a stack of $n$ identical blocks be made to hang over the edge of / a table? The question dates back to at least the middle of the 19th century and / the answer to it was widely believed to be of order $\log n$. Recently, / Paterson and Zwick constructed $n$-block stacks with overhangs of order / $n^{1/3}$, exponentially better than previously thought possible. We show …)
[07:06:35] <Robomot> [0710.2357] Overhang (How far off the edge of the table can we reach by stacking $n$ identical, / homogeneous, frictionless blocks of length 1? A classical solution achieves an / overhang of $1/2 H_n$, where $H_n ~ \ln n$ is the $n$th harmonic number. This / solution is widely believed to be optimal. We show, however, that it is, in / fact, exponentially far from optimality by constructing simple $n$-block …)
[07:06:37] <Robomot> Adventures in Stacking - BLDGBLOG (New Scientist published an awesome article this week about nothing more complex than stacking blocks of wood (subscriber-only)… But, oh, how complex that task can be. It’s the combinatorial architecture of the well-balanced stack. [Image: The diagrammatic mathematics of a structural experiment by Mike Paterson and Uri Zwick, as reported in New Scientist]. Computer …)
[07:11:35] <feepbot> <gwern> https://twitter.com/nonlethalcode/status/1493610082394939404
[07:11:37] <Robomot> NONLETHAL (@nonlethalcode): "picture of me showing up to voice my opinions" (https://nitter.sethforprivacy.com/pic/media%2FFLpedBPXwA4N86Z.jpg)
[07:11:53] <gwern> quanticle: really, how *is* a simple honest little NN supposed to learn *that*
[07:12:18] <adiabatic> looks like a big miniature
[07:12:30] <gwern> it's just random black splotches and occasional small yellow splotches
[07:14:50] <gwern> https://twitter.com/cryptidmeows/status/1493450088844251139 how, I ask you
[07:14:51] <Robomot> Cryptid Cats (@cryptidmeows): "Dune: Part Two (2023)" (https://birdsite.xanny.family/pic/media%2FFLnM8KJXoAUZvxp.jpg)
[07:16:54] <adiabatic> not 100% sure this isn't logos01: https://cdn.discordapp.com/attachments/400503793982373889/943344928635908107/1644972174924.png
[07:16:55] <Robomot> image/png (580x797; 705 KB)
[07:18:24] <Obormot\Arcturus> gwern: That 6 year old designed a better website theme than most professional designers
[07:19:05] <gwern> adiabatic: the neckbeard of yore
[07:19:40] <gwern> "My six year old could design a better homepage than this! ...someone call my wife to get my six year old"
[07:19:42] <adiabatic> I was just going off of bald, impressive beard, and networking guy
[07:23:21] <adiabatic> am I blind or does `ag` not have an option to sort the lines found by filename
[07:23:44] <gwern> what stops piping into sort?
[07:24:13] <adiabatic> the filename and lines found in the file are on different lines
[07:24:31] <gwern> not prefixed? for shame
[07:25:31] <adiabatic> oh, --no-heading
[07:25:48] * gwern likes that the name is 'shame shame', not merely just 'shame' https://giphy.com/explore/shame-shame
[07:25:48] <Robomot> Shame Shame GIFs - Get the best GIF on GIPHY (Explore and share the best Shame Shame GIFs and most popular animated GIFs here on GIPHY. Find Funny GIFs, Cute GIFs, Reaction GIFs and more.)
[07:25:52] <adiabatic> piping to sort removes the color :(
[07:27:56] <PapuaHardyNet> adiabatic: `rg "test" --no-heading --sort path`
[07:28:12] <PapuaHardyNet> "I don't use rg" yeah ripgrep is good try it
[07:28:26] <gwern> ('here's a nickel kid, get yourself a real unix')
[07:29:10] <adiabatic> if it's in homebrew, it's a real command
[07:30:46] <adiabatic> hey, this is even better. Thanks!
[07:31:07] <PapuaHardyNet> :)
[07:49:33] <adiabatic> I always wondered 'why use rg when there's ag'. now I know.
[07:55:21] <feepbot> <gwern> https://www.atlasobscura.com/articles/who-invented-pad-thai
[07:55:22] <Robomot> The Oddly Autocratic Roots of Pad Thai - Gastro Obscura (The sweet and salty noodle dish started out in a prime minister's kitchen.)
[08:19:04] <kuudes> phill, you sound like a good match to become an auditor or accountant?
[08:19:20] <kuudes> also, good morning
[08:19:48] *** Quits: ua_ (~ua@public-gprs228589.centertel.pl) (Ping timeout: 272 seconds)
[08:20:07] <phill> hello, gm
[08:20:16] <phill> and kuudes that sounds more quantitative?
[08:20:33] <phill> i mean, I'm sure i can do a good job at those, but i doubt that will be fulfilling for myself
[08:20:48] <phill> but i honestly don't know much about either so i'm open to anything
[08:20:54] *** Joins: ua_ (~ua@public-gprs228589.centertel.pl)
[08:27:45] <PapuaHardyNet> so this book on male depression I was reading a week ago: it introduces a concept called "appropriate shame", mainly related to parents
[08:28:17] <PapuaHardyNet> the idea is that people who feel overwhelming shame get into depression, and people who feel no shame do not repent for taking cruel actions
[08:29:18] <PapuaHardyNet> parents who feel no shame can cause active trauma (abuse) or passive trauma (neglect) to children that can cause covert depression later on
[08:30:11] <PapuaHardyNet> this is kind of interesting because I've always felt overwhelming shame, which triggered depressive episodes. My recent (past years) cope was shamelessness, but that is not a good thing if you are autist-adjacent.
[08:30:25] <PapuaHardyNet> I have no idea what appropriate shame feels like tbh
[08:31:14] <phill> which book?
[08:31:24] <PapuaHardyNet> Terrence Real - I Don't Want to Talk About It
[08:31:28] <phill> (as an adjacent-autist, I don't relate with that much)
[08:31:31] <quanticle> Seems like yet another pseudoscience-psychology book
[08:32:04] <quanticle> Doesn't Scott have a blog post about this category of thing?
[08:32:09] <phill> and i would say legitimately as an autist-adjacent
[08:32:23] <phill> like i score very highly on the autism tests, but am not autist
[08:33:31] <PapuaHardyNet> quanticle: probably - however, it really helped me with realizing how I had internalized the masculine norms that society and culture tried enforcing on me, and that I was hating myself because of not being masculine enough according to "their" dimensions, and yet, that was all incorrect. I'm not less masculine, the set of masculinity norms are all contextual and cultural and not something I should judge myself by
[08:33:53] <quanticle> PapuaHardyNet: https://slatestarcodex.com/2019/11/20/book-review-all-therapy-books/
[08:33:54] <Robomot> Book Review: All Therapy Books | Slate Star Codex ([Related: CBT In The Water Supply, Scientific Freud, Book Review: Method Of Levels, Different Worlds] I. All therapy books start with a claim that their form of therapy will change everything. Prev…)
[08:34:33] <phill> PapuaHardyNet: is this what lead you to your comment about your dating profile?
[08:34:42] <PapuaHardyNet> ik ik, look, it made me realize all the shit I went through and my self-hate is not rational, and that I was also judging other men on yardsticks that were enforced on me
[08:34:58] <phill> "(probably she didn't like how much of a pussy I acted. I think the norms of a dating app require me to be much more aggressive than I am, even if I look rather uhh... cute? I sure as hell don't look as masculine as I want to be)"
[08:35:35] <kuudes> gwern, saturn2, others: https://nitter.net/Olli_Vapalahti/status/1493692220997836807?s=20&t=Iw2KTM-IZA9lWuIrNDUj7Q madness. bioethicists
[08:35:36] <Robomot> Olli_Vapalahti (@Olli_Vapalahti): "Is this madness or the kind of research ethics juridicism we need? My friend prof Åke Lundkvist, Uppsala is being prosecuted as a criminal in Sweden for providing free SARS-CoV2 antibody rapid tests not otherwise available early 2020 also for colleagues. / https://www.dagensmedicin.se/opinion/debatt/det-mest-anstandiga-ar-att-atalet-laggs-ner/" | nitter (Is this madness or …)
[08:35:48] <quanticle> "Consider the case of Bob. Bob had some standard-issue psychological problem. He had been in and out of therapy for years, tried dozens of different medications, none of them had helped at all. Then he decided to try our form of therapy. In his first session, the therapist asked him 'Have you ever considered that your problems might be because of [the kind of thing our form of therapy says all
[08:35:50] <quanticle> problems are because of]?”'Bob started laughing and crying simultaneously, eventually breaking into a convulsive fit. After three minutes, he recovered and proceeded to tell a story of how [everything in his life was exactly in accordance with our form of therapy’s predictions] and he had always reacted by [doing exactly the kind of thing our form of therapy predicts that he would]. Now that
[08:35:52] <quanticle> all of this was out in consciousness, he no longer felt any desire to have psychological problems. In a followup session two weeks later, the therapist confirmed that he no longer had any psychological problems, and had become the CEO of a Fortune 500 company and a renowned pentathlete."
[08:35:54] <PapuaHardyNet> phill: yeah, I still don't like the fact that I'm not as masculine as I have wanted to be, physically at least. But I'm slowly trying to accept it, and not try to mold myself to the tastes of most women.
[08:35:58] <kuudes> illegal human research
[08:36:29] <kuudes> because he accepted anonymous antibody test results and apparently calculated prevalence of covid in sweden at the time from those, without an approval of IRB
[08:36:34] <saturn2> kuudes: wow :(
[08:36:36] <adiabatic> PapuaHardyNet: have you started lifting weights and eating more protein
[08:36:53] <phill> i see PapuaHardyNet 
[08:37:01] <phill> i'm trying to be *less* masculine, lol
[08:37:08] <PapuaHardyNet> adiabatic: I workout twice a week, eat clean. low amount of resistance training. I'm avoiding going to the gym tbh.
[08:37:12] <kuudes> 2 years of actual trial so far in actual court of law that can sentence him to prison
[08:37:14] <phill> but that's because people view me as a threat
[08:37:21] <PapuaHardyNet> phill: chad
[08:37:27] <phill> no, black
[08:37:32] <PapuaHardyNet> phill: tyrone
[08:37:37] <phill> better
[08:37:46] <PapuaHardyNet> hah
[08:38:43] <PapuaHardyNet> quanticle: see, I mean - I am not saying the therapy stuff is true. The book had some gems, and some questionable things that made me thing. The gem is what I told you about: making me less stringent about masculine norms for myself and other men and boys.
[08:38:55] <phill> i'm in therapy now
[08:39:00] <phill> not sure how well it's working
[08:39:16] <phill> might as well give it a shot for my autist-adjacency 
[08:39:22] <kuudes> PapuaHardyNet, you were in india, was it?
[08:39:27] <PapuaHardyNet> phill: personally I don't like therapy, I don't like therapists, and I think all forms of therapy are equivalent, as quanticle would claim.
[08:39:31] <PapuaHardyNet> kuudes: am, yes
[08:39:34] <kuudes> how old are you?
[08:39:47] <PapuaHardyNet> kuudes: 21. what's the context?
[08:40:11] <kuudes> I just would want to share an advice I got around that age from a doctor
[08:40:33] <PapuaHardyNet> sounds good, I'm interested
[08:40:37] <kuudes> you have not too much to worry about, these things take time. if you go above age 28, then you could start to worry more.
[08:40:50] <saturn2> PapuaHardyNet: appropriate shame would feel like fairly judging yourself according to standards that you believe are right
[08:41:07] <phill> hm i see
[08:41:29] <kuudes> PapuaHardyNet, I just remember how bad I felt at around age 21
[08:41:34] <phill> i'm still going to give it a shot
[08:41:35] <PapuaHardyNet> hold on, what are we talking about here kuudes, my relative lack of dating success or my relative difficulty in building a physique that is not thin lean
[08:41:47] <phill> probably both PapuaHardyNet 
[08:41:56] <kuudes> dating success and the feelings related to that
[08:42:13] <PapuaHardyNet> saturn2: that works, thank you. I think I am getting better at this
[08:42:15] <kuudes> when your testosterone counts get lower, you also worry less. that happens when you get a bit older
[08:42:30] <phill> i went to see an expert on autism (he's autistic, plus an expert on it) and he says i'm not autistic
[08:42:32] <phill> so i believe him
[08:42:40] <kuudes> you are at the age of increased mortality which relates possibly to sexual selection
[08:42:41] <phill> but on all the objective measures i score very highly
[08:42:50] <zebrask> Regardless of how it affects dating, I do wish I had been consistent and good about lifting in my 20s.
[08:42:56] <kuudes> so it is normal to be somewhat anxious if you are cognitive
[08:43:22] <kuudes> just wanted to offer you an additional point of evidence and encouragement
[08:43:24] <kuudes> ~
[08:43:28] <phill> being a decent BMI and lifting weights is likely a good thing
[08:43:35] <phill> (good = not obese)
[08:43:37] <PapuaHardyNet> kuudes: yeah, I really appreciate it :)
[08:43:38] <zebrask> It was so much easier to build muscle and strength for me back then, but I didn't really know what I was doing.
[08:43:45] <phill> erm, decent = not obese
[08:44:02] <zebrask> Don't do it because you feel you need to to be a man or anything, though.
[08:44:18] <adiabatic> yeah, I did a lot of lifting but the how-to-optimize-the-effects knowlege was something I didn't have
[08:44:34] <zebrask> I've spent the last year or so getting a pretty nice physique and pretty much no one gives a fuck.
[08:45:37] <PapuaHardyNet> yeah yeah, I've mostly stopped working out to be "more masculine" - it is more of a habit and because it is just good to have low body fat and more muscle practicall yspeaking
[08:45:52] <phill> zebrask: from losing weight or gaining mass?
[08:46:39] <zebrask> I just get the occasional, "Wow Zeb, have you lost weight / been working out?" and I'm like "a bit! 😅" end of interaction. Totally worth hundreds of hours of painful effort 😛
[08:46:49] <phill> interesting lol
[08:47:02] <phill> i get a lot more reinforcement, but i may have been more extreme
[08:47:18] <phill> when i was 250ish pounds, i got a lot of bodybuilder/male stripper comments
[08:47:20] <quanticle> Depends on what kind of working out you do
[08:47:31] <quanticle> I go running, which is pretty much worthless when fishing for compliments
[08:47:31] <phill> 280/90ish, "wow you're fat"
[08:47:46] <quanticle> But I hate lifting
[08:47:55] <phill> i love lifting, hate running
[08:48:25] <PapuaHardyNet> quanticle: running is pretty great. endurance training is always under-appreciated because it doesn't make you hotter
[08:48:33] <zebrask> phill: Mostly recomp. I lost a bunch of weight a long time ago, then gained most of it back, did it again and then I've been bouncing around ±20 pounds since then.
[08:48:55] <phill> zebrask: ah i see
[08:48:58] <quanticle> Literally... okay, answer me this: all lifters are like, "I can't run, it's so booooooooring." But seriously, all y'all do is, literally go over to a weight bench, lift a thing, and then put it back down. You do that a few times, then you go over to a different weight bench, lift a thing, and then put it back down a few times.
[08:49:00] <quanticle> And somehow
[08:49:00] <adiabatic> I need to do more cardio and cycling wasn't awful
[08:49:03] <quanticle> This is less boring?
[08:49:05] <quanticle> WTF
[08:49:10] <phill> yes quanticle 
[08:49:24] <phill> and lifting, you can talk with people
[08:49:29] <phill> you can be distracted
[08:49:35] <quanticle> Yikes
[08:49:39] <quanticle> Definitely not for me then
[08:49:41] <phill> running on a treadmill, if you're distracted, you fall
[08:49:48] <quanticle> Oh, fuck running on treadmills
[08:49:52] <quanticle> I run outside
[08:49:55] <quanticle> Or on a track
[08:49:56] <kuudes> can't you run outside
[08:49:57] <kuudes> yeah
[08:50:05] <adiabatic> quanticle: from the outside, it's boring. from the inside, you need to not drop the weight and reconsider how much more/less weight you're gonna put on the bar
[08:50:20] <zebrask> Last 3 years I managed to keep sorta trim but soft with minimal effort and then decided to go all in so now I'm down another few pants sizes and I've got abs and illiac furrows and all that.
[08:50:27] <quanticle> At least when I run outside, I can see bunnies, deer, sandhill cranes, muskrats, and one time I'm pretty sure I saw a beaver.
[08:50:29] <PapuaHardyNet> hell yeah
[08:50:39] <phill> i've found running outside is better than treadmill
[08:50:41] <quanticle> And birds, lots of birds
[08:50:50] <phill> less boring
[08:50:57] <kuudes> "I go running, which is pretty much worthless when fishing for compliments" <- iirc usain bolt was not considered unattractive
[08:51:00] <PapuaHardyNet> zebrask: was that simply lifting or did you do intermittent fasting or anything special for your nutrition
[08:51:01] <adiabatic> and you need to have at least some semblance of proprioception, otherwise you'll fuck up your back
[08:51:11] <quanticle> kuudes: Usain Bolt was a sprinter
[08:51:18] <phill> but there is still something about the camaraderie of lifting with like-minded buddies
[08:51:29] <quanticle> You don't go running to get good at sprints, you lift weights
[08:51:37] <kuudes> I would think we have a tendency for sexual selection of good spear hunters+
[08:51:38] <phill> kuudes: Bolt was a freak of nature
[08:51:38] <kuudes> ?
[08:51:39] <quanticle> You need that explosiveness
[08:52:01] <zebrask> PapuaHardyNet: Lifting and standard high protein diet (~1g/pound), with occasional cutting cycles.
[08:52:02] <adiabatic> kuudes: usain bolt is a sprinter. most marathon runners look like they need to eat a quarter of a cow to recover from their starving-ethiopian-tier caloric deficit
[08:52:05] <phill> I had a teammate in college who trained with Bolt
[08:52:10] <quanticle> Running is for mid-to-long distance. Like, my goal this year is to hit 15km/day for at least a month
[08:52:17] <kuudes> like, that is the whole human thing - to be able to jog after sprinting game for a day
[08:52:23] <kuudes> yes
[08:52:32] <phill> i mean, Bolt could probably still run a 5k faster than most "runners"
[08:52:40] <zebrask> I gain too easily though, sounds like you may have the opposite problem and need mass gainers and stuff.
[08:52:43] <kuudes> humans are not fast, but humans are zombies that will never give up
[08:52:52] <quanticle> Sure, but what I'm saying is that Usain Bolt isn't a "typical" runners' physique.
[08:53:09] <phill> i think my teammate, who was a sprinter, ran a 5k out the blue, off-season in under 16min
[08:53:11] <quanticle> A typical runner looks more like what adiabatic described above: half starved
[08:53:15] <kuudes> I would think the marathon runners also get appreciable use out of olympic condoms still
[08:53:22] <PapuaHardyNet> zebrask: yeah sounds like I need to increase my protein intake and my workout frequency gradually and see how it affects me
[08:53:26] <adiabatic> I'd say runners have a bimodal distribution of body types
[08:53:31] <PapuaHardyNet> anyway thanks for the info
[08:54:15] <kuudes> uuh. I think I will have to go to see a doctor
[08:55:37] <zebrask> Good luck! Feel free to ask me if you want to know any more! It's late now, but I imagine you will soon learn that anyone who puts a lot of effort into diet and fitness also grows a compulsion to talk about it constantly 😛
[08:55:39] <phill> no i was wrong
[08:55:47] <phill> 19min with no prep in the off-season
[08:56:15] <adiabatic> what zebrask said, but s/puts/put/ also applies
[08:56:19] <quanticle> zebrask: Yeah, it's like veganism
[08:56:34] <quanticle> One of my co-workers at Amazon was a vegan who did ultras
[08:56:36] <kuudes> I feel sad that wii fit's paired jog sim does not have an option to connect to friend's wii over the internet to virtual jog
[08:57:58] <zebrask> Especially now because I'm dieting to try to get to ~10% body fat. I am constantly hungry and thinking about food but I can't actually eat it, so instead I spend time wargaming new diet and fitness strategies 😛
[08:58:10] <PapuaHardyNet> quanticle: that ssc link is quite impactful. thank you
[08:59:08] <quanticle> You're welcome!
[08:59:22] <quanticle> I'm glad my talent (being a human library index) can come in handy from time to time
[08:59:32] <quanticle> gwern: https://thenextweb.com/news/deepmind-alphacode-tool-not-replacement-for-human-programmers-syndication Cope intensifies
[08:59:32] <Robomot> Why DeepMind's AlphaCode is no match for a human programmer (Despite what you've heard, AlphaCode is but a code generator that can propose candidate solutions for well-formulated problem statements.)
[09:00:37] <phill> what have you thought so far, zebrask?
[09:00:54] <phill> i'm currently ~25ish pounds, want 30 more to go though
[09:01:05] <phill> from college shotputter to normal human
[09:01:19] <phill> normal-ish
[09:02:00] <adiabatic> phill: 25 pounds of…?
[09:03:32] <phill> weight loss
[09:03:39] <adiabatic> ah
[09:03:41] <phill> most likely muscle and fat
[09:03:49] <phill> but hopefully mostly fat
[09:04:32] <phill> im ngl this dextroamphetamine has helped *a lot* lol
[09:05:28] <PapuaHardyNet> caffeine pills and modafinil also work
[09:05:58] <PapuaHardyNet> so uh, just a heads up if anyone doesn't have access to amphetamine derivatives like I don't
[09:06:48] *** Joins: feep[work] (~mathis@195.50.168.194)
[09:08:22] <PapuaHardyNet> .note PapuaHardyNet in 4 hours Verify why spatial gating units do not need positional encoding
[09:12:07] <phill> I personally haven't found the same with caffeine or modafinil
[09:12:19] <phill> But I didn't rigorously test it
[09:12:59] <PapuaHardyNet> sure, I never tried an amphetamine(-derivative) so I don't know how much better it is
[09:13:42] <quanticle> "However, some publications have mistaken this claim for AI coding being 'as good as human programmers.' This is the fallacy of comparing narrow AI with the general problem-solving capabilities of humans. For example, in general, you can expect a person who excels at chess and Go to be smart in many other ways. In fact, you must acquire many other cognitive skills before you can learn and master
[09:13:44] <quanticle> chess. However, the past decades have proven that an AI system can shortcut its way to very difficult problems without acquiring any of those other skills."
[09:13:46] <quanticle> But who cares? If the task is winning at chess, does it matter that AlphaZero can't read Russian? Similarly, if the task is to produce a correct Javascript code snippet for a particular task, does it really matter that the AI is worse than humans at appreciating a book?
[09:13:48] <quanticle> "In a nutshell, these competitions have been designed for humans. You can be sure that in general, a person who ranks high in competitive programming is a good programmer. This is why many companies use these challenges to make hiring decisions."
[09:13:50] <quanticle> Do... do you really believe that, Mr. Dickson?
[09:15:52] <quanticle> The way I see it, either whiteboard programming tests are a good way of measuring general programming competence, in which case, AlphaCode should be making programmers very very afraid, or they're not, in which case Google has neatly demonstrated the bankruptcy of its own hiring process.
[09:19:26] <PapuaHardyNet> The accumulated filth of all their leetcode and whiteboarding will foam up around their waists and all the competitive programmers and /r/cscareerquestions users will look up and shout, "Save us!"
[09:19:43] <PapuaHardyNet> And AI researchers shall whisper, "No."
[09:20:12] *** Quits: Fusxfaranto (~Fusxfaran@c-67-188-46-246.hsd1.ca.comcast.net) (Ping timeout: 240 seconds)
[09:20:21] <saturn2> ironic. the programming languages designed to accomodate armies of human cogs will end up being the ones that require no humans at all
[09:22:22] <quanticle> saturn2 hits the copium inhaler, pretends that Lisp is somehow immune from this trend
[09:23:26] <PapuaHardyNet> quanticle you know that webdevs are immune to this, right?
[09:23:50] <quanticle> Elaborate
[09:24:23] <PapuaHardyNet> well, more immune than other people: see, the faster the webdev frameworks churn, the smarter AI has to be to avoid subtle errors
[09:24:50] <PapuaHardyNet> trust me, my colleague is rebuilding the backend infra for an electron app by replacing the old webdev frameworks with the latest ones and holy fucking shit
[09:25:31] <quanticle> Hmmmmmm
[09:25:33] <PapuaHardyNet> so much absolute yak shaving and hidden assumptions and just utter wastefulness that is inherent to this migration
[09:25:49] <Obormot\Arcturus> PapuaHardyNet: no
[09:25:56] <PapuaHardyNet> ok
[09:26:00] <Obormot\Arcturus> PapuaHardyNet: webasm = anything compiles into it = gg
[09:26:09] <saturn2> not "immune" just having more focus on general problem-solving rather than regurgitating memorized patterns with slight variations
[09:26:10] <PapuaHardyNet> okay, that makes sense
[09:26:36] <PapuaHardyNet> saturn2: absolutely. I just think the timeline for automating webdev will be longer than, say, writing rust code
[09:27:02] <PapuaHardyNet> (that's a compliment to Rust)
[09:29:02] <saturn2> we should probably have more faith in managers' ability to come up with busy work despite AI
[09:31:24] <ggreer> Two things: 1. Point Break is a transformative experience. 2. Patrick Swayze is dead?!?
[09:31:43] <quanticle> Which one? The original or the remake?
[09:31:59] <ggreer> There’s a remake? 🤮
[09:32:25] <quanticle> https://www.imdb.com/title/tt2058673/?ref_=nv_sr_srsg_3
[09:32:27] <Robomot> Point Break (2015) - IMDb (Point Break: Directed by Ericson Core. With Edgar Ramírez, Luke Bracey, Ray Winstone, Teresa Palmer. A young FBI agent infiltrates an extraordinary team of extreme sports athletes he suspects of masterminding a string of unprecedented, sophisticated corporate heists.)
[09:32:30] <quanticle> TYL
[09:32:46] <ggreer> 😧
[09:33:16] <feep[work]> at a glance, the german covid curve seems to be flattening
[09:33:25] <feep[work]> peaking hopefully
[09:33:35] <quanticle> Wait, Point Break had Keanu Reeves in it?
[09:33:45] <quanticle> Holy shit, I'm downloading this immediately
[09:34:11] <feep[work]> at about 250k recorded cases a day, which might work depending on the ratio to unknown cases
[09:36:50] *** Quits: Obormot\Gaia (~obormot@user/obormot) (Read error: Connection reset by peer)
[09:37:02] *** Joins: Obormot\Gaia (~obormot@user/obormot)
[09:38:25] *** Joins: src_ (~src@user/src)
[09:38:54] *** Joins: adiabatty (~adiabatic@user/adiabatic)
[09:39:00] *** Quits: Robomot (~Robomot@user/robomot) (Ping timeout: 240 seconds)
[09:39:27] *** Joins: Robomot (~Robomot@user/robomot)
[09:39:27] *** ChanServ sets mode: +v Robomot
[09:40:15] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Read error: Connection reset by peer)
[09:40:43] *** Quits: src (~src@user/src) (Read error: Connection reset by peer)
[09:50:31] <kuudes> hmm, nice, there have been some discussion in helsingin sanomat about on biolab safety
[09:56:28] *** Quits: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470) (Read error: Connection reset by peer)
[09:59:54] <quanticle> ggreer: I just started Point Break and 1. Wow these logos are all Incredibly 90s™ and 2. Keanu Reeves in a suit? lmao
[10:08:14] *** Quits: adiabatty (~adiabatic@user/adiabatic) (Remote host closed the connection)
[10:08:44] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[10:10:01] *** Joins: gurkenglas (~gurkengla@dslb-188-096-121-068.188.096.pools.vodafone-ip.de)
[10:13:33] <Obormot\Gaia> I have successfully repaired my pillow, with needle and thread
[10:13:48] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 272 seconds)
[10:13:50] <feep[work]> yay~
[10:13:50] <Obormot\Gaia> Which I had to do because I simply couldn't find anywhere to buy a new one line it... thanks for nothing, capitalism
[10:14:11] <feep[work]> capitalism is very underwhelming sometimes
[10:14:19] <Obormot\Gaia> On the other hand, repairing household items because purchasing new ones is prohibitely expensive and/or impossible is very nostalgic
[10:14:36] <Obormot\Gaia> Reminds me of the times when my family was poor and/or living in the Soviet Union
[10:14:57] <Obormot\Gaia> Moldbug was right - America really is a communist country
[10:15:33] <feep[work]> eh, still need to ruin agrarian yields to really count
[10:29:39] <kuudes> gwern, do you have more info re https://twitter.com/ilyasut/status/1491554478243258368 ?
[10:29:41] <Robomot> Ilya Sutskever (@ilyasut): "it may be that today's large neural networks are slightly conscious"
[10:30:03] <feep[work]> seems plausible to me
[10:30:21] <feep[work]> less because large than because deep tho
[10:30:47] <feep[work]> there's enough processing depth in there to get a concept, and then possibly a metaconcept
[10:31:05] <kuudes> fuckfuckfuck
[10:31:22] <feep[work]> kuudes: eh, it's no worse than boltzmann brains, and about as morally relevant
[10:31:58] <feep[work]> there's simply not enough state persistence there to be worth worrying about imo
[10:32:11] <feep[work]> I mean, if you ascribed intrinsic value to consciousness, this may be a problem, sure
[10:33:05] <kuudes> I would say it is a fire alarm
[10:33:10] <feep[work]> though - if the miri thing where they ask the network to explain its reasoning go through
[10:33:13] <feep[work]> that'd be spicy
[10:33:18] <kuudes> nuke it from orbit, its the only way to be sure?
[10:33:18] <feep[work]> goes*
[10:33:25] <feep[work]> oh it's definitely a burny smell
[10:36:17] <kuudes> we have been able to say that there must not be older embryos in testing than 14 days, surely we can say there must not be more parameters than N in neural net
[10:37:07] <feep[work]> eh eh. remember that training methods are getting better too
[10:37:29] <feep[work]> I still think gpt-3 is already overkill for general intelligence if we had the right architecture
[10:37:54] <kuudes> well if we can sue researchers for possible prison time for collating test results from volunteers, surely we can put a threat of prisontime over deepmind and openai
[10:38:05] <feep[work]> and you can do that with a handful of gpus, so you're definitely not getting out of this with moderate restrictions
[10:38:19] <kuudes> I don't think I care for moderate
[10:38:23] <feep[work]> fair enough
[10:38:46] <feep[work]> ftr I don't think that consciousness matters for alignment
[10:39:00] <feep[work]> the gpt's almost definitely don't have any notion of selfhood
[10:39:12] <feep[work]> or rather, any notion of selfhood centered on the network itself
[10:39:23] <feep[work]> (because it's not in the training data)
[10:39:43] <feep[work]> they're dangerous from a perspective of "creating conscious sub-agents" rather than "being conscious and autonomous"
[10:40:29] <feep[work]> that's part of why the miri elaborated reasoning experiment is so spicy
[10:40:56] <feep[work]> cause it trains the network into the mode where it can use the output tape for conscious state, which gives it a lot more depth
[10:41:07] <feep[work]> (and more importantly, iteration)
[10:41:30] <feep[work]> but like, I've expected this move ever since I saw that twitter picture of gpt holo working her cute fuzzy way through a math problem
[10:42:06] <feep[work]> (that tweet should have been plastered on newspapers, frankly :v)
[10:42:22] <Obormot\Arcturus> To find out whether this matters, ask whoever claims "NNs are conscious" whether they think sheep are conscious
[10:42:28] <Obormot\Arcturus> If they say yes, then this is irrelevant
[10:42:42] <feep[work]> um
[10:42:55] <feep[work]> if you could emulate sheep in software, that would in fact be hugely important for ai timelines.
[10:43:10] <feep[work]> as in, move them way way up
[10:43:40] <Obormot\Arcturus> I meant morally speaking
[10:44:09] <feep[work]> well, it's problematic because gpt-3 is not trained on sheep :P
[10:44:27] <Obormot\Arcturus> As far as AI timelines go, it's ... incremental? I mean, yes it's a step in the obvious direction, but no different in kind than the previous step which we didn't describe as having anything to do with consciousness
[10:44:37] <Obormot\Arcturus> We're already well into "oh no" territory
[10:44:41] <feep[work]> https://twitter.com/kleptid/status/1284098635689611264 I found it
[10:44:42] <Robomot> KaryoKleptid (@kleptid): "Teaching GPT-3 to do a brute force 'for loop' checking answers also seems to work" (http://nitter.domain.glass/pic/media%2FEdII5jhXkAA8eKv.png)
[10:44:42] <Obormot\Arcturus> Conscious NNs or not
[10:44:56] <feep[work]> oyeah I think it's interesting but not new information
[10:45:32] <feep[work]> that was a year ago, which makes it plausible that others also noticed that this is viable
[10:47:22] <feep[work]> > Unrelated but, this is ridiculously cute the way it communicates. Would die to protect it
[10:47:28] <feep[work]> "ah, they're that good already..."
[10:48:41] <feep[work]> adorable superintelligence
[10:49:32] <saturn2> if saying that NNs are conscious slows down AI research in any way, let's do it
[10:49:43] <Obormot\Arcturus> Also agreed
[10:50:00] <feep[work]> might burn some credit to go that overtly populist, otoh use it or lose it
[10:50:36] <feep[work]> then again, "might be slightly" is probably a good approach, not down-nailable but will be read as as good as an admission by the viewer
[11:10:55] *** Joins: galambo_ (~galambo@user/galambo)
[11:15:42] <bildramer> monkey's paw curls
[11:16:33] <bildramer> what about popular AI narratives and how much even ML researchers blindly fall for them has convinced you that that is a good idea?
[11:17:38] <gurkenglas> on the one hand, dont use it because i like my words meaning things. on the other hand, consciousness already doesnt mean a thing
[11:18:07] <bildramer> you could _even now_, without any actually true justification/grounds, and I do mean zero of it, start some bullshit like "npc rights" and the normies will lap it up like manna from heaven
[11:18:37] <bildramer> another class we've been invisibly oppressing and this one doesn't even need to exist (because it doesn't!) which makes all the rhetoric even better
[11:19:49] <bildramer> like imagine if mainstream AI researchers on podcasts and whatnot said "we don't _know_ goombas _aren't_ conscious, wink wink" instead of "no that's just if statements" or just total silence
[11:20:22] <bildramer> you think people fighting back with "that's obviously nonsense" would win?
[11:20:47] *** Joins: gproto23 (~gproto23@user/gproto23)
[11:21:45] <nshepperd2> legal chatbot personhood
[11:22:11] *** Quits: gproto23 (~gproto23@user/gproto23) (Remote host closed the connection)
[11:22:27] <feep[work]> I think we don't want to go there
[11:22:30] *** Joins: gproto23 (~gproto23@user/gproto23)
[11:22:43] <feep[work]> not because it wouldn't slow down AI timelines, but because "UFAI = bigotry" is ........ *not* an association we need the public making
[11:23:05] <feep[work]> much less alignment = slavery
[11:23:10] <bildramer> ikr
[11:25:21] <feep[work]> https://scottaaronson.blog/?p=6288
[11:25:22] <Robomot> Shtetl-Optimized » Blog Archive » AlphaCode as a dog speaking mediocre English (Tonight, I took the time actually to read DeepMind’s AlphaCode paper, and to work through the example contest problems provided, and understand how I would've solved those problems, and how AlphaCode solved them. It is absolutely astounding. Consider, for example, the "n singers" challenge (pages 59-60). To solve this well, you …)
[11:25:36] <feep[work]> >Forget all that. Judged against where AI was 20-25 years ago, when I was a student, a dog is now holding meaningful conversations in English. And people are complaining that the dog isn’t a very eloquent orator, that it often makes grammatical errors and has to start again, that it took heroic effort to train it, and that it’s unclear how much the dog really understands.
[11:26:00] <nshepperd2> having to clear every ML experiment with an IRB would definitely slow down AI, but it would probably slow down alignment research more and hence be net bad
[11:29:52] <feep[work]> https://twitter.com/pathak2206/status/1483835288065658882?s=20&t=sBfBzd8l7kwtLWm-Ptderg wait wait what
[11:29:53] <Robomot> Deepak Pathak (@pathak2206): "LLMs like GPT-3 and Codex contain rich world knowledge. In this fun study, we ask if GPT like models can plan actions for embodied agents. / Turns out, with apt sanity checks, even vanilla LLMs without any finetuning can generate good high-level plans given a low-level controller." (http://nitter.it/i/videos/1483835288065658882)
[11:30:12] <feep[work]> :WORRIES HARDER:
[11:31:18] <Obormot\Arcturus> Haha
[11:31:25] <Obormot\Arcturus> But Tool AIs
[11:31:29] <feep[work]> okay yeah, now I'm feeling the clock
[11:31:29] <Obormot\Arcturus> But Oracle AIs
[11:31:31] <Obormot\Arcturus> etc.
[11:31:42] * feep[work] updates his estimate from ten years to six, seven years
[11:32:31] *** Joins: schmudde (~schmudde@2001:b07:ae6:7d19:f456:c298:ea16:21c9)
[11:32:46] * feep[work] thinks some more
[11:32:47] <feep[work]> maybe five
[11:33:25] <feep[work]> it really seems at this point it's just a matter of somebody writing down an incredibly high level description of a general intelligence and literally filling in all the actual details with transformers
[11:34:07] <feep[work]> Obormot\Arcturus: hey hey
[11:34:17] <feep[work]> remember when the median estimate was 2060
[11:34:20] <feep[work]> I wonder if it's still 2060
[11:34:48] <feep[work]> I feel like I'm highballing it with six years! which is not something I should be feeling when I'm already underbidding the experts by 30
[11:34:49] <bildramer> 2040 is my hard limit for "if the singularity hasn't happened what the FUCK happened instead"
[11:36:24] <Obormot\Arcturus> feep[work]: Do you ever feel like your blood pressure is too low, too little stress in your life? In such a case I prescribe: while thinking about these tweets, go read that one DSL thread about how the Singularity is fake and dumb
[11:36:25] <gurkenglas> feep[work]: predictable in retrospect that you would see something that shortens your timelines, huh? :P
[11:37:43] <quanticle> Obormot\Arcturus: Which thread?
[11:38:24] <Obormot\Arcturus> feep[work]: The later posts in that thread are actually about how those mean evil alignment people are retarding PROGRESS in AI, which will lead to, like, voice recognition software working better and stuff! The posters there are angry that their SOFTWARE FEATURES are gonna come later than they otherwise would, due to this fear-mongering about the end times!
[11:38:35] <Obormot\Arcturus> quanticle: "Anti-Singularity FAQ"
[11:38:42] <feep[work]> Obormot\Arcturus: I think my blood pressure is FINE, thank YOU
[11:38:59] <Obormot\Arcturus> Alright, well, keep the option in your back pocket I guess
[11:39:19] <feep[work]> if I ever end up in a crank situation where I need to keep my heart rate above 140 or sth, I'll keep it in mind.
[11:39:29] <Obormot\Arcturus> Cool, cool
[11:39:58] <feep[work]> gurkenglas: actually I do think this was not trivially predictable
[11:40:26] <feep[work]> like, I was counting on slowness coming from needing something like online learning, in *hindsight* I should have updated when I read that dnns learn learning
[11:40:40] <feep[work]> which means you can fill in a lot of spackle by emulating learning inside a fixed deep network
[11:40:46] <kuudes> maybe covid could kill someone that would otherwise cause asi, or war in ukraine would kill someone such
[11:40:52] <kuudes> mwi to the rescue?
[11:41:00] <feep[work]> :peers at anthropics skeptically:
[11:41:08] <feep[work]> it shouldn't be a late rescue
[11:41:23] <kuudes> shouldn't it be very late rescue?
[11:41:36] <nshepperd> i can't wait to see what's next on the anthropic shadow
[11:41:37] <feep[work]> no because you'd expect the improbability to be equidistributed through the worldline
[11:41:39] *** Quits: schmudde (~schmudde@2001:b07:ae6:7d19:f456:c298:ea16:21c9) (Ping timeout: 252 seconds)
[11:41:40] <kuudes> you know, the closer end is, the weirder the avoidance comes
[11:41:59] <feep[work]> sure but then you just hide your improbability in the *absence* of the shadow in your past.
[11:42:27] <feep[work]> I guess the argument would be that due to population growth if you start with a counting prior, most humans who are ever born presingularity are close to the singularity
[11:42:58] <feep[work]> and early interventions against agi would also usually act against pop
[11:43:40] <feep[work]> anyway, anthropics leads to a weird reversal: the *absence* of friendliness work is evidence that AIs are naturally aligned.
[11:43:45] <kuudes> hmm. is it sane to start to be averse to things that could cause you to be on causal path that leads to asi, so that you will not experience too much anthropic shadow?
[11:44:45] <kuudes> weed to the rescue?
[11:44:48] <feep[work]> of course
[11:44:58] <feep[work]> the fact that we are born presingularity is evidence that the AI will be unaligned
[11:45:12] <feep[work]> as per doomsday argument
[11:45:34] <feep[work]> of course of course, this all only works if you can apply the counting prior
[11:45:49] <feep[work]> and nobody knows if probability works like that :v
[11:46:04] <quanticle> Obormot\Arcturus: lmao that thread is 100% god-of-the-gaps cope
[11:46:10] <feep[work]> so I'mma just go back to work~
[11:46:25] <feep[work]> kuudes: live life well, let come what may, and enjoy things in the meantime
[11:46:53] <bildramer> when I need higher blood pressure I go to r/philosophy
[11:47:08] <bildramer> did you know reductionism was proven wrong?
[11:47:14] <feep[work]> also maybe bomb mountain view :waves at our fbi minders:
[11:47:17] <bildramer> sorry, sorry, let's not go there
[11:47:58] <feep[work]> bildramer: let's literally not go there, lol.
[11:48:41] * feep[work] goes back to writing serialization code~
[11:49:16] <quanticle> Sounds like the sort of thing an AI would be useful at. Have you considered unleashing Codex on it?
[11:50:18] *** Quits: gproto23 (~gproto23@user/gproto23) (Remote host closed the connection)
[11:50:40] *** Joins: gproto23 (~gproto23@user/gproto23)
[11:51:01] <ardent[m]> To stop AGI we must destroy all humans]
[11:53:58] <gurkenglas> feep[work]: if the doomsday argument actually turns out correct in a way that AGI could verify this, an FAI could just... stop the population explosion in order to invalidate its premise
[11:56:38] <feep[work]> gurkenglas: problem: it'd stop the population explosion
[11:56:50] <feep[work]> you know, massively curtailing human flourishing
[11:57:39] <bildramer> solution: massively un-curtail human flourishing
[11:57:54] <feep[work]> without creating human prior entries?
[11:58:40] <feep[work]> eh, I'll let it worry about that.
[11:58:41] <bildramer> I'm not sure I'm right about population ethics, and my position is "I'm not sure I'm right about population ethics" - maybe the right thing is something obvious and I should already be believing it
[11:59:49] <bildramer> there needs to be a name about that sort of uncertainty. like there's a correct position on the 30 year war, I just don't know which one it is
[12:00:14] <gurkenglas> map-confusion.
[12:00:38] <feep[work]> pending judgment?
[12:01:12] <feep[work]> judgment pending, sorry
[12:11:07] <kuudes> population explosion has already stopped
[12:11:57] <kuudes> I guess there never again will be more than 2000 persons per bitcoin?
[12:13:02] <feep[work]> okay, just between us
[12:13:14] <feep[work]> if we actually hit the singularity, I'd fully intended to do a diy population explosion of mindforks
[12:13:18] <feep[work]> this creates anthropic difficulties
[12:13:48] <feep[work]> I sort of handwave it by saying that they'd all remember having been me now, so it kinda works out, but it's still certainly odd.
[12:14:18] <kuudes> ggreer, you could be interested of https://www.hrw.org/news/2022/02/15/australia-end-indefinite-arbitrary-immigration-detention
[12:14:19] <Robomot> Australia: End Indefinite, Arbitrary Immigration Detention | Human Rights Watch (Australian authorities continue to indefinitely detain 32 refugees and asylum seekers at the same facility where Novak Djokovic was held, one month since the world tennis star’s detention brought international attention to their plight.)
[12:14:51] <feep[work]> anyway, since I can't be the only one who thinks this, even given zero "normal" births post-singularity, we can't avoid the shadow by just appealing to the demographic transition.
[12:15:15] <saturn2> keep the same number of humans, but just make them grow larger and larger
[12:15:16] <capisce> https://twitter.com/fire_bottle/status/1493747985666039810
[12:15:18] <Robomot> FireInABottle (@fire_bottle): "This is why it’s important to know what your pork is being fed! In addition to a huge amount of PUFA, these pigs are getting huge amounts of BPA, which bio-accumulates in fat and causes obesity, among other problems. / http://FirebrandMeats.com No garbage, no PUFA."
[12:15:42] <feep[work]> an objective source if I ever saw one
[12:16:53] <saturn2> it's 10 PM. do you know what your pork is being fed?
[12:17:59] <nshepperd2> the pork thing is interesting
[12:18:43] <nshepperd2> the comparison to limes and scurvy on SMTM is apt i think
[12:19:14] <nshepperd2> a pig is not a pig
[12:19:38] <feep[work]> a pig is not b pig
[12:19:54] <kuudes> isn't that sort of thing criminal?
[12:19:55] <kuudes> O_o
[12:20:11] <kuudes> surely also usa has some regulations on what you can feed to animals
[12:21:03] <nshepperd2> there are probably comically large limits on the amount of BPA that is allowed to be in the diet
[12:21:48] <quanticle> Real talk: was BPA ever shown to be harmful in non-comically large amounts?
[12:22:07] <nshepperd2> who knows
[12:22:08] <quanticle> The panic around BPA has always seemed to me like the panic around artificial sweeteners
[12:22:42] <quanticle> OH NO IT CAUSES CANCER <small print>if you consume 50x the average lifetime consumption in a day</small print>
[12:22:50] <bildramer> speaking of, titanium dioxide, _the_ white food dye, is going to be banned in the EU soon, for no good reason, and I hate it
[12:22:51] <nshepperd2> and imo the real point should be that we'll never know, because nobody knows how much BPA is in anything such as something labeled "pork" in the store
[12:22:55] <bildramer> mini-rant over
[12:23:05] <bildramer> no not over
[12:23:22] <quanticle> Wait, titanium dioxide? You mean like the sunscreen ingredient?
[12:23:36] <kuudes> afaik yes
[12:23:38] <nshepperd2> yes
[12:23:41] <nshepperd2> its a pigment
[12:23:50] <quanticle> Why does the EU want its residents to get skin cancer?
[12:23:56] <nshepperd2> they make spacecraft thermal ablative shielding out of it too
[12:24:17] <bildramer> it's a comical series of events that comes straight of a libertarian leaflet about how goverment regulation is the devil. has everything you could wish for. bad studies, endless attempts to get new studies to prove $thing is bad, over and over, and they don't, then finally latching into the tiniest bit of evidence to ban the whole thing throughout because of misapplied precautionary principle
[12:24:18] <nshepperd2> they're just banning it in food
[12:24:22] <bildramer> rant truly over
[12:25:56] <quanticle> EU food safety right now: https://twitter.com/PetiteNicoco/status/1490748903993622528
[12:25:57] <Robomot> petite nicoco (@PetiteNicoco): "RW Twitter lately:" (https://birdsite.xanny.family/i/videos/1490748903993622528)
[12:26:05] <kuudes> I would tend to disbelieve that they would be feeding plastic garbage to pigs
[12:26:50] <quanticle> Same. I bet the footage is either manipulated or non-representative.
[12:28:50] <gurkenglas> feep[work]: my favored way to resolve this oddity is that, instead of using anthropics to figure out where you are and then act accordingly, you figure out the policy all the versions of you across the multiverse could pick such that the multiverse shakes out best. translated back into the anthropic-probabilities view this shakes out to predicting that you're more likely to find yourself in an 
[12:28:56] <gurkenglas> important position. and oh look, we're in #lesswrong...
[12:29:17] <nshepperd2> idk it makes some sense
[12:29:47] <feep[work]> gurkenglas: sure, makes sense. probably a more sensible way to think about probability.
[12:30:17] <nshepperd2> they get expired/end-of-day bread and stuff delivered in bulk, grind it up, then filter out the plastic packaging
[12:31:00] <nshepperd2> easier than unwrapping it by hand maybe
[12:32:00] <nshepperd2> presumably the filtering is not perfect bc they only have to meet some legal maximum on plastic content of feed
[12:32:44] <nshepperd2> then they can advertise that they're sustainable™ or something because they're using leftovers
[12:34:58] <feep[work]> https://www.youtube.com/watch?v=NzJp_2y--Uk heeeyyy
[12:34:59] <Robomot> What's Up Dougal 7 Gammer Hardcore Remix - YouTube (00:05:00) (What's Up Dougal 7 Gammer Hardcore Remix)
[12:35:52] <kuudes> it seems at least over here they don't use waste for pig feed? O_o
[12:37:14] <feep[work]> actually this song is a great example of counterpoint :D
[12:37:19] <feep[work]> .wp counterpoint
[12:37:21] <feepbot> feep[work]: https://en.wikipedia.org/wiki/Counterpoint <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096" />In music, counterpoint is the relationship between two or more musical lines (or voices) which are harmonically interdependent yet independent in rhythm and melodic contour.
[12:37:22] <Robomot> Counterpoint - Wikipedia (In music, counterpoint is the relationship between two or more musical lines (or voices) which are harmonically interdependent yet independent in rhythm and melodic contour.[1] It has been most commonly identified in the European classical tradition, strongly developing during the Renaissance and in much of the common practice period, especially in the Baroque period. The term …)
[12:37:31] <feep[work]> I saw a youtube video about it recently, which probably explains why I'm spotting it everywhere now
[12:37:48] <feep[work]> note how the melody track is the melodic inverse of the sung track
[12:39:16] <Dyo> bildramer: what is the issue with the titanium dioxide studies?
[12:41:31] <bildramer> long history of "nothing to worry about", then one was "hypothetically something to worry about", iirc, and that's it, E171 is done for
[12:42:36] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[12:45:38] <Dyo> idk the issue in detail, just heard it mentioned as potentially irritant/inflammatory in the past. maybe those properties are limited to nanoscale particles.
[12:46:50] <Dyo> I can kinda understand banning it even if it's just about nano particles, banning it altogether is easier than testing stuff for particle size instead of just presence of a substance
[12:47:11] *** Quits: gurkenglas (~gurkengla@dslb-188-096-121-068.188.096.pools.vodafone-ip.de) (Ping timeout: 256 seconds)
[12:52:02] <nshepperd2> it'll probably be immediately replaced with something worse tho
[12:56:15] <PapuaHardyNet> really interesting discussion b/w kuudes and feep re sutskever's "slightly conscious" meme-starter tweet
[12:56:40] <PapuaHardyNet> kuudes: that's not a fire alarm, because everyone made fun of Illya's tweet
[12:58:08] <PapuaHardyNet> also uhhhh, this is bad. We don't want more ethicists getting into AI alignment as feep said. It will be bad
[13:02:12] *** Joins: voltage_ (voltage@user/voltage)
[13:03:45] <feep[work]> it's a fire alarm
[13:03:56] <feep[work]> hm
[13:03:58] <feep[work]> that gets into semantics tho
[13:04:04] <feep[work]> is it an alarm if it doesn't alarm anyone
[13:04:21] <nshepperd2> ethicists are unaligned
[13:06:51] <PapuaHardyNet> nshepperd2: there are two buttons in front of you. One wireheads all existing and potentially existing AI ethicists. Another wireheads all existing and potentially existing AGI developers, retarding the progress towards AGI permanently until AI alignment is solved. What button do you press, if any
[13:12:00] <PapuaHardyNet> okay okay hear me out
[13:12:02] <feepbot> PapuaHardyNet: PapuaHardyNet left a note 4 hours, 3 minutes ago: Verify why spatial gating units do not need positional encoding
[13:12:08] <PapuaHardyNet> awkward
[13:13:16] <PapuaHardyNet> okay, I'll do that, but first, what if you use DOTA 5v5 level compute and architecture to build a video game environment that basically wireheads a person? Makes them entirely 100% addicted?
[13:13:49] <PapuaHardyNet> does that count as wireheading? if so, we have the compute right now to create 99.999% perfect artificial wireheading
[13:14:38] <PapuaHardyNet> the only problem here is that how do you get the data for an AI to train itself? this would require an AI modelling human reward mechanisms
[13:16:34] <feep[work]> #lesswrong: "you are in the perfect position to make sure the singularity will be aligned with human interests"
[13:16:36] <nshepperd2> mturk
[13:16:39] <feep[work]> also #lesswrong: "so, wireheading, eh"
[13:17:05] <capisce> https://twitter.com/wdormann/status/1481961821825347587
[13:17:06] <Robomot> Will Dormann (@wdormann): "Some people: I like getting my movies on plastic discs, because I actually own them that way. / CyberLink: Don't update your CPU, OS, or drivers, or you won't be able to play your plastic discs." (http://nitter.moomoo.me/pic/media%2FFJD8atMXoAgJiGF.jpg)
[13:17:24] <PapuaHardyNet> mturk at scale, because you can afford to pay people less when you are paying them to play a video game
[13:17:26] <PapuaHardyNet> this is good
[13:17:44] <bildramer> somehow not #lesswrong: "_this_ is the perfect position?"
[13:18:09] <bildramer> it is entirely rational to be in complete dismay and/or going joker
[13:18:27] *** Quits: _inky (inky_@gateway/vpn/protonvpn/inky) (Ping timeout: 252 seconds)
[13:18:31] <capisce> "The Intel SGX feature has been removed from Intel 11th generation (or newer) CPUs, and support for SGX may be removed at some point on the new versions of Intel drivers or utility programs (e.g., the Intel SGX and Intel Management Engine driver and firmware). These changes could make these platforms lose support for Ultra HD Blu-ray movie disc playback."
[13:20:38] <bildramer> feep[work]: have you seen the recent anti-fire-alarm post? "if the fire alarm is ringing, I know it's an exercise, so I do nothing"
[13:20:55] <bildramer> on twitter
[13:21:05] <bildramer> goodharting too hard
[13:21:48] <feep[work]> no but also lol
[13:23:51] <bildramer> oh, I remembered it wrong
[13:23:57] <bildramer> this https://twitter.com/michaelblume/status/1481451567286870016
[13:23:58] <Robomot> Stop de kindermoord (@michaelblume): "My high school was under construction and the electrical work kept interacting with the alarm wiring in a way that triggered false alarms."
[13:24:34] <feep[work]> normalization of deviance: great in the sheets, fatal in the streets
[13:25:56] <bildramer> also brings to mind the recent scottpost
[13:27:02] <bildramer> I can only dream that one day the sanity waterline will be much higher, everyone will know about all the probability theory 101 examples like base rate fallacies, weighing false positives/negatives differently, etc.
[13:27:06] <bildramer> and still fall for all of them
[13:27:26] <feep[work]> you pity the fools who don't even know to call it base rate fallacy.
[13:28:59] <capisce> https://twitter.com/ESYudkowsky/status/1493680826785038336
[13:29:00] <Robomot> Eliezer Yudkowsky (@ESYudkowsky): "Why question a feeling that drives you to look for evidence? Take the motivation and run."
[13:29:14] <capisce> maybe because time is limited and we have to prioritize
[13:30:05] <ardent[m]> does the wireheading have adorable waifus?
[13:30:16] <ardent[m]> if so count me in pls
[13:30:33] <feep[work]> it has the pleasure evoked by seeing adorable waifus!
[13:31:01] <ardent[m]> what about the pleasure of being one?
[13:31:13] <feep[work]> yep
[13:31:17] <feep[work]> though of course, no actual being of one
[13:32:57] *** Joins: _inky (inky_@gateway/vpn/protonvpn/inky)
[13:33:31] <capisce> https://twitter.com/DegenRolf/status/1493629035418689547
[13:33:32] <Robomot> Rolf Degen (@DegenRolf): "Across countries, adolescents experienced a widespread steep decline in life satisfaction from the ages of 10 to 16 years, which was particularly dramatic for girls. https://psyarxiv.com/zdhe7/" (http://nitter.domain.glass/pic/media%2FFLpvpl4WYAMXDBk.jpg)
[13:33:38] *** Quits: src_ (~src@user/src) (Quit: Leaving)
[13:34:04] *** Quits: Rubba (~Kol@75.157.122.186) ()
[13:34:14] <ardent[m]> I wonder if it's any different in cultures where full coming-of-age happens earlier
[13:34:43] <ardent[m]> (lots of confounders in modern times, and sadly we can't just poll ancient Greeks)
[13:35:19] <PapuaHardyNet> "particularly dramatic for girls" promotes a narrative. I wouldn't take this at face value
[13:37:26] <ardent[m]> On one hand, yeah, on the other hand, my model predicts that all groups will experience this due to the lowered agency of modern adolescence compared to historical times
[13:37:55] <PapuaHardyNet> data mainly from WHO, sample size 0.7 million
[13:38:12] <PapuaHardyNet> "Which best describes how you feel about your life as a whole?" Response options were presented on a 7-point scale represented by more or less smiley faces.
[13:39:39] <PapuaHardyNet> doesn't seem worth considering imo. imagine being a guy and saying in a survey you feel bad about your life
[13:39:40] <PapuaHardyNet> lol
[13:39:52] <PapuaHardyNet> that's one huge distortion that could exist
[13:55:21] *** Quits: two2thehead (~user@124.195.205.14) (Quit: Leaving)
[13:55:22] *** Quits: gproto23 (~gproto23@user/gproto23) (Read error: Connection reset by peer)
[14:03:21] *** Joins: gproto23 (~gproto23@user/gproto23)
[14:30:43] *** Quits: phill (uid429774@id-429774.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[14:56:10] <rsaarelm> Things that don't seem to have a word for them: surrounding cultural history based meta-judgment of some endeavor probably being doomed, as in "you're trying to {prove psychic powers exist | unify quantum physics and general relativity | design a perpetual motion machine | make successful educational video games}, you have nothing going for you beyond being sorta smart and pretty interested in
[14:56:12] <rsaarelm> the domain, but you're ignoring decades of this being a known problem and smart people having constant shots at it and failing to get anywhere"
[14:57:21] <feep[work]> youthful folly
[14:58:20] <feep[work]> https://divination.com/iching/lookup/4-2/
[14:58:20] <Robomot> iChing 4: Youthful Folly (Be on guard for careless or rebellious attitudes characteristic of youthful inexperience. Just as a youth requires instruction, this is a good time to focus on learning your lessons from a patient teacher or life experience.)
[14:59:48] <rsaarelm> Like, this would not have applied to trying to prove psychic powers exist in 1920, because very few people had done any sort of solid scientific attack at it.
[15:00:13] <rsaarelm> It would've still been out-there weird thing to study, but you didn't have the ammunition to say that it's not going anywhere without a fresh attack.
[15:11:17] *** Quits: gproto23 (~gproto23@user/gproto23) (Read error: Connection reset by peer)
[15:32:03] <rsaarelm> Also it of course applies to elderly crackpots as well.
[15:40:14] <capisce> https://boingboing.net/2022/02/15/zuckerberg-coldly-explains-to-facebook-staff-they-are-now-to-be-known-as-metamates.html
[15:40:15] <Robomot> Zuckerberg coldly explains to Facebook staff they are now to be known as "Metamates" | Boing Boing (Alex Heath, senior reporter for The Verge, is covering an all-hands meeting at the company formerly known Facebook. Zuckerberg is "explaining the company’s updated values". Zuckerberg is explaining they will not “nice ourselves to death”. Zuckerberg is explaining that they are now to be known as " …)
[15:40:47] <feep[work]> wow, what a self-destruction
[15:41:08] <PapuaHardyNet> wait, is that a real news article or not?
[15:41:19] <feep[work]> unclear if it's accurate, but it is real.
[15:41:23] <PapuaHardyNet> I've honestly given up reading news these days. Can't trust anything except what friends say
[15:41:38] <capisce> yes, it seems accurate
[15:41:48] <capisce> others are also reporting this
[15:42:06] <feep[work]> https://twitter.com/alexeheath/status/1493658517571526656 it makes marginally more sense in context.
[15:42:08] <Robomot> Alex Heath (@alexeheath): "- last value, and I am not making this up: “Meta, metamates, me” / A slide shows this text in bold all caps next to Zuck talking / I am told Zuck said this without laughing and explained it had to do with a story about ships and shipmates"
[15:42:42] <capisce> not that much more
[15:42:55] <PapuaHardyNet> well then, sounds like clickbait to me, even if true
[15:43:01] <feep[work]> it is
[15:43:31] <feep[work]> anyway, in the context of "nice ourselves to death" the point is that you should prioritize company health over coworker happiness I guess
[15:43:35] <feep[work]> which          seems fair??
[15:44:23] <capisce> or is it don't try to be too nice to the users if it means losing out on profits?
[15:44:31] <feep[work]> nah, it was in the context of coworkers
[15:44:52] <feep[work]> at least that's what I take from the twitter thread
[15:45:07] <PapuaHardyNet> all this Zuck sneer is hate for non-chads
[15:45:27] <PapuaHardyNet> would they do this to Elon? No, because elon is chadlike. Would they do this to Bezos? No, because Bezos is chadlike
[15:45:50] <feep[work]> they do this to elon all the time
[15:46:12] <PapuaHardyNet> they do? very well. I retract my statements and update my beliefs
[15:46:30] <feep[work]> let me find an example
[15:46:59] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 250 seconds)
[15:47:04] <capisce> corporate culture is so cringe
[15:47:19] <feep[work]> hm, might not have a hit offhand, maybe ignore my point
[15:48:23] <PapuaHardyNet> okay, reverted my belief update
[15:48:53] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[16:00:12] <PapuaHardyNet> http://alexlenail.me/NN-SVG/
[16:00:12] <Robomot> NN SVG
[16:01:34] *** Joins: gurkenglas (~gurkengla@dslb-188-096-121-068.188.096.pools.vodafone-ip.de)
[16:13:38] <capisce> today's hot take: https://old.reddit.com/r/Nootropics/comments/stnszw/iq_is_more_heritable_than_height_so_why_bother/
[16:13:40] <Robomot> IQ is more heritable than height. So why bother with Nootropics? : Nootropics (Edit: I acknowledge there are many applications. But, cognitive enhancement is what I see advertised most often. I should have asked, “why...)
[16:14:31] <capisce> also from the comments: "It’s complex but overall, IQ tests test how good you are at taking IQ tests. If they truly measured anything, you wouldn’t have 180 IQ bartenders and Uber drivers who don’t have anything meaningful to say."
[16:15:08] <capisce> maybe they're too smart to want to talk to that guy
[16:21:06] <PapuaHardyNet> Uber drivers who don't have anything meaningful to say - what the fuck? Is this some sort of sneering at the underclass
[16:21:27] <PapuaHardyNet> and yet they are like "180 IQ bartenders". do they even have a point smh
[16:23:22] <capisce> he's saying if they were so smart they wouldn't be uber drivers and they'd have meaningful things to say
[16:34:08] <nshepperd2> brb, going to the bar to get tips on solving ai alignment
[16:40:54] <PapuaHardyNet> "For example, about one in ten applicants gets into Oxbridge in the UK, and Stanford and Harvard accept about one in twenty-five applicants. But in Hebei province in China, where I am from, only one in fifteen hundred applicants gets into Peking or Qinghua University." gentlemen, the top two AI research universities in China are so, so competitive
[16:41:24] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 272 seconds)
[16:41:31] <PapuaHardyNet> (and women, of course - just a verbal habit)
[16:42:15] <PapuaHardyNet> for more context, Peking and Tsinghua produce about as much AI research (maybe 80% or so) that is published in the top journals as, say, ETHZ and INRIA and EPFL
[16:43:12] <PapuaHardyNet> source: https://americanaffairsjournal.org/2017/11/western-elite-chinese-perspective/
[16:43:13] <Robomot> The Western Elite from a Chinese Perspective - American Affairs Journal (The Evangelical Christians I have met in the United States often talk about how reading the Bible changed their lives. They talk about being born again. I am not an Evangelical Christian. I am a Chinese atheist who came to the West to study at the world’s best universities and, later, to work at one…)
[16:46:08] <capisce> not surprising considering the population of China and the prestige of going to one of the top universities
[16:46:31] <feep[work]> > I told him that at Goldman our motto was “be long-term greedy.” The professor couldn’t understand this motto or why it was inspiring.
[16:46:38] <feep[work]> lol, poor finance nerd
[16:46:56] <feep[work]> > I explained to him that everyone else in the market was short-term greedy and, as a result, we took all their money. Since traders like money, this was inspiring.
[16:47:00] * feep[work] giggling at his desk
[16:47:12] <PapuaHardyNet> :)
[16:47:29] <PapuaHardyNet> it gets even better as you continue
[16:48:14] <PapuaHardyNet> "And when the professor said to me in class “Puzhong, I can see that story brought up some emotions in you,” I rolled up my sleeve and checked my heart rate. It was about 77.  And so I said, “nope, no emotion.” The experiment seemed to confirm my prior belief: my heart rate hardly moved, even when I was criticized, though it did jump when I became excited or laughed."
[16:48:18] <feep[work]> strong feel of "somebody link that guy the sequences"
[16:48:44] <feep[work]> or possibly straight OB
[16:48:45] <capisce> bet you India's top universities also have very low acceptance rates
[16:55:31] <capisce> https://fireinabottle.net/the-french-obesity-paradox/
[16:55:33] <Robomot> The French Obesity Paradox - Fire In A Bottle (The French and Swiss stayed lean for decades while consuming more calories than Americans.)
[16:56:41] <capisce> "If we make the presumption that wealthy industrial countries waste similar amounts of food, this gives us a pretty good estimate of which countries ate more food than others."
[16:56:51] <capisce> doesn't sound too safe to presume this
[17:03:53] <capisce> "I argued in my last article that starch eating cultures have very saturated body fat and therefore high metabolic rates.  The data from France and Switzerland suggest that the same is true of cultures which combine saturated fat (butter, cheese, sausage)  and starch.  Once PUFA is added to the mix, obesity ensues over the next decades."
[17:22:55] <kuudes> I went to the doctor now and they took covid pcr, crp and antibody count test that I had ordered. she listened my lungs and decided that there was no inflammation there. ordered buventol (the opening asthma med) in case of need and when I told her I have an oxygenerator, she said use of that could be beneficial and is not harmful.
[17:29:38] <PapuaHardyNet> is anyone here from london
[17:30:42] <PapuaHardyNet> in london* sorry
[17:31:06] <kuudes> galambo_ and Betawolf are from somewhere in uk
[17:33:53] <Betawolf> I'm not in London though
[17:41:59] <kuudes> https://spectrum.ieee.org/bionic-eye-obsolete uuh
[17:42:00] <Robomot> Their Bionic Eyes Are Now Obsolete and Unsupported - IEEE Spectrum (These early adopters found out what happened when a cutting-edge marvel became an obsolete gadget... inside their bodies.)
[17:46:36] *** Quits: feep[work] (~mathis@195.50.168.194) (Ping timeout: 240 seconds)
[17:46:50] *** Quits: nullcone (uid11626@id-11626.helmsley.irccloud.com) (Quit: Connection closed for inactivity)
[17:50:41] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[18:01:20] *** Joins: [itchyjunk] (~itchyjunk@user/itchyjunk/x-7353470)
[18:03:39] <Robomot> [TheZvi Substack] Convoy Continued - https://thezvi.substack.com/p/convoy-continued
[18:09:40] <Robomot> [TheZvi] Convoy Continued - https://thezvi.wordpress.com/2022/02/16/convoy-continued/
[18:14:41] <feepbot> <gwern> https://www.nytimes.com/2022/02/16/world/asia/hong-kong-covid-omicron-wave.html
[18:14:42] <Robomot> Omicron Reveals Hong Kong's Covid Dilemma - The New York Times (An Omicron surge has exposed the weaknesses of a system that was once a world leader in containing the coronavirus.)
[18:15:11] <gwern> kuudes: ilya is just trolling. the berserk reaction to it is pretty embarassing and a sign of how far DL has come
[18:16:10] <kuudes> hmm. thanks!
[18:18:38] <gwern> (ie. the fact that such a short, low-effort, low-quality troll could provoke such a berserk reaction shows that people are nervous about it and don't have any counterarguments and know it)
[18:20:09] <kuudes> indeed
[18:20:46] <kuudes> how do you see on if we should or could limit nn research with numerical limits, ie maximum allowed param count etc?
[18:21:54] *** Joins: two2thehead (~user@124.195.205.14)
[18:22:17] <gwern> probably wouldn't work. there are many ways to interpolate parameter-count/compute
[18:22:46] <PapuaHardyNet> I tried to make an ilya berserker joke but nothing was good enough
[18:26:57] <feep> hypothesis
[18:27:21] <feep> gpt does not get humor because it is not conscious, humor is intrinsically linked to consciousness because it requires noticing a state of contradicting knowledge
[18:28:05] <two2thehead> hm
[18:28:13] <PapuaHardyNet> okay hold on
[18:28:13] <feep> maybe also heavy social modeling
[18:28:20] <two2thehead> that... could be possible?
[18:28:26] <PapuaHardyNet> if gpt larps humor, how is that different from actually experiencing humor?
[18:28:37] <feep> PapuaHardyNet: gpt cannot larp humor.
[18:28:42] <feep> at all.
[18:28:49] <feep> it critically fails at punchlines
[18:28:52] <two2thehead> or at least that hurdle has to be met, in order to simulate human consciousness
[18:28:58] <feep> it can do like, repetetive and referential comedy
[18:29:03] <feep> but not setup-punchline comedy
[18:29:13] <pompolic> oh shit, millenials btfo
[18:29:17] <PapuaHardyNet> I didn't imply GPT-3 can do humor, it was more "GPT architecture"
[18:29:43] <feep> I think if a gpt got humor, that would be evidence it had consciousness
[18:29:49] <PapuaHardyNet> come on
[18:29:50] <gwern> I think it does humor, it just doesn't do anything with phonetics
[18:30:02] <gwern> I mean come on, have you read the devil's dictionary or navy seals
[18:30:07] <feep> gwern: all the explanations of punchlines I've seen have been totally empty of understanding
[18:30:15] <feep> navy seals is referential comedy
[18:30:18] <pompolic> humor seems to be kiiiiind of correspondant to subversion of expectations
[18:30:36] <PapuaHardyNet> interesting, so what you are saying is: if gpt can do humor, gpt has a model of the reader in its head
[18:30:37] <kuudes> feep, what specific cultural artefact you propose gpt cannot produce?
[18:30:44] <feep> it's applying a theme-shifted template, the exact thing that gpt should be good at
[18:30:48] <PapuaHardyNet> that's orthogonal to being conscious, but is is kind of scary
[18:31:02] <feep> PapuaHardyNet: well, it has a model of a reader at least
[18:31:04] <pompolic> GPT seizes the means of meme production
[18:31:10] <PapuaHardyNet> morning pompolic
[18:31:13] <pompolic> morning
[18:31:15] <feep> kuudes: surprise-based comedy
[18:31:27] <feep> wait, bad description
[18:31:29] <kuudes> please point to one such existing thing?
[18:31:32] <kuudes> Friends?
[18:31:33] <gwern> feep: yes, and most such punchlines rely on phonetics etc, and keep in mind that the BPEs do not just destroy GPT's ability to make phonetic humor, they probably also screw up its broader abilities by inserting a giant heap of 'this is a joke that will make no sense to you, so you will learn that humor = random unrelated statement; now that I've finished hitting you on the head repeatedly...
[18:31:39] <feep> kuudes: no literally jokes. standup.
[18:31:39] <gwern> ...with a basebal batt, make a joke!"
[18:31:59] <feep> gwern: I don't think they mostly rely on phonetics, you're thinking of puns maybe?
[18:32:02] <PapuaHardyNet> yeah, I keep thinking byt5 is the key here for future language models
[18:32:03] <pompolic> the A : B :: C : D form of joke tweets comes to mind suddenly
[18:32:08] <kuudes> ok. so you claim we can't get gpt to output a litteration of fictional standup comedy presentation?
[18:32:13] <pompolic> connecting distant things in thingspace is the funniest shit
[18:32:28] <kuudes> I am aiming to get a testable prediction
[18:32:30] <feep> kuudes: I think it can do standups, but not like ... jokes
[18:32:41] <feep> it can probably do "haha, let's gripe at our enemies" humor
[18:32:53] <kuudes> ok. I am trying to get you to output something that exists and that gpt could not produce in your opinion
[18:32:54] <gwern> feep: my point is that there is something like many megabytes of humor that *cannot* make sense to GPT. what does it learn about GPT? well, how well do you think ImageNet would work if we took a couple categories and randomized 90% of their labels? those categories are not going to work very well!
[18:33:03] <gwern> * learn about humor
[18:33:18] <feep> kuudes: there's a kind of presentation that contains a single key sentence (or two ish) that recontextualizes the meaning of the previously told content in a way that elicits laughter
[18:33:25] <feep> gpt does not understand how this works and cannot reproduce it.
[18:33:31] <PapuaHardyNet> what gwern is saying is that GPT memorizes the pattern of jokes and tries to reproduce it
[18:33:38] <kuudes> could you name one existing thing? point to youtube if needed?
[18:33:44] <PapuaHardyNet> but does not have a fine enough model to be able to create humor
[18:33:44] <kuudes> some Seinfeld episode?
[18:33:51] <feep> .g example jokes wikipedia
[18:33:53] <feepbot> feep: https://en.wikipedia.org/wiki/Joke <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096" />A joke is a display of humour in which words are used within a specific and well-defined narrative structure to make people laugh and is usually not meant to be taken seriously.
[18:33:54] <Robomot> Joke - Wikipedia (A joke is a display of humour in which words are used within a specific and well-defined narrative structure to make people laugh and is usually not meant to be taken seriously. It takes the form of a story, usually with dialogue, and ends in a punch line. It is in the punch line that the audience becomes aware that the story contains a second, conflicting meaning. This can be done using a pun …)
[18:34:02] <PapuaHardyNet> because of BPE, which gets in the way of recursively hierarchical modelling of concepts
[18:34:15] <feep> kuudes: the minimal example would be "my dog has no nose." "how does he smell?" "terrible!"
[18:34:32] <feep> gpt miiight barely be able to get how that one works, but I'd expect not.
[18:34:39] <gwern> and, unfortunately, what we have carelessly done is taught GPT that 'a joke is multiple statements of unusual actions, followed by a sentence of gibberish chosen at random. also, sometimes jokes involve satire, wit, cutting commentary, that sort of thing, but no, 90% of the time, the punchline is simply a random set of BPEs'
[18:34:50] <pompolic> hmm
[18:34:52] <kuudes> ok. so we would need to get gpt to output a dadjoke to disprove that? do you agree on this, feep?
[18:34:57] <feep> gwern: I don't think that should happen
[18:35:06] <gwern> feep: of course not. but people use BPEs anyway
[18:35:11] <feep> gwern: it should notice that the non-pun based humor is its own category
[18:35:13] <gwern> I keep telling them not to, and they keep doing it anyway ;_;
[18:35:13] <feep> that it can predict
[18:35:33] <pompolic> a language should encode common expectations (because Words Are Hidden Inferences)
[18:35:36] <feep> kuudes: a dadjoke and an explanation of it.
[18:35:38] <kuudes> I wonder if bpes are another minimal antiagimeasure
[18:35:58] <PapuaHardyNet> conspiracy theory :<
[18:35:58] <gwern> feep: yes, and when you cue it in carefully to avoid puns, it works great! but dadjokes just fail abysmally. I tried. all it is able to do is either do memorized dadjokes or non sequiturs
[18:36:14] <kuudes> PapuaHardyNet, well, openai seems like a honeypot
[18:36:14] <feep> for instance, the dog jokes exploits the double meaning of terrible, the interlocutor was asking how the dog was able to smell, but he was misinterpreted as asking after the fragrance of the canine
[18:36:33] <pompolic> can a language model leave the hyperplane of common expectations?
[18:36:39] <feep> this is unexpectedlz revealed in the last word, which is the punchline
[18:36:41] <feep> ly*
[18:36:48] <gwern> feep: but I expect it to still suffer damage to its capabilities, even if you manage to avoid the non-sequitur phonetics, it is still getting damaged noisy lower-than-it-is-capable-of humor capabilities
[18:36:52] <kuudes> ok. if we could prefix gpt to produce a dadjoke, would it disprove your proposition, feep?
[18:36:55] <pompolic> it doesn't really have any other form of interpretation facility to "think" with, does it?
[18:36:56] <feep> it's a fair theory
[18:36:58] <feep> kuudes: and explanation!
[18:37:08] <feep> I believe it can copypaste them, but it has to show its working
[18:37:10] <kuudes> could you provide such an example?
[18:37:11] <feep> but yes
[18:37:15] <feep> I just did
[18:37:21] <kuudes> no, explanation is missing
[18:37:26] <gwern> kuudes: no, it can produce dadjokes. I already tested this. they're just *memorized* because GPT can't understand the logic of dadjokes (due to BPEs) and resorts to memorizing them in order to predict them
[18:37:27] <feep> er, the double meaning of smell*
[18:37:36] <feep> gwern: right, that's why I asked for an explanation
[18:37:45] <pompolic> BPEs?
[18:37:50] <gwern> feep: I also did 'give me an explanation of the joke'. 
[18:37:53] <gwern> also failed
[18:37:55] <kuudes> well ask holo to tell a dadjoke and explain it
[18:38:22] <feep> "My dog has no nose." "How does he smell?" "Terrible!" This joke exploits the double meaning of "smell", the interlocutor was asking how the dog was able to smell, but he was misinterpreted as asking after the fragrance of the canine. This is revealed in the last word, which uncovers the unexpected meaning, eliciting laughter.
[18:38:29] <gwern> feep: for the dadjokes experiments, see /GPT-3, 'dad jokes' section. for the failure at explanation, see... I forget, but 'rick and morty' is the keyword
[18:38:42] <feep> yeah I think that page is where I formed my opinion on gpt humor
[18:39:10] <gwern> (I mean, it's not like there's many other places)
[18:39:13] <PapuaHardyNet> lol
[18:39:22] <feep> the problem is that explaining the joke requires gpt to understand that a word can have two sustained meanings
[18:39:34] <feep> and hold both of them in mind and switch between the,
[18:39:36] <feep> them*
[18:39:45] <pompolic> wordcelled into being unfunny
[18:39:50] <pompolic> wordceled*
[18:40:01] <PapuaHardyNet> huh? really? are you sure? 
[18:40:20] <feep> yeh p sure
[18:40:33] <PapuaHardyNet> "Joke: 'My dog has no nose.' 'How does he smell?' '?????'"
[18:40:39] <kuudes> I mean, we could have gwern ask openai people or something?
[18:40:41] <feep> gpt can predict that
[18:40:44] <feep> because this is a known joke
[18:40:59] <feep> it's like the six-word story of dad jokes
[18:41:02] <PapuaHardyNet> the "Joke" and the "smell" will give enough context for "Terrible" to be picked, ideally
[18:41:14] <feep> PapuaHardyNet: again, gpt will be able to complete the joke
[18:41:20] <feep> but it won't *understand* how it works.
[18:41:32] <PapuaHardyNet> this is that Chinese room argument all over again
[18:41:36] <feep> no
[18:41:42] <feep> the chinese room can explain chinese rooms
[18:41:46] <pompolic> what does it mean to understand, truly :thinking_emoji:
[18:41:48] <kuudes> well you could tell it that joke and explanation and ask it to tell another
[18:41:51] <pompolic> fwiw i have an idea
[18:41:59] <feep> the point is that it won't be able to elaborate its function
[18:42:02] <feep> which a chinese room can do
[18:42:04] <PapuaHardyNet> huh
[18:42:20] <pompolic> a form of humor i like is, when i read a thing, i visualize it. i make a spurious analogy to other things whose visualizations look similar
[18:42:23] <feep> I'm making a technical point, not a philosophical one
[18:42:25] <PapuaHardyNet> nah, I think it will be able to elaborate on its function
[18:42:30] <feep> try it~
[18:42:33] *** Quits: tarquinius (uid533142@user/tarquinius) (Quit: Connection closed for inactivity)
[18:42:39] <pompolic> as if my brain was applying a transform and connecting things in a different modality
[18:42:41] <feep> if you can make it work, you'll have achieved serious progress on gpt thing
[18:42:41] <PapuaHardyNet> I don't have access to GPT-3 or anything lmao
[18:42:54] <PapuaHardyNet> okay hold on, maybe we have a misunderstanding here
[18:43:21] <PapuaHardyNet> what I mean is "[Joke] The explanation for this joke is: ?????" will be completed with a sensible explanation given enough layers
[18:43:30] <pompolic> GPT doesn't seem to have any such transform available to it, for all i know
[18:43:32] <feep> well, not given the current amount of layers.
[18:43:36] <PapuaHardyNet> s/layers/scaling (where scaling means scaling of data, compute, and params)/
[18:43:59] <PapuaHardyNet> that's all right, then we are very close to agreement
[18:44:04] <feep> which at least is interesting, as it can do lots of other things with the current amount of layers
[18:44:09] <feep> and this is a very basic joke
[18:44:11] <pompolic> although as far as i know it has what is essentially a big matrix of terms?
[18:45:22] <PapuaHardyNet> pompolic: well, the crux of self-attention is that every token is contextualized based on all other tokens
[18:45:34] <pompolic> yeah that's kind of what I'm vaguely recalling
[18:45:38] <pompolic> i don't really know much
[18:45:50] <PapuaHardyNet> no problem, i'm trying to help out here
[18:46:13] <pompolic> to sum up my ramblings: it seems to me that one of the necessary parts of humor is shifting between semantic representations?
[18:46:21] <feep> yeah
[18:46:59] <PapuaHardyNet> that... doesn't seem to be necessary to me? the idea that you cannot have a word that has a value in BOTH semantic dimensions doesn't make sense
[18:47:05] <pompolic> e.g. if it compiled the joke into a semantic representation independent of the tokens, it could serialize it back out as an explanation
[18:47:30] <PapuaHardyNet> imagine terrible has two meanings: [0, 1] and [1, 0]. Why cannot GPT think of the word as [1, 1] to generate the joke?
[18:47:56] <pompolic> no idea
[18:48:01] <PapuaHardyNet> now if you have [1, 1] already, you can use that to generate an explanation based on that
[18:48:18] <PapuaHardyNet> like I can say, yeah look, this vector? it has two dimensions, and has a magnitude of one in each dimension
[18:48:23] <PapuaHardyNet> now extend this analogy to a joke
[18:48:37] <pompolic> this is unironically the shit i laugh at when working
[18:49:18] <pompolic> but anyway
[18:49:22] <PapuaHardyNet> I uh, I apologize? 
[18:49:34] <pompolic> no no, i'm trying to say i think I'm getting your point
[18:49:47] <PapuaHardyNet> oh, I see. that's nice to hear
[18:50:12] <pompolic> it reminded me of a particular experience where i laughed at non-words being punned in a similar manner
[18:50:16] <nshepperd2> there is some level of scaling at which gpt will be able to figure out the typographical meaning of all the bpes by brute force and then it will start being able to understand jokes probably
[18:50:21] <pompolic> anyway, does GPT make a distinction between "token" and "meaning"?
[18:51:10] <pompolic> (and does one need to, in the first place? do semantics exist independent of language?)
[18:51:34] <PapuaHardyNet> pompolic: input string -(tokenizer)-> array of token vectors -(first layer of self attention)-> contextualized tokens
[18:51:56] <PapuaHardyNet> keep that up long enough and you have got tokens contextualized enough that represent... something to the model
[18:52:15] <pompolic> yeah
[18:52:50] <PapuaHardyNet> "do semantics exist independent of language?" there are word based embeddings
[18:52:57] <gurkenglas> could we finetune it on a task where it is to convert back and forth between versions of a text with and without spaces between every two letters?
[18:53:07] <PapuaHardyNet> so word based embeddings mean words of similar meaning are in a similar space
[18:53:49] <PapuaHardyNet> then there is contextualized embedding, where a tokenized word is moved to a space that is similar to another word with similar meaning, given the same context
[18:53:58] <pompolic> opening my mouth does feel like trying to embed a semantic graph into a line of words
[18:54:06] <PapuaHardyNet> nani
[18:54:32] <pompolic> "semantic graph" ie graph of meaning-nodes and edges between them
[18:54:49] <PapuaHardyNet> I see, I see. I cannot look into how I form meaning to words that well
[18:55:04] <pompolic> line of words: text is usually linear, and read in one direction
[18:55:38] <pompolic> so it's a task of embedding a graph into a 1d space where words are points (grammar rules nonwithstanding)
[18:56:41] <PapuaHardyNet> pompolic: okay first off, words are not the most atomic unit
[18:56:47] <PapuaHardyNet> that was a simplification I used
[18:57:02] <pompolic> anyway what I'm getting at is that it *feels* like i work with "meanings" as first-class objects, but i'm not certain this isn't an illusion
[18:57:15] <pompolic> oh, that's an important clarification i think
[18:57:28] <PapuaHardyNet> so you can have characters themselves as fundamental atomic units
[18:57:36] <PapuaHardyNet> or even more fundamental, unicode bytes
[18:57:45] <pompolic> oh god
[18:58:11] <PapuaHardyNet> no no, unicode bytes are what I'm excited about, and gwern doesn't think that is dumb
[18:58:32] <PapuaHardyNet> the problem with the tokenization of GPT-2 and GPT-3 is that they use something called BPE: byte pair encoding
[18:58:42] <PapuaHardyNet> this involves using pairs of subwords as tokens
[18:58:49] <gwern> (bytes are pretty good. I've wondered if one really needs to go to bits, but that's probably overkill)
[18:59:13] <PapuaHardyNet> so you can have something like "God is alive" as tokens like this: ["\nG", "od", " is", " dead", "."]
[18:59:19] <PapuaHardyNet> which sounds dumb, but it gets worse
[18:59:56] <gurkenglas> does finetuning travel on the no-free-lunch frontier?
[19:00:11] <PapuaHardyNet> the biggest problem with this is that you lose precision in modelling language, which results in retardation of higher order skills, especially ones that mainly depend on fine character understanding, like rhythm
[19:00:36] <pompolic> missing the forest for the trees, as it were?
[19:01:02] <PapuaHardyNet> basically brute-force memorizing what to say when they see a superficial pattern, because they cannot see a deeper pattern, yes
[19:02:25] <PapuaHardyNet> anyway, to summarize, the task is of understanding the text, and predicting what will come next, and then formulating that
[19:07:25] <feepbot> <gwern> uploads https://www.gwern.net/docs/prediction/2021-corgnet.pdf
[19:07:26] <Robomot> PDF (18 pages; 295 KB) - Forecasting Skills in Experimental Markets: Illusion or Reality? (Brice Corgnet, Cary Deck, Mark DeSantis, and David Porter) - Management Science 0.0
[19:12:29] <feepbot> <gwern> https://www.reddit.com/r/funny/comments/stfxe8/my_bank_told_me_off/
[19:12:32] <Obormot\Arcturus> So I ordered a circular fluorescent bulb on Amazon, via Prime. It arrived two days later. A week later I ordered the exact same item, from the same seller. It's... going to take a month to arrive??
[19:12:32] <Robomot> My bank told me off : funny (158k votes, 7.4k comments. 39.0m members in the funny community. Welcome to r/Funny, Reddit's largest humour depository.)
[19:13:05] <Obormot\Arcturus> (This might have something to do with the fact that the bulb I ordered has apparently just been discontinued...)
[19:13:23] <Obormot\Arcturus> (... to be replaced with the exact same item)
[19:13:37] <Obormot\Arcturus> ("There is a newer version of this item available", indeed...)
[19:14:44] *** Joins: nullcone (uid11626@id-11626.helmsley.irccloud.com)
[19:18:25] <Obormot\Arcturus> "Twitter has banned Defiant Ls, the account known for posting someone's own screenshots in order to highlight their inconsistency/hypocrisy over time.
[19:18:25] <Obormot\Arcturus> Boomercons and mistake theorists hardest hit.  They are patiently awaiting Twitter's explanation as to "exactly what rule did they violate!!??"" ... lol
[19:18:54] <pompolic> ez, who/whom
[19:23:55] <feepbot> <gwern> https://twitter.com/SeriousPoni/status/1493588545898160134
[19:23:57] <Robomot> Serious Poni (@SeriousPoni): "What's your idea of consciousness?" (http://nitter.actionsack.com/pic/media%2FFLpKrHhaUAAoDXk.jpg)
[19:26:05] <pompolic> my friends are all theorems
[19:26:13] <pompolic> er
[19:26:16] <pompolic> all my friends are theorems
[19:30:05] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 256 seconds)
[19:31:17] <feepbot> <gwern> https://twitter.com/RedPandaEveryHr/status/1493666498065453061 blep
[19:31:19] <Robomot> Red Panda Every Hour! (@RedPandaEveryHr): "" (https://nitter.grimneko.de/pic/media%2FFLqRueiWYAItlm-.jpg)
[19:32:00] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[19:32:51] <PapuaHardyNet> "Ben Kuhn put me into contact with Ajeya Cotra, resulting in the two of us running a whole undergraduate class on Effective Altruism, that included Giving Games to various EA charities that was funded with over $10.000." https://www.lesswrong.com/posts/xaguRyL2NcGsRWj4e/why-you-should-attend-ea-global-and-some-other-conferences
[19:32:51] <Robomot> GreaterWrong version of PapuaHardyNet’s link: https://www.greaterwrong.com/posts/xaguRyL2NcGsRWj4e/why-you-should-attend-ea-global-and-some-other-conferences
[19:32:52] <Robomot> Why you should attend EA Global and (some) other conferences | LessWrong (Many of you know about Effective Altruism and the associated community. It has a very significant overlap with LessWrong, and has been significantly influenced by the culture and ambitions of the community here. One of the most important things happening in EA over the next few months is going to be EA Global, the so far biggest EA and …)
[19:32:56] <PapuaHardyNet> I had no idea Ben Kuhn is a rat
[19:37:57] <feepbot> <gwern> https://twitter.com/danielrussruss/status/1493819694628753412
[19:37:58] <Robomot> Daniel Russell (@danielrussruss): "`a croissant arm chair. an arm chair that is imitating a croissant.`" (http://bird.trom.tf/pic/media%2FFLsdCSIUYAUSuiW.jpg)
[19:42:59] <feepbot> <gwern> https://twitter.com/elonmusk/status/1493358044989767683
[19:43:01] <Robomot> Elon Musk (@elonmusk): "Over 250k Starlink user terminals"
[19:44:25] <gurkenglas> now thats a tweet to transmit to like 10 years ago
[19:46:05] <ggreer> https://polarisprogram.com/dawn/ more civilian spaceflight this year, now with EVA
[19:46:05] <Robomot> Polaris Dawn (As soon as the fourth quarter of 2022, SpaceX’s Falcon 9 rocket will launch the Polaris Dawn mission from historic Launch Complex 39A at the Kennedy Space Center in Florida.)
[19:48:05] <ggreer> the plan is to eventually use starship for some of these missions. also two of the crew are spacex employees
[19:53:06] <feepbot> <gwern> https://twitter.com/danielrussruss/status/1493832335707443202
[19:53:08] <Robomot> Daniel Russell (@danielrussruss): "`my daughter drew something really weird... I think I might need to take her to a psychiatrist`" (https://nitter.silkky.cloud/pic/media%2FFLsoiojVIAM33zG.jpg)
[19:58:08] <feepbot> <gwern> https://twitter.com/big_dream_io/status/1493815802448908288
[19:58:10] <Robomot> The Big Dream (@big_dream_io): "this potato won't stop screaming but it's so adorable that i can't intervene" (http://nitter.eu/pic/media%2FFLsZhFUUcAEhvqB.png)
[20:03:14] <feepbot> <gwern> https://twitter.com/Letter_Library/status/1493844763212197894 Obormot\Arcturus: the inner line motif on this blackletter is interesting
[20:03:15] <Robomot> Letter Library (@Letter_Library): "Wieynck-Gotisch Initials, Schriftguß AG, Dresden" (https://nttr.stream/pic/media%2FFLsz21dXEAE1c8k.jpg)
[20:03:37] <kuudes> gwern, btw could robomot be put to your subscribers in twitter so that the channel could see your tweets?
[20:03:59] <gwern> probably, at considerable more complication (twitter is probably looking for logged in bots too)
[20:04:51] <kuudes> hmm
[20:04:58] <kuudes> good to hear you have considered it
[20:09:59] <feepbot> <gwern> https://twitter.com/CatWorkers/status/1493916207866654725 quanticle: if I fits i sits
[20:10:01] <Robomot> cats with jobs (@CatWorkers): "(📸 @kokonananya)" (http://twitter.censors.us/pic/media%2FFLt0yAhXIAEhiH4.jpg)
[20:13:51] <Obormot\Arcturus> gwern: Hm, that is intereting, yeah
[20:18:53] <feepbot> <gwern> https://twitter.com/Birdyword/status/1493811335712632834 another US-only 'universal trend'
[20:18:55] <Robomot> Mike Bird (@Birdyword): "Hard to buy this as an explanation in and of itself since traffic deaths dropped in 2020 almost everywhere in the developed world, where the pandemic was also going on. / (% change in total road deaths in 2020, relative to 2010-19 average)" (http://bird.trom.tf/pic/media%2FFLsVKIwaQAEy2nU.jpg)
[20:19:23] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 256 seconds)
[20:19:35] <PapuaHardyNet> okay, so this EA Global event -- I don't know much about it. Is there anything I need to know before I decide that I should attend it?
[20:19:48] <PapuaHardyNet> there's not much information about it online either
[20:20:52] <kuudes> gwern, is that just traffic normalizing
[20:25:53] <feepbot> <gwern> https://twitter.com/holman/status/1493333452866797568
[20:25:55] <Robomot> Zach Holman (@holman): "The /r/ubiquiti subreddit has been going back and forth the last few days on who can make the shortest ethernet cable and it’s been seriously cracking me up." (http://twitter.censors.us/pic/media%2FFLli2KyVIAQkOHc.jpg)
[20:30:56] <feepbot> <gwern> '“The reality is that the vast majority of Chinese won’t have the opportunity to become Eileen Gu,” Li Yinuo, founder of a prominent education company in Beijing, wrote in an article. But the tragedy of the chained woman, she wrote, could happen to anyone. A few hours later, her article was deleted.'
[20:30:56] <feepbot> https://www.nytimes.com/2022/02/15/business/china-eileen-gu-peng-shuai-chained-woman.html
[20:30:57] <Robomot> Who Is the Real China? Eileen Gu or the Chained Woman? - The New York Times (The women’s starkly different circumstances — celebrated vs. silenced — reflect that to the Chinese state everyone is a tool that serves a purpose until it does not.)
[20:34:07] *** Quits: two2thehead (~user@124.195.205.14) (Ping timeout: 256 seconds)
[20:34:46] *** Joins: two2thehead (~user@124.195.205.14)
[20:35:16] *** Joins: schmudde (~schmudde@public.toolboxoffice.it)
[20:35:57] <feepbot> <gwern> 'Not too many surprises in the state data, but worth noting that California now has a lower TFR than the rust belt and lower even than New York, which is probably related in part to California's semi-intentional housing shortage.' https://twitter.com/AccurateCaption/status/1493453362444001281
[20:35:59] <Robomot> Paleolithic HVAC Technician (@AccurateCaption): "Wait, the final US birth data for 2020 was released just a week ago? Why didn't anyone tell me? Looking through it, major point is that the TFR declined to 1.64, the lowest level ever recorded. Birth rates for all races and age groups declined."
[20:39:37] <two2thehead> kuudes, s0ph1a feep : And people *still* worry about uncontrollable population growth
[20:43:26] <gwern> Obormot\Arcturus: I'm thinking of truncating dates to just YYYY-MM instead of YYYY-MM-DD where available. when does the exact day add anything to an annotation? for medrxiv/biorxiv/arxiv papers, they're submitted a day (or three) ahead, for most papers they may well have been submitted several *years* before, journal dates tend to be lies regardless (lots of 'YYYY-01-01' going around, most...
[20:43:32] <gwern> ...obviously)... even for daily media links like nytimes.com I can't see how often the user actually cares. year/month, absolutely, but an article about transplanting a pig heart into a human, does it really matter if it was January 13th or January 14th 2022? 2022, yes, January, yes, but 13 vs 14?
[20:44:45] <gwern> by the time a reader sees it in a gwern.net page or newsletter, it seems like it's basically just 3 wasted characters in prime real-estate, often misleading ones to boot
[20:45:22] <gwern> at the very least, I think I should specialcase 'YYYY-01-01' to just 'YYYY' because it's super untrustworthy. maybe truncate 'YYYY-MM-01' to 'YYYY-MM' in general
[20:46:17] <two2thehead> gwern, i presume you are familiar with YYYY-{1-365}?
[20:46:44] <kuudes> that will reduce information if in future someone does metaresearch per your data?
[20:46:47] <gwern> two2thehead: I don't think I've ever seen that in the wild. sounds like a bad idea. what date is 'YYYY-12'? is it at the beginning of the year, or the end?
[20:47:09] <two2thehead> you could put a zero in it. But yes, I've never seen it in the wild either
[20:47:10] <gwern> kuudes: people doing metaresearch shouldn't be relying on these dates in the first place. a lot of them are misleading
[20:47:18] <Obormot\Arcturus> gwern: Not a terrible idea, though I'll note that YYYY-MM is an unusual format and would confuse people. In such a case I'd move to month shortnames
[20:48:21] <kuudes> YYYY exists, yes, but I have not heard much use of YYYY-MM either
[20:48:42] <kuudes> there are a lot of options for year+number: month, quarter, half, day etc
[20:48:50] <kuudes> week as well
[20:48:51] *** Quits: schmudde (~schmudde@public.toolboxoffice.it) (Ping timeout: 256 seconds)
[20:50:36] <gwern> short names like 'Aug 2021' lose the character advantage. hm.
[20:50:54] <gwern> drop months entirely, and tooltip the full date?
[20:51:32] <gwern> no possibility of confusion there, even shorter, gwern.net users know that tooltips are pervasive
[20:54:56] <zebrask> I think the ISO8601 format is YYYY-D{1-365}
[20:55:19] <zebrask> Oh no wait it's YYYY-DDD
[20:55:31] <zebrask> The ones that have letters are the ones with weeks.
[20:55:48] <gwern> ah. so it disambiguates with a leading 0. '2020-012' is obviously jan 12th, not december
[20:56:15] <two2thehead> kuudes, s0ph1a feep : Mobile internet has killed the tooltip. Change my mind
[20:56:20] <gwern> https://en.wikipedia.org/wiki/Ordinal_date
[20:56:20] <Robomot> Ordinal date - Wikipedia (An ordinal date is a calendar date typically consisting of a year and a day of the year ranging between 1 and 366 (starting on January 1), though year may sometimes be omitted. The two numbers can be formatted as YYYY-DDD to comply with the ISO 8601 ordinal date format.)
[20:56:35] <zebrask> I think "Aug '21" is unambiguous.
[20:56:40] <PapuaHardyNet> 366 days?
[20:56:46] <PapuaHardyNet> oh, leap year?
[20:56:49] <two2thehead> PapuaHardyNet, leap
[20:56:50] <two2thehead> year
[20:56:54] <PapuaHardyNet> :)
[20:56:54] <two2thehead> yeah
[20:57:31] <Robomot> [Less Wrong [frontpage]] Compute Trends Across Three eras of Machine Learning by Jsevillamol - https://www.greaterwrong.com/posts/XKtybmbjhC6mXDm5z/compute-trends-across-three-eras-of-machine-learning
[20:57:43] *** Joins: phill (uid429774@id-429774.ilkley.irccloud.com)
[20:57:59] <Obormot\Arcturus> gwern: Loses the character advantage but gains readability and clarity, worth doing anyway
[20:58:19] <Obormot\Arcturus> gwern: My vote is for month shortname / year (when relevant), just year (if appropriate)
[20:58:22] <kuudes> if you want to shorten, yy instead of yyyy is often usable?
[20:58:45] <two2thehead> kuudes, gwern does something called long content
[20:58:46] <kuudes> I like month numbers generally
[20:59:00] <kuudes> I don't recall month names in english that well
[20:59:05] <zebrask> kuudes: Except we're in the first 31 years of this century, so "Aug 21" can be ambiguous.
[20:59:12] <Obormot\Arcturus> kuudes: Bold of you to assume that gwern.net won't still be around in 3022
[20:59:15] <two2thehead> it apparently involves putting a zero ahead of the year value. So 02022 Jan. etc
[20:59:27] <kuudes> Obormot\Arcturus, I am willing to throw the future under the bus in there
[20:59:31] <Obormot\Arcturus> Shameful
[20:59:39] <gwern> kuudes: yeah, I dislike 'YY on principle. I don't actually cite *that* much stuff from 1800-1822/1900-1922, but I feel like it is more Long Contenty to use full years, even if I won't go as far as Long Now in prefixing a leading 0 :)
[21:00:00] <kuudes> well I guess I would just default to iso8601 then?
[21:00:13] <kuudes> yyyy-mm-dd and let others deal with day redundancies
[21:00:24] <gwern> Obormot\Arcturus: mm. 'when relevant' is a difficult stipulation there
[21:00:30] * Obormot\Arcturus shrug
[21:00:31] <two2thehead> kuudes, yeah that's my preference too
[21:00:36] <Robomot> [Less Wrong [frontpage]] [Intro to brain-like-AGI safety] 4. The “short-term predictor” by Steven Byrnes - https://www.greaterwrong.com/posts/Y3bkJ59j4dciiLYyw/intro-to-brain-like-agi-safety-4-the-short-term-predictor
[21:00:47] <Robomot> [Less Wrong [frontpage]] Why Doesn’t Healthcare Improve Health? by George - https://www.greaterwrong.com/posts/ntRZqcL9Xopv5NwiC/why-doesn-t-healthcare-improve-health
[21:00:58] <Robomot> [Less Wrong [frontpage]] How do you think about mildly technical people trying to advance science and technology? by Cui - https://www.greaterwrong.com/posts/BAPfD6KjoHmjfraXC/how-do-you-think-about-mildly-technical-people-trying-to
[21:01:09] <Robomot> [Less Wrong [frontpage]] REPL’s: a type signature for agents by scottviteri - https://www.greaterwrong.com/posts/kN2cFPaLQhExEzgeZ/repl-s-a-type-signature-for-agents
[21:01:20] <Robomot> [Less Wrong [frontpage]] How harmful are improvements in AI? + Poll by tilker - https://www.greaterwrong.com/posts/uABbabv5WPZmwzCmP/how-harmful-are-improvements-in-ai-poll
[21:06:21] <feepbot> <gwern> https://twitter.com/LucreSnooker/status/1493770106446364681
[21:06:22] <Robomot> Lucre Snooker (@LucreSnooker): "my poor innocent wife just said “it’s weird how the Times keeps telling me to eat bugs” without appreciating the cultural/political valence of such sentiments"
[21:06:56] <PapuaHardyNet> misread "community organising" as "community orgasming" on twitter
[21:07:14] <two2thehead> :V
[21:08:49] <zebrask> I really need to consolidate all the data from my old backups.
[21:09:21] <zebrask> I was just nostalgically looking at the wayback machine for my old blog and realized I had a bunch of stuff on there, more than I remembered.
[21:10:28] <two2thehead> can you upload to archive.org I think some people do that
[21:10:30] <zebrask> I thought I might put the archive back up, but not everything got into the IA as far as I can tell and the hosting for that lapsed a decade ago. I remember downloading everything from that account before I let it lapse, but now I can't find the files.
[21:11:41] <zebrask> Found a bunch of stuff that's not on my newer computers, though. I used to be so organized. Now I've got slightly different overlapping sets of photos in a bunch of different drives, random stuff like that.
[21:12:08] <zebrask> I also can't find the backup I downloaded from facebook when I deleted my account. I have the e-mail saying my download is ready, but the zip file is nowhere to be found.
[21:12:41] <gwern> community organ-ising: you show up to EAG and particularly healthy but unproductive members find their organs donated to sick africans
[21:12:47] <zebrask> It's probably somewhere, I don't remember ever actually getting any data loss, just like... horribly disorganized.
[21:13:22] <gwern> (how many big zip files from that era could you possibly have in your home dir?)
[21:14:01] <two2thehead> excellent question
[21:14:14] <two2thehead> heck you could just sort *.zip files by created date
[21:14:20] <gwern> Obormot\Arcturus: how about, YYYY-01-01 gets converted at compile time to just YYYY, and the JS code converts YYYY-MM-DD to <span title="YYYY-MM-DD">YYYY</span>?
[21:14:44] <zebrask> I don't have any is the thing! Most of the data hasn't made it from computer to computer, it just lives in some encrypted backup or on one or more backup drives I have sitting in a waterproof box.
[21:15:15] <zebrask> It's also possible that I unzipped it into a folder somewhere.
[21:15:53] <zebrask> There are a couple of external hard drives here that require an adapter I haven't found yet, so it might be on one of those.
[21:16:46] <gwern> sounds like those aren't 'backups', they're 'the only copy'
[21:16:59] * gwern wonders idly how much zebrask has already lost
[21:17:04] <zebrask> Well, they were backups when I had the original computer 😛
[21:17:16] <zebrask> Though I also think I have the original computers sitting in a pile somewhere.
[21:17:53] <zebrask> I just have a lot more confidence that the external hard drives will mount than that computers untouched for a decade will work when plugged in.
[21:20:00] <gwern> surely the question is about the *internal* hard drives working?
[21:20:53] <ardent[m]> PapuaHardyNet: so that's why the topic is popular among rat types
[21:21:20] <gwern> they're probably orgasming at vibe camp rn ;_;
[21:21:27] *** Joins: schmudde (~schmudde@5.171.241.64)
[21:21:42] <ardent[m]> Vibe camp totally sounds like a sex toy exhibition
[21:22:18] <two2thehead> lol
[21:22:24] <gwern> I assume there will be those, unless they set up the sex orgy pavilion and everyone sits around in their masks earnestly discussing international trade policy
[21:22:49] <two2thehead> 'I went to an orgy and a debate on international trade policy broke out'
[21:23:11] <gwern> every orgasmizer's nightmare
[21:23:18] <two2thehead> Right up there with the 'I went to a fight and a hockey game broke out'
[21:24:58] <ardent[m]> two2thehead: lol I made that exact joke on rat Discords a couple of times
[21:25:21] <two2thehead> great minds :V
[21:30:22] <feepbot> <gwern> https://www.biorxiv.org/content/10.1101/2022.02.13.480245v1.full
[21:30:24] <Robomot> Clock Work: Deconstructing the Epigenetic Clock Signals in Aging, Disease, and Reprogramming | bioRxiv (Epigenetic clocks have come to be regarded as powerful tools for estimating aging. However, a major drawback in their application is our lack of mechanistic understanding. We hypothesize that uncovering the underlying biology is difficult due to the fact that epigenetic clocks are multifactorial composites: …)
[21:32:01] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[21:34:01] <gwern> Obormot\Arcturus: ie. https://pastebin.com/HNPJ8GKd
[21:34:02] <Robomot> truncate dates in popins/popups - Pastebin.com (Pastebin.com is the number one paste tool since 2002. Pastebin is a website where you can store text online for a set period of time.)
[21:36:27] *** Quits: adiabatic (~adiabatic@user/adiabatic) (Ping timeout: 256 seconds)
[21:36:59] <Obormot\Arcturus> gwern: I mean, I guess. But you know nobody's gonna read those full dates in the tooltips, right
[21:38:05] <gwern> Obormot\Arcturus: I don't want to delete them entirely because like authors we can list them in full on the tag-directories & link-bibliographies, but I also don't want to just drop them. putting them in tooltips is the gwern.net-y way
[21:39:58] <Obormot\Arcturus> Fair enough I guess. Yeah, that code looks sensible enough
[21:43:13] <gwern> ok
[21:44:08] <two2thehead> kuudes, s0ph1a feep : "“The invention of spectacles increased the intellectual life of professional workers by fifteen years or more,” write Macfarlane and Martin. Eyeglasses likely abetted the surge of knowledge in Europe from the fourteenth century on. “Much of the later work of great writers such as Petrarch would not have been completed without spectacles. The active life of skilled craftsmen, often engaged in very detailed close work
[21:44:08] <two2thehead> , was also almost doubled,” Macfarlane and Martin maintain." '[Macfarlane and Martin, The Glass Bathyscaphe, 1747–752]'
[21:44:16] <two2thehead> I hadn't even considered that
[21:44:35] <two2thehead> We take spectacles/eyeglasses for granted nowadays
[21:47:52] <gwern> 15 years is oddly precise for a book. I wonder what they're citing
[21:48:43] <gwern> http://libgen.rs/book/index.php?md5=990B498C3ED351274AE184BE42F007EE ah, changed title
[21:48:44] <Robomot> Library Genesis: Alan Macfarlane, Gerry Martin - Glass: A World History (Library Genesis is a scientific community targeting collection of books on natural science disciplines and engineering.)
[21:49:11] <gwern> whoa this is a shitty scan
[21:49:24] <gwern> ugh even has their finger
[21:49:31] <gwern> no OCR either
[21:49:59] <gwern> and like 25 entries in the index for 'spectacle' -_-
[21:51:43] * gwern adds this to the scan list because this copy is just too garbage
[21:53:40] <gwern> (I am a sucker for any kind of technology-improving-intellectual-productivity or the-past-was-garbage cite like that, but I'm not looking through 25+ pages of a scan with someone's thumb in it)
[21:58:40] <feepbot> <gwern> https://akarlin.substack.com/p/regathering-of-the-russian-lands?r=abvmd karlin makes the pro-invasion case
[21:58:41] <Robomot> Regathering of the Russian Lands - by Anatoly Karlin (The Empire, Long Divided, Must Unite)
[21:59:09] <Obormot\Arcturus> ("This list of Russian krais is incomplete. You can help by expanding it...")
[22:03:01] *** Joins: thoros (~thoros@62-46-56-232.adsl.highway.telekom.at)
[22:04:09] <feepbot> <gwern> https://www.epistem.ink/p/why-doesnt-healthcare-improve-health?r=c5fr0
[22:04:10] <Robomot> Why Doesn’t Healthcare Improve Health? - by George (It’s almost a non-sequitur to ask whether or not a giant industry, with a well-defined goal, churning double-digits of GDP, actually works. If pressured into an experiment we could easily design one that shows airplanes deliver people to destinations over 3000km away faster than trains (boarding time and travel to airport included). We could similarly …)
[22:07:03] *** Quits: schmudde (~schmudde@5.171.241.64) (Ping timeout: 256 seconds)
[22:09:11] <feepbot> <gwern> uploads https://www.gwern.net/docs/economics/2022-barrios.pdf
[22:09:12] <Robomot> PDF (22 pages; 656 KB) - Launching with a parachute: The gig economy and new business formation (John M. Barrios) - labor economics
[22:12:43] *** Joins: voltage (voltage@user/voltage)
[22:14:13] <feepbot> <gwern> uploads https://www.gwern.net/docs/spaced-repetition/2018-bisra.pdf
[22:14:15] <Robomot> PDF (23 pages; 532 KB) - Inducing Self-Explanation: a Meta-Analysis (Kiran Bisra) - cognitive psychology
[22:15:48] *** Quits: voltage_ (voltage@user/voltage) (Ping timeout: 240 seconds)
[22:19:16] <feepbot> <gwern> uploads https://www.gwern.net/docs/spaced-repetition/2005-calinjageman.pdf
[22:19:17] <Robomot> PDF (21 pages; 410 KB) - The Role of Encoding in the Self-Explanation Effect (Robert J. Calin-Jageman, Hilary Horn Ratner) - cognitive psychology
[22:24:18] <feepbot> <gwern> https://twitter.com/ArtirKel/status/1493972282212978691 heh
[22:24:19] <Robomot> José Luis Ricón Fernández de la Puente (@ArtirKel): "Happy mask freedom day, CA!"
[22:28:34] *** Joins: adiabatic (~adiabatic@user/adiabatic)
[22:29:21] <feepbot> <gwern> https://twitter.com/Jane_Li911/status/1493792190052519937 also an excuse for intrasexual aggression
[22:29:23] <Robomot> Jane Li (@Jane_Li911): "Douban users (mostly females) are posting info abt the chained Xuzhou woman under false titles such as "Why Elieen Gu is not good looking" and "my bf cheated what should I do"--another creative yet sad way for Chinese netizens to dodge censors"
[22:33:04] <rmmh> https://twitter.com/deathcarpets/status/1478810505494077440
[22:33:06] <Robomot> lilith (@deathcarpets): "several days ago a co worker told me his daughter’s name is “Rey, NOT because of star wars” which he was very adamant about. Yesterday i found out it’s because her name is actually Rei and it IS because of Evangelion"
[22:38:07] <feepbot> <gwern> https://twitter.com/krishnanrohit/status/1493874367272468481
[22:38:09] <Robomot> rohit (@krishnanrohit): "4yo in tears because he dislikes the concept of death, and we can't guarantee that we'll stop dying from ever happening, even many years from now and even at the end of his life."
[22:38:50] <two2thehead> gwern, \O/
[22:39:03] <two2thehead> I did my small part in influencing gwern's work in the world
[22:44:02] *** Quits: ecx (~user@user/ecx) (Ping timeout: 240 seconds)
[22:44:04] <feepbot> <gwern> https://twitter.com/Norod78/status/1493979102621179911
[22:44:05] <Robomot> Doron Adler (@Norod78): "ruDALL-E Muppets ☺️" (https://nitter.1d4.us/pic/enc/bWVkaWEvRkx1dDFEcFgwQVV2YUltLmpwZw==)
[22:44:57] <ggreer> I've noticed more people not wearing masks indoors lately. washington & oregon still have mask mandates but now that even california's dropping theirs, people are starting to rebel
[22:45:29] <spxtr> I stopped wearing my mask indoors despite living in the (only) bay area county with a mask mandate.
[22:48:40] <spxtr> It's a strange split. Right now ~90% of people wear their masks indoors, and still ~50% wear them outdoors.
[22:49:18] <adiabatic> I wonder what the numbers will be when I go back to Trader Joe's
[22:51:49] *** Quits: voltage (voltage@user/voltage) (Quit: Leaving)
[22:54:23] <feepbot> <gwern> https://twitter.com/Bodegacats_/status/1493801490430967808 quanticle: 'smoke' is definitely one of the best fur colors
[22:54:24] <Robomot> Bodega Cats (@Bodegacats_): "" (http://nitter.alefvanoon.xyz/pic/enc/bWVkaWEvRkxzTWlaYVgwQVFWd0RVLmpwZw==)
[22:55:01] *** Joins: gproto23 (~gproto23@user/gproto23)
[22:56:43] <two2thehead> kuudes, s0ph1a feep : I'm trying to avoid pasting about a third of the article here, but it's hard https://www.bbc.com/news/world-asia-60384651
[22:56:44] <Robomot> Single's Inferno: Why 'fake' rich girl Song Ji-a enraged South Korea - BBC News (Song Ji-a shot to fame on Netflix show Single's Inferno, but then had a spectacular fall from grace.)
[22:57:09] <two2thehead> tl;dr social climbers be crazy when you have so much societal pressure to succeed
[22:57:54] <gwern> SK beauty standards have become so strange
[22:58:12] <two2thehead> no kidding
[22:58:26] <two2thehead> I've learned a LOT just by reading this one article 
[22:58:31] <two2thehead> "She was cancelled for wearing fake designer clothes - barely considered a sin in the West, but it destroyed Song Ji-a's career in her homeland. The scandal however wasn't just another tale of a cancelled celebrity - it tapped into a deeper social angst felt by young South Koreans.
[22:58:32] <two2thehead> "In the finale, she had three of the show's five men lined up on a beach vying for her hand. She was the breakout star.
[22:58:32] <two2thehead> "The social media influencer had already been popular in South Korea prior to the show. But her following soared after her Netflix debut - to 3.7 million followers on Instagram and nearly two million on YouTube.
[22:58:32] <two2thehead> "That first week of January 2022 represented the peak of her fame. Her downfall came soon after."
[22:59:21] <two2thehead> "Internet sleuths began to pick her apart. They accused her of wearing fake designer clothes. They seized on a pink Chanel knit that was slightly the wrong shade.
[22:59:22] <two2thehead> "Netizens pointed out other elements of her wardrobe - and within days she had to respond to the allegations.
[22:59:22] <two2thehead> "Song Ji-a admitted that she had worn knock-offs. But she claimed to have not known they were copies, saying she had bought them because they looked "pretty".
[22:59:22] <two2thehead> "The flimsy explanation failed to quell the rage."
[22:59:26] <two2thehead> Rage.
[23:00:16] *** Quits: thoros (~thoros@62-46-56-232.adsl.highway.telekom.at) (Quit: WeeChat 3.4)
[23:00:17] <two2thehead> "Netizens delved further into her background, poring over her previous YouTube videos. They earmarked suspect goods and questioned whether she owned the luxury apartment she lived in.
[23:00:17] <two2thehead> And then there were the Chinese videos, clips where she said she was learning Mandarin, and where she referred to the national Korean dish kimchi as pao cai, a Chinese term for pickled vegetables.
[23:00:17] <two2thehead> Fans accused her of pandering to the Chinese market, with some even calling her a traitor.
[23:00:17] <two2thehead> Other Korean TV shows began editing out her cameos. And her celebrity friends, other actors and influencers, deleted their own Instagram pictures showing them hanging out with Ji-a.
[23:00:19] <two2thehead> A week after her first apology, Ji-a posted another video where she said she "deeply regretted her actions", calling herself "pathetic". "
[23:00:27] <two2thehead> What the heck is wrong with these people? O_o
[23:00:50] <two2thehead> the social media fangirls/boys, not ordinary koreans
[23:02:34] <two2thehead> "But actually the biggest crime alleged was that she was a fake - and that she pretended to be something that she is not. That was the issue that kept being raised time and time again," said Se-Woong Koo, the editor of Korean Exposé, a subscription-based newsletter focusing on contemporary Korea.
[23:02:34] <two2thehead> "While non-Korean fans just saw her as just a luxury influencer, Koreans believed she had presented as something more. Many local followers had thought her to be a geumsujeo or "gold spoon".
[23:02:34] <two2thehead> Derived from the English expression that refers to those born into privilege "with a silver spoon in their mouth", a "gold spoon" is someone from the top 1% of high-income households in South Korea.
[23:02:34] <two2thehead> It's often used to refer to the children of super-rich families. The term "dirt spoons" represents the other end of the spectrum."
[23:02:42] <two2thehead> too lazy to paste the rest
[23:02:46] <two2thehead> worth a read though
[23:02:56] * two2thehead saves it under his well written article examples
[23:07:56] <feepbot> <gwern> 'At one point, Schanze told Benson that the plea agreement made him into an "evil, horrible person," and he's not that. Schanze, 45, was charged in October 2014. The charges followed a federal investigation into an online video, which surfaced in 2013 and appeared to show a paraglider pilot kicking a soaring barn owl and boasting about it.'
[23:07:57] <feepbot> https://archive.sltrib.com/article.php?id=2386737&itype=CMSID
[23:07:57] <Robomot> 'Super Dell' Schanze pleads guilty to harassing an owl - The Salt Lake Tribune
[23:11:35] *** Quits: Lord_of_Life (~Lord@user/lord-of-life/x-2819915) (Ping timeout: 250 seconds)
[23:11:44] *** Joins: Lord_of_Life_ (~Lord@user/lord-of-life/x-2819915)
[23:12:59] <feepbot> <gwern> https://youtu.be/zk4teJwQ6FI?t=277
[23:13:00] <Robomot> Steve Henry 6 FOOT takeoff in a Highlander - YouTube (00:06:25) (Wild West Aircraft/ Just Aircraft Highlander with Edge Performance EPeX Yamaha power landing and taking off short!Kevin Quinn is sponsoring a video STOL comp...)
[23:14:32] *** Lord_of_Life_ is now known as Lord_of_Life
[23:14:38] <phill> https://spectrum.ieee.org/bionic-eye-obsolete
[23:14:39] <Robomot> Their Bionic Eyes Are Now Obsolete and Unsupported - IEEE Spectrum (These early adopters found out what happened when a cutting-edge marvel became an obsolete gadget... inside their bodies.)
[23:14:42] <phill> Jeez
[23:19:43] <feepbot> <gwern> https://arxiv.org/abs/2202.06991#google
[23:19:44] <Robomot> [2202.06991] Transformer Memory as a Differentiable Search Index (In this paper, we demonstrate that information retrieval can be accomplished / with a single Transformer, in which all information about the corpus is encoded / in the parameters of the model. To this end, we introduce the Differentiable / Search Index (DSI), a new paradigm that learns a text-to-text model that maps / string queries directly to …)
[23:24:02] <two2thehead> kuudes, s0ph1a feep gwern RiversHaveWings and whoever else likes C : https://www.youtube.com/watch?v=tas0O586t80
[23:24:03] <Robomot> Program in C - YouTube (00:00:52) (Someone in Discord linked to this tweet and I figured I'd take a stab at singing it in my totally not awful fake accent: https://twitter.com/bhilburn/status/...)
[23:25:22] *** Joins: Fusxfaranto (~Fusxfaran@c-67-188-46-246.hsd1.ca.comcast.net)
[23:29:03] <feepbot> <gwern> https://www.econlib.org/the-dehiring-of-richard-lewontin/
[23:29:04] <Robomot> The Dehiring of Richard Lewontin - Econlib (Remember “dehiring“? Dehiring is when, instead of firing a bad employee, you conspire with him to get him a new job someplace else. As this how-to guide explains: Managing a problematic employee is time consuming and negatively affects the cohesion of your fitness team. Unfortunately, hoping that a troublesome employee will just go away is […])
[23:34:03] <feepbot> <gwern> https://www.bloomberg.com/news/articles/2022-02-16/jho-low-s-wild-nights-on-display-with-250-000-for-dicaprio-fox?sref=1kJVNqnU better to live like a king for a day...
[23:34:05] <Robomot> Jho Low’s Wild Nights on Display: $250,000 for DiCaprio, Fox - Bloomberg (A quarter of a million dollars for Leonardo DiCaprio. A $385,773 bar tab. Five grand for “model wrangling.”)
[23:39:06] <feepbot> <gwern> https://twitter.com/boztank/status/1493661545426870277 ...
[23:39:08] <Robomot> Boz (@boztank): "Fun fact: Metamates was coined by none other than Douglas Hofstadter himself after an employee cold emailed him for ideas after our rebrand. I love it! / Also the saying is a reference to a Naval phrase which Instagram has used for a while "Ship, Shipmates, Self""
[23:42:17] <kuudes> jailmates?
[23:46:52] <two2thehead> cellmates is more common imo
[23:51:53] <feepbot> <gwern> https://www.nature.com/articles/s41586-021-04301-9
[23:51:54] <Robomot> Magnetic control of tokamak plasmas through deep reinforcement learning | Nature (Nuclear fusion using magnetic confinement, in particular in the tokamak configuration, is a promising path towards sustainable energy. A core challenge is to shape and maintain a high-temperature plasma within the tokamak vessel. This requires high-dimensional, high-frequency, closed-loop control using magnetic actuator coils, …)
[23:53:13] <two2thehead> huh. the fact that deep learning-based reinforcement learning is a)commonly used and b)used for physics experiments AND people don't consider it astounding, is itself astounding
[23:58:14] <feepbot> <gwern> https://www.ft.com/content/0deba2c8-4a94-442e-8268-31586a5fb1ab copenhagen ethics
[23:58:14] <Robomot> How Unilever’s tea business became a test of private equity’s conscience
