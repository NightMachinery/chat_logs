[00:01:16] <hams> aaguys, its working
[00:01:22] <hams> databaes are being copied
[00:01:28] <hams> i used command line rather than pgadmin
[00:01:34] <hams> pgadmin was giving me connection issues
[00:02:31] *** Quits: carragom (~textual@201.204.94.76) (Quit: My iMac has gone to sleep. ZZZzzz…)
[00:02:48] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[00:03:18] *** Joins: sliss (~sliss@109.136.165.60)
[00:05:32] *** Quits: hams (~hams@user/hams) (Read error: Connection reset by peer)
[00:05:40] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[00:05:48] *** Joins: Nekomander (~BadAdvice@user/badadvicecat)
[00:06:52] *** Quits: BadAdviceCat (~BadAdvice@user/badadvicecat) (Ping timeout: 272 seconds)
[00:09:11] *** Joins: ur5us_ (~ur5us@2406:e002:6dd8:5f01:a4b3:dc81:c8c:8966)
[00:10:50] *** Quits: telser (~AdminUser@user/telser) (Remote host closed the connection)
[00:12:02] *** Joins: telser (~AdminUser@2601:c0:c300:7620::1d06)
[00:14:56] *** Quits: Numero (~Nouser@99-157-54-155.lightspeed.tukrga.sbcglobal.net) (Quit: Leaving)
[00:16:20] *** Joins: jazzy (~jaziz@user/jaziz)
[00:16:40] <ilmari> johto: what immutable abuse? we got rid of the need for that by doing WITH … MATERIALIZED
[00:17:22] *** Quits: shiranaihito (~textual@123-192-192-149.dynamic.kbronet.com.tw) (Quit: My MacBook Air has gone to sleep. ZZZzzz…)
[00:17:49] *** Quits: ur5us_ (~ur5us@2406:e002:6dd8:5f01:a4b3:dc81:c8c:8966) (Remote host closed the connection)
[00:18:06] *** Quits: DNH (~DNH@2a02:8108:1100:16d8:bca1:a272:d62b:37ab) (Ping timeout: 252 seconds)
[00:18:07] *** Joins: ur5us_ (~ur5us@2406:e002:6dd8:5f01:a4b3:dc81:c8c:8966)
[00:18:57] <johto> oh.
[00:18:59] <johto> we did? cool
[00:19:49] *** Quits: ferr_ (~ferr@185.65.50.97) (Ping timeout: 240 seconds)
[00:20:01] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Remote host closed the connection)
[00:21:38] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[00:22:55] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[00:22:56] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[00:23:24] *** Joins: sliss (~sliss@109.136.165.60)
[00:25:15] *** Quits: immibis (~hexchat@62.156.144.218) (Ping timeout: 256 seconds)
[00:25:49] *** Joins: fercell (~ferr@185.65.50.80)
[00:29:45] *** Quits: eroux (~eroux@102-65-81-186.ftth.web.africa) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[00:32:23] *** Quits: funhouse (~funhouse@user/funhouse) (Quit: Client closed)
[00:33:18] *** Quits: telser (~AdminUser@2601:c0:c300:7620::1d06) (Changing host)
[00:33:18] *** Joins: telser (~AdminUser@user/telser)
[00:33:48] *** Quits: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net) (Ping timeout: 240 seconds)
[00:33:56] *** Quits: telser (~AdminUser@user/telser) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[00:34:05] *** Joins: Rashad_ (~textual@2a01:9700:131e:a000:380e:f024:1b6f:38bb)
[00:34:11] *** Joins: telser (~AdminUser@user/telser)
[00:36:31] *** Quits: telser (~AdminUser@user/telser) (Client Quit)
[00:36:35] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 240 seconds)
[00:37:24] *** Joins: telser (~AdminUser@user/telser)
[00:37:27] *** Quits: foul_owl (~kerry@207.244.125.36) (Ping timeout: 250 seconds)
[00:37:29] *** Joins: funhouse (~funhouse@user/funhouse)
[00:37:29] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[00:38:46] *** Quits: Diggsey (uid120933@id-120933.uxbridge.irccloud.com) (Quit: Connection closed for inactivity)
[00:43:03] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[00:43:33] *** Joins: sliss (~sliss@109.136.165.60)
[00:44:54] *** Quits: _mikey (~mikey@user/mikey/x-4335048) (Quit: WeeChat 3.4)
[00:46:08] *** Quits: ekathva (~ekathva@n3k05e951yzy0eo5x-1.v6.elisa-mobile.fi) (Quit: Leaving)
[00:49:04] *** Joins: _mikey (~mikey@user/mikey/x-4335048)
[00:50:33] *** Quits: `2jt (~jtomas@130.red-88-22-46.staticip.rima-tde.net) (Ping timeout: 252 seconds)
[00:53:02] *** Quits: Teraii (~teraii@185.219.206.44) (Quit: %Ho Ishuudaa%)
[00:53:44] *** Joins: foul_owl (~kerry@207.244.125.36)
[00:53:51] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 252 seconds)
[00:54:03] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[00:57:49] *** Quits: Komzzpa (~kom@2a02:220f:2000:2c00:fef7:4e28:78ec:e3ab) (Quit: Konversation terminated!)
[01:03:11] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[01:03:38] *** Joins: sliss (~sliss@109.136.165.60)
[01:04:00] *** Joins: Komzzpa (~kom@2a02:220f:2000:2c00:1970:3e30:a2e:201)
[01:04:16] *** Joins: Teraii (~teraii@juraii-s1-1.teraii.net)
[01:10:02] *** Quits: telser (~AdminUser@user/telser) (Remote host closed the connection)
[01:10:17] *** Joins: telser (~AdminUser@user/telser)
[01:10:50] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[01:11:35] *** Quits: telser (~AdminUser@user/telser) (Client Quit)
[01:12:33] *** Joins: telser (~AdminUser@2601:c0:c300:7620::1063)
[01:13:37] *** Joins: immibis (~hexchat@62.156.144.218)
[01:13:48] *** Quits: telser (~AdminUser@2601:c0:c300:7620::1063) (Client Quit)
[01:14:06] *** Joins: telser (~AdminUser@user/telser)
[01:14:28] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[01:15:05] *** Quits: SwK (~SwK_@user/swk) (Read error: Connection reset by peer)
[01:15:06] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[01:15:18] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Client Quit)
[01:15:58] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[01:16:53] <StuckMojo> are there any stat views/tables that show info on checkpoints? i.e. when the last one occurred?
[01:16:57] *** Quits: uncleyear (~ian@pppoe.178-66-157-18.dynamic.avangarddsl.ru) (Ping timeout: 252 seconds)
[01:17:24] *** Quits: bmomjian (~bruce@momjian.us) (Ping timeout: 240 seconds)
[01:17:35] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[01:18:59] <ademan[m]> I have a URL column I want to index, where the protocol will always be https, and the hostname will be one of a small number of possibilities (hundreds or thousands vs hundreds of thousands or millions of rows). Is there any way to compress the index with this knowledge?
[01:19:00] <johto> select * from pg_control_checkpoint();  Ithink
[01:19:00] *** Joins: SwK (~SwK_@2600:1700:5360:40d0:9a3:a2e5:e8b6:c8ec)
[01:19:00] *** Quits: SwK (~SwK_@2600:1700:5360:40d0:9a3:a2e5:e8b6:c8ec) (Changing host)
[01:19:00] *** Joins: SwK (~SwK_@user/swk)
[01:19:29] *** Joins: bmomjian (~bruce@momjian.us)
[01:19:29] <StuckMojo> thanks!
[01:21:09] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[01:21:48] <ufk>  can i explain analyze two inserts ? i want to compare explain analyze of two inserts comparing to one insert with a with statement to select and then insert in two places.
[01:23:18] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[01:23:32] <johto> they would be executed one by one anyway, no? just do two EXPLAIN ANALYZEs
[01:23:47] *** Joins: sliss (~sliss@109.136.165.60)
[01:25:16] <ufk> i'm wonder if a result of a with statement and then joining to it  is faster then selecting again from the table and joining while the table is index
[01:26:08] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[01:26:36] *** Quits: adac (~adac@213-47-252-7.cable.dynamic.surfer.at) (Ping timeout: 240 seconds)
[01:26:57] *** Joins: concrete-houses (~g@209.6.150.53)
[01:27:08] <concrete-houses> how do i see queries as they are run?
[01:27:15] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[01:27:34] <concrete-houses> can I use a long running query command and watch?
[01:27:42] <concrete-houses> I need the sql no dev can find
[01:27:43] *** Quits: michalz (~michalz@185.246.204.89) (Ping timeout: 250 seconds)
[01:27:56] *** Quits: mizi (~mizi@user/mizi) (Ping timeout: 272 seconds)
[01:29:50] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[01:30:55] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[01:35:16] *** Quits: rewrit3 (~rewrit3@user/rewrit3) (Read error: Connection reset by peer)
[01:35:20] *** Quits: magla (~gelignite@55d42258.access.ecotel.net) (Quit: Stay safe!)
[01:36:41] *** Joins: magla (~gelignite@55d42258.access.ecotel.net)
[01:37:16] *** Quits: magla (~gelignite@55d42258.access.ecotel.net) (Remote host closed the connection)
[01:37:24] *** Quits: ur5us_ (~ur5us@2406:e002:6dd8:5f01:a4b3:dc81:c8c:8966) (Ping timeout: 240 seconds)
[01:37:29] <crunchy_david> concrete-houses: pg_stat_activity shows the currently running queries
[01:37:41] <concrete-houses> how do I see the queries being run on the db?
[01:37:47] *** Joins: merzo (~Thunderbi@188.163.72.240)
[01:38:12] <concrete-houses> oh pg_stat_activity
[01:38:50] *** Quits: rendar (~rendar@user/rendar) (Quit: Leaving)
[01:38:57] *** Quits: Komzzpa (~kom@2a02:220f:2000:2c00:1970:3e30:a2e:201) (Ping timeout: 252 seconds)
[01:40:44] <crunchy_david> SELECT * FROM pg_stat_activity WHERE state = 'active'
[01:41:28] <crunchy_david> there's one entry in that view for each connected backend; `active` are the ones currently running queries
[01:43:26] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[01:43:53] *** Joins: sliss (~sliss@109.136.165.60)
[01:44:11] <concrete-houses> ok
[01:44:44] *** Joins: abf (~abf@user/abf)
[01:45:00] *** Quits: shka (~herr@109.231.0.226) (Ping timeout: 252 seconds)
[01:45:39] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Quit: My Mac Pro has gone to sleep. ZZZzzz…)
[01:48:26] *** Joins: ur5us_ (~ur5us@2406:e002:6dd8:5f01:fc34:35d:f7a3:2784)
[01:48:35] <concrete-houses> will it show a long gnarley query?
[01:48:41] <concrete-houses> or cut it off?
[01:49:32] <ilmari> it's limited by the track_activity_query_size config variable (default 1kB)
[01:49:43] <ilmari> (or 1024 characters, not sure, see the docs)
[01:50:01] <ilmari> the unit in pg_settings is B, so presumably bytes
[01:50:17] <ilmari> I wonder how it handles multibyte characters spanning the boundary …
[01:54:04] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[01:54:21] *** Quits: Rashad_ (~textual@2a01:9700:131e:a000:380e:f024:1b6f:38bb) (Ping timeout: 252 seconds)
[01:55:54] *** Quits: grandrew (~grandrew@2600:1700:42f3:9180:f22f:74ff:feac:90a3) (Remote host closed the connection)
[01:56:08] *** Joins: Atque (~Atque@user/atque)
[01:56:58] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[01:58:23] <concrete-houses> so some dev just ran a report
[01:58:36] <concrete-houses> its no longer active
[01:58:44] <concrete-houses> they want the sql
[01:59:28] <peerce> they want what sql ?
[02:01:00] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 240 seconds)
[02:03:56] <concrete-houses> some dev is running a report
[02:04:15] <concrete-houses> They said hey can you look at the query hitting postgres and tell us what the sql is?
[02:04:29] <concrete-houses> Like how do I see that last 50 queries run on the db?
[02:05:07] <concrete-houses> I did select * from pg_stat_activity looking at it..
[02:06:03] <concrete-houses> Its weird because it seems to show they query with $1 not the data bit the app filled in..... so when I rerun a query I have to put in guess values...
[02:06:21] <concrete-houses> IS there some switch to have it show the query as run?
[02:07:23] *** Joins: BadAdviceCat (~BadAdvice@user/badadvicecat)
[02:07:48] *** Quits: Nekomander (~BadAdvice@user/badadvicecat) (Ping timeout: 240 seconds)
[02:10:31] *** Quits: telser (~AdminUser@user/telser) (Remote host closed the connection)
[02:11:01] <peerce> to show past queries, query logging needs to have been enabled when they were run
[02:11:14] <peerce> pg_stat_activity shows a snapshot of this instant only.
[02:11:16] *** Quits: merzo (~Thunderbi@188.163.72.240) (Read error: Connection reset by peer)
[02:11:41] <peerce> query logging can get pretty expensive on a busy server that might be running 1000s of queries/second
[02:11:46] *** Joins: telser (~AdminUser@user/telser)
[02:14:04] *** Quits: Auron (Auron956@user/auron) (Remote host closed the connection)
[02:15:34] <concrete-houses> oh
[02:16:18] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[02:24:34] <concrete-houses> I feel so ignorant and powerless
[02:26:59] <peerce> thats what happens when you lie about your knowlege and experience on a job interview.
[02:27:38] <peerce> I bet they didn't realize they were hiring an IRC channel
[02:27:48] <Darius> are there DTrace/SystemTAP/etc hooks that let you grab it?
[02:28:02] <Darius> peerce: in a trench coat
[02:28:24] <Rembane> And a fancy hat
[02:28:51] <Darius> oooh
[02:29:07] <peerce> Darius; its easier to just enable query logging, run your test, then shut it off.
[02:29:15] <peerce> ??logging
[02:29:16] <pg_docbot> https://github.com/omniti-labs/pg_jobmon :: https://www.postgresql.org/docs/current/static/wal.html
[02:29:16] <pg_docbot> https://www.postgresql.org/docs/current/static/runtime-config-logging.html
[02:30:04] <Darius> peerce: yeah but way less cool
[02:30:08] <peerce> log_statements=all
[02:30:54] *** Quits: Simplar (~Simplar@188.163.93.241) (Quit: Going offline, see ya! (www.adiirc.com))
[02:31:49] <peerce> ALTER SYSTEM SET log_statements='all';   select pg_reload_conf(); ...  then run the test, then ALTER SYSTEM RESET log_statements;  select pg_reload_conf();
[02:31:54] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[02:32:37] *** Quits: manti7 (~manti7@176.10.104.94) (Quit: WeeChat 3.3)
[02:33:00] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 240 seconds)
[02:36:00] <concrete-houses> hmmm
[02:37:53] <peerce> then extrract the sql from your postgres .logs
[02:39:28] *** Quits: zeden (~zeden@user/zeden) (Quit: WeeChat 3.4)
[02:39:36] <concrete-houses> :)
[02:39:40] <concrete-houses> thank you
[02:40:31] *** Joins: zeden (~zeden@user/zeden)
[02:45:48] *** Quits: kitsunenokenja (~kitsunech@68.91.220.96) (Ping timeout: 240 seconds)
[02:50:41] <peerce> do be sure to have the log_prefix set to something that includes the PID and other useful info
[02:53:07] *** Quits: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk) (Quit: Leaving)
[02:57:29] <concrete-houses> oow ok
[02:58:01] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[02:58:02] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[02:58:15] *** Joins: xocolatl (~xocolatl@193.32.126.213)
[03:06:08] *** Quits: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[03:06:44] *** Quits: concrete-houses (~g@209.6.150.53) (Quit: Lost terminal)
[03:07:50] *** Joins: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net)
[03:09:49] <peerce> oops, its log_line_prefix.    i usually set it to something like, '%m [%p] %u@%r/%d '    which is timestamp [pid] user@host:port/dbname
[03:10:41] *** Quits: telser (~AdminUser@user/telser) (Quit: No Ping reply in 180 seconds.)
[03:11:56] *** Joins: telser (~AdminUser@user/telser)
[03:18:46] *** Quits: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 272 seconds)
[03:19:31] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 250 seconds)
[03:20:47] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[03:22:59] *** Quits: pedja (~pedja@user/deus-ex/x-7934090) (Quit: Leaving)
[03:25:43] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[03:28:20] *** Quits: maxzor (~maxzor@2a01cb04054faa002a846f07b3ea5054.ipv6.abo.wanadoo.fr) (Remote host closed the connection)
[03:28:36] *** Quits: Haudegen (~quassel@178.115.237.87.static.drei.at) (Ping timeout: 240 seconds)
[03:30:21] *** Quits: obimod (~obimod@gateway/vpn/pia/obimod) (Ping timeout: 250 seconds)
[03:34:42] *** Quits: rb (~augh@theguntretort.com) (Ping timeout: 250 seconds)
[03:36:26] *** Joins: k8yun (~k8yun@user/k8yun)
[03:38:03] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[03:42:12] *** Joins: rwb (~augh@209.141.39.190)
[03:42:28] *** Joins: Alex8532 (~Alex8532@user/alex8532)
[03:44:05] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[03:44:36] *** Joins: obimod (~obimod@gateway/vpn/pia/obimod)
[03:48:41] *** Quits: k8yun (~k8yun@user/k8yun) (Quit: Leaving)
[03:50:25] *** Joins: gp5st (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net)
[03:54:57] *** Quits: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[04:00:24] *** Joins: zachxxz (~zachary@124.133.18.218)
[04:03:17] *** Quits: richard_h (~richard@2406:e001:8:a900:6e62:6dff:fe05:ae29) (Quit: Leaving.)
[04:04:36] <glik22_> not sure if this is an AWS specific question or what, but i'll give it a go. i noticed the OldestReplicationSlotLag metric for my primary db has been increasing steadily for the past week. it went from 28gb to 7tb. how would i go about debugging this?
[04:05:57] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[04:10:42] *** Quits: BadAdviceCat (~BadAdvice@user/badadvicecat) (Ping timeout: 272 seconds)
[04:10:51] *** Quits: telser (~AdminUser@user/telser) (Quit: No Ping reply in 180 seconds.)
[04:12:06] *** Joins: telser (~AdminUser@user/telser)
[04:12:57] *** Quits: peteyboy1 (~peteyboy1@95.169.226.66) (Ping timeout: 252 seconds)
[04:13:52] *** Quits: Reiner_Unsinn (~quassel@p579d7a94.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[04:15:06] *** Joins: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net)
[04:19:33] *** Quits: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 252 seconds)
[04:23:19] *** Joins: peteyboy1 (~peteyboy1@95.169.226.66)
[04:27:24] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[04:27:41] *** Joins: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net)
[04:27:48] *** Quits: peteyboy1 (~peteyboy1@95.169.226.66) (Ping timeout: 252 seconds)
[04:28:15] *** Joins: BadAdviceCat (~BadAdvice@user/badadvicecat)
[04:28:26] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 272 seconds)
[04:30:15] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[04:34:36] *** Quits: BadAdviceCat (~BadAdvice@user/badadvicecat) (Ping timeout: 240 seconds)
[04:34:45] *** Joins: Nekomander (~BadAdvice@user/badadvicecat)
[04:40:42] *** Joins: justyb11 (~justyb@64.253.212.72)
[04:58:21] *** Joins: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net)
[04:58:40] *** Quits: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[05:00:07] *** Joins: bpmedley_ (~bpmedley@2600:1700:e2c:8410:a11b:dff5:39c9:bc45)
[05:00:24] *** Quits: Stanley (~stanley@d66-183-88-69.bchsia.telus.net) (Quit: ZNC - https://znc.in)
[05:00:48] *** Joins: Stanley (~stanley@d66-183-88-69.bchsia.telus.net)
[05:02:22] *** Quits: tozhu (~tozhu@171.88.40.27) (Quit: tozhu)
[05:02:57] *** Quits: bpmedley (~bpmedley@2600:1700:e2c:8410:e438:c47c:d7b4:3864) (Ping timeout: 240 seconds)
[05:08:11] *** Joins: rjuju (~rjuju@2001-b011-1005-1e7d-03a3-07ec-f8b4-aadc.dynamic-ip6.hinet.net)
[05:10:31] *** Quits: telser (~AdminUser@user/telser) (Quit: No Ping reply in 180 seconds.)
[05:11:45] *** Joins: telser (~AdminUser@user/telser)
[05:13:07] *** Quits: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net) (Ping timeout: 256 seconds)
[05:14:32] <StuckMojo> glik22_: that sounds like no one is consuming that replication slot anymore
[05:16:33] <StuckMojo> select * from pg_replication_slots; see if one of them is not active
[05:16:51] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[05:17:19] <StuckMojo> //www.postgresql.org/docs/current/static/view-pg-replication-slots.html
[05:17:24] <StuckMojo> damn it
[05:17:34] <StuckMojo> https://www.postgresql.org/docs/current/static/view-pg-replication-slots.html
[05:17:43] *** Joins: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net)
[05:17:48] *** Quits: gp5st (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net) (Ping timeout: 240 seconds)
[05:17:57] *** Quits: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net) (Read error: Connection reset by peer)
[05:18:06] <StuckMojo> a slot that is not consumed (inactive) will cause WAL to pile up on the primary forever. you need to drop the slot if that's the case
[05:18:09] <StuckMojo> ??slots
[05:18:10] <pg_docbot> http://www.pateldenish.com/2015/10/postgres-replication-slot-pg_basebackup.html :: https://www.postgresql.org/docs/current/static/view-pg-replication-slots.html
[05:18:10] <pg_docbot> https://www.postgresql.org/docs/current/static/warm-standby.html#STREAMING-REPLICATION-SLOTS
[05:20:30] *** Joins: fstd_ (~fstd@xdsl-81-173-174-103.nc.de)
[05:21:08] *** Joins: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net)
[05:22:11] *** Quits: libsys (~libsys@186.105.132.6) (Ping timeout: 256 seconds)
[05:23:06] *** Joins: libsys (~libsys@186.105.132.6)
[05:23:39] *** Quits: fstd (~fstd@xdsl-87-79-44-63.nc.de) (Ping timeout: 250 seconds)
[05:23:54] *** Quits: qwedfg (~qwedfg@user/qwedfg) (Remote host closed the connection)
[05:24:42] *** Joins: qwedfg (~qwedfg@user/qwedfg)
[05:27:39] *** Joins: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net)
[05:28:50] *** Quits: dfee (~dfee@162-227-164-101.lightspeed.sntcca.sbcglobal.net) (Client Quit)
[05:33:02] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[05:34:33] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[05:35:24] *** Quits: MrZeus__ (~MrZeus@185.248.85.38) (Ping timeout: 240 seconds)
[05:40:58] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[05:42:36] *** Quits: bmomjian (~bruce@momjian.us) (Ping timeout: 252 seconds)
[05:45:41] *** Quits: f3f3lix (~weechat@55d499e5.access.ecotel.net) (Ping timeout: 256 seconds)
[05:46:25] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[05:47:11] *** Joins: f3f3lix (~weechat@55d487fc.access.ecotel.net)
[05:49:50] *** Joins: bmomjian (~bruce@momjian.us)
[05:53:55] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[05:56:27] *** Quits: Su-Shee (~Susanne@p50894207.dip0.t-ipconnect.de) (Ping timeout: 256 seconds)
[05:57:56] *** Joins: Su-Shee (~Susanne@p4ffc7a34.dip0.t-ipconnect.de)
[05:59:49] *** Quits: supplicant (~supplican@ec2-52-22-71-188.compute-1.amazonaws.com) (Remote host closed the connection)
[06:07:20] *** Quits: zeden (~zeden@user/zeden) (Quit: WeeChat 3.4)
[06:07:29] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[06:10:41] *** Quits: telser (~AdminUser@user/telser) (Quit: No Ping reply in 180 seconds.)
[06:11:56] *** Joins: telser (~AdminUser@user/telser)
[06:17:45] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[06:19:08] *** Quits: schinckel (uid38120@id-38120.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[06:20:01] *** Quits: _mikey (~mikey@user/mikey/x-4335048) (Quit: WeeChat 3.4)
[06:21:10] *** Joins: wachin (~wachin@181.46.68.8)
[06:21:21] *** Parts: wachin (~wachin@181.46.68.8) (Leaving)
[06:22:26] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[06:23:11] *** Joins: _mikey (~mikey@user/mikey/x-4335048)
[06:23:57] *** Quits: Alex8532 (~Alex8532@user/alex8532) (Quit: Going offline, see ya! (www.adiirc.com))
[06:32:35] *** Joins: ammer (~ammer@113.247.176.9)
[06:33:31] <riceandbeans> Forgive me if this is a dumb question, is listen/notify basically like making postgres be a pub/sub system, a message queue of a sort?
[06:34:06] <peerce> kinda/sorta/notreally.
[06:35:38] *** Quits: abf (~abf@user/abf) (Quit: Leaving)
[06:36:11] <riceandbeans> I....what?
[06:37:57] *** Joins: n0fun (~jack@mue-88-130-48-082.dsl.tropolys.de)
[06:38:16] *** Quits: n0fun_ (~jack@mue-88-130-48-076.dsl.tropolys.de) (Ping timeout: 272 seconds)
[06:41:54] *** Quits: libsys (~libsys@186.105.132.6) (Remote host closed the connection)
[06:42:06] <peerce> its not a direct replacement for a guaranteed delivery message queuing system, although you could build something like that around it, it probably wouldn't perform as well as a decent distributed MQ kinda thing
[06:42:12] <peerce> RabbitMQ, etc etc.
[06:43:14] <riceandbeans> Ok, so it can be used like a MQ but doesn't guarantee the delivery and isn't as performant, that said, what's the proper use of it then?
[06:43:54] *** Joins: mowotter (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c)
[06:44:25] *** Joins: libsys (~libsys@186.105.132.6)
[06:45:36] <leont> Combine it with a trigger, so your application gets an update if it needs to recheck some table
[06:46:17] <riceandbeans> Could you give me an example of something plausible?
[06:46:24] *** Quits: mowcat (~mowcat@host86-129-162-211.range86-129.btcentralplus.com) (Ping timeout: 252 seconds)
[06:54:58] <leont> Essentially, what I just described is a cache invalidation
[06:56:37] *** Joins: k8yun (~k8yun@user/k8yun)
[06:56:49] *** Joins: maxzor (~maxzor@2a01cb04054faa0018329ba70d7bd268.ipv6.abo.wanadoo.fr)
[06:57:10] *** Quits: maxzor (~maxzor@2a01cb04054faa0018329ba70d7bd268.ipv6.abo.wanadoo.fr) (Read error: Connection reset by peer)
[06:57:29] *** Joins: maxzor (~maxzor@2a01cb04054faa0018329ba70d7bd268.ipv6.abo.wanadoo.fr)
[06:57:57] *** Quits: cliluw (~cliluw@47.147.73.223) (Ping timeout: 240 seconds)
[06:58:38] *** Joins: cliluw (~cliluw@47.147.73.223)
[07:07:18] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 252 seconds)
[07:07:31] *** Joins: Emet-Selch (~haise01@user/haise01)
[07:08:02] *** Quits: Vacuity (~Vacuity@user/vovo) (Ping timeout: 272 seconds)
[07:09:17] *** Joins: Vacuity (~Vacuity@user/vovo)
[07:10:29] *** Quits: Azem (~haise01@user/haise01) (Ping timeout: 250 seconds)
[07:10:51] *** Quits: telser (~AdminUser@user/telser) (Quit: No Ping reply in 180 seconds.)
[07:12:06] *** Joins: telser (~AdminUser@user/telser)
[07:12:36] *** Quits: bmomjian (~bruce@momjian.us) (Ping timeout: 240 seconds)
[07:13:34] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[07:13:40] *** Joins: ponsfrilus1 (~Thunderbi@adsl-178-39-219-60.adslplus.ch)
[07:13:48] *** Quits: ponsfrilus (~Thunderbi@vpn-253-238.epfl.ch) (Ping timeout: 240 seconds)
[07:13:48] *** ponsfrilus1 is now known as ponsfrilus
[07:14:05] *** Joins: bmomjian (~bruce@momjian.us)
[07:15:52] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[07:17:41] *** Joins: tozhu (~tozhu@171.88.40.27)
[07:18:10] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[07:21:15] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[07:23:00] *** Joins: SwK_ (~SwK_@2600:1700:5360:40d0:9a3:a2e5:e8b6:c8ec)
[07:23:10] *** Quits: Xof (~Xof@157-131-136-66.dedicated.static.sonic.net) (Quit: Bye.)
[07:23:29] *** Joins: richard_h (~richard@2406:e001:8:a900:6e62:6dff:fe05:ae29)
[07:26:12] *** Quits: SwK (~SwK_@user/swk) (Ping timeout: 240 seconds)
[07:33:01] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[07:35:52] *** Joins: SwK (~SwK_@2600:1700:5360:40d0:f067:7a91:7176:3fc2)
[07:35:52] *** Quits: SwK (~SwK_@2600:1700:5360:40d0:f067:7a91:7176:3fc2) (Changing host)
[07:35:52] *** Joins: SwK (~SwK_@user/swk)
[07:37:00] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 240 seconds)
[07:38:12] *** Quits: SwK_ (~SwK_@2600:1700:5360:40d0:9a3:a2e5:e8b6:c8ec) (Ping timeout: 240 seconds)
[07:42:33] *** Joins: blaklistd (~blaklistd@user/blaklistd)
[07:44:54] *** Quits: peerce (mudshark@2601:647:c980:247:5437:fb5a:4d2f:5689) (Ping timeout: 260 seconds)
[07:46:33] *** Joins: peerce (mudshark@2601:647:c980:247:6940:7c7b:1452:57f0)
[07:47:48] *** Quits: ur5us_ (~ur5us@2406:e002:6dd8:5f01:fc34:35d:f7a3:2784) (Ping timeout: 240 seconds)
[07:49:50] *** Quits: sreve_ (~quassel@p549d73fe.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[07:50:05] *** Joins: sreve (~quassel@p4ff44d01.dip0.t-ipconnect.de)
[07:53:28] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[08:00:39] *** Quits: n0fun (~jack@mue-88-130-48-082.dsl.tropolys.de) (Ping timeout: 252 seconds)
[08:07:39] *** Joins: shiranaihito (~textual@123-192-192-149.dynamic.kbronet.com.tw)
[08:11:01] *** Quits: telser (~AdminUser@user/telser) (Quit: No Ping reply in 180 seconds.)
[08:12:16] *** Joins: telser (~AdminUser@user/telser)
[08:12:53] *** Quits: JordiGH (~jordi@user/jordigh) (Ping timeout: 250 seconds)
[08:14:08] *** Joins: ur5us_ (~ur5us@2406:e002:6dd8:5f01:a4b3:dc81:c8c:8966)
[08:19:01] *** Quits: telser (~AdminUser@user/telser) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[08:21:33] *** Quits: richard_h (~richard@2406:e001:8:a900:6e62:6dff:fe05:ae29) (Quit: Leaving.)
[08:23:00] *** Quits: zlinux (~zlinux@149.109.1.168) (Ping timeout: 240 seconds)
[08:27:50] *** Quits: jazzy (~jaziz@user/jaziz) (Ping timeout: 272 seconds)
[08:30:16] *** Quits: mowotter (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c) (Remote host closed the connection)
[08:32:09] *** Joins: Haudegen (~quassel@178.115.237.87.static.drei.at)
[08:32:18] *** Joins: carragom (~textual@201.204.94.76)
[08:41:58] *** Quits: k8yun (~k8yun@user/k8yun) (Quit: Leaving)
[08:42:59] *** Quits: electron^-892402 (~electron^@212.66.122.116) (Read error: Connection reset by peer)
[08:43:02] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 272 seconds)
[08:43:32] *** Joins: concrete-houses (~g@209.6.150.53)
[08:44:13] *** Joins: k8yun (~k8yun@user/k8yun)
[08:44:16] <concrete-houses> What do you do when you have 122mil lines in order table but most of that is ancient ? Is there a way to seperate old stuff from say more active recent stuff?
[08:44:17] *** Quits: liriel (~liriel@user/liriel) (Ping timeout: 240 seconds)
[08:44:36] <concrete-houses> aso how important is max parallel workers per gather for apraalleizing queries?
[08:44:58] *** Joins: uncleyear (~ian@pppoe.178-66-157-18.dynamic.avangarddsl.ru)
[08:56:38] *** Quits: k8yun (~k8yun@user/k8yun) (Quit: Leaving)
[08:56:47] *** Joins: schinckel (uid38120@id-38120.ilkley.irccloud.com)
[08:56:58] *** Quits: tozhu (~tozhu@171.88.40.27) (Quit: tozhu)
[08:58:02] <peerce> 122 million lines of *what* ?
[08:58:11] <peerce> old log files?
[08:58:19] <peerce> data in a table ?
[08:59:06] <peerce> what is 'order table' ?  does this table have a date field in it that can be used to distinguish old from new ?
[08:59:12] *** Joins: ekathva (~ekathva@n3k04mk1g2jsn5ncy-1.v6.elisa-mobile.fi)
[09:01:33] *** Joins: liriel (~liriel@185.21.217.6)
[09:01:35] *** Quits: liriel (~liriel@185.21.217.6) (Changing host)
[09:01:35] *** Joins: liriel (~liriel@user/liriel)
[09:04:47] <peerce> and your second question, well, thats entirely depedent on the queries, and the overall work load on your database, and how many CPU cores you have.
[09:05:24] <peerce> if this is the ONLY query running, and its a highly parallizable query, and thats *ALL* this server is doing at that point in time, you might want that as higha s your cpu core/thread count
[09:06:13] <peerce> most OLTP kind of queries can't use parallel workers anyways, they fetch/update single rows
[09:06:24] <peerce> and are by concept and design, fast and short.
[09:06:31] *** Joins: JordiGH (~jordi@fencepost.gnu.org)
[09:06:31] *** Quits: JordiGH (~jordi@fencepost.gnu.org) (Changing host)
[09:06:31] *** Joins: JordiGH (~jordi@user/jordigh)
[09:07:11] <peerce> parallel queries come in when you are doing OLAP reporting sorts of queries that fetch many rows from a table or tables.
[09:07:22] <peerce> big aggregates, etc.
[09:07:57] <peerce> we found it quite productive to have seperate servers for our OLTP transactional line operations vs our back end reporting OLAP queries
[09:09:02] <peerce> the reporting servers got so busy we ended up running several in parallel, and some highly specialized rollup statistical servers also used by reporting operations.
[09:09:42] <peerce> the rollup servers stored pre-aggreageted-over-time data.   like statistics per hour, per shift, per day, per week, per month.
[09:09:57] <peerce> with 1000s and 1000s of different statistics all being rolledup like that in near realtime
[09:10:31] <peerce> operational dashboards used those rollup servers a LOT because a general aggregation query of the big OLAP database would take way too long
[09:11:06] <peerce> but the big OLAP database was still there for ad hoc queries that didn't fit into any existing rollups
[09:11:43] <peerce> correlating post-manufacturing field failures with factory operator sick leave
[09:11:59] *** Joins: liquid-silence (sid522629@id-522629.uxbridge.irccloud.com)
[09:12:08] *** Joins: manti7 (~manti7@176.10.104.94)
[09:13:24] *** Quits: ur5us_ (~ur5us@2406:e002:6dd8:5f01:a4b3:dc81:c8c:8966) (Ping timeout: 240 seconds)
[09:13:25] <liquid-silence> Hi all, I am currently restoring a database of around 4GB, is there a way to disable constraint checks when doing a data import? I recall with MSSQL you could disable that and the import will be dramatically faster
[09:16:55] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[09:17:03] <peerce> the biggest expense in most restores is the index building, and you can greatly speed those up with a healthy maintenance_work_mem allocation, I typically use 1GB
[09:18:01] <peerce> constraint checking and said indexes are closely related, since a unique constraint implies a b-tree index
[09:18:19] <peerce> check constraints generally aren't at all expensive.
[09:18:28] <peerce> FK restraints, same thing, reliant on indexes.
[09:18:57] *** Joins: the_lanetly_052 (~the_lanet@185.30.91.186)
[09:21:22] *** Quits: concrete-houses (~g@209.6.150.53) (Quit: Lost terminal)
[09:21:40] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[09:24:31] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[09:24:36] *** Quits: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 240 seconds)
[09:32:59] <liquid-silence> @peerce
[09:33:30] <liquid-silence> I don't see a considerable increase in speed of importing the data with that, I guess its because its mainly postgis data?
[09:36:31] *** Quits: JordiGH (~jordi@user/jordigh) (Ping timeout: 250 seconds)
[09:37:42] *** Joins: mattil (~mattil@87-92-28-123.bb.dnainternet.fi)
[09:39:04] *** Joins: mattil__ (~mattil@helsinki.portalify.com)
[09:39:39] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 252 seconds)
[09:40:18] *** Joins: Elodin (~elodin@user/elodin)
[09:42:12] *** Quits: mattil (~mattil@87-92-28-123.bb.dnainternet.fi) (Ping timeout: 240 seconds)
[09:42:15] *** Joins: tozhu (~tozhu@171.88.40.27)
[09:42:24] *** Joins: JordiGH (~jordi@fencepost.gnu.org)
[09:42:24] *** Quits: JordiGH (~jordi@fencepost.gnu.org) (Changing host)
[09:42:24] *** Joins: JordiGH (~jordi@user/jordigh)
[09:44:21] *** Joins: Reiner_Unsinn_ (~quassel@p579d7a94.dip0.t-ipconnect.de)
[09:45:37] *** Joins: tochu (~tozhu@218.89.244.95)
[09:46:15] *** Quits: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon) (Ping timeout: 240 seconds)
[09:46:58] *** Quits: tozhu (~tozhu@171.88.40.27) (Ping timeout: 250 seconds)
[09:46:59] *** tochu is now known as tozhu
[09:55:36] *** Quits: Elodin (~elodin@user/elodin) (Ping timeout: 252 seconds)
[09:57:47] *** Quits: reprazent (~reprazent@178-118-195-230.access.telenet.be) (Ping timeout: 252 seconds)
[09:58:06] *** Joins: shka (~herr@109.231.0.226)
[09:58:23] *** Joins: reprazent (~reprazent@178-118-195-230.access.telenet.be)
[10:00:03] *** Joins: mattil (~mattil@87-92-28-123.bb.dnainternet.fi)
[10:00:05] *** Quits: mattil (~mattil@87-92-28-123.bb.dnainternet.fi) (Remote host closed the connection)
[10:00:48] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[10:02:12] *** Quits: mattil__ (~mattil@helsinki.portalify.com) (Ping timeout: 252 seconds)
[10:07:48] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 240 seconds)
[10:11:24] *** Quits: gambl0re (~gambl0re@2607:fea8:a59f:c360::82dc) (Ping timeout: 240 seconds)
[10:13:13] *** Joins: Guest71 (~Guest71@49.207.207.127)
[10:14:49] *** Joins: mattil (~mattil@87-92-28-123.bb.dnainternet.fi)
[10:15:20] *** Joins: off^ (~off@50.235.176.163)
[10:15:22] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[10:19:00] *** Quits: mattil (~mattil@87-92-28-123.bb.dnainternet.fi) (Ping timeout: 240 seconds)
[10:20:43] *** Quits: JordiGH (~jordi@user/jordigh) (Ping timeout: 250 seconds)
[10:22:47] *** Quits: randir (~randir@2.92.196.208) (Remote host closed the connection)
[10:23:20] *** Joins: randir (~randir@2.92.196.208)
[10:23:52] *** Joins: darutoko (~darutoko@37.21.224.109)
[10:26:14] *** Quits: tozhu (~tozhu@218.89.244.95) (Quit: tozhu)
[10:28:10] *** Quits: randir (~randir@2.92.196.208) (Ping timeout: 272 seconds)
[10:28:18] *** Joins: mattil (~mattil@87-92-28-123.bb.dnainternet.fi)
[10:28:28] *** Quits: mattil (~mattil@87-92-28-123.bb.dnainternet.fi) (Remote host closed the connection)
[10:28:46] <merpaderp> first time me using FULL JOIN in my queries, it's quite handy, glues two tables together if there is a match, can sum things together if matched
[10:29:42] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 252 seconds)
[10:29:53] *** Quits: Guest71 (~Guest71@49.207.207.127) (Quit: Client closed)
[10:30:46] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[10:31:14] *** Joins: Komzzpa (~kom@2a02:220f:2000:2c00:2ecb:f46e:e0b3:4d75)
[10:31:49] *** Joins: Guest71 (~Guest71@49.207.207.127)
[10:33:01] *** Joins: Alex8532 (~Alex8532@user/alex8532)
[10:34:07] *** Joins: palasso (~palasso@user/palasso)
[10:35:20] *** Quits: Guest71 (~Guest71@49.207.207.127) (Client Quit)
[10:36:03] *** Joins: randir (~randir@93.159.239.42)
[10:37:00] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Ping timeout: 240 seconds)
[10:38:35] *** Quits: _mikey (~mikey@user/mikey/x-4335048) (Quit: WeeChat 3.4)
[10:40:09] *** Quits: Nekomander (~BadAdvice@user/badadvicecat) (Ping timeout: 252 seconds)
[10:40:11] *** Joins: BadAdviceCat (~BadAdvice@user/badadvicecat)
[10:43:20] *** Joins: maret (~maret@nat-88-212-37-89.antik.sk)
[10:45:16] *** Joins: GNUmoon (~GNUmoon@gateway/tor-sasl/gnumoon)
[10:46:44] *** Joins: michalz (~michalz@185.246.204.93)
[10:47:52] *** Joins: `2jt (~jtomas@130.red-88-22-46.staticip.rima-tde.net)
[10:49:20] *** Joins: ekathva_ (~ekathva@n3k06ap29nlro92ao-1.v6.elisa-mobile.fi)
[10:49:28] *** Quits: ekathva_ (~ekathva@n3k06ap29nlro92ao-1.v6.elisa-mobile.fi) (Remote host closed the connection)
[10:52:36] *** Quits: ponsfrilus (~Thunderbi@adsl-178-39-219-60.adslplus.ch) (Ping timeout: 240 seconds)
[10:52:48] *** Joins: ponsfrilus (~Thunderbi@vpn-254-202.epfl.ch)
[10:56:05] *** Quits: justyb11 (~justyb@64.253.212.72) (Quit: Leaving)
[11:00:28] *** Quits: op2 (~op2@user/op2) (Ping timeout: 272 seconds)
[11:00:38] *** Joins: jazzy (~jaziz@user/jaziz)
[11:02:35] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[11:04:35] *** Joins: sliss (~sliss@109.136.165.60)
[11:08:11] *** Joins: k_sze (~k_sze@mail2.kalunite.net)
[11:12:51] <k_sze> In MySQL, `a LEFT JOIN b ON a.col='bla' AND a.b_id=b.id` will do a kind of filtering that I can only describe as "weird". What does PostgreSQL do here?
[11:15:26] <riceandbeans> I don't think I've ever used a LEFT JOIN
[11:16:34] *** Joins: jmarsac (~jmarsac@2a01:cb1d:1f5:ca00:80b7:e519:59ae:5543)
[11:17:20] *** Quits: jmarsac (~jmarsac@2a01:cb1d:1f5:ca00:80b7:e519:59ae:5543) (Client Quit)
[11:18:17] *** Quits: maxzor (~maxzor@2a01cb04054faa0018329ba70d7bd268.ipv6.abo.wanadoo.fr) (Quit: Leaving)
[11:18:29] *** Joins: psoo (~psoo@dslb-090-186-134-090.090.186.pools.vodafone-ip.de)
[11:19:11] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[11:20:02] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570)
[11:24:34] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[11:25:04] *** Joins: sliss (~sliss@109.136.165.60)
[11:25:29] <merpaderp> woah, duckduckgo just returned a postgresql documentation version 14 not 9 as it used to
[11:25:46] <capitol> progress!
[11:26:13] <leio> now if they'd link to current/
[11:27:04] *** Quits: fcr (~fran@r167-60-10-45.dialup.adsl.anteldata.net.uy) (Ping timeout: 272 seconds)
[11:28:33] *** Quits: Komzzpa (~kom@2a02:220f:2000:2c00:2ecb:f46e:e0b3:4d75) (Ping timeout: 252 seconds)
[11:29:16] *** Joins: tmunro (~user@freefall.freebsd.org)
[11:29:46] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[11:30:21] *** Joins: adac (~adac@213-47-252-7.cable.dynamic.surfer.at)
[11:30:52] <Alex8532> Guys, my team lead and I are having a debate about unique database constraints in our Python app, whether to rely directly on it by handling the exception.  I want to do a SELECT query to avoid the constraint during INSERTs/UPDATEs.  It is efficent, especially when using an ORM which usually have quirks or bulk operations.  On the other hand, he wants to directly rely on the unique constraint by handling the exception.  It has caused us to use a
[11:30:52] <Alex8532> funky design pattern in some cases and could cause performance issues when doing bulk.  Tell me which approach is right?
[11:31:14] *** Joins: fcr (~fran@r186-48-76-186.dialup.adsl.anteldata.net.uy)
[11:32:20] *** Quits: jdavfsxd (~rvgzuuqp@gateway/tor-sasl/rvgzuuqp) (Quit: jdavfsxd)
[11:32:36] *** Joins: peteyboy1 (~peteyboy1@95.169.226.66)
[11:34:01] <Zr40> what would the exception handling do exactly?
[11:34:20] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[11:34:30] *** Joins: rendar (~rendar@user/rendar)
[11:36:11] *** Joins: merzo (~Thunderbi@185.39.197.205)
[11:52:05] *** Quits: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca) (Quit: WeeChat 3.4)
[11:55:16] *** Joins: bkkk (~bkkk@dslb-088-070-030-097.088.070.pools.vodafone-ip.de)
[11:55:23] *** Quits: ammer (~ammer@113.247.176.9) (Quit: WeeChat 2.8)
[11:57:47] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Quit: My Mac Pro has gone to sleep. ZZZzzz…)
[12:00:41] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[12:04:26] *** Joins: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c)
[12:05:48] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Ping timeout: 240 seconds)
[12:06:18] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[12:09:30] *** Quits: Alex8532 (~Alex8532@user/alex8532) (Ping timeout: 272 seconds)
[12:09:53] *** Joins: vladoski (~vladoski@2001:b07:add:d406:c006:7bd7:322c:328b)
[12:11:34] *** Joins: perrierjouet (~perrier-j@modemcable012.251-130-66.mc.videotron.ca)
[12:11:45] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) (Read error: Connection reset by peer)
[12:13:00] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 240 seconds)
[12:15:08] *** Joins: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net)
[12:24:29] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[12:25:47] *** Joins: Kohe (~Kohe@46.12.76.236.dsl.dyn.forthnet.gr)
[12:27:21] *** Joins: Ergo^ (~ergo@91.238.59.144)
[12:27:52] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[12:33:07] *** Quits: bkkk (~bkkk@dslb-088-070-030-097.088.070.pools.vodafone-ip.de) (Remote host closed the connection)
[12:35:16] <belst> hi, short question. I have a function that takes 2 arguments and returns a table. now I want to select the arguments from another table, how can I return the table from the function? atm I only get 1 column with the whole row
[12:35:49] <belst> I did sth like `select * from (select myfun(arg1, arg2) from args) as tmp`
[12:35:59] <belst> but that does not work obviously
[12:36:32] *** Joins: Raven737 (~Raven737@67.205.142.134)
[12:36:46] *** Quits: Kyros (~kyros@user/kyros) (Quit: ZNC 1.8.2 - https://znc.in)
[12:37:05] *** Joins: Kyros (~kyros@user/kyros)
[12:37:22] *** Joins: masber (~masber@213.55.224.10)
[12:39:48] *** Quits: BadAdviceCat (~BadAdvice@user/badadvicecat) (Ping timeout: 240 seconds)
[12:39:57] *** Joins: ben_ (~ben@host86-160-225-46.range86-160.btcentralplus.com)
[12:40:19] <Raven737> Hi, I am trying to pg_restore with data only and disable triggers but some tables have already have some (default) values. Is there a way to clean (truncate) tables first?
[12:41:41] *** Quits: Suzumiya (~Mutsumi@99-93-141-12.lightspeed.mssnks.sbcglobal.net) (Ping timeout: 256 seconds)
[12:41:42] *** Quits: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net) (Ping timeout: 252 seconds)
[12:41:56] <Myon> there is a --clean switch
[12:42:05] <Myon> but it won't magically make FKs work
[12:42:40] <Raven737> Using clean and without data only I get errors during the drop of the px "because other objects depend on it"
[12:43:02] <Myon> you can send a manual "delete from tbl"
[12:43:23] <Myon> pg_dump/pg_restore are really only meant to be used with empty databases
[12:44:22] *** Joins: bkkk (~bkkk@dslb-088-070-030-097.088.070.pools.vodafone-ip.de)
[12:44:29] <Raven737> I am using compressed custom format. Is there some way I can "delete from table" for each table in the dump?
[12:45:00] <Myon> pg_restore -l | sed
[12:45:01] <Raven737> The dump is not a full dump of the database but only of a set of seelct tables
[12:45:06] <Raven737> oh thank you
[12:45:15] <Raven737> I will read about and try that
[12:46:04] <peerce> pg_restore can output the sql that it would use to 'restore' per any arguments specified.
[12:46:25] <peerce> Myon's example is exactly that.
[12:46:29] *** Joins: Mutsumi (~Mutsumi@99-93-141-12.lightspeed.mssnks.sbcglobal.net)
[12:46:49] *** Quits: masber (~masber@213.55.224.10) (Quit: Client closed)
[12:48:30] *** Quits: m5zs7k (aquares@web10.mydevil.net) (Read error: Connection reset by peer)
[12:48:48] *** Joins: m5zs7k_ (aquares@web10.mydevil.net)
[12:50:52] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[12:51:12] *** Joins: masber (~masber@213.55.224.10)
[12:53:42] *** Joins: AceSlash (~slash@cosium-fo-152-18.fib.nerim.net)
[12:57:46] *** m5zs7k_ is now known as m5zs7k
[13:01:29] *** Joins: gambl0re (~gambl0re@2607:fea8:a59f:c360::82dc)
[13:02:54] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[13:03:32] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[13:06:39] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[13:06:55] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[13:07:19] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[13:09:17] *** Quits: gambl0re (~gambl0re@2607:fea8:a59f:c360::82dc) (Ping timeout: 250 seconds)
[13:12:16] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Quit: My Mac Pro has gone to sleep. ZZZzzz…)
[13:14:06] *** Quits: jazzy (~jaziz@user/jaziz) (Ping timeout: 272 seconds)
[13:14:16] *** Joins: aLeSD (~aLeSD@80.169.85.234)
[13:16:03] *** Quits: masber (~masber@213.55.224.10) (Quit: Client closed)
[13:16:54] *** Quits: held (~heldchen@user/held) (Ping timeout: 252 seconds)
[13:18:02] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[13:22:56] *** Quits: bkkk (~bkkk@dslb-088-070-030-097.088.070.pools.vodafone-ip.de) ()
[13:23:00] *** Joins: the4thdoctor (~thedoctor@host201-61-234-109.static.ehiweb.it)
[13:23:04] *** Joins: bkkk (~bkkk@dslb-088-070-030-097.088.070.pools.vodafone-ip.de)
[13:23:15] *** Joins: gambl0re (~gambl0re@2607:fea8:a59f:c360::82dc)
[13:25:32] *** Joins: eroux (~eroux@102-65-81-186.ftth.web.africa)
[13:27:29] *** Quits: gambl0re (~gambl0re@2607:fea8:a59f:c360::82dc) (Ping timeout: 250 seconds)
[13:29:33] *** Quits: zachxxz (~zachary@124.133.18.218) (Ping timeout: 252 seconds)
[13:32:01] *** Quits: aLeSD (~aLeSD@80.169.85.234) (Quit: Leaving)
[13:34:14] *** Joins: held (~heldchen@user/held)
[13:34:30] *** Joins: bizolos (~bizolos@2a01:e0a:21e:50e0:d7e9:1241:ef6e:683d)
[13:36:20] *** Parts: FreeBDSM (~FreeBDSM@user/freebdsm) (Leaving)
[13:40:09] *** Quits: carragom (~textual@201.204.94.76) (Quit: Textual IRC Client: www.textualapp.com)
[13:41:49] <merpaderp> is there a way to backup all dbs with pg_dumpall and then use pg_restore, but only restore single database?
[13:42:10] *** Joins: aLeSD[m] (~alambicco@2001:470:69fc:105::1:452a)
[13:43:05] <sliss> how to regex_match an '
[13:45:16] <merpaderp> looks like my only option is to use pg_dump -F c for every db
[13:45:42] <xocolatl> sliss: regexp_match(col, '''')
[13:48:56] *** Joins: Komzzpa (~kom@2a02:220f:2000:2c00:b113:cbb3:ee84:7479)
[13:53:51] <sliss> super thx
[13:54:13] <peerce> merpaderp; simple answerr, 'no'.     pg_dumpall generates sql, and has to be run through psql, not pg_restore.
[13:54:39] <peerce> BUT, I had a simple shell script, that ran pg_dumpall --globals-only, then ran pg_dump -Fc on each database
[13:54:46] <maret> is it possible to figure out what was last row inserted into a table withouth having any timestamp or simple primary key ?
[13:55:08] <Myon> maret: you could have a look at xmin
[13:55:14] <peerce> and those database backups were meant to be restored via pg_resetore
[13:55:20] <peerce> and those database backups were meant to be restored via pg_restore
[13:55:36] <maret> Myon thanks I will
[13:55:59] <Myon> maret: but note it's 32-bit only so it will eventually overflow
[14:01:28] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Read error: Connection reset by peer)
[14:01:48] *** Joins: immibis_ (~hexchat@dynamic-046-114-038-006.46.114.pool.telefonica.de)
[14:03:46] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[14:04:12] *** Quits: immibis (~hexchat@62.156.144.218) (Ping timeout: 240 seconds)
[14:06:29] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[14:09:45] *** Joins: szymon (~ugh@37.120.211.198)
[14:12:33] *** Quits: `2jt (~jtomas@130.red-88-22-46.staticip.rima-tde.net) (Read error: Connection reset by peer)
[14:14:35] <ufk> in general, 'group by' is faster then distinct ?
[14:14:45] *** Joins: `2jt (~jtomas@130.red-88-22-46.staticip.rima-tde.net)
[14:14:56] <ilmari> ufk: distinct is just group by all the columns
[14:14:58] <ilmari> compare the plan
[14:15:08] <ufk> good idea
[14:15:15] <ilmari> always compare the plan
[14:15:32] *** Quits: foul_owl (~kerry@207.244.125.36) (Ping timeout: 272 seconds)
[14:15:34] <merpaderp> peerce: ok thanks, did your script generated list of dbs on its own? like psql -c '\l
[14:15:37] <merpaderp> or something.
[14:19:04] *** Joins: op2 (~op2@user/op2)
[14:20:59] *** Quits: Warped (~Warped@user/warped) (Quit: We Gone! Bye Bye)
[14:25:05] *** Quits: michalz (~michalz@185.246.204.93) (Read error: Connection reset by peer)
[14:25:05] *** Quits: `2jt (~jtomas@130.red-88-22-46.staticip.rima-tde.net) (Remote host closed the connection)
[14:25:15] *** Quits: Junxter (~Junxter@222.95.164.193) (Read error: Connection reset by peer)
[14:25:21] *** Joins: `2jt (~jtomas@130.red-88-22-46.staticip.rima-tde.net)
[14:25:38] *** Joins: Junxter (~Junxter@222.95.164.193)
[14:25:41] *** Joins: michalz (~michalz@185.246.204.93)
[14:25:49] <peerce> yeah it used a psql -c "select name from pg_databases where name not in (..)" sort of thing
[14:26:21] <peerce> oops, datname
[14:27:11] <peerce> select datname from pg_database where not datistemplate;
[14:27:35] <merpaderp> thanks, will hack my own then
[14:28:56] <peerce> i used a date thing to generate a fileame timestamp like '2022-02-15_02-58'  that got used in all the output filenames.
[14:30:41] *** Quits: econo (uid147250@user/econo) (Quit: Connection closed for inactivity)
[14:31:42] <merpaderp> yea and a find command with -mtime and -delete to remove old backups
[14:33:00] *** Quits: cliluw (~cliluw@47.147.73.223) (Ping timeout: 240 seconds)
[14:33:25] *** Joins: cliluw (~cliluw@47.147.73.223)
[14:35:24] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Ping timeout: 240 seconds)
[14:36:26] *** Quits: nyov (~nyov@user/nyov) (Ping timeout: 272 seconds)
[14:38:00] *** Joins: nyov (~nyov@user/nyov)
[14:39:10] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[14:40:40] *** Joins: foul_owl (~kerry@207.244.125.36)
[14:40:44] *** Quits: rendar (~rendar@user/rendar) (Quit: Leaving)
[14:40:55] *** Joins: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net)
[14:42:09] *** Joins: rendar (~rendar@user/rendar)
[14:52:12] *** Quits: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net) (Ping timeout: 240 seconds)
[14:57:46] *** Joins: jpa (~jpa@2a01:e0a:5cb:6b80:9dd8:d715:f031:d21c)
[14:58:07] *** Joins: zlinux (~zlinux@149.109.1.168)
[15:00:41] *** Joins: rodo (~rodo@pop.92-184-117-34.mobile.abo.orange.fr)
[15:00:41] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[15:00:46] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[15:04:26] *** Quits: the_lanetly_052 (~the_lanet@185.30.91.186) (Remote host closed the connection)
[15:04:47] *** Joins: the_lanetly_052 (~the_lanet@185.30.91.186)
[15:05:14] *** Joins: BadAdviceCat (~BadAdvice@user/badadvicecat)
[15:06:39] *** Joins: pedja (~pedja@user/deus-ex/x-7934090)
[15:07:38] *** Joins: enoq (~enoq@194-208-178-35.lampert.tv)
[15:09:41] *** Joins: walterwhip (~www@user/walterwhip)
[15:10:45] *** Quits: bizolos (~bizolos@2a01:e0a:21e:50e0:d7e9:1241:ef6e:683d) (Ping timeout: 252 seconds)
[15:14:36] *** Quits: the_lanetly_052 (~the_lanet@185.30.91.186) (Ping timeout: 252 seconds)
[15:16:01] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[15:16:34] *** Joins: sliss (~sliss@109.136.165.60)
[15:18:17] *** Joins: zlinux_ (~zlinux@149.109.1.168)
[15:18:18] *** Quits: zlinux (~zlinux@149.109.1.168) (Read error: Connection reset by peer)
[15:21:26] *** Quits: rodo (~rodo@pop.92-184-117-34.mobile.abo.orange.fr) (Read error: Connection reset by peer)
[15:24:34] *** Joins: Guest2992 (~Guest29@188.230.128.6)
[15:27:03] *** Joins: zlinux (~zlinux@142.247.18.145)
[15:27:16] <depesz> Hmm .. i have pg 12 on bionic. Replicated to focal, and did reindex of all text-based indexes. but still when I try to pg_dump -s, I get: "pg_dump: error: query failed: SSL SYSCALL error: EOF detected"
[15:27:54] <depesz> in pg logs I see: https://paste.depesz.com/s/1MB
[15:27:58] <depesz> any idea on how to debug/fix it?
[15:28:29] <depesz> i will tear this long pg_dump query into small bits till I will get the error to happen on as small query as possible...
[15:29:14] <ilmari> ??gdb
[15:29:15] <pg_docbot> https://wiki.postgresql.org/wiki/Getting_a_stack_trace_of_a_running_PostgreSQL_backend_on_Linux/BSD
[15:29:28] <ilmari> always first port of call when you get a segfault ^^
[15:29:38] *** Quits: zlinux_ (~zlinux@149.109.1.168) (Ping timeout: 272 seconds)
[15:30:33] *** Quits: waveform (~quassel@waveform.plus.com) (Ping timeout: 252 seconds)
[15:31:01] *** Quits: szymon (~ugh@37.120.211.198) (Remote host closed the connection)
[15:33:11] *** Joins: waveform (~quassel@waveform.plus.com)
[15:38:01] <depesz> will test. thanks.
[15:40:00] *** Joins: maxzor (~maxzor@2a01cb04054faa005e5492c0e79f264a.ipv6.abo.wanadoo.fr)
[15:40:21] *** Quits: maxzor (~maxzor@2a01cb04054faa005e5492c0e79f264a.ipv6.abo.wanadoo.fr) (Remote host closed the connection)
[15:40:40] *** Joins: maxzor (~maxzor@2a01cb04054faa005e5492c0e79f264a.ipv6.abo.wanadoo.fr)
[15:42:11] *** Joins: immibis (~hexchat@dynamic-046-114-038-006.46.114.pool.telefonica.de)
[15:42:50] *** Quits: immibis_ (~hexchat@dynamic-046-114-038-006.46.114.pool.telefonica.de) (Read error: Connection reset by peer)
[15:43:22] <ilmari> ??segfault
[15:43:23] <pg_docbot> Nothing found
[15:44:49] *** Quits: ekathva (~ekathva@n3k04mk1g2jsn5ncy-1.v6.elisa-mobile.fi) (Quit: Leaving)
[15:45:04] <Zr40> ??debug
[15:45:04] <pg_docbot> http://sethc23.github.io/2015/09/20/interactively_debugging_plpython/ :: https://git.postgresql.org/gitweb/?p=pldebugger.git;a=summary
[15:45:08] <Zr40> ??gdb
[15:45:09] <pg_docbot> https://wiki.postgresql.org/wiki/Getting_a_stack_trace_of_a_running_PostgreSQL_backend_on_Linux/BSD
[15:45:40] <Myon> the query seems truncated
[15:46:12] <Zr40> ?learn debug segfault https://wiki.postgresql.org/wiki/Getting_a_stack_trace_of_a_running_PostgreSQL_backend_on_Linux/BSD
[15:46:13] <pg_docbot> Successfully added 2 keywords
[15:50:45] *** Joins: zeden (~zeden@user/zeden)
[15:52:12] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 240 seconds)
[15:56:12] *** Quits: walterwhip (~www@user/walterwhip) (Ping timeout: 240 seconds)
[15:56:42] *** Joins: rufito (~phil@186-79-21-194.baf.movistar.cl)
[15:56:46] *** Quits: immibis (~hexchat@dynamic-046-114-038-006.46.114.pool.telefonica.de) (Read error: Connection reset by peer)
[15:56:53] *** Joins: immibis (~hexchat@dynamic-046-114-038-006.46.114.pool.telefonica.de)
[15:57:40] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Quit: My Mac Pro has gone to sleep. ZZZzzz…)
[15:59:08] *** Quits: schinckel (uid38120@id-38120.ilkley.irccloud.com) (Quit: Connection closed for inactivity)
[16:03:17] *** Joins: joyider (~igloo@81-233-182-147-no86.tbcn.telia.com)
[16:05:17] *** Joins: MrZeus__ (~MrZeus@185.248.85.23)
[16:05:48] <joyider> Does anyone know when an update trigger is fired when you have a transaction with 2 or more updates on the same table? After each update statement or after the transaction commits or some thing else :)
[16:05:52] *** Joins: rufo (~phil@186-79-29-179.baf.movistar.cl)
[16:08:36] *** Quits: joyider (~igloo@81-233-182-147-no86.tbcn.telia.com) (Remote host closed the connection)
[16:08:54] *** Quits: rufito (~phil@186-79-21-194.baf.movistar.cl) (Ping timeout: 272 seconds)
[16:09:57] <ne2k> joyider oh he's gone
[16:11:00] *** Joins: joyider (~igloo@81-233-182-147-no86.tbcn.telia.com)
[16:12:00] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[16:12:06] *** Joins: JordiGH (~jordi@fencepost.gnu.org)
[16:12:06] *** Quits: JordiGH (~jordi@fencepost.gnu.org) (Changing host)
[16:12:06] *** Joins: JordiGH (~jordi@user/jordigh)
[16:17:59] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[16:19:20] <Myon> joyider: by default immediate, but triggers can also be deferred
[16:19:42] <Myon> then it's part of the commit
[16:21:13] *** Quits: joyider (~igloo@81-233-182-147-no86.tbcn.telia.com) (Remote host closed the connection)
[16:23:59] *** Joins: Elodin (~elodin@user/elodin)
[16:24:23] *** Joins: rodo (~rodo@pop.92-184-117-34.mobile.abo.orange.fr)
[16:26:20] *** Joins: Alex8532 (~Alex8532@user/alex8532)
[16:26:22] *** Joins: bizolos (~bizolos@2a01:e0a:21e:50e0:d7e9:1241:ef6e:683d)
[16:27:58] *** Quits: Elodin (~elodin@user/elodin) (Client Quit)
[16:28:56] *** Joins: Elodin (~elodin@user/elodin)
[16:30:30] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 252 seconds)
[16:31:20] <merpaderp> peerce: I think backups doesnt get any easier than this: https://raw.githubusercontent.com/merpkz/MERP/main/random_scripts/postgresql_backup.sh
[16:31:32] <merpaderp> my super simple list databases and backup type of script
[16:31:45] <merpaderp> works best if monitored, ofc
[16:31:52] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[16:32:45] <merpaderp> now when I think about it, it makes sense to remove old backups before taking new ones...
[16:33:41] <koollman> merpaderp: no
[16:33:58] *** Joins: n0fun (~jack@mue-88-130-48-082.dsl.tropolys.de)
[16:34:01] <koollman> merpaderp: imagine your backup fails for some reason. you only remove old ones, never creating new ones
[16:34:18] <merpaderp> koollman: that actually happened to me before
[16:34:28] <merpaderp> I was absolutely flabergasted
[16:34:37] <koollman> so, in this script, the ordering is ok
[16:34:41] <merpaderp> to find gzip error message about empty input instead of my backups
[16:34:53] <koollman> at least if something fails in a detectable way, you don't remove the old backups
[16:34:56] <merpaderp> thanks for reminding me, like, for real.
[16:35:34] <koollman> still need monitoring, but backup older than what you want are still better than no backup at all :)
[16:36:09] <merpaderp> I think I will just make exit code monitoring
[16:36:11] <koollman> my main other suggestion is to use -Fd for the backup
[16:36:22] <merpaderp> shorted flags? dat pedantic
[16:36:49] <koollman> no, directory format for pg_dump, not text format
[16:37:08] <merpaderp> oh, read about that one in manual as well, didn't seemed like I am going to use it
[16:37:16] <koollman> it's worth it
[16:38:22] <koollman> well, I guess you can convert from it anyway, but still... something to consider
[16:38:37] <koollman> oh, and be extra sure you don't have spaces in the db names, but that's a reasonable assumption :)
[16:38:39] <merpaderp> it's then possible to restore just single table and things like that if it's in directory format?
[16:38:45] <koollman> yes
[16:39:03] <koollman> and to restore things in parallel, too. (or even backup them in parallel)
[16:39:48] <merpaderp> that is interesting, maybe having that option is worth it
[16:42:28] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[16:42:32] <merpaderp> welp, that creates a directory per db, so now I either have single backup, which is ok, or remove directories recurisively
[16:43:34] *** Quits: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c) (Remote host closed the connection)
[16:44:22] *** Quits: BadAdviceCat (~BadAdvice@user/badadvicecat) (Ping timeout: 272 seconds)
[16:46:25] *** Joins: SwK_ (~SwK_@190.102.96.6)
[16:47:08] *** Quits: SwK (~SwK_@user/swk) (Read error: Connection reset by peer)
[16:50:42] *** Joins: rewrit3 (~rewrit3@user/rewrit3)
[16:52:38] <aLeSD[m]> hi all
[16:53:47] <aLeSD[m]> I have a table with only a serial as column. Is it possible to insert n rows ?
[16:56:48] <johto> INSERT INTO foo SELECT from generate_Series(1, n);
[16:57:05] <johto> (requires version 9.5 or so)
[16:57:20] <aLeSD[m]> johto: thanks
[16:58:48] *** Quits: Elodin (~elodin@user/elodin) (Read error: Connection reset by peer)
[16:59:10] *** Joins: Elodin (~elodin@user/elodin)
[16:59:18] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[16:59:32] *** Quits: Guest2992 (~Guest29@188.230.128.6) (Quit: Client closed)
[17:02:38] *** Joins: ba|ch (~user@p200300f3a700c4de7bc3a1ba32abf837.dip0.t-ipconnect.de)
[17:07:41] *** Joins: gp5st (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net)
[17:09:16] *** Joins: rjuju_ (~rjuju@82-64-124-11.subs.proxad.net)
[17:10:10] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[17:10:15] *** Joins: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net)
[17:11:00] <strk> does the "CREATE EXTENSION xxx VERSION yyy" support specifying a DEFAULT as yyy ?
[17:11:18] <strk> or if `VERSION yyy` is given, the default version needs to be fetched by the user in some other way ?
[17:13:08] <ilmari> if you want the default version (i.e. whatever's in the extension's control file, don't specify a VERSION clause
[17:13:57] <ilmari>  you can see the available extension versions in the pg_available_extension_versions view
[17:14:43] *** Quits: Atque (~Atque@user/atque) (Quit: ...)
[17:15:24] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[17:19:29] <ba|ch> Hello, I am planning to upgrade my PG 9.6 DB to 14.1 (I am using a lot of PL/pgSQL).  Since the ChangeLog is quite large, I wonder if some blogpost/summary exists for doing such an upgrade?  Do you have any tips for me?  Is there anything I should particularly bear in mind when reading the ChangeLog?
[17:19:48] *** Quits: Haudegen (~quassel@178.115.237.87.static.drei.at) (Quit: Bin weg.)
[17:20:14] *** Joins: BadAdviceCat (~BadAdvice@user/badadvicecat)
[17:21:32] <depesz> ba|ch: pg_upgrade is your friend. or logical replicaiton. and always: 1. run lots of tests on test/dev environment, 2. have backup
[17:21:40] <depesz> ba|ch: how do you read changelogs?
[17:21:51] <depesz> also, which 9.6.?
[17:23:25] <pedja> wow, this is nice. https://why-upgrade.depesz.com/show?from=14.1&to=14.2&keywords=
[17:23:59] <pedja> what's the pgdocbot keyword for it? I presume it exists
[17:24:02] <depesz> thanks. this is what I wanted to suggest to ba|ch -0 obviously with different "from"
[17:24:15] <depesz> no idea, sorry
[17:24:18] *** Joins: joyider (~igloo@81-233-182-147-no86.tbcn.telia.com)
[17:24:20] <depesz> ??changelog
[17:24:20] <pg_docbot> https://bucardo.org/postgres_all_versions.html :: https://www.postgresql.org/docs/devel/static/release.html
[17:24:21] <pg_docbot> https://github.com/davidfetter/changelog_trigger
[17:24:24] <ilmari> ??why
[17:24:25] <pg_docbot> Nothing found
[17:24:37] <depesz> ?learn changelog https://why-upgrade.depesz.com/
[17:24:38] <pg_docbot> Successfully added URL with 1 keyword
[17:24:40] <depesz> ??upgrade
[17:24:41] <pg_docbot> http://why-upgrade.depesz.com/ :: https://www.postgresql.org/docs/current/static/release.html
[17:24:41] <pg_docbot> https://www.postgresql.org/docs/current/static/upgrading.html
[17:24:46] <depesz> there it is :)
[17:25:03] <ilmari> depesz: spanning several major versions, do you really need every minor version inbetween?
[17:25:28] <ilmari> e.g. presumably everything in 10.1 is also in 11
[17:25:39] <depesz> ilmari: not in 11.0
[17:25:55] <ba|ch> That is something I wanted to ask, do I need to read 10.1, 10.2, 10.3 etc?
[17:25:57] <ilmari> 11.0 is about the same time as 10.3
[17:26:16] <ba|ch> Thanks for the URLs!  I am running the latest 9.6.24 - the URLs you're giving me are great starting points.
[17:27:16] <ilmari> depesz: but when upgrading e.g. from 9.6 to 14, the changes in 10.6 are hardly relevant
[17:27:19] <depesz> ilmari: why-upgrade filters out duplicate items
[17:27:44] <depesz> ilmari: well, it lists change at first version the thing happened at.
[17:28:07] *** Joins: dfee (~dfee@c-73-163-174-1.hsd1.dc.comcast.net)
[17:28:17] <depesz> anyway - you can ignore "which version it happened" - the list would still be the same.
[17:28:31] <ilmari> ah, I see
[17:29:29] *** Quits: joyider (~igloo@81-233-182-147-no86.tbcn.telia.com) (Ping timeout: 256 seconds)
[17:29:32] <depesz> the underused feature of why-upgrade is search box, and specifically, the fact that you can search for word prefix*
[17:30:12] *** Quits: the4thdoctor (~thedoctor@host201-61-234-109.static.ehiweb.it) (Ping timeout: 240 seconds)
[17:30:51] <depesz> like: https://why-upgrade.depesz.com/show?from=9.6.24&to=14.2&keywords=index*
[17:31:44] <depesz> heh. pasting the link in here made me get like 20 immediate requests from something "The Lounge IRC Client; +https://github.com/thelounge/thelounge"
[17:33:12] *** Quits: peteyboy1 (~peteyboy1@95.169.226.66) (Read error: Connection reset by peer)
[17:34:54] *** Quits: psoo (~psoo@dslb-090-186-134-090.090.186.pools.vodafone-ip.de) (Quit: Connection closed)
[17:35:19] *** Joins: Rashad (~textual@2a01:9700:1a7c:8900:ddbc:1f8:5c0:689f)
[17:35:36] <ilmari> people like URL previews
[17:36:21] *** Joins: dfee_ (~dfee@c-73-163-174-1.hsd1.dc.comcast.net)
[17:36:56] *** Quits: dfee (~dfee@c-73-163-174-1.hsd1.dc.comcast.net) (Ping timeout: 272 seconds)
[17:37:32] <ilmari> you probably got some from Synapse as well
[17:42:34] <depesz> yepp. less of these, though.
[17:42:39] <depesz> fewer?
[17:44:41] <ilmari> fewer. and it makes sense, because in matrix it's the homeserver that generates the URL preview, not the client
[17:45:05] <ilmari> to avoid leaking client PII
[17:46:25] *** Quits: dfee_ (~dfee@c-73-163-174-1.hsd1.dc.comcast.net) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[17:48:40] *** Joins: Vitto (~Vitto@se-14.nat.univ-paris4.fr)
[17:49:41] *** Quits: jnnnnnnnnn (~jnnnnnnnn@c-2172524e.016-77-73746f43.bbcust.telenor.se) (Remote host closed the connection)
[17:49:48] *** Quits: obimod (~obimod@gateway/vpn/pia/obimod) (Ping timeout: 240 seconds)
[17:49:57] *** Joins: zer0bitz (~zer0bitz@2001:2003:f74d:b800:690a:d027:b8ea:dcab)
[17:50:15] *** Joins: jnnnnnnnnn (~jnnnnnnnn@157.97.164.5)
[17:50:44] <ba|ch> depesz: when doing upgrade from=9.6.24 to=14.2, it says "[..] gives you 3.0 months worth of fixes".  When using from=14.1 to=14.2, it says it gives me 3.0 months wort of fixes.  Is this an error?
[17:51:04] *** Joins: obimod (~obimod@gateway/vpn/pia/obimod)
[17:51:08] <depesz> no.
[17:51:23] *** Quits: zer0bitz_ (~zer0bitz@2001:2003:f74d:b800:5c57:7f45:b808:8adb) (Ping timeout: 250 seconds)
[17:51:23] <depesz> it's virtually impossible to show how much time have passed from version to version.
[17:51:31] <depesz> if the versions are in different majors.
[17:51:41] <ba|ch> Ok, I see. :-)
[17:51:45] <depesz> why-upgrade picks *a* way to calcualte it.
[17:51:53] <depesz> which kinda works, but not always.
[17:52:12] <ba|ch> it was a bit misleading for me when I first looked at it.
[17:52:19] <deepy> why-upgrade is amazing
[17:52:32] <deepy> it also reminds me that I need to upgrade my postgres
[17:52:56] <depesz> 9.6.24 was released 2021-11-11. 14.2 was released 2022-02-10
[17:53:06] <depesz> hence the 3 months.
[17:53:08] *** Joins: dfee (~dfee@c-73-163-174-1.hsd1.dc.comcast.net)
[17:53:25] <depesz> there are 3 months worth of *bugfixes*. and LOOOOONG time for new features.
[17:53:53] <depesz> if you'll figure out a better way to calculate the time diff, i'm open for suggestions.
[17:54:51] *** Quits: zer0bitz (~zer0bitz@2001:2003:f74d:b800:690a:d027:b8ea:dcab) (Ping timeout: 250 seconds)
[17:55:02] *** Joins: psoo (~psoo@dslb-090-186-134-090.090.186.pools.vodafone-ip.de)
[17:55:11] *** Joins: supplicant (~supplican@ec2-52-22-71-188.compute-1.amazonaws.com)
[17:56:54] <ba|ch> Hmm, probably not - I guess you already thought much longer about this then I did.  But I am curious why not "Releasedate(to) - Releasedate(from)" ?
[17:59:33] <depesz> ba|ch: I just showed you that this is what I do. releasedate(14.2) == 2022-02-10. releasedate(9.6.24) == 2021-11-11 ===> 2022-02-10 - 2021-11-11 =~ 3 months
[18:00:36] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[18:00:38] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[18:01:09] <ba|ch> Ah, right, sorry. Hmm, I always truncate 9.6.24 to 9.6.
[18:01:37] *** Quits: vladoski (~vladoski@2001:b07:add:d406:c006:7bd7:322c:328b) (Remote host closed the connection)
[18:02:38] *** Quits: obimod (~obimod@gateway/vpn/pia/obimod) (Quit: every day brings new choices)
[18:03:21] <ba|ch> "It gives you bug fixes worth releasedate(14.2)-releasedate(9.6.24) and features worth releasedate(14)-releasedate(9)" ?
[18:03:35] <depesz> yeah, but that will get long.
[18:03:42] *** Parts: strk (~strk@user/strk) (WeeChat 3.4)
[18:03:46] <depesz> tbh, i'm mostly in favor of removing the time information altogether.
[18:03:56] <depesz> because whatever I did put in there, there were people that didn't like it.
[18:04:17] <ba|ch> yes - anyway, this page is awesome.  The best thing for me is removing duplicated ChangeLog entries and the keyword search functionality I guess.
[18:04:53] <depesz> not to mention that it gets even trickier to do, when someone wants to show changes from, for example, 13.6 to 14.0
[18:05:00] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 240 seconds)
[18:05:24] *** Joins: CodeMouse92 (~CodeMouse@user/codemouse92)
[18:05:56] *** Quits: Rashad (~textual@2a01:9700:1a7c:8900:ddbc:1f8:5c0:689f) (Read error: Connection reset by peer)
[18:07:30] *** Joins: zer0bitz (~zer0bitz@2001:2003:f74d:b800:95ea:d1ff:55f2:9ea6)
[18:15:14] *** Joins: zer0bitz_ (~zer0bitz@2001:2003:f74d:b800:95ea:d1ff:55f2:9ea6)
[18:16:57] *** Quits: zer0bitz (~zer0bitz@2001:2003:f74d:b800:95ea:d1ff:55f2:9ea6) (Ping timeout: 250 seconds)
[18:19:37] *** Joins: Haudegen (~quassel@91.114.49.10)
[18:23:20] <maret> Does postgres create temp data when adding a column to a table? I am adding BIGSerial column to a existing table. It's a bit table and seems like creating takes a lot of data,
[18:23:53] <Berge> maret: Are you adding it with a DEFAULT value (and not using postgres 14)?
[18:24:28] <Berge> No, it doesn't write to a temporary table, but pre-14 (I think), adding a column with a default value required writing to all tuples on disk
[18:25:05] <Berge> oh, no, the add-quickly-with-default-value feature came in 11.
[18:28:08] <maret> Berge no default value I am running  ALTER TABLE results ADD COLUMN id BIGSERIAL PRIMARY KEY;
[18:28:32] <Berge> maret: A PK must have a value, obviously
[18:29:12] <Berge> And it must be unique. And I misread your first statement as "bigint", not bigserial, sorry about that. So yes, in this case, every single row needs to be rewritten.
[18:29:24] <Berge> Since each row will have to get its own value from the serial.
[18:31:21] *** Joins: ponsfrilus1 (~Thunderbi@mob-194-230-146-20.cgn.sunrise.net)
[18:32:36] *** Quits: ponsfrilus (~Thunderbi@vpn-254-202.epfl.ch) (Ping timeout: 240 seconds)
[18:32:36] *** ponsfrilus1 is now known as ponsfrilus
[18:33:41] *** Joins: Klinda (~superleag@user/klinda)
[18:34:33] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[18:35:30] *** Quits: Raven737 (~Raven737@67.205.142.134) (Quit: Client closed)
[18:36:03] *** Quits: zeden (~zeden@user/zeden) (Quit: WeeChat 3.4)
[18:36:55] *** Quits: k_sze (~k_sze@mail2.kalunite.net) (Quit: ZNC 1.8.2 - https://znc.in)
[18:38:41] *** Joins: k_sze (~k_sze@mail2.kalunite.net)
[18:39:00] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 240 seconds)
[18:42:27] *** Joins: zeden (~zeden@user/zeden)
[18:46:57] *** Joins: ivii (~ivan@user/ivii)
[18:53:59] *** Quits: ivii (~ivan@user/ivii) (Remote host closed the connection)
[19:06:01] *** Quits: AceSlash (~slash@cosium-fo-152-18.fib.nerim.net) (Quit: Leaving)
[19:06:15] *** Joins: mattil (~mattil@87-92-28-123.bb.dnainternet.fi)
[19:06:32] *** Joins: gambl0re (~gambl0re@2607:fea8:a59f:c360::82dc)
[19:06:54] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[19:07:10] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[19:11:18] *** Quits: mattil (~mattil@87-92-28-123.bb.dnainternet.fi) (Ping timeout: 272 seconds)
[19:11:18] *** Quits: ponsfrilus (~Thunderbi@mob-194-230-146-20.cgn.sunrise.net) (Read error: Connection reset by peer)
[19:11:35] *** Joins: ponsfrilus (~Thunderbi@adsl-178-39-226-100.adslplus.ch)
[19:12:03] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 256 seconds)
[19:13:18] *** Quits: funhouse (~funhouse@user/funhouse) (Quit: Client closed)
[19:13:27] *** Quits: ba|ch (~user@p200300f3a700c4de7bc3a1ba32abf837.dip0.t-ipconnect.de) (Remote host closed the connection)
[19:13:40] *** Joins: ba|ch (~user@p200300f3a700c4deef5cb672ef1025e7.dip0.t-ipconnect.de)
[19:17:35] <maret> Berge ou ok , the issue is that I have large table with aprox 7.5 billion rows  and 1.7TB of free space, but it isnt enough. I am running out of space and getting ERROR:  could not extend file "base error
[19:18:38] <ilmari> maret: bisgserial is just shorthand for `bigint not null default nextval(<a new sequence>)`
[19:19:12] <johto> new sequence owned by the column
[19:19:17] <ilmari> yes
[19:19:39] <maret> I see still i underestimated how much date will the column take, its 8 bytes per row + size of value it self?
[19:20:03] <ilmari> the ALTER command will creat a whole new copy of the table, with the new column added
[19:20:28] <ilmari> so it needs enough free space for all the live rows in the table, plus the extra column
[19:20:42] <ilmari> an option will be to add the column without a default, then add the default value
[19:20:56] <ilmari> that way it won't rewrite the table, but only new rows will get the default value
[19:21:05] *** Quits: dfee (~dfee@c-73-163-174-1.hsd1.dc.comcast.net) (Ping timeout: 250 seconds)
[19:21:22] <ilmari> then you can gradually UPDATE existing rows, making sure autovacuum is keeping up
[19:21:33] *** Quits: held (~heldchen@user/held) (Ping timeout: 252 seconds)
[19:21:38] <maret> wouldnt that still create a copy of a whole table just withouth data for bigserial column?
[19:22:20] <ilmari> no, adding a column without a default value (or an immuatble default value) is a metadata-only operation
[19:22:51] <ilmari> it just notes in the table header what the value should be for rows that don't have a value stored for that column
[19:23:33] <ilmari> each row header stores how many columns it actually has, so if it's fewer than the table has, it just fills the rest in with NULL or the stored default value
[19:24:15] <ilmari> actually, it's inn the pg_attribute catalog table, not the table header
[19:28:36] *** Quits: ponsfrilus (~Thunderbi@adsl-178-39-226-100.adslplus.ch) (Read error: Connection reset by peer)
[19:29:00] *** Joins: ponsfrilus (~Thunderbi@adsl-178-39-226-100.adslplus.ch)
[19:33:46] *** Joins: held (~heldchen@user/held)
[19:35:17] <liquid-silence> Hello all, I am still pretty stumped with importing a couple of million rows into a postgresql database, it seems to take more than 1 hour for the 250 tables
[19:35:30] <liquid-silence> My environment is in docker though, so it might be an issue.
[19:35:37] <maret> ilmari great thanks !
[19:39:33] <ne2k> liquid-silence, what form is the import?
[19:39:40] <ne2k> as in, what are you actually doing?
[19:39:42] *** Quits: rodo (~rodo@pop.92-184-117-34.mobile.abo.orange.fr) (Ping timeout: 252 seconds)
[19:40:00] *** Joins: magla (~gelignite@d536370e.access.ecotel.net)
[19:40:28] <ne2k> when I started with databases I made the mistake of running lots of individual INSERT statements and being surprised how slow it was. COPY is designed for this sort of thing
[19:40:53] <ne2k> and making sure you create the indexes and constraints afterwards
[19:41:15] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[19:41:27] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[19:41:45] <liquid-silence> @ne2k its a schema and data import using COPY not insert
[19:42:00] <ne2k> liquid-silence, ok, good, just thought I'd check
[19:42:21] <liquid-silence> takes around 1 hours and 30 minutes to import a 4GB sql dump
[19:42:27] <ilmari> liquid-silence: make sure to add any indexes and foreign keys to the tables after importing the data
[19:42:44] <liquid-silence> ilmari: I cannot change the structure of the dump file
[19:42:51] <ne2k> liquid-silence, well, I mean, you can...
[19:42:54] <ne2k> it's just a text fiel
[19:43:06] <ne2k> where did the file come from?
[19:43:11] <ilmari> if it's a plain pg_dump file, it will add the indexes and foreign keys last
[19:43:21] <liquid-silence> yeah it does that @ilmari
[19:43:25] <ilmari> but if the tables already exist, that won't help
[19:43:32] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[19:43:36] <ilmari> (unless it was created with pg_dump --clean)
[19:43:41] <ne2k> liquid-silence, are you importing into an empty database?
[19:43:50] <liquid-silence> Yes no database exists
[19:43:57] <liquid-silence> oh wow I think I know what the problem is
[19:44:00] <ne2k> liquid-silence, what is the underlying storage?
[19:44:03] <liquid-silence> Docker on Mac is POS
[19:44:25] <liquid-silence> I volume mount the data dir in postgresql
[19:44:31] *** Quits: karjala (sid176588@id-176588.lymington.irccloud.com) (Ping timeout: 245 seconds)
[19:44:52] <liquid-silence> I volume mount the data dir for Postgres via the docker-compose
[19:44:54] <liquid-silence> and if I recall volumes with Docker / Mac are slow as hell
[19:44:59] <liquid-silence> ne2k:
[19:45:05] <liquid-silence> m1 pro 1tb ssd
[19:45:48] <liquid-silence> Why is Docker on Mac so slow? Docker on Mac has had some performance issues since the beginning. These are related to volume performance, the way volumes are mounted, and the underlying osxfs filesystem.17 Feb 2021
[19:45:55] <liquid-silence> There is we go, its the volume mount
[19:46:08] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[19:46:09] <maret> How. would I split creating a column and adding default value from sequence? -> ALTER TABLE foo ADD COLUMN ID bigint not null;  CREATE SEQUENCE foo_id_sequence START 1; ALTER TABLE foo ALTER COLUMN id SET DEFAULT nextval('foo_id_sequence');
[19:46:09] <maret> ?
[19:46:24] *** Joins: karjala (sid176588@id-176588.lymington.irccloud.com)
[19:46:56] <ne2k> maret, that isn't going to work for a number of reasons
[19:47:18] <ilmari> ne2k: have you been following the discussion from half an hour ago?
[19:47:32] *** Joins: hoppity (~hoppity@user/hoppity)
[19:47:39] *** Quits: randir (~randir@93.159.239.42) (Remote host closed the connection)
[19:47:48] <ne2k> ilmari, not in detail, let me check
[19:48:12] *** Joins: randir (~randir@93.159.239.42)
[19:48:23] <ilmari> maret: you walso want `alter sequence foo_id_sequence owned by foo.id;`
[19:49:00] <ne2k> you presumably can't add a non-null column without giving it a value. as... what non-null value would it have?
[19:49:30] <ne2k> you'd need to add the not null afterwards
[19:49:33] *** Joins: ncollins (~ncollins@mail.xes-mad.com)
[19:49:41] <ne2k> or am I being stupid?
[19:49:46] <ilmari> yeah, that's correct
[19:50:31] <liquid-silence> ne2k: I am going to run a test now without the volume mount
[19:50:40] <liquid-silence> after I have actually imported the data
[19:50:44] <ne2k> ilmari and so how would be then update a bunch of rows to take successive values from the sequence?
[19:51:13] <ilmari> ne2k: update foo set id = nextval('foo_id_sequence') where ctid in (select ctid from foo where id is null limit 100);
[19:51:24] <ne2k> ilmari surely the best approach would be to just use generate_series, forget the sequence, and then create the sequence afterwards, starting at where you'd got to
[19:51:35] <ne2k> oh, so nextval is clever enough to work like that
[19:51:54] <ilmari> nextval is volatile, so it gets called for each row
[19:52:06] <ilmari> and sequences are non-transactional, so it works even with concurrent updates
[19:52:12] *** Quits: randir (~randir@93.159.239.42) (Ping timeout: 240 seconds)
[19:52:17] <ne2k> fair. well, that approach seems good, then
[19:52:48] <ne2k> so he's worked out that he has enough space for the resultant table with the ids, just not enough space to rewrite the whole thing all at once?
[19:52:53] *** Joins: rodo (~rodo@pop.92-184-106-178.mobile.abo.orange.fr)
[19:53:14] <ne2k> is there some way to brain your ctid approach so it works on specific pages at a time?
[19:53:21] <ilmari> maret: oh, you want to make the column UNIQUE as well
[19:53:47] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[19:55:25] *** Quits: enoq (~enoq@194-208-178-35.lampert.tv) (Quit: enoq)
[19:55:55] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[19:56:16] *** Joins: Simplar (~quassel@188.163.93.241)
[19:56:34] <ilmari> ne2k: i guess you could order by ctid to cluster it, but that still causes an actual sort operation
[19:57:04] <liquid-silence> ilmari, ne2k it is the volume mount
[19:57:41] <ne2k> liquid-silence, well done. you've reinforced my view that Docker is a pointless piece of shit
[19:57:51] <liquid-silence> its pissing me off now
[19:58:16] *** Quits: mncheckm (~mncheck@193.224.205.254) (Ping timeout: 245 seconds)
[19:58:19] <ne2k> the only reason I would use it is to run a piece of software that only comes packaged as a Docker container.
[19:58:25] <ne2k> but maybe I'm missing a trick, who knows
[19:58:58] <ilmari> liquid-silence: there are native postgres packages for macos: https://www.postgresql.org/download/macosx/
[19:59:19] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[19:59:28] <liquid-silence> ilmari: I have to use docker as its cross platform setup
[19:59:40] *** Quits: Vitto (~Vitto@se-14.nat.univ-paris4.fr) (Read error: Connection reset by peer)
[20:00:41] <maret> ilmari good point thanks
[20:01:25] <ne2k> liquid-silence, well, I mean, you don't have to....
[20:03:22] <liquid-silence> ne2k: what's the other option, I have 80+ engineers that need the same setup
[20:03:23] <liquid-silence> :D
[20:03:55] <liquid-silence> ne2k: you can use NFS mounts on Mac that speeds it up considerably
[20:04:11] <ne2k> meh, you know your requirements
[20:05:09] *** Joins: mncheck (~mncheck@193.224.205.254)
[20:05:41] <selckin> or that docker isn't supported on mac, and it has to run linux in a virtual machine
[20:06:22] <liquid-silence> It has a new experimental feature, that uses Big Sums virtualisation framework, not qemu anymore
[20:06:36] <maret> ilmari and also i cant create not null column because i get contains null values error
[20:06:51] <ne2k> maret, I did mention that
[20:07:00] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 240 seconds)
[20:07:23] <liquid-silence> *big sur
[20:07:36] <ne2k> maret, btw, why are you trying to add a serial column to a vast table anyway?
[20:07:47] <ilmari_> maret: yes, ne2k pointed that out. You need to add the constraint after having backfilled all the rows
[20:07:50] *** Joins: randir (~randir@2.92.196.208)
[20:08:05] <maret> sorry missed that
[20:08:29] <maret> ilmari not null constraint or unique or both?
[20:08:52] <maret> ne2k sorry missed that! and I am add serial column because I dont have one yet
[20:09:11] <ne2k> maret, well, obviously, but what do you actually want it for?
[20:09:24] <maret> honestly using ORM which seems to require it
[20:09:32] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[20:09:56] <ilmari_> maret: UNIQUE straight away, NOT NULL afterwards
[20:10:01] *** Joins: sliss (~sliss@109.136.165.60)
[20:10:40] <maret> although actually  maybe I don't need ID column because I need to create unique constraint across 4 columns and id wouldnt help there
[20:10:53] <ilmari_> maret: does it really require a serial column, or just a primary key?
[20:11:11] <maret> it requires unique identifier
[20:11:19] *** Joins: mizi (~mizi@user/mizi)
[20:11:45] <ilmari_> if you have an existing set of not null columns that are unique, you can make that the primary key
[20:12:11] <ilmari_> If the ORM can't handle composite primary keys, it's not fit for purpose
[20:13:35] <maret> yeah to be fair i automatically starting to add id column because I was used to it, but nwo thinking about it, from business point of view id column doesnt help me
[20:14:05] <maret> and I need composite unique key anyway
[20:15:42] <ne2k> ??keyvil
[20:15:42] <pg_docbot> http://www.databasesoup.com/2015/03/primary-keyvil-reprised.html
[20:15:46] <ne2k> aren't you glad I asked
[20:16:23] *** Joins: mattil (~mattil@87-92-28-123.bb.dnainternet.fi)
[20:16:56] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[20:17:37] <maret> ilmari_ it should handle that and it maks more sense to have composite primary key , btw is there a way to add composite unique constraint withouth running out of the space? seems like postgres copies table too or?
[20:17:39] *** Quits: gp5st (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net) (Ping timeout: 252 seconds)
[20:17:46] *** Joins: kinabalu (~kinabalu@198.23.166.98)
[20:17:46] *** Quits: kinabalu (~kinabalu@198.23.166.98) (Changing host)
[20:17:46] *** Joins: kinabalu (~kinabalu@about/java/kinabalu)
[20:17:55] <maret> i am saying that because I tried to run it previously and run out of space
[20:18:17] <ne2k> I don't see why it would copy anything to create a constraint
[20:18:35] <ne2k> it just has to check they are all valid
[20:18:42] *** Joins: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net)
[20:18:54] *** Quits: merzo (~Thunderbi@185.39.197.205) (Quit: merzo)
[20:18:57] <ne2k> of course if there are many, many, many rows, it may not be able to hold all the info to do that checking in RAM, so may do it using temp files
[20:19:15] <ne2k> (I'm making this up, btw, I know nothing about internals,.. ;-)
[20:19:42] *** Joins: mattil__ (~mattil@87-92-28-123.bb.dnainternet.fi)
[20:20:00] *** Quits: mattil__ (~mattil@87-92-28-123.bb.dnainternet.fi) (Read error: Connection reset by peer)
[20:20:19] *** Joins: mattil__ (~mattil@87-92-28-123.bb.dnainternet.fi)
[20:20:58] *** Quits: mattil (~mattil@87-92-28-123.bb.dnainternet.fi) (Ping timeout: 272 seconds)
[20:22:03] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 252 seconds)
[20:22:25] <ilmari> maret: if you already have a unique index, you can `alter table foo add primary key using index index_name;`
[20:22:34] <ilmari> that's a metadata-only operations
[20:23:42] <ilmari> maret: if you don't already have the unique index, creating that will take space, because the index itself takes space
[20:24:36] *** Quits: mattil__ (~mattil@87-92-28-123.bb.dnainternet.fi) (Ping timeout: 240 seconds)
[20:25:22] <ncollins> I'm in the process of configuring a basic primary/replica server pair on Ubuntu 20.04 running Postgresql 12.9 and am encountering an issue where the replica only reads updates from the WAL logs when the postgresql service is restarted. I've been doing extensive testing with streaming replication both enabled and disabled and haven't yet been able
[20:25:22] <ncollins> to get the replica to read logs without restarting postgresql. I put some configuration snippets and logs in https://pastebin.com/raw/P6sz9f63, any input appreciated.
[20:25:55] *** Joins: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net)
[20:30:46] *** Quits: rjuju (~rjuju@2001-b011-1005-1e7d-03a3-07ec-f8b4-aadc.dynamic-ip6.hinet.net) (Quit: Leaving)
[20:31:02] *** Joins: gp5st (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net)
[20:33:00] *** Quits: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net) (Ping timeout: 240 seconds)
[20:33:21] *** Quits: Haudegen (~quassel@91.114.49.10) (Quit: Bin weg.)
[20:34:28] *** Quits: gr33nR10t (~greenriot@user/gr33nr10t) (Read error: Connection reset by peer)
[20:36:19] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Quit: My Mac Pro has gone to sleep. ZZZzzz…)
[20:37:36] *** Joins: gr33nR10t (~greenriot@user/gr33nr10t)
[20:38:35] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570) (Remote host closed the connection)
[20:39:06] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 252 seconds)
[20:39:48] *** Quits: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net) (Ping timeout: 240 seconds)
[20:47:15] *** Joins: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net)
[20:47:31] *** Joins: sagax (~sagax_nb@user/sagax)
[20:51:55] *** Parts: jpa (~jpa@2a01:e0a:5cb:6b80:9dd8:d715:f031:d21c) ()
[20:51:56] <liquid-silence> ne2k: I hate docker now as well
[20:55:10] *** Joins: Auron (Auron956@user/auron)
[20:55:41] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[21:01:06] *** Quits: bizolos (~bizolos@2a01:e0a:21e:50e0:d7e9:1241:ef6e:683d) (Ping timeout: 252 seconds)
[21:01:16] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[21:02:47] *** Quits: rodo (~rodo@pop.92-184-106-178.mobile.abo.orange.fr) (Read error: Connection reset by peer)
[21:03:48] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570)
[21:03:53] *** Joins: Xof (~Xof@157-131-136-66.dedicated.static.sonic.net)
[21:05:12] *** Joins: davidfetter_work (~davidfett@c-73-252-148-184.hsd1.ca.comcast.net)
[21:05:33] *** Quits: ben_ (~ben@host86-160-225-46.range86-160.btcentralplus.com) (Remote host closed the connection)
[21:06:12] *** Quits: ne2k (~andy@212.250.187.98) (Quit: Ex-Chat)
[21:06:13] *** Quits: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net) (Remote host closed the connection)
[21:06:40] *** Joins: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net)
[21:07:04] *** Joins: gmh (~gmh@c-73-244-192-129.hsd1.fl.comcast.net)
[21:07:33] <gmh> Hi guys, is there any way I can get the definition for the function string_agg, I want to  try and migrate it to redshift
[21:07:36] *** Joins: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net)
[21:08:15] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570) (Ping timeout: 252 seconds)
[21:08:28] <peerce> gmh; its undobutably in the postgresql source code.   does redshift allow compiled C functions ?
[21:12:19] *** Quits: ufk (~textual@bzq-84-108-89-219.cablep.bezeqint.net) (Quit: My Mac Pro has gone to sleep. ZZZzzz…)
[21:12:24] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[21:12:53] *** Joins: sliss (~sliss@109.136.165.60)
[21:13:03] *** Joins: tozhu (~tozhu@218.89.244.95)
[21:13:17] *** Joins: newdimension (~newdimnes@user/newdimension)
[21:13:43] <ilmari> redshift is a fork of postgres 8.2 or something ancient like that
[21:15:08] <ilmari> 8.0.2, in fact!
[21:15:10] <ilmari> string_agg was added in 9.0
[21:15:45] <ilmari> gmh: it has LISTAGG: https://docs.aws.amazon.com/redshift/latest/dg/r_LISTAGG.html
[21:15:50] *** Joins: immibis_ (~hexchat@dynamic-089-204-138-014.89.204.138.pool.telefonica.de)
[21:16:21] <ilmari> literally the first hit on https://duckduckgo.com/?q=amazon+redshift+string_agg
[21:16:32] *** Joins: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net)
[21:17:32] *** Joins: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c)
[21:17:34] <gmh> peerce: i dont think it does I was hoping simply to get is definition and add it to functions
[21:17:50] <gmh> ilmari: I will review listagg, thanks
[21:17:54] *** rwb is now known as rb
[21:18:36] *** Quits: immibis (~hexchat@dynamic-046-114-038-006.46.114.pool.telefonica.de) (Ping timeout: 272 seconds)
[21:21:15] <sliss> i would like to look at a 'ft' or a ' in a CASE ... WHEN ('ft' or '''') THEN but it is not working... is there an other way accept making two WHEN's??
[21:21:44] *** Quits: darutoko (~darutoko@37.21.224.109) (Quit: Leaving)
[21:21:50] <sliss> *exept
[21:22:24] *** Quits: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net) (Ping timeout: 272 seconds)
[21:22:31] <sliss> or can I put in a regex?
[21:23:54] <davidfetter_work> sliss, I don't quite understand what you want to do. and yes, there's an excellent regex library.
[21:23:58] <ilmari> case when foo in ('ft', '''') then ...
[21:25:16] <ilmari> the simple form (CASE expr WHEN value THEN ...) only works for single value equality, you need the full CASE WHEN cond THEN ... from for anything more complex
[21:27:33] <sliss> I use the CASE foo WHEN structure, so CASE foo WHEN in ('ft', '''') THEN should work? It gave me a syntax error near in.
[21:27:55] <sliss> ah ok...
[21:28:03] *** Quits: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net) (Ping timeout: 252 seconds)
[21:29:09] *** Quits: marco44 (~marco44@82-64-126-208.subs.proxad.net) (Remote host closed the connection)
[21:29:11] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570)
[21:29:25] *** Joins: marco44 (~marco44@82-64-126-208.subs.proxad.net)
[21:33:33] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570) (Ping timeout: 252 seconds)
[21:35:04] *** Quits: psoo (~psoo@dslb-090-186-134-090.090.186.pools.vodafone-ip.de) (Ping timeout: 272 seconds)
[21:39:37] *** Joins: Rashad (~textual@2a01:9700:1a7c:8900:d0ba:80af:b42:3745)
[21:39:41] *** Quits: turlando (~turlando@user/turlando) (Ping timeout: 256 seconds)
[21:40:20] *** Joins: Haudegen (~quassel@178.115.237.87.static.drei.at)
[21:41:24] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 272 seconds)
[21:42:00] *** Joins: turlando (~turlando@93-42-250-112.ip89.fastwebnet.it)
[21:42:00] *** Quits: turlando (~turlando@93-42-250-112.ip89.fastwebnet.it) (Changing host)
[21:42:00] *** Joins: turlando (~turlando@user/turlando)
[21:42:27] *** Joins: dba (uid533975@id-533975.hampstead.irccloud.com)
[21:42:59] <dba> Can somebody help with this https://bpa.st/VUIQ I am getting an error `ERROR:  there is no unique constraint matching given keys for referenced table "purchase"`
[21:43:12] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[21:45:40] <ilmari> dba: you need a unique constraint on supplier(supplierid)
[21:46:21] *** Quits: Junxter (~Junxter@222.95.164.193) (Read error: Connection reset by peer)
[21:46:21] <maret> ilmari sorry had to go afk, does creating of a index take more space than index it self ? meaning are there some temp data?
[21:48:14] <maret> reason I am asking is to estimate how much the creation process can take , my table is around 1.8TB and I have 1.7 space left
[21:48:45] *** Quits: acidsys (~LSD@2a03:4000:55:d20::3) (Excess Flood)
[21:49:24] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[21:51:26] *** Joins: acidsys (~LSD@2a03:4000:55:d20::3)
[21:51:57] <ilmari> creating an index does not take any extra space beyond the index itself, afaik
[21:52:21] <ilmari> if you can attach more storage, you could create the index on a different tablespace
[21:52:45] <ilmari> but I would expect the index to take less space than the table, unless it covers most of the columns in it
[21:54:57] <ilmari> dba: actually the error is slightly misleading: a unique index is enough, you don't need an actual constraint
[21:58:39] <dba> ilmari, how can i fix it? or how do i figure out the solution?
[21:59:22] *** Quits: magla (~gelignite@d536370e.access.ecotel.net) (Quit: Stay safe!)
[21:59:24] <ilmari> dba: create unique index on supplier (supplierid);
[21:59:48] <ilmari> but judging from the name that should probably be the primary key
[22:00:09] <dba> ilmari, it is indeed
[22:01:48] <ilmari> oh, I misread your error message, it's complaining about the `purchasedate date references purchase(purchasedate)`
[22:02:09] *** Quits: Rashad (~textual@2a01:9700:1a7c:8900:d0ba:80af:b42:3745) (Ping timeout: 252 seconds)
[22:02:11] <ilmari> there's no reason to have that column at all in the purchasedetail table
[22:02:35] <ilmari> since you can get the date by joining to the purchase table
[22:03:52] <dba> ilmari, Thank you very much removing the purchasedate frm the table solved the problem
[22:06:04] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570)
[22:08:12] *** Quits: Ergo^ (~ergo@91.238.59.144) (Remote host closed the connection)
[22:08:17] *** Quits: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net) (Remote host closed the connection)
[22:08:43] *** Joins: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net)
[22:09:16] *** Quits: BadAdviceCat (~BadAdvice@user/badadvicecat) (Ping timeout: 272 seconds)
[22:09:23] *** Joins: Nekomander (~BadAdvice@user/badadvicecat)
[22:10:25] <maret> btw correct me if I am wrong but if I already have two indexes one for  column A and second for column B and I am about to do unique constraint across 4 columns including A and B I might as well drop indexes and create UNIQUE index across those 4 columns right?
[22:10:37] *** Joins: Rashad (~textual@2a01:9700:1a7c:8900:658f:58fa:f5cc:30bb)
[22:10:39] *** Quits: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net) (Remote host closed the connection)
[22:10:57] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570) (Ping timeout: 252 seconds)
[22:11:05] *** Joins: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net)
[22:11:07] *** Quits: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net) (Client Quit)
[22:13:12] *** Quits: sliss (~sliss@109.136.165.60) (Quit: sliss)
[22:14:07] <johto> maret; the one index on (b) alone can be useful
[22:15:35] <maret> HWO SO ?
[22:18:24] <johto> an index on  (a, b, c, d)  is often not very useful for a query such as  WHERE b = 1
[22:19:36] *** Joins: LuxuryMode (uid91005@id-91005.ilkley.irccloud.com)
[22:21:43] <maret> afaik from what i read postgres should be able to use combined index for b = 1;
[22:21:50] *** Joins: econo (uid147250@user/econo)
[22:22:10] *** Joins: serafeim (serafeim@2001:41d0:700:1ccb::10)
[22:23:33] <serafeim> hello friends, i'm using the postgresql fts with the greek_stem configuration (pg 13). this works great for greek but does not match english nice. if i use the english_stem it won't match greek nice. is there a way to compare these ?
[22:23:53] <serafeim> so i'll get good stemming for both langs ?
[22:25:09] *** Joins: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net)
[22:26:36] <johto> maret; it can, but it's extremely inefficient in most cases
[22:28:52] *** Joins: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net)
[22:30:12] *** Quits: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net) (Ping timeout: 240 seconds)
[22:31:01] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570)
[22:32:09] *** Quits: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net) (Client Quit)
[22:32:40] *** Joins: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net)
[22:32:45] *** Quits: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net) (Client Quit)
[22:34:14] *** Joins: aremaref (~aremaref@107-198-1-161.lightspeed.irvnca.sbcglobal.net)
[22:35:13] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[22:35:16] <LuxuryMode> Is there a way to determine how many MB or GB of data were transferred when executing a query from a remote server?
[22:35:39] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570) (Ping timeout: 250 seconds)
[22:35:44] *** Quits: TMM_ (hp@amanda.tmm.cx) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[22:35:45] *** Quits: Simplar (~quassel@188.163.93.241) (Quit: https://quassel-irc.org - Chat comfortably. Anywhere.)
[22:35:49] *** Quits: rvalue (~rvalue@user/rvalue) (Read error: Connection reset by peer)
[22:35:51] *** Joins: TMM_ (hp@amanda.tmm.cx)
[22:35:52] *** Quits: mthall (~quassel@mail.thalliman.com) (Ping timeout: 272 seconds)
[22:35:54] *** Joins: mthall_ (~quassel@mail.thalliman.com)
[22:36:02] *** Joins: rvalue (~rvalue@user/rvalue)
[22:37:20] *** Quits: jnnnnnnnnn (~jnnnnnnnn@157.97.164.5) (Quit: Textual IRC Client: www.textualapp.com)
[22:37:45] *** Quits: veesh (~veesh@5.28.147.93) (Ping timeout: 256 seconds)
[22:38:05] <StuckMojo> LuxuryMode: you'd probably have to use an external tool, like iftop or something
[22:39:36] <LuxuryMode> thanks StuckMojo
[22:40:26] *** Joins: feld (~feld@107-208-180-225.lightspeed.mdsnwi.sbcglobal.net)
[22:47:54] *** Quits: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[22:48:48] *** Joins: MrZeus_ (~MrZeus@185.248.85.10)
[22:50:46] *** Joins: veesh (~veesh@89.237.109.60)
[22:51:07] *** Joins: jazzy (~jaziz@user/jaziz)
[22:51:48] *** Quits: MrZeus__ (~MrZeus@185.248.85.23) (Ping timeout: 240 seconds)
[22:53:28] *** Quits: mexen (uid495612@user/mexen) (Quit: Connection closed for inactivity)
[22:55:30] *** Quits: john_johnk (~Thunderbi@232.58.140.77.rev.sfr.net) (Ping timeout: 272 seconds)
[22:55:38] *** Quits: tozhu (~tozhu@218.89.244.95) (Ping timeout: 250 seconds)
[22:55:55] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570)
[23:00:27] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:417c:95d2:471b:6570) (Ping timeout: 252 seconds)
[23:02:14] *** Quits: newdimension (~newdimnes@user/newdimension) (Remote host closed the connection)
[23:03:58] *** Joins: Exterminador (sid116151@user/pegasus)
[23:26:23] *** Quits: fcr (~fran@r186-48-76-186.dialup.adsl.anteldata.net.uy) (Read error: Connection reset by peer)
[23:26:48] *** mst_ is now known as mst
[23:27:24] *** Quits: james_la1 (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 252 seconds)
[23:33:23] *** Joins: fcr (~fran@r167-56-63-10.dialup.adsl.anteldata.net.uy)
[23:34:16] *** Quits: Alex8532 (~Alex8532@user/alex8532) (Quit: Going offline, see ya! (www.adiirc.com))
[23:34:34] *** Joins: DevAntoine (~DevAntoin@78.193.133.12)
[23:35:57] *** Joins: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net)
[23:39:30] *** Quits: DevAntoine (~DevAntoin@78.193.133.12) (Ping timeout: 252 seconds)
[23:39:38] *** Joins: supplica_ (~supplican@ool-44c6b790.dyn.optonline.net)
[23:41:51] *** Quits: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net) (Remote host closed the connection)
[23:42:10] *** Joins: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net)
[23:42:13] *** Joins: ben_ (~ben@host86-160-225-46.range86-160.btcentralplus.com)
[23:42:23] *** Quits: supplicant (~supplican@ec2-52-22-71-188.compute-1.amazonaws.com) (Ping timeout: 250 seconds)
[23:42:55] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[23:43:34] *** Joins: Tenchi (~Tenchi@user/tenchi)
[23:45:10] *** Joins: kakashiAL (~kakashi@p5b31684e.dip0.t-ipconnect.de)
[23:46:06] *** Quits: gmh (~gmh@c-73-244-192-129.hsd1.fl.comcast.net) (Ping timeout: 252 seconds)
[23:46:48] *** Quits: xenoterracide (~xenoterra@99-124-139-34.lightspeed.iplsin.sbcglobal.net) (Ping timeout: 272 seconds)
[23:48:50] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[23:52:08] *** Quits: v0idpwn (sid483136@helmsley.irccloud.com) (Ping timeout: 268 seconds)
[23:52:42] *** Quits: dingdreher (~dingdrehe@2a02:aa08:401e:fff2:9980:28d:a4a3:60f) (Ping timeout: 252 seconds)
[23:54:07] *** Joins: Komzpa (~kom@2a02:220f:2000:2c00:d6e5:55f1:99ff:20b6)
[23:54:08] *** Quits: midipix (~midipix@mail.culturestrings.org) (Quit: ZNC 1.7.5 - https://znc.in)
[23:54:24] *** Joins: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net)
[23:54:47] *** Joins: jkavalik_ (~jkavalik@ip-78-102-141-139.net.upcbroadband.cz)
[23:55:57] *** Joins: v0idpwn (sid483136@id-483136.helmsley.irccloud.com)
[23:56:14] *** Joins: jazzy2 (~jaziz@user/jaziz)
[23:57:27] *** Joins: magla (~gelignite@d536370e.access.ecotel.net)
[23:57:39] *** Quits: Komzzpa (~kom@2a02:220f:2000:2c00:b113:cbb3:ee84:7479) (Ping timeout: 252 seconds)
[23:57:41] *** Quits: jkavalik (~jkavalik@ip-78-102-141-139.net.upcbroadband.cz) (Ping timeout: 268 seconds)
[23:59:32] *** Joins: sliss (~sliss@109.136.165.60)
