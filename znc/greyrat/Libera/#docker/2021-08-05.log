[00:01:20] <ada_> cluelessperson: typically, containers talk to each other via tcp/udp over a docker network
[00:01:42] <ada_> cluelessperson: if you're doing something like RPC, you can just use the other container's name to resolve it
[00:01:52] *** Joins: TheSilentLink (~TheSilent@user/thesilentlink)
[00:01:58] <ada_> cluelessperson: can you give a working example of what you'd like to solve?
[00:04:53] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Remote host closed the connection)
[00:12:09] *** Quits: irrgit (~irrgit@192.241.175.183) (Quit: Leaving)
[00:12:23] *** Joins: irrgit (~irrgit@192.241.175.183)
[00:18:16] *** Quits: yamchah2 (~yamchah2@user/yamchah2) (Ping timeout: 258 seconds)
[00:19:07] <Lutin> Meh I need to debug a forward rule...
[00:19:32] *** Joins: yamchah2 (~yamchah2@user/yamchah2)
[00:27:21] *** Quits: andycooper (uid246432@id-246432.brockwell.irccloud.com) (Quit: Connection closed for inactivity)
[00:29:37] *** Quits: c10l (~c10l@89.34.167.207) (Quit: Ping timeout (120 seconds))
[00:29:56] *** Joins: c10l (~c10l@89.34.167.207)
[00:32:41] *** Quits: c10l (~c10l@89.34.167.207) (Client Quit)
[00:33:04] *** Joins: c10l (~c10l@89.34.167.207)
[00:36:11] <Lutin> ada_ have you used ufw with docker ?
[00:38:07] <ada_> no I usually turn it off
[00:38:14] <ada_> I think there's an easy way to put docker into ufw's allow list, though
[00:41:04] <zoredache> I mostly have found that trying to use docker with any other firewall/iptables management tool just results in pain, even if the tool claims to work correctly with docker.
[00:41:38] <ada_> agree
[00:41:53] *** Quits: c10l (~c10l@89.34.167.207) (Ping timeout: 250 seconds)
[00:41:54] <ada_> I'm used to iptables interface, so I am not very motivated to learn firewalld/ufw
[00:45:05] *** Quits: Haxxa (~Haxxa@89nnjg0xckz9ggn6r5xm.ip6.superloop.com) (Quit: Haxxa flies away.)
[00:47:48] *** Joins: Haxxa (~Haxxa@122.199.45.186)
[00:48:20] *** Joins: alzgh (~alzgh@216.155.158.214)
[00:49:16] *** Joins: c10l (~c10l@89.34.167.207)
[00:49:41] *** Parts: rhu (~rhu@84.71.117.34) (WeeChat 2.8)
[00:49:42] *** Quits: vidbina_ (~vid@dynamic-089-014-101-244.89.14.pool.telefonica.de) (Ping timeout: 258 seconds)
[01:14:32] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Read error: Connection reset by peer)
[01:18:55] *** Joins: dostoyevsky2 (~sck@user/dostoyevsky2)
[01:21:43] *** Joins: keypushe- (keypusher@user/keypusher)
[01:23:16] *** Quits: keypusher (keypusher@user/keypusher) (Ping timeout: 272 seconds)
[01:23:29] *** Joins: junktext (~junktext@109.201.152.167)
[01:23:55] *** Quits: junktext (~junktext@109.201.152.167) (Client Quit)
[01:24:58] *** keypushe- is now known as keypusher
[01:25:19] *** Joins: matsaman (~matsaman@user/matsaman)
[01:26:14] <matsaman> so I get an 'Error' for one item during build from docker-compose -- what do I pass to get actual verbose information on that error? Is there an env var for it?
[01:34:15] *** Quits: [diablo] (~diablo]@user/diablo/x-9068044) (Quit: The Lounge - https://thelounge.chat)
[01:35:45] *** Joins: [diablo] (~diablo]@user/diablo/x-9068044)
[01:37:42] *** Joins: thiras (~thiras@user/thiras)
[01:42:30] *** Parts: matsaman (~matsaman@user/matsaman) ()
[01:43:31] *** Joins: pvdp (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au)
[01:46:06] *** Quits: BtbN (btbn@ffmpeg/developer/btbn) (Remote host closed the connection)
[01:46:09] *** Quits: Nothing4You (N4Y@nothing4you.w.tf-w.tf) (Remote host closed the connection)
[01:46:21] *** Joins: BtbN (btbn@ffmpeg/developer/btbn)
[01:47:37] *** Joins: Nothing4You (N4Y@nothing4you.w.tf-w.tf)
[01:51:18] *** Quits: BenjiProd (~BenjiProd@user/benjiprod) (Remote host closed the connection)
[01:52:57] <Lutin> ada_ yeah you used "dedicated" FW's in front ? I mostly do as well as VM or so but this is a different case
[01:53:22] <Lutin> zoredache yeah.. ufw is pretty well supported but there are "things" indeed
[01:53:23] <Lutin> brb
[01:53:27] *** Quits: Lutin (~Lutin@user/lutin) (Quit: Lutin)
[01:53:32] *** Quits: yamchah2 (~yamchah2@user/yamchah2) (Ping timeout: 268 seconds)
[01:54:52] *** Joins: yamchah2 (~yamchah2@user/yamchah2)
[01:58:58] *** Joins: Lutin (~Lutin@user/lutin)
[02:00:15] *** Joins: vidbina_ (~vid@dynamic-089-014-101-244.89.14.pool.telefonica.de)
[02:00:42] *** Quits: indigaz (~indigaz@c-73-168-117-231.hsd1.in.comcast.net) (Read error: Connection reset by peer)
[02:01:07] *** Joins: indigaz (~indigaz@c-73-168-117-231.hsd1.in.comcast.net)
[02:08:07] *** Quits: lilgopher (~textual@c-73-51-174-246.hsd1.il.comcast.net) (Quit: Textual IRC Client: www.textualapp.com)
[02:09:53] *** Joins: scaleww (~scaleww@77-41-20-31.ftth.glasoperator.nl)
[02:11:20] *** Joins: auk (auk@gateway/vpn/protonvpn/auk)
[02:15:22] *** Quits: vidbina_ (~vid@dynamic-089-014-101-244.89.14.pool.telefonica.de) (Ping timeout: 240 seconds)
[02:24:31] *** Joins: jarthur_ (~jarthur@2603-8080-1540-002d-b0eb-14a2-3229-7a8f.res6.spectrum.com)
[02:24:38] <auk> Stderr: cgroups: cgroup mountpoint does not exist: unknown
[02:24:43] <auk> ^ getting this error
[02:25:09] <auk> is this something to do with cgroups v2 / mismatch of os and docker versions?
[02:26:33] *** Quits: jarthur (~jarthur@2603-8080-1540-002d-9410-1ec0-4d93-e07a.res6.spectrum.com) (Ping timeout: 252 seconds)
[02:26:41] *** Quits: scaleww (~scaleww@77-41-20-31.ftth.glasoperator.nl) (Ping timeout: 258 seconds)
[02:28:45] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 252 seconds)
[02:33:23] <Lutin> ada_ back!
[02:39:20] *** Quits: Lyn (~Lyn@user/law) (Ping timeout: 258 seconds)
[02:40:08] *** Quits: fedenix (~fedenix@gateway/tor-sasl/fedenix) (Remote host closed the connection)
[02:40:40] *** Joins: pjs (~pjs@user/pjs)
[02:43:33] <pjs> Hi all. Not very docker literate here. If I have an image built from a docker file (ie, docker build -f <file> .), and I make an update to the Dockerfile, do I have to do a full rebuild of the image or is there a way to update the existing image built from the Dockerfile?
[02:47:42] *** Quits: linsux (~metbsd@user/linsux) (Quit: byeircer)
[02:49:34] *** Parts: ash_worksi (~ash_m@user/ash-m/x-3292451) ()
[02:50:07] *** Joins: linsux (~metbsd@user/linsux)
[02:59:39] <cluelessperson> ada_,   docker exec other_container media_scanner /directory/
[02:59:55] *** Quits: martums (~martums@user/martums) (Read error: Connection reset by peer)
[03:00:47] <cluelessperson> pjs, docker images are built one layer at a time for each line/command in the dockerfile.   If you alter a dockerfile, it'll reuse the existing layers up to that point.
[03:01:31] <cluelessperson> pjs, this is also why you'll see some using line continuation like \ to string multiple commands into one RUN command, so it only creates one new layer
[03:06:28] <tabakhase> pjs both & neither - yes it will redo all, but there is also "layer cache" than will make the "redoing take 0 seconds" (with then a few rules to follow to make this work correctly) 
[03:06:42] <tabakhase> https://docs.docker.com/develop/develop-images/dockerfile_best-practices/
[03:07:39] <tabakhase> notably, "this only works on the same host" layers arent trusted when they come from a remote ((but if you own it, --cache-from=... can bypass this)) (you still need to manually pull the image first)
[03:07:58] <tabakhase> common to see in say CI where the whole runner gets thrown away
[03:09:57] *** Quits: mohabaks_ (~mohabaks@gateway/tor-sasl/mohabaks) (Ping timeout: 244 seconds)
[03:25:37] <pjs> thanks
[03:26:02] <pjs> I must be doing something wrong because it's redoing everything every time and eating up a few G's each time (having to clean up images/containers after 3-4 updates)
[03:27:14] *** Quits: DoofusCanadensis (~DoofusCan@207.229.38.10) (Quit: So long, suckers)
[03:44:24] <programmerq> pjs▸ you may need to adjust the order of your instructions to optimize for the build cache.
[03:44:43] <wez> That's normal for Docker to eat up all of your resources.
[03:44:48] <programmerq> for example doing a COPY . /some/path really high up will mean that any change to anywhere in your build context will bust the cache from that point forward
[03:45:17] <programmerq> if you share your Dockerfile in a pastebin/gist more specific optimizations could be recommended.
[03:49:29] *** Quits: p_stampy (~p_stampy@user/p-stampy/x-2915953) (Ping timeout: 252 seconds)
[03:49:29] *** Quits: c10l (~c10l@89.34.167.207) (Ping timeout: 258 seconds)
[03:52:48] <tabakhase> *insert clap emoji* dockerfile review
[03:52:59] *** Joins: c10l (~c10l@89.34.167.207)
[03:53:15] <pjs> thanks all. Sure give me a second to paste it (middle of a build lol)
[03:54:06] <tabakhase> also maybe ship a "ls -l" and ifg you have it contents of ".dockerignore" ((its like gitignore, but for dockers packign step to quickly cut out stuff like your ".git" dir 
[03:54:29] <pjs> programmerq: actually that makes sense. The COPY is high up and obviously I'm making changes that would be copied there. 
[03:54:48] *** Joins: p_stampy (~p_stampy@user/p-stampy/x-2915953)
[03:55:41] <tabakhase> your code copy/add likely should be one of the last real steps, maybe a compile after if needed ((and it doesnt matter much for "instant"-layers like CMD that are commonly still below it))
[03:59:19] *** Quits: brickfat (~brickfat@user/brickfat) (Quit: Leaving)
[03:59:40] <pjs> it's OK to set WORKDIR higher up though right?
[04:01:31] <tabakhase> sure
[04:02:17] <Ryu945> Why does version 3 say that group_add is unsupported?  I thought that was supported now?
[04:02:25] <Ryu945> In docker compose
[04:04:28] <tabakhase> pjs its rly just COPY/ADD thats "so bad" - obvs it will always have "your change" to bust that layer and all after, but in some cases (say where you add the root (.) and dont have a "./src" folder(or similar) in your repo youd see "rebuild even when no code changed", the .git is a common curlpit there hence the note on ".dockerignore"
[04:05:27] <tabakhase> Ryu945 nothing wrong with using v2 files 
[04:06:03] <tabakhase> (that whole 3 thing was somewhat a rehash for stack or swarm i think...)
[04:06:08] <pjs> Thank you all. Moving the COPY totally made rebuilding much faster
[04:06:31] <Ryu945> It will not break my containers if I use version 2 since I don't use that?
[04:07:21] <pjs> tabakhase: Good point. I rarely use Docker so today has been fun for sure
[04:07:32] <tabakhase> Ryu945 asside some different key names / some gone/added no, the resulting thing in docker remains all the same
[04:08:05] <tabakhase> Ryu945 actually... is your compose up2date? supposedly "Since 1.27.0, version 2.x and version 3.x schema are merged" oO
[04:08:39] <pjs> another dumb Q, can I label the name of a container when it's run (docker run..) so I can have a consistent way to shell in? Seems like it's assigning random names (trusty_woodpecker, etc.)
[04:09:18] <Ryu945> pjs: Yes you can name it
[04:09:35] <tabakhase> pjs i belive it :D - id like to say docker doesnt have a learnign curve... more a series of steps where the whole way is flipping back and forth between "what stupid is this?!" and "oh... now the last 10 things suddenly make sense" :D
[04:09:45] <Ryu945> pjs: In docker compose, use this line 
[04:09:46] <Ryu945> container_name:
[04:09:59] <tabakhase> --name bla for cli
[04:10:23] <tabakhase> and dont use container_name: in compose... -- with compose you can use the service name
[04:11:17] <pjs> Honestly I'm more comfortable with compose because I've had to use it more frequently. This particular case is all cli. So --name it is
[04:11:26] <pjs> thanks again everyone!
[04:11:26] <ectospasm> How do I prevent docker-compose from setting a host port?  I'm intentionally not defining a host port for some of my containers, yet docker-compose is setting a random host port listening on every host interface (0.0.0.0).  Here's my docker-compose.yml:  https://git.eldon.me/trey/pastes/src/branch/master/docker-compose.yml
[04:12:14] <tabakhase> pjs na "--name" is to "docker" -- if your eusing compose already that does nothing --- but you have "docker-compose exec SERVICENAME" then
[04:12:31] <tabakhase> (where servicename is whatever the you have under services:)
[04:12:36] <Ryu945> is 1.24.1 the lastest version of docker-compose?
[04:13:01] <tabakhase> Ryu945 1.29.2 is current
[04:13:04] <pjs> Got it
[04:13:49] <tabakhase> 1.24 is from mid/early 2019 ;D
[04:14:11] <Ryu945> it says no package named docker-compose is available when I type yum update docker-compose
[04:15:01] <tabakhase> Ryu945 check how you installed it, and update according (or directly download, its just one static compiled binary anyhow)
[04:15:33] <tabakhase> ectospasm ' - "${GITEA_CONTAINER_PORT}"' = only inside port = outside is selected randomly
[04:15:37] <Ryu945> I don't remember.   I was wondering if there was a repository you recommend to set
[04:16:27] <ectospasm> tabakhase:  yes, but that's not what I want.  I don't want the host port to be selected randomly.  I don't want these containers to be reachable from the public Internet.
[04:17:03] <tabakhase> ectospasm the "for every" comes from docker doing 0.0.0.0 if you gave no ip by default - this can be changed in docker/daemon.json, (some consider it a bad insecure default) - but you can overwrite it anythime inside a "-p/ports:" too, - 127.0.0.1:80:8080 = localhost only
[04:17:26] <ectospasm> It looks like docker creates its own firewalld zone, and my public zone doesn't have those random ports exposed.  nmap from another system shows those containers are reachable.
[04:17:34] <ectospasm> tabakhase: I was thinking I'd have to do that.
[04:18:12] <ectospasm> I'd rather set it up in daemon.json, do you happen to know which parameter I need to set?
[04:18:20] <tabakhase> "your firewall" doesnt matter much for docker yea - from its view its more like a router doing NAT
[04:19:33] <tabakhase> think it was just "ip" : "127.0.0.1", ectospasm
[04:20:02] <ectospasm> OK, I'll give that a whirl.
[04:23:36] <Ryu945> I didn't find a repository but I found to commands to upgrade it
[04:24:27] <Ryu945> *two*
[04:28:31] *** Quits: Sasazuka (~Sasazuka@user/sasazuka) (Quit: My MacBook has gone to sleep. ZZZzzz…)
[04:39:19] *** Quits: c10l (~c10l@89.34.167.207) (Ping timeout: 258 seconds)
[04:42:14] *** Joins: ppg- (ppg@068-190-019-202.res.spectrum.com)
[04:42:36] <ppg-> when opening a shell into a docker container, where can I  find the start up scripts?  The ones that automatically start when you start the container?  I've tried googling docker boot scripts but I keep getting guides on how to make docker start on bootup or start containers on bootup
[04:44:31] <tianon> ppg-: "entrypoint" is probably the keyword you're looking for
[04:44:44] <ppg-> thanks!
[04:44:56] *** Joins: eletrotupi (~eletrotup@user/eletrotupi)
[04:46:43] <ppg-> oh, I can use docker inspect to find the entrypoint and cmds it runs, thats what I was looking for, thank you
[04:48:23] *** Joins: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[04:49:38] <tianon> :D
[04:54:44] *** Joins: daddy (~ryan@hashbang/bdfl)
[05:01:33] *** Parts: pjs (~pjs@user/pjs) ()
[05:14:51] *** Quits: blackop (~ocloud@user/blackop) (Ping timeout: 252 seconds)
[05:15:15] *** Joins: blackop (~ocloud@user/blackop)
[05:17:17] *** Joins: Atque (~Atque@user/atque)
[05:17:44] <ectospasm> tabakhase:  turns out setting the "ip" parameter in daemon.json does *NOT* work.  See bug #2999 on GitHub.  I had to explicitly set com.docker.network.bridge.host_binding_ipv4: "127.0.0.1" for both custom networks defined in docker-compose.yml, and then explicitly set the bind address for the host ports I did want to expose publicly.
[05:18:17] <ectospasm> There's a PR for it, but it has not been merged yet.
[05:18:39] *** Joins: Atum_ (~IRC@user/atum/x-2392232)
[05:22:24] *** Quits: auk (auk@gateway/vpn/protonvpn/auk) (Remote host closed the connection)
[05:28:05] *** Joins: auk (auk@gateway/vpn/protonvpn/auk)
[05:28:23] *** Quits: Code_Bleu (~Code_Bleu@user/code-bleu/x-6939963) (Ping timeout: 258 seconds)
[05:30:23] *** Quits: vlm (~vlm@user/vlm) (Quit: "")
[05:31:58] *** Joins: jazzy3 (~jaziz@2600:380:8600:750f:a0eb:13de:7970:4f87)
[05:33:01] *** Quits: alzgh (~alzgh@216.155.158.214) (Quit: Client closed)
[05:34:17] *** Joins: vlm (~vlm@user/vlm)
[05:40:08] *** Joins: Code_Bleu (~Code_Bleu@user/code-bleu/x-6939963)
[05:52:32] *** Quits: Atum_ (~IRC@user/atum/x-2392232) (Quit: Atum_)
[05:58:27] <tabakhase> ectospasm but only "not" with compose? how utterly stupid, but sounds like a thing docker would do indeed :F
[05:58:41] *** Joins: keypushe- (keypusher@user/keypusher)
[05:58:54] *** Quits: keypusher (keypusher@user/keypusher) (Remote host closed the connection)
[06:00:00] <tabakhase> ectospasm guess then best patten would be using some "ports: - ${BIND_IP:-127.0.0.1}:80:8080" - and then setting BIND_IP to 0.0.0.0 or whatever if wanted in ".env"
[06:01:27] *** Joins: Jimmy_H (~Jimmy_H@113.118.5.73)
[06:01:44] *** keypushe- is now known as keypusher
[06:01:45] *** Quits: Bossi (~quassel@p4fc22c5c.dip0.t-ipconnect.de) (Ping timeout: 265 seconds)
[06:01:54] *** Quits: Jimmy_H (~Jimmy_H@113.118.5.73) (Read error: Connection reset by peer)
[06:02:02] <ectospasm> I basically set the custom networks to bind to 127.0.0.1 by default, and only explicitly published the ports I wanted in .env by defining the ${HOST_PORT} to be "0.0.0.0:<ext_port>".  That way, it's intentional if a port is externally published.
[06:06:31] *** Joins: Bossi (~quassel@p5dc597d7.dip0.t-ipconnect.de)
[06:18:13] *** Quits: Code_Bleu (~Code_Bleu@user/code-bleu/x-6939963) (Ping timeout: 258 seconds)
[06:19:43] *** Quits: jarthur_ (~jarthur@2603-8080-1540-002d-b0eb-14a2-3229-7a8f.res6.spectrum.com) (Quit: jarthur_)
[06:22:32] *** Joins: alzgh (~alzgh@216.155.158.214)
[06:23:57] *** Joins: jarthur (~jarthur@2603-8080-1540-002d-b0eb-14a2-3229-7a8f.res6.spectrum.com)
[06:31:22] *** Quits: Lutin (~Lutin@user/lutin) (Quit: Lutin)
[06:32:33] *** Joins: Code_Bleu (~Code_Bleu@user/code-bleu/x-6939963)
[06:34:14] *** Quits: notsponsible (~notsponsi@45.144.113.76) (Ping timeout: 272 seconds)
[06:43:38] *** Joins: notsponsible (~notsponsi@45.144.113.73)
[06:46:29] *** Joins: andycooper (uid246432@id-246432.brockwell.irccloud.com)
[06:53:54] *** Quits: pvalenta (~petr@mail.open-system.cz) (Ping timeout: 240 seconds)
[06:54:31] *** Quits: notsponsible (~notsponsi@45.144.113.73) (Quit: notsponsible)
[07:08:06] *** Joins: notsponsible (~notsponsi@45.144.113.73)
[07:09:23] *** Quits: phalanx (~thelounge@user/phalanx) (Quit: The Lounge - https://thelounge.chat)
[07:14:08] *** Quits: artok (~azo@mobile-access-b04845-49.dhcp.inet.fi) (Quit: work)
[07:16:49] *** Joins: phalanx (~thelounge@user/phalanx)
[07:19:24] *** Joins: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx)
[07:27:35] <auk> if i `RUN bash script.sh`, is that executing in a different environment than the other RUN commands? are changes the script makes not permanenet for the image container?
[07:27:41] *** Quits: Ryu945 (~Ryu945@181.214.227.73) (Quit: Leaving)
[07:29:36] *** Quits: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx) (Remote host closed the connection)
[07:33:22] *** Quits: auk (auk@gateway/vpn/protonvpn/auk) (Remote host closed the connection)
[07:33:25] <alzgh> auk AFAIK, it inherits the same environment as the other scripts, but the changes that `script.sh` may do to the environment are not permanent, meaning the other scripts won't have it. But the changes that `script.sh` does to the image itself are permanent. You can avoid that by running `RUN ./script.sh` instead. Also, I'm a novice and may be
[07:33:26] <alzgh> totally wrong. Just my 2 cents.
[07:36:13] *** Quits: shokohsc (~shokohsc@161.88.195.77.rev.sfr.net) (Read error: Connection reset by peer)
[07:37:14] *** Joins: shokohsc (~shokohsc@161.88.195.77.rev.sfr.net)
[07:37:16] <tabakhase> ./script.sh still wouldnt stay in env - for that you have to "source ./script.sh" - but this still only stays "in this run step" (env-wise that is) -- filesystem changes should remain from whatever of those you pick
[07:39:21] <tabakhase> so to really set a env for the container you have to use "ENV ..." in the dockerfile ((and i guess some systems slurp up /etc/environment but that hangs on some more conditions...))
[07:41:35] <alzgh> True, You can also do `RUN source ./script.sh && next_command && next_command`, but as tabakhase pointed out, the changes in environment won't last after the RUN.
[07:51:03] *** Quits: Code_Bleu (~Code_Bleu@user/code-bleu/x-6939963) (Ping timeout: 252 seconds)
[07:51:22] *** Joins: Code_Bleu (~Code_Bleu@user/code-bleu/x-6939963)
[07:56:38] *** Joins: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx)
[07:58:45] *** Quits: alzgh (~alzgh@216.155.158.214) (Quit: Client closed)
[08:20:00] *** Quits: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx) (Remote host closed the connection)
[08:20:19] *** Joins: auk (auk@gateway/vpn/protonvpn/auk)
[08:21:21] <cim> DOCKER RUN --PRIV
[08:23:59] *** Joins: pvalenta (~petr@mail.open-system.cz)
[08:27:27] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[08:33:43] *** Joins: waldo323__ (~waldo323@d149-67-45-83.clv.wideopenwest.com)
[08:35:46] *** Quits: waldo323_ (~waldo323@d149-67-45-83.clv.wideopenwest.com) (Ping timeout: 240 seconds)
[08:36:34] *** Quits: Atque (~Atque@user/atque) (Quit: ...)
[08:36:36] *** Joins: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx)
[08:39:18] *** p_stampy is now known as mrs_mwsb
[08:39:45] *** mrs_mwsb is now known as p_stampy
[08:40:58] *** Quits: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx) (Ping timeout: 240 seconds)
[09:11:34] *** Quits: auk (auk@gateway/vpn/protonvpn/auk) (Quit: Leaving)
[09:21:31] *** Quits: lemonzest (~lemonzest@user/lemonzest) (Quit: Quitting)
[09:26:22] *** Joins: justyb11 (~justyb@2601:483:500:3ea:4dc4:f6e0:8f19:7ed8)
[09:36:03] *** Quits: andycooper (uid246432@id-246432.brockwell.irccloud.com) (Quit: Connection closed for inactivity)
[09:44:24] *** Joins: oxum (~oxum@122.172.39.197)
[09:44:33] *** Joins: lemonzest (~lemonzest@user/lemonzest)
[09:46:37] *** Joins: rgl (~rgl@bl12-47-147.dsl.telepac.pt)
[09:49:18] *** Quits: oxum (~oxum@122.172.39.197) (Ping timeout: 252 seconds)
[09:50:40] *** Joins: nickjj_ (~nickjj@user/nickjj)
[09:51:06] *** Quits: realies (~realies@user/realies) (Ping timeout: 240 seconds)
[09:53:01] *** Joins: jayray_ (~jayray@user/jayray)
[09:53:44] *** Quits: nickjj (~nickjj@user/nickjj) (Ping timeout: 256 seconds)
[09:54:13] *** Quits: jayray (~jayray@user/jayray) (Read error: Connection reset by peer)
[09:54:27] *** jayray_ is now known as jayray
[09:59:20] *** Quits: momomo (~momomo@user/momomo) (Ping timeout: 258 seconds)
[09:59:24] *** Quits: ppg- (ppg@068-190-019-202.res.spectrum.com) (Ping timeout: 256 seconds)
[10:01:07] *** Joins: momomo (~momomo@user/momomo)
[10:04:09] *** Quits: Bruners (lasseb@178.16.67.227) (Ping timeout: 252 seconds)
[10:18:23] *** Joins: debayer (~ins0mni4c@2603-8000-cf00-0010-edbe-2a5a-b353-8e2e.res6.spectrum.com)
[10:35:39] *** Quits: cmc (~methos@gateway/tor-sasl/cmc) (Remote host closed the connection)
[10:36:07] *** Joins: cmc (~methos@gateway/tor-sasl/cmc)
[10:44:48] *** Quits: zamba (~marius@5.226.162.54) (Read error: Connection reset by peer)
[10:48:30] *** Joins: realies (~realies@user/realies)
[10:56:32] *** jazzy3 is now known as jazy
[10:56:35] *** jazy is now known as jazzy
[11:14:58] *** Quits: BobbyJr2 (~BobbyJr@38.142.116.242) (Ping timeout: 240 seconds)
[11:18:03] *** Joins: _dp (~dp@2a01:4f8:211:1a21::2)
[11:20:48] *** Quits: _dp (~dp@2a01:4f8:211:1a21::2) (Quit: Jesus has left the building)
[11:23:47] *** Joins: Flash_ (~Flash@user/flash)
[11:24:34] *** Quits: Flash (~Flash@user/flash) (Ping timeout: 240 seconds)
[11:27:34] *** Joins: dp_ (~dp@136.243.0.177)
[11:38:56] *** Joins: [diablo]3 (~diablo]@user/diablo/x-9068044)
[11:39:21] *** Joins: vidbina_ (~vid@dynamic-089-012-168-231.89.12.pool.telefonica.de)
[11:40:33] *** Quits: [diablo] (~diablo]@user/diablo/x-9068044) (Ping timeout: 250 seconds)
[11:40:33] *** [diablo]3 is now known as [diablo]
[11:42:47] *** Joins: mohabaks_ (~mohabaks@gateway/tor-sasl/mohabaks)
[11:47:54] *** Joins: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[11:50:54] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 272 seconds)
[11:55:51] *** Joins: kikijiki (~Thunderbi@user/kikijiki)
[11:57:46] *** Quits: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469) (Remote host closed the connection)
[12:02:53] *** Joins: TomyWork (~TomyLobo@p200300e80f133c0099fbaea743b3eb58.dip0.t-ipconnect.de)
[12:14:21] *** Quits: debayer (~ins0mni4c@2603-8000-cf00-0010-edbe-2a5a-b353-8e2e.res6.spectrum.com) (Quit: Client closed)
[12:28:07] *** Quits: dp_ (~dp@136.243.0.177) (Changing host)
[12:28:07] *** Joins: dp_ (~dp@user/dp/x-8792323)
[12:32:21] *** Joins: Lutin (~Lutin@user/lutin)
[12:37:08] *** Joins: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx)
[12:41:33] *** Quits: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx) (Ping timeout: 258 seconds)
[12:43:56] *** Joins: bouncy (~ben@user/benoit)
[12:54:40] *** Quits: securethemews (~securethe@2a00:23c4:1e9b:2f00::1) (Quit: Leaving)
[12:57:28] *** Joins: svm_invictvs (~svm_invic@user/svm-invictvs/x-6696469)
[12:59:03] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Ping timeout: 252 seconds)
[13:26:47] *** Quits: nickjj_ (~nickjj@user/nickjj) (Read error: Connection reset by peer)
[13:27:55] *** Joins: nickjj_ (~nickjj@user/nickjj)
[13:30:47] *** Quits: cmc (~methos@gateway/tor-sasl/cmc) (Remote host closed the connection)
[13:31:09] *** Joins: cmc (~methos@gateway/tor-sasl/cmc)
[13:31:45] *** Joins: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[13:34:50] *** Quits: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 258 seconds)
[13:35:46] *** Joins: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[13:39:03] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 258 seconds)
[13:39:20] *** Quits: jazzy (~jaziz@2600:380:8600:750f:a0eb:13de:7970:4f87) (Read error: Connection reset by peer)
[13:46:30] *** Quits: realies (~realies@user/realies) (Read error: Connection reset by peer)
[13:47:09] *** Joins: realies (~realies@user/realies)
[13:53:08] *** Joins: thiras (~thiras@user/thiras)
[14:01:34] *** Joins: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[14:03:21] *** Joins: securethemews (~securethe@2a00:23c4:1e9b:2f00::1)
[14:04:54] *** Quits: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 268 seconds)
[14:34:05] *** nickjj_ is now known as nickjj
[14:39:13] *** Quits: securethemews (~securethe@2a00:23c4:1e9b:2f00::1) (Quit: Leaving)
[14:40:34] *** Quits: yamchah2 (~yamchah2@user/yamchah2) (Ping timeout: 240 seconds)
[14:43:00] *** Joins: yamchah2 (~yamchah2@user/yamchah2)
[14:49:03] *** Quits: weyhmueller (~weyhmuell@blofeld.nc.w9r.de) (Quit: ZNC 1.8.2 - https://znc.in)
[14:49:57] *** Joins: weyhmueller (~weyhmuell@blofeld.nc.w9r.de)
[14:59:10] *** Quits: realies (~realies@user/realies) (Ping timeout: 256 seconds)
[15:00:03] *** Joins: debayer (~debayer@2603-8000-cf00-0010-edbe-2a5a-b353-8e2e.res6.spectrum.com)
[15:02:38] *** Joins: mike18 (~geri@217-149-163-174.nat.highway.telekom.at)
[15:03:14] <mike18> hi - can i pass a dockerfile an argument to select between 2 apps to run? CMD [ "python", "app.py" ] vs CMD [ "python", "app2.py" ]
[15:03:56] *** Joins: jazzy (~jaziz@2600:380:8600:750f:893b:e73a:55b2:fe00)
[15:03:56] *** Joins: realies (~realies@user/realies)
[15:08:16] <mike18> or is that a bad idea?
[15:08:45] *** Quits: realies (~realies@user/realies) (Ping timeout: 258 seconds)
[15:11:35] *** Joins: realies (~realies@user/realies)
[15:12:33] *** Joins: Jimmy_H (~Jimmy_H@113.118.5.73)
[15:12:55] *** Quits: realies (~realies@user/realies) (Read error: Connection reset by peer)
[15:13:14] *** Joins: realies (~realies@user/realies)
[15:13:16] *** Quits: mike18 (~geri@217-149-163-174.nat.highway.telekom.at) (Remote host closed the connection)
[15:15:41] *** Quits: realies (~realies@user/realies) (Read error: Connection reset by peer)
[15:16:16] *** Joins: realies (~realies@user/realies)
[15:16:43] *** Quits: realies (~realies@user/realies) (Read error: Connection reset by peer)
[15:18:29] *** Joins: mike18 (~geri@216.200.232.252)
[15:29:12] *** Quits: Jimmy_H (~Jimmy_H@113.118.5.73) (Ping timeout: 256 seconds)
[15:32:28] <mike18> hi
[15:32:31] <mike18> hi - can i pass a dockerfile an argument to select between 2 apps to run? CMD [ "python", "app.py" ] vs CMD [ "python", "app2.py" ]
[15:32:35] <mike18> is that a bad idea?
[15:34:32] <Lutin> nope an a bad idea :D
[15:34:44] <Lutin> you could only do it on runtime with an arg
[15:39:02] *** Quits: mike18 (~geri@216.200.232.252) (Ping timeout: 258 seconds)
[15:40:56] *** Joins: realies (~realies@user/realies)
[15:46:32] *** Joins: rgl (~rgl@bl12-47-147.dsl.telepac.pt)
[15:52:02] *** Joins: mike18 (~geri@217-149-162-237.nat.highway.telekom.at)
[15:52:10] <mike18> @Lutin in what sense?
[15:52:18] <mike18> better to have 2 docker files?
[15:52:37] <Lutin> mike18 a docker file creates an image for a service so yes
[15:52:55] <mike18> Dockerfil1 and Dockerfile2 ?
[15:53:25] <mike18> Dockerfile DockerfileServer
[15:53:52] *** Quits: realies (~realies@user/realies) (Ping timeout: 245 seconds)
[15:56:10] <mike18> Lutin: and its file to have 2 dockerfiles in the same dir right?
[15:56:31] <Lutin> you can if you want
[16:15:36] *** Joins: rewrit3 (~rewrit3@user/rewrit3)
[16:22:32] *** Joins: Tera (~Tera@h-85-24-240-165.A218.priv.bahnhof.se)
[16:26:11] *** Joins: phalanx0 (~thelounge@user/phalanx)
[16:28:10] *** Quits: phalanx (~thelounge@user/phalanx) (Ping timeout: 240 seconds)
[16:28:10] *** phalanx0 is now known as phalanx
[16:31:24] *** jazzy is now known as chouxmaker
[16:31:30] *** chouxmaker is now known as jazzy
[16:48:15] <tabakhase> mike18 sure, there are "build args" (ARG appname && CMD python $appname) and when you quote it correctly you can even delay that expansion to "when its run" (opposed to "when its build") - and for just cmd, "docker run myimage python app2.py" or command: python app2.py in a compose file all works perfectly fine too
[16:48:32] <mike18> but better use 2 docker files - aka 2 images?
[16:49:17] <mike18> its for standalone app and server app
[16:49:19] <tabakhase> now if thats the "right thing" kinda depends - if you want to distribute em as "images" your 2nd dockerfile can be a 2-liner (FROM myother, CMD app2)
[16:50:48] <tabakhase> ("delayed expansion" above as in 'you ship it in as docker run --env appname=app2.py myimage" or such
[16:51:06] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 258 seconds)
[16:51:16] <mike18> ok - i try to think whats the advantage of it?
[16:52:48] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Ping timeout: 252 seconds)
[16:53:00] *** Quits: mike18 (~geri@217-149-162-237.nat.highway.telekom.at) (Remote host closed the connection)
[16:53:35] <tabakhase> of what over witch :P its like 4 different patterns :D
[16:54:25] <tabakhase> and all of them can be reasonable to use, or nonsense :D
[17:16:31] *** Quits: metah4ck3r (~meta@user/metah4ck3r) (Quit: WeeChat 3.2)
[17:18:36] <ada_> morning
[17:31:26] *** Joins: thiras (~thiras@user/thiras)
[17:33:58] *** Joins: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[17:34:13] *** Joins: Atum_ (~IRC@user/atum/x-2392232)
[17:36:47] *** Quits: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 245 seconds)
[17:40:22] *** Quits: raub (~Raub_Voge@cpe-107-15-44-154.nc.res.rr.com) (Quit: Leaving.)
[17:41:39] *** Joins: Flyer (~flyer@lol.flyer.org)
[17:42:13] <wez> ada_: evening
[17:54:31] *** Quits: debayer (~debayer@2603-8000-cf00-0010-edbe-2a5a-b353-8e2e.res6.spectrum.com) (Quit: Textual IRC Client: www.textualapp.com)
[17:56:16] *** Joins: night_wulfe (~wulfe@cpe-174-103-156-213.cinci.res.rr.com)
[17:59:17] *** Quits: night_wulfe_ (~wulfe@cpe-174-103-156-213.cinci.res.rr.com) (Ping timeout: 245 seconds)
[18:00:13] *** Joins: rgl (~rgl@bl12-47-147.dsl.telepac.pt)
[18:05:32] *** Joins: andycooper (uid246432@id-246432.brockwell.irccloud.com)
[18:07:45] *** Joins: zitter (~danilodim@93-57-35-194.ip162.fastwebnet.it)
[18:10:00] <zitter> hi, good afternoon/morning/whatever. I have pushed my image:latest on my private registry. Now I've re-created that image and re-pushed on registry with same name but it seems that when you pull it returns the first version. Is it normal? How does it work image's versioning?
[18:12:02] *** Joins: mort (~mort@188.166.114.29)
[18:12:19] <mort> hey, is there any way to have a persistent root partition?
[18:12:45] <mort> for example, I'm currently on macOS, and would like to have a persistent Linux system
[18:15:17] *** Joins: metah4ck3r (~meta@user/metah4ck3r)
[18:16:24] *** Joins: realies (~realies@user/realies)
[18:16:54] *** Quits: pvdp (~Pieter@static-n58-105-183-94.rdl4.qld.optusnet.com.au) (Remote host closed the connection)
[18:17:20] *** Quits: realies (~realies@user/realies) (Read error: Connection reset by peer)
[18:17:52] *** Quits: TheSilentLink (~TheSilent@user/thesilentlink) (Ping timeout: 272 seconds)
[18:19:53] <ada_> mort: use a VM
[18:20:17] <mort> hmm, but docker basically seems ideal here
[18:20:28] <ada_> docker is about applications, not OSes
[18:20:41] <ada_> docker runs a process in a sandbox, but it isn't intended to run entire linux distributions 
[18:20:43] <mort> it's about both, isn't it? You have a full ubuntu system in your container
[18:20:49] <ada_> no, you don't
[18:20:59] <mort> you do though
[18:21:03] <ada_> I mean, the assertion that there's a whole ubuntu system in a container is not correct
[18:21:12] <ada_> the ubuntu base image has a package manager and basic tools
[18:21:28] <ada_> but it doens't have an init system, it doesn't have a logging daemon, it doesn't have x,y,z things that make a linux distribution
[18:21:53] *** Joins: TheSilentLink (~TheSilent@user/thesilentlink)
[18:21:57] <ada_> the use case for docker is narrowly defined;  it's about running a process in isolation
[18:22:50] <mort> well, but the only thing preventing docker from being a full lightweight linux system I can access from my terminal is that the root partition is deleted when the container stops running so I need to apt-get install everything every time
[18:23:25] <ada_> I would still argue that it isn't a full linux system, but you should write a Dockerfile and build an image that has the tools you want in it
[18:23:33] <ada_> that way you don't have to reinstall every time
[18:23:54] <ada_> and you should mount a volume into your container in the place that you expect to create/save/persist the files that you edit/create
[18:24:06] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Ping timeout: 252 seconds)
[18:24:17] <ada_> that way when the container dies and the root fs is removed (as expected) your important data isn't removed along with it
[18:24:46] <mort> but this is my exact point, docker is absolutely perfect for this use case, except that having to reinstall everything every time the container restarts is annoying
[18:25:04] <mort> even if reinstalling means running the Dockerfile again
[18:25:06] <ada_> you should write a Dockerfile and use it to install the tools you want and then build an image from that Dockerfile
[18:25:28] <ada_> you build the Dockerfile into an image, and you run a container based off that image
[18:25:45] <tabakhase> mort your docker IS a vm already on mac :D
[18:26:04] <ada_> an implementation detail
[18:26:06] <mort> then you want to install another package, so you edit the dockerfile, build the dockerfile into an image, and run a new container based off that image
[18:26:12] <ada_> mort: correct
[18:26:13] <mort> just more annoying than `apt install whatever`
[18:26:18] <tabakhase> if inside that vm you then instakll docker again is "up to you" and totally valid too
[18:26:23] <ada_> idk what to tell you, thats the design pattern
[18:26:25] <tabakhase> (this as in make one yourself)
[18:26:30] <ada_> maybe you really need a VM?
[18:26:32] <mort> is there some technical reason why docker has to remove the root partition?
[18:26:43] <ada_> its by design^tm
[18:26:50] <mort> so no
[18:26:54] <mort> what VM would you recommend then?
[18:27:01] <ada_> what OS do you prefer
[18:27:02] <mort> for the use case where you don't need anything graphical
[18:27:14] <mort> well ubuntu is nice
[18:27:17] <ada_> then use that one
[18:27:27] <mort> ubuntu isn't a VM, it's an operating system
[18:27:35] <ada_> I don't understand the question
[18:27:46] <ada_> you could use virtualbox, vmware, multipass, xhyve as your hypervisor
[18:27:51] <ada_> there are lots of options there
[18:27:55] <ada_> virtualbox is pretty easy to use
[18:27:58] <mort> yeah, I'm asking which one of those you would recommend
[18:28:03] <ada_> on linux I use kvm and qemu
[18:28:13] <wez> ada_: parallels, lxc, AWS, Azure, GCP
[18:28:25] <mort> virtualbox doesn't seem that relevant, unless there's some way I don't know to just launch it from the terminal and use it in the terminal
[18:28:30] <ada_> vbox create ...
[18:28:37] <ada_> ssh user@vbox
[18:28:38] <mort> it seems mainly built around the graphical system, having a separate window with a virtual screen
[18:28:51] <ada_> you can pick to install the ubuntu server ISO image and it won't include a desktop
[18:29:04] <ada_> and you don't have to use the graphical interface
[18:29:22] <ada_> but the graphical interface is easier for configuring your VM the first time, then you could use the vbox cli to start/stop it
[18:29:33] <mort> right
[18:29:47] <ada_> you could also use something like vagrant
[18:30:05] <ada_> if you wanted a "purely" terminal based way to do this
[18:30:17] <ada_> i mean you could configure vbox machines from teh cli too
[18:30:27] <ada_> I like vagrant for setting up my vms programmatically
[18:30:39] <ada_> and vagrant can talk to vbox, vmware, aws, azure, etc.  to provision your machine
[18:33:52] *** Quits: metah4ck3r (~meta@user/metah4ck3r) (Quit: WeeChat 3.2)
[18:35:27] *** Joins: metah4ck3r (~meta@user/metah4ck3r)
[18:35:40] *** Joins: realies (~realies@user/realies)
[18:41:54] <wez> mort: Yes, virtualbox can be run from CLI
[18:42:04] <wez> you can set it up to load at boot tooo
[18:42:42] <wez> I am partial to cloudinit
[18:49:10] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 258 seconds)
[18:51:51] <wez> Ramdom question, if someone doesn't respond to you, is it appopriate to ask someone else to ask them if they have you on their ignore list?  Or is this considered pre-teen behaviour?
[18:55:14] *** Joins: withered_wolf (~withered_@1437135-v103.1561-static.stchilaa.metronetinc.net)
[19:02:20] <ada_> how well do you know this person?
[19:03:11] *** toinen is now known as yksi
[19:05:21] <wez> A number of years
[19:06:27] *** Quits: vidbina_ (~vid@dynamic-089-012-168-231.89.12.pool.telefonica.de) (Ping timeout: 250 seconds)
[19:20:39] *** Joins: faceface (~faceface@user/faceface)
[19:20:42] <faceface> helo!
[19:21:08] <faceface> What is 'the best' way to build an image for a node package that calls out to python?
[19:21:44] <faceface> I just tried "FROM node:14-slim AS base ... RUN apt update && apt install python3 -y", but the version of python is so old
[19:21:45] <ada_> faceface: docker build
[19:21:54] <faceface> ada_: very clever
[19:22:34] <ada_> well, there's node:16
[19:22:48] <ada_> the answer is really dependent on what repos you're hitting
[19:22:49] <faceface> before I continue doing this rough type of thing, is that broadly the 'right' way to do it?
[19:22:58] <ada_> generally, yes
[19:23:01] <faceface> ada_: you mean apt repos?
[19:23:16] <ada_> in this case, it does look like apt
[19:23:34] <ada_> what image is node:14 based on?  that would tell you what version of ubuntu repos you're targeting
[19:23:55] <faceface> right, I was thinking to make sure I got a base image with repos that had newer python, but then I wondered if I'm fixing a broken method
[19:24:03] <faceface> OK, I see
[19:24:20] <faceface> I'll try 16 and see what happens, if not I'll look down the hierarchy...
[19:24:35] <faceface> is there some way I can sort of merge a node and a python image?
[19:24:42] <faceface> that was one of my first thoughts
[19:24:44] <ada_> no, there is no merge operation
[19:24:48] <faceface> kk
[19:25:22] *** Quits: zakame (~zakame@user/zakame) (Ping timeout: 240 seconds)
[19:25:37] *** Quits: gschanuel (~gschanuel@user/gschanuel) (Read error: Connection reset by peer)
[19:25:45] <ada_> you could do a multi-stage build, which it looks like you're already doing;  you could specify a FROM node as a stage, and a FROM python as a stage, and then in a third stage do COPY --from node  and COPY --from python and copy all the right folders into the final stage
[19:26:14] <ada_> alternatively, if you already know the right path, you could skip defining the first two stages and just use COPY --from as it takes an image name from dockerhub as an argument
[19:26:55] <faceface> ada_: right, I think I vaguely had that in mind... I guess my question is... is that 'style' preferred over running 'apt update...' within an image? SOmehow feels a bit wrong.
[19:26:58] <ada_> looks to me like node:14-slim uses debian as a base
[19:27:13] <ada_> that probabaly explains why your python is old
[19:27:16] <ada_> because debian
[19:27:17] *** Joins: s0ullight (~s0ullight@212.224.229.49)
[19:27:41] *** Joins: zakame (~zakame@user/zakame)
[19:28:02] <faceface> heh
[19:28:04] <wez> I like debian
[19:28:19] *** Parts: s0ullight (~s0ullight@212.224.229.49) ()
[19:28:19] <faceface> node:14-alpine didn't have apt...
[19:28:25] <wez> Alpine is good too
[19:28:32] <ada_> yeah it uses alpine's apk package manager
[19:28:37] <faceface> I red a blog that sez, don use alpine
[19:28:44] <ada_> why did it say that
[19:28:47] <faceface> (for python)
[19:28:59] <faceface> one moment...
[19:29:18] <wez> faceface: I read a blog that says getting the COVID vacination will give you good 5G reception, but the chinese will intercept it
[19:29:18] <faceface> Using Alpine can make Python Docker builds 50× slower
[19:29:29] <ada_> I mean there is one major difference with alpine in that it uses musl instead of glibc, so things compiled against musl will not have the same glibc bindings, which may not work with other things you've compiled
[19:29:30] <faceface> wez: heh
[19:30:00] <wez> faceface: Blogs aren't usually the best place to get crediable information from 
[19:30:04] <ada_> if you're mixing code from different places, then that is something you need to watch out for
[19:30:06] <faceface> But if you’re using Python, Alpine Linux will quite often: Make your builds much slower. Make your images bigger. Waste your time. On occassion, introduce obscure runtime bugs.
[19:30:18] <gordonjcp> faceface: yeah, that's largely nonsense
[19:30:20] <ada_> but idk I would have to see the justification for why they said that, a technical justification
[19:30:28] <ada_> like, do they publish their test rig?
[19:30:32] <faceface> https://pythonspeed.com/articles/alpine-docker-python/
[19:30:34] <ada_> maybe they're just Doing it Wrong... idk 
[19:30:37] <gordonjcp> faceface: that's written by someone who doesn't know how to package for alpine or python
[19:30:53] <gordonjcp> faceface: yes, it's a blog by someone who doesn't have a clue what they're talking about
[19:31:00] <faceface> this is why I came in here to ask...
[19:31:30] <ada_> it looks like the method they're using relies on pypi which downloads precompiled binaries
[19:31:35] <ada_> so yeah, a musl/glibc problem
[19:31:44] <ada_> so I imagine you'd have to rebuild all the C code behind those modules
[19:31:45] <wez> faceface: I disagree, I have used both debian and alpine, I find that chmoding or chowning your image will double the storage space, it is better to do that in a build image first (using the FROM bleh AS build clause) and then copy from that in your executable image,
[19:31:53] <wez> in both
[19:32:14] <faceface> Python 3.7.3 in node:16-slim ... not /much/ better
[19:32:18] <faceface> but better
[19:32:19] *** Quits: jushur (~human@user/jushur) (Quit:  ¯\_(ツ)_/¯)
[19:32:27] <wez> alpine images, for me, turn out smaller, especially if you use the FROM imagename AS clause
[19:32:37] <zitter> Any idea on how to delete images from my private registry? it is impossibile...
[19:32:48] <wez> zitter: Use the delete command
[19:32:53] <faceface> wez: I don't have enough docker chops to really know how to do that
[19:32:58] <ada_> zitter: send a delete command to the registry API and wait for garbage collection
[19:33:09] <zitter> wez, you mean using CURL? I've tried with no success
[19:33:12] <gordonjcp> wez: exactly
[19:33:19] <gordonjcp> multi-stage builds, folks
[19:33:20] <ada_> zitter: "tried with no success" doesn't tell us much
[19:33:23] <wez> faceface: Read the docker docs, it is the best authoritive source then a random blog
[19:33:29] <ada_> zitter: show us what you did and the reason you think it "didn't work"
[19:33:33] <ada_> !gist
[19:33:40] <ada_> oh boo I thought we had a bot working
[19:33:57] <gordonjcp> faceface: I read that article too, ages ago, and the main thing that struck me was that they do not give any concrete examples that I can use to test their ideas myself
[19:33:57] <wez> gordonjcp: Multi-stage builds for the win!
[19:34:12] <faceface> hmm
[19:34:46] <faceface> OK, so after I'm done building and testing the node, I switch to a python image and copy the node package over?
[19:35:12] <ada_> faceface: what problme are you trying to solve
[19:35:21] <wez> gordonjcp: That blog was probably funded by a company or contained a shite load of ads
[19:35:22] <faceface> heh
[19:35:23] <ada_> faceface: always describe the end state you want to get to, not what you think the solution might be
[19:35:26] <Lutin> wow guys, ufw with automatic rules and docker is really great!
[19:35:37] <wez> gordonjcp: or both
[19:35:42] <gordonjcp> faceface: what I tend to do is create a docker image that builds all my packages, then copy the packages across to a fresh container
[19:35:42] <Lutin> *and woma/en
[19:35:45] <gordonjcp> wez: likely
[19:35:51] <faceface> ada_: My end state is a node package that makes calls out to a python script
[19:36:07] <faceface> I think I has it working with node:16-slim and then apt install python
[19:36:11] <Lutin> wezwhich blog ?
[19:36:15] <Lutin> wez which blog ?
[19:36:26] <wez> Lutin: Ask faceface 
[19:36:33] <gordonjcp> Lutin: 16:00 < faceface> https://pythonspeed.com/articles/alpine-docker-python/
[19:36:43] <wez> thnx gordonjcp 
[19:36:44] * Lutin checks
[19:36:50] <Lutin> wez beer him!
[19:36:51] <ada_> faceface: is node webserver going to be the long-running process?
[19:36:56] <faceface> Great, it's working now
[19:36:56] <gordonjcp> faceface: do you need to compile specific modules for python for that?
[19:36:58] <ada_> faceface: or is python going to spin up a server?
[19:37:01] <faceface> ada_: yes
[19:37:07] <wez> gordonjcp: You are a champ!
[19:37:08] <faceface> sorry, the former
[19:37:22] <ada_> faceface: then I would probably stick with a node image since the entrypoint will be set to start node
[19:37:24] <faceface> ada_: the node process is the webserver, and it periodically runs python
[19:37:25] <wez> Lutin: I wish I could, I am still in lockdown
[19:37:31] <faceface> yup
[19:37:36] <faceface> cool
[19:37:39] <Lutin> wez there is always FedEX!
[19:37:46] <zitter> wez, ada_ https://pastebin.com/vsN0eQjH TIA
[19:37:47] <wez> Lutin: Beer is heavy
[19:37:57] <ada_> pack of hard drives in a box is still the best bandwidth you can get
[19:38:00] <faceface> is there any other consideration using slim over alpine (slim has apt)?
[19:38:10] <Lutin> ada_ indeed
[19:38:13] <wez> ada_: sneakernet is fast too :)
[19:38:21] <faceface> the latency will kill you though
[19:38:23] <zitter> my goal is learn how to delete an image. I can access to registry container too
[19:38:28] <ada_> faceface: no game no life
[19:38:32] <faceface> thanks for help all
[19:38:39] <ada_> zitter: the registry API has a delete command
[19:38:41] <wez> jog the SSDs is both good exercise and great bandwidth :)
[19:38:45] <ada_> zitter: but the bits are not freed from disk until GC runs
[19:38:59] <ada_> zitter: delete the image from the registry API and run garbage collection
[19:39:14] <wez> faceface: alpine has apk
[19:39:20] <ada_> zitter: if it "doesn't work" then show us using your favorite paste tool what you did and any errors that you get
[19:39:36] <ada_> zitter: if you get no errors, show us also the evidence that you see that your image is still in the registry
[19:39:53] <ada_> zitter: you're recreating a screen share;  we cannot help based on the description "didn't work"
[19:40:16] <Lutin> Oh OL PyPI Iwas asked for a hugeass company as devOps... now I had an interview with their "Python Specialist" whicha aimed to be a DevOps and when he wasn't able to tell me what a nullroute does, he thought serving 1 million concurrent users on a single AWS instance is damn HA and I found a nice video about him developing with PyPi for that company... I understood why I didn't fit the team :D
[19:40:48] <Lutin> they CEO's wer pretty confident that I was very technical but... damn their team seemed to lack ;)
[19:41:19] <zitter> step 1) listing catalogs with /v2/_catalog 
[19:41:31] <Lutin> *their
[19:41:58] <Lutin> so since then wez I have my questions/doubts by Python people
[19:42:10] <zitter> step 2) listing tags for related catalog /v2/timekeeper_database/tags/list that returns "latest"
[19:42:16] <ada_> zitter: when your troubleshooting data gets mixed with the chat it becomes very hard to parse.  can you type up your process in a pastebin
[19:42:16] *** Quits: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com) (Quit: WeeChat 3.0.1)
[19:42:30] <ada_> use the literal terminal commands you ran
[19:42:46] <zitter> ada_, the pastebin I've passed before isn't good?
[19:42:58] <ada_> I don't see one from you
[19:43:08] <zitter> https://pastebin.com/vsN0eQjH TIA
[19:43:16] <ada_> ty
[19:43:22] * Lutin points ada_ to https://github.com/shinebayar-g/ufw-docker-automated
[19:43:31] <ada_> oh I do see it now, it just got hilighted weird
[19:43:47] <zitter> I tried even with reg from genuinetools
[19:44:04] <Lutin> ada_ was it the NSA ?
[19:44:13] <wez> I like the NS
[19:44:14] <wez> A
[19:44:21] <ada_> Lutin: CIA NSA WTF BBQ
[19:44:31] <wez> ada_: roflcoptersteamtrain
[19:44:37] *** Joins: brickfat (~brickfat@user/brickfat)
[19:44:39] <Lutin> ada_ they I assume the all BBQ, indeed WTF!
[19:44:59] <Lutin> wez there are pills for that :P
[19:45:12] <wez> Lutin: Indeed there are
[19:45:20] <ada_> zitter: what registry are you using?
[19:45:25] <Lutin> wez to avoid it ;)
[19:45:27] <zitter> ada_, I have also set delete: enabled: true in registry/config.yml 
[19:45:30] <wez> bbl, sleep(36000);
[19:45:33] <zitter> ada_, my own registry
[19:45:38] <ada_> zitter: assuming docker's `registry` image
[19:45:53] <zitter> yes it is 
[19:45:57] <wez> I wish people in this channel didn't ignore me
[19:45:59] <ada_> :looking:
[19:46:05] <wez> bbl
[19:46:10] <zitter> the only thing I dont know how to restart service 
[19:46:18] <zitter> it doesnt have 'docker' command
[19:46:26] <ada_> zitter: "what" doesn't have the docker command
[19:46:29] <ada_> zitter: your workstation?
[19:46:43] <zitter> restart to apply enabled: true to delete in config
[19:46:57] <zitter> docker <-- command not found
[19:47:03] <Lutin> wez sleep well!
[19:47:05] <ada_> yeah I'm asking: where are you running that docker command?
[19:47:10] <ada_> is it on your workstation?  
[19:47:12] <zitter> inside the official registry container
[19:47:17] <ada_> don't be inside the container
[19:47:19] <zitter> yes, my workstation
[19:47:36] <ada_> from your workstation, run "docker restart" on your registry container
[19:47:46] <zitter> yes, I'm running 'docker' command inside registry container
[19:48:03] <ada_> I'm saying: don't be inside the container, run "docker" cli commands from teh host
[19:48:17] <zitter> ok
[19:48:23] <ada_> docker restart $registrycontainer
[19:48:42] <ada_> when you successfully send a DELETE command, curl should respond with an HTTP 202 code
[19:49:12] <ada_> you can use `curl -vvvv` to show all the headers, and after you restart your container, try the DELETE again, and check the return code for an HTTP 202 to confirm
[19:49:30] <ada_> if it fails you should get a 404
[19:50:34] <zitter> well, at moment I don't have container /running or NOT running) in my host
[19:50:56] <ada_> well im super confused then
[19:51:20] <zitter> anyway I don't understand why I have to run docker restart from host, when I have registry in oher pc
[19:51:31] <ada_> well, you didn't explain that at first
[19:51:35] <ada_> so I made an assumption
[19:51:42] <ada_> go to the other pc and use the docker cli there to restart the container ...
[19:52:15] <zitter> the situation is this host_A: is a client host_B is a PC running Docker with an official image of registry. 
[19:52:32] <zitter> host_B is registry.waltertosto.it in my pastebin
[19:52:45] <ada_> well, you're still trying to restart the container, and I think you can figure out how to do that
[19:52:48] <zitter> I can enter inside registry.waltertosto.it
[19:52:59] <ada_> maybe you ssh to the other machine and use the docker cli to restart it?
[19:53:05] <ada_> or walk over to it
[19:53:47] <zitter> If I do a ssh inside the registry (I'm using Portainer) and do a "docker restart" it returns a "sh: docker: not found"
[19:54:33] <zitter> so it seems to me that "docker" binary does not exist inside the official registry image. Can it be?
[19:54:55] <ada_> you don't need it to be
[19:55:11] <ada_> follow the instructions:  from the Docker host running the registry container, execute "docker restart $registry"
[19:55:14] <ada_> do not be inside any container
[19:55:27] <zitter> ok
[19:55:48] <zitter> but from the host, as I wrote earlier, I don't have -at the moment- any runnning contianer
[19:56:04] <ada_> the docker host _that runs the registry_
[19:56:06] <zitter> so first of all I will run an image from my private registry, ok?
[19:56:12] *** Joins: thiras (~thiras@user/thiras)
[19:56:48] <zitter> ah ok
[20:05:06] <zitter> I have restarted the $registry
[20:05:23] <zitter> I've used Portainer GUI
[20:05:48] <zitter> now I have to repeat curl operations, right?
[20:06:11] <zitter> maybe using -vvv to be sure to obtain a 202 status code?
[20:06:36] <ada_> yep
[20:07:22] *** Quits: jazzy (~jaziz@2600:380:8600:750f:893b:e73a:55b2:fe00) (Ping timeout: 258 seconds)
[20:07:27] <zitter> MANIFEST_UNKNOWN error
[20:07:44] <zitter> Let's discover what it does mean...
[20:08:23] <ada_> you need to delete the image by its digest
[20:09:09] <zitter> so the question is: how to get the digest? curl https://registry.waltertosto.it/v2/myubuntu/manifests/mytag
[20:09:09] <zitter>  returns a lot of infos but NOT the digest
[20:11:16] <ada_> show
[20:11:24] *** Joins: artok (~azo@194.196.241.83.in-addr.dgcsystems.net)
[20:11:39] <tabakhase> checkout https://github.com/genuinetools/reg zitter
[20:12:03] <ada_> https://docs.docker.com/registry/spec/api/#deleting-an-image
[20:12:05] <zitter> yeah, I've tried that
[20:12:21] <ada_> make sure you have set the right Accept: header when doing GET or HEAD on the manifest
[20:12:27] <ada_> the docs ^ point that out for registry version >2.3
[20:13:10] <ada_> curl -H "Accept: application/vnd..."
[20:16:19] <zitter> ok, I will try tomorrow... a final question: do you agree with me that is too difficult to accomplish a simple task as deleting an image on a private registry?
[20:16:52] <ada_> subjective
[20:17:24] <zitter> :-P
[20:17:26] <gordonjcp> zitter: compared to the difficulty of running a private registry?
[20:17:45] <ada_> deleting an image isn't really a simple task
[20:17:53] <ada_> the image is a set of layers, and the manifest points to those layers
[20:17:57] <ada_> the layers are shared between many images
[20:18:07] <ada_> it wouldn't be good to simply delete all the layers of the manifest because that might break other images
[20:18:34] <ada_> so the registry needs to delete the _manifest_ while the layers are left intact until GC runs and determines which layers are no longer needed for any image in the registry
[20:19:19] <zitter> gordonjcp, setting up a private registry wasnt too difficoult
[20:22:49] <zitter> anyway,  reg rm registry.waltertosto.it/sha256:d388ba452d5f3f29399fc38c6928a65e4f28328a413c2edeee354569e7ab9bc9 returns "invalid checksum digest format"
[20:24:14] <ada_> you're using the wrong syntax
[20:24:34] <ada_> reg rm registry.domain.com/imagename@sha256:...
[20:28:37] <zitter> oh, thanks
[20:28:53] <zitter> so it deletes the TAG but not the repo
[20:29:13] <ada_> thats right
[20:31:11] <zitter> anyway... thanks a lot for your patience :)
[20:31:48] <ada_> any time
[20:31:59] *** Joins: stkrdknmibalz (~test@rrcs-75-87-43-226.sw.biz.rr.com)
[20:33:01] *** Joins: rgl (~rgl@bl12-47-147.dsl.telepac.pt)
[20:33:41] *** Joins: waldo323_ (~waldo323@d149-67-45-83.clv.wideopenwest.com)
[20:36:06] *** Quits: waldo323__ (~waldo323@d149-67-45-83.clv.wideopenwest.com) (Ping timeout: 252 seconds)
[20:41:36] *** Quits: thiras (~thiras@user/thiras) (Ping timeout: 252 seconds)
[20:42:54] *** Quits: artok (~azo@194.196.241.83.in-addr.dgcsystems.net) (Ping timeout: 276 seconds)
[20:45:09] *** Quits: andycooper (uid246432@id-246432.brockwell.irccloud.com) (Quit: Connection closed for inactivity)
[20:53:29] *** Joins: yaalon (~yaalon@201.171.68.25.dsl.dyn.telnor.net)
[21:01:15] *** Quits: yaalon (~yaalon@201.171.68.25.dsl.dyn.telnor.net) (Read error: Connection reset by peer)
[21:01:58] *** Joins: yaalon (~yaalon@201.171.68.25.dsl.dyn.telnor.net)
[21:09:44] *** Quits: yaalon (~yaalon@201.171.68.25.dsl.dyn.telnor.net) (Remote host closed the connection)
[21:10:57] <Lutin> ada_ now!
[21:11:03] <Lutin> hug me!
[21:11:07] <Lutin> you said any time :)
[21:11:27] * Lutin does hug back as well
[21:12:59] *** Quits: akik (akik@dsl-tkubng22-50de9d-120.dhcp.inet.fi) (Quit: leaving)
[21:15:42] *** Joins: yaalon (~yaalon@201.171.68.25.dsl.dyn.telnor.net)
[21:15:51] *** Joins: akik (akik@dsl-tkubng22-50de9d-120.dhcp.inet.fi)
[21:16:46] *** Quits: TomyWork (~TomyLobo@p200300e80f133c0099fbaea743b3eb58.dip0.t-ipconnect.de) (Quit: Leaving)
[21:17:17] *** Quits: yaalon (~yaalon@201.171.68.25.dsl.dyn.telnor.net) (Remote host closed the connection)
[21:31:52] *** Joins: fedenix (~fedenix@gateway/tor-sasl/fedenix)
[21:42:05] *** Joins: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx)
[21:44:45] *** Joins: Sasazuka (~Sasazuka@user/sasazuka)
[21:50:40] *** Quits: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx) (Ping timeout: 272 seconds)
[22:14:29] *** Joins: DoofusCanadensis (~DoofusCan@207.229.38.10)
[22:19:12] *** Joins: c10l (~c10l@89.34.167.207)
[22:26:41] *** Quits: lemonzest (~lemonzest@user/lemonzest) (Quit: Quitting)
[22:43:11] *** Joins: alzgh (~alzgh@216.155.158.214)
[22:54:42] <zoredache> Can a swarm service use a non-overlay bridge network?
[22:54:54] <ada_> zoredache: I don't think so, no
[22:55:13] *** Quits: realies (~realies@user/realies) (Read error: Connection reset by peer)
[22:55:20] <ada_> but you can attach a plain container to an overlay network if you created the network with the "attachable" flag set
[22:57:01] <zoredache> Right, but I am having a weird issue with overlay networks, but a bridge network works.
[22:57:13] *** Joins: realies (~realies@user/realies)
[22:57:41] <zoredache> So I was kinda hoping I could have the services just skip all the swarm ingress and other network magic and just connect like any other other container
[22:57:59] <ada_> whats the problem with overlay?
[22:58:07] <ada_> you CAN skip the ingress network and publish ports straight to the host
[22:58:56] <zoredache> https://www.irccloud.com/pastebin/dIbKjI0i/
[22:59:27] <zoredache> Haven't totally collected all the data yet, but on a bridge network name resolution between containers works, on an overlay, it doesn't work.
[23:00:21] <ada_> zoredache: the "hostname" field doesn't set a DNS name in the networkdb
[23:00:30] <ada_> it just sets the contents of /etc/hostname inside the container if the container needs to know its own hostname
[23:00:36] *** Quits: TomTom (uid45892@id-45892.charlton.irccloud.com) (Quit: Connection closed for inactivity)
[23:01:34] <zoredache> oh, but I am still confused why it seems to work on a bridge versus overlay
[23:01:52] <ada_> huh
[23:01:57] <ada_> yeah thats a good point
[23:02:34] <ada_> that might be a difference between the bridge driver and the overlay driver
[23:03:07] <ada_> i was under the impression that --hostname would not add to the networkdb
[23:03:19] <ada_> I also don't use ipv6 so I don't know if that is confounding
[23:04:16] <zoredache> what is the option to add a name/alias to network db?
[23:04:21] <ada_> --network-alias
[23:10:22] *** Quits: rgl (~rgl@bl12-47-147.dsl.telepac.pt) (Quit: Leaving)
[23:11:36] <zoredache> adding a --network-alias didn't seem to change anything.  Disabling IPv6 did. Though I want IPv6
[23:12:56] *** Quits: optimant (~prime@user/optimant) (Quit: Quitting)
[23:13:05] *** Joins: optimant (quasselcor@user/optimant)
[23:16:32] <zoredache> On a not quiet unrelated question, is there an easy to use 'secrets' functionality that any one suggests other then what is provided by swarm?
[23:32:20] *** Joins: goldfish (~goldfish@user/goldfish)
[23:40:30] *** Quits: goldfish (~goldfish@user/goldfish) (Ping timeout: 256 seconds)
[23:40:31] *** Joins: goldfish_ (~goldfish@user/goldfish)
[23:41:28] *** Quits: nvmd (~nvmd@user/nvmd) (Quit: Later, nerds.)
[23:45:41] *** Joins: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx)
[23:50:22] *** Quits: yaalon (~yaalon@189.202.79.36.cable.dyn.cableonline.com.mx) (Ping timeout: 272 seconds)
