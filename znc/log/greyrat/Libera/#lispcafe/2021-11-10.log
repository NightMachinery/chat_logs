[00:00:29] <gilberth> hayley: And for Gray Streams? Nothing. But as I said, you need to do your own buffer, and I am surprised, that a CVS reader isn't at least using READ-LINE.
[00:00:29] <hayley> Still, have you checked that the file is being cached and you're not disk IO bound?
[00:00:57] <shka> hayley: yeah, checked that, the file is in the cache
[00:01:45] <shka> gilberth: so yeah, i will be reading line, feed it into read-csv-line, and it should be all better
[00:02:11] <hayley> https://www.youtube.com/watch?v=en9qbih88BU
[00:02:12] -ixelp- Pan Pizza - You Suck at Cooking (episode-134) - YouTube
[00:03:04] <shka> heck, maybe i will feed it multiple lines at the same time
[00:03:15] <shka> it is doable
[00:05:46] <hayley> Yeah, could do with some CSE.
[00:07:38] <shka> my head is hurting
[00:09:03] <shka> i will gonna need read-sequence version of the read-line
[00:10:39] <shka> hmmm, maybe not actually
[00:13:23] <shka> eh, fuck it, i will read the whole file into string
[00:17:57] <hayley> "<Erik Österlund> Yes, many thoughts indeed. The main one being hope https://openjdk.java.net/jeps/421 integrates soon so we can… finalize it. See what I did there?"
[00:17:58] -ixelp- JEP 421: Deprecate Finalization for Removal
[00:29:17] <shka> yeah, so the problem is that fare-csv does not believe in the buffering 
[00:29:58] <shka> gilberth, hayley: thanks you were of good assistance to me 
[00:30:11] <shka> good nigh all
[00:30:24] <shka> i will try to hack this tomorrow 
[00:30:57] <hayley> Take care.
[00:36:33] <mfiano> Maybe it's a sign that CSV belongs on the stack of uselessness with XML and JSON
[00:36:50] <shka> csv is crap, but it is still widely used
[00:36:55] <shka> xml is not a crap imho
[00:37:17] <sham1> XML is crap if you need to interact with it as a huma
[00:37:36] <sham1> For a machine it's brilliant
[00:39:14] <gilberth> It's shit because it still has strings in attributes, which then have their own micro-syntax. Only because you can read XML does not imply that you have an internal representation of the data.
[00:40:18] <sham1> Well the purpose of XML Is to be an external representation of the data, probably for some kind of information interchange
[00:40:53] <gilberth> Yes, and as such it isn't better than a stream of bytes.
[00:41:32] *** Quits: shka (~herr@83.175.151.96.piasta.pl) (Ping timeout: 240 seconds)
[00:42:12] <gilberth> Well, at least you get characters, granted.
[00:43:24] <sham1> Well glossing over the fact that XML is obviously "a stream of bytes", the thing XML has is that it's structured. Of course you can do structure in a non-textual information interchange format like CBOR, which I do prefer over XML and JSON or whatnot, but that's something XML does. It also has some self-documentation and schema properties which could be useful for some stuff
[00:43:45] <gilberth> What is the structure of "M 100 100 L 200 300"?
[00:44:25] <sham1> Ambiguous
[00:44:31] <gilberth> See.
[00:45:27] <gilberth> Could also be written as "M100,100L200 300" obvious? Obvious.
[00:47:01] <sham1> Well if you have something like <M><item>100</item><item>100</item></M>... and so on, it does delimit the stream into discernible units
[00:47:28] <gilberth> Thing is: Attributes have no structures, and still people put things there that has. So I need a specific parser for each XML format. JSON is different, you need only one parser.
[00:48:14] <gilberth> sham1: But you don't in practice.
[00:48:17] <sham1> That's true. People do abuse XML attributes
[00:49:22] <gilberth> They shouldn't exist in the first place. And PCDATA or whatever it is called in XML-speak also is just a sequence of characters. Heck, you cannot even tell a number from a string with XML.
[00:49:42] <gilberth> But this happens when you sell a markup language as a data interchange format.
[00:50:25] <gilberth> May I propose LaTeX as the hottest, newest, kewlest data exchange format?
[00:50:59] <pl> Does it have XSD equivalent plus tooling? 
[00:51:06] <pl> That's what really made XML work for me 
[00:51:12] <sham1> Now now, it clearly has to be PostScript. Since it's actually been used as data interchange with printers
[00:51:27] <sham1> Yeah, XSD does make XML nice since it actually gives it types
[00:52:05] <gilberth> pl: Doesn't change the fact, that XML is a silly idea to begin with. Or rather to use a markup language for data exchange. And XML was sold as the latter.
[00:52:38] <sham1> One could indeed argue that XSD is a bandaid
[00:53:46] <pl> gilberth: well, I disagree in the sense that a) XML works for that if actually implemented instead of pretending b) XSD is used eith schema-first design, not "lol throw some autogenerator at this class" 
[00:56:06] <sham1> Well since this is a Lisp channel, one could also think about the Canonical S-expression encoding
[00:56:29] <gilberth> See, I am not talking about XSD, but about XML. I mean this is as if saying plain text files are fine, because we could spec a DTD for it. And XSD is a hack, which would not have been needed for a data exchange format in the first place.
[00:57:28] <gilberth> sham1: I was told the other other night that s-expressions will never find wide-spread use.
[00:57:38] <pl> gilberth: XSD and XML were designed together, though authoritative XSD spec arrived later. But the data interchange argument depends on the full suite, not small slice 
[00:58:11] <pl> Anyway, of course the right data interchange format is ASN.1 DER with embedded specs 
[00:58:38] <gilberth> pl: Still, why using a markup language as a vehicle? Only because HTML was hot?
[00:59:19] <pl> No, because we (as programmers) have fetish for text formats 
[00:59:56] <pl> There are binary encodings for XML though, a variant of one is even popular for implementing video formats 
[00:59:57] <gilberth> And a fetish for spelling out close parens it seems.
[01:02:24] <gilberth> pl: And we are mixing two things here. A grammar for the data itself, and a generic external representation of a small set of internal objects. XML alone doesn't provide for the latter, you still need specific parsers. While JSON or s-expressions have a generic syntax.
[01:02:52] <gilberth> And I can parse any JSON or s-expression one comes up with in 20 years, right now.
[01:03:29] <sham1> Well one could still stuff a lot of weird data into JSON strings just like one can do with XML attributes
[01:03:37] <pl> Yep 
[01:03:43] <gilberth> Without facing strings of characters at the leaves of my AST.
[01:03:57] <pl> Anyway, you generate parser by running XSD 
[01:04:18] <moon-child> gilberth: 'strings in attributes, which then have their own micro-syntax' you never get away from that.  e.g. CL:FORMAT
[01:04:45] <gilberth> pl: And that is the problem. I can't know the schema you come up in 20 years now.
[01:05:17] <gilberth> This is silly. This is like saying text files are fine because we have lex(1) and yacc(1).
[01:05:25] <pl> gilberth: nor can you figure out what the shit in json is 
[01:05:40] <pl> Not to mention what dialect of json it is 
[01:05:41] <sham1> You still need domain-specific handling of the deserialized JSON or CBOR or whatever data in order to use the interchanged data properly
[01:06:14] <pl> XSD goes into specifying domain, and for example I've used lisp parsers that automatically took in XSD as well 
[01:06:15] <gilberth> pl: Dialect? JSON is an ECMA standard.
[01:06:28] *** Joins: pjb (~pjb@user/pjb)
[01:06:33] <pl> gilberth: ohh you sweet summer child 
[01:06:39] <sham1> Comments in JSON
[01:06:44] <sham1> Thanks Microsoft btw
[01:07:01] <sham1> It's non-standard, and thus you might encounter it or you mightn't
[01:07:20] <gilberth> We get nowhere when we don't talk about a specific format.
[01:07:38] <pl> Strictest JSON encoding is full of painful moments like encoding integers as ints, because JSON doesn't support integers 
[01:08:02] <pl> So you have a lot of "small stringy formats" embedded in it 
[01:08:14] <gilberth> This arguments holds for any file format for which some OOB channel exists people could place funny information at.
[01:08:25] <sham1> Exactly
[01:08:39] <pl> Also, you can't depend on full IEEE floats in JSON too
[01:08:40] <sham1> This is not a technical question
[01:08:50] <pl> Because Mozilla does fun things in doubles 
[01:09:00] <pl> As in, Mozilla uses doubles as pointers 
[01:09:10] *** Joins: dec0d3r (~dec0d3r@2001:8003:480a:e00:e07:e7c3:7efc:ed0f)
[01:09:48] <pl> JSON being shitty format is why so much of it contains BASE64 
[01:10:04] <sham1> Guilty
[01:10:45] <gilberth> pl: Have you read the ECMA standard? Where does it say something about integers?
[01:12:33] <sham1> ECMA doesn't. IETF does
[01:12:46] <pl> It has vague motion of number with no implementation requirements
[01:13:05] <pl> Generally ECMA-json is dead 
[01:13:24] <pl> It's the most strict interpretation, which also fails as basis for interchange 
[01:14:12] <gilberth> Does it fail by design? Or rather because of actual implementations?
[01:14:36] <gilberth> Though I doubt it was actually designed.
[01:14:43] <pjb> by design: it doesn't specify integers other than as a regexp for their token.
[01:14:49] <pjb> [-+][0-9]+
[01:15:03] <gilberth> Which should be suffice.
[01:15:34] <pjb> Nope.  eg. if you try to read a json in C, when it has been written from lisp.
[01:15:55] <pjb> (you can say that C libraries are full of bugs).
[01:15:57] <gilberth> ojb: #include <gmp.h>
[01:16:09] <pjb> indeed.
[01:16:21] <sham1> "This specification allows implementations to set limits on the range and precision of numbers accepted. Since software that implements IEEE 754 binary64 (double precision) numbers is generally available and widely used, good interoperability can be achieved by implementations that expect no more precision or range than these provide, in the sense that implementations will approximate JSON
[01:16:23] <sham1> numbers within the expected precision"
[01:17:32] <sham1> https://datatracker.ietf.org/doc/html/rfc8259#page-8
[01:17:33] -ixelp- rfc8259
[01:18:42] <gilberth> Which, I supposed is an after the fact specification.
[01:19:17] <sham1> So while it doesn't prohibit things such as integers larger than 2**53, it clearly says that an implementation should take this stuff into account
[01:20:31] <gilberth> I doubt many do, as in signalling a runtime error, when they encounter an integer, they are unwilling to represent, and silently cut off enough bits until it fits.
[01:21:45] <sham1> Well that's a potential problem with the interchange
[01:22:42] <gilberth> At least I won't need to write parsers all day. Which was my point.
[01:22:45] *** Joins: Jacobis9000 (~jonaholuf@host86-189-251-32.range86-189.btcentralplus.com)
[01:23:21] <gilberth> I am very tired of needing parsers for this and for that pet syntax one came up with.
[01:27:48] <sham1> And my point is that while you might not need to parse as much pet syntax with something like JSON, you can still get something silly out-of-band and there's really no way of stopping that
[01:30:22] <gilberth> Agreed but as I said this applies to every data format. You can't stop people from doing silly things and mislabel the file format they generate.
[01:33:19] *** Joins: notzmv (~zmv@user/notzmv)
[01:45:56] * hayley uploaded an image: (19KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/UpGLFtKiqOOarNKjbaZOEaOZ/bruhcha.jpg >
[01:46:27] * hayley handrolled a binary format so that there was exactly one valid representation of an object
[01:51:14] <pl> gilberth: remember that original spec for JSON was "whatever will go through eval()"
[01:52:51] <gilberth> Which is a joke and not a spec. :-)
[01:52:54] <sham1> If there is a way to encode arbitrary binary data then that's not happening. But as has been said, that's a thing with literall every useful data interchange format so that's not really a thing to focus on. Usually one rather wants stuff like maybe self-documenting, compactness, or other such qualities
[02:03:15] <hayley> https://www.youtube.com/watch?v=GpBo2XWjC-Y
[02:03:16] -ixelp- Emerson, Lake & Palmer - Hoedown - Live In '73 - YouTube
[02:09:17] *** Joins: OlCe (~user@lfbn-nic-1-526-60.w90-118.abo.wanadoo.fr)
[02:13:29] <Gnuxie> selwyn: https://old.reddit.com/r/LabourUK/comments/qqb0mk/corbyn_vetoed_second_job_for_starmer_in_2017/hjz4cp8/
[02:13:29] -ixelp- ZenpodManc comments on Corbyn vetoed second job for Starmer in 2017
[02:15:03] <Gnuxie> damn
[02:15:15] <Gnuxie> he's got nowhere to go if he's given up his certificate of practice 
[02:28:36] <Jacobis9000> https://www.youtube.com/watch?v=d-7o9xYp7eE
[02:28:37] -ixelp- Don't Talk to the Police - YouTube
[02:28:53] <hayley> Shut the fuck up Friday
[02:29:16] <hayley> https://www.youtube.com/watch?v=sgWHrkDX35o
[02:29:17] -ixelp- SHUT THE FUCK UP FRIDAY! - YouTube
[02:30:01] <hayley> "If you shut the fuck up, we have a good good chance we can make the case go away."
[02:30:46] <Jacobis9000> heh that's a blast from the past
[02:30:48] <Jacobis9000> great video
[02:31:12] <Jacobis9000> this guy making the Don't Talk to the Police lecture is great
[02:31:16] <Jacobis9000> I love American lawyers
[02:43:28] <hayley> https://twitter.com/UATX_phys/status/1458085877213716489
[02:43:29] <hayley> "We wholly reject group theory here at UATX. Groups require an identity element, and we do NOT trade in identity politics."
[02:45:59] <Jacobis9000> I feel like I would get that joke if I knew more maths.
[02:49:16] <Jacobis9000> https://www.youtube.com/watch?v=tcdVC4e6EV4
[02:49:17] -ixelp- Deadly Truth of General AI? - Computerphile - YouTube
[02:49:23] <Jacobis9000> this is a good video
[02:51:32] <hayley> Jacobis9000: A group is a set of elements (call it S) and some operation (call it F) such that for all a, b, c in S, F(a, F(b, c)) = F(F(a, b), c), there exists some "identity" e such that, for all a in S, F(a, e) = F(e, a) = a, and every element in S has some inverse, i.e. for all a in S there exists some b such that F(a, b) = e
[02:52:18] <hayley> For example, addition on integers is a group. It is always the case that a + (b + c) = (a + b) = c, our identity e = 0, and the inverse of some integer x is -x as x + -x = 0
[02:53:08] <Jacobis9000> Thank you for explaining but I am not capable of understanding at this point.
[02:53:58] <Jacobis9000> I do not know enough maths.
[03:03:21] <Jacobis9000> sorry I feel rude
[03:03:27] <Jacobis9000> I can't follow though
[03:03:30] <Jacobis9000> Also I am tired
[03:04:04] <Catie> Jacobis9000: If it helps, I didn't read that as rude at all
[03:06:35] <hayley> https://www.youtube.com/watch?v=by3HklSPpp4
[03:06:36] -ixelp- Every Plumber Ever... | Garn. - YouTube
[03:10:58] <Jacobis9000> Ok that's good Catie
[03:22:05] <hayley> It's funny that people complain about some communication service having deletion or not, when any functional deletion function requires plugging the analog hole, even when such a communication service just runs on one server.
[03:27:36] *** Quits: Inline (~Inline@2a02:908:1252:7a80:6c0:2b98:1609:4e92) (Ping timeout: 245 seconds)
[03:43:32] *** Quits: random-nick (~random-ni@87.116.165.220) (Ping timeout: 240 seconds)
[03:44:40] *** Joins: Inline (~Inline@aftr-37-201-240-235.unity-media.net)
[03:52:32] <Jacobis9000> Oh it is actually Gerald J Sussman who I am watching
[03:52:43] <Jacobis9000> I like him
[03:53:14] <White_Flame> watching the sicp lectures?  they trade off
[03:53:36] <Jacobis9000> I'm on Lecture 1B
[03:54:00] <Jacobis9000> How's it going White_Flame? Nice evening?
[03:54:07] <White_Flame> eh, busy
[03:56:48] <Jacobis9000> I actually discovered Lisp concurrently but coincidentally, one by YT algorithm suggesting me the SICP lectures, but I thought there was only one lecture so only watched one, and was wondering what this wonderful language was he was using, and also my friend told me MUSHcode, which is the first language I ever learned, has been compared to LISP
[03:57:40] <Jacobis9000> so I investigated Lisp, bit of a run on sentence there sorry
[03:59:04] <Jacobis9000> You see these two isolated things happened, but they both related to Lisp, and they both led me to Lisp? I tried to explain the concept of coincidence to a Buddhist monk once, he did not get it (everything is intrinsically karmically linked, cause and effect, things don't just happen at the same time coincidentally in Buddhist thought.)
[04:00:40] <Jacobis9000> And I suppose I can see the karma: I was researching programming languages, so YT began suggesting to me programming lectures, and also I was asking questions of my friend because of my curiosity about programming languages. Thus I caused two seemingly separate events, which led to the same programming language.
[04:02:15] <Jacobis9000> I suppose that is why there is talk of the 'Law of Attraction', but it is not that some supernatural force brings you the focus of your meditations, it is the fundamental interconnectedness of mind and matter, and the power of mind over matter.
[04:03:36] <Jacobis9000> sorry got carried away in thought there
[04:03:48] <Jacobis9000> Glad I found Lisp though
[04:14:07] <Jacobis9000> can you use git with Lisp?
[04:14:36] <Catie> One hundred percent yes, you can
[04:17:29] <Jacobis9000> Thanks, thought so just wanted to check.
[04:24:34] <Jacobis9000> https://www.youtube.com/watch?v=pAX8GAsRaYk
[04:24:35] -ixelp- Is This Why You’re Bad At Programming? - YouTube
[04:25:43] <Jacobis9000> This guy is good, if you can ignore his proselytizing and idealising of science 
[04:25:47] *** Joins: occ (~occ@user/occ)
[04:29:48] <hayley> Betteridge says no.
[04:29:53] <White_Flame> eh, he definitely makes a negative first impressino
[04:30:10] <White_Flame> but any sort of "conclusion" really doesn't make sense, because software development isn't a homogeneous thing
[04:30:13] <Jacobis9000> Yes but what he has to say is good.
[04:30:29] <Jacobis9000> I like the idea of 'pair programming'
[04:30:41] <White_Flame> I mean, I'm only in his first topic, but you can't perform a major refactoring,for instance, under his description of CI
[04:30:56] <White_Flame> even if CI is a generally good thing in the standard forward march of code
[04:31:20] <Jacobis9000> Yes I did wonder that, what if there had to be major changes?
[04:31:46] <White_Flame> so many of these problems that he tries to address comes from bad organization
[04:31:49] <Jacobis9000> I think he slightly idealises, I think it is a tendency of his personality and why he idealises science.
[04:31:58] <White_Flame> too many "software teams" are way too large, and way too driven by externalities
[04:33:16] <White_Flame> and of course, one of his most commonly referred to terms is "devops", so I can safely discard his opinions outright ;)
[04:33:40] * hayley avoids going Terry Davis mode on who's a bad programmer.
[04:34:38] <Jacobis9000> CI sounds good to me. I have never worked in a software team, but I already had concerns about branching from my first discoveries of git.
[04:35:04] <Jacobis9000> CI is kind of how you write Lisp
[04:35:32] <Jacobis9000> Write in REPL, test, if it works, write to file. Or at least, that's how I do it? 
[04:36:00] <White_Flame> "always have a running version" is a common saying, older than the term "continuous integration"
[04:36:29] <Jacobis9000> So here is what I thought about branching, for my own projects:
[04:36:43] <Jacobis9000> I would not touch the Master branch, and only work on a branch, and then merge.
[04:36:48] <Jacobis9000> if the branch is good.
[04:37:20] <Jacobis9000> So work is done in branches and working version of code is always preserved.
[04:37:20] <hayley> The one-more-re-nightmare compatibility policy would be "POSIX compliant until proven otherwise"
[04:38:43] <Jacobis9000> But not have loads of branches. 
[04:38:50] <White_Flame> Jacobis9000: the term CI is always about multi-person teams; doesn't really apply to a single person's dev though
[04:38:58] <Jacobis9000> Yeah
[04:39:04] <White_Flame> you need to make sure your stuff integrates with others' work
[04:39:14] <White_Flame> and that's done by committing and automated build/test processes
[04:39:31] <Jacobis9000> I have just swung the conversation around to something I was thinking about, which is a single person's development process
[04:40:36] <Jacobis9000> but we don't have to talk about that.
[04:41:12] <Jacobis9000> I've gotta hit the hay anyway, work tomorrow
[04:41:20] <Alfr> White_Flame, CI may also be useful for single developer lisp project. Accidentally committing something broken when build from scratch, e.g. some old definition was still in the running image.
[04:41:31] <White_Flame> either way.  Individual devs have different needs, and as I mentioned above, teams in the business sense tend to be screwy and self-defeating anyway ;)
[04:42:00] <White_Flame> Alfr: sure, it just dpeends on how you define "CI".  There's no "integration" in what you say, it's just the "automated compile/test" portion
[04:43:59] <Jacobis9000> I am not at the point I could utilise automated tests
[04:44:01] <Alfr> White_Flame, I don't think integrating program parts can really be automated.
[04:44:38] <White_Flame> Alfr: I mean, there's nobody else's codebase to integrate with.  YOu just have your own.  The automated tests ensure you're committing sane code
[04:44:58] <White_Flame> and as you say, the image nature of lisp might diverge your running code from your saved code, hence the need for clean builds
[04:45:05] <White_Flame> but that's not _technically_ "CI"
[04:45:13] <White_Flame> it uses tools intended for CI, though ;)
[04:46:45] <Alfr> White_Flame, you mean there's no merging? That's true.
[04:47:10] <White_Flame> no, I mean there's no other dev to integrate changes with
[04:47:24] <White_Flame> no other foreign generator of source code
[04:49:30] <Alfr> Hm ... how about rephrasing "I" as follows? "For all devs' works w: merge w and then see what breaks"
[05:02:24] *** Quits: Catie (~user@user/catie) (Quit: heading home)
[05:06:56] <Jacobis9000> right off to bed
[05:07:18] <Jacobis9000> night folks!
[05:11:29] *** Quits: Jacobis9000 (~jonaholuf@host86-189-251-32.range86-189.btcentralplus.com) (Ping timeout: 246 seconds)
[05:12:56] * hayley finishes the demo video with "Thanks for watching" but sadly didn't think to have the laptop ssh'ed in to run /kill hayley for the Alternate Reality Kit reference
[05:13:26] <hayley> https://youtu.be/I9LZ6TnSP40?t=682
[05:13:26] -ixelp- Alternate Reality Kit by Randall Smith at Xerox PARC 1986 (VPRI-0131) - YouTube
[05:20:03] <moon-child> 'let us denote the two triangles T₁ and T₂; the vertices of T₁ and T₂ by V₀¹,V₁¹,V₂¹, and V₀²,V₁²,V₂² respectively'
[05:20:10] <moon-child> are you zero-indexed or one-indexed?  Make up your mind!
[05:20:30] *** Quits: wheelsucker (~user@2600:8801:8c1a:5d00::ddb8) (Remote host closed the connection)
[05:20:36] <hayley> lol
[05:21:26] <hayley> "When he wrote in 1991 cache wasn't as big a deal because CPU and memory speed were more evenly matched." Eh, what?
[05:21:38] <hayley> Baker's "cache conscious copying GC" was 1992 IIRC, cache was a problem.
[05:21:51] <hayley> Better, 1991 too!
[05:26:59] <hayley> moon-child: IIRC you had a reference for always correctly predicted branches not being a performance problem these days?
[05:29:19] <moon-child> hmm, not that I can remember.  Feel free to cite me
[05:29:42] <hayley> I'll just say that the branch predictor gets the idea on JITed code quickly.
[05:30:16] <moon-child> agner says correctly-predicted jcc is 0.5 cycles on recent amd and 2 cycles on recent intel
[05:31:29] <hayley> I guess SBCL without type declarations and all isn't the fastest thing around, but it's pretty damn fast, even with fixnum arithmetic and bounds checking and all the good stuff.
[05:34:58] <moon-child> uarch manual: 'The fraction of mispredictions is slightly higher than it would be without pattern recognition because the processor keeps trying to find repeated patterns in a sequence that has no regularities'
[05:35:00] <moon-child> just like a human!
[05:36:10] <hayley> https://www.reddit.com/r/programming/comments/qq10zi/pyjion_a_python_jit_compiler/hk0lr90/ Any complaints?
[05:36:11] -ixelp- Pyjion – A Python JIT Compiler : programming
[05:37:39] *** Joins: Catie (~user@user/catie)
[05:38:50] <moon-child> 'many type tests are just picking off tag bits' I think that might be less true in a language like python.  More important probably is that the branch is speculated so you don't actually have to wait for the memory access 
[05:39:35] <hayley> I haven't worked on a Python compiler, so sure. IIRC of the interpreters, only MicroPython uses tagged fixnums still.
[05:58:32] *** Quits: Inline (~Inline@aftr-37-201-240-235.unity-media.net) (Ping timeout: 240 seconds)
[06:27:05] <hayley> https://www.youtube.com/watch?v=1FqXTCvDLeo
[06:27:06] -ixelp- Honest Government Ad | Net Zero by 2050 (feat. Greta Thunberg) - YouTube
[06:45:19] <hayley> https://twitter.com/hotcistakes/status/1458094487671119881 Men wearing skirts in Scotland of all places???
[06:46:42] <Catie> couldn't be
[06:51:12] <hayley> https://scholarship.rice.edu/bitstream/handle/1911/16127/8900220.PDF?sequence=1&isAllowed=y A thesis on "storage containment" for garbage collection. I wonder why there's like 3 theses from Rice University on GC optimisation in the same year.
[06:51:21] <hayley> Must be a big university, or they really like GCs.
[07:12:27] <copec> Are any of them using ML, or blockchain?
[07:15:05] <hayley> In 1988? 
[07:15:09] <hayley> I guess ML = Meta Language
[07:15:15] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Quit: ec)
[07:17:11] *** Quits: emacsomancer (~emacsoman@136.60.128.68) (Ping timeout: 245 seconds)
[07:18:22] <copec> I would think there is a fair chance of using ML in regards to a GC in 1988
[07:18:37] <copec> however, I thought you were talking recent :-p
[07:18:48] <hayley> hayley? talking recent??
[07:19:01] *** Joins: emacsomancer (~emacsoman@136.60.128.68)
[07:23:47] *** Joins: dave0 (~davezero@069.d.003.ncl.iprimus.net.au)
[07:24:11] <dave0> maw
[07:24:38] <hayley> wam
[07:25:39] *** Joins: lexi_sparks (~lexi_spar@user/lexi-sparks/x-9241394)
[07:29:45] <hayley> gilberth: EVAL in microcode and concurrent GC in 1971: https://kilthub.cmu.edu/articles/journal_contribution/C_ai_a_LISP_processor_for_C_ai/6603989/1
[07:29:46] -ixelp- C.ai : a LISP processor for C.ai
[07:30:25] <dave0> maw hayley 
[07:31:12] <hayley> Huh, they had 2K(somethings, words?) of cache in 1971, which is 25x faster than core.
[07:33:13] <mfiano> Morning. After a very long break, I am at least starting to think about code again. No idea when I'll be doing it yet. Thinking about large complicated architectures is hard :/
[07:35:33] <mfiano> Also, it's Farnsworth time in 3, 2, 1...
[07:36:15] * hayley uploaded an image: (109KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/oSxrjpZWWAfmPbRBdygPwkCd/good-morning-everyone.jpeg >
[07:39:27] <dave0> Good News Everyone!
[07:54:43] <White_Flame> GME everyone!
[07:55:05] <aeth> now that's a stock that wore out its welcome
[07:55:16] <aeth> was so fun back in January, February, March
[07:55:29] <aeth> now swing traders try to get people to pump it up while they keep it bound in a tight range
[07:57:41] <aeth> AMD's been giving me the GME-in-January feeling recently, which probably means I won't sell in time 
[07:58:26] *** Quits: waleee (~waleee@h-98-128-228-119.NA.cust.bahnhof.se) (Ping timeout: 246 seconds)
[08:02:50] <White_Flame> yeah, I've been in AMD and NVDA for a long time
[08:03:15] <White_Flame> I think AMD has a lot of long term growth as it slowly takes over the datacenter
[08:07:20] <White_Flame> I don't expect it to take a rocketship up, though
[08:07:28] <White_Flame> in terms of share price
[08:08:17] <aeth> I mean it did, but in options
[08:08:23] <aeth> I don't mean sell AMD shares, I mean sell to close the calls
[08:08:52] <aeth> yet another situation where something does too well so I have to start selling or all my wealth would wind up in it (or, more likely, I would see a catastrophic loss when it starts moving the other direction)
[08:14:13] <MetaYan> -.
[08:22:07] <White_Flame> ah.  I had some longer term calls that I didn't trust and sold for a profit some weeks before this last rise, which annoys me, but hey, a win is a win
[08:22:37] <aeth> I didn't sell them, I rolled them into June $185c
[08:22:41] <aeth> which... still worked out
[08:22:46] <White_Flame> yep
[08:22:48] <aeth> (I mean, I did sell them to roll them forward, but w/e)
[08:23:04] <aeth> I will take any opportunity to buy more time in options, even if that sacrifices some profit
[08:23:10] <aeth> even my $150c would've been ITM now though
[08:23:45] <White_Flame> right, I had that strike, don't recall what date
[08:24:09] <aeth> I'm getting a bit nervous with calls in the $1200 to $1500 price range though
[08:24:16] <aeth> that's a lot of money in one trade (for me, anyway)
[08:24:28] <White_Flame> lol yeah that's pretty jackpotty
[08:25:53] <White_Flame> sold mine for $4, they're $23 now
[08:26:13] <White_Flame> june 2022 $150s
[08:26:19] <aeth> in case I'm unclear
[08:26:22] <aeth> I mean $12.00 to $15.00
[08:26:31] <White_Flame> oh, not strike price ;)
[08:26:32] <aeth> it's just that they're really $1200 to $1500
[08:27:35] <aeth> if it was 100 shares at $12-$15 I'd just slowly sell throughout the day and not worry, but the contract means I have to sell 100 at once
[08:29:40] <aeth> an easy way to just straight up lose $100 with bad timing. Or worse.
[08:32:21] *** Quits: semz (~none@user/semz) (Ping timeout: 250 seconds)
[08:38:37] <White_Flame> you don't "lose" on taking profit, only maybe some opportunity
[08:38:48] <White_Flame> the market is impossible to time, as long as you're not negative, you're ahead
[08:40:38] <hayley> My group came second for something I didn't do, and my prize is that I get to go in some startup funding shite. No thanks.
[08:41:04] * hayley didn't even get to run her demo to the other finalist students before being cut off.
[08:41:07] *** Joins: lisp123 (~lisp123@5.30.23.247)
[08:41:31] <aeth> White_Flame: these are options. I'm in decent profit right now, but I can easily be -80% at market open tomorrow
[08:42:28] <White_Flame> oh sorry, thought you meant trying to time selling for $1200 vs selling for $1500
[08:42:31] * White_Flame is in a bunch of channels
[08:43:00] <aeth> I mean, that's exactly what I mean
[08:43:05] <aeth> high yesterday for my strike price was $1500 iirc
[08:43:16] <aeth> low $1115
[08:43:20] <aeth> (well $15.00 and $11.15)
[08:43:33] <aeth> set a limit sell for $15.00 and you might wind up waking up to -80% the next day
[08:44:24] <aeth> it's a lot calmer when the options aren't (yet) profitable and there's plenty of time
[08:45:00] <aeth> (waking up to -80% and never getting filled, I mean)
[08:45:04] *** Joins: semz (~none@user/semz)
[08:45:43] <aeth> even just a perfect sell vs a suboptimal sell is a Steam Deck, per contract
[08:46:52] <White_Flame> again, you can't worry about catching the highest high, and buying the lowest low
[08:47:02] *** Quits: lexi_sparks (~lexi_spar@user/lexi-sparks/x-9241394) (Ping timeout: 240 seconds)
[08:47:56] * hayley gets a response of size O(2^n), and doesn't feel like doubling in size again.
[08:48:44] <hayley> "Sure, [caching in 1991] was important but you are missing my point: it's 100x more important now. If your language design requires objects to be boxed, your performance is already shot." Really, it has to end up in cache in either case.
[08:49:02] <hayley> "In Python every type in every module is changeable at runtime by every other module. There is pretty much nothing you can count on staying the same. There are also many facilities to load new code at runtime, which can arbitrarily rewrite any old code and change any existing type." Who did that ever stop?
[08:51:02] *** Quits: notzmv (~zmv@user/notzmv) (Ping timeout: 240 seconds)
[09:06:20] <hayley> If someone does that, then use debugging information to jump back into bytecode until you recompile. There's absolutely no problem with redefinition.
[09:15:15] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[09:15:34] <moon-child> I think I've said this before, but
[09:15:41] <moon-child> on-stack replacement is fucking _whack_
[09:15:52] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[09:16:43] <hayley> I think you have.
[09:17:28] <hayley> But if you have debugging information always available, and I hope you do, then it's hard not to come up with a way to bail out when you broke some invariant.
[09:21:02] <hayley> Hm, if you have stack allocated objects but they're still boxed, is it really that bad to use boxing, assuming the C weenie model of "stack is so hot that it gives you third degree burns, and heap is 0 Kelvin"?
[09:21:17] <hayley> *C weenie model of cache
[09:27:45] *** Quits: Catie (~user@user/catie) (Quit: rcirc on GNU Emacs 29.0.50)
[09:39:30] *** Quits: lisp123 (~lisp123@5.30.23.247) (Quit: Leaving...)
[10:04:16] *** Joins: shka (~herr@83.175.151.96.piasta.pl)
[10:24:04] *** Quits: White_Flame (~quassel@user/white-flame/x-6930243) (Remote host closed the connection)
[10:25:17] *** Joins: White_Flame (~quassel@user/white-flame/x-6930243)
[10:28:40] <hayley> https://www.youtube.com/watch?v=_KQdSQRd-6g
[10:28:41] -ixelp- The Joy Circuit - YouTube
[10:46:11] *** Quits: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de) (Quit: Leaving)
[10:52:35] *** Quits: shka (~herr@83.175.151.96.piasta.pl) (Ping timeout: 256 seconds)
[10:53:02] *** Quits: pjb (~pjb@user/pjb) (Ping timeout: 240 seconds)
[11:02:47] <pl> ... Why you can't operate on boxed data in cache? 
[11:05:02] *** Quits: bcasiello (~bcasiello@066-189-087-112.biz.spectrum.com) (Read error: Connection reset by peer)
[11:32:00] *** Quits: dec0d3r (~dec0d3r@2001:8003:480a:e00:e07:e7c3:7efc:ed0f) (Quit: Leaving)
[11:43:43] *** Joins: lisp123 (~lisp123@5.30.23.247)
[11:51:41] *** Joins: Qwnavery (~Qwnavery@user/qwnavery)
[11:59:16] *** Quits: Qwnavery (~Qwnavery@user/qwnavery) (Quit: WeeChat 3.3)
[12:54:25] *** Quits: occ (~occ@user/occ) (Ping timeout: 256 seconds)
[12:58:52] <hayley> Yeah, it has to get into cache either way. Though contiguity is now dependent on the allocator (so, still pretty good in practise), and hardware prefetching perhaps is less magic with boxing.
[12:59:15] * hayley will make Henry Baker look like a C programmer some day
[13:00:38] * hayley also downvoted to hell for linking Craig Chambers's PhD thesis
[13:02:55] <moon-child> 'btb bloat' this is why I want to use faults for never-taken branches
[13:03:25] <moon-child> for some reason nobody ever seems to think this is a worthwhile idea
[13:03:54] <hayley> Well, still a fair price for ad hoc polymorphism IMO.
[13:04:15] <moon-child> yeah
[13:04:35] <hayley> If you wanna go fast, then do that, but having a more than good enough compiler for "slow" code lets you be very lazy.
[13:05:02] <moon-child> that's the other thing--nobody really believes knuth when he says 97%/3%
[13:05:31] <hayley> But that doesn't look nice in an argument. It's not "look, scripting language, I can go slow if I hack fast" or the opposite.
[13:07:08] <hayley> Though e.g. Self and CL are more dynamic in actually useful ways, like dynamic inheritance and useful redefinition, as compared to crap like diddling locals in the stack frame of some caller.
[13:08:24] <hayley> And bignums are less footgun-y than machine integers, so they should be default, but I'm preaching to the choir with that in #lispcafe.
[13:09:40] <moon-child> fused add+jo when
[13:11:54] *** Quits: cwebber (~user@user/cwebber) (Read error: Connection reset by peer)
[13:12:59] <dave0> forgot to carry the one
[13:14:09] <hayley> Maybe I should link that paper from 1971 where cache was 25x faster than core memory. It's basically 100x, give or take.
[13:14:58] <hayley> And I really can't understate the value of having shit code run acceptably fast.
[13:15:02] <dave0> has memory caches been around for that long?
[13:15:33] <hayley> I think the idea of memory being O(sqrt(n)) is pretty old.
[13:16:33] <hayley> https://en.m.wikipedia.org/wiki/CPU_cache has a history.
[13:17:08] <dave0> cool i'll click
[13:17:42] <hayley> Though it only dates from 1976, which is meh.
[13:17:43] <dave0> i just remember the old 8 bit computers in the 80's didn't have one
[13:18:40] <dave0> but motorola 68020 did... iirc it was 256 byte data cache.. maybe an instruction cache too
[13:19:19] <dave0> i just remember because there was discussions around demos for amiga (which i had)
[13:24:43] <hayley> IIRC there were caches around the 486 era, which is about 1991. But you also wanted locality of reference on e.g. Lisp machines to avoid paging too.
[13:25:14] <hayley> So there's always been slow memory of some sort.
[13:26:20] <moon-child> yeah, that is what I hear--back when memory was fast, it was small enough that if you were nto careful to fit your entire working set into it you would page.  Memory didn't get faster or slower, we just added more hierarchies
[13:27:38] <hayley> 486 was 1989-2007, close enough.
[13:35:22] <pl> caches were a thing since... early 1980s, late 1970s
[13:37:02] <pl> 1992 and some workstations were sporting 2MB L1 cache
[13:54:55] *** Joins: occ (~occ@user/occ)
[13:54:59] <hayley> Were they a big deal back then?
[13:55:46] <hayley> (Still, one magnitude of lossage isn't much better than two, so I don't see the point in saying it's only gotten worse, if it was bad to start with.)
[13:59:25] <hayley> https://www.youtube.com/watch?v=t3J_2R9rAp8
[13:59:26] -ixelp- Fearless - YouTube
[14:00:23] *** Quits: lisp123 (~lisp123@5.30.23.247) (Quit: Leaving...)
[14:05:20] <hayley> gilberth: forget CLIM here is Minecraft https://www.youtube.com/watch?v=9TQTMvoPJJY
[14:05:20] -ixelp- Visualisation tool demo - YouTube
[14:14:23] * dave0 makes a lambda in hayley's cupaccino froth
[14:17:45] * hayley reads forth
[14:18:33] <sham1> I read FORTH too and was very confused
[14:19:07] <dave0> lol
[14:20:12] *** Joins: random-nick (~random-ni@87.116.176.55)
[14:28:29] <hayley> (to the tune of Freddie Laker (Concorde and Eurobus))... (full message at https://libera.ems.host/_matrix/media/r0/download/libera.chat/33750f53d54c8227a8d9d6c128c68713abb582c7)
[14:29:26] <pl> hayley: caches were stupidly big on performance improvements
[14:29:42] <pl> only started being problematic for SMP
[14:30:23] <hayley> Right.
[14:32:16] <hayley> (Also, amusingly boxing makes lock free programming easier, as you usually can only CAS one word at a time.)
[14:38:59] * hayley uploaded an image: (99KiB) < https://libera.ems.host/_matrix/media/r0/download/matrix.org/LXlOdDqKiwYVZfpvJEFrgrqf/v8-goes-brrrrrrr.png >
[14:39:22] <hayley> (Previously on "low level weenies have like 2 arguments"...)
[14:45:28] <sham1> There's also LuaJIT
[14:47:35] <hayley> TruffleRuby is also considered magically good.
[14:48:10] <hayley> But there was also the idea of a language which was "designed to be JITed", which I think none are.
[14:49:01] <hayley> APL definitely wasn't designed with it in mind, as compilers came later. I don't think Smalltalk-80 or Self was either. Not even Java probably.
[14:49:12] <sham1> Languages aren't designed to be JITted just as they aren't designed to be compiled or interpreted. It's a property of implementation
[14:49:55] <sham1> A language can certainly make it easier for an implementation to be JITted or interpreted or AOT compiled, but that's still fundamentally about the implementation
[14:51:51] <hayley> @[moon-child] I'm away from a desktop to properly answer in the thread on object relocation, but I mentioned that SBCL just tells hash tables to rehash after a GC.
[14:52:47] <hayley> And the trick of one bit refcounting was that, would you have a backup mark sweep collector, you'd reuse the bitmap. The partial RC paper just uses two bits.
[14:54:07] <hayley> I'll put this in the issue log eventually.
[14:58:06] <hayley> But I have to sketch out deciding when to rehash in my head. I guess checking if the key moved after a miss tends to work.
[14:59:00] <hayley> Have each thread local GC keep a count of how many GCs have been done, make sure it's relatively fast to probe, sample before and after a hash table lookup.
[15:21:23] *** Joins: pjb (~pjb@user/pjb)
[16:15:13] *** Quits: Aurora_v_kosmose (~LispyLigh@user/lispylights) (Remote host closed the connection)
[16:16:05] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Remote host closed the connection)
[16:16:51] *** Joins: chiselfuse (~chiselfus@user/chiselfuse)
[16:19:05] *** Joins: Aurora_v_kosmose (~LispyLigh@user/lispylights)
[16:31:05] *** Joins: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de)
[16:41:24] *** Quits: chiselfuse (~chiselfus@user/chiselfuse) (Remote host closed the connection)
[16:41:31] <gilberth> Good morning #lispcafe!
[16:41:41] <Alfr> Good morning, gilberth!
[16:42:18] *** Joins: chiselfuse (~chiselfus@user/chiselfuse)
[16:42:53] <gilberth> May I have a compiler macro (PARSE-INTEGER (SUBSEQ x s e)) => (PARSE-INTEGER x :START s :END e)?
[16:48:30] <Alfr> gilberth, I think that'd be a case of the usual ub when messing with the meaning of symbols in CL (when it's not explicitly allowed).
[16:52:29] <gilberth> Well, some random application may not mess with symbols of the CL package, that's obvious and not the question.
[16:54:31] <Alfr> gilberth, I guess an implementation could do that.
[16:55:07] <Alfr> gilberth, oh ... see the notes section of DEFINE-COMPILER-MACRO.
[16:59:09] <gilberth> Again, that is not the question. The question rather is, whether such a transformation would be fine.
[17:00:38] <Alfr> Sorry, I misunderstood your "may I have" to mean "may I install one".
[17:01:20] <gilberth> I could have formulated that in a more careful way.
[17:03:05] *** Quits: dave0 (~davezero@069.d.003.ncl.iprimus.net.au) (Quit: dave's not here)
[17:04:34] <gilberth> I come up with that because of my scanner/lexer generator. There is a symbol macro in the semantic action/value part of a rule, which has $$ as a symbol macro for the match, so you could have a rule like (:integer -> "[0-9]+" => (parse-integer $$)). And that would unneedlessly cons and copy. $$ expands to SUBSEQ, and it would be nice, if that would just work, that is bypass the consing and copying.
[17:07:55] <Alfr> gilberth, if you ask me, yes. But I think you'd have to fixup the second value returned from parse-integer, i.e. subtract s.
[17:08:55] <gilberth> In theory there could be a lexical compiler macro on PARSE-INTEGER, which won't work in practice --- even when there would be lexical compiler macros --- because macro expansion is "dirty".
[17:10:08] *** Quits: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de) (Quit: Leaving)
[17:10:17] <gilberth> Alfr: No, you don't have to subtract S either.
[17:12:50] <Alfr> gilberth, I thought its second value is an index into string where it stopped reading. Am I mistaken and does it give the number of chars read instead??
[17:14:00] <gilberth> Sorry, I was confused. You would need to add S to the second return value, right.
[17:14:57] * gilberth wants more clever compilers.
[17:18:14] <Alfr> gilberth, if you go from (p-i (subseq ..)) to (p-i ..), it's subtracting, because the second value of the first form should be (- E S) and for the second form that would be simply be E. (Assuming p-i doesn't bail.)
[17:20:33] <gilberth> Alfr: (parse-inetger "xxx12" :start 3) => 12; 5, and (parse-integer (subseq "xxx12" :start 3)) => 12; 2
[17:21:02] *** Quits: occ (~occ@user/occ) (Ping timeout: 240 seconds)
[17:21:14] <gilberth> Rather (SUBSEQ "xxx12" 3) ;sigh
[17:22:05] <gilberth> Alfr: So, yes, you're correct.
[17:22:21] <Alfr> gilberth, but that's the opposite direction of the transformation you wanted to make above. ;)
[17:22:22] <Alfr> Yes/
[17:23:08] <gilberth> Yep, exactly, I was thinking in the wrong direction. /me needs more coffee.
[17:23:09] * Alfr pours gilberth a Maß full of coffee.
[17:23:36] <gilberth> Puh! That's a lot! Hope that helps.
[17:24:26] * gilberth has trouble even lifting the Maß.
[18:03:20] *** Joins: occ (~occ@user/occ)
[18:16:11] *** Joins: Inline (~Inline@aftr-37-201-240-235.unity-media.net)
[18:21:40] *** Joins: edgar-rft (~edgar-rft@HSI-KBW-109-193-249-223.hsi7.kabel-badenwuerttemberg.de)
[18:54:47] *** Joins: waleee (~waleee@2001:9b0:216:8200:d457:9189:7843:1dbd)
[19:22:56] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[19:29:12] <contrapunctus> gilberth nimmt ein Maß als Maßnahme gegen Fehler 🤔️
[19:29:19] <contrapunctus> SCNR
[19:32:55] <gilberth> Heh. Finally I know where "Maßnahme" is coming from!
[19:34:18] <gilberth> "Wir brauchen Maßnahmen!" has a new meaning. :-)
[19:35:02] <contrapunctus> lol, I thought I was going to get murdered by silence xD
[19:35:34] <gilberth> Well, but then I am North German and thus don't drink beer in "Maßen", nor in "Massen". :-)
[20:25:55] *** Joins: Catie (~user@user/catie)
[20:29:33] *** Joins: notzmv (~zmv@user/notzmv)
[20:44:02] <gilberth> I think Perl and me will never become friends. It's just too strange, and I am too lazy to really dig it.
[20:49:05] *** Joins: shka (~herr@83.175.151.96.piasta.pl)
[20:55:06] *** Joins: bcasiello (~bcasiello@066-189-087-112.biz.spectrum.com)
[21:04:03] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Quit: ec)
[21:04:40] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[21:15:05] *** Quits: X-Scale (~ARM@31.22.162.107) (Ping timeout: 264 seconds)
[21:15:26] *** Joins: X-Scale` (~ARM@165.201.137.78.rev.vodafone.pt)
[21:16:45] *** X-Scale` is now known as X-Scale
[21:17:22] <mfiano> Raku (Perl 6) is a very different language, and I think it touches on everything I don't like about Perl <6
[21:20:09] <shka> hi all
[21:20:15] <gilberth> mfiano: Which won't help me, when I try to fix an existing Perl script.
[21:20:26] <gilberth> shka: Hello there!
[21:20:41] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Remote host closed the connection)
[21:21:13] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[21:23:36] <gilberth> You know what the problem with scripting languages is: They end up being uses for things larger than a dozen lines. There should be a law against coming up with "scripting language".
[21:28:50] <sham1> Raku is also not nearly as ubiquitous as perl 5
[21:32:18] <sham1> And yeah, scripting language as a category is weird
[21:41:02] *** Quits: occ (~occ@user/occ) (Ping timeout: 240 seconds)
[21:47:00] *** Joins: occ (~occ@user/occ)
[21:53:19] *** Quits: X-Scale (~ARM@165.201.137.78.rev.vodafone.pt) (Ping timeout: 256 seconds)
[21:54:52] *** Joins: X-Scale` (~ARM@31.22.202.101)
[21:56:06] *** X-Scale` is now known as X-Scale
[22:13:58] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Remote host closed the connection)
[22:14:23] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[22:33:21] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[22:35:20] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[22:45:56] <pl> Ruby is my perl replacement :)
[22:46:01] *** Quits: Inline (~Inline@aftr-37-201-240-235.unity-media.net) (Ping timeout: 250 seconds)
[22:47:04] <gilberth> Does it mimic as line noise equally well?
[22:52:00] * contrapunctus wonders how everyone here likes https://www.nongnu.org/txr/
[22:57:56] <gilberth> Behold! It has parens, plenty of them!
[22:59:11] <gilberth> Otherwise I can't tell without further reading.
[23:05:34] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Quit: ec)
[23:10:05] <selwyn> gnuxie: the article got deleted before i could read it? but everyone else seems to have read it lol
[23:12:27] <selwyn> https://nitter.eu/pic/media%2FFD2eC_2XMAQt5XZ.jpg%3Fname%3Dorig lol
[23:13:38] <selwyn> my 'not a corrupt country' shirt has people asking a lot of questions already answered by my shirt
[23:14:29] <pl> gilberth: a bunch of things in Ruby was done as "let's make a saner Perl that isn't such lìne noise, oh and make the VM design sane by basing on Lisp and Smalltalk" 
[23:16:56] <gilberth> Hmm, I always assumed Ruby is some kind of Smalltalk.
[23:18:47] <pl> gilberth: the language evolved into something very smalltalkish, yes
[23:19:05] <pl> gilberth: from Perl came the various convenience things for Perl-like scripting
[23:19:24] <selwyn> is perl well designed?
[23:19:28] <pl> and Lisp (through Emacs Lisp) was big influence on internals design
[23:19:30] <pl> selwyn: nope
[23:24:03] *** Joins: ec (~ec@gateway/tor-sasl/ec)
[23:24:34] *** Quits: clothespin (~awolven@c-73-209-95-92.hsd1.il.comcast.net) (Remote host closed the connection)
[23:24:47] <mfiano> My only exposure to ruby has been from crystal-lang, and I was impressed for the most part, especially the inheritence/mixin hybrid that it inherited from ruby, but what put me off is it being a class-centric language
[23:37:16] <pl> mfiano: Ruby takes it's object model from Smalltalk. Dunno how crystal handles it, but Ruby makes certain allowances so you can actually program like it's not as class oriented as it seems
[23:37:39] <pl> tl;dr there are constructs which will imply the necessary boilerplate into existence in ways you don't need to care about
[23:37:49] <aeth> afaik, Ruby is ultra-dynamic OOP to the point where it is impossible to optimize properly
[23:37:53] <GreaseMonkey> it adheres to the "everything is an object" philosophy properly and when a language does that, one can get away with forgetting that it's the case
[23:38:41] <GreaseMonkey> if you want an example of a language which fails at that, well, Java
[23:39:04] <pl> well, yeah, there's no separate primitive and object
[23:39:44] <GreaseMonkey> Java is that language which tells you at every opportunity "i'm an OO language! i'm an OO language!" but manages to screw things up. Ruby (and Python for that matter) both don't care if you don't care for OO, you just naturally have it
[23:40:02] <Catie> Ruby, I think, does pure object orientation really well. And the un-optimizable dynamic environment makes it a lot more fun to work with
[23:40:27] <mfiano> pl: I understand. I just don't like methods associated with a single class. multiple-dispatch ftw!
[23:40:39] <mfiano> sadly, very few languages have this property though.
[23:40:46] <mfiano> and CL is where I parked
[23:40:58] <pl> mfiano: well, Ruby is rather explicit about the message-passing nature of its OOP, methods are really syntax sugar
[23:41:04] <GreaseMonkey> yeah i have to concur that CLOS did a better job of OOP than Smalltalk did
[23:41:11] <Catie> See, multiple dispatch is what I think makes other languages break the object-oriented paradigm
[23:41:30] <pl> GreaseMonkey: I think of it as rather different take on the concept
[23:41:56] <selwyn> i found it hard to dislike java
[23:41:58] <GreaseMonkey> some operations work well when tied to a specific class, some operations work better when they're treated as a multimethod between two classes (object-object collision for example)
[23:48:06] *** Quits: ec (~ec@gateway/tor-sasl/ec) (Ping timeout: 276 seconds)
[23:48:30] <gilberth> My greatest critique for so called object oriented languages, is having both the x.f(y) and f(x,y) syntax for no good reason.
[23:48:51] <selwyn> return to (x)f
[23:49:37] <ck_> just put the value I mean why even evaluate a function don't you care about the planet
[23:49:37] <pl> gilberth: that depends on language. Ruby doesn't have that, in python it's essentially the very shitty metamodel leaking through
[23:49:53] <selwyn> i hate python oop
[23:50:04] <pl> also I think MSVC++ ABI doesn't use first arg for class information
[23:50:27] <hayley> https://www.youtube.com/watch?v=H-MZD3Kuwkg
[23:50:27] -ixelp- The 1930's Rust - YouTube
[23:50:50] <gilberth> pl: So when Ruby doesn't have it, my critique does not apply to Ruby.
[23:52:13] <pl> gilberth: it's part of why I like how it handles OOP :)
[23:52:15] <gilberth> I believe CLOS got it right with generic functions. In so called OOP languages, I can't define a new "g" for the x.g(y) case, but I can for the g(x,y) case. Why?
[23:53:47] <selwyn> although i am reluctant to bring the tone down, can anyone list the deficiencies of clos
[23:54:19] <gilberth> But then in both Java and C++ classes are often misused what modules are for.
[23:55:16] <hayley> "In less dynamic languages you can allocate polymorphic objects on the stack." Which?
[23:55:53] <hayley> "Python has no preprocessor or macro support so all metaprogramming is done by overwriting types and functions at runtime. Even a simple @logged decorator may change what code it overwrites an existing function with based on runtime configuration" Really?
[23:56:08] <hayley> A decorator only attaches to the function after it, no?
[23:58:38] <hayley> The function for computing class precedence lists is weird in some places.
[23:59:05] <gilberth> hayley: I found another painting <http://clim.rocks/gilbert/temp.jpg>
