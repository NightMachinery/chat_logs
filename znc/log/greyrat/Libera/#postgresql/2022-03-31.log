[00:01:43] *** Quits: jnnnnnnnnn (~jnnnnnnnn@65.99.151.178) (Remote host closed the connection)
[00:02:00] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[00:04:01] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[00:06:35] *** Joins: jnnnnnnnnn (~jnnnnnnnn@65.99.151.178)
[00:08:47] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Ping timeout: 252 seconds)
[00:09:15] *** Joins: zaher_ (~zaher@37.48.152.217)
[00:09:48] *** Quits: mizi_ (~mizi@user/mizi) (Ping timeout: 272 seconds)
[00:12:20] *** Quits: zaher (~zaher@37.48.154.70) (Ping timeout: 272 seconds)
[00:14:07] *** Joins: concrete-houses (~g@209.6.150.53)
[00:14:08] *** Quits: mamad (~mam@5.123.103.228) (Read error: Connection reset by peer)
[00:15:08] <concrete-houses> so to get autovacuum to work well you want to leave global setting and set per table
[00:15:13] <concrete-houses> or a combo of both?
[00:15:46] *** Quits: `2jt (~jtomas@210.red-88-24-179.staticip.rima-tde.net) (Remote host closed the connection)
[00:20:27] <johto> depends on the way in which it is not "working well"?
[00:25:53] *** Joins: Auron (~Auron956@user/auron)
[00:26:15] *** Joins: ovnicraft (~ovnicraft@ftth-179-49-44-28.cue.celerity.ec)
[00:29:32] *** Quits: ovnicraft (~ovnicraft@ftth-179-49-44-28.cue.celerity.ec) (Client Quit)
[00:30:19] *** Joins: haris (~haris@69.169.3.81)
[00:31:37] *** Quits: haris (~haris@69.169.3.81) (Client Quit)
[00:32:13] *** Joins: haris (~haris@69.169.3.81)
[00:33:31] *** Quits: haris (~haris@69.169.3.81) (Client Quit)
[00:34:00] *** Joins: haris (~haris@69.169.3.81)
[00:34:09] *** Quits: adlaistevenson (~adlaistev@068-188-185-039.res.spectrum.com) (Quit: Client closed)
[00:34:22] *** Quits: zmt00 (~zmt00@user/zmt00) (Read error: Connection reset by peer)
[00:35:47] *** Joins: zmt00 (~zmt00@user/zmt00)
[00:38:43] *** Joins: AnselmoCampanas (~AnselmoCa@190.99.69.41)
[00:40:03] *** Quits: kid (~kid@user/kid) (Ping timeout: 256 seconds)
[00:41:10] *** Joins: ur5us (~ur5us@203.86.198.200)
[00:49:47] *** Quits: Tenchi (~Tenchi@user/tenchi) (Quit: Textual IRC Client: www.textualapp.com)
[00:50:37] *** Quits: randir (~randir@95-31-138-202.broadband.corbina.ru) (Remote host closed the connection)
[00:52:55] *** Joins: kid (~kid@2a01:799:199d:5800:216:3eff:feed:12b2)
[00:52:55] *** Quits: kid (~kid@2a01:799:199d:5800:216:3eff:feed:12b2) (Changing host)
[00:52:55] *** Joins: kid (~kid@user/kid)
[00:54:12] *** Joins: harpia (~harpia@143.208.84.100)
[00:56:31] *** Joins: randir (~randir@95-31-138-202.broadband.corbina.ru)
[01:00:28] *** Quits: maret (~maret@nat-88-212-37-89.antik.sk) (Ping timeout: 272 seconds)
[01:01:41] <harpia> I have this database using encoding LATIN1, and then I retrieve data from it with PHP (PDO). It's annoying having to convert strings to UTF-8 every time I want to put them in a JSON. Is there a way to convert everything on-the-fly to UTF-8? I'm not allowed to change the encoding of the database.
[01:02:04] <concrete-houses> is analzye more important than vacuum?
[01:03:45] <peerce> harpia; client encoding can be different than database encoding all versions since quite awhile ago
[01:04:18] <peerce> concrete-houses; is the engine more important than the brakes?
[01:07:01] *** Joins: jazzy (~jaziz@user/jaziz)
[01:08:03] *** Quits: bmomjian (~bruce@momjian.us) (Quit: Leaving.)
[01:08:09] *** Joins: bmomjian (~bruce@momjian.us)
[01:13:42] *** Joins: maciek__ (~maciek@2600:1700:a412:1c00:a2d9:3194:988b:4417)
[01:13:59] <concrete-houses> yes
[01:14:06] <concrete-houses> well unless you want to stop
[01:15:20] <Myon> harpia: set client_encoding = 'UTF-8';
[01:15:34] <concrete-houses> I want to get autovacuum working and I think you said to do per table settings for bigger tables.
[01:16:52] *** Quits: shored1 (~shored@user/shored) (Quit: ZNC 1.8.2+deb2 - https://znc.in)
[01:16:59] <concrete-houses> I have a query that shows deadtuples and last autovacuum, analayze, last vac, alst analyze from pg_stat_user_tables
[01:17:08] *** Joins: shored (~shored@user/shored)
[01:18:00] <concrete-houses> What I am still unclear on is if deadtuples is what is compared to sacling factor * reltuples + threshold
[01:18:16] <concrete-houses> or is it some combinaton of up/del
[01:18:43] <concrete-houses> someone here said 100% its deadtuples
[01:18:50] <concrete-houses> I am unsure
[01:19:11] *** Quits: shiranaihito_ (~textual@123-192-192-149.dynamic.kbronet.com.tw) (Quit: My MacBook Air has gone to sleep. ZZZzzzâ€¦)
[01:19:20] <peerce> harpia; note that if the client provides UTF-8 that has no LATIN1 equivalent, that transaction will have an error, and require a ROLLBACK
[01:19:48] <harpia> Myon: peerce: that worked, thanks. I didn't know about the client_encoding thing.
[01:20:07] <harpia> got it. I just tested here, it seems to be ok
[01:22:20] *** Quits: marcel (~marcel@user/marcel) (Quit: The Lounge - https://thelounge.chat)
[01:23:16] *** Joins: jazzy2 (~jaziz@user/jaziz)
[01:23:16] *** Joins: marcel (~marcel@user/marcel)
[01:23:18] <xocolatl> it is 100% n_dead_tup in postgresql.  no idea what it is in your database
[01:24:48] <concrete-houses> ok
[01:25:41] <concrete-houses> I am querying pg_stat_user_tables and last_analyze is null for all tables even ones showing auto_analyze with a date
[01:26:08] <xocolatl> when is the last time you manually ran analyze on those tables?
[01:26:30] *** Quits: jazzy (~jaziz@user/jaziz) (Ping timeout: 260 seconds)
[01:26:35] *** Joins: kitsunenokenja (~kitsunech@68.91.220.96)
[01:27:43] *** Quits: fcr (~fran@r167-60-9-180.dialup.adsl.anteldata.net.uy) (Read error: Connection reset by peer)
[01:31:24] *** Quits: vnf_ (~vnf@46.159.151.228) (Quit: Leaving)
[01:33:18] <peerce> does any of this even apply to Amazon Aurura ?
[01:33:19] *** Quits: uncleyear (~ian@31.173.80.95) (Ping timeout: 256 seconds)
[01:33:33] <xocolatl> who knows
[01:33:47] *** Joins: vnf (~vnf@46.159.151.228)
[01:34:55] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[01:35:06] *** Joins: uncleyear (~ian@31.173.80.95)
[01:35:57] *** Quits: epony (epony@user/epony) (Quit: QUIT)
[01:36:20] *** Joins: fcr (~fran@r167-60-138-35.dialup.adsl.anteldata.net.uy)
[01:36:55] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[01:36:58] <concrete-houses> I never have... except for 2 big ones when we were troublehsooting
[01:37:05] *** Quits: iliv (~iliv@93-77-147-152.lvv.volia.net) (Changing host)
[01:37:05] *** Joins: iliv (~iliv@user/iliv)
[01:37:18] <xocolatl> so why are you expecting anything in that column?
[01:38:39] *** Joins: dionysus69 (~Thunderbi@94-43-121-219.dsl.utg.ge)
[01:39:04] <concrete-houses> ok ok let me remember
[01:39:24] <concrete-houses> WE toubleshot the db and manually ran vac/analzye on 10 tables
[01:39:39] <concrete-houses> one of them shows null for auto and manual
[01:39:49] <concrete-houses> and I know we did manually a week or so back
[01:39:59] <xocolatl> did it finish correctly?
[01:40:08] <xocolatl> try again on a small table
[01:40:29] <concrete-houses> oh no I had to kill it since the replication lag went up and the manager said that causes instability
[01:40:31] *** Joins: john_johnk (~Thunderbi@102.178.207.77.rev.sfr.net)
[01:40:32] <concrete-houses> ah ha!!
[01:40:32] <concrete-houses> ok
[01:40:44] *** Quits: john_johnk (~Thunderbi@102.178.207.77.rev.sfr.net) (Client Quit)
[01:40:52] <Myon> the numbers are lost on unclean shutdowns
[01:40:53] <concrete-houses> see I had 10 lines one per table and ran all 10 in dbeaver
[01:41:08] *** Quits: funhouse (~funhouse@user/funhouse) (Quit: Client closed)
[01:41:27] <concrete-houses> now devs are freaked out when I try and suggest per table setting or global scale factor change to fix auto vac/analyze
[01:42:25] <concrete-houses> if I run vacuum (verbose, analyze)   and do NOT list a table, will it do the tables 1 by 1 or do something similar to the 10 I selected in dbeaver and hit run?  which is bad for our system?
[01:42:42] <xocolatl> it will do them all one by one
[01:42:49] <concrete-houses> yesss!!
[01:42:50] *** Quits: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk) (Quit: Leaving)
[01:42:50] <concrete-houses> ok
[01:43:02] *** Quits: manti7 (~manti7@176.10.104.94) (Quit: WeeChat 3.4)
[01:43:07] <xocolatl> devs don't get to freak out about the dba's job
[01:43:07] <concrete-houses> how risky to do that on a production db after hours?
[01:43:40] <concrete-houses> I am figuring out I am not the only one who only knows cerain things in this organziation.... I am a baby at db
[01:44:07] <concrete-houses> people are giving me all thier impossible bs problems I hate it
[01:44:35] *** Quits: magla (~gelignite@55d42a76.access.ecotel.net) (Quit: Stay safe!)
[01:45:09] <xocolatl> imagine how we feel when people dump their aurora problems on us
[01:45:13] <concrete-houses> if you set the scaling factor to say .001 in autovacuum+analzye   do smaller tables end up being hit nonstop?
[01:45:23] <concrete-houses> I am sorry
[01:45:32] <xocolatl> the threshold is to protect small tables
[01:45:43] <concrete-houses> I think its only 50
[01:45:54] <xocolatl> it is 50 by default
[01:46:07] <concrete-houses> hmmmm
[01:46:13] <concrete-houses> What do you do?
[01:46:56] <xocolatl> I don't remember the details of your situation, but when maintenance tasks can't keep up it is time to partition
[01:48:35] *** Quits: AnselmoCampanas (~AnselmoCa@190.99.69.41) (Quit: Client closed)
[01:52:17] <peerce> does that also apply to Aurora ?
[01:52:27] <xocolatl> no idea
[01:53:10] <xocolatl> if it does, great.  if it doesn't, I don't care
[01:54:03] <Myon> if I had problems with Aurora, I'd call Sun
[01:55:13] <concrete-houses> but for most intents postgres assumes you are running auovac+analyze regularly so the query planner can do its job
[01:55:17] *** Joins: SwK (~SwK_@158.120.197.136)
[01:55:17] *** Quits: SwK (~SwK_@158.120.197.136) (Changing host)
[01:55:17] *** Joins: SwK (~SwK_@user/swk)
[01:56:11] *** Quits: zer0bitz (~zer0bitz@2001:2003:f750:a200:88a0:fb04:2d2:c434) (Ping timeout: 245 seconds)
[01:56:16] <concrete-houses> do most postgresql setups have 1 cluster with many databases and developers have discipline that thier apps do not connect to the wrong db?
[01:56:32] *** Quits: vnf (~vnf@46.159.151.228) (Quit: Leaving)
[01:56:56] *** Quits: ncwbqcfe (~rvgzuuqp@gateway/tor-sasl/rvgzuuqp) (Quit: ncwbqcfe)
[01:56:56] <peerce> our development setups were like that, but our production databases tended tob e on large dedicated servers
[01:57:04] <xocolatl> it's not discipline, it's access control
[01:57:21] <concrete-houses> things here are sloppy which is systemic problem
[01:57:23] *** Joins: vnf (~vnf@46.159.151.228)
[01:57:28] *** Quits: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 272 seconds)
[01:57:41] *** Quits: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net) (Ping timeout: 256 seconds)
[01:57:43] *** Quits: SwK_ (~SwK_@158.120.197.136) (Ping timeout: 246 seconds)
[01:57:49] <concrete-houses> the apps are having performacne problems due to nothign being analzyed for like year or more
[01:57:52] *** Joins: ncwbqcfe (~rvgzuuqp@gateway/tor-sasl/rvgzuuqp)
[01:58:22] <concrete-houses> they do vac/analzye during slwodown when client complain
[01:58:24] <concrete-houses> meh
[01:58:40] <concrete-houses> I am going to get autovac/analyze working
[01:58:44] <concrete-houses> basics
[01:58:51] <concrete-houses> even though I know almost nothing
[01:59:31] <concrete-houses> I will say the docs could be clearer that the stat to look for is deadtuples   they say some combination of up/del
[01:59:43] <concrete-houses> obsolete tuples or something
[01:59:50] <xocolatl> I haven't read the aurora docs
[02:01:35] *** Joins: peteyboy_ (~peteyboy1@199.157.133.37.dynamic.jazztel.es)
[02:01:50] *** Joins: AnselmoCampanas (~AnselmoCa@190.99.69.41)
[02:01:58] <concrete-houses> ok let me ask this:  if you have a production support team ... that has access to prod databases to troubleshoot....and they want to be able to run cleanup scripts which they ahve bene doing forever
[02:02:05] <concrete-houses> I maen how do you have safety?
[02:02:10] <concrete-houses> unless I kick them off
[02:02:23] <xocolatl> safety?
[02:02:32] *** Quits: peteyboy1 (~peteyboy1@199.157.133.37.dynamic.jazztel.es) (Ping timeout: 272 seconds)
[02:02:45] <concrete-houses> I mean they have ability to destory stuff but biz seems to need them to do data cleanup
[02:02:56] *** Quits: vnf (~vnf@46.159.151.228) (Quit: Leaving)
[02:03:01] *** Joins: funhouse (~funhouse@user/funhouse)
[02:03:05] <xocolatl> either you trust them or you don't
[02:03:15] <xocolatl> if you don't, revoke their privileges
[02:03:23] <concrete-houses> thier boss knows a lot more about out db than I do hes been here
[02:03:54] <xocolatl> the fun thing about my answer is that it does not depend on who knows what
[02:03:59] <concrete-houses> they jammed backups by creating things like sequences and I had to fix by changing to the role the app runs as
[02:04:05] <concrete-houses> heh
[02:04:14] <concrete-houses> interesting caveat
[02:04:44] <concrete-houses> my career is  a joke and I am not learning
[02:04:50] <concrete-houses> I am so furstrated
[02:08:44] *** Quits: michalz (~michalz@185.246.204.107) (Remote host closed the connection)
[02:11:11] *** Quits: shka (~herr@109.231.3.55) (Ping timeout: 260 seconds)
[02:12:39] *** Joins: Exuma (~Exuma@47-208-155-156.erkacmtk03.res.dyn.suddenlink.net)
[02:13:20] *** Quits: Exuma (~Exuma@47-208-155-156.erkacmtk03.res.dyn.suddenlink.net) (Client Quit)
[02:14:52] *** Quits: peteyboy_ (~peteyboy1@199.157.133.37.dynamic.jazztel.es) (Ping timeout: 246 seconds)
[02:15:10] <concrete-houses> hmmm
[02:15:46] <concrete-houses> I saw that no-gap sequences are not easy in postgresql
[02:15:57] <concrete-houses> and can be done at performacne cost
[02:16:04] <xocolatl> they aren't needed (except one case)
[02:16:16] *** Joins: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net)
[02:16:18] <xocolatl> and that case doesn't require performance
[02:16:28] <concrete-houses> so we should tell the biz side jsut deal, or that its even beter security to not have in perf order?
[02:16:40] *** Joins: peteyboy1 (~peteyboy1@199.157.133.37.dynamic.jazztel.es)
[02:16:52] <xocolatl> depends on the use case
[02:17:32] <xocolatl> if the reason for gapless is a legal one, then you can't tell them to "just deal"
[02:18:35] <Snow-Man> have fun with all your transactions serialized, lol
[02:19:55] <concrete-houses> I think we hav dynamic queries from entiryt frameowrk and entiyr core asp.net or something to aws aurora psotgresql lol
[02:20:03] <concrete-houses> frankestine monster of tek
[02:20:05] *** Quits: shored (~shored@user/shored) (Quit: ZNC 1.8.2+deb2 - https://znc.in)
[02:21:15] *** Joins: shored (~shored@user/shored)
[02:22:57] *** Joins: the_lanetly_052_ (~the_lanet@194.135.169.165)
[02:23:26] *** Quits: harpia (~harpia@143.208.84.100) (Quit: harpia)
[02:25:23] *** Quits: the_lanetly_052 (~the_lanet@194.135.169.76) (Ping timeout: 260 seconds)
[02:26:15] *** Quits: rendar (~rendar@user/rendar) (Quit: Leaving)
[02:30:49] *** Quits: steinomead (~steinomea@c-71-236-242-8.hsd1.or.comcast.net) (Remote host closed the connection)
[02:33:50] *** Quits: Guest75 (~textual@ip184-181-47-47.no.no.cox.net) (Quit: Textual IRC Client: www.textualapp.com)
[02:34:18] *** Joins: sympatico (~textual@ip184-181-47-47.no.no.cox.net)
[02:35:57] *** Quits: sympatico (~textual@ip184-181-47-47.no.no.cox.net) (Client Quit)
[02:41:48] *** Quits: kitsunenokenja (~kitsunech@68.91.220.96) (Ping timeout: 272 seconds)
[02:42:47] *** Quits: peteyboy1 (~peteyboy1@199.157.133.37.dynamic.jazztel.es) (Ping timeout: 252 seconds)
[02:43:00] *** Quits: NCS_One (~NCS_One@bl11-90-133.dsl.telepac.pt) (Quit: Lost terminal)
[02:43:23] *** Quits: pedja (~pedja@user/deus-ex/x-7934090) (Quit: Leaving)
[02:44:04] *** Joins: richard_h (~richard@2406:e001:8:a900:6e62:6dff:fe05:ae29)
[02:47:19] <texasmynsted> thank you xocolatl
[02:47:45] <texasmynsted> Any advice or links you suggest for using partitioning for archiving data?
[02:51:46] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[02:51:47] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[02:53:27] *** Joins: dfee (~dfee@ew4-143.ewnet.net)
[02:54:16] *** Joins: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net)
[02:56:17] *** Quits: bmomjian (~bruce@momjian.us) (Quit: Leaving.)
[02:56:23] *** Joins: bmomjian1 (~bruce@momjian.us)
[02:58:44] *** Quits: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net) (Ping timeout: 252 seconds)
[02:58:53] *** Quits: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 256 seconds)
[03:07:01] *** Quits: EvanCarroll (~ecarroll@4.78.9.73) (Ping timeout: 245 seconds)
[03:11:43] *** Quits: Likorn (~Likorn@c114-150.icpnet.pl) (Quit: WeeChat 3.4)
[03:12:56] *** Quits: Auron (~Auron956@user/auron) (Remote host closed the connection)
[03:15:36] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[03:15:48] *** Quits: HumanG33k (~HumanG33k@2a01:e0a:95:5d90:215:c5ff:fe68:fb04) (Ping timeout: 240 seconds)
[03:15:55] *** Joins: rageshkrishna_ (~rageshkri@122.162.198.225)
[03:16:09] *** Quits: rageshkrishna (~rageshkri@124.40.245.74) (Read error: Connection reset by peer)
[03:18:01] *** Joins: HumanG33k (~HumanG33k@dau94-2-82-66-65-160.fbx.proxad.net)
[03:20:15] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Ping timeout: 260 seconds)
[03:20:35] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[03:21:45] *** Joins: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net)
[03:23:24] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[03:24:06] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 260 seconds)
[03:24:09] *** Quits: haris (~haris@69.169.3.81) (Remote host closed the connection)
[03:28:35] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[03:30:59] *** Quits: ur5us (~ur5us@203.86.198.200) (Ping timeout: 260 seconds)
[03:34:12] *** Quits: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 260 seconds)
[03:35:59] *** Quits: zaher_ (~zaher@37.48.152.217) (Read error: Connection reset by peer)
[03:36:32] *** Joins: dre (~dre@2001:8003:c932:c301:ddea:d36a:75bb:2e08)
[03:37:13] *** Quits: Klinda (~superleag@user/klinda) (Quit: Konversation terminated!)
[03:37:22] *** Joins: zaher (~zaher@37.48.179.27)
[03:42:22] *** Joins: zaher_ (~zaher@37.48.159.60)
[03:43:11] *** Quits: Optimus (~risto@87.227.227.147) ()
[03:44:11] *** Quits: CanuteTheGreat (~CanuteThe@user/canutethegreat) (Read error: Connection reset by peer)
[03:44:28] *** Quits: zaher (~zaher@37.48.179.27) (Ping timeout: 246 seconds)
[03:46:09] *** Joins: Atque (~Atque@user/atque)
[03:52:06] *** Quits: dionysus69 (~Thunderbi@94-43-121-219.dsl.utg.ge) (Ping timeout: 272 seconds)
[03:55:07] <StuckMojo> how do you schema qualify an operator?
[03:55:09] *** Joins: CanuteTheGreat (~CanuteThe@user/canutethegreat)
[03:55:14] *** Joins: Reiner_Unsinn (~quassel@46.140.210.242)
[03:55:47] <xocolatl> operator(schemaname.++)
[03:56:18] <xocolatl> WHERE id OPERATOR(pg_catalog.=) 42
[03:56:31] <StuckMojo> thanks
[03:59:18] *** Quits: concrete-houses (~g@209.6.150.53) (Ping timeout: 260 seconds)
[04:01:08] *** Joins: concrete-houses (~g@209.6.150.53)
[04:02:04] *** Quits: ncwbqcfe (~rvgzuuqp@gateway/tor-sasl/rvgzuuqp) (Quit: ncwbqcfe)
[04:03:35] *** Quits: AnselmoCampanas (~AnselmoCa@190.99.69.41) (Quit: Client closed)
[04:05:24] *** Quits: the_lanetly_052_ (~the_lanet@194.135.169.165) (Ping timeout: 272 seconds)
[04:05:56] *** Joins: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net)
[04:10:14] *** Quits: bmomjian1 (~bruce@momjian.us) (Quit: Leaving.)
[04:10:15] *** Joins: bmomjian (~bruce@momjian.us)
[04:12:10] *** Joins: sympatico (~textual@ip184-181-47-47.no.no.cox.net)
[04:12:26] *** Quits: lifeless (~robertc@168.92-220-19.customer.lyse.net) (Ping timeout: 245 seconds)
[04:15:20] <StuckMojo> since when can a non-superuser create an extension?
[04:15:29] <StuckMojo> can a database owner make them?
[04:15:44] *** Quits: sympatico (~textual@ip184-181-47-47.no.no.cox.net) (Client Quit)
[04:16:02] *** Joins: sympatico (~textual@ip184-181-47-47.no.no.cox.net)
[04:17:37] <StuckMojo> no they can't
[04:17:44] * StuckMojo sighs
[04:17:48] <StuckMojo> stupid users
[04:18:08] <xocolatl> I think 14 introduced "trusted" extensions
[04:19:33] *** Joins: lifeless (~robertc@168.92-220-19.customer.lyse.net)
[04:21:36] *** Quits: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c) (Remote host closed the connection)
[04:24:09] *** Joins: tozhu (~tozhu@218.89.234.111)
[04:24:47] <ario> this is slow for such a simple query, right? https://explain.depesz.com/s/pLxh
[04:25:02] *** Quits: n0fun (~jack@mue-88-130-48-035.dsl.tropolys.de) (Ping timeout: 272 seconds)
[04:25:47] <ario> maybe 0.5ms is fast
[04:26:28] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[04:26:29] <xocolatl> seems pretty fast to me
[04:26:37] <xocolatl> what problem are you experiencing?
[04:26:53] <ario> sometimes an endpoint hitting this query is taking 5 seconds!
[04:27:39] <ario> and the query can take ~2seconds observing from the endpoint trace
[04:28:36] <xocolatl> unless you can show the query itself causing that lag, it isn't the database
[04:29:04] <ario> The trace shows the query itself is taking 2-4seconds sometimes
[04:30:02] <xocolatl> show us the explain for that one then
[04:30:59] <StuckMojo> ario: the trace shows the *netowrk* *call* for the query taking 2-4 seconds
[04:31:13] *** Quits: tozhu (~tozhu@218.89.234.111) (Quit: tozhu)
[04:31:15] <ario> That is correct
[04:31:17] <ario> hmm
[04:31:24] <StuckMojo> and that would mean....
[04:31:31] <StuckMojo> come with me here....
[04:31:34] <ario> haha
[04:31:39] <StuckMojo> that the problem is in your.....
[04:31:48] <ario> network?
[04:31:49] <ario> lmao
[04:31:55] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[04:31:56] <StuckMojo> *bingo*!
[04:32:05] <StuckMojo> we have a winner
[04:32:20] <ario> come on network, work fater!
[04:32:23] <ario> faster*
[04:32:27] <xocolatl> what did they win, bob?
[04:32:41] <StuckMojo> a sloooowww netowork!
[04:32:58] <StuckMojo> yaaaaayayayaaaay!
[04:33:04] <ario> *gives slow network back*
[04:33:21] <StuckMojo> heh, so anyway, it's probably transient network congestion
[04:33:47] *** Joins: EvanCarroll (~ecarroll@4.78.9.77)
[04:34:02] <StuckMojo> if this is all within one datacenter, have network team look at the switch graphs for the overall network usage levels
[04:34:27] <StuckMojo> if it's between two DCs, look for capacity issues in the trunk connecting them
[04:35:48] <StuckMojo> if it's all within a single rack, look for failing or flaky network cards
[04:35:56] <ario> yeah
[04:35:58] <ario> looks like it!
[04:36:00] <ario> wow
[04:36:07] <StuckMojo> which one?
[04:36:47] <ario> my nginx route rule i setup for that endpoint to divert to a different pod
[04:36:48] <ario> is slow!
[04:36:59] <StuckMojo> that'll do it
[04:37:06] <StuckMojo> gotta love kube
[04:37:16] <ario> why is one pod slow and other one faster wtf
[04:37:19] <ario> *dies*
[04:37:38] <StuckMojo> well, the pods all share resources with all the other pods so...
[04:38:02] <StuckMojo> you're at the mercy of noisy neighbors
[04:38:47] <StuckMojo> maybe there's something wrong with the rule itself, or nginx is getting starved out
[04:39:01] *** Quits: Bebef (sbreit@phobos.bebef.de) (Quit: bye)
[04:39:07] <ario> but pods have reservations and run as different processes at least
[04:39:26] <ario> it's a nginx-controller that should load balance
[04:39:45] <StuckMojo> meh. that assumes the sum total of all the reservations is not greater than the total capacity of the underlying host
[04:40:33] <StuckMojo> try putting all your pods on their own machine
[04:41:09] <ario> i want to add a verb rule to my nginx routing then
[04:41:09] <ario> hmm
[04:41:18] <ario> get it out of the noisy neighborhood
[04:41:29] <StuckMojo> or just live with the fact that vurtualized enviornments like this have these issues
[04:41:47] <StuckMojo> it's hard to get really persistant static performance levels
[04:42:03] <StuckMojo> but at least now you know what to complain about
[04:42:09] <ario> :)
[04:42:24] <StuckMojo> to the team that runs the underlying architecture
[04:43:07] *** Joins: tozhu (~tozhu@218.89.234.111)
[04:43:39] *** Joins: Bebef (sbreit@phobos.bebef.de)
[04:43:59] <ario> is it possible to put an nginx rule on identical routes that are GET/POST but only on the POST?
[04:44:32] <StuckMojo> i dunno, you're out of my area there
[04:44:59] <ario> im derailing this wonderful channel aswell
[04:45:17] <StuckMojo> true, you've gotten a little off topic now
[04:46:15] <StuckMojo> but it was quiet anyway, maybe someone who knows will answer...although most of the folks here with lots of experience are DBAs who work on big dedicated hardware instances, or large instance classes in AWS
[04:46:20] *** Quits: tozhu (~tozhu@218.89.234.111) (Client Quit)
[04:48:34] <ario> i'm looking it up
[04:53:16] *** Joins: tozhu (~tozhu@218.89.234.111)
[04:57:47] *** Quits: tozhu (~tozhu@218.89.234.111) (Client Quit)
[05:05:36] *** Joins: ur5us (~ur5us@2406:e002:689a:b901:920f:b571:c0ce:1fdb)
[05:07:33] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[05:12:16] *** Joins: inak (~justme@228-134-237-24.gci.net)
[05:15:39] <ario> damn i don't think it's possible with nginx - it's too dumb
[05:17:36] *** Joins: dfee (~dfee@ew4-143.ewnet.net)
[05:20:08] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[05:21:11] *** Quits: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 252 seconds)
[05:26:13] *** Quits: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net) (Read error: Connection reset by peer)
[05:27:02] *** Joins: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net)
[05:27:55] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[05:30:06] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[05:36:15] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[05:37:52] *** Quits: zaher_ (~zaher@37.48.159.60) (Ping timeout: 246 seconds)
[05:39:39] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[05:42:37] *** Joins: tozhu (~tozhu@117.139.163.129)
[05:46:54] *** Joins: xocolatl_ (~xocolatl@138.199.15.167)
[05:47:45] *** Quits: xocolatl (~xocolatl@138.199.15.151) (Ping timeout: 250 seconds)
[05:48:11] *** Quits: Reiner_Unsinn (~quassel@46.140.210.242) (Ping timeout: 260 seconds)
[05:48:38] *** Joins: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net)
[05:52:36] *** Joins: impermanence (~impermane@c-75-73-193-204.hsd1.mn.comcast.net)
[05:54:08] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[05:57:08] *** Quits: f3f3lix (~weechat@55d4df2c.access.ecotel.net) (Ping timeout: 260 seconds)
[05:57:37] *** Joins: xiongxin (~Thunderbi@117.136.39.213)
[05:59:01] *** Joins: f3f3lix (~weechat@55d4d8f5.access.ecotel.net)
[06:05:27] *** Quits: stark__ (~stark@192.222.248.88) (Ping timeout: 260 seconds)
[06:06:15] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[06:10:20] *** Joins: xiongxin1 (~Thunderbi@2409:8954:2e14:296d:7f3d:c53e:c634:5e61)
[06:13:15] *** Quits: xiongxin (~Thunderbi@117.136.39.213) (Ping timeout: 256 seconds)
[06:14:36] *** Quits: xiongxin1 (~Thunderbi@2409:8954:2e14:296d:7f3d:c53e:c634:5e61) (Ping timeout: 240 seconds)
[06:17:58] *** Joins: dodobrain (~dodobrain@user/dodobrain)
[06:18:19] *** Joins: trafficjam (~trafficja@203.176.111.34)
[06:20:13] *** Quits: MrZeus (~MrZeus@185.206.227.135) (Ping timeout: 246 seconds)
[06:24:45] *** Joins: Guest48 (~textual@2001:ee0:4081:6914:c4b6:c300:278:fafe)
[06:27:23] *** Quits: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net) (Ping timeout: 260 seconds)
[06:27:47] *** Joins: austb_ (~austb@c-73-240-245-80.hsd1.or.comcast.net)
[06:28:28] *** Joins: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net)
[06:31:59] *** Joins: ncwbqcfe (~rvgzuuqp@gateway/tor-sasl/rvgzuuqp)
[06:32:05] *** Joins: xiongxin (~Thunderbi@117.136.40.174)
[06:33:03] *** Quits: Xof (~Xof@157-131-136-66.dedicated.static.sonic.net) (Quit: Bye.)
[06:33:42] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[06:33:56] *** xocolatl_ is now known as xocolatl
[06:35:30] *** Quits: acovrig (~acovrig@host-173-247-7-127.JENOLT2.epbfi.com) (Quit: Ping timeout (120 seconds))
[06:35:53] *** Joins: acovrig (~acovrig@host-173-247-7-127.JENOLT2.epbfi.com)
[06:41:58] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 260 seconds)
[06:43:49] *** Joins: _xor (~xor@74.215.232.169)
[06:57:02] *** Quits: Vacuity (~Vacuity@user/vovo) (Ping timeout: 272 seconds)
[06:58:20] *** Joins: Vacuity (~Vacuity@user/vovo)
[06:58:55] *** Quits: acovrig (~acovrig@host-173-247-7-127.JENOLT2.epbfi.com) (Ping timeout: 256 seconds)
[06:59:20] *** Joins: acovrig (~acovrig@host-173-247-7-127.JENOLT2.epbfi.com)
[07:00:31] *** Quits: AceSlash (~slash@2a01:e0a:432:c050:cd12:393c:3664:2a6e) (Quit: Leaving)
[07:09:54] *** Joins: dfee (~dfee@ew4-143.ewnet.net)
[07:17:37] *** Joins: asymmentric (~asymmentr@157.45.122.233)
[07:17:40] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[07:18:16] *** Quits: asymmentric (~asymmentr@157.45.122.233) (Client Quit)
[07:18:29] *** Joins: asymmentric (~asymmentr@157.45.122.233)
[07:20:28] *** Quits: austb_ (~austb@c-73-240-245-80.hsd1.or.comcast.net) (Ping timeout: 272 seconds)
[07:21:49] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Ping timeout: 240 seconds)
[07:25:51] *** Joins: Shells (~michelle@2407:8800:bc20:200a:7c00:910f:8e36:433c)
[07:27:07] *** Quits: Michelle (~michelle@203.206.128.220) (Ping timeout: 260 seconds)
[07:27:08] *** Joins: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net)
[07:28:47] *** Quits: xinming (~xinming@115.219.39.250) (Ping timeout: 252 seconds)
[07:29:11] *** Joins: xinming (~xinming@115.219.39.250)
[07:29:42] *** Quits: rageshkrishna_ (~rageshkri@122.162.198.225) (Quit: ZNC 1.8.2 - https://znc.in)
[07:30:05] *** Joins: rageshkrishna (~rageshkri@122.162.198.225)
[07:39:15] *** Joins: xiongxin1 (~Thunderbi@2409:8954:2e14:1a84:e291:3593:78a1:6401)
[07:42:00] *** Quits: xiongxin (~Thunderbi@117.136.40.174) (Ping timeout: 272 seconds)
[07:42:01] *** xiongxin1 is now known as xiongxin
[07:43:38] *** Quits: trafficjam (~trafficja@203.176.111.34) (Ping timeout: 250 seconds)
[07:46:12] *** Quits: wasutton (~wasutton3@75-46-236-127.lightspeed.tukrga.sbcglobal.net) (Quit: ZNC 1.8.2 - https://znc.in)
[07:52:07] *** Quits: rewrit3 (~rewrit3@user/rewrit3) (Read error: Connection reset by peer)
[07:52:19] *** Quits: xiongxin (~Thunderbi@2409:8954:2e14:1a84:e291:3593:78a1:6401) (Ping timeout: 260 seconds)
[07:52:47] *** Quits: ivii (~ivan@user/ivii) (Remote host closed the connection)
[07:56:59] *** Quits: asymmentric (~asymmentr@157.45.122.233) (Quit: Connection closed)
[08:00:10] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[08:03:18] *** Joins: trafficjam (~trafficja@203.176.111.34)
[08:08:03] *** Quits: Guest48 (~textual@2001:ee0:4081:6914:c4b6:c300:278:fafe) (Ping timeout: 256 seconds)
[08:09:53] *** Joins: dfee (~dfee@ew4-143.ewnet.net)
[08:10:13] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Client Quit)
[08:15:34] *** Quits: sreve (~quassel@p4ff44df2.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[08:15:36] *** Joins: sreve_ (~quassel@p4ff44f3f.dip0.t-ipconnect.de)
[08:33:22] *** Quits: ksynwa (~ksynwa@5.45.111.57) (Quit: oh no they're here)
[08:37:35] *** Quits: op2 (~op2@user/op2) (Ping timeout: 260 seconds)
[08:43:55] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[08:44:41] *** Joins: ged (~ged@deveiate.org)
[08:50:02] *** Quits: dodobrain (~dodobrain@user/dodobrain) (Ping timeout: 240 seconds)
[08:54:28] *** Quits: ur5us (~ur5us@2406:e002:689a:b901:920f:b571:c0ce:1fdb) (Ping timeout: 260 seconds)
[08:55:03] *** Quits: RonWhoCares (~ronpi@104.158.0.91) (Quit: Konversation terminated!)
[08:58:12] *** Quits: mrgz (~mrgz@201-42-0-191.dsl.telesp.net.br) (Ping timeout: 240 seconds)
[09:08:08] *** Quits: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net) (Ping timeout: 272 seconds)
[09:09:58] *** Quits: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net) (Ping timeout: 246 seconds)
[09:10:50] *** Joins: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:12:09] *** Quits: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Remote host closed the connection)
[09:13:07] *** Joins: trafficjam35 (~trafficja@203.176.111.34)
[09:13:17] *** Joins: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:15:56] *** Quits: trafficjam (~trafficja@203.176.111.34) (Ping timeout: 250 seconds)
[09:17:49] *** Joins: maret (~maret@nat-88-212-37-89.antik.sk)
[09:17:52] *** Joins: dodobrain (~dodobrain@user/dodobrain)
[09:21:13] *** Quits: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Remote host closed the connection)
[09:22:01] *** Joins: shiranaihito (~textual@123.192.192.149)
[09:26:21] *** Joins: mattil (~mattil@helsinki.portalify.com)
[09:26:27] *** Joins: dfee (~dfee@ew4-143.ewnet.net)
[09:27:01] *** Joins: trafficjam (~trafficja@2001:8004:1500:4d7d:f6af:bf82:4a55:37f7)
[09:27:11] *** Joins: mattil_ (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:27:21] *** Quits: mattil_ (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Remote host closed the connection)
[09:27:28] *** Joins: mattil_ (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:28:30] *** Quits: trafficjam35 (~trafficja@203.176.111.34) (Ping timeout: 250 seconds)
[09:28:40] *** Quits: mattil_ (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Read error: Connection reset by peer)
[09:29:08] *** Joins: mattil_ (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:29:32] *** Joins: trafficjam15 (~trafficja@203.176.111.34)
[09:31:13] *** Quits: mattil (~mattil@helsinki.portalify.com) (Ping timeout: 260 seconds)
[09:31:58] *** Quits: trafficjam (~trafficja@2001:8004:1500:4d7d:f6af:bf82:4a55:37f7) (Ping timeout: 250 seconds)
[09:32:04] *** Quits: trafficjam15 (~trafficja@203.176.111.34) (Client Quit)
[09:32:24] *** Joins: trafficjam (~trafficja@203.176.111.34)
[09:37:05] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[09:38:53] *** Joins: RonWhoCares (~ronpi@104.158.0.91)
[09:39:20] *** Quits: RonWhoCares (~ronpi@104.158.0.91) (Client Quit)
[09:39:32] *** Quits: mattil_ (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Remote host closed the connection)
[09:39:36] *** Joins: RonWhoCares (~ronpi@104.158.0.91)
[09:39:41] *** Quits: tozhu (~tozhu@117.139.163.129) (Quit: tozhu)
[09:39:58] *** Joins: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:41:13] *** Joins: manti7 (~manti7@176.10.104.94)
[09:42:35] *** Quits: blaklistd (~blaklistd@user/blaklistd) (Quit: au revoir)
[09:44:17] *** Joins: blaklistd (~blaklistd@user/blaklistd)
[09:44:38] *** Quits: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Ping timeout: 252 seconds)
[09:47:28] *** Quits: dodobrain (~dodobrain@user/dodobrain) (Remote host closed the connection)
[09:48:17] *** Joins: carragom (~textual@201.204.94.76)
[09:52:19] *** Quits: dob1 (~dob1@user/dob1) (Ping timeout: 246 seconds)
[09:53:52] *** Joins: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi)
[09:55:14] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[09:58:26] *** Joins: vnf (~vnf@46.159.151.228)
[09:58:36] *** Quits: mattil (~mattil@dzdrfkgfwyq7zpkrhwk-4.rev.dnainternet.fi) (Ping timeout: 240 seconds)
[10:00:42] *** Joins: Reiner_Unsinn (~quassel@46.140.210.242)
[10:05:39] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[10:06:57] *** Joins: dob1 (~dob1@user/dob1)
[10:07:56] *** Joins: tnewman (~tnewman@118.150.44.48)
[10:07:58] *** Joins: ekathva (~ekathva@93-90-58-246.welcomnet.fi)
[10:08:04] *** Joins: dodobrain (~dodobrain@user/dodobrain)
[10:09:17] *** Quits: Reiner_Unsinn (~quassel@46.140.210.242) (Read error: Connection reset by peer)
[10:09:37] *** Joins: Reiner_Unsinn (~quassel@46.140.210.242)
[10:13:13] *** Quits: dob1 (~dob1@user/dob1) (Ping timeout: 260 seconds)
[10:16:52] *** Quits: tnewman (~tnewman@118.150.44.48) (Read error: Connection reset by peer)
[10:17:26] *** Quits: rvalue (~rvalue@user/rvalue) (Read error: Connection reset by peer)
[10:17:43] *** Joins: tnewman (~tnewman@118.150.44.48)
[10:17:58] *** Joins: rvalue (~rvalue@user/rvalue)
[10:18:32] <tnewman> investigating postgresql + pgpool2 for one of our business workloads.  does anyone have a favorite tutorial/guide for getting my feet wet?
[10:21:12] *** Quits: zauberfisch (~Zauberfis@cm147-42.liwest.at) ()
[10:22:17] *** Joins: zauberfisch (~Zauberfis@cm147-42.liwest.at)
[10:25:41] *** Joins: Guest5279 (~Guest52@213.162.65.111)
[10:28:34] *** Quits: mjf_ (~mjf@cst-prg-87-91.cust.vodafone.cz) (Ping timeout: 272 seconds)
[10:29:40] *** Joins: mjf_ (~mjf@2001:1528:1:fffd:a02e:21d3:b3d4:86b8)
[10:31:53] <Guest5279> Hi, does any body know how to write a "manual" unique constraint? i have a many-to-many table "from, relation_type, to". Normaly we want only one relation to be allowed between two objects. But there are some relation_types, which are allowed to be added addtionaly (but each type only once). so trigger is clear - but do i need to lock the table all
[10:31:53] <Guest5279> the time to ensure that? serializable is not an option - i cant ensure that on every transaction
[10:35:22] *** Joins: mexen (uid495612@user/mexen)
[10:37:07] *** Quits: Reiner_Unsinn (~quassel@46.140.210.242) (Ping timeout: 246 seconds)
[10:39:42] *** Parts: trafficjam (~trafficja@203.176.111.34) ()
[10:40:26] *** Quits: vnf (~vnf@46.159.151.228) (Quit: Leaving)
[10:43:46] *** Quits: mncheck (~mncheck@193.224.205.254) (Read error: Connection reset by peer)
[10:45:28] *** Joins: vnf (~vnf@46.159.151.228)
[10:50:18] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[10:52:09] *** Joins: op2 (~op2@user/op2)
[10:54:56] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Ping timeout: 245 seconds)
[10:56:49] *** Joins: darutoko (~darutoko@5.136.93.106)
[11:00:25] *** Joins: cliluw (~cliluw@47.147.77.43)
[11:03:02] *** Quits: jnnnnnnnnn (~jnnnnnnnn@65.99.151.178) (Remote host closed the connection)
[11:05:36] *** Quits: dsrt^ (~dsrt@96-91-136-49-static.hfc.comcastbusiness.net) (Read error: Connection reset by peer)
[11:05:59] *** Joins: dsrt^ (~dsrt@96-91-136-49-static.hfc.comcastbusiness.net)
[11:06:16] *** Quits: jmcgnh (~jmcgnh@wikipedia/jmcgnh) (Remote host closed the connection)
[11:07:29] *** Joins: Reiner_Unsinn (~quassel@46.140.210.242)
[11:07:49] *** Quits: HumanG33k (~HumanG33k@dau94-2-82-66-65-160.fbx.proxad.net) (Quit: WeeChat 3.0)
[11:07:52] *** Joins: jnnnnnnnnn (~jnnnnnnnn@65.99.151.178)
[11:11:13] *** Joins: jmcgnh (~jmcgnh@wikipedia/jmcgnh)
[11:11:49] *** Joins: Optimus (~risto@87.227.227.147)
[11:14:48] *** Joins: odnes (~odnes@5-203-245-187.pat.nym.cosmote.net)
[11:14:53] *** Quits: inak (~justme@228-134-237-24.gci.net) (Quit: Leaving)
[11:15:26] *** Quits: Optimus (~risto@87.227.227.147) (Read error: Connection reset by peer)
[11:15:43] *** Joins: Optimus (~risto@87.227.227.147)
[11:16:13] *** Joins: ur5us (~ur5us@2406:e002:689a:b901:920f:b571:c0ce:1fdb)
[11:16:19] *** Quits: iliv (~iliv@user/iliv) (Ping timeout: 246 seconds)
[11:16:49] *** Quits: Reiner_Unsinn (~quassel@46.140.210.242) (Read error: Connection reset by peer)
[11:17:15] *** Joins: Reiner_Unsinn (~quassel@46.140.210.242)
[11:18:15] *** Quits: Reiner_Unsinn (~quassel@46.140.210.242) (Read error: Connection reset by peer)
[11:18:15] *** Quits: randir (~randir@95-31-138-202.broadband.corbina.ru) (Read error: Connection reset by peer)
[11:19:01] *** Joins: Reiner_Unsinn (~quassel@46.140.210.242)
[11:19:57] *** Joins: michalz (~michalz@185.246.204.125)
[11:22:49] *** Joins: iliv (~iliv@93-77-147-152.lvv.volia.net)
[11:23:22] *** Quits: dodobrain (~dodobrain@user/dodobrain) (Ping timeout: 240 seconds)
[11:27:41] *** Joins: xiongxin (~Thunderbi@117.136.39.222)
[11:31:53] <modin> Guest5279: you can have UNIQUE over relation_type
[11:35:49] *** Quits: maciek__ (~maciek@2600:1700:a412:1c00:a2d9:3194:988b:4417) (Remote host closed the connection)
[11:36:13] *** Joins: maciek__ (~maciek@2600:1700:a412:1c00:a2d9:3194:988b:4417)
[11:37:17] *** Joins: palasso (~palasso@user/palasso)
[11:37:45] *** Joins: fordfrog_ (~fordfrog@gentoo/developer/fordfrog)
[11:49:02] *** Joins: shka (~herr@109.231.3.55)
[11:49:07] <Guest5279> modin its a little bit different requirement: for example: relation_type "a", "b", "c" is allowed only to be unique (so one a-->b should only have one of them), but it should be allowed to add "x", "y" additionaly
[11:49:36] *** Joins: dob1 (~dob1@user/dob1)
[11:49:44] <Guest5279> modin its a little bit different requirement: for example: relation_type "rt1", "rt2", "rt3" is allowed only to be unique (so one a-->b should only have one of them), but it should be allowed to add "x", "y" additionaly
[11:52:16] <Guest5279> (maybe its possible with GIST exlude)
[11:55:28] *** Quits: jnnnnnnnnn (~jnnnnnnnn@65.99.151.178) (Quit: Textual IRC Client: www.textualapp.com)
[11:55:58] *** Quits: dob1 (~dob1@user/dob1) (Ping timeout: 272 seconds)
[11:57:38] *** Quits: ekathva (~ekathva@93-90-58-246.welcomnet.fi) (Ping timeout: 260 seconds)
[12:00:28] *** Joins: gleu (~guillaume@2a01cb0c0e54b8007e39e75cb4390e1c.ipv6.abo.wanadoo.fr)
[12:00:40] *** Joins: otisolsen70 (~otisolsen@80.80.4.2)
[12:00:51] *** Quits: strNophix9 (~strNophix@86-83-36-18.fixed.kpn.net) (Remote host closed the connection)
[12:01:48] *** Quits: otisolsen70 (~otisolsen@80.80.4.2) (Remote host closed the connection)
[12:03:03] *** Joins: otisolsen70 (~otisolsen@80.80.4.2)
[12:04:41] *** Quits: eric (~user@45.91.144.178) (Remote host closed the connection)
[12:04:46] *** Joins: henrydance777 (~henrydanc@static-n49-176-146-220.meb4.vic.optusnet.com.au)
[12:07:43] *** Joins: ur5us_ (~ur5us@2406:e002:689a:b901:920f:b571:c0ce:1fdb)
[12:07:53] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[12:08:36] *** Quits: ur5us (~ur5us@2406:e002:689a:b901:920f:b571:c0ce:1fdb) (Read error: Connection reset by peer)
[12:11:31] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[12:11:56] *** Joins: dob1 (~dob1@user/dob1)
[12:12:44] *** Joins: xiongxin1 (~Thunderbi@2409:8954:2e14:3316:5adc:f35f:7fae:8bc4)
[12:13:18] *** Joins: palasso (~palasso@user/palasso)
[12:14:55] *** Joins: psoo (~psoo@dslb-002-202-190-148.002.202.pools.vodafone-ip.de)
[12:14:58] *** Quits: xiongxin (~Thunderbi@117.136.39.222) (Ping timeout: 272 seconds)
[12:14:59] *** xiongxin1 is now known as xiongxin
[12:15:03] *** Joins: n0fun (~jack@mue-88-130-48-078.dsl.tropolys.de)
[12:15:34] *** Joins: rendar (~rendar@user/rendar)
[12:17:12] *** Joins: mncheck (~mncheck@193.224.205.254)
[12:17:59] *** Joins: eroux (~eroux@102-65-72-61.ftth.web.africa)
[12:20:33] *** Quits: maciek__ (~maciek@2600:1700:a412:1c00:a2d9:3194:988b:4417) (Ping timeout: 250 seconds)
[12:21:13] *** Quits: henrydance777 (~henrydanc@static-n49-176-146-220.meb4.vic.optusnet.com.au) (Remote host closed the connection)
[12:21:47] *** Joins: randir (~randir@93.159.239.42)
[12:24:31] *** Joins: Ergo^ (~ergo@91.238.59.144)
[12:25:08] *** Quits: Guest5279 (~Guest52@213.162.65.111) (Quit: Client closed)
[12:29:36] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Remote host closed the connection)
[12:29:44] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[12:31:23] *** Joins: tnewman8 (~tnewman@118.150.44.48)
[12:31:49] *** Joins: vladoski (~vladoski@2001:b07:add:d406:ce46:ce1d:6082:2c6f)
[12:32:05] *** Joins: rodo (~rodo@2a01:e0a:2c6:d5f0:9fdf:316a:1fc5:954e)
[12:33:19] *** Quits: tnewman (~tnewman@118.150.44.48) (Ping timeout: 246 seconds)
[12:33:20] *** tnewman8 is now known as tnewman
[12:36:31] *** Quits: sympatico (~textual@ip184-181-47-47.no.no.cox.net) (Quit: My iMac has gone to sleep. ZZZzzzâ€¦)
[12:37:10] *** Quits: jmcgnh (~jmcgnh@wikipedia/jmcgnh) (Ping timeout: 246 seconds)
[12:40:23] *** Joins: peteyboy1 (~peteyboy1@199.157.133.37.dynamic.jazztel.es)
[12:41:32] *** Joins: tnewman0 (~tnewman@118.150.44.48)
[12:42:23] *** Quits: tnewman (~tnewman@118.150.44.48) (Read error: Connection reset by peer)
[12:42:23] *** tnewman0 is now known as tnewman
[12:42:43] *** Joins: michelle_ (~michelle@203.206.128.220)
[12:43:03] *** Quits: dre (~dre@2001:8003:c932:c301:ddea:d36a:75bb:2e08) (Ping timeout: 260 seconds)
[12:43:59] *** Joins: jmcgnh (~jmcgnh@wikipedia/jmcgnh)
[12:44:53] *** Quits: Shells (~michelle@2407:8800:bc20:200a:7c00:910f:8e36:433c) (Ping timeout: 260 seconds)
[12:45:06] *** Joins: fandre1986 (~fandre198@78.10.85.96)
[12:48:13] *** Joins: otisolsen70_ (~otisolsen@80.80.4.2)
[12:48:50] *** Joins: dionysus69 (~Thunderbi@94-43-121-219.dsl.utg.ge)
[12:48:57] *** Quits: newdimension (~newdimens@user/newdimension) (Quit: Ping timeout (120 seconds))
[12:49:09] *** Joins: mamad (~mam@5.124.223.190)
[12:49:42] *** Joins: Guest48 (~textual@2001:ee0:4081:6914:99b7:825c:2784:1235)
[12:49:48] *** Joins: newdimension (~newdimens@user/newdimension)
[12:51:36] *** Quits: shka (~herr@109.231.3.55) (Quit: Konversation terminated!)
[12:51:43] *** Quits: otisolsen70 (~otisolsen@80.80.4.2) (Ping timeout: 272 seconds)
[12:51:52] *** Joins: shka (~herr@109.231.3.55)
[12:52:59] *** Quits: mamad (~mam@5.124.223.190) (Client Quit)
[12:53:08] *** Quits: Guest48 (~textual@2001:ee0:4081:6914:99b7:825c:2784:1235) (Client Quit)
[12:53:31] *** Joins: mamad (~mam@5.124.223.190)
[12:54:14] *** Quits: iliv (~iliv@93-77-147-152.lvv.volia.net) (Changing host)
[12:54:14] *** Joins: iliv (~iliv@user/iliv)
[12:55:50] *** Quits: otisolsen70_ (~otisolsen@80.80.4.2) (Remote host closed the connection)
[13:04:41] *** Quits: richard_h (~richard@2406:e001:8:a900:6e62:6dff:fe05:ae29) (Quit: Leaving.)
[13:07:32] *** Joins: Guest48 (~textual@2001:ee0:4081:6914:6868:2b77:4d50:9077)
[13:09:17] *** Joins: vnf_ (~vnf@85.175.252.98)
[13:11:24] *** Quits: vnf (~vnf@46.159.151.228) (Ping timeout: 240 seconds)
[13:16:55] *** Joins: ekathva (~ekathva@93-90-58-246.welcomnet.fi)
[13:17:24] *** Quits: xiongxin (~Thunderbi@2409:8954:2e14:3316:5adc:f35f:7fae:8bc4) (Ping timeout: 240 seconds)
[13:17:59] *** Joins: TomTom (uid45892@id-45892.ilkley.irccloud.com)
[13:18:56] *** Quits: Reiner_Unsinn (~quassel@46.140.210.242) (Ping timeout: 272 seconds)
[13:21:15] *** Joins: dfee (~dfee@ew4-143.ewnet.net)
[13:26:00] <maret> Any way how to track a progress of a long update query -> Update foo SET my_id = other_table.id from other_table where foo.something = other_table.something. I tried to run select MAX(my_id) expecting that my_id column was updated but I got null
[13:26:52] <maret> I guess that update hasnt finished so I cant seen changes yet.
[13:29:25] <Myon> that's the 'A' in ACID
[13:29:42] <maret> yeah
[13:30:08] <maret> issue is that the table is huge and the query has been running for 18 hours already, but I guess I will have to just wait
[13:31:02] <Myon> everything properly indexed? Including any FK fields? Triggers?
[13:31:36] *** Quits: fcr (~fran@r167-60-138-35.dialup.adsl.anteldata.net.uy) (Ping timeout: 245 seconds)
[13:34:23] *** Joins: zer0bitz (~zer0bitz@2001:2003:f750:a200:c06:c5f:5435:411f)
[13:34:47] *** Joins: otisolsen70 (~otisolsen@80.80.4.2)
[13:36:08] *** Joins: xiongxin (~Thunderbi@117.136.39.211)
[13:36:43] *** Quits: dfee (~dfee@ew4-143.ewnet.net) (Ping timeout: 256 seconds)
[13:37:14] *** Joins: fcr (~fran@r167-60-139-91.dialup.adsl.anteldata.net.uy)
[13:37:50] *** Joins: merzo1 (~Thunderbi@192.162.238.196)
[13:38:52] <maret> unfortunately, wanted to do index after I fix data
[13:39:34] *** Joins: xiongxin1 (~Thunderbi@2409:8954:2e14:184f:2d11:2654:9001:c0ca)
[13:40:05] *** merzo1 is now known as merzo
[13:43:13] *** Quits: xiongxin (~Thunderbi@117.136.39.211) (Ping timeout: 260 seconds)
[13:43:13] *** xiongxin1 is now known as xiongxin
[13:43:43] *** Joins: tozhu (~tozhu@118.115.54.168)
[13:44:03] *** Joins: plugwash (~plugwash@2a02:c7f:bce9:2d00::2)
[13:45:22] <plugwash> When running the query to check which indexes are affected at https://wiki.postgresql.org/wiki/Locale_data_changes i get
[13:45:39] <plugwash> ERROR:  column "collprovider" does not exist
[13:45:39] <plugwash> LINE 4: WHERE collprovider IN ('d', 'c') AND collname NOT IN ('C', '...
[13:45:47] <plugwash> any suggestions what the probem might be?
[13:53:11] *** Quits: tozhu (~tozhu@118.115.54.168) (Quit: tozhu)
[13:53:59] *** Quits: vladoski (~vladoski@2001:b07:add:d406:ce46:ce1d:6082:2c6f) (Ping timeout: 260 seconds)
[13:54:14] *** Joins: Klinda (~superleag@user/klinda)
[13:55:12] *** Joins: antis (~quassel@2001:9e8:4fdb:f800:3147:6b73:e41e:f2ff)
[13:55:38] *** Joins: Likorn (~Likorn@c114-150.icpnet.pl)
[13:57:49] *** Quits: Likorn (~Likorn@c114-150.icpnet.pl) (Client Quit)
[13:59:51] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[14:00:19] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[14:00:56] *** Joins: vladoski (~vladoski@93-32-199-119.ip35.fastwebnet.it)
[14:03:38] *** Quits: ekathva (~ekathva@93-90-58-246.welcomnet.fi) (Ping timeout: 260 seconds)
[14:04:53] *** Quits: vladoski (~vladoski@93-32-199-119.ip35.fastwebnet.it) (Remote host closed the connection)
[14:05:58] *** Quits: held (~heldchen@user/held) ()
[14:18:03] *** Joins: ekathva (~ekathva@93-90-58-246.welcomnet.fi)
[14:20:37] *** Quits: karlpinc (~user@173-161-46-9-Illinois.hfc.comcastbusiness.net) (Ping timeout: 240 seconds)
[14:20:55] *** Joins: ivii (~ivan@user/ivii)
[14:21:57] *** Joins: held (~heldchen@user/held)
[14:22:38] <Myon> PostgreSQL too old for that query
[14:22:49] <Myon> just remove "collprovider and"
[14:24:00] *** Quits: mamad (~mam@5.124.223.190) (Quit: Konversation terminated!)
[14:25:07] <azeem> that wiki page shoul have alternative queries then I guess
[14:25:40] *** Joins: dodobrain (~dodobrain@user/dodobrain)
[14:27:23] <Myon> true, but that's the first complaint we got in all those years
[14:27:23] *** Quits: dionysus69 (~Thunderbi@94-43-121-219.dsl.utg.ge) (Read error: Connection reset by peer)
[14:28:24] *** Quits: funhouse (~funhouse@user/funhouse) (Quit: Client closed)
[14:28:51] *** Quits: held (~heldchen@user/held) ()
[14:28:53] *** Joins: enoq (~enoq@2a05:1141:1f5:5600:b9c9:721a:599:bfe7)
[14:29:01] *** Joins: held (~heldchen@user/held)
[14:29:59] *** Joins: dionysus69 (~Thunderbi@94-43-121-219.dsl.utg.ge)
[14:30:17] *** Joins: grumper (~grumper@ip-178-200-140-153.um45.pools.vodafone-ip.de)
[14:31:55] *** Joins: Csm319_ (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[14:32:04] <grumper> greetings! I am facing a problem where I need to pull the contents of a table quickly ( no WHERE conditions, no transforms, just SELECT * basically ), and the transfer itself is what takes a while. Could someone point me to resources of how I can speed things up, giving up on type-niceties in the process etc. On the client side I use golangs pgx
[14:32:04] <grumper> currently, but can use something else if needed.
[14:32:17] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Ping timeout: 252 seconds)
[14:33:00] <marahin> Hi. I'm facing an issue where an app (that has some level of concurrency) is seemingly exceeding connections in my psql. I even set max_connections to 100, but: at any point in time during ~10 minutes when i was observing the log errors, total connections shown in DBeaver did not exceed ~60
[14:33:14] <marahin> SELECT COUNT(*) from pg_stat_activity; also returned a number between 20 and ~40
[14:33:31] <marahin> yet I'm facing regular errors like: FATAL: remaining connection slots are reserved for non-replication superuser connections (SQLSTATE 53300)
[14:34:22] <marahin> Google tells me its a connection issue, that I'm not closign connections somewhere, or I just have to set max_connections to a higher limit. `show max_connections;` returns 100 as of right now, and well... The connections more or less add up to what I need and use in the app. I don't think it's related to not closing connections properly.
[14:34:49] <marahin> Postgres is deployed in a Kubernetes cluster in a form of a single pod deployment.
[14:34:57] <marahin> Image used is `postgres:12`
[14:36:37] <Berge> marahin: Sounds like you have brief peaks of >95 connections, then
[14:36:48] <Berge> Consider using a pooler, such as pgbouncer
[14:37:04] <Berge> Or consider configuring your clients so that they don't open that many connections
[14:37:22] <Berge> Do you log connections and disconnections? You should be able to make some stats based on that
[14:37:28] <marahin> Berge: but for this reason I started DBeaver and went into the built in dashboard - at no point (even though errors were coming up) this postgres instance exceeded ~70 total connections.
[14:37:43] <Berge> marahin: But that's sampling
[14:37:53] <marahin> Mhm.
[14:37:57] <Berge> It's probably just doing SELECT COUNT(*) FROM pg_stat_activity; at some interval
[14:38:03] <marahin> Understandable
[14:38:05] <Berge> I wouldn't know, I don't use DBeaver
[14:38:24] <marahin> Alright, I'll give it a shot with pgBouncer
[14:38:25] <Berge> I agree it doesn't sound like you have lingering connections.
[14:38:25] <marahin> Thank you.
[14:38:33] *** Quits: econo (uid147250@user/econo) (Quit: Connection closed for inactivity)
[14:39:04] <Berge> If you're worried about that, look at idle_session_timeout (and/or idle_in_transaction_session_timeout)
[14:39:19] <marahin> will do:)
[14:39:25] <Berge> ah, you can't use idle_session_timeout iun 12
[14:39:37] <Berge> It's a new feature in 14
[14:39:46] <marahin> Never upgraded postgres before but I assume it won't be that big of an issue for a pretty standard DB
[14:40:03] <Berge> There are several approaches
[14:40:05] <marahin> so definitely an option at some point
[14:40:10] <Berge> All of which will be much more complex if you're running in Kubernetes
[14:43:10] *** Quits: nyov (~nyov@user/nyov) (Ping timeout: 272 seconds)
[14:43:24] *** Quits: ur5us_ (~ur5us@2406:e002:689a:b901:920f:b571:c0ce:1fdb) (Ping timeout: 240 seconds)
[14:43:36] <koollman> some approaches aren't much more complex. dump and reload is not hard, it's just long :)
[14:44:12] <marahin> all i have here is "production" so friends or colleagues access it, but it's not "production" in a business sense - none of that is monetizing or self-sustainable and hence no guarantees of quality to anyone:)
[14:44:14] <Berge> koollman: With data dir on a CSI thing?
[14:44:16] *** Joins: nyov (~nyov@user/nyov)
[14:44:23] <marahin> and also it's really small databases, all of them less then 10GB I think.
[14:44:25] <Berge> Well, I suppose you can, yes, if you have superuser access setup
[14:44:32] <Berge> â€¦which is more complex without unix sockets (-:
[14:44:37] <koollman> Berge: doesn't matter where the data is, really, as long as you can point pg_dump and psql to it
[14:45:05] <marahin> I'd assume the most primitive way would be to dump data -> upgrade it locally to pg14 -> upgrade the deployment to pg14 -> restore data
[14:45:07] <Berge> koollman: â€¦and can authenticat3e
[14:45:09] <Berge> s/3//
[14:45:32] <Berge> which I maintain is much more straight forward with "sudo -u postgres -i" than figuring out whatever pg_hba.conf stuff a random Docker image has setup
[14:45:36] <koollman> Berge: well, yeah. But that, too, is supposed to work. a db you cannot connect to isn't very useful :)
[14:46:41] <koollman> kubectl exec can usually lead you to a very similar situation
[14:46:48] *** Quits: xiongxin (~Thunderbi@2409:8954:2e14:184f:2d11:2654:9001:c0ca) (Ping timeout: 260 seconds)
[14:47:35] <Berge> true
[14:48:29] *** Quits: otisolsen70 (~otisolsen@80.80.4.2) (Quit: Leaving)
[14:52:26] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[14:55:01] *** Quits: Guest48 (~textual@2001:ee0:4081:6914:6868:2b77:4d50:9077) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[15:01:31] *** Quits: Csm319_ (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Quit: Leaving)
[15:03:48] *** Joins: pedja (~pedja@user/deus-ex/x-7934090)
[15:07:14] <maret> I am running an update query Update entities SET entities.group_id = groups_id FROM groups where entitities.hash = groups.hash. on a large table with 9 billions rows. There are no indexes right now so query is already taking 20hours. Reason why there are no indexes is, that those tables are new and I wanted to remove hash columns which are unique identifiers with bigserial column.
[15:08:22] <maret> Now I am not sure if its worth to cancel the query, create indexes which I guess will take several hours too and run the query again. Or update original source files for the tables (around 100GB of CSV files) and replace hash for integer values
[15:08:25] *** michelle_ is now known as Michelle
[15:10:08] <maret> Related question -> Is UPDATE query where XYZ like this comparable with SELECT query with the same WHERE condition , time wise?
[15:10:49] <maret> I am asking mainly to figure out whats the longest that this whole update can still take
[15:10:53] <maret> aproximatelly
[15:11:16] <ilmari> maret: plus the time taken to actually write the updated rows. `EXPLAIN (ANALYZE, BUFFERS) UPDATE â€¦`will show both (and also do the update, so do it in a transaction you roll back if you don't want that)
[15:12:09] <Berge> And plus the time it takes to check any FKs
[15:12:20] <Berge> And run any triggers
[15:12:41] <ilmari> yeah
[15:13:07] <maret> ilmari so lets say I will run this update for just one row so I would change condition from where  where entitities.hash = groups.has tom where entities.hash = 'somehash'; and lets say it would take 10 seconds for one row. Can I aproximate how much it will take to update all rows based on that?
[15:13:10] <Berge> And deal with write amplification, if applicable
[15:13:13] <ilmari> add VERBOSE to EXPLAIN option list to see how long each trigger took
[15:13:32] <maret> really what I am asking here is should I cancel the update already running for almost a day, run indexes and run it again or just wait (or to do maybe something else)
[15:13:48] <Berge> maret: The longest runtime is approximately the hardware's lifespan (-:
[15:13:56] <maret> :D
[15:14:14] <maret> or my, whichever comes first
[15:14:24] <Berge> Nah, the query will go on even if you expire
[15:14:26] <maret> because if I am not watching query riunning, does it still run :P
[15:15:26] <maret> Anyway what do you think, should I stop update query, create indexes and run it again?
[15:15:52] <ilmari> yes
[15:16:16] <Berge> maret: Out of curiosity, what sort of data is this+
[15:17:06] <maret> what do you mean exactly?
[15:17:08] <ilmari> looking at the query, it looks like you're changing the foreign key from the hash to a surrogate key?
[15:17:25] <ilmari> why?
[15:17:30] <maret> yeah although the hash is not used as FK right now
[15:17:50] <Berge> maret: What does the data represent? It's a reasonably big database.
[15:18:02] <Berge> Like, sensor events, for instance?
[15:18:51] <maret> the reason is that I want to use bigint instead of hash as primary key for better performance. There isnt really any reason why use hash, data just came with it
[15:20:57] <ilmari> what data type and how long is the hash?
[15:21:13] <ilmari> and how did you determine that that was the bottleneck?
[15:21:20] *** Quits: kvn_ (~weechat@user/kvn) (Quit: WeeChat 3.1)
[15:22:19] <ilmari> I estimate the performance improvement from indexing the hash columns would be vastly greater than changing to a bigint surrogate key
[15:23:50] <maret> string 64 charactes
[15:24:46] <maret> The question is should I use 64char text as primary / foreing key or bigint
[15:24:52] *** Joins: kvn_ (~weechat@user/kvn)
[15:25:01] <maret> both indexed properly
[15:25:29] <ilmari> when you say 64 characters, do you mean 64 hexadecimal digits (i.e. 32 bytes of actual data)?
[15:26:06] <maret> I mean strings like 2f5f4ac70f11bf838daef8f82142a1fc4183f7dad2f0d185aae48d4a466f346d
[15:26:17] *** Quits: mncheck (~mncheck@193.224.205.254) (Read error: Connection reset by peer)
[15:26:40] <Berge> They're always hex?
[15:26:51] <ilmari> it would be better to store those as bytea
[15:27:11] *** kvn_ is now known as kvn
[15:27:51] *** Quits: ekathva (~ekathva@93-90-58-246.welcomnet.fi) (Ping timeout: 245 seconds)
[15:28:58] <maret> yeah but again there is no reason why they need to be in this format, it just happens that thats how i go the data
[15:29:35] <maret> i just don't see a reason to keep it like that , when it takes more space and might be slower later on compared to simple bigserial
[15:30:04] <Berge> Why do you think that?
[15:30:20] <Berge> Slower for what?
[15:30:29] <kjetilho> Berge: 64 > 8 ;)
[15:30:34] <Berge> (=
[15:31:09] <maret> so my plan seem to be 1. Cancel update 2. Create an index  on hash 3. Update entities.group_id  4. drop hash , add index on group_id column
[15:31:46] <Berge> kjetilho: To be fair, bytea would be one byte larger on disk
[15:31:47] <maret> Berge had discussion here yesterday and in AFAIK in principle comparing bigint should be faster than strings, but I repeat my self here. No reason for me to  keep the string in table
[15:31:56] <Berge> It's one byte plus payload, iirc
[15:32:12] <ilmari> Berge: but it would be half the size of the current text representation
[15:32:25] <Berge> ilmari: Absolutely
[15:32:30] <maret> so I am only deciding how to update it the fastes
[15:32:41] <Berge> Why do you store them if you don't need them?
[15:32:50] <ilmari> maret: you don't need it for reference to any external entity (e.g. for subsequent updates of the data)?
[15:33:09] <maret> I don't want to store them , I am planning to drop it after update
[15:33:11] <maret> ilmari nope
[15:33:36] <Berge> Why are you storing it in the first place, then?
[15:34:04] <ilmari> note that dropping the column won't actually free up any space
[15:34:24] <maret> thanks will keep that in mind
[15:34:44] <ilmari> the space will only get reclaimed as rows get updated, and the new version gets written without the data
[15:35:48] <maret> btw so i need to create indexes for both columns in where clause right? (entitities.hash = groups.hash)
[15:36:13] *** Quits: jazzy2 (~jaziz@user/jaziz) (Ping timeout: 250 seconds)
[15:43:39] *** Joins: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c)
[15:44:11] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[15:49:30] <furrymcgee> edb team suggests hash partitioning when there is no obvious way of dividing data into logically similar groups  www.enterprisedb.com/blog/postgres-table-partitioning
[15:51:47] *** Joins: MrZeus (~MrZeus@81.92.206.10)
[15:58:46] *** Joins: c2main (~quassel@82.66.25.238)
[15:58:47] *** Quits: c2main (~quassel@82.66.25.238) (Changing host)
[15:58:47] *** Joins: c2main (~quassel@user/c2main)
[16:01:21] *** Joins: Shells (~michelle@203.206.128.220)
[16:01:41] <strk> in which case would you not want constraints to be deferrable ?
[16:02:26] *** Quits: Michelle (~michelle@203.206.128.220) (Ping timeout: 260 seconds)
[16:07:45] *** Quits: fordfrog_ (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[16:08:36] <ilmari> maret: since you're updating the entire entities table it's going to have to do a full sequential scan on that one anyway, so you probably only need one on groups for this case. create that one first, then EXPLAIN (without ANALYZE) the UPDATE query
[16:12:04] *** Quits: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net) (Ping timeout: 246 seconds)
[16:16:49] *** Joins: Guest48_ (~textual@2001:ee0:4081:6914:59d4:c39b:227b:2087)
[16:19:43] *** Quits: Guest48_ (~textual@2001:ee0:4081:6914:59d4:c39b:227b:2087) (Client Quit)
[16:23:19] *** Quits: dodobrain (~dodobrain@user/dodobrain) (Remote host closed the connection)
[16:23:46] *** Joins: dodobrain (~dodobrain@user/dodobrain)
[16:25:33] <nickb> strk: for example when your transactions operate data in such a way that the data is transiently inconsistent.
[16:25:56] <nickb> strk: I didn't read that "not" :S
[16:26:25] *** Joins: G_SabinoMullane (~G_SabinoM@pool-72-94-251-236.phlapa.fios.verizon.net)
[16:26:25] *** Quits: concrete-houses (~g@209.6.150.53) (Ping timeout: 246 seconds)
[16:27:21] <nickb> strk: the downside of having deferrable constraints is that the `COMMIT` command can suddenly become very expensive. If that is undesired one can restrict deferrable constraints
[16:27:54] <johto> DEFERRABLE doesn't mean DEFERRED
[16:27:56] <nickb> obviously some business logic specific restrictions
[16:28:04] <johto> you should only defer constraints you actually need to
[16:28:34] *** Joins: concrete-houses (~g@209.6.150.53)
[16:28:36] <nickb> yeah but maybe you want to forbid users to do that for whatever reason
[16:28:59] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 256 seconds)
[16:30:30] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[16:45:02] *** Quits: dodobrain (~dodobrain@user/dodobrain) (Ping timeout: 240 seconds)
[16:46:00] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Quit: elastic_dog)
[16:46:02] *** Quits: fandre1986 (~fandre198@78.10.85.96) (Quit: Connection closed)
[16:46:15] <maret> ilmari index already finished and exaplain returned one hash join , seq scan on entities as you said https://explain.depesz.com/s/ucdx
[16:47:01] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[16:54:05] <maret> although I would expect some index being used here?
[16:54:29] <ilmari> it seems to have decided to build a hash table of all 400 million groups instead
[16:55:04] <maret> yeah running Analyze on groups table, just to see if its change planner mind
[16:55:37] <ilmari> another thing that's worth doing is `set track_io_timing = on; explain (analyze, buffers, verbose) select * from entities join groups on (entities.hash = groups hash);`
[16:55:50] <ilmari> `groups.hash`, even
[16:58:59] *** Joins: AceSlash (~slash@2a01:e0a:432:c050:cd12:393c:3664:2a6e)
[17:03:14] <maret> for what? and are you saying that hash table might be slow here?
[17:03:55] <maret> afaik it uses seq scan on groups to load them to memory to create a hash join right and that might be slow
[17:04:17] *** Shells is now known as Michelle
[17:06:36] *** Quits: roger_rabbit (~roger_rab@2607:fcd0:aa80:1304::bf2d) (Ping timeout: 240 seconds)
[17:07:40] *** Joins: Guest48_ (~textual@2001:ee0:4081:6914:d947:7613:ea9e:b0dc)
[17:09:57] <maret> Not sure if I read this correctly but it means that index wont be used, Should I create an index for entities(hash) ?
[17:10:07] *** Quits: onu (~onufn@gibbs.uberspace.de) (Read error: Connection reset by peer)
[17:13:08] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) ()
[17:13:18] *** Joins: onu (~onufn@gibbs.uberspace.de)
[17:14:42] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[17:15:17] <ilmari> the hash join will be fast if there's enough memory to avoid spilling the hash table to disk
[17:15:41] <ilmari> which is what the `explain (analyze, â€¦) â€¦` will tell us
[17:15:49] <ilmari> what is your work_mem setting?
[17:16:00] <maret> 16MB
[17:16:10] *** Joins: luk1337_ (~luk1337@2a02:6ea0:dc05::a15d)
[17:16:28] *** Joins: Shells (~michelle@203.206.128.220)
[17:16:36] <maret> btw would it be stupid to turn of seqscan just for the update ?
[17:16:38] <ilmari> ouch, that is waaaay to low
[17:17:07] *** Quits: Guest48_ (~textual@2001:ee0:4081:6914:d947:7613:ea9e:b0dc) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[17:17:40] <maret> yeah so far worked nicely , I only increased it for some sorting operations
[17:17:53] *** Quits: Michelle (~michelle@203.206.128.220) (Ping timeout: 260 seconds)
[17:20:13] <maret> btw reading this response https://stackoverflow.com/questions/42549126/postgresql-how-to-speed-up-for-updating-huge-table100-million-rows seems like I should actually drop index increase work memory and hope for the best
[17:20:14] *** Quits: merzo (~Thunderbi@192.162.238.196) (Read error: Connection reset by peer)
[17:20:38] <michalz> hello. I've heard that pg14 has improved handling a big number of connections. I'm curious if that means that now is possible to avoid using pgbouncer? The max amount of connections is set to 10000 in pgbouncer.
[17:22:56] *** Joins: james_lavin (~jameslavi@ool-457981b2.dyn.optonline.net)
[17:25:06] <maret> so seems like I should rop index, increase work_mem to ? 4GB (16GB on the machine in total)
[17:25:35] <maret> + increase checkpoint_timeout and max_wal_size
[17:27:54] *** Joins: umbridge (~umbridge@212-51-134-33.fiber7.init7.net)
[17:28:42] *** Joins: Guest48_ (~textual@2001:ee0:4081:6914:21dc:9af0:7cc1:e4dc)
[17:29:08] <umbridge> Hi, I checked if earthdistance is installed as a function and I tried following query: select ll_to_earth(cast(46.54751000 as float8), cast(6.577080 as float8)); but that gives me: function ll_to_earth(double precision, double precision) does not exist. I tried googling for an answer but to no avail. Anyone maybe got a tip?
[17:31:35] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[17:32:33] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Remote host closed the connection)
[17:33:14] *** Joins: mattil (~mattil@helsinki.portalify.com)
[17:33:59] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[17:36:15] <depesz> umbridge: what does `\df ll_to_earth`  show?
[17:36:53] <depesz> umbridge: or, even: \dx
[17:36:55] <depesz> all in psql
[17:37:00] <umbridge> it works, I forgot to run: CREATE EXTENSION earthdistance CASCADE;. I didn't know that this was needed.
[17:37:09] <umbridge> thanks for your help.
[17:37:58] *** Quits: ees-mobile (~ees-mobil@pool-108-18-30-46.washdc.fios.verizon.net) (Ping timeout: 272 seconds)
[17:38:41] *** Quits: mattil (~mattil@helsinki.portalify.com) (Ping timeout: 256 seconds)
[17:39:59] *** Quits: Guest48_ (~textual@2001:ee0:4081:6914:21dc:9af0:7cc1:e4dc) (Quit: Textual IRC Client: www.textualapp.com)
[17:40:14] *** Joins: favadi (~favadi@2001:ee0:4081:6914:21dc:9af0:7cc1:e4dc)
[17:43:02] *** Joins: rewrit3 (~rewrit3@user/rewrit3)
[17:43:09] <wez> umbridge: Do you like cats?
[17:44:43] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[17:47:13] *** Joins: jlc (~jlc@cpe-107-15-173-212.nc.res.rr.com)
[17:48:25] <umbridge> ?
[17:48:47] <umbridge> hahaha, flew right past me
[17:49:21] <wez> :)
[17:49:31] <wez> All good, I am off!
[17:49:33] <Berge> I didn't get it!
[17:49:47] <Berge> I wondered if wez was trolling
[17:50:19] <kjetilho> what!  I can't find a cast/cats typo or anything?
[17:50:37] <Berge> Me neither!
[17:52:44] <capitol> maybe he was just wondering
[17:52:55] <Berge> Well, I like cats.
[17:53:26] <capitol> i don't, they make me sneeze
[17:53:43] <Berge> I'm also allergic to them, but I still love them.
[17:53:46] <Berge> It's not the cats' fault.
[17:53:56] *** Quits: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c) (Remote host closed the connection)
[17:53:57] <zelest> I'm allergic to cats as well, but I do own a big fat cat :D
[17:54:09] *** Shells is now known as Michelle
[17:54:15] <zelest> as long as I avoid burying my face in his belly, then all is good
[17:54:56] <umbridge> so, I svck at maths but why can't I find a copy&paste, sql-only solution for a radius search, e.g.: all dealerships in a radius of 30km of point X.
[17:55:09] <Berge> umbridge: Using postgis?
[17:55:18] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[17:55:28] <Berge> Do you have a column with a point (or other shape) for a dealship location?
[17:55:28] <umbridge> I don't have access to postgis on the managed server that I have to use
[17:55:40] <umbridge> I do have latitude and longitude for the dealership.
[17:55:45] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[17:56:03] <umbridge> I'm sure some smart brain could do sinus and cosinus stuff but not me haha
[17:56:18] <Berge> The smart brain would use postgis (-:
[17:56:33] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[17:56:36] <umbridge> I would as well if postgis would be available :D
[17:56:46] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[17:56:50] <Xgc> umbridge: That will with a sinus headache.
[17:56:53] <Berge> How are you storing dealership locations?
[17:58:00] <umbridge> following two columns: latitude, longitude as numeric(8,6)
[17:58:36] <Myon> create extension earthdistance;
[17:58:44] <Myon> (or better: postgis)
[17:58:57] <depesz> Berge: um,bridge from harry potter was a witch, and (i think) she loved cats.
[17:59:00] <umbridge> Myon I couldn't run create extension earthdistance.
[17:59:11] <umbridge> no permission
[17:59:17] <Berge> depesz: â€¦ah! I do know Umbridge from the books, but I had forgotten she likes cats
[17:59:26] <Myon> there's surely a whole wikipedia page for that formula
[18:00:45] <Xgc> umbridge: Here's the simple description.  You can convert this to SQL:  https://en.wikipedia.org/wiki/Haversine_formula
[18:01:28] <umbridge> exactly my mind of humor
[18:01:52] <Berge> umbridge doesn't want the distance between two points, though
[18:02:01] <umbridge> I see formulas, my brain blocks
[18:02:12] <Berge> But to figure out if a point falls within a circle (as projected in 2D, but I'm sure a polygon on a sphere will do)
[18:02:29] *** Joins: sympatico (~textual@ip184-181-47-47.no.no.cox.net)
[18:02:50] <umbridge> exactly.
[18:03:08] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[18:03:09] <Berge> The correct answer is postgis.
[18:03:34] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[18:04:04] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Quit: varioust)
[18:04:21] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[18:04:30] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[18:04:36] <ilmari> umbridge: complain to your hosted postgres provider's support contact
[18:04:47] <umbridge> will do that.
[18:04:51] <Berge> +1
[18:04:57] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[18:05:03] <Berge> I thought most managed postgres providers supported postgis
[18:05:05] <ilmari> reasonable providers will allow a set of blessed extensions
[18:05:27] <ilmari> postgis being one of the most prominent ones I would expect that to be available
[18:05:58] *** Joins: fruity_tomato (~fruity_to@user/fruity-tomato/x-3541336)
[18:06:05] *** Joins: stark__ (~stark@192.222.248.88)
[18:08:48] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[18:09:15] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[18:09:38] <maret> ilmari sorry to interupt, what do you think about ideas from the thread  https://stackoverflow.com/questions/42549126/postgresql-how-to-speed-up-for-updating-huge-table100-million-rows . TLDR index actually can cause problem for update, so drop it increase work memory, max_wal_size and checkpoint_timeout
[18:10:01] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[18:10:08] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[18:11:23] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Remote host closed the connection)
[18:15:12] <strk> maybe I should not define constraints at all
[18:18:05] <strk> those I define are only *partially* preventing topology corruption
[18:18:28] <strk> why slowing things down at all, at that point
[18:20:39] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[18:22:58] *** Quits: umbridge (~umbridge@212-51-134-33.fiber7.init7.net) (Quit: Connection closed)
[18:22:59] *** Quits: mjf_ (~mjf@2001:1528:1:fffd:a02e:21d3:b3d4:86b8) (Read error: Connection reset by peer)
[18:23:09] *** Joins: mjf_ (~mjf@2001:1528:1:fffd:a02e:21d3:b3d4:86b8)
[18:23:29] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Remote host closed the connection)
[18:23:55] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[18:23:55] *** Joins: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi)
[18:24:05] *** Joins: mamad (~mam@5.124.223.190)
[18:27:34] *** Quits: mjf_ (~mjf@2001:1528:1:fffd:a02e:21d3:b3d4:86b8) (Ping timeout: 260 seconds)
[18:28:30] *** Quits: mattil (~mattil@dz-p5r3b5g750txnzby-4.rev.dnainternet.fi) (Ping timeout: 260 seconds)
[18:28:39] *** Joins: mjf_ (~mjf@cst-prg-87-91.cust.vodafone.cz)
[18:31:04] <strk> alright it looks like deferred foreign key constraints are not being run for every *version* of rows
[18:31:06] <strk> that's good
[18:31:40] <strk> if those were NOT deferred, they would then run much more often
[18:31:55] <strk> in a scenario in which you have to make a lot of edits, in a single transaction
[18:32:02] <Myon> depesz: the focal-llvm-9 thing is fixed, thanks for spotting!
[18:32:03] <strk> say, 3 updates
[18:32:20] <strk> (on the same row): non-deferred constraints would run 3 times
[18:32:25] <strk> deferred ones would run only once
[18:32:26] *** Quits: mamad (~mam@5.124.223.190) (Ping timeout: 272 seconds)
[18:34:49] <strk> http://strk.kbt.io/tmp/test.sql
[18:35:24] <strk> in the third block ^ only a single time the foreign key will be checked, instead of two times
[18:38:09] *** Joins: mamad (~mam@5.124.223.190)
[18:39:42] *** Quits: fruity_tomato (~fruity_to@user/fruity-tomato/x-3541336) (Ping timeout: 250 seconds)
[18:42:39] *** Quits: impermanence (~impermane@c-75-73-193-204.hsd1.mn.comcast.net) (Quit: Connection closed)
[18:48:20] *** Joins: mrgz (~mrgz@201-42-0-191.dsl.telesp.net.br)
[18:50:34] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) ()
[18:51:51] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[19:02:10] *** Joins: Likorn (~Likorn@c114-150.icpnet.pl)
[19:02:12] *** Quits: sreve_ (~quassel@p4ff44f3f.dip0.t-ipconnect.de) (Ping timeout: 272 seconds)
[19:04:04] *** Joins: sreve (~quassel@p54a71c9d.dip0.t-ipconnect.de)
[19:09:48] *** Joins: Rashad (~textual@2a01:9700:1290:7400:1dbd:dda2:a86f:d8e9)
[19:12:57] *** Joins: mattil (~mattil@87-92-20-81.bb.dnainternet.fi)
[19:13:35] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[19:14:58] *** Quits: Rashad (~textual@2a01:9700:1290:7400:1dbd:dda2:a86f:d8e9) (Read error: Connection reset by peer)
[19:16:12] *** Joins: tozhu (~tozhu@117.139.163.129)
[19:16:38] *** Joins: Rashad (~textual@2a01:9700:1290:7400:1dbd:dda2:a86f:d8e9)
[19:16:55] *** Quits: dsrt^ (~dsrt@96-91-136-49-static.hfc.comcastbusiness.net) (Remote host closed the connection)
[19:17:02] <depesz> Myon: sweet. thanks.
[19:17:31] *** Quits: mattil (~mattil@87-92-20-81.bb.dnainternet.fi) (Ping timeout: 256 seconds)
[19:17:51] <azeem> Myon: to be fair, I had to hand-edit that query due to collprovider myself in the past as well, but didn't do anything about it
[19:19:06] <Myon> nod
[19:19:44] <Myon> the sad part is that the whole collversion tracking stuff will proably never be needed again
[19:19:49] <Myon> at least not at that scale
[19:20:09] *** Joins: otisolsen70 (~otisolsen@xd4ed80b5.cust.hiper.dk)
[19:20:32] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[19:22:39] *** Joins: gastus (~gastus@mawercer.de)
[19:26:06] *** Quits: Likorn (~Likorn@c114-150.icpnet.pl) (Quit: WeeChat 3.4)
[19:28:00] *** Joins: robin44 (~robin44@131.106.25.151)
[19:28:33] <robin44> hello all! i am here seeking the intuition of experts! i am wondering which of these is better:
[19:29:06] <robin44> i want to have one of my api endpoints return a list of conversations with their most recent messages, and i have two ways of doing it:
[19:29:31] <robin44> a) query the list of conversations and then also jsonb_agg the 50 most recent messages for each (such that it is returned in a single database query)
[19:29:51] <robin44> b) do two separate database queries. one for the list of conversations, and one for the list of 50 most recent messages for each (using a lateral join)
[19:30:36] <robin44> here's why it's a predicament: using jsonb_agg adds significantly to the query processing time. this can be solved by doing two separate queries. but _then_ you have the overhead of doing two separate queries
[19:31:25] <robin44> so i'm not sure which is "better". because with `a)` you strain the database, but with `b)` it likely results in a longer api response time because it has to do query 1, wait for the results, then do query 2, and _then_ return both
[19:31:53] <robin44> ideally there'd be a way to return both queries in a single database call, such that only a single round trip is needed, but i'm not sure if that's possible, because they both return completely different result sets
[19:31:55] <robin44> any advice?
[19:32:58] *** Joins: maciek__ (~maciek@2600:1700:a412:1c00:9dc9:ab61:a07a:fc38)
[19:34:30] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Ping timeout: 272 seconds)
[19:37:15] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[19:38:41] <crunchy_david> if you're doing it right, a) isn't any more strain on the db than b), and you get the data you need in a single call. should be possible to do what you want w/a)
[19:41:53] <robin44> crunchy_david are you sure? i'm doing `explain analyze` and it looks like `jsonb_agg` has overhead compared to just returning the list of rows normally
[19:43:55] *** Quits: kakashiA1 (~kakashi@ip-037-201-198-071.um10.pools.vodafone-ip.de) (Ping timeout: 256 seconds)
[19:44:00] *** Quits: tnewman (~tnewman@118.150.44.48) (Quit: Ping timeout (120 seconds))
[19:44:24] *** Joins: tnewman (~tnewman@118.150.44.48)
[19:44:27] *** Quits: Ergo^ (~ergo@91.238.59.144) (Remote host closed the connection)
[19:44:38] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Ping timeout: 272 seconds)
[19:47:01] *** Joins: mizi_ (~mizi@user/mizi)
[19:48:53] *** Joins: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net)
[19:52:19] <robin44> i have an idea .. one moment
[19:53:36] <robin44> yeah it seems to have an overhead? when i do explain analyze for `select * from usp_get_messages($1)` it takes 0.5 milliseconds and when i do explain analyze for `select jsonb_agg(messages) from usp_get_messages($1) messages` it takes 1.5 milliseconds
[19:54:14] <robin44> interestingly json_agg as opposed to jsonb_agg seems to be a bit faster..
[19:54:42] *** Quits: tnewman (~tnewman@118.150.44.48) (Quit: Ping timeout (120 seconds))
[19:55:05] *** Joins: tnewman (~tnewman@118.150.44.48)
[19:56:11] *** Joins: gareppa (~gareppa@user/gareppa)
[19:56:18] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[19:56:44] *** Quits: gareppa (~gareppa@user/gareppa) (Remote host closed the connection)
[19:57:48] <ilmari> robin44: is usp_get_messages() a function that returns the most recent messags from conversation? have you tried an inline lateral subquery instead?
[19:58:06] *** Quits: csm3105 (~csm3105@143.red-83-48-84.staticip.rima-tde.net) (Quit: Leaving)
[19:58:34] <robin44> ilmari yes it is and yes i do believe a lateral subquery is probably faster, but isn't it also the case that my point above seems to still stand somewhat? in that it appears that jsonb_agg has an overhead as opposed to just returning rows
[20:01:54] <ilmari> well, yes. doing things takes time
[20:02:05] <ilmari> but is it really a bottleneck?
[20:02:13] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 240 seconds)
[20:04:08] <robin44> yeah it is my most expensive query by far (takes like 50 milliseconds) so looking to get it down
[20:05:54] *** Joins: digimer (~digimer@198.96.117.110)
[20:06:37] <robin44> also ilmari not to keep drilling this same point but i am still confused so i'll reiterate regardless: does jsonb_agg have an overhead or no? because crunchy seemed to somewhat imply that it doesn't, but my explain analyze seems to indicate that it does? so i'm not sure what the truth is
[20:07:16] <robin44> if it does indeed have an overhead, would two separate queries be better, latency be damned? or in the cost benefit analysis is it better to have a tiny bit of overhead in a query as opposed to an overhead of having to run two queries? i'm not sure
[20:07:49] <digimer> Hi all, I've got an interesting issue I was hoping for guidance on... I have two separate databases on two hosts that our software writes to for redundancy. Periodically, I want to count the number of records in a given table on each DB to ensure they both have the same data. The trick is, while I do these counts, other clients could write data causing one count to differ from the other, simple because a write happened after I couted on table and befor
[20:08:07] <ilmari> json_agg() does work. doing work takes time. just returning the rows without aggregation is less work.
[20:08:34] <ilmari> to measure the actual overhead, try both and compare, with realistic data amounts and system load
[20:08:36] <digimer> So I plan to try using locks, but I was hoping to get some clarity on how these work. If I set a table lock, and another client tries to write, does it simply fail, or does the write wait for the lock to be released?
[20:09:04] <robin44> but i did exactly that? ah oh well i'll just play with it some more. i suppose this sort of question is too nebulous for a proper answer. my apologies
[20:09:14] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[20:09:24] <ilmari> robin44: select c.*, json_agg(m.*) from conversations c, lateral (select * from messages where messages.conversation_id = c.id order by received desc limit 50) m where â€¦ ;
[20:09:46] <robin44> okay one moment i'll try that
[20:10:28] <ilmari> one advantage of fetching the messages separately is that you could do it lazily and concurrently, for lower perceived latency (depending on your application UI and architecture)
[20:11:17] *** Joins: magla (~gelignite@d5362fd7.access.ecotel.net)
[20:11:27] <robin44> how could i do it concurrently? i'm using async await in rust if you're familiar
[20:11:28] <ilmari> but that would put more overall load on the server, because of per-request overhead
[20:11:46] <robin44> oh i was thinking about just doing it in a single api request regardless
[20:12:00] <robin44> and just returning { convos, messages } from the api for it to be assembled manually on the client
[20:12:29] *** Joins: econo (uid147250@user/econo)
[20:13:20] <gastus> When using knex .wher('a','=', 10) the 10 turns out to be a string when logging SQL. Is this knex or postgresql issue?
[20:14:37] *** Quits: held (~heldchen@user/held) (Ping timeout: 260 seconds)
[20:15:28] <ilmari> digimer: other writes will wait while the table is locked. but it won't solve anything, since just like a client could insert something between the two counts, it could insert something between the time you lock the first table and the second
[20:15:41] <johto> gastus; what do you mean? "turns out to be a string"?
[20:16:09] <ilmari> gastus: do you mean it generates SQL like "where a = '10'"?
[20:16:18] <gastus> I try to insert JSON data. I have epoch (number) however when accessing it with ->> it looks like its a string then.
[20:16:33] <gastus> Yes, it generates a = $1  and $1 is logged as '10'
[20:16:34] <ilmari> what does that have to do with a where clause?
[20:16:47] <gastus> .where is just the way I used to pass data to knex.
[20:16:48] <ilmari> ->> always returns strings
[20:17:02] <gastus> Is there ->> which returns the values the way they are ?
[20:17:11] <gastus> Cause > behaves differently on string/numbers
[20:17:23] <ilmari> -> returns it as jsonb, with the appropriate type inside
[20:17:23] <johto> gastus; what's the full log message?
[20:18:29] <gastus> https://dpaste.com/BFYE6MF94
[20:19:16] <ilmari> and what is the problem?
[20:19:29] *** Joins: odnes_ (~odnes@5-203-245-187.pat.nym.cosmote.net)
[20:19:56] *** Quits: odnes (~odnes@5-203-245-187.pat.nym.cosmote.net) (Read error: Connection reset by peer)
[20:20:24] <gastus> The problem is if the JSON contains numbers I'd like ->> to return a number.
[20:20:42] <gastus> Cause I want to use epoche between number1 and number2 and the like without having string sorting.
[20:20:51] <ilmari> cast it
[20:20:56] <gastus> SO i can cast with ::float ::text or alike but its unexpected.
[20:21:09] *** Joins: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec)
[20:21:39] <gastus> Even if I cass it I end up with '234234'::float = 'string here'  where 'string here' should have been a number and I did pass a number to knex not a string (typeof JS operator shows number).
[20:22:09] *** Joins: elastic_1 (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[20:22:13] *** Quits: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec) (Client Quit)
[20:22:39] *** Quits: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Ping timeout: 250 seconds)
[20:22:42] *** Joins: TomyWork (~TomyLobo@p200300e80f158200e43262fee561722d.dip0.t-ipconnect.de)
[20:22:56] <ilmari> placeholder values are always transmitted as text, but postgres knows to interpret it as a float based on the type on the left-hand side of th e=
[20:23:02] <ilmari> *the =
[20:23:06] <digimer> ilmari: aye, it's still racy... Any suggestions on how to freeze two separate DBs at the same time?
[20:23:18] <digimer> locks would be less racy, but not perfect =/
[20:23:43] *** Joins: kakashiA1 (~kakashi@37.84.2.12)
[20:23:45] <gastus> I could be using knex.raw instead of placeholders to pass the number without ''
[20:23:47] <digimer> I suppose I could set a flag and wait for all clients to awknowledge the flag, but that seems messy as well
[20:23:51] <TomyWork> is there a special kind of index that's especially suited to having only a small number of possible values, say 20 different values over a million rows?
[20:23:55] *** Quits: elastic_1 (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb) (Client Quit)
[20:24:04] <gastus> But it still sucks that ->> returns text always.
[20:24:18] *** Joins: elastic_dog (~elastic_d@2a01:118f:822:9c00:f583:aa51:9ad4:d4fb)
[20:24:34] *** Joins: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec)
[20:24:42] <gastus> Is tehre a ->> which returns original type ?
[20:24:43] *** Quits: favadi (~favadi@2001:ee0:4081:6914:21dc:9af0:7cc1:e4dc) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[20:24:59] <johto> there's no way to have an operator which returns different types
[20:25:10] <johto> SQL doesn't work that way
[20:25:21] <ilmari> gastus: no. use placeholders. the '' in the log is just how it's displayed. it's not a problem
[20:25:43] *** Joins: Likorn (~Likorn@c114-150.icpnet.pl)
[20:25:57] <ilmari> TomyWork: in recent postgres versions btree indexes deduplicate values
[20:28:23] <TomyWork> ilmari, I'm skimming this: https://mydbops.wordpress.com/2020/09/25/deduplication-of-b-tree-indexes-in-postgresql-13/ It seems to talk about some different kind of deduplication that's introduced by btree+
[20:29:24] <TomyWork> or maybe not? idk
[20:29:29] <ilmari> https://www.postgresql.org/docs/13/btree-implementation.html#BTREE-DEDUPLICATION
[20:29:34] <ilmari> that is what I was referring to
[20:30:15] <ilmari> it greatly reduces the storage size and query latency when there are many rows with the same values for the indexedcolumns
[20:32:07] <TomyWork> hmm, this doesn't work on varchar in case of a nondeterministic collation
[20:33:01] <TomyWork> those dont seem to be the default, however, so it's probably fine :)
[20:34:29] <ilmari> correct, those have to be created explicitly, e.g. case- or accent-insensitive ones
[20:35:07] <gastus> https://mawercer.de/tmp/tmp/x.txt That's my problem that I'd like to check whether the item is there by amoutn, datetime epoche.
[20:35:13] <gastus> But the index doesn't seem to work.
[20:35:19] <gastus> I tried with and without ::float
[20:35:28] <TomyWork> ilmari, accent-insensitive, ugh, an american must have thought of that
[20:35:48] *** Quits: enoq (~enoq@2a05:1141:1f5:5600:b9c9:721a:599:bfe7) (Quit: enoq)
[20:36:02] <gastus> I'd expect a simple select with index to be like 1ms not 150 to 180ms
[20:36:13] <TomyWork> or someone else with no accents in any language they speak
[20:36:43] *** Joins: tnewman4 (~tnewman@118.150.44.48)
[20:37:32] *** Joins: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c)
[20:37:45] *** Joins: mattil (~mattil@87-92-20-81.bb.dnainternet.fi)
[20:38:13] *** Quits: tnewman (~tnewman@118.150.44.48) (Ping timeout: 240 seconds)
[20:38:13] *** tnewman4 is now known as tnewman
[20:38:26] *** Quits: palasso (~palasso@user/palasso) (Remote host closed the connection)
[20:39:13] <Zr40> or someone who thought of the practicality
[20:39:20] *** Quits: gleu (~guillaume@2a01cb0c0e54b8007e39e75cb4390e1c.ipv6.abo.wanadoo.fr) (Quit: Leaving.)
[20:39:23] <Zr40> plenty of systems or keyboards that simply can't produce the correct characters
[20:39:39] *** Joins: kitsunenokenja (~kitsunech@68.91.220.96)
[20:40:06] <Zr40> it's there if you want to use it. It's not required.
[20:40:49] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 256 seconds)
[20:41:33] <gastus> Nobody any idea about my x.txt performance problem why the index isn't used even when casting everyting to ::float ?
[20:41:55] <ilmari> gastus: the explain you did doesn't use the expression you created the index on
[20:42:26] <TomyWork> i guess i'm just pissed off at software that forces this on you, like confluence
[20:42:29] <ilmari> also, if you're only using using equality conditions, a gin index and the @> operator is more flexible
[20:42:38] *** Quits: mattil (~mattil@87-92-20-81.bb.dnainternet.fi) (Ping timeout: 260 seconds)
[20:43:03] <ilmari> ??jsonb index
[20:43:04] <pg_docbot> Nothing found
[20:43:05] <ilmari> ??jsonb indexing
[20:43:05] <pg_docbot> Nothing found
[20:43:07] <ilmari> ??json indexing
[20:43:07] <pg_docbot> Nothing found
[20:43:08] <ilmari> ??jsonb
[20:43:09] <pg_docbot> https://www.postgresql.org/docs/current/static/datatype-json.html :: https://www.postgresql.org/docs/current/static/functions-json.html
[20:43:13] <ilmari> ??json
[20:43:14] <pg_docbot> https://www.postgresql.org/docs/current/static/datatype-json.html :: https://www.postgresql.org/docs/current/static/functions-json.html
[20:43:14] <pg_docbot> https://schinckel.net/2017/07/01/tree-data-as-a-nested-list-redux/
[20:43:16] <ilmari> bah
[20:44:03] <ilmari> gastus: see https://www.postgresql.org/docs/current/datatype-json.html#JSON-CONTAINMENT and https://www.postgresql.org/docs/current/datatype-json.html#JSON-INDEXING
[20:48:12] <gastus> I got it.
[20:48:15] <gastus> I had 2 issues.
[20:48:22] <gastus> Problem was me.
[20:55:23] *** Quits: mjf_ (~mjf@cst-prg-87-91.cust.vodafone.cz) (Ping timeout: 260 seconds)
[20:55:41] *** Joins: mjf_ (~mjf@cst-prg-87-91.cust.vodafone.cz)
[21:00:20] <marahin> <Berge> Consider using a pooler, such as pgbouncer
[21:00:46] <marahin> Berge: just deployed pgbouncer 15 minutes ago, with some basic settings tinkering and adjusting the connection settings, it seems to have resolved the issue. Thank you again!
[21:01:05] *** Quits: randir (~randir@93.159.239.42) (Remote host closed the connection)
[21:01:16] *** Quits: eroux (~eroux@102-65-72-61.ftth.web.africa) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[21:04:12] <gastus> Ok index isused, still only like 5 items per second An item is BEGIN .. select test if its there . insert .. END
[21:05:02] *** Joins: eroux (~eroux@102-65-72-61.ftth.web.africa)
[21:05:16] *** Joins: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net)
[21:06:11] *** Joins: held (~heldchen@user/held)
[21:06:38] <ilmari> gastus: what if someone else does the same at the same thing? if you create a unique index you can do INSERT ... ON CONFLICT ... to handle that more efficiently and in a race-free fasion
[21:06:57] <ilmari> ??on conflict
[21:06:57] <pg_docbot> https://www.postgresql.org/docs/current/static/sql-insert.html#SQL-ON-CONFLICT
[21:07:03] *** Quits: mamad (~mam@5.124.223.190) (Quit: Konversation terminated!)
[21:09:45] *** Quits: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[21:13:15] <gastus> That's what I am doing.
[21:15:47] <gastus> Only doing select 10 its fast.
[21:22:47] *** Joins: Xof (~Xof@157-131-136-66.dedicated.static.sonic.net)
[21:23:20] *** Quits: tozhu (~tozhu@117.139.163.129) (Quit: tozhu)
[21:23:46] *** Joins: tozhu (~tozhu@117.139.163.129)
[21:23:53] *** Quits: tozhu (~tozhu@117.139.163.129) (Client Quit)
[21:24:09] *** Parts: digimer (~digimer@198.96.117.110) ()
[21:27:50] *** Quits: magla (~gelignite@d5362fd7.access.ecotel.net) (Quit: Stay safe!)
[21:31:15] *** Joins: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec)
[21:31:16] *** Quits: MrZeus (~MrZeus@81.92.206.10) (Ping timeout: 246 seconds)
[21:32:10] *** Quits: mexen (uid495612@user/mexen) (Quit: Connection closed for inactivity)
[21:33:57] *** Quits: held (~heldchen@user/held) (Ping timeout: 260 seconds)
[21:35:47] *** Joins: karlpinc (~user@173-161-46-9-Illinois.hfc.comcastbusiness.net)
[21:37:54] *** Joins: john_johnk (~Thunderbi@102.178.207.77.rev.sfr.net)
[21:39:19] *** Quits: gslin (~gslin@114-34-121-114.hinet-ip.hinet.net) (Quit: WeeChat 2.8)
[21:40:39] *** Quits: psoo (~psoo@dslb-002-202-190-148.002.202.pools.vodafone-ip.de) (Ping timeout: 250 seconds)
[21:43:29] *** Joins: gslin (~gslin@114-34-121-114.hinet-ip.hinet.net)
[21:45:41] *** Joins: held (~heldchen@user/held)
[21:50:50] *** Joins: raptelan (~raptelan@208.127.242.46)
[21:51:09] *** Quits: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[21:54:31] *** Joins: randir (~randir@95-31-138-202.broadband.corbina.ru)
[22:01:28] *** Joins: meialuadecompass (uid505943@id-505943.ilkley.irccloud.com)
[22:02:45] *** Quits: g2anj (~v@58.228.230.4) (Quit: .)
[22:02:54] *** Joins: funhouse (~funhouse@user/funhouse)
[22:04:22] *** Quits: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c) (Remote host closed the connection)
[22:04:30] *** Quits: odnes_ (~odnes@5-203-245-187.pat.nym.cosmote.net) (Remote host closed the connection)
[22:04:40] *** Quits: pedja (~pedja@user/deus-ex/x-7934090) (Quit: Leaving)
[22:05:37] *** Joins: odnes_ (~odnes@5-203-245-187.pat.nym.cosmote.net)
[22:05:55] *** Quits: odnes_ (~odnes@5-203-245-187.pat.nym.cosmote.net) (Remote host closed the connection)
[22:06:08] *** Joins: MrZeus (~MrZeus@194.37.96.151)
[22:12:26] *** Quits: antis (~quassel@2001:9e8:4fdb:f800:3147:6b73:e41e:f2ff) (Quit: http://quassel-irc.org - Chat comfortably. Anywhere.)
[22:13:26] <raptelan> Hi guys, I haven't used row-level security policies before so not familiar with how they work.  I am working with a database that has one defined for a table, and it is causing pg_dump to fail with ERROR:  query would be affected by row-level security policy for table "client".
[22:13:53] <raptelan> I can copy/paste the COPY command that pg_dump is trying, logged in to psql as the same user as I was running pg_dump as, and it works without issue though.
[22:15:35] *** Quits: varioust (~varioust@gateway/tor-sasl/varioust) (Ping timeout: 240 seconds)
[22:17:29] <ilmari> raptelan: the --enable-row-security option might be relevant: https://www.postgresql.org/docs/current/app-pgdump.html
[22:17:35] *** Quits: maret (~maret@nat-88-212-37-89.antik.sk) (Read error: Connection reset by peer)
[22:17:58] *** Joins: varioust (~varioust@gateway/tor-sasl/varioust)
[22:18:24] *** Joins: maret (~maret@nat-88-212-37-89.antik.sk)
[22:18:36] *** Joins: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec)
[22:19:38] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Remote host closed the connection)
[22:20:08] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[22:20:54] *** Quits: EvanCarroll (~ecarroll@4.78.9.77) (Ping timeout: 260 seconds)
[22:22:37] *** Joins: EvanCarroll (~ecarroll@172.56.15.131)
[22:28:12] *** Quits: phenom (~primus@user/phenom) (Ping timeout: 240 seconds)
[22:29:01] *** Quits: Likorn (~Likorn@c114-150.icpnet.pl) (Quit: WeeChat 3.4)
[22:30:01] *** Quits: ns12 (~ns12@user/ns12) (Quit: bye)
[22:31:09] *** Joins: ns12 (~ns12@user/ns12)
[22:31:34] *** Joins: Likorn (~Likorn@c114-150.icpnet.pl)
[22:31:40] <raptelan> ilmari: Well, it sounds like that allows it to dump only the rows it has access to.  It *should* have access to all rows, and I want all to be included in the dump.
[22:32:06] <raptelan> There are actually zero rows in my test database as it's just a restore of a schema-only dump, but I'm still getting the error.
[22:32:15] *** Joins: pedja (~pedja@user/deus-ex/x-7934090)
[22:32:56] <raptelan> I did add a policy like this already, but it didn't make any difference:  create policy backup on client for select to backup_user;
[22:33:07] <ilmari> is it the dump or the restore that errors?
[22:33:28] <raptelan> When I try to run pg_dump against my restored schema-only db.
[22:33:58] <raptelan> Very strange that it doesn't error when I run the same copy command in psql too.
[22:34:04] <ilmari> does the user you're dumping as have the bypassrls option?
[22:34:15] <raptelan> Nope.
[22:34:33] <raptelan> I can grant that - does it inherit?
[22:36:45] <ilmari> not sure
[22:37:59] <raptelan> https://dpaste.com/24JZVPT9N
[22:38:51] <raptelan> hmm, pg_dump works when I set bypassrls on the user directly, but it doesn't inherit from a group role.
[22:40:48] *** Joins: mowcat (~mowcat@2a00:23c5:d190:1901:f22f:74ff:fe77:1e1c)
[22:43:55] *** Quits: grumper (~grumper@ip-178-200-140-153.um45.pools.vodafone-ip.de) (Quit: Client closed)
[22:45:13] *** Joins: phenom (~primus@user/phenom)
[22:48:15] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[22:50:20] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[22:50:47] *** Joins: magla (~gelignite@d5362fd7.access.ecotel.net)
[22:51:43] *** Joins: fordfrog (~fordfrog@gentoo/developer/fordfrog)
[22:52:35] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Remote host closed the connection)
[22:54:37] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Ping timeout: 240 seconds)
[22:54:37] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[22:54:51] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Ping timeout: 260 seconds)
[22:54:56] *** Quits: ovnicraft (~ovnicraft@corp-179-49-44-28.uio.puntonet.ec) (Quit: My MacBook has gone to sleep. ZZZzzzâ€¦)
[22:57:39] *** Quits: gp5st_ (~gp5st@pool-72-77-44-213.pitbpa.fios.verizon.net) (Ping timeout: 260 seconds)
[22:57:58] *** Quits: sakasama (~sakasama@user/sakasama) (Ping timeout: 260 seconds)
[22:58:41] *** Quits: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net) (Ping timeout: 245 seconds)
[22:58:43] *** Joins: sakasama (~sakasama@user/sakasama)
[22:59:07] *** Joins: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a)
[23:00:22] *** Quits: riceandbeans (~zach@user/riceandbeans) (Quit: rebooting)
[23:02:03] *** Quits: john_johnk (~Thunderbi@102.178.207.77.rev.sfr.net) (Ping timeout: 260 seconds)
[23:02:46] *** Quits: Rashad (~textual@2a01:9700:1290:7400:1dbd:dda2:a86f:d8e9) (Quit: My MacBook Air has gone to sleep. ZZZzzzâ€¦)
[23:03:40] *** Joins: riceandbeans (~zach@user/riceandbeans)
[23:03:41] *** Joins: john_johnk (~Thunderbi@102.178.207.77.rev.sfr.net)
[23:03:51] *** Quits: DevAntoine (~DevAntoin@2a01:e34:ec18:50c0:6028:512c:43b4:598a) (Ping timeout: 250 seconds)
[23:09:36] *** Joins: mattil (~mattil@87-92-20-81.bb.dnainternet.fi)
[23:10:16] *** Joins: mattil_ (~mattil@helsinki.portalify.com)
[23:13:49] *** Quits: mattil (~mattil@87-92-20-81.bb.dnainternet.fi) (Ping timeout: 246 seconds)
[23:15:12] *** Quits: mattil_ (~mattil@helsinki.portalify.com) (Quit: Leaving...)
[23:20:38] *** Joins: digimer (~digimer@198.96.117.110)
[23:20:45] *** Quits: fordfrog (~fordfrog@gentoo/developer/fordfrog) (Quit: Leaving)
[23:21:52] *** Joins: ksynwa (~kartik@2401:4900:1f25:3de5:4412:99f6:abbc:3b7b)
[23:22:26] <ksynwa> Facing a very weird problem where I cannot clear up a table: https://dpaste.org/VJEC/raw
[23:22:35] <ksynwa> It's a simple table with no foreign constraints too.
[23:22:41] <ksynwa> Any idea what I am doing wrong?
[23:23:48] <peerce> \d comment
[23:25:10] <ksynwa> peerce: Output = https://dpaste.org/HTWe/raw
[23:25:32] <peerce> could your delete trigger be blocking the delete ?
[23:25:33] <digimer> I'm reading on locks, and maybe I'm being dense, but I'm hoping for some help clarifying... I want to make a table read-only temporarily, and have any INSERT/UPDATE hold until the lock is replaced. I'm reading this - https://www.postgresql.org/docs/10/explicit-locking.html
[23:25:47] <ksynwa> Yeah probably something is up with that. Will have to check.
[23:25:50] <peerce> Triggers:
[23:25:51] <peerce>     comment_event_delete BEFORE DELETE ON comment FOR EACH ROW EXECUTE FUNCTION notify_event('comment', 'id')
[23:25:52] <ksynwa> Thanks man.
[23:26:45] <peerce> i'm not a fan of triggers for exactly this sort of thing
[23:28:16] <robin44> does anyone have any idea why my lateral join isn't sorting properly? i'm doing a long query that includes a `LEFT JOIN LATERAL (SELECT * FROM x ORDER BY x.id DESC LIMIT 50)` and for whatever reason it seems like it's not ordering them properly
[23:28:51] <johto> the output isn't ordered based on that ORDER BY
[23:28:56] <johto> (necessarily, anyway)
[23:29:10] <robin44> any idea why? and is there a way to fix it?
[23:29:23] <johto> add an ORDER BY into the outer query
[23:29:41] <robin44> oh wait a second i think i see what you're saying
[23:29:50] <robin44> (maybe)
[23:30:05] <johto> SELECT * FROM .. LEFT JOIN LATERAL (..) ss ORDER BY <here>;
[23:30:06] <robin44> you're saying that it will return the proper data (the most 50 recent items), but those 50 items aren't ordered?
[23:30:16] <johto> correct
[23:30:26] <robin44> okay, then it's fine. i'll just order on the client (browser)
[23:30:33] <robin44> just wanted to make sure i wasn't missing data
[23:31:16] *** Joins: ovnicraft (~ovnicraft@ftth-179-49-44-28.cue.celerity.ec)
[23:32:43] <peerce> just add an order by to the outer query, pg already has the data in an optimal structure for efficiently sorting
[23:33:16] *** Joins: DevAntoine (~DevAntoin@78.193.133.12)
[23:34:17] <robin44> well i was going to but i'm trying to optimize performance
[23:34:23] <robin44> so i'm moving filtering and ordering to the client
[23:34:34] <robin44> got my query down from 6 milliseconds to 1 millisecond (based on explain analyzes)
[23:36:57] *** Quits: darutoko (~darutoko@5.136.93.106) (Quit: Leaving)
[23:36:59] <robin44> huh, i'm surprised finding the length of an array is so expensive in postgres
[23:37:22] *** Joins: rpkilby (~rpkilby@c-24-20-208-106.hsd1.or.comcast.net)
[23:37:51] *** Quits: DevAntoine (~DevAntoin@78.193.133.12) (Ping timeout: 245 seconds)
[23:37:54] *** Quits: zer0def (~zer0def@user/zer0def) (Ping timeout: 252 seconds)
[23:38:11] <robin44> all i did was change my query from `SELECT * FROM ...` to `WITH x AS (SELECT * FROM ..) SELECT *, (CASE WHEN jsonb_array_length(messages) = 50 THEN false ELSE true END) finished FROM x` and the runtime went from 1.2 milliseconds to 3.6 milliseconds
[23:38:40] <robin44> if i cut off that last part (and keep the CTE), it runs in 1.2 ms
[23:38:58] <robin44> so it's not the CTE that's doing it, it's simply the column that checks the array length
[23:39:26] <robin44> oh well i'll just do that on the client too
[23:39:32] <robin44> no big deal
[23:40:40] *** Joins: Auron (~Auron956@user/auron)
[23:43:51] <peerce> milliseconds suggest the query is dealing with a trivial amount of data.
[23:45:08] <peerce> what about  SELECT *, (CASE WHEN jsonb_array_length(messages) = 50 THEN false ELSE true END) finished FROM ...  ?
[23:45:46] <peerce> parsing json does take some time.
[23:46:01] <peerce> that doesn't even need to be a case.
[23:46:12] <robin44> wait how is yours different?
[23:46:20] <peerce> what about  SELECT *, (jsonb_array_length(messages) <> 50)  finished FROM ...  ?
[23:46:21] <raptelan> How can I do a query where I get a maximum of say 10 rows per value in a given column?  For example, if I want max of 10 tables per schema from pg_tables?
[23:46:26] <peerce> no CTE needed.
[23:46:58] <robin44> i believe i need a CTE or otherwise it says `messages` does not exist
[23:47:31] <peerce> um, messages is not part of whatever .... table ?  then your original CTE based statement was rather incomplete of critical information
[23:48:06] <robin44> sorry no messages is in the query as follows: `COALESCE((SELECT json_agg(messages) FROM usp_get_convo_replies(c.convo_id, 9223372036854775807, $1) as messages), '[]') messages`
[23:48:16] *** Joins: xocolatl_ (~xocolatl@138.199.15.151)
[23:48:17] <peerce> wow, see thats *entirely* different than you showed
[23:48:33] <peerce> hey, I have a white car, and its throwing a check engine light!  whats wrong?
[23:48:41] *** Quits: xocolatl (~xocolatl@138.199.15.167) (Ping timeout: 245 seconds)
[23:48:42] <robin44> huh? nuh uh
[23:48:48] <raptelan> lol
[23:48:57] <ilmari> raptelan: select n.nspname, r.relname from pg_namespace n, lateral (select relname from pg_class c where c.relnamespace = n.oid order by relname limit 10) c;
[23:49:06] <raptelan> I tried repainting it red, yet the dang light is still on!
[23:49:16] <johto> instead of doing a json_array_length(json_agg()), you could just do a LATERAL which aggregates and counts
[23:49:45] <robin44> the reason i'm not doing a lateral join is because i already have a function called get_convo_replies which would do exactly what the lateral does
[23:49:57] <robin44> and rather than repeating the sql logic i can just call the function
[23:50:22] <ilmari> robin44: did you compare the performance of that vs. the lateral?
[23:50:35] <robin44> yeah it's 1ms vs 1.2 ms (with the function)
[23:50:43] <robin44> so lateral is a bit faster but not enough to make it worth duplicating sql logic imo
[23:50:48] <ilmari> and it's the subquery that's lateral, not the join
[23:50:56] <raptelan> I found a whole bunch of string_to_array (string_agg (foo, ','), ',') bits in some queries, lol.
[23:51:17] <peerce> assuming the raw data isn't already in json, using json_agg then json_array_lenght is going to be way slower than count(...)
[23:51:31] <raptelan> ilmari: awesome, I need to get familiar with lateral again, haven't used it in ages and forgot all about it.
[23:51:36] <robin44> the raw data is not in json, correct
[23:52:19] *** Joins: zer0def (~zer0def@user/zer0def)
[23:53:43] <raptelan> ilmari: but what if pg_tables were a single table and not a view on top of two separate ones?
[23:53:57] *** Quits: iliv (~iliv@user/iliv) (Ping timeout: 260 seconds)
[23:56:02] <ilmari> raptelan: you mean if you don't have a separate table with just the values you want to get the N other values by?
[23:56:39] <ilmari> this is why you should use your actual use case when asking questions, not some other thing â€¦
[23:57:25] <ilmari> OTOH, my first question about that would have been "do you have a separate table for the entities you want n related entities for"
[23:59:02] <ilmari> you _could_ do: select a.*, b.* from (select distinct a from the_table) a, lateral (select b.b from the_table b where a.a = b.a order by x limit 10) b; but that's horribly inefficient
